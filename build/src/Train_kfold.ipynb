{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "from util.datagen import generator\n",
    "from util.model import *\n",
    "from cfg import *\n",
    "\n",
    "import segmentation_models as sm\n",
    "sm.set_framework('tf.keras')\n",
    "import tensorflow.keras.backend as k\n",
    "import gc\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "import os, glob, datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.rcParams['figure.figsize'] = (10,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterator로부터 create dataset\n",
    "test_set = tf.data.Dataset.from_generator(\n",
    "    file_gen,\n",
    "    tf.string, \n",
    "    output_shapes = tf.TensorShape([None]),\n",
    "    args = (TEST_ZIP,)\n",
    ")\n",
    "# dataset을 img load func에 mapping\n",
    "test_set = test_set.map(lambda input_paths : tf.numpy_function(\n",
    "    test_map_func,\n",
    "    [input_paths],\n",
    "    [tf.float32,tf.float32]\n",
    "),num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "# batch size\n",
    "test_set = test_set.batch(BATCH_SIZE,drop_remainder=True)\n",
    "# buffer\n",
    "test_set = test_set.prefetch(buffer_size = tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./model/tumor_100_unet_efficientnetb0_imagenet_09290.hdf5\n",
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Number of devices: 2\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Epoch 1/200\n",
      "INFO:tensorflow:batch_all_reduce: 130 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 130 all-reduces with algorithm = nccl, num_packs = 1\n",
      "      1/Unknown - 54s 54s/step - loss: 0.6082 - iou_score: 0.2170 - f1-score: 0.3564For batch 0, tr_loss is    0.61.\n",
      "      2/Unknown - 54s 481ms/step - loss: 0.5965 - iou_score: 0.2522 - f1-score: 0.4014For batch 1, tr_loss is    0.60.\n",
      "      3/Unknown - 55s 862ms/step - loss: 0.5759 - iou_score: 0.2987 - f1-score: 0.4546For batch 2, tr_loss is    0.58.\n",
      "      4/Unknown - 56s 899ms/step - loss: 0.5718 - iou_score: 0.3212 - f1-score: 0.4808For batch 3, tr_loss is    0.57.\n",
      "      5/Unknown - 57s 933ms/step - loss: 0.5547 - iou_score: 0.3489 - f1-score: 0.5106For batch 4, tr_loss is    0.55.\n",
      "      6/Unknown - 58s 872ms/step - loss: 0.5472 - iou_score: 0.3648 - f1-score: 0.5280For batch 5, tr_loss is    0.55.\n",
      "      7/Unknown - 58s 812ms/step - loss: 0.5557 - iou_score: 0.3615 - f1-score: 0.5242For batch 6, tr_loss is    0.56.\n",
      "      8/Unknown - 60s 859ms/step - loss: 0.5482 - iou_score: 0.3741 - f1-score: 0.5373For batch 7, tr_loss is    0.55.\n",
      "      9/Unknown - 61s 880ms/step - loss: 0.5373 - iou_score: 0.3899 - f1-score: 0.5532For batch 8, tr_loss is    0.54.\n",
      "     10/Unknown - 62s 895ms/step - loss: 0.5343 - iou_score: 0.3963 - f1-score: 0.5597For batch 9, tr_loss is    0.53.\n",
      "     11/Unknown - 63s 909ms/step - loss: 0.5315 - iou_score: 0.4028 - f1-score: 0.5667For batch 10, tr_loss is    0.53.\n",
      "     12/Unknown - 64s 919ms/step - loss: 0.5282 - iou_score: 0.4095 - f1-score: 0.5737For batch 11, tr_loss is    0.53.\n",
      "     13/Unknown - 65s 929ms/step - loss: 0.5243 - iou_score: 0.4178 - f1-score: 0.5820For batch 12, tr_loss is    0.52.\n",
      "     14/Unknown - 66s 916ms/step - loss: 0.5204 - iou_score: 0.4230 - f1-score: 0.5873For batch 13, tr_loss is    0.52.\n",
      "     15/Unknown - 67s 959ms/step - loss: 0.5168 - iou_score: 0.4302 - f1-score: 0.5944For batch 14, tr_loss is    0.52.\n",
      "     16/Unknown - 68s 962ms/step - loss: 0.5125 - iou_score: 0.4386 - f1-score: 0.6023For batch 15, tr_loss is    0.51.\n",
      "     17/Unknown - 69s 968ms/step - loss: 0.5070 - iou_score: 0.4466 - f1-score: 0.6098For batch 16, tr_loss is    0.51.\n",
      "     18/Unknown - 70s 952ms/step - loss: 0.5006 - iou_score: 0.4560 - f1-score: 0.6183For batch 17, tr_loss is    0.50.\n",
      "     19/Unknown - 71s 956ms/step - loss: 0.5000 - iou_score: 0.4582 - f1-score: 0.6204For batch 18, tr_loss is    0.50.\n",
      "     20/Unknown - 72s 948ms/step - loss: 0.4948 - iou_score: 0.4651 - f1-score: 0.6268For batch 19, tr_loss is    0.49.\n",
      "     21/Unknown - 73s 951ms/step - loss: 0.4912 - iou_score: 0.4705 - f1-score: 0.6318For batch 20, tr_loss is    0.49.\n",
      "     22/Unknown - 73s 945ms/step - loss: 0.4886 - iou_score: 0.4750 - f1-score: 0.6360For batch 21, tr_loss is    0.49.\n",
      "     23/Unknown - 74s 923ms/step - loss: 0.4843 - iou_score: 0.4804 - f1-score: 0.6409For batch 22, tr_loss is    0.48.\n",
      "     24/Unknown - 75s 937ms/step - loss: 0.4814 - iou_score: 0.4843 - f1-score: 0.6446For batch 23, tr_loss is    0.48.\n",
      "     25/Unknown - 76s 940ms/step - loss: 0.4774 - iou_score: 0.4892 - f1-score: 0.6490For batch 24, tr_loss is    0.48.\n",
      "     26/Unknown - 77s 931ms/step - loss: 0.4771 - iou_score: 0.4906 - f1-score: 0.6504For batch 25, tr_loss is    0.48.\n",
      "     27/Unknown - 78s 936ms/step - loss: 0.4746 - iou_score: 0.4945 - f1-score: 0.6539For batch 26, tr_loss is    0.47.\n",
      "     28/Unknown - 79s 928ms/step - loss: 0.4719 - iou_score: 0.4982 - f1-score: 0.6573For batch 27, tr_loss is    0.47.\n",
      "     29/Unknown - 79s 914ms/step - loss: 0.4699 - iou_score: 0.5009 - f1-score: 0.6598For batch 28, tr_loss is    0.47.\n",
      "     30/Unknown - 80s 924ms/step - loss: 0.4668 - iou_score: 0.5049 - f1-score: 0.6633For batch 29, tr_loss is    0.47.\n",
      "     31/Unknown - 81s 926ms/step - loss: 0.4637 - iou_score: 0.5090 - f1-score: 0.6668For batch 30, tr_loss is    0.46.\n",
      "     32/Unknown - 82s 913ms/step - loss: 0.4605 - iou_score: 0.5135 - f1-score: 0.6707For batch 31, tr_loss is    0.46.\n",
      "     33/Unknown - 83s 924ms/step - loss: 0.4578 - iou_score: 0.5171 - f1-score: 0.6738For batch 32, tr_loss is    0.46.\n",
      "     34/Unknown - 84s 926ms/step - loss: 0.4573 - iou_score: 0.5179 - f1-score: 0.6747For batch 33, tr_loss is    0.46.\n",
      "     35/Unknown - 85s 928ms/step - loss: 0.4544 - iou_score: 0.5215 - f1-score: 0.6778For batch 34, tr_loss is    0.45.\n",
      "     36/Unknown - 86s 917ms/step - loss: 0.4528 - iou_score: 0.5236 - f1-score: 0.6797For batch 35, tr_loss is    0.45.\n",
      "     37/Unknown - 87s 925ms/step - loss: 0.4522 - iou_score: 0.5245 - f1-score: 0.6807For batch 36, tr_loss is    0.45.\n",
      "     38/Unknown - 88s 927ms/step - loss: 0.4518 - iou_score: 0.5249 - f1-score: 0.6812For batch 37, tr_loss is    0.45.\n",
      "     39/Unknown - 89s 925ms/step - loss: 0.4503 - iou_score: 0.5267 - f1-score: 0.6829For batch 38, tr_loss is    0.45.\n",
      "     40/Unknown - 90s 927ms/step - loss: 0.4479 - iou_score: 0.5297 - f1-score: 0.6854For batch 39, tr_loss is    0.45.\n",
      "     41/Unknown - 90s 916ms/step - loss: 0.4468 - iou_score: 0.5309 - f1-score: 0.6865For batch 40, tr_loss is    0.45.\n",
      "     42/Unknown - 91s 923ms/step - loss: 0.4461 - iou_score: 0.5319 - f1-score: 0.6875For batch 41, tr_loss is    0.45.\n",
      "     43/Unknown - 92s 925ms/step - loss: 0.4441 - iou_score: 0.5345 - f1-score: 0.6897For batch 42, tr_loss is    0.44.\n",
      "     44/Unknown - 93s 914ms/step - loss: 0.4423 - iou_score: 0.5371 - f1-score: 0.6919For batch 43, tr_loss is    0.44.\n",
      "     45/Unknown - 94s 912ms/step - loss: 0.4413 - iou_score: 0.5387 - f1-score: 0.6933For batch 44, tr_loss is    0.44.\n",
      "     46/Unknown - 95s 914ms/step - loss: 0.4403 - iou_score: 0.5402 - f1-score: 0.6945For batch 45, tr_loss is    0.44.\n",
      "     47/Unknown - 95s 907ms/step - loss: 0.4400 - iou_score: 0.5411 - f1-score: 0.6954For batch 46, tr_loss is    0.44.\n",
      "     48/Unknown - 97s 914ms/step - loss: 0.4392 - iou_score: 0.5417 - f1-score: 0.6960For batch 47, tr_loss is    0.44.\n",
      "     49/Unknown - 98s 916ms/step - loss: 0.4377 - iou_score: 0.5434 - f1-score: 0.6975For batch 48, tr_loss is    0.44.\n",
      "     50/Unknown - 98s 909ms/step - loss: 0.4360 - iou_score: 0.5450 - f1-score: 0.6989For batch 49, tr_loss is    0.44.\n",
      "     51/Unknown - 99s 912ms/step - loss: 0.4345 - iou_score: 0.5465 - f1-score: 0.7002For batch 50, tr_loss is    0.43.\n",
      "     52/Unknown - 100s 914ms/step - loss: 0.4340 - iou_score: 0.5470 - f1-score: 0.7007For batch 51, tr_loss is    0.43.\n",
      "     53/Unknown - 101s 911ms/step - loss: 0.4332 - iou_score: 0.5480 - f1-score: 0.7017For batch 52, tr_loss is    0.43.\n",
      "     54/Unknown - 102s 907ms/step - loss: 0.4329 - iou_score: 0.5489 - f1-score: 0.7025For batch 53, tr_loss is    0.43.\n",
      "     55/Unknown - 103s 909ms/step - loss: 0.4313 - iou_score: 0.5508 - f1-score: 0.7041For batch 54, tr_loss is    0.43.\n",
      "     56/Unknown - 104s 911ms/step - loss: 0.4302 - iou_score: 0.5526 - f1-score: 0.7055For batch 55, tr_loss is    0.43.\n",
      "     57/Unknown - 105s 914ms/step - loss: 0.4298 - iou_score: 0.5533 - f1-score: 0.7062For batch 56, tr_loss is    0.43.\n",
      "     58/Unknown - 106s 916ms/step - loss: 0.4288 - iou_score: 0.5547 - f1-score: 0.7074For batch 57, tr_loss is    0.43.\n",
      "     59/Unknown - 107s 917ms/step - loss: 0.4271 - iou_score: 0.5569 - f1-score: 0.7092For batch 58, tr_loss is    0.43.\n",
      "     60/Unknown - 107s 911ms/step - loss: 0.4267 - iou_score: 0.5572 - f1-score: 0.7095For batch 59, tr_loss is    0.43.\n",
      "     61/Unknown - 109s 916ms/step - loss: 0.4273 - iou_score: 0.5572 - f1-score: 0.7096For batch 60, tr_loss is    0.43.\n",
      "     62/Unknown - 110s 916ms/step - loss: 0.4274 - iou_score: 0.5575 - f1-score: 0.7100For batch 61, tr_loss is    0.43.\n",
      "     63/Unknown - 111s 918ms/step - loss: 0.4268 - iou_score: 0.5588 - f1-score: 0.7110For batch 62, tr_loss is    0.43.\n",
      "     64/Unknown - 112s 920ms/step - loss: 0.4272 - iou_score: 0.5581 - f1-score: 0.7106For batch 63, tr_loss is    0.43.\n",
      "     65/Unknown - 113s 923ms/step - loss: 0.4256 - iou_score: 0.5605 - f1-score: 0.7124For batch 64, tr_loss is    0.43.\n",
      "     66/Unknown - 114s 925ms/step - loss: 0.4264 - iou_score: 0.5595 - f1-score: 0.7116For batch 65, tr_loss is    0.43.\n",
      "     67/Unknown - 115s 926ms/step - loss: 0.4249 - iou_score: 0.5616 - f1-score: 0.7133For batch 66, tr_loss is    0.42.\n",
      "     68/Unknown - 116s 928ms/step - loss: 0.4241 - iou_score: 0.5625 - f1-score: 0.7141For batch 67, tr_loss is    0.42.\n",
      "     69/Unknown - 117s 930ms/step - loss: 0.4244 - iou_score: 0.5621 - f1-score: 0.7137For batch 68, tr_loss is    0.42.\n",
      "     70/Unknown - 118s 932ms/step - loss: 0.4236 - iou_score: 0.5631 - f1-score: 0.7146For batch 69, tr_loss is    0.42.\n",
      "     71/Unknown - 119s 933ms/step - loss: 0.4226 - iou_score: 0.5642 - f1-score: 0.7156For batch 70, tr_loss is    0.42.\n",
      "     72/Unknown - 120s 935ms/step - loss: 0.4221 - iou_score: 0.5648 - f1-score: 0.7161For batch 71, tr_loss is    0.42.\n",
      "     73/Unknown - 121s 936ms/step - loss: 0.4209 - iou_score: 0.5662 - f1-score: 0.7173For batch 72, tr_loss is    0.42.\n",
      "     74/Unknown - 122s 937ms/step - loss: 0.4212 - iou_score: 0.5659 - f1-score: 0.7170For batch 73, tr_loss is    0.42.\n",
      "     75/Unknown - 123s 938ms/step - loss: 0.4214 - iou_score: 0.5657 - f1-score: 0.7169For batch 74, tr_loss is    0.42.\n",
      "     76/Unknown - 124s 934ms/step - loss: 0.4213 - iou_score: 0.5657 - f1-score: 0.7170For batch 75, tr_loss is    0.42.\n",
      "     77/Unknown - 125s 935ms/step - loss: 0.4206 - iou_score: 0.5665 - f1-score: 0.7177For batch 76, tr_loss is    0.42.\n",
      "     78/Unknown - 125s 928ms/step - loss: 0.4203 - iou_score: 0.5668 - f1-score: 0.7179For batch 77, tr_loss is    0.42.\n",
      "     79/Unknown - 126s 925ms/step - loss: 0.4197 - iou_score: 0.5675 - f1-score: 0.7186For batch 78, tr_loss is    0.42.\n",
      "     80/Unknown - 127s 922ms/step - loss: 0.4187 - iou_score: 0.5686 - f1-score: 0.7195For batch 79, tr_loss is    0.42.\n",
      "     81/Unknown - 127s 920ms/step - loss: 0.4172 - iou_score: 0.5705 - f1-score: 0.7210For batch 80, tr_loss is    0.42.\n",
      "     82/Unknown - 128s 919ms/step - loss: 0.4166 - iou_score: 0.5712 - f1-score: 0.7216For batch 81, tr_loss is    0.42.\n",
      "     83/Unknown - 129s 921ms/step - loss: 0.4164 - iou_score: 0.5714 - f1-score: 0.7218For batch 82, tr_loss is    0.42.\n",
      "     84/Unknown - 130s 922ms/step - loss: 0.4159 - iou_score: 0.5718 - f1-score: 0.7222For batch 83, tr_loss is    0.42.\n",
      "     85/Unknown - 131s 923ms/step - loss: 0.4160 - iou_score: 0.5716 - f1-score: 0.7220For batch 84, tr_loss is    0.42.\n",
      "     86/Unknown - 132s 918ms/step - loss: 0.4160 - iou_score: 0.5714 - f1-score: 0.7219For batch 85, tr_loss is    0.42.\n",
      "     87/Unknown - 133s 921ms/step - loss: 0.4151 - iou_score: 0.5727 - f1-score: 0.7229For batch 86, tr_loss is    0.42.\n",
      "     88/Unknown - 134s 922ms/step - loss: 0.4144 - iou_score: 0.5734 - f1-score: 0.7235For batch 87, tr_loss is    0.41.\n",
      "     89/Unknown - 135s 923ms/step - loss: 0.4146 - iou_score: 0.5732 - f1-score: 0.7234For batch 88, tr_loss is    0.41.\n",
      "     90/Unknown - 136s 924ms/step - loss: 0.4146 - iou_score: 0.5730 - f1-score: 0.7233For batch 89, tr_loss is    0.41.\n",
      "     91/Unknown - 137s 924ms/step - loss: 0.4141 - iou_score: 0.5735 - f1-score: 0.7237For batch 90, tr_loss is    0.41.\n",
      "     92/Unknown - 138s 925ms/step - loss: 0.4144 - iou_score: 0.5731 - f1-score: 0.7235For batch 91, tr_loss is    0.41.\n",
      "     93/Unknown - 139s 925ms/step - loss: 0.4142 - iou_score: 0.5733 - f1-score: 0.7237For batch 92, tr_loss is    0.41.\n",
      "     94/Unknown - 140s 926ms/step - loss: 0.4149 - iou_score: 0.5723 - f1-score: 0.7229For batch 93, tr_loss is    0.41.\n",
      "     95/Unknown - 140s 922ms/step - loss: 0.4150 - iou_score: 0.5723 - f1-score: 0.7229For batch 94, tr_loss is    0.41.\n",
      "     96/Unknown - 141s 920ms/step - loss: 0.4145 - iou_score: 0.5730 - f1-score: 0.7235For batch 95, tr_loss is    0.41.\n",
      "     97/Unknown - 142s 917ms/step - loss: 0.4146 - iou_score: 0.5728 - f1-score: 0.7234For batch 96, tr_loss is    0.41.\n",
      "     98/Unknown - 143s 919ms/step - loss: 0.4141 - iou_score: 0.5735 - f1-score: 0.7240For batch 97, tr_loss is    0.41.\n",
      "     99/Unknown - 144s 918ms/step - loss: 0.4136 - iou_score: 0.5742 - f1-score: 0.7245For batch 98, tr_loss is    0.41.\n",
      "    100/Unknown - 145s 919ms/step - loss: 0.4134 - iou_score: 0.5745 - f1-score: 0.7248For batch 99, tr_loss is    0.41.\n",
      "    101/Unknown - 145s 917ms/step - loss: 0.4132 - iou_score: 0.5749 - f1-score: 0.7252For batch 100, tr_loss is    0.41.\n",
      "    102/Unknown - 146s 912ms/step - loss: 0.4130 - iou_score: 0.5750 - f1-score: 0.7253For batch 101, tr_loss is    0.41.\n",
      "    103/Unknown - 147s 914ms/step - loss: 0.4129 - iou_score: 0.5752 - f1-score: 0.7255For batch 102, tr_loss is    0.41.\n",
      "    104/Unknown - 147s 911ms/step - loss: 0.4129 - iou_score: 0.5751 - f1-score: 0.7254For batch 103, tr_loss is    0.41.\n",
      "    105/Unknown - 149s 913ms/step - loss: 0.4129 - iou_score: 0.5752 - f1-score: 0.7255For batch 104, tr_loss is    0.41.\n",
      "    106/Unknown - 150s 914ms/step - loss: 0.4127 - iou_score: 0.5753 - f1-score: 0.7257For batch 105, tr_loss is    0.41.\n",
      "    107/Unknown - 150s 912ms/step - loss: 0.4126 - iou_score: 0.5754 - f1-score: 0.7258For batch 106, tr_loss is    0.41.\n",
      "    108/Unknown - 151s 908ms/step - loss: 0.4124 - iou_score: 0.5757 - f1-score: 0.7260For batch 107, tr_loss is    0.41.\n",
      "    109/Unknown - 152s 906ms/step - loss: 0.4118 - iou_score: 0.5763 - f1-score: 0.7265For batch 108, tr_loss is    0.41.\n",
      "    110/Unknown - 152s 904ms/step - loss: 0.4112 - iou_score: 0.5769 - f1-score: 0.7270For batch 109, tr_loss is    0.41.\n",
      "    111/Unknown - 153s 902ms/step - loss: 0.4104 - iou_score: 0.5780 - f1-score: 0.7278For batch 110, tr_loss is    0.41.\n",
      "    112/Unknown - 154s 901ms/step - loss: 0.4101 - iou_score: 0.5780 - f1-score: 0.7279For batch 111, tr_loss is    0.41.\n",
      "    113/Unknown - 155s 902ms/step - loss: 0.4112 - iou_score: 0.5771 - f1-score: 0.7271For batch 112, tr_loss is    0.41.\n",
      "    114/Unknown - 156s 903ms/step - loss: 0.4113 - iou_score: 0.5768 - f1-score: 0.7269For batch 113, tr_loss is    0.41.\n",
      "    115/Unknown - 157s 904ms/step - loss: 0.4110 - iou_score: 0.5771 - f1-score: 0.7271For batch 114, tr_loss is    0.41.\n",
      "    116/Unknown - 158s 905ms/step - loss: 0.4112 - iou_score: 0.5768 - f1-score: 0.7269For batch 115, tr_loss is    0.41.\n",
      "    117/Unknown - 158s 901ms/step - loss: 0.4112 - iou_score: 0.5770 - f1-score: 0.7271For batch 116, tr_loss is    0.41.\n",
      "    118/Unknown - 159s 903ms/step - loss: 0.4108 - iou_score: 0.5776 - f1-score: 0.7276For batch 117, tr_loss is    0.41.\n",
      "    119/Unknown - 160s 901ms/step - loss: 0.4106 - iou_score: 0.5777 - f1-score: 0.7277For batch 118, tr_loss is    0.41.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    120/Unknown - 161s 902ms/step - loss: 0.4099 - iou_score: 0.5787 - f1-score: 0.7285For batch 119, tr_loss is    0.41.\n",
      "    121/Unknown - 162s 902ms/step - loss: 0.4093 - iou_score: 0.5796 - f1-score: 0.7292For batch 120, tr_loss is    0.41.\n",
      "    122/Unknown - 163s 902ms/step - loss: 0.4091 - iou_score: 0.5799 - f1-score: 0.7295For batch 121, tr_loss is    0.41.\n",
      "    123/Unknown - 163s 898ms/step - loss: 0.4093 - iou_score: 0.5795 - f1-score: 0.7292For batch 122, tr_loss is    0.41.\n",
      "    124/Unknown - 164s 899ms/step - loss: 0.4092 - iou_score: 0.5797 - f1-score: 0.7294For batch 123, tr_loss is    0.41.\n",
      "    125/Unknown - 165s 897ms/step - loss: 0.4093 - iou_score: 0.5797 - f1-score: 0.7294For batch 124, tr_loss is    0.41.\n",
      "    126/Unknown - 166s 899ms/step - loss: 0.4087 - iou_score: 0.5805 - f1-score: 0.7300For batch 125, tr_loss is    0.41.\n",
      "    127/Unknown - 167s 900ms/step - loss: 0.4082 - iou_score: 0.5810 - f1-score: 0.7304For batch 126, tr_loss is    0.41.\n",
      "    128/Unknown - 168s 900ms/step - loss: 0.4090 - iou_score: 0.5800 - f1-score: 0.7296For batch 127, tr_loss is    0.41.\n",
      "    129/Unknown - 168s 897ms/step - loss: 0.4087 - iou_score: 0.5804 - f1-score: 0.7299For batch 128, tr_loss is    0.41.\n",
      "    130/Unknown - 170s 899ms/step - loss: 0.4082 - iou_score: 0.5810 - f1-score: 0.7305For batch 129, tr_loss is    0.41.\n",
      "    131/Unknown - 171s 899ms/step - loss: 0.4078 - iou_score: 0.5813 - f1-score: 0.7307For batch 130, tr_loss is    0.41.\n",
      "    132/Unknown - 171s 897ms/step - loss: 0.4072 - iou_score: 0.5820 - f1-score: 0.7312For batch 131, tr_loss is    0.41.\n",
      "    133/Unknown - 172s 895ms/step - loss: 0.4071 - iou_score: 0.5821 - f1-score: 0.7314For batch 132, tr_loss is    0.41.\n",
      "    134/Unknown - 173s 895ms/step - loss: 0.4075 - iou_score: 0.5817 - f1-score: 0.7311For batch 133, tr_loss is    0.41.\n",
      "    135/Unknown - 174s 895ms/step - loss: 0.4076 - iou_score: 0.5818 - f1-score: 0.7311For batch 134, tr_loss is    0.41.\n",
      "    136/Unknown - 174s 892ms/step - loss: 0.4076 - iou_score: 0.5818 - f1-score: 0.7312For batch 135, tr_loss is    0.41.\n",
      "    137/Unknown - 175s 892ms/step - loss: 0.4081 - iou_score: 0.5810 - f1-score: 0.7305For batch 136, tr_loss is    0.41.\n",
      "    138/Unknown - 176s 890ms/step - loss: 0.4080 - iou_score: 0.5812 - f1-score: 0.7307For batch 137, tr_loss is    0.41.\n",
      "    139/Unknown - 176s 890ms/step - loss: 0.4076 - iou_score: 0.5816 - f1-score: 0.7311For batch 138, tr_loss is    0.41.\n",
      "    140/Unknown - 177s 891ms/step - loss: 0.4083 - iou_score: 0.5808 - f1-score: 0.7303For batch 139, tr_loss is    0.41.\n",
      "    141/Unknown - 178s 892ms/step - loss: 0.4086 - iou_score: 0.5805 - f1-score: 0.7301For batch 140, tr_loss is    0.41.\n",
      "    142/Unknown - 179s 893ms/step - loss: 0.4080 - iou_score: 0.5814 - f1-score: 0.7308For batch 141, tr_loss is    0.41.\n",
      "    143/Unknown - 180s 893ms/step - loss: 0.4079 - iou_score: 0.5816 - f1-score: 0.7309For batch 142, tr_loss is    0.41.\n",
      "    144/Unknown - 181s 893ms/step - loss: 0.4080 - iou_score: 0.5815 - f1-score: 0.7308For batch 143, tr_loss is    0.41.\n",
      "    145/Unknown - 182s 890ms/step - loss: 0.4080 - iou_score: 0.5814 - f1-score: 0.7308For batch 144, tr_loss is    0.41.\n",
      "    146/Unknown - 182s 888ms/step - loss: 0.4074 - iou_score: 0.5823 - f1-score: 0.7315For batch 145, tr_loss is    0.41.\n",
      "    147/Unknown - 183s 887ms/step - loss: 0.4073 - iou_score: 0.5824 - f1-score: 0.7316For batch 146, tr_loss is    0.41.\n",
      "    148/Unknown - 184s 887ms/step - loss: 0.4066 - iou_score: 0.5833 - f1-score: 0.7322For batch 147, tr_loss is    0.41.\n",
      "    149/Unknown - 185s 888ms/step - loss: 0.4063 - iou_score: 0.5836 - f1-score: 0.7325For batch 148, tr_loss is    0.41.\n",
      "    150/Unknown - 185s 885ms/step - loss: 0.4056 - iou_score: 0.5845 - f1-score: 0.7332For batch 149, tr_loss is    0.41.\n",
      "    151/Unknown - 187s 887ms/step - loss: 0.4056 - iou_score: 0.5845 - f1-score: 0.7332For batch 150, tr_loss is    0.41.\n",
      "    152/Unknown - 187s 886ms/step - loss: 0.4054 - iou_score: 0.5848 - f1-score: 0.7334For batch 151, tr_loss is    0.41.\n",
      "    153/Unknown - 188s 883ms/step - loss: 0.4050 - iou_score: 0.5852 - f1-score: 0.7338For batch 152, tr_loss is    0.40.\n",
      "    154/Unknown - 189s 883ms/step - loss: 0.4051 - iou_score: 0.5851 - f1-score: 0.7338For batch 153, tr_loss is    0.41.\n",
      "    155/Unknown - 190s 885ms/step - loss: 0.4048 - iou_score: 0.5855 - f1-score: 0.7341For batch 154, tr_loss is    0.40.\n",
      "    156/Unknown - 191s 884ms/step - loss: 0.4043 - iou_score: 0.5861 - f1-score: 0.7345For batch 155, tr_loss is    0.40.\n",
      "    157/Unknown - 191s 882ms/step - loss: 0.4043 - iou_score: 0.5859 - f1-score: 0.7344For batch 156, tr_loss is    0.40.\n",
      "    158/Unknown - 192s 880ms/step - loss: 0.4044 - iou_score: 0.5859 - f1-score: 0.7344For batch 157, tr_loss is    0.40.\n",
      "    159/Unknown - 193s 880ms/step - loss: 0.4044 - iou_score: 0.5859 - f1-score: 0.7344For batch 158, tr_loss is    0.40.\n",
      "    160/Unknown - 193s 878ms/step - loss: 0.4043 - iou_score: 0.5859 - f1-score: 0.7344For batch 159, tr_loss is    0.40.\n",
      "    161/Unknown - 194s 879ms/step - loss: 0.4043 - iou_score: 0.5858 - f1-score: 0.7344For batch 160, tr_loss is    0.40.\n",
      "    162/Unknown - 195s 880ms/step - loss: 0.4043 - iou_score: 0.5858 - f1-score: 0.7345For batch 161, tr_loss is    0.40.\n",
      "    163/Unknown - 196s 880ms/step - loss: 0.4036 - iou_score: 0.5867 - f1-score: 0.7351For batch 162, tr_loss is    0.40.\n",
      "    164/Unknown - 197s 881ms/step - loss: 0.4034 - iou_score: 0.5869 - f1-score: 0.7353For batch 163, tr_loss is    0.40.\n",
      "    165/Unknown - 198s 879ms/step - loss: 0.4029 - iou_score: 0.5875 - f1-score: 0.7358For batch 164, tr_loss is    0.40.\n",
      "    166/Unknown - 198s 878ms/step - loss: 0.4029 - iou_score: 0.5876 - f1-score: 0.7358For batch 165, tr_loss is    0.40.\n",
      "    167/Unknown - 200s 879ms/step - loss: 0.4021 - iou_score: 0.5886 - f1-score: 0.7366For batch 166, tr_loss is    0.40.\n",
      "    168/Unknown - 200s 879ms/step - loss: 0.4021 - iou_score: 0.5885 - f1-score: 0.7365For batch 167, tr_loss is    0.40.\n",
      "    169/Unknown - 201s 880ms/step - loss: 0.4021 - iou_score: 0.5885 - f1-score: 0.7365For batch 168, tr_loss is    0.40.\n",
      "    170/Unknown - 202s 880ms/step - loss: 0.4016 - iou_score: 0.5891 - f1-score: 0.7370For batch 169, tr_loss is    0.40.\n",
      "    171/Unknown - 203s 881ms/step - loss: 0.4015 - iou_score: 0.5893 - f1-score: 0.7372For batch 170, tr_loss is    0.40.\n",
      "    172/Unknown - 204s 882ms/step - loss: 0.4010 - iou_score: 0.5899 - f1-score: 0.7377For batch 171, tr_loss is    0.40.\n",
      "    173/Unknown - 205s 883ms/step - loss: 0.4007 - iou_score: 0.5902 - f1-score: 0.7379For batch 172, tr_loss is    0.40.\n",
      "    174/Unknown - 206s 884ms/step - loss: 0.4003 - iou_score: 0.5906 - f1-score: 0.7382For batch 173, tr_loss is    0.40.\n",
      "    175/Unknown - 208s 884ms/step - loss: 0.3999 - iou_score: 0.5911 - f1-score: 0.7386For batch 174, tr_loss is    0.40.\n",
      "    176/Unknown - 208s 882ms/step - loss: 0.3998 - iou_score: 0.5911 - f1-score: 0.7386For batch 175, tr_loss is    0.40.\n",
      "    177/Unknown - 209s 882ms/step - loss: 0.3994 - iou_score: 0.5916 - f1-score: 0.7390For batch 176, tr_loss is    0.40.\n",
      "    178/Unknown - 209s 880ms/step - loss: 0.3997 - iou_score: 0.5911 - f1-score: 0.7386For batch 177, tr_loss is    0.40.\n",
      "    179/Unknown - 211s 882ms/step - loss: 0.3991 - iou_score: 0.5918 - f1-score: 0.7391For batch 178, tr_loss is    0.40.\n",
      "    180/Unknown - 211s 880ms/step - loss: 0.3992 - iou_score: 0.5917 - f1-score: 0.7391For batch 179, tr_loss is    0.40.\n",
      "    181/Unknown - 212s 878ms/step - loss: 0.3991 - iou_score: 0.5918 - f1-score: 0.7392For batch 180, tr_loss is    0.40.\n",
      "    182/Unknown - 213s 879ms/step - loss: 0.3990 - iou_score: 0.5919 - f1-score: 0.7393For batch 181, tr_loss is    0.40.\n",
      "    183/Unknown - 213s 877ms/step - loss: 0.3989 - iou_score: 0.5920 - f1-score: 0.7394For batch 182, tr_loss is    0.40.\n",
      "    184/Unknown - 214s 876ms/step - loss: 0.3984 - iou_score: 0.5926 - f1-score: 0.7398For batch 183, tr_loss is    0.40.\n",
      "    185/Unknown - 215s 875ms/step - loss: 0.3981 - iou_score: 0.5929 - f1-score: 0.7400For batch 184, tr_loss is    0.40.\n",
      "    186/Unknown - 216s 876ms/step - loss: 0.3979 - iou_score: 0.5932 - f1-score: 0.7403For batch 185, tr_loss is    0.40.\n",
      "    187/Unknown - 217s 877ms/step - loss: 0.3977 - iou_score: 0.5935 - f1-score: 0.7405For batch 186, tr_loss is    0.40.\n",
      "    188/Unknown - 217s 876ms/step - loss: 0.3973 - iou_score: 0.5939 - f1-score: 0.7409For batch 187, tr_loss is    0.40.\n",
      "    189/Unknown - 218s 874ms/step - loss: 0.3973 - iou_score: 0.5939 - f1-score: 0.7409For batch 188, tr_loss is    0.40.\n",
      "    190/Unknown - 219s 874ms/step - loss: 0.3973 - iou_score: 0.5938 - f1-score: 0.7408For batch 189, tr_loss is    0.40.\n",
      "    191/Unknown - 220s 873ms/step - loss: 0.3977 - iou_score: 0.5933 - f1-score: 0.7404For batch 190, tr_loss is    0.40.\n",
      "    192/Unknown - 221s 874ms/step - loss: 0.3980 - iou_score: 0.5930 - f1-score: 0.7402For batch 191, tr_loss is    0.40.\n",
      "    193/Unknown - 221s 873ms/step - loss: 0.3976 - iou_score: 0.5934 - f1-score: 0.7405For batch 192, tr_loss is    0.40.\n",
      "    194/Unknown - 222s 871ms/step - loss: 0.3975 - iou_score: 0.5934 - f1-score: 0.7405For batch 193, tr_loss is    0.40.\n",
      "    195/Unknown - 222s 868ms/step - loss: 0.3975 - iou_score: 0.5934 - f1-score: 0.7405For batch 194, tr_loss is    0.40.\n",
      "    196/Unknown - 222s 866ms/step - loss: 0.3975 - iou_score: 0.5934 - f1-score: 0.7405For batch 195, tr_loss is    0.40.\n",
      "    197/Unknown - 223s 863ms/step - loss: 0.3970 - iou_score: 0.5940 - f1-score: 0.7410For batch 196, tr_loss is    0.40.\n",
      "    198/Unknown - 223s 860ms/step - loss: 0.3971 - iou_score: 0.5939 - f1-score: 0.7409For batch 197, tr_loss is    0.40.\n",
      "    199/Unknown - 223s 857ms/step - loss: 0.3972 - iou_score: 0.5937 - f1-score: 0.7408For batch 198, tr_loss is    0.40.\n",
      "    200/Unknown - 224s 855ms/step - loss: 0.3969 - iou_score: 0.5939 - f1-score: 0.7410For batch 199, tr_loss is    0.40.\n",
      "For batch 0, vl_loss is    0.60.\n",
      "For batch 1, vl_loss is    0.53.\n",
      "For batch 2, vl_loss is    0.51.\n",
      "For batch 3, vl_loss is    0.51.\n",
      "For batch 4, vl_loss is    0.50.\n",
      "For batch 5, vl_loss is    0.48.\n",
      "For batch 6, vl_loss is    0.48.\n",
      "For batch 7, vl_loss is    0.47.\n",
      "For batch 8, vl_loss is    0.48.\n",
      "For batch 9, vl_loss is    0.49.\n",
      "For batch 10, vl_loss is    0.50.\n",
      "For batch 11, vl_loss is    0.48.\n",
      "For batch 12, vl_loss is    0.48.\n",
      "For batch 13, vl_loss is    0.48.\n",
      "For batch 14, vl_loss is    0.48.\n",
      "For batch 15, vl_loss is    0.47.\n",
      "For batch 16, vl_loss is    0.47.\n",
      "For batch 17, vl_loss is    0.48.\n",
      "For batch 18, vl_loss is    0.47.\n",
      "For batch 19, vl_loss is    0.47.\n",
      "For batch 20, vl_loss is    0.47.\n",
      "For batch 21, vl_loss is    0.47.\n",
      "For batch 22, vl_loss is    0.47.\n",
      "For batch 23, vl_loss is    0.47.\n",
      "For batch 24, vl_loss is    0.47.\n",
      "For batch 25, vl_loss is    0.48.\n",
      "For batch 26, vl_loss is    0.48.\n",
      "For batch 27, vl_loss is    0.48.\n",
      "For batch 28, vl_loss is    0.48.\n",
      "For batch 29, vl_loss is    0.48.\n",
      "For batch 30, vl_loss is    0.48.\n",
      "For batch 31, vl_loss is    0.48.\n",
      "For batch 32, vl_loss is    0.48.\n",
      "For batch 33, vl_loss is    0.48.\n",
      "For batch 34, vl_loss is    0.48.\n",
      "For batch 35, vl_loss is    0.48.\n",
      "For batch 36, vl_loss is    0.48.\n",
      "For batch 37, vl_loss is    0.48.\n",
      "For batch 38, vl_loss is    0.48.\n",
      "For batch 39, vl_loss is    0.49.\n",
      "For batch 40, vl_loss is    0.49.\n",
      "For batch 41, vl_loss is    0.48.\n",
      "For batch 42, vl_loss is    0.49.\n",
      "For batch 43, vl_loss is    0.49.\n",
      "For batch 44, vl_loss is    0.49.\n",
      "For batch 45, vl_loss is    0.49.\n",
      "For batch 46, vl_loss is    0.49.\n",
      "For batch 47, vl_loss is    0.49.\n",
      "For batch 48, vl_loss is    0.49.\n",
      "For batch 49, vl_loss is    0.49.\n",
      "For batch 50, vl_loss is    0.49.\n",
      "For batch 51, vl_loss is    0.49.\n",
      "For batch 52, vl_loss is    0.49.\n",
      "For batch 53, vl_loss is    0.49.\n",
      "For batch 54, vl_loss is    0.49.\n",
      "For batch 55, vl_loss is    0.49.\n",
      "For batch 56, vl_loss is    0.49.\n",
      "For batch 57, vl_loss is    0.49.\n",
      "For batch 58, vl_loss is    0.49.\n",
      "For batch 59, vl_loss is    0.49.\n",
      "For batch 60, vl_loss is    0.50.\n",
      "For batch 61, vl_loss is    0.50.\n",
      "For batch 62, vl_loss is    0.49.\n",
      "For batch 63, vl_loss is    0.49.\n",
      "For batch 64, vl_loss is    0.50.\n",
      "For batch 65, vl_loss is    0.49.\n",
      "For batch 66, vl_loss is    0.49.\n",
      "For batch 67, vl_loss is    0.49.\n",
      "For batch 68, vl_loss is    0.49.\n",
      "For batch 69, vl_loss is    0.49.\n",
      "For batch 70, vl_loss is    0.50.\n",
      "For batch 71, vl_loss is    0.49.\n",
      "For batch 72, vl_loss is    0.49.\n",
      "For batch 73, vl_loss is    0.50.\n",
      "For batch 74, vl_loss is    0.50.\n",
      "For batch 75, vl_loss is    0.49.\n",
      "For batch 76, vl_loss is    0.49.\n",
      "For batch 77, vl_loss is    0.49.\n",
      "For batch 78, vl_loss is    0.49.\n",
      "For batch 79, vl_loss is    0.49.\n",
      "For batch 80, vl_loss is    0.49.\n",
      "For batch 81, vl_loss is    0.49.\n",
      "For batch 82, vl_loss is    0.49.\n",
      "For batch 83, vl_loss is    0.50.\n",
      "For batch 84, vl_loss is    0.49.\n",
      "For batch 85, vl_loss is    0.49.\n",
      "For batch 86, vl_loss is    0.50.\n",
      "For batch 87, vl_loss is    0.49.\n",
      "For batch 88, vl_loss is    0.49.\n",
      "For batch 89, vl_loss is    0.49.\n",
      "For batch 90, vl_loss is    0.50.\n",
      "For batch 91, vl_loss is    0.50.\n",
      "For batch 92, vl_loss is    0.50.\n",
      "For batch 93, vl_loss is    0.50.\n",
      "For batch 94, vl_loss is    0.50.\n",
      "For batch 95, vl_loss is    0.50.\n",
      "For batch 96, vl_loss is    0.50.\n",
      "For batch 97, vl_loss is    0.50.\n",
      "For batch 98, vl_loss is    0.50.\n",
      "For batch 99, vl_loss is    0.50.\n",
      "200/200 [==============================] - 237s 923ms/step - loss: 0.3969 - iou_score: 0.5939 - f1-score: 0.7410 - val_loss: 0.5045 - val_iou_score: 0.6468 - val_f1-score: 0.7834\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.50450, saving model to ./model/tumor_100_unet_efficientnetb0_imagenet_09290.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average loss for epoch 0 is    0.40 \n",
      "Epoch 2/200\n",
      "INFO:tensorflow:batch_all_reduce: 130 all-reduces with algorithm = nccl, num_packs = 1\n",
      "  1/200 [..............................] - ETA: 1:42:30 - loss: 0.3495 - iou_score: 0.6375 - f1-score: 0.7784For batch 0, tr_loss is    0.35.\n",
      "  2/200 [..............................] - ETA: 4:21 - loss: 0.3476 - iou_score: 0.6416 - f1-score: 0.7806   For batch 1, tr_loss is    0.35.\n",
      "  3/200 [..............................] - ETA: 4:08 - loss: 0.3527 - iou_score: 0.6391 - f1-score: 0.7786For batch 2, tr_loss is    0.35.\n",
      "  4/200 [..............................] - ETA: 4:01 - loss: 0.3572 - iou_score: 0.6332 - f1-score: 0.7744For batch 3, tr_loss is    0.36.\n",
      "  5/200 [..............................] - ETA: 3:57 - loss: 0.3599 - iou_score: 0.6328 - f1-score: 0.7740For batch 4, tr_loss is    0.36.\n",
      "  6/200 [..............................] - ETA: 4:04 - loss: 0.3733 - iou_score: 0.6198 - f1-score: 0.7638For batch 5, tr_loss is    0.37.\n",
      "  7/200 [>.............................] - ETA: 4:08 - loss: 0.3830 - iou_score: 0.6069 - f1-score: 0.7527For batch 6, tr_loss is    0.38.\n",
      "  8/200 [>.............................] - ETA: 4:11 - loss: 0.3814 - iou_score: 0.6083 - f1-score: 0.7540For batch 7, tr_loss is    0.38.\n",
      "  9/200 [>.............................] - ETA: 4:18 - loss: 0.3755 - iou_score: 0.6176 - f1-score: 0.7608For batch 8, tr_loss is    0.38.\n",
      " 10/200 [>.............................] - ETA: 4:08 - loss: 0.3775 - iou_score: 0.6161 - f1-score: 0.7595For batch 9, tr_loss is    0.38.\n",
      " 11/200 [>.............................] - ETA: 3:51 - loss: 0.3760 - iou_score: 0.6175 - f1-score: 0.7608For batch 10, tr_loss is    0.38.\n",
      " 12/200 [>.............................] - ETA: 3:48 - loss: 0.3785 - iou_score: 0.6133 - f1-score: 0.7576For batch 11, tr_loss is    0.38.\n",
      " 13/200 [>.............................] - ETA: 3:44 - loss: 0.3801 - iou_score: 0.6107 - f1-score: 0.7557For batch 12, tr_loss is    0.38.\n",
      " 14/200 [=>............................] - ETA: 3:37 - loss: 0.3808 - iou_score: 0.6096 - f1-score: 0.7550For batch 13, tr_loss is    0.38.\n",
      " 15/200 [=>............................] - ETA: 3:34 - loss: 0.3795 - iou_score: 0.6105 - f1-score: 0.7558For batch 14, tr_loss is    0.38.\n",
      " 16/200 [=>............................] - ETA: 3:31 - loss: 0.3798 - iou_score: 0.6099 - f1-score: 0.7555For batch 15, tr_loss is    0.38.\n",
      " 17/200 [=>............................] - ETA: 3:29 - loss: 0.3789 - iou_score: 0.6110 - f1-score: 0.7564For batch 16, tr_loss is    0.38.\n",
      " 18/200 [=>............................] - ETA: 3:26 - loss: 0.3759 - iou_score: 0.6141 - f1-score: 0.7588For batch 17, tr_loss is    0.38.\n",
      " 19/200 [=>............................] - ETA: 3:24 - loss: 0.3782 - iou_score: 0.6120 - f1-score: 0.7570For batch 18, tr_loss is    0.38.\n",
      " 20/200 [==>...........................] - ETA: 3:19 - loss: 0.3751 - iou_score: 0.6161 - f1-score: 0.7601For batch 19, tr_loss is    0.38.\n",
      " 21/200 [==>...........................] - ETA: 3:17 - loss: 0.3725 - iou_score: 0.6194 - f1-score: 0.7626For batch 20, tr_loss is    0.37.\n",
      " 22/200 [==>...........................] - ETA: 3:15 - loss: 0.3716 - iou_score: 0.6211 - f1-score: 0.7640For batch 21, tr_loss is    0.37.\n",
      " 23/200 [==>...........................] - ETA: 3:10 - loss: 0.3701 - iou_score: 0.6231 - f1-score: 0.7655For batch 22, tr_loss is    0.37.\n",
      " 24/200 [==>...........................] - ETA: 3:08 - loss: 0.3699 - iou_score: 0.6230 - f1-score: 0.7655For batch 23, tr_loss is    0.37.\n",
      " 25/200 [==>...........................] - ETA: 3:06 - loss: 0.3687 - iou_score: 0.6241 - f1-score: 0.7664For batch 24, tr_loss is    0.37.\n",
      " 26/200 [==>...........................] - ETA: 3:03 - loss: 0.3713 - iou_score: 0.6219 - f1-score: 0.7647For batch 25, tr_loss is    0.37.\n",
      " 27/200 [===>..........................] - ETA: 3:02 - loss: 0.3700 - iou_score: 0.6237 - f1-score: 0.7661For batch 26, tr_loss is    0.37.\n",
      " 28/200 [===>..........................] - ETA: 3:01 - loss: 0.3692 - iou_score: 0.6248 - f1-score: 0.7670For batch 27, tr_loss is    0.37.\n",
      " 29/200 [===>..........................] - ETA: 3:00 - loss: 0.3694 - iou_score: 0.6244 - f1-score: 0.7667For batch 28, tr_loss is    0.37.\n",
      " 30/200 [===>..........................] - ETA: 2:55 - loss: 0.3683 - iou_score: 0.6256 - f1-score: 0.7676For batch 29, tr_loss is    0.37.\n",
      " 31/200 [===>..........................] - ETA: 2:52 - loss: 0.3667 - iou_score: 0.6278 - f1-score: 0.7692For batch 30, tr_loss is    0.37.\n",
      " 32/200 [===>..........................] - ETA: 2:50 - loss: 0.3649 - iou_score: 0.6300 - f1-score: 0.7708For batch 31, tr_loss is    0.36.\n",
      " 33/200 [===>..........................] - ETA: 2:46 - loss: 0.3633 - iou_score: 0.6317 - f1-score: 0.7721For batch 32, tr_loss is    0.36.\n",
      " 34/200 [====>.........................] - ETA: 2:46 - loss: 0.3640 - iou_score: 0.6309 - f1-score: 0.7715For batch 33, tr_loss is    0.36.\n",
      " 35/200 [====>.........................] - ETA: 2:45 - loss: 0.3628 - iou_score: 0.6324 - f1-score: 0.7727For batch 34, tr_loss is    0.36.\n",
      " 36/200 [====>.........................] - ETA: 2:42 - loss: 0.3624 - iou_score: 0.6330 - f1-score: 0.7732For batch 35, tr_loss is    0.36.\n",
      " 37/200 [====>.........................] - ETA: 2:41 - loss: 0.3628 - iou_score: 0.6323 - f1-score: 0.7726For batch 36, tr_loss is    0.36.\n",
      " 38/200 [====>.........................] - ETA: 2:40 - loss: 0.3636 - iou_score: 0.6310 - f1-score: 0.7717For batch 37, tr_loss is    0.36.\n",
      " 39/200 [====>.........................] - ETA: 2:38 - loss: 0.3627 - iou_score: 0.6320 - f1-score: 0.7725For batch 38, tr_loss is    0.36.\n",
      " 40/200 [=====>........................] - ETA: 2:37 - loss: 0.3612 - iou_score: 0.6335 - f1-score: 0.7736For batch 39, tr_loss is    0.36.\n",
      " 41/200 [=====>........................] - ETA: 2:37 - loss: 0.3610 - iou_score: 0.6334 - f1-score: 0.7735For batch 40, tr_loss is    0.36.\n",
      " 42/200 [=====>........................] - ETA: 2:36 - loss: 0.3616 - iou_score: 0.6327 - f1-score: 0.7730For batch 41, tr_loss is    0.36.\n",
      " 43/200 [=====>........................] - ETA: 2:35 - loss: 0.3616 - iou_score: 0.6330 - f1-score: 0.7733For batch 42, tr_loss is    0.36.\n",
      " 44/200 [=====>........................] - ETA: 2:32 - loss: 0.3613 - iou_score: 0.6338 - f1-score: 0.7739For batch 43, tr_loss is    0.36.\n",
      " 45/200 [=====>........................] - ETA: 2:31 - loss: 0.3617 - iou_score: 0.6338 - f1-score: 0.7739For batch 44, tr_loss is    0.36.\n",
      " 46/200 [=====>........................] - ETA: 2:29 - loss: 0.3624 - iou_score: 0.6334 - f1-score: 0.7736For batch 45, tr_loss is    0.36.\n",
      " 47/200 [======>.......................] - ETA: 2:28 - loss: 0.3634 - iou_score: 0.6326 - f1-score: 0.7730For batch 46, tr_loss is    0.36.\n",
      " 48/200 [======>.......................] - ETA: 2:28 - loss: 0.3636 - iou_score: 0.6323 - f1-score: 0.7728For batch 47, tr_loss is    0.36.\n",
      " 49/200 [======>.......................] - ETA: 2:25 - loss: 0.3631 - iou_score: 0.6328 - f1-score: 0.7732For batch 48, tr_loss is    0.36.\n",
      " 50/200 [======>.......................] - ETA: 2:24 - loss: 0.3625 - iou_score: 0.6334 - f1-score: 0.7736For batch 49, tr_loss is    0.36.\n",
      " 51/200 [======>.......................] - ETA: 2:22 - loss: 0.3623 - iou_score: 0.6335 - f1-score: 0.7737For batch 50, tr_loss is    0.36.\n",
      " 52/200 [======>.......................] - ETA: 2:21 - loss: 0.3626 - iou_score: 0.6331 - f1-score: 0.7734For batch 51, tr_loss is    0.36.\n",
      " 53/200 [======>.......................] - ETA: 2:21 - loss: 0.3623 - iou_score: 0.6335 - f1-score: 0.7737For batch 52, tr_loss is    0.36.\n",
      " 54/200 [=======>......................] - ETA: 2:19 - loss: 0.3627 - iou_score: 0.6330 - f1-score: 0.7734For batch 53, tr_loss is    0.36.\n",
      " 55/200 [=======>......................] - ETA: 2:17 - loss: 0.3616 - iou_score: 0.6343 - f1-score: 0.7743For batch 54, tr_loss is    0.36.\n",
      " 56/200 [=======>......................] - ETA: 2:16 - loss: 0.3618 - iou_score: 0.6342 - f1-score: 0.7742For batch 55, tr_loss is    0.36.\n",
      " 57/200 [=======>......................] - ETA: 2:16 - loss: 0.3620 - iou_score: 0.6339 - f1-score: 0.7740For batch 56, tr_loss is    0.36.\n",
      " 58/200 [=======>......................] - ETA: 2:14 - loss: 0.3619 - iou_score: 0.6341 - f1-score: 0.7742For batch 57, tr_loss is    0.36.\n",
      " 59/200 [=======>......................] - ETA: 2:12 - loss: 0.3608 - iou_score: 0.6352 - f1-score: 0.7750For batch 58, tr_loss is    0.36.\n",
      " 60/200 [========>.....................] - ETA: 2:12 - loss: 0.3605 - iou_score: 0.6351 - f1-score: 0.7749For batch 59, tr_loss is    0.36.\n",
      " 61/200 [========>.....................] - ETA: 2:11 - loss: 0.3613 - iou_score: 0.6345 - f1-score: 0.7745For batch 60, tr_loss is    0.36.\n",
      " 62/200 [========>.....................] - ETA: 2:10 - loss: 0.3610 - iou_score: 0.6348 - f1-score: 0.7748For batch 61, tr_loss is    0.36.\n",
      " 63/200 [========>.....................] - ETA: 2:09 - loss: 0.3607 - iou_score: 0.6353 - f1-score: 0.7752For batch 62, tr_loss is    0.36.\n",
      " 64/200 [========>.....................] - ETA: 2:09 - loss: 0.3615 - iou_score: 0.6340 - f1-score: 0.7742For batch 63, tr_loss is    0.36.\n",
      " 65/200 [========>.....................] - ETA: 2:07 - loss: 0.3601 - iou_score: 0.6357 - f1-score: 0.7754For batch 64, tr_loss is    0.36.\n",
      " 66/200 [========>.....................] - ETA: 2:05 - loss: 0.3617 - iou_score: 0.6338 - f1-score: 0.7738For batch 65, tr_loss is    0.36.\n",
      " 67/200 [=========>....................] - ETA: 2:05 - loss: 0.3608 - iou_score: 0.6346 - f1-score: 0.7744For batch 66, tr_loss is    0.36.\n",
      " 68/200 [=========>....................] - ETA: 2:04 - loss: 0.3605 - iou_score: 0.6348 - f1-score: 0.7745For batch 67, tr_loss is    0.36.\n",
      " 69/200 [=========>....................] - ETA: 2:02 - loss: 0.3611 - iou_score: 0.6336 - f1-score: 0.7736For batch 68, tr_loss is    0.36.\n",
      " 70/200 [=========>....................] - ETA: 2:02 - loss: 0.3611 - iou_score: 0.6338 - f1-score: 0.7738For batch 69, tr_loss is    0.36.\n",
      " 71/200 [=========>....................] - ETA: 2:00 - loss: 0.3607 - iou_score: 0.6343 - f1-score: 0.7742For batch 70, tr_loss is    0.36.\n",
      " 72/200 [=========>....................] - ETA: 2:00 - loss: 0.3608 - iou_score: 0.6343 - f1-score: 0.7742For batch 71, tr_loss is    0.36.\n",
      " 73/200 [=========>....................] - ETA: 1:58 - loss: 0.3603 - iou_score: 0.6348 - f1-score: 0.7746For batch 72, tr_loss is    0.36.\n",
      " 74/200 [==========>...................] - ETA: 1:57 - loss: 0.3607 - iou_score: 0.6340 - f1-score: 0.7740For batch 73, tr_loss is    0.36.\n",
      " 75/200 [==========>...................] - ETA: 1:56 - loss: 0.3613 - iou_score: 0.6330 - f1-score: 0.7732For batch 74, tr_loss is    0.36.\n",
      " 76/200 [==========>...................] - ETA: 1:54 - loss: 0.3615 - iou_score: 0.6326 - f1-score: 0.7729For batch 75, tr_loss is    0.36.\n",
      " 77/200 [==========>...................] - ETA: 1:53 - loss: 0.3613 - iou_score: 0.6328 - f1-score: 0.7731For batch 76, tr_loss is    0.36.\n",
      " 78/200 [==========>...................] - ETA: 1:53 - loss: 0.3611 - iou_score: 0.6329 - f1-score: 0.7731For batch 77, tr_loss is    0.36.\n",
      " 79/200 [==========>...................] - ETA: 1:52 - loss: 0.3611 - iou_score: 0.6329 - f1-score: 0.7732For batch 78, tr_loss is    0.36.\n",
      " 80/200 [===========>..................] - ETA: 1:51 - loss: 0.3606 - iou_score: 0.6335 - f1-score: 0.7737For batch 79, tr_loss is    0.36.\n",
      " 81/200 [===========>..................] - ETA: 1:50 - loss: 0.3597 - iou_score: 0.6346 - f1-score: 0.7745For batch 80, tr_loss is    0.36.\n",
      " 82/200 [===========>..................] - ETA: 1:49 - loss: 0.3596 - iou_score: 0.6347 - f1-score: 0.7746For batch 81, tr_loss is    0.36.\n",
      " 83/200 [===========>..................] - ETA: 1:48 - loss: 0.3598 - iou_score: 0.6345 - f1-score: 0.7744For batch 82, tr_loss is    0.36.\n",
      " 84/200 [===========>..................] - ETA: 1:47 - loss: 0.3596 - iou_score: 0.6347 - f1-score: 0.7746For batch 83, tr_loss is    0.36.\n",
      " 85/200 [===========>..................] - ETA: 1:46 - loss: 0.3600 - iou_score: 0.6340 - f1-score: 0.7740For batch 84, tr_loss is    0.36.\n",
      " 86/200 [===========>..................] - ETA: 1:45 - loss: 0.3605 - iou_score: 0.6334 - f1-score: 0.7735For batch 85, tr_loss is    0.36.\n",
      " 87/200 [============>.................] - ETA: 1:44 - loss: 0.3597 - iou_score: 0.6343 - f1-score: 0.7742For batch 86, tr_loss is    0.36.\n",
      " 88/200 [============>.................] - ETA: 1:43 - loss: 0.3593 - iou_score: 0.6347 - f1-score: 0.7745For batch 87, tr_loss is    0.36.\n",
      " 89/200 [============>.................] - ETA: 1:42 - loss: 0.3596 - iou_score: 0.6342 - f1-score: 0.7742For batch 88, tr_loss is    0.36.\n",
      " 90/200 [============>.................] - ETA: 1:41 - loss: 0.3598 - iou_score: 0.6339 - f1-score: 0.7739For batch 89, tr_loss is    0.36.\n",
      " 91/200 [============>.................] - ETA: 1:41 - loss: 0.3597 - iou_score: 0.6340 - f1-score: 0.7740For batch 90, tr_loss is    0.36.\n",
      " 92/200 [============>.................] - ETA: 1:39 - loss: 0.3603 - iou_score: 0.6332 - f1-score: 0.7734For batch 91, tr_loss is    0.36.\n",
      " 93/200 [============>.................] - ETA: 1:38 - loss: 0.3605 - iou_score: 0.6330 - f1-score: 0.7732For batch 92, tr_loss is    0.36.\n",
      " 94/200 [=============>................] - ETA: 1:37 - loss: 0.3616 - iou_score: 0.6316 - f1-score: 0.7722For batch 93, tr_loss is    0.36.\n",
      " 95/200 [=============>................] - ETA: 1:36 - loss: 0.3621 - iou_score: 0.6311 - f1-score: 0.7718For batch 94, tr_loss is    0.36.\n",
      " 96/200 [=============>................] - ETA: 1:34 - loss: 0.3617 - iou_score: 0.6316 - f1-score: 0.7722For batch 95, tr_loss is    0.36.\n",
      " 97/200 [=============>................] - ETA: 1:33 - loss: 0.3621 - iou_score: 0.6310 - f1-score: 0.7717For batch 96, tr_loss is    0.36.\n",
      " 98/200 [=============>................] - ETA: 1:33 - loss: 0.3619 - iou_score: 0.6312 - f1-score: 0.7719For batch 97, tr_loss is    0.36.\n",
      " 99/200 [=============>................] - ETA: 1:31 - loss: 0.3617 - iou_score: 0.6316 - f1-score: 0.7722For batch 98, tr_loss is    0.36.\n",
      "100/200 [==============>...............] - ETA: 1:30 - loss: 0.3620 - iou_score: 0.6315 - f1-score: 0.7722For batch 99, tr_loss is    0.36.\n",
      "101/200 [==============>...............] - ETA: 1:30 - loss: 0.3621 - iou_score: 0.6315 - f1-score: 0.7722For batch 100, tr_loss is    0.36.\n",
      "102/200 [==============>...............] - ETA: 1:28 - loss: 0.3622 - iou_score: 0.6312 - f1-score: 0.7719For batch 101, tr_loss is    0.36.\n",
      "103/200 [==============>...............] - ETA: 1:28 - loss: 0.3626 - iou_score: 0.6309 - f1-score: 0.7717For batch 102, tr_loss is    0.36.\n",
      "104/200 [==============>...............] - ETA: 1:26 - loss: 0.3629 - iou_score: 0.6304 - f1-score: 0.7714For batch 103, tr_loss is    0.36.\n",
      "105/200 [==============>...............] - ETA: 1:25 - loss: 0.3629 - iou_score: 0.6305 - f1-score: 0.7714For batch 104, tr_loss is    0.36.\n",
      "106/200 [==============>...............] - ETA: 1:25 - loss: 0.3629 - iou_score: 0.6304 - f1-score: 0.7713For batch 105, tr_loss is    0.36.\n",
      "107/200 [===============>..............] - ETA: 1:24 - loss: 0.3632 - iou_score: 0.6300 - f1-score: 0.7711For batch 106, tr_loss is    0.36.\n",
      "108/200 [===============>..............] - ETA: 1:23 - loss: 0.3632 - iou_score: 0.6301 - f1-score: 0.7711For batch 107, tr_loss is    0.36.\n",
      "109/200 [===============>..............] - ETA: 1:22 - loss: 0.3630 - iou_score: 0.6303 - f1-score: 0.7713For batch 108, tr_loss is    0.36.\n",
      "110/200 [===============>..............] - ETA: 1:21 - loss: 0.3628 - iou_score: 0.6305 - f1-score: 0.7714For batch 109, tr_loss is    0.36.\n",
      "111/200 [===============>..............] - ETA: 1:20 - loss: 0.3622 - iou_score: 0.6314 - f1-score: 0.7720For batch 110, tr_loss is    0.36.\n",
      "112/200 [===============>..............] - ETA: 1:19 - loss: 0.3621 - iou_score: 0.6314 - f1-score: 0.7721For batch 111, tr_loss is    0.36.\n",
      "113/200 [===============>..............] - ETA: 1:19 - loss: 0.3631 - iou_score: 0.6304 - f1-score: 0.7712For batch 112, tr_loss is    0.36.\n",
      "114/200 [================>.............] - ETA: 1:18 - loss: 0.3636 - iou_score: 0.6298 - f1-score: 0.7708For batch 113, tr_loss is    0.36.\n",
      "115/200 [================>.............] - ETA: 1:17 - loss: 0.3635 - iou_score: 0.6298 - f1-score: 0.7708For batch 114, tr_loss is    0.36.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/200 [================>.............] - ETA: 1:16 - loss: 0.3637 - iou_score: 0.6294 - f1-score: 0.7705For batch 115, tr_loss is    0.36.\n",
      "117/200 [================>.............] - ETA: 1:15 - loss: 0.3641 - iou_score: 0.6292 - f1-score: 0.7704For batch 116, tr_loss is    0.36.\n",
      "118/200 [================>.............] - ETA: 1:14 - loss: 0.3640 - iou_score: 0.6293 - f1-score: 0.7705For batch 117, tr_loss is    0.36.\n",
      "119/200 [================>.............] - ETA: 1:14 - loss: 0.3640 - iou_score: 0.6292 - f1-score: 0.7703For batch 118, tr_loss is    0.36.\n",
      "120/200 [=================>............] - ETA: 1:13 - loss: 0.3635 - iou_score: 0.6299 - f1-score: 0.7709For batch 119, tr_loss is    0.36.\n",
      "121/200 [=================>............] - ETA: 1:12 - loss: 0.3631 - iou_score: 0.6305 - f1-score: 0.7713For batch 120, tr_loss is    0.36.\n",
      "122/200 [=================>............] - ETA: 1:11 - loss: 0.3631 - iou_score: 0.6305 - f1-score: 0.7713For batch 121, tr_loss is    0.36.\n",
      "123/200 [=================>............] - ETA: 1:10 - loss: 0.3636 - iou_score: 0.6297 - f1-score: 0.7707For batch 122, tr_loss is    0.36.\n",
      "124/200 [=================>............] - ETA: 1:09 - loss: 0.3639 - iou_score: 0.6295 - f1-score: 0.7705For batch 123, tr_loss is    0.36.\n",
      "125/200 [=================>............] - ETA: 1:08 - loss: 0.3640 - iou_score: 0.6293 - f1-score: 0.7704For batch 124, tr_loss is    0.36.\n",
      "126/200 [=================>............] - ETA: 1:07 - loss: 0.3637 - iou_score: 0.6297 - f1-score: 0.7707For batch 125, tr_loss is    0.36.\n",
      "127/200 [==================>...........] - ETA: 1:06 - loss: 0.3635 - iou_score: 0.6297 - f1-score: 0.7707For batch 126, tr_loss is    0.36.\n",
      "128/200 [==================>...........] - ETA: 1:05 - loss: 0.3646 - iou_score: 0.6282 - f1-score: 0.7695For batch 127, tr_loss is    0.36.\n",
      "129/200 [==================>...........] - ETA: 1:04 - loss: 0.3645 - iou_score: 0.6284 - f1-score: 0.7696For batch 128, tr_loss is    0.36.\n",
      "130/200 [==================>...........] - ETA: 1:04 - loss: 0.3641 - iou_score: 0.6289 - f1-score: 0.7700For batch 129, tr_loss is    0.36.\n",
      "131/200 [==================>...........] - ETA: 1:02 - loss: 0.3637 - iou_score: 0.6290 - f1-score: 0.7701For batch 130, tr_loss is    0.36.\n",
      "132/200 [==================>...........] - ETA: 1:02 - loss: 0.3634 - iou_score: 0.6294 - f1-score: 0.7704For batch 131, tr_loss is    0.36.\n",
      "133/200 [==================>...........] - ETA: 1:01 - loss: 0.3635 - iou_score: 0.6292 - f1-score: 0.7702For batch 132, tr_loss is    0.36.\n",
      "134/200 [===================>..........] - ETA: 1:00 - loss: 0.3643 - iou_score: 0.6285 - f1-score: 0.7697For batch 133, tr_loss is    0.36.\n",
      "135/200 [===================>..........] - ETA: 59s - loss: 0.3647 - iou_score: 0.6281 - f1-score: 0.7694 For batch 134, tr_loss is    0.36.\n",
      "136/200 [===================>..........] - ETA: 58s - loss: 0.3647 - iou_score: 0.6281 - f1-score: 0.7694For batch 135, tr_loss is    0.36.\n",
      "137/200 [===================>..........] - ETA: 57s - loss: 0.3654 - iou_score: 0.6272 - f1-score: 0.7687For batch 136, tr_loss is    0.37.\n",
      "138/200 [===================>..........] - ETA: 56s - loss: 0.3654 - iou_score: 0.6272 - f1-score: 0.7687For batch 137, tr_loss is    0.37.\n",
      "139/200 [===================>..........] - ETA: 55s - loss: 0.3650 - iou_score: 0.6277 - f1-score: 0.7690For batch 138, tr_loss is    0.36.\n",
      "140/200 [====================>.........] - ETA: 54s - loss: 0.3659 - iou_score: 0.6267 - f1-score: 0.7681For batch 139, tr_loss is    0.37.\n",
      "141/200 [====================>.........] - ETA: 53s - loss: 0.3662 - iou_score: 0.6263 - f1-score: 0.7678For batch 140, tr_loss is    0.37.\n",
      "142/200 [====================>.........] - ETA: 53s - loss: 0.3658 - iou_score: 0.6270 - f1-score: 0.7683For batch 141, tr_loss is    0.37.\n",
      "143/200 [====================>.........] - ETA: 52s - loss: 0.3658 - iou_score: 0.6271 - f1-score: 0.7684For batch 142, tr_loss is    0.37.\n",
      "144/200 [====================>.........] - ETA: 51s - loss: 0.3660 - iou_score: 0.6268 - f1-score: 0.7681For batch 143, tr_loss is    0.37.\n",
      "145/200 [====================>.........] - ETA: 50s - loss: 0.3662 - iou_score: 0.6264 - f1-score: 0.7679For batch 144, tr_loss is    0.37.\n",
      "146/200 [====================>.........] - ETA: 49s - loss: 0.3657 - iou_score: 0.6272 - f1-score: 0.7684For batch 145, tr_loss is    0.37.\n",
      "147/200 [=====================>........] - ETA: 48s - loss: 0.3658 - iou_score: 0.6270 - f1-score: 0.7683For batch 146, tr_loss is    0.37.\n",
      "148/200 [=====================>........] - ETA: 47s - loss: 0.3652 - iou_score: 0.6279 - f1-score: 0.7689For batch 147, tr_loss is    0.37.\n",
      "149/200 [=====================>........] - ETA: 46s - loss: 0.3651 - iou_score: 0.6281 - f1-score: 0.7690For batch 148, tr_loss is    0.37.\n",
      "150/200 [=====================>........] - ETA: 45s - loss: 0.3644 - iou_score: 0.6288 - f1-score: 0.7696For batch 149, tr_loss is    0.36.\n",
      "151/200 [=====================>........] - ETA: 44s - loss: 0.3645 - iou_score: 0.6288 - f1-score: 0.7695For batch 150, tr_loss is    0.36.\n",
      "152/200 [=====================>........] - ETA: 43s - loss: 0.3644 - iou_score: 0.6289 - f1-score: 0.7697For batch 151, tr_loss is    0.36.\n",
      "153/200 [=====================>........] - ETA: 42s - loss: 0.3641 - iou_score: 0.6292 - f1-score: 0.7699For batch 152, tr_loss is    0.36.\n",
      "154/200 [======================>.......] - ETA: 41s - loss: 0.3645 - iou_score: 0.6289 - f1-score: 0.7697For batch 153, tr_loss is    0.36.\n",
      "155/200 [======================>.......] - ETA: 41s - loss: 0.3643 - iou_score: 0.6290 - f1-score: 0.7698For batch 154, tr_loss is    0.36.\n",
      "156/200 [======================>.......] - ETA: 40s - loss: 0.3640 - iou_score: 0.6293 - f1-score: 0.7700For batch 155, tr_loss is    0.36.\n",
      "157/200 [======================>.......] - ETA: 39s - loss: 0.3641 - iou_score: 0.6290 - f1-score: 0.7698For batch 156, tr_loss is    0.36.\n",
      "158/200 [======================>.......] - ETA: 38s - loss: 0.3643 - iou_score: 0.6290 - f1-score: 0.7698For batch 157, tr_loss is    0.36.\n",
      "159/200 [======================>.......] - ETA: 37s - loss: 0.3645 - iou_score: 0.6288 - f1-score: 0.7696For batch 158, tr_loss is    0.36.\n",
      "160/200 [=======================>......] - ETA: 36s - loss: 0.3645 - iou_score: 0.6287 - f1-score: 0.7696For batch 159, tr_loss is    0.36.\n",
      "161/200 [=======================>......] - ETA: 35s - loss: 0.3646 - iou_score: 0.6285 - f1-score: 0.7694For batch 160, tr_loss is    0.36.\n",
      "162/200 [=======================>......] - ETA: 34s - loss: 0.3648 - iou_score: 0.6284 - f1-score: 0.7693For batch 161, tr_loss is    0.36.\n",
      "163/200 [=======================>......] - ETA: 33s - loss: 0.3643 - iou_score: 0.6290 - f1-score: 0.7698For batch 162, tr_loss is    0.36.\n",
      "164/200 [=======================>......] - ETA: 32s - loss: 0.3642 - iou_score: 0.6291 - f1-score: 0.7699For batch 163, tr_loss is    0.36.\n",
      "165/200 [=======================>......] - ETA: 31s - loss: 0.3638 - iou_score: 0.6297 - f1-score: 0.7703For batch 164, tr_loss is    0.36.\n",
      "166/200 [=======================>......] - ETA: 30s - loss: 0.3639 - iou_score: 0.6296 - f1-score: 0.7702For batch 165, tr_loss is    0.36.\n",
      "167/200 [========================>.....] - ETA: 30s - loss: 0.3632 - iou_score: 0.6305 - f1-score: 0.7709For batch 166, tr_loss is    0.36.\n",
      "168/200 [========================>.....] - ETA: 29s - loss: 0.3632 - iou_score: 0.6303 - f1-score: 0.7707For batch 167, tr_loss is    0.36.\n",
      "169/200 [========================>.....] - ETA: 28s - loss: 0.3633 - iou_score: 0.6301 - f1-score: 0.7706For batch 168, tr_loss is    0.36.\n",
      "170/200 [========================>.....] - ETA: 27s - loss: 0.3629 - iou_score: 0.6307 - f1-score: 0.7710For batch 169, tr_loss is    0.36.\n",
      "171/200 [========================>.....] - ETA: 26s - loss: 0.3630 - iou_score: 0.6305 - f1-score: 0.7709For batch 170, tr_loss is    0.36.\n",
      "172/200 [========================>.....] - ETA: 25s - loss: 0.3626 - iou_score: 0.6311 - f1-score: 0.7713For batch 171, tr_loss is    0.36.\n",
      "173/200 [========================>.....] - ETA: 24s - loss: 0.3624 - iou_score: 0.6313 - f1-score: 0.7714For batch 172, tr_loss is    0.36.\n",
      "174/200 [=========================>....] - ETA: 23s - loss: 0.3622 - iou_score: 0.6316 - f1-score: 0.7716For batch 173, tr_loss is    0.36.\n",
      "175/200 [=========================>....] - ETA: 22s - loss: 0.3619 - iou_score: 0.6320 - f1-score: 0.7719For batch 174, tr_loss is    0.36.\n",
      "176/200 [=========================>....] - ETA: 21s - loss: 0.3619 - iou_score: 0.6318 - f1-score: 0.7718For batch 175, tr_loss is    0.36.\n",
      "177/200 [=========================>....] - ETA: 21s - loss: 0.3615 - iou_score: 0.6322 - f1-score: 0.7721For batch 176, tr_loss is    0.36.\n",
      "178/200 [=========================>....] - ETA: 20s - loss: 0.3619 - iou_score: 0.6316 - f1-score: 0.7717For batch 177, tr_loss is    0.36.\n",
      "179/200 [=========================>....] - ETA: 19s - loss: 0.3614 - iou_score: 0.6323 - f1-score: 0.7721For batch 178, tr_loss is    0.36.\n",
      "180/200 [==========================>...] - ETA: 18s - loss: 0.3615 - iou_score: 0.6322 - f1-score: 0.7720For batch 179, tr_loss is    0.36.\n",
      "181/200 [==========================>...] - ETA: 17s - loss: 0.3616 - iou_score: 0.6320 - f1-score: 0.7719For batch 180, tr_loss is    0.36.\n",
      "182/200 [==========================>...] - ETA: 16s - loss: 0.3616 - iou_score: 0.6320 - f1-score: 0.7719For batch 181, tr_loss is    0.36.\n",
      "183/200 [==========================>...] - ETA: 15s - loss: 0.3616 - iou_score: 0.6319 - f1-score: 0.7719For batch 182, tr_loss is    0.36.\n",
      "184/200 [==========================>...] - ETA: 14s - loss: 0.3613 - iou_score: 0.6323 - f1-score: 0.7721For batch 183, tr_loss is    0.36.\n",
      "185/200 [==========================>...] - ETA: 13s - loss: 0.3612 - iou_score: 0.6324 - f1-score: 0.7722For batch 184, tr_loss is    0.36.\n",
      "186/200 [==========================>...] - ETA: 12s - loss: 0.3610 - iou_score: 0.6326 - f1-score: 0.7723For batch 185, tr_loss is    0.36.\n",
      "187/200 [===========================>..] - ETA: 11s - loss: 0.3608 - iou_score: 0.6328 - f1-score: 0.7725For batch 186, tr_loss is    0.36.\n",
      "188/200 [===========================>..] - ETA: 10s - loss: 0.3605 - iou_score: 0.6332 - f1-score: 0.7728For batch 187, tr_loss is    0.36.\n",
      "189/200 [===========================>..] - ETA: 10s - loss: 0.3607 - iou_score: 0.6330 - f1-score: 0.7726For batch 188, tr_loss is    0.36.\n",
      "190/200 [===========================>..] - ETA: 9s - loss: 0.3608 - iou_score: 0.6327 - f1-score: 0.7724 For batch 189, tr_loss is    0.36.\n",
      "191/200 [===========================>..] - ETA: 8s - loss: 0.3612 - iou_score: 0.6322 - f1-score: 0.7721For batch 190, tr_loss is    0.36.\n",
      "192/200 [===========================>..] - ETA: 7s - loss: 0.3614 - iou_score: 0.6319 - f1-score: 0.7718For batch 191, tr_loss is    0.36.\n",
      "193/200 [===========================>..] - ETA: 6s - loss: 0.3611 - iou_score: 0.6323 - f1-score: 0.7721For batch 192, tr_loss is    0.36.\n",
      "194/200 [============================>.] - ETA: 5s - loss: 0.3612 - iou_score: 0.6321 - f1-score: 0.7719For batch 193, tr_loss is    0.36.\n",
      "195/200 [============================>.] - ETA: 4s - loss: 0.3612 - iou_score: 0.6321 - f1-score: 0.7719For batch 194, tr_loss is    0.36.\n",
      "196/200 [============================>.] - ETA: 3s - loss: 0.3613 - iou_score: 0.6318 - f1-score: 0.7718For batch 195, tr_loss is    0.36.\n",
      "197/200 [============================>.] - ETA: 2s - loss: 0.3608 - iou_score: 0.6325 - f1-score: 0.7722For batch 196, tr_loss is    0.36.\n",
      "198/200 [============================>.] - ETA: 1s - loss: 0.3609 - iou_score: 0.6324 - f1-score: 0.7722For batch 197, tr_loss is    0.36.\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.3611 - iou_score: 0.6321 - f1-score: 0.7720For batch 198, tr_loss is    0.36.\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.3609 - iou_score: 0.6323 - f1-score: 0.7721For batch 199, tr_loss is    0.36.\n",
      "For batch 0, vl_loss is    0.40.\n",
      "For batch 1, vl_loss is    0.37.\n",
      "For batch 2, vl_loss is    0.36.\n",
      "For batch 3, vl_loss is    0.36.\n",
      "For batch 4, vl_loss is    0.35.\n",
      "For batch 5, vl_loss is    0.34.\n",
      "For batch 6, vl_loss is    0.35.\n",
      "For batch 7, vl_loss is    0.34.\n",
      "For batch 8, vl_loss is    0.35.\n",
      "For batch 9, vl_loss is    0.35.\n",
      "For batch 10, vl_loss is    0.36.\n",
      "For batch 11, vl_loss is    0.35.\n",
      "For batch 12, vl_loss is    0.35.\n",
      "For batch 13, vl_loss is    0.35.\n",
      "For batch 14, vl_loss is    0.35.\n",
      "For batch 15, vl_loss is    0.34.\n",
      "For batch 16, vl_loss is    0.33.\n",
      "For batch 17, vl_loss is    0.34.\n",
      "For batch 18, vl_loss is    0.33.\n",
      "For batch 19, vl_loss is    0.33.\n",
      "For batch 20, vl_loss is    0.33.\n",
      "For batch 21, vl_loss is    0.33.\n",
      "For batch 22, vl_loss is    0.33.\n",
      "For batch 23, vl_loss is    0.33.\n",
      "For batch 24, vl_loss is    0.33.\n",
      "For batch 25, vl_loss is    0.33.\n",
      "For batch 26, vl_loss is    0.33.\n",
      "For batch 27, vl_loss is    0.33.\n",
      "For batch 28, vl_loss is    0.33.\n",
      "For batch 29, vl_loss is    0.34.\n",
      "For batch 30, vl_loss is    0.33.\n",
      "For batch 31, vl_loss is    0.33.\n",
      "For batch 32, vl_loss is    0.34.\n",
      "For batch 33, vl_loss is    0.33.\n",
      "For batch 34, vl_loss is    0.33.\n",
      "For batch 35, vl_loss is    0.34.\n",
      "For batch 36, vl_loss is    0.33.\n",
      "For batch 37, vl_loss is    0.33.\n",
      "For batch 38, vl_loss is    0.33.\n",
      "For batch 39, vl_loss is    0.33.\n",
      "For batch 40, vl_loss is    0.34.\n",
      "For batch 41, vl_loss is    0.33.\n",
      "For batch 42, vl_loss is    0.33.\n",
      "For batch 43, vl_loss is    0.33.\n",
      "For batch 44, vl_loss is    0.33.\n",
      "For batch 45, vl_loss is    0.33.\n",
      "For batch 46, vl_loss is    0.34.\n",
      "For batch 47, vl_loss is    0.34.\n",
      "For batch 48, vl_loss is    0.34.\n",
      "For batch 49, vl_loss is    0.34.\n",
      "For batch 50, vl_loss is    0.34.\n",
      "For batch 51, vl_loss is    0.34.\n",
      "For batch 52, vl_loss is    0.34.\n",
      "For batch 53, vl_loss is    0.34.\n",
      "For batch 54, vl_loss is    0.34.\n",
      "For batch 55, vl_loss is    0.34.\n",
      "For batch 56, vl_loss is    0.34.\n",
      "For batch 57, vl_loss is    0.34.\n",
      "For batch 58, vl_loss is    0.34.\n",
      "For batch 59, vl_loss is    0.34.\n",
      "For batch 60, vl_loss is    0.34.\n",
      "For batch 61, vl_loss is    0.34.\n",
      "For batch 62, vl_loss is    0.34.\n",
      "For batch 63, vl_loss is    0.34.\n",
      "For batch 64, vl_loss is    0.34.\n",
      "For batch 65, vl_loss is    0.34.\n",
      "For batch 66, vl_loss is    0.34.\n",
      "For batch 67, vl_loss is    0.34.\n",
      "For batch 68, vl_loss is    0.34.\n",
      "For batch 69, vl_loss is    0.34.\n",
      "For batch 70, vl_loss is    0.34.\n",
      "For batch 71, vl_loss is    0.34.\n",
      "For batch 72, vl_loss is    0.34.\n",
      "For batch 73, vl_loss is    0.34.\n",
      "For batch 74, vl_loss is    0.34.\n",
      "For batch 75, vl_loss is    0.34.\n",
      "For batch 76, vl_loss is    0.34.\n",
      "For batch 77, vl_loss is    0.33.\n",
      "For batch 78, vl_loss is    0.33.\n",
      "For batch 79, vl_loss is    0.33.\n",
      "For batch 80, vl_loss is    0.33.\n",
      "For batch 81, vl_loss is    0.33.\n",
      "For batch 82, vl_loss is    0.34.\n",
      "For batch 83, vl_loss is    0.34.\n",
      "For batch 84, vl_loss is    0.34.\n",
      "For batch 85, vl_loss is    0.33.\n",
      "For batch 86, vl_loss is    0.34.\n",
      "For batch 87, vl_loss is    0.33.\n",
      "For batch 88, vl_loss is    0.33.\n",
      "For batch 89, vl_loss is    0.33.\n",
      "For batch 90, vl_loss is    0.33.\n",
      "For batch 91, vl_loss is    0.34.\n",
      "For batch 92, vl_loss is    0.34.\n",
      "For batch 93, vl_loss is    0.34.\n",
      "For batch 94, vl_loss is    0.34.\n",
      "For batch 95, vl_loss is    0.34.\n",
      "For batch 96, vl_loss is    0.34.\n",
      "For batch 97, vl_loss is    0.34.\n",
      "For batch 98, vl_loss is    0.34.\n",
      "For batch 99, vl_loss is    0.34.\n",
      "200/200 [==============================] - 217s 933ms/step - loss: 0.3609 - iou_score: 0.6323 - f1-score: 0.7721 - val_loss: 0.3392 - val_iou_score: 0.6853 - val_f1-score: 0.8114\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.50450 to 0.33916, saving model to ./model/tumor_100_unet_efficientnetb0_imagenet_09290.hdf5\n",
      "The average loss for epoch 1 is    0.36 \n",
      "Epoch 3/200\n",
      "  1/200 [..............................] - ETA: 9:57 - loss: 0.3408 - iou_score: 0.6589 - f1-score: 0.7943For batch 0, tr_loss is    0.34.\n",
      "  2/200 [..............................] - ETA: 4:09 - loss: 0.3402 - iou_score: 0.6552 - f1-score: 0.7909For batch 1, tr_loss is    0.34.\n",
      "  3/200 [..............................] - ETA: 4:50 - loss: 0.3434 - iou_score: 0.6523 - f1-score: 0.7887For batch 2, tr_loss is    0.34.\n",
      "  4/200 [..............................] - ETA: 4:48 - loss: 0.3480 - iou_score: 0.6446 - f1-score: 0.7830For batch 3, tr_loss is    0.35.\n",
      "  5/200 [..............................] - ETA: 4:44 - loss: 0.3474 - iou_score: 0.6457 - f1-score: 0.7839For batch 4, tr_loss is    0.35.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6/200 [..............................] - ETA: 4:46 - loss: 0.3567 - iou_score: 0.6357 - f1-score: 0.7763For batch 5, tr_loss is    0.36.\n",
      "  7/200 [>.............................] - ETA: 4:45 - loss: 0.3662 - iou_score: 0.6240 - f1-score: 0.7665For batch 6, tr_loss is    0.37.\n",
      "  8/200 [>.............................] - ETA: 4:32 - loss: 0.3637 - iou_score: 0.6271 - f1-score: 0.7689For batch 7, tr_loss is    0.36.\n",
      "  9/200 [>.............................] - ETA: 4:09 - loss: 0.3595 - iou_score: 0.6343 - f1-score: 0.7741For batch 8, tr_loss is    0.36.\n",
      " 10/200 [>.............................] - ETA: 4:04 - loss: 0.3607 - iou_score: 0.6339 - f1-score: 0.7736For batch 9, tr_loss is    0.36.\n",
      " 11/200 [>.............................] - ETA: 3:52 - loss: 0.3590 - iou_score: 0.6356 - f1-score: 0.7749For batch 10, tr_loss is    0.36.\n",
      " 12/200 [>.............................] - ETA: 3:38 - loss: 0.3611 - iou_score: 0.6321 - f1-score: 0.7723For batch 11, tr_loss is    0.36.\n",
      " 13/200 [>.............................] - ETA: 3:31 - loss: 0.3640 - iou_score: 0.6281 - f1-score: 0.7693For batch 12, tr_loss is    0.36.\n",
      " 14/200 [=>............................] - ETA: 3:23 - loss: 0.3635 - iou_score: 0.6287 - f1-score: 0.7699For batch 13, tr_loss is    0.36.\n",
      " 15/200 [=>............................] - ETA: 3:16 - loss: 0.3620 - iou_score: 0.6299 - f1-score: 0.7709For batch 14, tr_loss is    0.36.\n",
      " 16/200 [=>............................] - ETA: 3:13 - loss: 0.3613 - iou_score: 0.6301 - f1-score: 0.7712For batch 15, tr_loss is    0.36.\n",
      " 17/200 [=>............................] - ETA: 3:12 - loss: 0.3596 - iou_score: 0.6315 - f1-score: 0.7723For batch 16, tr_loss is    0.36.\n",
      " 18/200 [=>............................] - ETA: 3:10 - loss: 0.3568 - iou_score: 0.6337 - f1-score: 0.7741For batch 17, tr_loss is    0.36.\n",
      " 19/200 [=>............................] - ETA: 3:03 - loss: 0.3598 - iou_score: 0.6304 - f1-score: 0.7714For batch 18, tr_loss is    0.36.\n",
      " 20/200 [==>...........................] - ETA: 3:00 - loss: 0.3569 - iou_score: 0.6337 - f1-score: 0.7738For batch 19, tr_loss is    0.36.\n",
      " 21/200 [==>...........................] - ETA: 3:00 - loss: 0.3545 - iou_score: 0.6367 - f1-score: 0.7760For batch 20, tr_loss is    0.35.\n",
      " 22/200 [==>...........................] - ETA: 2:58 - loss: 0.3538 - iou_score: 0.6380 - f1-score: 0.7771For batch 21, tr_loss is    0.35.\n",
      " 23/200 [==>...........................] - ETA: 2:53 - loss: 0.3524 - iou_score: 0.6396 - f1-score: 0.7783For batch 22, tr_loss is    0.35.\n",
      " 24/200 [==>...........................] - ETA: 2:49 - loss: 0.3522 - iou_score: 0.6395 - f1-score: 0.7783For batch 23, tr_loss is    0.35.\n",
      " 25/200 [==>...........................] - ETA: 2:47 - loss: 0.3505 - iou_score: 0.6410 - f1-score: 0.7794For batch 24, tr_loss is    0.35.\n",
      " 26/200 [==>...........................] - ETA: 2:47 - loss: 0.3528 - iou_score: 0.6392 - f1-score: 0.7781For batch 25, tr_loss is    0.35.\n",
      " 27/200 [===>..........................] - ETA: 2:45 - loss: 0.3515 - iou_score: 0.6411 - f1-score: 0.7795For batch 26, tr_loss is    0.35.\n",
      " 28/200 [===>..........................] - ETA: 2:42 - loss: 0.3516 - iou_score: 0.6414 - f1-score: 0.7798For batch 27, tr_loss is    0.35.\n",
      " 29/200 [===>..........................] - ETA: 2:39 - loss: 0.3516 - iou_score: 0.6411 - f1-score: 0.7795For batch 28, tr_loss is    0.35.\n",
      " 30/200 [===>..........................] - ETA: 2:37 - loss: 0.3498 - iou_score: 0.6431 - f1-score: 0.7810For batch 29, tr_loss is    0.35.\n",
      " 31/200 [===>..........................] - ETA: 2:37 - loss: 0.3483 - iou_score: 0.6447 - f1-score: 0.7822For batch 30, tr_loss is    0.35.\n",
      " 32/200 [===>..........................] - ETA: 2:34 - loss: 0.3464 - iou_score: 0.6474 - f1-score: 0.7841For batch 31, tr_loss is    0.35.\n",
      " 33/200 [===>..........................] - ETA: 2:33 - loss: 0.3450 - iou_score: 0.6486 - f1-score: 0.7851For batch 32, tr_loss is    0.35.\n",
      " 34/200 [====>.........................] - ETA: 2:33 - loss: 0.3451 - iou_score: 0.6482 - f1-score: 0.7848For batch 33, tr_loss is    0.35.\n",
      " 35/200 [====>.........................] - ETA: 2:30 - loss: 0.3438 - iou_score: 0.6498 - f1-score: 0.7860For batch 34, tr_loss is    0.34.\n",
      " 36/200 [====>.........................] - ETA: 2:31 - loss: 0.3429 - iou_score: 0.6509 - f1-score: 0.7868For batch 35, tr_loss is    0.34.\n",
      " 37/200 [====>.........................] - ETA: 2:28 - loss: 0.3435 - iou_score: 0.6500 - f1-score: 0.7861For batch 36, tr_loss is    0.34.\n",
      " 38/200 [====>.........................] - ETA: 2:26 - loss: 0.3442 - iou_score: 0.6487 - f1-score: 0.7852For batch 37, tr_loss is    0.34.\n",
      " 39/200 [====>.........................] - ETA: 2:26 - loss: 0.3441 - iou_score: 0.6491 - f1-score: 0.7855For batch 38, tr_loss is    0.34.\n",
      " 40/200 [=====>........................] - ETA: 2:23 - loss: 0.3424 - iou_score: 0.6507 - f1-score: 0.7866For batch 39, tr_loss is    0.34.\n",
      " 41/200 [=====>........................] - ETA: 2:21 - loss: 0.3419 - iou_score: 0.6504 - f1-score: 0.7864For batch 40, tr_loss is    0.34.\n",
      " 42/200 [=====>........................] - ETA: 2:21 - loss: 0.3420 - iou_score: 0.6502 - f1-score: 0.7863For batch 41, tr_loss is    0.34.\n",
      " 43/200 [=====>........................] - ETA: 2:19 - loss: 0.3423 - iou_score: 0.6504 - f1-score: 0.7863For batch 42, tr_loss is    0.34.\n",
      " 44/200 [=====>........................] - ETA: 2:18 - loss: 0.3420 - iou_score: 0.6513 - f1-score: 0.7871For batch 43, tr_loss is    0.34.\n",
      " 45/200 [=====>........................] - ETA: 2:18 - loss: 0.3425 - iou_score: 0.6513 - f1-score: 0.7870For batch 44, tr_loss is    0.34.\n",
      " 46/200 [=====>........................] - ETA: 2:17 - loss: 0.3431 - iou_score: 0.6507 - f1-score: 0.7866For batch 45, tr_loss is    0.34.\n",
      " 47/200 [======>.......................] - ETA: 2:17 - loss: 0.3443 - iou_score: 0.6500 - f1-score: 0.7860For batch 46, tr_loss is    0.34.\n",
      " 48/200 [======>.......................] - ETA: 2:15 - loss: 0.3445 - iou_score: 0.6496 - f1-score: 0.7857For batch 47, tr_loss is    0.34.\n",
      " 49/200 [======>.......................] - ETA: 2:15 - loss: 0.3442 - iou_score: 0.6499 - f1-score: 0.7860For batch 48, tr_loss is    0.34.\n",
      " 50/200 [======>.......................] - ETA: 2:14 - loss: 0.3433 - iou_score: 0.6508 - f1-score: 0.7866For batch 49, tr_loss is    0.34.\n",
      " 51/200 [======>.......................] - ETA: 2:14 - loss: 0.3430 - iou_score: 0.6514 - f1-score: 0.7871For batch 50, tr_loss is    0.34.\n",
      " 52/200 [======>.......................] - ETA: 2:13 - loss: 0.3432 - iou_score: 0.6511 - f1-score: 0.7868For batch 51, tr_loss is    0.34.\n",
      " 53/200 [======>.......................] - ETA: 2:13 - loss: 0.3428 - iou_score: 0.6514 - f1-score: 0.7871For batch 52, tr_loss is    0.34.\n",
      " 54/200 [=======>......................] - ETA: 2:12 - loss: 0.3432 - iou_score: 0.6510 - f1-score: 0.7869For batch 53, tr_loss is    0.34.\n",
      " 55/200 [=======>......................] - ETA: 2:10 - loss: 0.3418 - iou_score: 0.6524 - f1-score: 0.7879For batch 54, tr_loss is    0.34.\n",
      " 56/200 [=======>......................] - ETA: 2:09 - loss: 0.3418 - iou_score: 0.6525 - f1-score: 0.7879For batch 55, tr_loss is    0.34.\n",
      " 57/200 [=======>......................] - ETA: 2:08 - loss: 0.3417 - iou_score: 0.6524 - f1-score: 0.7879For batch 56, tr_loss is    0.34.\n",
      " 58/200 [=======>......................] - ETA: 2:07 - loss: 0.3416 - iou_score: 0.6526 - f1-score: 0.7881For batch 57, tr_loss is    0.34.\n",
      " 59/200 [=======>......................] - ETA: 2:06 - loss: 0.3407 - iou_score: 0.6536 - f1-score: 0.7888For batch 58, tr_loss is    0.34.\n",
      " 60/200 [========>.....................] - ETA: 2:06 - loss: 0.3404 - iou_score: 0.6536 - f1-score: 0.7888For batch 59, tr_loss is    0.34.\n",
      " 61/200 [========>.....................] - ETA: 2:04 - loss: 0.3417 - iou_score: 0.6525 - f1-score: 0.7880For batch 60, tr_loss is    0.34.\n",
      " 62/200 [========>.....................] - ETA: 2:03 - loss: 0.3418 - iou_score: 0.6523 - f1-score: 0.7879For batch 61, tr_loss is    0.34.\n",
      " 63/200 [========>.....................] - ETA: 2:02 - loss: 0.3414 - iou_score: 0.6528 - f1-score: 0.7882For batch 62, tr_loss is    0.34.\n",
      " 64/200 [========>.....................] - ETA: 2:01 - loss: 0.3427 - iou_score: 0.6512 - f1-score: 0.7870For batch 63, tr_loss is    0.34.\n",
      " 65/200 [========>.....................] - ETA: 2:01 - loss: 0.3412 - iou_score: 0.6529 - f1-score: 0.7882For batch 64, tr_loss is    0.34.\n",
      " 66/200 [========>.....................] - ETA: 2:00 - loss: 0.3429 - iou_score: 0.6510 - f1-score: 0.7866For batch 65, tr_loss is    0.34.\n",
      " 67/200 [=========>....................] - ETA: 1:59 - loss: 0.3419 - iou_score: 0.6520 - f1-score: 0.7873For batch 66, tr_loss is    0.34.\n",
      " 68/200 [=========>....................] - ETA: 1:59 - loss: 0.3416 - iou_score: 0.6521 - f1-score: 0.7874For batch 67, tr_loss is    0.34.\n",
      " 69/200 [=========>....................] - ETA: 1:58 - loss: 0.3426 - iou_score: 0.6507 - f1-score: 0.7864For batch 68, tr_loss is    0.34.\n",
      " 70/200 [=========>....................] - ETA: 1:56 - loss: 0.3421 - iou_score: 0.6513 - f1-score: 0.7869For batch 69, tr_loss is    0.34.\n",
      " 71/200 [=========>....................] - ETA: 1:55 - loss: 0.3419 - iou_score: 0.6517 - f1-score: 0.7872For batch 70, tr_loss is    0.34.\n",
      " 72/200 [=========>....................] - ETA: 1:53 - loss: 0.3421 - iou_score: 0.6514 - f1-score: 0.7869For batch 71, tr_loss is    0.34.\n",
      " 73/200 [=========>....................] - ETA: 1:53 - loss: 0.3415 - iou_score: 0.6520 - f1-score: 0.7874For batch 72, tr_loss is    0.34.\n",
      " 74/200 [==========>...................] - ETA: 1:52 - loss: 0.3425 - iou_score: 0.6509 - f1-score: 0.7865For batch 73, tr_loss is    0.34.\n",
      " 75/200 [==========>...................] - ETA: 1:51 - loss: 0.3433 - iou_score: 0.6497 - f1-score: 0.7856For batch 74, tr_loss is    0.34.\n",
      " 76/200 [==========>...................] - ETA: 1:50 - loss: 0.3433 - iou_score: 0.6494 - f1-score: 0.7854For batch 75, tr_loss is    0.34.\n",
      " 77/200 [==========>...................] - ETA: 1:48 - loss: 0.3431 - iou_score: 0.6496 - f1-score: 0.7855For batch 76, tr_loss is    0.34.\n",
      " 78/200 [==========>...................] - ETA: 1:48 - loss: 0.3428 - iou_score: 0.6496 - f1-score: 0.7855For batch 77, tr_loss is    0.34.\n",
      " 79/200 [==========>...................] - ETA: 1:47 - loss: 0.3428 - iou_score: 0.6496 - f1-score: 0.7856For batch 78, tr_loss is    0.34.\n",
      " 80/200 [===========>..................] - ETA: 1:47 - loss: 0.3423 - iou_score: 0.6502 - f1-score: 0.7860For batch 79, tr_loss is    0.34.\n",
      " 81/200 [===========>..................] - ETA: 1:46 - loss: 0.3414 - iou_score: 0.6513 - f1-score: 0.7868For batch 80, tr_loss is    0.34.\n",
      " 82/200 [===========>..................] - ETA: 1:45 - loss: 0.3412 - iou_score: 0.6516 - f1-score: 0.7870For batch 81, tr_loss is    0.34.\n",
      " 83/200 [===========>..................] - ETA: 1:44 - loss: 0.3414 - iou_score: 0.6514 - f1-score: 0.7869For batch 82, tr_loss is    0.34.\n",
      " 84/200 [===========>..................] - ETA: 1:44 - loss: 0.3413 - iou_score: 0.6515 - f1-score: 0.7870For batch 83, tr_loss is    0.34.\n",
      " 85/200 [===========>..................] - ETA: 1:42 - loss: 0.3418 - iou_score: 0.6508 - f1-score: 0.7864For batch 84, tr_loss is    0.34.\n",
      " 86/200 [===========>..................] - ETA: 1:42 - loss: 0.3422 - iou_score: 0.6501 - f1-score: 0.7859For batch 85, tr_loss is    0.34.\n",
      " 87/200 [============>.................] - ETA: 1:41 - loss: 0.3417 - iou_score: 0.6508 - f1-score: 0.7864For batch 86, tr_loss is    0.34.\n",
      " 88/200 [============>.................] - ETA: 1:39 - loss: 0.3414 - iou_score: 0.6512 - f1-score: 0.7867For batch 87, tr_loss is    0.34.\n",
      " 89/200 [============>.................] - ETA: 1:39 - loss: 0.3419 - iou_score: 0.6506 - f1-score: 0.7863For batch 88, tr_loss is    0.34.\n",
      " 90/200 [============>.................] - ETA: 1:38 - loss: 0.3421 - iou_score: 0.6504 - f1-score: 0.7861For batch 89, tr_loss is    0.34.\n",
      " 91/200 [============>.................] - ETA: 1:37 - loss: 0.3420 - iou_score: 0.6506 - f1-score: 0.7862For batch 90, tr_loss is    0.34.\n",
      " 92/200 [============>.................] - ETA: 1:36 - loss: 0.3429 - iou_score: 0.6496 - f1-score: 0.7855For batch 91, tr_loss is    0.34.\n",
      " 93/200 [============>.................] - ETA: 1:35 - loss: 0.3430 - iou_score: 0.6495 - f1-score: 0.7854For batch 92, tr_loss is    0.34.\n",
      " 94/200 [=============>................] - ETA: 1:35 - loss: 0.3439 - iou_score: 0.6482 - f1-score: 0.7844For batch 93, tr_loss is    0.34.\n",
      " 95/200 [=============>................] - ETA: 1:34 - loss: 0.3445 - iou_score: 0.6476 - f1-score: 0.7840For batch 94, tr_loss is    0.34.\n",
      " 96/200 [=============>................] - ETA: 1:33 - loss: 0.3441 - iou_score: 0.6482 - f1-score: 0.7844For batch 95, tr_loss is    0.34.\n",
      " 97/200 [=============>................] - ETA: 1:32 - loss: 0.3445 - iou_score: 0.6475 - f1-score: 0.7839For batch 96, tr_loss is    0.34.\n",
      " 98/200 [=============>................] - ETA: 1:31 - loss: 0.3445 - iou_score: 0.6477 - f1-score: 0.7841For batch 97, tr_loss is    0.34.\n",
      " 99/200 [=============>................] - ETA: 1:30 - loss: 0.3443 - iou_score: 0.6480 - f1-score: 0.7843For batch 98, tr_loss is    0.34.\n",
      "100/200 [==============>...............] - ETA: 1:29 - loss: 0.3447 - iou_score: 0.6477 - f1-score: 0.7841For batch 99, tr_loss is    0.34.\n",
      "101/200 [==============>...............] - ETA: 1:27 - loss: 0.3450 - iou_score: 0.6476 - f1-score: 0.7840For batch 100, tr_loss is    0.34.\n",
      "102/200 [==============>...............] - ETA: 1:26 - loss: 0.3452 - iou_score: 0.6472 - f1-score: 0.7837For batch 101, tr_loss is    0.35.\n",
      "103/200 [==============>...............] - ETA: 1:25 - loss: 0.3456 - iou_score: 0.6468 - f1-score: 0.7835For batch 102, tr_loss is    0.35.\n",
      "104/200 [==============>...............] - ETA: 1:25 - loss: 0.3460 - iou_score: 0.6462 - f1-score: 0.7830For batch 103, tr_loss is    0.35.\n",
      "105/200 [==============>...............] - ETA: 1:24 - loss: 0.3461 - iou_score: 0.6460 - f1-score: 0.7829For batch 104, tr_loss is    0.35.\n",
      "106/200 [==============>...............] - ETA: 1:23 - loss: 0.3462 - iou_score: 0.6459 - f1-score: 0.7828For batch 105, tr_loss is    0.35.\n",
      "107/200 [===============>..............] - ETA: 1:22 - loss: 0.3465 - iou_score: 0.6455 - f1-score: 0.7825For batch 106, tr_loss is    0.35.\n",
      "108/200 [===============>..............] - ETA: 1:21 - loss: 0.3465 - iou_score: 0.6456 - f1-score: 0.7826For batch 107, tr_loss is    0.35.\n",
      "109/200 [===============>..............] - ETA: 1:20 - loss: 0.3464 - iou_score: 0.6458 - f1-score: 0.7827For batch 108, tr_loss is    0.35.\n",
      "110/200 [===============>..............] - ETA: 1:20 - loss: 0.3462 - iou_score: 0.6461 - f1-score: 0.7830For batch 109, tr_loss is    0.35.\n",
      "111/200 [===============>..............] - ETA: 1:18 - loss: 0.3455 - iou_score: 0.6468 - f1-score: 0.7835For batch 110, tr_loss is    0.35.\n",
      "112/200 [===============>..............] - ETA: 1:18 - loss: 0.3454 - iou_score: 0.6468 - f1-score: 0.7835For batch 111, tr_loss is    0.35.\n",
      "113/200 [===============>..............] - ETA: 1:17 - loss: 0.3465 - iou_score: 0.6457 - f1-score: 0.7826For batch 112, tr_loss is    0.35.\n",
      "114/200 [================>.............] - ETA: 1:15 - loss: 0.3470 - iou_score: 0.6452 - f1-score: 0.7822For batch 113, tr_loss is    0.35.\n",
      "115/200 [================>.............] - ETA: 1:15 - loss: 0.3471 - iou_score: 0.6451 - f1-score: 0.7821For batch 114, tr_loss is    0.35.\n",
      "116/200 [================>.............] - ETA: 1:13 - loss: 0.3472 - iou_score: 0.6448 - f1-score: 0.7819For batch 115, tr_loss is    0.35.\n",
      "117/200 [================>.............] - ETA: 1:13 - loss: 0.3474 - iou_score: 0.6447 - f1-score: 0.7818For batch 116, tr_loss is    0.35.\n",
      "118/200 [================>.............] - ETA: 1:12 - loss: 0.3473 - iou_score: 0.6448 - f1-score: 0.7819For batch 117, tr_loss is    0.35.\n",
      "119/200 [================>.............] - ETA: 1:11 - loss: 0.3475 - iou_score: 0.6445 - f1-score: 0.7817For batch 118, tr_loss is    0.35.\n",
      "120/200 [=================>............] - ETA: 1:10 - loss: 0.3470 - iou_score: 0.6452 - f1-score: 0.7822For batch 119, tr_loss is    0.35.\n",
      "121/200 [=================>............] - ETA: 1:09 - loss: 0.3466 - iou_score: 0.6457 - f1-score: 0.7826For batch 120, tr_loss is    0.35.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/200 [=================>............] - ETA: 1:08 - loss: 0.3465 - iou_score: 0.6458 - f1-score: 0.7826For batch 121, tr_loss is    0.35.\n",
      "123/200 [=================>............] - ETA: 1:07 - loss: 0.3471 - iou_score: 0.6451 - f1-score: 0.7821For batch 122, tr_loss is    0.35.\n",
      "124/200 [=================>............] - ETA: 1:07 - loss: 0.3472 - iou_score: 0.6449 - f1-score: 0.7820For batch 123, tr_loss is    0.35.\n",
      "125/200 [=================>............] - ETA: 1:06 - loss: 0.3473 - iou_score: 0.6447 - f1-score: 0.7818For batch 124, tr_loss is    0.35.\n",
      "126/200 [=================>............] - ETA: 1:05 - loss: 0.3471 - iou_score: 0.6451 - f1-score: 0.7821For batch 125, tr_loss is    0.35.\n",
      "127/200 [==================>...........] - ETA: 1:04 - loss: 0.3469 - iou_score: 0.6451 - f1-score: 0.7821For batch 126, tr_loss is    0.35.\n",
      "128/200 [==================>...........] - ETA: 1:03 - loss: 0.3479 - iou_score: 0.6438 - f1-score: 0.7811For batch 127, tr_loss is    0.35.\n",
      "129/200 [==================>...........] - ETA: 1:02 - loss: 0.3479 - iou_score: 0.6439 - f1-score: 0.7812For batch 128, tr_loss is    0.35.\n",
      "130/200 [==================>...........] - ETA: 1:01 - loss: 0.3476 - iou_score: 0.6443 - f1-score: 0.7815For batch 129, tr_loss is    0.35.\n",
      "131/200 [==================>...........] - ETA: 1:00 - loss: 0.3473 - iou_score: 0.6446 - f1-score: 0.7817For batch 130, tr_loss is    0.35.\n",
      "132/200 [==================>...........] - ETA: 1:00 - loss: 0.3470 - iou_score: 0.6451 - f1-score: 0.7820For batch 131, tr_loss is    0.35.\n",
      "133/200 [==================>...........] - ETA: 59s - loss: 0.3470 - iou_score: 0.6451 - f1-score: 0.7820 For batch 132, tr_loss is    0.35.\n",
      "134/200 [===================>..........] - ETA: 58s - loss: 0.3476 - iou_score: 0.6444 - f1-score: 0.7815For batch 133, tr_loss is    0.35.\n",
      "135/200 [===================>..........] - ETA: 57s - loss: 0.3479 - iou_score: 0.6442 - f1-score: 0.7813For batch 134, tr_loss is    0.35.\n",
      "136/200 [===================>..........] - ETA: 56s - loss: 0.3479 - iou_score: 0.6441 - f1-score: 0.7813For batch 135, tr_loss is    0.35.\n",
      "137/200 [===================>..........] - ETA: 55s - loss: 0.3489 - iou_score: 0.6431 - f1-score: 0.7805For batch 136, tr_loss is    0.35.\n",
      "138/200 [===================>..........] - ETA: 54s - loss: 0.3489 - iou_score: 0.6430 - f1-score: 0.7804For batch 137, tr_loss is    0.35.\n",
      "139/200 [===================>..........] - ETA: 54s - loss: 0.3485 - iou_score: 0.6435 - f1-score: 0.7808For batch 138, tr_loss is    0.35.\n",
      "140/200 [====================>.........] - ETA: 53s - loss: 0.3496 - iou_score: 0.6424 - f1-score: 0.7798For batch 139, tr_loss is    0.35.\n",
      "141/200 [====================>.........] - ETA: 52s - loss: 0.3499 - iou_score: 0.6420 - f1-score: 0.7795For batch 140, tr_loss is    0.35.\n",
      "142/200 [====================>.........] - ETA: 51s - loss: 0.3496 - iou_score: 0.6425 - f1-score: 0.7798For batch 141, tr_loss is    0.35.\n",
      "143/200 [====================>.........] - ETA: 50s - loss: 0.3496 - iou_score: 0.6424 - f1-score: 0.7798For batch 142, tr_loss is    0.35.\n",
      "144/200 [====================>.........] - ETA: 49s - loss: 0.3498 - iou_score: 0.6422 - f1-score: 0.7796For batch 143, tr_loss is    0.35.\n",
      "145/200 [====================>.........] - ETA: 48s - loss: 0.3499 - iou_score: 0.6421 - f1-score: 0.7796For batch 144, tr_loss is    0.35.\n",
      "146/200 [====================>.........] - ETA: 48s - loss: 0.3494 - iou_score: 0.6429 - f1-score: 0.7801For batch 145, tr_loss is    0.35.\n",
      "147/200 [=====================>........] - ETA: 47s - loss: 0.3495 - iou_score: 0.6427 - f1-score: 0.7799For batch 146, tr_loss is    0.35.\n",
      "148/200 [=====================>........] - ETA: 46s - loss: 0.3491 - iou_score: 0.6433 - f1-score: 0.7804For batch 147, tr_loss is    0.35.\n",
      "149/200 [=====================>........] - ETA: 45s - loss: 0.3488 - iou_score: 0.6436 - f1-score: 0.7806For batch 148, tr_loss is    0.35.\n",
      "150/200 [=====================>........] - ETA: 44s - loss: 0.3483 - iou_score: 0.6443 - f1-score: 0.7811For batch 149, tr_loss is    0.35.\n",
      "151/200 [=====================>........] - ETA: 43s - loss: 0.3485 - iou_score: 0.6441 - f1-score: 0.7809For batch 150, tr_loss is    0.35.\n",
      "152/200 [=====================>........] - ETA: 42s - loss: 0.3486 - iou_score: 0.6440 - f1-score: 0.7808For batch 151, tr_loss is    0.35.\n",
      "153/200 [=====================>........] - ETA: 42s - loss: 0.3483 - iou_score: 0.6441 - f1-score: 0.7810For batch 152, tr_loss is    0.35.\n",
      "154/200 [======================>.......] - ETA: 41s - loss: 0.3484 - iou_score: 0.6440 - f1-score: 0.7808For batch 153, tr_loss is    0.35.\n",
      "155/200 [======================>.......] - ETA: 40s - loss: 0.3483 - iou_score: 0.6442 - f1-score: 0.7810For batch 154, tr_loss is    0.35.\n",
      "156/200 [======================>.......] - ETA: 39s - loss: 0.3480 - iou_score: 0.6445 - f1-score: 0.7813For batch 155, tr_loss is    0.35.\n",
      "157/200 [======================>.......] - ETA: 38s - loss: 0.3482 - iou_score: 0.6442 - f1-score: 0.7810For batch 156, tr_loss is    0.35.\n",
      "158/200 [======================>.......] - ETA: 37s - loss: 0.3482 - iou_score: 0.6441 - f1-score: 0.7810For batch 157, tr_loss is    0.35.\n",
      "159/200 [======================>.......] - ETA: 36s - loss: 0.3484 - iou_score: 0.6439 - f1-score: 0.7808For batch 158, tr_loss is    0.35.\n",
      "160/200 [=======================>......] - ETA: 36s - loss: 0.3485 - iou_score: 0.6438 - f1-score: 0.7808For batch 159, tr_loss is    0.35.\n",
      "161/200 [=======================>......] - ETA: 35s - loss: 0.3485 - iou_score: 0.6437 - f1-score: 0.7807For batch 160, tr_loss is    0.35.\n",
      "162/200 [=======================>......] - ETA: 34s - loss: 0.3486 - iou_score: 0.6436 - f1-score: 0.7806For batch 161, tr_loss is    0.35.\n",
      "163/200 [=======================>......] - ETA: 33s - loss: 0.3480 - iou_score: 0.6445 - f1-score: 0.7813For batch 162, tr_loss is    0.35.\n",
      "164/200 [=======================>......] - ETA: 32s - loss: 0.3480 - iou_score: 0.6446 - f1-score: 0.7814For batch 163, tr_loss is    0.35.\n",
      "165/200 [=======================>......] - ETA: 31s - loss: 0.3476 - iou_score: 0.6451 - f1-score: 0.7817For batch 164, tr_loss is    0.35.\n",
      "166/200 [=======================>......] - ETA: 30s - loss: 0.3477 - iou_score: 0.6450 - f1-score: 0.7817For batch 165, tr_loss is    0.35.\n",
      "167/200 [========================>.....] - ETA: 29s - loss: 0.3469 - iou_score: 0.6460 - f1-score: 0.7823For batch 166, tr_loss is    0.35.\n",
      "168/200 [========================>.....] - ETA: 28s - loss: 0.3470 - iou_score: 0.6458 - f1-score: 0.7822For batch 167, tr_loss is    0.35.\n",
      "169/200 [========================>.....] - ETA: 27s - loss: 0.3470 - iou_score: 0.6457 - f1-score: 0.7821For batch 168, tr_loss is    0.35.\n",
      "170/200 [========================>.....] - ETA: 26s - loss: 0.3467 - iou_score: 0.6461 - f1-score: 0.7824For batch 169, tr_loss is    0.35.\n",
      "171/200 [========================>.....] - ETA: 25s - loss: 0.3467 - iou_score: 0.6460 - f1-score: 0.7824For batch 170, tr_loss is    0.35.\n",
      "172/200 [========================>.....] - ETA: 25s - loss: 0.3462 - iou_score: 0.6466 - f1-score: 0.7827For batch 171, tr_loss is    0.35.\n",
      "173/200 [========================>.....] - ETA: 24s - loss: 0.3462 - iou_score: 0.6466 - f1-score: 0.7828For batch 172, tr_loss is    0.35.\n",
      "174/200 [=========================>....] - ETA: 23s - loss: 0.3459 - iou_score: 0.6469 - f1-score: 0.7830For batch 173, tr_loss is    0.35.\n",
      "175/200 [=========================>....] - ETA: 22s - loss: 0.3457 - iou_score: 0.6472 - f1-score: 0.7832For batch 174, tr_loss is    0.35.\n",
      "176/200 [=========================>....] - ETA: 21s - loss: 0.3458 - iou_score: 0.6470 - f1-score: 0.7830For batch 175, tr_loss is    0.35.\n",
      "177/200 [=========================>....] - ETA: 20s - loss: 0.3456 - iou_score: 0.6473 - f1-score: 0.7832For batch 176, tr_loss is    0.35.\n",
      "178/200 [=========================>....] - ETA: 19s - loss: 0.3459 - iou_score: 0.6467 - f1-score: 0.7828For batch 177, tr_loss is    0.35.\n",
      "179/200 [=========================>....] - ETA: 18s - loss: 0.3455 - iou_score: 0.6471 - f1-score: 0.7831For batch 178, tr_loss is    0.35.\n",
      "180/200 [==========================>...] - ETA: 17s - loss: 0.3458 - iou_score: 0.6469 - f1-score: 0.7830For batch 179, tr_loss is    0.35.\n",
      "181/200 [==========================>...] - ETA: 16s - loss: 0.3460 - iou_score: 0.6467 - f1-score: 0.7828For batch 180, tr_loss is    0.35.\n",
      "182/200 [==========================>...] - ETA: 16s - loss: 0.3461 - iou_score: 0.6466 - f1-score: 0.7827For batch 181, tr_loss is    0.35.\n",
      "183/200 [==========================>...] - ETA: 15s - loss: 0.3460 - iou_score: 0.6465 - f1-score: 0.7827For batch 182, tr_loss is    0.35.\n",
      "184/200 [==========================>...] - ETA: 14s - loss: 0.3457 - iou_score: 0.6469 - f1-score: 0.7829For batch 183, tr_loss is    0.35.\n",
      "185/200 [==========================>...] - ETA: 13s - loss: 0.3456 - iou_score: 0.6469 - f1-score: 0.7830For batch 184, tr_loss is    0.35.\n",
      "186/200 [==========================>...] - ETA: 12s - loss: 0.3454 - iou_score: 0.6471 - f1-score: 0.7831For batch 185, tr_loss is    0.35.\n",
      "187/200 [===========================>..] - ETA: 11s - loss: 0.3452 - iou_score: 0.6474 - f1-score: 0.7833For batch 186, tr_loss is    0.35.\n",
      "188/200 [===========================>..] - ETA: 10s - loss: 0.3450 - iou_score: 0.6477 - f1-score: 0.7835For batch 187, tr_loss is    0.34.\n",
      "189/200 [===========================>..] - ETA: 9s - loss: 0.3452 - iou_score: 0.6474 - f1-score: 0.7833 For batch 188, tr_loss is    0.35.\n",
      "190/200 [===========================>..] - ETA: 8s - loss: 0.3452 - iou_score: 0.6473 - f1-score: 0.7833For batch 189, tr_loss is    0.35.\n",
      "191/200 [===========================>..] - ETA: 8s - loss: 0.3457 - iou_score: 0.6467 - f1-score: 0.7828For batch 190, tr_loss is    0.35.\n",
      "192/200 [===========================>..] - ETA: 7s - loss: 0.3460 - iou_score: 0.6462 - f1-score: 0.7824For batch 191, tr_loss is    0.35.\n",
      "193/200 [===========================>..] - ETA: 6s - loss: 0.3457 - iou_score: 0.6467 - f1-score: 0.7827For batch 192, tr_loss is    0.35.\n",
      "194/200 [============================>.] - ETA: 5s - loss: 0.3458 - iou_score: 0.6464 - f1-score: 0.7826For batch 193, tr_loss is    0.35.\n",
      "195/200 [============================>.] - ETA: 4s - loss: 0.3459 - iou_score: 0.6463 - f1-score: 0.7825For batch 194, tr_loss is    0.35.\n",
      "196/200 [============================>.] - ETA: 3s - loss: 0.3460 - iou_score: 0.6461 - f1-score: 0.7823For batch 195, tr_loss is    0.35.\n",
      "197/200 [============================>.] - ETA: 2s - loss: 0.3456 - iou_score: 0.6467 - f1-score: 0.7827For batch 196, tr_loss is    0.35.\n",
      "198/200 [============================>.] - ETA: 1s - loss: 0.3457 - iou_score: 0.6467 - f1-score: 0.7827For batch 197, tr_loss is    0.35.\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.3459 - iou_score: 0.6464 - f1-score: 0.7825For batch 198, tr_loss is    0.35.\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.3457 - iou_score: 0.6464 - f1-score: 0.7825For batch 199, tr_loss is    0.35.\n",
      "For batch 0, vl_loss is    0.38.\n",
      "For batch 1, vl_loss is    0.36.\n",
      "For batch 2, vl_loss is    0.35.\n",
      "For batch 3, vl_loss is    0.36.\n",
      "For batch 4, vl_loss is    0.34.\n",
      "For batch 5, vl_loss is    0.33.\n",
      "For batch 6, vl_loss is    0.35.\n",
      "For batch 7, vl_loss is    0.34.\n",
      "For batch 8, vl_loss is    0.35.\n",
      "For batch 9, vl_loss is    0.35.\n",
      "For batch 10, vl_loss is    0.36.\n",
      "For batch 11, vl_loss is    0.35.\n",
      "For batch 12, vl_loss is    0.35.\n",
      "For batch 13, vl_loss is    0.34.\n",
      "For batch 14, vl_loss is    0.34.\n",
      "For batch 15, vl_loss is    0.34.\n",
      "For batch 16, vl_loss is    0.33.\n",
      "For batch 17, vl_loss is    0.34.\n",
      "For batch 18, vl_loss is    0.33.\n",
      "For batch 19, vl_loss is    0.33.\n",
      "For batch 20, vl_loss is    0.33.\n",
      "For batch 21, vl_loss is    0.33.\n",
      "For batch 22, vl_loss is    0.33.\n",
      "For batch 23, vl_loss is    0.33.\n",
      "For batch 24, vl_loss is    0.33.\n",
      "For batch 25, vl_loss is    0.33.\n",
      "For batch 26, vl_loss is    0.33.\n",
      "For batch 27, vl_loss is    0.33.\n",
      "For batch 28, vl_loss is    0.33.\n",
      "For batch 29, vl_loss is    0.33.\n",
      "For batch 30, vl_loss is    0.33.\n",
      "For batch 31, vl_loss is    0.33.\n",
      "For batch 32, vl_loss is    0.33.\n",
      "For batch 33, vl_loss is    0.33.\n",
      "For batch 34, vl_loss is    0.33.\n",
      "For batch 35, vl_loss is    0.33.\n",
      "For batch 36, vl_loss is    0.33.\n",
      "For batch 37, vl_loss is    0.33.\n",
      "For batch 38, vl_loss is    0.33.\n",
      "For batch 39, vl_loss is    0.33.\n",
      "For batch 40, vl_loss is    0.33.\n",
      "For batch 41, vl_loss is    0.33.\n",
      "For batch 42, vl_loss is    0.33.\n",
      "For batch 43, vl_loss is    0.33.\n",
      "For batch 44, vl_loss is    0.33.\n",
      "For batch 45, vl_loss is    0.33.\n",
      "For batch 46, vl_loss is    0.33.\n",
      "For batch 47, vl_loss is    0.33.\n",
      "For batch 48, vl_loss is    0.33.\n",
      "For batch 49, vl_loss is    0.33.\n",
      "For batch 50, vl_loss is    0.33.\n",
      "For batch 51, vl_loss is    0.33.\n",
      "For batch 52, vl_loss is    0.33.\n",
      "For batch 53, vl_loss is    0.33.\n",
      "For batch 54, vl_loss is    0.33.\n",
      "For batch 55, vl_loss is    0.33.\n",
      "For batch 56, vl_loss is    0.33.\n",
      "For batch 57, vl_loss is    0.33.\n",
      "For batch 58, vl_loss is    0.33.\n",
      "For batch 59, vl_loss is    0.33.\n",
      "For batch 60, vl_loss is    0.33.\n",
      "For batch 61, vl_loss is    0.33.\n",
      "For batch 62, vl_loss is    0.33.\n",
      "For batch 63, vl_loss is    0.33.\n",
      "For batch 64, vl_loss is    0.33.\n",
      "For batch 65, vl_loss is    0.33.\n",
      "For batch 66, vl_loss is    0.33.\n",
      "For batch 67, vl_loss is    0.33.\n",
      "For batch 68, vl_loss is    0.33.\n",
      "For batch 69, vl_loss is    0.33.\n",
      "For batch 70, vl_loss is    0.33.\n",
      "For batch 71, vl_loss is    0.33.\n",
      "For batch 72, vl_loss is    0.33.\n",
      "For batch 73, vl_loss is    0.33.\n",
      "For batch 74, vl_loss is    0.33.\n",
      "For batch 75, vl_loss is    0.33.\n",
      "For batch 76, vl_loss is    0.33.\n",
      "For batch 77, vl_loss is    0.33.\n",
      "For batch 78, vl_loss is    0.33.\n",
      "For batch 79, vl_loss is    0.33.\n",
      "For batch 80, vl_loss is    0.33.\n",
      "For batch 81, vl_loss is    0.33.\n",
      "For batch 82, vl_loss is    0.33.\n",
      "For batch 83, vl_loss is    0.33.\n",
      "For batch 84, vl_loss is    0.33.\n",
      "For batch 85, vl_loss is    0.33.\n",
      "For batch 86, vl_loss is    0.33.\n",
      "For batch 87, vl_loss is    0.33.\n",
      "For batch 88, vl_loss is    0.33.\n",
      "For batch 89, vl_loss is    0.33.\n",
      "For batch 90, vl_loss is    0.33.\n",
      "For batch 91, vl_loss is    0.33.\n",
      "For batch 92, vl_loss is    0.33.\n",
      "For batch 93, vl_loss is    0.33.\n",
      "For batch 94, vl_loss is    0.33.\n",
      "For batch 95, vl_loss is    0.33.\n",
      "For batch 96, vl_loss is    0.33.\n",
      "For batch 97, vl_loss is    0.33.\n",
      "For batch 98, vl_loss is    0.33.\n",
      "For batch 99, vl_loss is    0.33.\n",
      "200/200 [==============================] - 185s 912ms/step - loss: 0.3457 - iou_score: 0.6464 - f1-score: 0.7825 - val_loss: 0.3322 - val_iou_score: 0.6778 - val_f1-score: 0.8064\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.33916 to 0.33218, saving model to ./model/tumor_100_unet_efficientnetb0_imagenet_09290.hdf5\n",
      "The average loss for epoch 2 is    0.35 \n",
      "Epoch 4/200\n",
      "  1/200 [..............................] - ETA: 10:59 - loss: 0.3402 - iou_score: 0.6556 - f1-score: 0.7915For batch 0, tr_loss is    0.34.\n",
      "  2/200 [..............................] - ETA: 5:49 - loss: 0.3331 - iou_score: 0.6571 - f1-score: 0.7925 For batch 1, tr_loss is    0.33.\n",
      "  3/200 [..............................] - ETA: 4:35 - loss: 0.3297 - iou_score: 0.6660 - f1-score: 0.7987For batch 2, tr_loss is    0.33.\n",
      "  4/200 [..............................] - ETA: 4:36 - loss: 0.3328 - iou_score: 0.6557 - f1-score: 0.7910For batch 3, tr_loss is    0.33.\n",
      "  5/200 [..............................] - ETA: 4:14 - loss: 0.3340 - iou_score: 0.6550 - f1-score: 0.7905For batch 4, tr_loss is    0.33.\n",
      "  6/200 [..............................] - ETA: 3:52 - loss: 0.3431 - iou_score: 0.6460 - f1-score: 0.7837For batch 5, tr_loss is    0.34.\n",
      "  7/200 [>.............................] - ETA: 3:57 - loss: 0.3537 - iou_score: 0.6315 - f1-score: 0.7721For batch 6, tr_loss is    0.35.\n",
      "  8/200 [>.............................] - ETA: 4:02 - loss: 0.3531 - iou_score: 0.6332 - f1-score: 0.7734For batch 7, tr_loss is    0.35.\n",
      "  9/200 [>.............................] - ETA: 4:06 - loss: 0.3481 - iou_score: 0.6423 - f1-score: 0.7800For batch 8, tr_loss is    0.35.\n",
      " 10/200 [>.............................] - ETA: 3:55 - loss: 0.3518 - iou_score: 0.6401 - f1-score: 0.7780For batch 9, tr_loss is    0.35.\n",
      " 11/200 [>.............................] - ETA: 3:48 - loss: 0.3496 - iou_score: 0.6419 - f1-score: 0.7795For batch 10, tr_loss is    0.35.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12/200 [>.............................] - ETA: 3:43 - loss: 0.3522 - iou_score: 0.6374 - f1-score: 0.7761For batch 11, tr_loss is    0.35.\n",
      " 13/200 [>.............................] - ETA: 3:36 - loss: 0.3533 - iou_score: 0.6345 - f1-score: 0.7740For batch 12, tr_loss is    0.35.\n",
      " 14/200 [=>............................] - ETA: 3:25 - loss: 0.3532 - iou_score: 0.6347 - f1-score: 0.7743For batch 13, tr_loss is    0.35.\n",
      " 15/200 [=>............................] - ETA: 3:19 - loss: 0.3508 - iou_score: 0.6362 - f1-score: 0.7755For batch 14, tr_loss is    0.35.\n",
      " 16/200 [=>............................] - ETA: 3:19 - loss: 0.3503 - iou_score: 0.6363 - f1-score: 0.7757For batch 15, tr_loss is    0.35.\n",
      " 17/200 [=>............................] - ETA: 3:16 - loss: 0.3491 - iou_score: 0.6383 - f1-score: 0.7773For batch 16, tr_loss is    0.35.\n",
      " 18/200 [=>............................] - ETA: 3:08 - loss: 0.3465 - iou_score: 0.6405 - f1-score: 0.7790For batch 17, tr_loss is    0.35.\n",
      " 19/200 [=>............................] - ETA: 3:04 - loss: 0.3489 - iou_score: 0.6382 - f1-score: 0.7770For batch 18, tr_loss is    0.35.\n",
      " 20/200 [==>...........................] - ETA: 3:03 - loss: 0.3453 - iou_score: 0.6428 - f1-score: 0.7804For batch 19, tr_loss is    0.35.\n",
      " 21/200 [==>...........................] - ETA: 2:59 - loss: 0.3430 - iou_score: 0.6457 - f1-score: 0.7825For batch 20, tr_loss is    0.34.\n",
      " 22/200 [==>...........................] - ETA: 2:55 - loss: 0.3413 - iou_score: 0.6480 - f1-score: 0.7842For batch 21, tr_loss is    0.34.\n",
      " 23/200 [==>...........................] - ETA: 2:51 - loss: 0.3402 - iou_score: 0.6494 - f1-score: 0.7854For batch 22, tr_loss is    0.34.\n",
      " 24/200 [==>...........................] - ETA: 2:49 - loss: 0.3390 - iou_score: 0.6502 - f1-score: 0.7860For batch 23, tr_loss is    0.34.\n",
      " 25/200 [==>...........................] - ETA: 2:49 - loss: 0.3376 - iou_score: 0.6514 - f1-score: 0.7870For batch 24, tr_loss is    0.34.\n",
      " 26/200 [==>...........................] - ETA: 2:47 - loss: 0.3405 - iou_score: 0.6489 - f1-score: 0.7851For batch 25, tr_loss is    0.34.\n",
      " 27/200 [===>..........................] - ETA: 2:46 - loss: 0.3392 - iou_score: 0.6507 - f1-score: 0.7864For batch 26, tr_loss is    0.34.\n",
      " 28/200 [===>..........................] - ETA: 2:46 - loss: 0.3394 - iou_score: 0.6508 - f1-score: 0.7865For batch 27, tr_loss is    0.34.\n",
      " 29/200 [===>..........................] - ETA: 2:45 - loss: 0.3393 - iou_score: 0.6504 - f1-score: 0.7863For batch 28, tr_loss is    0.34.\n",
      " 30/200 [===>..........................] - ETA: 2:44 - loss: 0.3375 - iou_score: 0.6525 - f1-score: 0.7878For batch 29, tr_loss is    0.34.\n",
      " 31/200 [===>..........................] - ETA: 2:41 - loss: 0.3355 - iou_score: 0.6549 - f1-score: 0.7895For batch 30, tr_loss is    0.34.\n",
      " 32/200 [===>..........................] - ETA: 2:41 - loss: 0.3341 - iou_score: 0.6571 - f1-score: 0.7910For batch 31, tr_loss is    0.33.\n",
      " 33/200 [===>..........................] - ETA: 2:38 - loss: 0.3330 - iou_score: 0.6583 - f1-score: 0.7919For batch 32, tr_loss is    0.33.\n",
      " 34/200 [====>.........................] - ETA: 2:37 - loss: 0.3337 - iou_score: 0.6574 - f1-score: 0.7913For batch 33, tr_loss is    0.33.\n",
      " 35/200 [====>.........................] - ETA: 2:36 - loss: 0.3324 - iou_score: 0.6592 - f1-score: 0.7926For batch 34, tr_loss is    0.33.\n",
      " 36/200 [====>.........................] - ETA: 2:34 - loss: 0.3319 - iou_score: 0.6601 - f1-score: 0.7932For batch 35, tr_loss is    0.33.\n",
      " 37/200 [====>.........................] - ETA: 2:34 - loss: 0.3323 - iou_score: 0.6596 - f1-score: 0.7929For batch 36, tr_loss is    0.33.\n",
      " 38/200 [====>.........................] - ETA: 2:33 - loss: 0.3328 - iou_score: 0.6580 - f1-score: 0.7918For batch 37, tr_loss is    0.33.\n",
      " 39/200 [====>.........................] - ETA: 2:32 - loss: 0.3319 - iou_score: 0.6592 - f1-score: 0.7926For batch 38, tr_loss is    0.33.\n",
      " 40/200 [=====>........................] - ETA: 2:30 - loss: 0.3306 - iou_score: 0.6605 - f1-score: 0.7936For batch 39, tr_loss is    0.33.\n",
      " 41/200 [=====>........................] - ETA: 2:29 - loss: 0.3296 - iou_score: 0.6606 - f1-score: 0.7937For batch 40, tr_loss is    0.33.\n",
      " 42/200 [=====>........................] - ETA: 2:29 - loss: 0.3302 - iou_score: 0.6598 - f1-score: 0.7932For batch 41, tr_loss is    0.33.\n",
      " 43/200 [=====>........................] - ETA: 2:27 - loss: 0.3305 - iou_score: 0.6603 - f1-score: 0.7934For batch 42, tr_loss is    0.33.\n",
      " 44/200 [=====>........................] - ETA: 2:26 - loss: 0.3298 - iou_score: 0.6616 - f1-score: 0.7944For batch 43, tr_loss is    0.33.\n",
      " 45/200 [=====>........................] - ETA: 2:24 - loss: 0.3305 - iou_score: 0.6611 - f1-score: 0.7941For batch 44, tr_loss is    0.33.\n",
      " 46/200 [=====>........................] - ETA: 2:22 - loss: 0.3312 - iou_score: 0.6607 - f1-score: 0.7937For batch 45, tr_loss is    0.33.\n",
      " 47/200 [======>.......................] - ETA: 2:21 - loss: 0.3320 - iou_score: 0.6598 - f1-score: 0.7930For batch 46, tr_loss is    0.33.\n",
      " 48/200 [======>.......................] - ETA: 2:19 - loss: 0.3324 - iou_score: 0.6592 - f1-score: 0.7926For batch 47, tr_loss is    0.33.\n",
      " 49/200 [======>.......................] - ETA: 2:18 - loss: 0.3322 - iou_score: 0.6597 - f1-score: 0.7930For batch 48, tr_loss is    0.33.\n",
      " 50/200 [======>.......................] - ETA: 2:17 - loss: 0.3310 - iou_score: 0.6609 - f1-score: 0.7938For batch 49, tr_loss is    0.33.\n",
      " 51/200 [======>.......................] - ETA: 2:16 - loss: 0.3308 - iou_score: 0.6614 - f1-score: 0.7942For batch 50, tr_loss is    0.33.\n",
      " 52/200 [======>.......................] - ETA: 2:14 - loss: 0.3310 - iou_score: 0.6611 - f1-score: 0.7940For batch 51, tr_loss is    0.33.\n",
      " 53/200 [======>.......................] - ETA: 2:12 - loss: 0.3306 - iou_score: 0.6616 - f1-score: 0.7943For batch 52, tr_loss is    0.33.\n",
      " 54/200 [=======>......................] - ETA: 2:13 - loss: 0.3308 - iou_score: 0.6614 - f1-score: 0.7942For batch 53, tr_loss is    0.33.\n",
      " 55/200 [=======>......................] - ETA: 2:12 - loss: 0.3294 - iou_score: 0.6630 - f1-score: 0.7954For batch 54, tr_loss is    0.33.\n",
      " 56/200 [=======>......................] - ETA: 2:11 - loss: 0.3295 - iou_score: 0.6626 - f1-score: 0.7951For batch 55, tr_loss is    0.33.\n",
      " 57/200 [=======>......................] - ETA: 2:09 - loss: 0.3295 - iou_score: 0.6624 - f1-score: 0.7949For batch 56, tr_loss is    0.33.\n",
      " 58/200 [=======>......................] - ETA: 2:08 - loss: 0.3291 - iou_score: 0.6626 - f1-score: 0.7951For batch 57, tr_loss is    0.33.\n",
      " 59/200 [=======>......................] - ETA: 2:07 - loss: 0.3283 - iou_score: 0.6631 - f1-score: 0.7955For batch 58, tr_loss is    0.33.\n",
      " 60/200 [========>.....................] - ETA: 2:07 - loss: 0.3276 - iou_score: 0.6635 - f1-score: 0.7958For batch 59, tr_loss is    0.33.\n",
      " 61/200 [========>.....................] - ETA: 2:06 - loss: 0.3294 - iou_score: 0.6622 - f1-score: 0.7948For batch 60, tr_loss is    0.33.\n",
      " 62/200 [========>.....................] - ETA: 2:05 - loss: 0.3295 - iou_score: 0.6620 - f1-score: 0.7947For batch 61, tr_loss is    0.33.\n",
      " 63/200 [========>.....................] - ETA: 2:05 - loss: 0.3292 - iou_score: 0.6624 - f1-score: 0.7950For batch 62, tr_loss is    0.33.\n",
      " 64/200 [========>.....................] - ETA: 2:03 - loss: 0.3304 - iou_score: 0.6609 - f1-score: 0.7939For batch 63, tr_loss is    0.33.\n",
      " 65/200 [========>.....................] - ETA: 2:01 - loss: 0.3290 - iou_score: 0.6626 - f1-score: 0.7951For batch 64, tr_loss is    0.33.\n",
      " 66/200 [========>.....................] - ETA: 2:01 - loss: 0.3306 - iou_score: 0.6607 - f1-score: 0.7936For batch 65, tr_loss is    0.33.\n",
      " 67/200 [=========>....................] - ETA: 2:00 - loss: 0.3299 - iou_score: 0.6615 - f1-score: 0.7942For batch 66, tr_loss is    0.33.\n",
      " 68/200 [=========>....................] - ETA: 1:59 - loss: 0.3297 - iou_score: 0.6616 - f1-score: 0.7943For batch 67, tr_loss is    0.33.\n",
      " 69/200 [=========>....................] - ETA: 1:59 - loss: 0.3306 - iou_score: 0.6602 - f1-score: 0.7932For batch 68, tr_loss is    0.33.\n",
      " 70/200 [=========>....................] - ETA: 1:57 - loss: 0.3303 - iou_score: 0.6604 - f1-score: 0.7934For batch 69, tr_loss is    0.33.\n",
      " 71/200 [=========>....................] - ETA: 1:56 - loss: 0.3299 - iou_score: 0.6610 - f1-score: 0.7938For batch 70, tr_loss is    0.33.\n",
      " 72/200 [=========>....................] - ETA: 1:54 - loss: 0.3300 - iou_score: 0.6610 - f1-score: 0.7938For batch 71, tr_loss is    0.33.\n",
      " 73/200 [=========>....................] - ETA: 1:54 - loss: 0.3295 - iou_score: 0.6614 - f1-score: 0.7941For batch 72, tr_loss is    0.33.\n",
      " 74/200 [==========>...................] - ETA: 1:53 - loss: 0.3299 - iou_score: 0.6608 - f1-score: 0.7937For batch 73, tr_loss is    0.33.\n",
      " 75/200 [==========>...................] - ETA: 1:53 - loss: 0.3307 - iou_score: 0.6601 - f1-score: 0.7932For batch 74, tr_loss is    0.33.\n",
      " 76/200 [==========>...................] - ETA: 1:51 - loss: 0.3307 - iou_score: 0.6597 - f1-score: 0.7929For batch 75, tr_loss is    0.33.\n",
      " 77/200 [==========>...................] - ETA: 1:51 - loss: 0.3308 - iou_score: 0.6596 - f1-score: 0.7929For batch 76, tr_loss is    0.33.\n",
      " 78/200 [==========>...................] - ETA: 1:50 - loss: 0.3303 - iou_score: 0.6598 - f1-score: 0.7930For batch 77, tr_loss is    0.33.\n",
      " 79/200 [==========>...................] - ETA: 1:49 - loss: 0.3300 - iou_score: 0.6603 - f1-score: 0.7934For batch 78, tr_loss is    0.33.\n",
      " 80/200 [===========>..................] - ETA: 1:48 - loss: 0.3296 - iou_score: 0.6608 - f1-score: 0.7938For batch 79, tr_loss is    0.33.\n",
      " 81/200 [===========>..................] - ETA: 1:47 - loss: 0.3286 - iou_score: 0.6621 - f1-score: 0.7947For batch 80, tr_loss is    0.33.\n",
      " 82/200 [===========>..................] - ETA: 1:46 - loss: 0.3284 - iou_score: 0.6625 - f1-score: 0.7950For batch 81, tr_loss is    0.33.\n",
      " 83/200 [===========>..................] - ETA: 1:45 - loss: 0.3285 - iou_score: 0.6624 - f1-score: 0.7949For batch 82, tr_loss is    0.33.\n",
      " 84/200 [===========>..................] - ETA: 1:44 - loss: 0.3281 - iou_score: 0.6630 - f1-score: 0.7953For batch 83, tr_loss is    0.33.\n",
      " 85/200 [===========>..................] - ETA: 1:43 - loss: 0.3286 - iou_score: 0.6623 - f1-score: 0.7948For batch 84, tr_loss is    0.33.\n",
      " 86/200 [===========>..................] - ETA: 1:42 - loss: 0.3290 - iou_score: 0.6616 - f1-score: 0.7943For batch 85, tr_loss is    0.33.\n",
      " 87/200 [============>.................] - ETA: 1:41 - loss: 0.3283 - iou_score: 0.6624 - f1-score: 0.7949For batch 86, tr_loss is    0.33.\n",
      " 88/200 [============>.................] - ETA: 1:41 - loss: 0.3278 - iou_score: 0.6630 - f1-score: 0.7953For batch 87, tr_loss is    0.33.\n",
      " 89/200 [============>.................] - ETA: 1:39 - loss: 0.3280 - iou_score: 0.6628 - f1-score: 0.7952For batch 88, tr_loss is    0.33.\n",
      " 90/200 [============>.................] - ETA: 1:39 - loss: 0.3283 - iou_score: 0.6624 - f1-score: 0.7949For batch 89, tr_loss is    0.33.\n",
      " 91/200 [============>.................] - ETA: 1:38 - loss: 0.3283 - iou_score: 0.6624 - f1-score: 0.7949For batch 90, tr_loss is    0.33.\n",
      " 92/200 [============>.................] - ETA: 1:37 - loss: 0.3293 - iou_score: 0.6614 - f1-score: 0.7942For batch 91, tr_loss is    0.33.\n",
      " 93/200 [============>.................] - ETA: 1:36 - loss: 0.3293 - iou_score: 0.6613 - f1-score: 0.7941For batch 92, tr_loss is    0.33.\n",
      " 94/200 [=============>................] - ETA: 1:35 - loss: 0.3303 - iou_score: 0.6595 - f1-score: 0.7927For batch 93, tr_loss is    0.33.\n",
      " 95/200 [=============>................] - ETA: 1:34 - loss: 0.3310 - iou_score: 0.6588 - f1-score: 0.7922For batch 94, tr_loss is    0.33.\n",
      " 96/200 [=============>................] - ETA: 1:33 - loss: 0.3309 - iou_score: 0.6594 - f1-score: 0.7926For batch 95, tr_loss is    0.33.\n",
      " 97/200 [=============>................] - ETA: 1:32 - loss: 0.3314 - iou_score: 0.6586 - f1-score: 0.7920For batch 96, tr_loss is    0.33.\n",
      " 98/200 [=============>................] - ETA: 1:32 - loss: 0.3315 - iou_score: 0.6587 - f1-score: 0.7921For batch 97, tr_loss is    0.33.\n",
      " 99/200 [=============>................] - ETA: 1:30 - loss: 0.3312 - iou_score: 0.6591 - f1-score: 0.7924For batch 98, tr_loss is    0.33.\n",
      "100/200 [==============>...............] - ETA: 1:30 - loss: 0.3315 - iou_score: 0.6588 - f1-score: 0.7922For batch 99, tr_loss is    0.33.\n",
      "101/200 [==============>...............] - ETA: 1:29 - loss: 0.3316 - iou_score: 0.6588 - f1-score: 0.7922For batch 100, tr_loss is    0.33.\n",
      "102/200 [==============>...............] - ETA: 1:28 - loss: 0.3320 - iou_score: 0.6581 - f1-score: 0.7917For batch 101, tr_loss is    0.33.\n",
      "103/200 [==============>...............] - ETA: 1:27 - loss: 0.3323 - iou_score: 0.6578 - f1-score: 0.7915For batch 102, tr_loss is    0.33.\n",
      "104/200 [==============>...............] - ETA: 1:26 - loss: 0.3327 - iou_score: 0.6572 - f1-score: 0.7910For batch 103, tr_loss is    0.33.\n",
      "105/200 [==============>...............] - ETA: 1:25 - loss: 0.3329 - iou_score: 0.6569 - f1-score: 0.7908For batch 104, tr_loss is    0.33.\n",
      "106/200 [==============>...............] - ETA: 1:24 - loss: 0.3335 - iou_score: 0.6564 - f1-score: 0.7905For batch 105, tr_loss is    0.33.\n",
      "107/200 [===============>..............] - ETA: 1:23 - loss: 0.3338 - iou_score: 0.6560 - f1-score: 0.7901For batch 106, tr_loss is    0.33.\n",
      "108/200 [===============>..............] - ETA: 1:22 - loss: 0.3337 - iou_score: 0.6562 - f1-score: 0.7903For batch 107, tr_loss is    0.33.\n",
      "109/200 [===============>..............] - ETA: 1:21 - loss: 0.3335 - iou_score: 0.6564 - f1-score: 0.7904For batch 108, tr_loss is    0.33.\n",
      "110/200 [===============>..............] - ETA: 1:20 - loss: 0.3334 - iou_score: 0.6566 - f1-score: 0.7906For batch 109, tr_loss is    0.33.\n",
      "111/200 [===============>..............] - ETA: 1:19 - loss: 0.3328 - iou_score: 0.6573 - f1-score: 0.7911For batch 110, tr_loss is    0.33.\n",
      "112/200 [===============>..............] - ETA: 1:18 - loss: 0.3328 - iou_score: 0.6572 - f1-score: 0.7910For batch 111, tr_loss is    0.33.\n",
      "113/200 [===============>..............] - ETA: 1:17 - loss: 0.3336 - iou_score: 0.6563 - f1-score: 0.7903For batch 112, tr_loss is    0.33.\n",
      "114/200 [================>.............] - ETA: 1:16 - loss: 0.3340 - iou_score: 0.6558 - f1-score: 0.7899For batch 113, tr_loss is    0.33.\n",
      "115/200 [================>.............] - ETA: 1:15 - loss: 0.3339 - iou_score: 0.6559 - f1-score: 0.7900For batch 114, tr_loss is    0.33.\n",
      "116/200 [================>.............] - ETA: 1:14 - loss: 0.3343 - iou_score: 0.6554 - f1-score: 0.7896For batch 115, tr_loss is    0.33.\n",
      "117/200 [================>.............] - ETA: 1:13 - loss: 0.3347 - iou_score: 0.6551 - f1-score: 0.7894For batch 116, tr_loss is    0.33.\n",
      "118/200 [================>.............] - ETA: 1:12 - loss: 0.3346 - iou_score: 0.6552 - f1-score: 0.7895For batch 117, tr_loss is    0.33.\n",
      "119/200 [================>.............] - ETA: 1:11 - loss: 0.3348 - iou_score: 0.6549 - f1-score: 0.7893For batch 118, tr_loss is    0.33.\n",
      "120/200 [=================>............] - ETA: 1:10 - loss: 0.3345 - iou_score: 0.6552 - f1-score: 0.7895For batch 119, tr_loss is    0.33.\n",
      "121/200 [=================>............] - ETA: 1:09 - loss: 0.3341 - iou_score: 0.6559 - f1-score: 0.7900For batch 120, tr_loss is    0.33.\n",
      "122/200 [=================>............] - ETA: 1:09 - loss: 0.3341 - iou_score: 0.6560 - f1-score: 0.7900For batch 121, tr_loss is    0.33.\n",
      "123/200 [=================>............] - ETA: 1:08 - loss: 0.3346 - iou_score: 0.6553 - f1-score: 0.7895For batch 122, tr_loss is    0.33.\n",
      "124/200 [=================>............] - ETA: 1:07 - loss: 0.3348 - iou_score: 0.6552 - f1-score: 0.7894For batch 123, tr_loss is    0.33.\n",
      "125/200 [=================>............] - ETA: 1:06 - loss: 0.3349 - iou_score: 0.6549 - f1-score: 0.7892For batch 124, tr_loss is    0.33.\n",
      "126/200 [=================>............] - ETA: 1:05 - loss: 0.3348 - iou_score: 0.6551 - f1-score: 0.7894For batch 125, tr_loss is    0.33.\n",
      "127/200 [==================>...........] - ETA: 1:04 - loss: 0.3347 - iou_score: 0.6550 - f1-score: 0.7893For batch 126, tr_loss is    0.33.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/200 [==================>...........] - ETA: 1:03 - loss: 0.3357 - iou_score: 0.6537 - f1-score: 0.7883For batch 127, tr_loss is    0.34.\n",
      "129/200 [==================>...........] - ETA: 1:02 - loss: 0.3356 - iou_score: 0.6538 - f1-score: 0.7884For batch 128, tr_loss is    0.34.\n",
      "130/200 [==================>...........] - ETA: 1:02 - loss: 0.3353 - iou_score: 0.6542 - f1-score: 0.7887For batch 129, tr_loss is    0.34.\n",
      "131/200 [==================>...........] - ETA: 1:01 - loss: 0.3349 - iou_score: 0.6547 - f1-score: 0.7890For batch 130, tr_loss is    0.33.\n",
      "132/200 [==================>...........] - ETA: 1:00 - loss: 0.3347 - iou_score: 0.6552 - f1-score: 0.7894For batch 131, tr_loss is    0.33.\n",
      "133/200 [==================>...........] - ETA: 59s - loss: 0.3349 - iou_score: 0.6551 - f1-score: 0.7894 For batch 132, tr_loss is    0.33.\n",
      "134/200 [===================>..........] - ETA: 58s - loss: 0.3353 - iou_score: 0.6545 - f1-score: 0.7889For batch 133, tr_loss is    0.34.\n",
      "135/200 [===================>..........] - ETA: 57s - loss: 0.3359 - iou_score: 0.6541 - f1-score: 0.7886For batch 134, tr_loss is    0.34.\n",
      "136/200 [===================>..........] - ETA: 56s - loss: 0.3358 - iou_score: 0.6541 - f1-score: 0.7886For batch 135, tr_loss is    0.34.\n",
      "137/200 [===================>..........] - ETA: 55s - loss: 0.3370 - iou_score: 0.6530 - f1-score: 0.7877For batch 136, tr_loss is    0.34.\n",
      "138/200 [===================>..........] - ETA: 54s - loss: 0.3372 - iou_score: 0.6528 - f1-score: 0.7876For batch 137, tr_loss is    0.34.\n",
      "139/200 [===================>..........] - ETA: 54s - loss: 0.3370 - iou_score: 0.6531 - f1-score: 0.7878For batch 138, tr_loss is    0.34.\n",
      "140/200 [====================>.........] - ETA: 53s - loss: 0.3380 - iou_score: 0.6518 - f1-score: 0.7867For batch 139, tr_loss is    0.34.\n",
      "141/200 [====================>.........] - ETA: 52s - loss: 0.3384 - iou_score: 0.6515 - f1-score: 0.7865For batch 140, tr_loss is    0.34.\n",
      "142/200 [====================>.........] - ETA: 51s - loss: 0.3381 - iou_score: 0.6519 - f1-score: 0.7868For batch 141, tr_loss is    0.34.\n",
      "143/200 [====================>.........] - ETA: 50s - loss: 0.3382 - iou_score: 0.6518 - f1-score: 0.7867For batch 142, tr_loss is    0.34.\n",
      "144/200 [====================>.........] - ETA: 49s - loss: 0.3384 - iou_score: 0.6515 - f1-score: 0.7865For batch 143, tr_loss is    0.34.\n",
      "145/200 [====================>.........] - ETA: 48s - loss: 0.3384 - iou_score: 0.6513 - f1-score: 0.7864For batch 144, tr_loss is    0.34.\n",
      "146/200 [====================>.........] - ETA: 47s - loss: 0.3380 - iou_score: 0.6521 - f1-score: 0.7869For batch 145, tr_loss is    0.34.\n",
      "147/200 [=====================>........] - ETA: 46s - loss: 0.3381 - iou_score: 0.6519 - f1-score: 0.7867For batch 146, tr_loss is    0.34.\n",
      "148/200 [=====================>........] - ETA: 46s - loss: 0.3376 - iou_score: 0.6527 - f1-score: 0.7873For batch 147, tr_loss is    0.34.\n",
      "149/200 [=====================>........] - ETA: 45s - loss: 0.3374 - iou_score: 0.6528 - f1-score: 0.7873For batch 148, tr_loss is    0.34.\n",
      "150/200 [=====================>........] - ETA: 44s - loss: 0.3370 - iou_score: 0.6534 - f1-score: 0.7877For batch 149, tr_loss is    0.34.\n",
      "151/200 [=====================>........] - ETA: 43s - loss: 0.3372 - iou_score: 0.6532 - f1-score: 0.7876For batch 150, tr_loss is    0.34.\n",
      "152/200 [=====================>........] - ETA: 42s - loss: 0.3373 - iou_score: 0.6531 - f1-score: 0.7876For batch 151, tr_loss is    0.34.\n",
      "153/200 [=====================>........] - ETA: 41s - loss: 0.3372 - iou_score: 0.6532 - f1-score: 0.7876For batch 152, tr_loss is    0.34.\n",
      "154/200 [======================>.......] - ETA: 40s - loss: 0.3373 - iou_score: 0.6531 - f1-score: 0.7876For batch 153, tr_loss is    0.34.\n",
      "155/200 [======================>.......] - ETA: 39s - loss: 0.3371 - iou_score: 0.6533 - f1-score: 0.7877For batch 154, tr_loss is    0.34.\n",
      "156/200 [======================>.......] - ETA: 38s - loss: 0.3368 - iou_score: 0.6537 - f1-score: 0.7880For batch 155, tr_loss is    0.34.\n",
      "157/200 [======================>.......] - ETA: 37s - loss: 0.3369 - iou_score: 0.6534 - f1-score: 0.7878For batch 156, tr_loss is    0.34.\n",
      "158/200 [======================>.......] - ETA: 36s - loss: 0.3371 - iou_score: 0.6533 - f1-score: 0.7877For batch 157, tr_loss is    0.34.\n",
      "159/200 [======================>.......] - ETA: 35s - loss: 0.3373 - iou_score: 0.6531 - f1-score: 0.7876For batch 158, tr_loss is    0.34.\n",
      "160/200 [=======================>......] - ETA: 35s - loss: 0.3373 - iou_score: 0.6530 - f1-score: 0.7876For batch 159, tr_loss is    0.34.\n",
      "161/200 [=======================>......] - ETA: 34s - loss: 0.3374 - iou_score: 0.6527 - f1-score: 0.7874For batch 160, tr_loss is    0.34.\n",
      "162/200 [=======================>......] - ETA: 33s - loss: 0.3376 - iou_score: 0.6525 - f1-score: 0.7872For batch 161, tr_loss is    0.34.\n",
      "163/200 [=======================>......] - ETA: 32s - loss: 0.3370 - iou_score: 0.6533 - f1-score: 0.7878For batch 162, tr_loss is    0.34.\n",
      "164/200 [=======================>......] - ETA: 31s - loss: 0.3372 - iou_score: 0.6532 - f1-score: 0.7877For batch 163, tr_loss is    0.34.\n",
      "165/200 [=======================>......] - ETA: 30s - loss: 0.3368 - iou_score: 0.6538 - f1-score: 0.7881For batch 164, tr_loss is    0.34.\n",
      "166/200 [=======================>......] - ETA: 29s - loss: 0.3368 - iou_score: 0.6538 - f1-score: 0.7881For batch 165, tr_loss is    0.34.\n",
      "167/200 [========================>.....] - ETA: 29s - loss: 0.3361 - iou_score: 0.6547 - f1-score: 0.7887For batch 166, tr_loss is    0.34.\n",
      "168/200 [========================>.....] - ETA: 28s - loss: 0.3362 - iou_score: 0.6544 - f1-score: 0.7885For batch 167, tr_loss is    0.34.\n",
      "169/200 [========================>.....] - ETA: 27s - loss: 0.3362 - iou_score: 0.6543 - f1-score: 0.7885For batch 168, tr_loss is    0.34.\n",
      "170/200 [========================>.....] - ETA: 26s - loss: 0.3358 - iou_score: 0.6548 - f1-score: 0.7888For batch 169, tr_loss is    0.34.\n",
      "171/200 [========================>.....] - ETA: 25s - loss: 0.3357 - iou_score: 0.6548 - f1-score: 0.7888For batch 170, tr_loss is    0.34.\n",
      "172/200 [========================>.....] - ETA: 24s - loss: 0.3353 - iou_score: 0.6553 - f1-score: 0.7892For batch 171, tr_loss is    0.34.\n",
      "173/200 [========================>.....] - ETA: 23s - loss: 0.3352 - iou_score: 0.6554 - f1-score: 0.7893For batch 172, tr_loss is    0.34.\n",
      "174/200 [=========================>....] - ETA: 22s - loss: 0.3349 - iou_score: 0.6557 - f1-score: 0.7895For batch 173, tr_loss is    0.33.\n",
      "175/200 [=========================>....] - ETA: 21s - loss: 0.3346 - iou_score: 0.6560 - f1-score: 0.7897For batch 174, tr_loss is    0.33.\n",
      "176/200 [=========================>....] - ETA: 21s - loss: 0.3348 - iou_score: 0.6558 - f1-score: 0.7895For batch 175, tr_loss is    0.33.\n",
      "177/200 [=========================>....] - ETA: 20s - loss: 0.3344 - iou_score: 0.6561 - f1-score: 0.7898For batch 176, tr_loss is    0.33.\n",
      "178/200 [=========================>....] - ETA: 19s - loss: 0.3347 - iou_score: 0.6557 - f1-score: 0.7894For batch 177, tr_loss is    0.33.\n",
      "179/200 [=========================>....] - ETA: 18s - loss: 0.3343 - iou_score: 0.6561 - f1-score: 0.7897For batch 178, tr_loss is    0.33.\n",
      "180/200 [==========================>...] - ETA: 17s - loss: 0.3344 - iou_score: 0.6559 - f1-score: 0.7896For batch 179, tr_loss is    0.33.\n",
      "181/200 [==========================>...] - ETA: 16s - loss: 0.3345 - iou_score: 0.6558 - f1-score: 0.7895For batch 180, tr_loss is    0.33.\n",
      "182/200 [==========================>...] - ETA: 15s - loss: 0.3344 - iou_score: 0.6558 - f1-score: 0.7896For batch 181, tr_loss is    0.33.\n",
      "183/200 [==========================>...] - ETA: 14s - loss: 0.3345 - iou_score: 0.6556 - f1-score: 0.7894For batch 182, tr_loss is    0.33.\n",
      "184/200 [==========================>...] - ETA: 14s - loss: 0.3343 - iou_score: 0.6559 - f1-score: 0.7896For batch 183, tr_loss is    0.33.\n",
      "185/200 [==========================>...] - ETA: 13s - loss: 0.3342 - iou_score: 0.6559 - f1-score: 0.7896For batch 184, tr_loss is    0.33.\n",
      "186/200 [==========================>...] - ETA: 12s - loss: 0.3340 - iou_score: 0.6561 - f1-score: 0.7898For batch 185, tr_loss is    0.33.\n",
      "187/200 [===========================>..] - ETA: 11s - loss: 0.3338 - iou_score: 0.6563 - f1-score: 0.7899For batch 186, tr_loss is    0.33.\n",
      "188/200 [===========================>..] - ETA: 10s - loss: 0.3335 - iou_score: 0.6566 - f1-score: 0.7901For batch 187, tr_loss is    0.33.\n",
      "189/200 [===========================>..] - ETA: 9s - loss: 0.3338 - iou_score: 0.6563 - f1-score: 0.7899 For batch 188, tr_loss is    0.33.\n",
      "190/200 [===========================>..] - ETA: 8s - loss: 0.3338 - iou_score: 0.6562 - f1-score: 0.7899For batch 189, tr_loss is    0.33.\n",
      "191/200 [===========================>..] - ETA: 7s - loss: 0.3343 - iou_score: 0.6556 - f1-score: 0.7894For batch 190, tr_loss is    0.33.\n",
      "192/200 [===========================>..] - ETA: 7s - loss: 0.3345 - iou_score: 0.6552 - f1-score: 0.7891For batch 191, tr_loss is    0.33.\n",
      "193/200 [===========================>..] - ETA: 6s - loss: 0.3342 - iou_score: 0.6556 - f1-score: 0.7894For batch 192, tr_loss is    0.33.\n",
      "194/200 [============================>.] - ETA: 5s - loss: 0.3343 - iou_score: 0.6555 - f1-score: 0.7893For batch 193, tr_loss is    0.33.\n",
      "195/200 [============================>.] - ETA: 4s - loss: 0.3344 - iou_score: 0.6553 - f1-score: 0.7892For batch 194, tr_loss is    0.33.\n",
      "196/200 [============================>.] - ETA: 3s - loss: 0.3345 - iou_score: 0.6551 - f1-score: 0.7890For batch 195, tr_loss is    0.33.\n",
      "197/200 [============================>.] - ETA: 2s - loss: 0.3341 - iou_score: 0.6557 - f1-score: 0.7894For batch 196, tr_loss is    0.33.\n",
      "198/200 [============================>.] - ETA: 1s - loss: 0.3341 - iou_score: 0.6557 - f1-score: 0.7894For batch 197, tr_loss is    0.33.\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.3343 - iou_score: 0.6554 - f1-score: 0.7892For batch 198, tr_loss is    0.33.\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.3342 - iou_score: 0.6553 - f1-score: 0.7892For batch 199, tr_loss is    0.33.\n",
      "For batch 0, vl_loss is    0.36.\n",
      "For batch 1, vl_loss is    0.36.\n",
      "For batch 2, vl_loss is    0.34.\n",
      "For batch 3, vl_loss is    0.34.\n",
      "For batch 4, vl_loss is    0.32.\n",
      "For batch 5, vl_loss is    0.32.\n",
      "For batch 6, vl_loss is    0.34.\n",
      "For batch 7, vl_loss is    0.33.\n",
      "For batch 8, vl_loss is    0.34.\n",
      "For batch 9, vl_loss is    0.35.\n",
      "For batch 10, vl_loss is    0.35.\n",
      "For batch 11, vl_loss is    0.34.\n",
      "For batch 12, vl_loss is    0.34.\n",
      "For batch 13, vl_loss is    0.34.\n",
      "For batch 14, vl_loss is    0.34.\n",
      "For batch 15, vl_loss is    0.33.\n",
      "For batch 16, vl_loss is    0.33.\n",
      "For batch 17, vl_loss is    0.33.\n",
      "For batch 18, vl_loss is    0.33.\n",
      "For batch 19, vl_loss is    0.33.\n",
      "For batch 20, vl_loss is    0.33.\n",
      "For batch 21, vl_loss is    0.33.\n",
      "For batch 22, vl_loss is    0.33.\n",
      "For batch 23, vl_loss is    0.34.\n",
      "For batch 24, vl_loss is    0.34.\n",
      "For batch 25, vl_loss is    0.35.\n",
      "For batch 26, vl_loss is    0.35.\n",
      "For batch 27, vl_loss is    0.34.\n",
      "For batch 28, vl_loss is    0.35.\n",
      "For batch 29, vl_loss is    0.35.\n",
      "For batch 30, vl_loss is    0.34.\n",
      "For batch 31, vl_loss is    0.34.\n",
      "For batch 32, vl_loss is    0.34.\n",
      "For batch 33, vl_loss is    0.34.\n",
      "For batch 34, vl_loss is    0.34.\n",
      "For batch 35, vl_loss is    0.34.\n",
      "For batch 36, vl_loss is    0.34.\n",
      "For batch 37, vl_loss is    0.34.\n",
      "For batch 38, vl_loss is    0.34.\n",
      "For batch 39, vl_loss is    0.34.\n",
      "For batch 40, vl_loss is    0.34.\n",
      "For batch 41, vl_loss is    0.34.\n",
      "For batch 42, vl_loss is    0.34.\n",
      "For batch 43, vl_loss is    0.34.\n",
      "For batch 44, vl_loss is    0.34.\n",
      "For batch 45, vl_loss is    0.34.\n",
      "For batch 46, vl_loss is    0.34.\n",
      "For batch 47, vl_loss is    0.34.\n",
      "For batch 48, vl_loss is    0.34.\n",
      "For batch 49, vl_loss is    0.34.\n",
      "For batch 50, vl_loss is    0.34.\n",
      "For batch 51, vl_loss is    0.34.\n",
      "For batch 52, vl_loss is    0.34.\n",
      "For batch 53, vl_loss is    0.34.\n",
      "For batch 54, vl_loss is    0.34.\n",
      "For batch 55, vl_loss is    0.34.\n",
      "For batch 56, vl_loss is    0.34.\n",
      "For batch 57, vl_loss is    0.34.\n",
      "For batch 58, vl_loss is    0.34.\n",
      "For batch 59, vl_loss is    0.34.\n",
      "For batch 60, vl_loss is    0.34.\n",
      "For batch 61, vl_loss is    0.34.\n",
      "For batch 62, vl_loss is    0.34.\n",
      "For batch 63, vl_loss is    0.34.\n",
      "For batch 64, vl_loss is    0.34.\n",
      "For batch 65, vl_loss is    0.34.\n",
      "For batch 66, vl_loss is    0.34.\n",
      "For batch 67, vl_loss is    0.34.\n",
      "For batch 68, vl_loss is    0.34.\n",
      "For batch 69, vl_loss is    0.34.\n",
      "For batch 70, vl_loss is    0.34.\n",
      "For batch 71, vl_loss is    0.34.\n",
      "For batch 72, vl_loss is    0.34.\n",
      "For batch 73, vl_loss is    0.34.\n",
      "For batch 74, vl_loss is    0.34.\n",
      "For batch 75, vl_loss is    0.34.\n",
      "For batch 76, vl_loss is    0.34.\n",
      "For batch 77, vl_loss is    0.34.\n",
      "For batch 78, vl_loss is    0.34.\n",
      "For batch 79, vl_loss is    0.34.\n",
      "For batch 80, vl_loss is    0.34.\n",
      "For batch 81, vl_loss is    0.34.\n",
      "For batch 82, vl_loss is    0.34.\n",
      "For batch 83, vl_loss is    0.34.\n",
      "For batch 84, vl_loss is    0.34.\n",
      "For batch 85, vl_loss is    0.34.\n",
      "For batch 86, vl_loss is    0.34.\n",
      "For batch 87, vl_loss is    0.34.\n",
      "For batch 88, vl_loss is    0.34.\n",
      "For batch 89, vl_loss is    0.34.\n",
      "For batch 90, vl_loss is    0.34.\n",
      "For batch 91, vl_loss is    0.34.\n",
      "For batch 92, vl_loss is    0.34.\n",
      "For batch 93, vl_loss is    0.34.\n",
      "For batch 94, vl_loss is    0.34.\n",
      "For batch 95, vl_loss is    0.34.\n",
      "For batch 96, vl_loss is    0.34.\n",
      "For batch 97, vl_loss is    0.34.\n",
      "For batch 98, vl_loss is    0.34.\n",
      "For batch 99, vl_loss is    0.34.\n",
      "200/200 [==============================] - 183s 901ms/step - loss: 0.3342 - iou_score: 0.6553 - f1-score: 0.7892 - val_loss: 0.3417 - val_iou_score: 0.6841 - val_f1-score: 0.8106\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.33218\n",
      "The average loss for epoch 3 is    0.33 \n",
      "Epoch 5/200\n",
      "  1/200 [..............................] - ETA: 8:01 - loss: 0.3334 - iou_score: 0.6766 - f1-score: 0.8068For batch 0, tr_loss is    0.33.\n",
      "  2/200 [..............................] - ETA: 5:26 - loss: 0.3220 - iou_score: 0.6786 - f1-score: 0.8079For batch 1, tr_loss is    0.32.\n",
      "  3/200 [..............................] - ETA: 4:43 - loss: 0.3175 - iou_score: 0.6828 - f1-score: 0.8108For batch 2, tr_loss is    0.32.\n",
      "  4/200 [..............................] - ETA: 4:36 - loss: 0.3193 - iou_score: 0.6745 - f1-score: 0.8050For batch 3, tr_loss is    0.32.\n",
      "  5/200 [..............................] - ETA: 4:25 - loss: 0.3184 - iou_score: 0.6743 - f1-score: 0.8049For batch 4, tr_loss is    0.32.\n",
      "  6/200 [..............................] - ETA: 4:13 - loss: 0.3267 - iou_score: 0.6640 - f1-score: 0.7973For batch 5, tr_loss is    0.33.\n",
      "  7/200 [>.............................] - ETA: 4:02 - loss: 0.3358 - iou_score: 0.6524 - f1-score: 0.7879For batch 6, tr_loss is    0.34.\n",
      "  8/200 [>.............................] - ETA: 3:55 - loss: 0.3379 - iou_score: 0.6509 - f1-score: 0.7869For batch 7, tr_loss is    0.34.\n",
      "  9/200 [>.............................] - ETA: 3:49 - loss: 0.3344 - iou_score: 0.6562 - f1-score: 0.7906For batch 8, tr_loss is    0.33.\n",
      " 10/200 [>.............................] - ETA: 3:51 - loss: 0.3354 - iou_score: 0.6557 - f1-score: 0.7899For batch 9, tr_loss is    0.34.\n",
      " 11/200 [>.............................] - ETA: 3:42 - loss: 0.3334 - iou_score: 0.6579 - f1-score: 0.7916For batch 10, tr_loss is    0.33.\n",
      " 12/200 [>.............................] - ETA: 3:39 - loss: 0.3365 - iou_score: 0.6518 - f1-score: 0.7870For batch 11, tr_loss is    0.34.\n",
      " 13/200 [>.............................] - ETA: 3:43 - loss: 0.3375 - iou_score: 0.6492 - f1-score: 0.7853For batch 12, tr_loss is    0.34.\n",
      " 14/200 [=>............................] - ETA: 3:36 - loss: 0.3380 - iou_score: 0.6495 - f1-score: 0.7855For batch 13, tr_loss is    0.34.\n",
      " 15/200 [=>............................] - ETA: 3:33 - loss: 0.3355 - iou_score: 0.6523 - f1-score: 0.7876For batch 14, tr_loss is    0.34.\n",
      " 16/200 [=>............................] - ETA: 3:24 - loss: 0.3366 - iou_score: 0.6503 - f1-score: 0.7862For batch 15, tr_loss is    0.34.\n",
      " 17/200 [=>............................] - ETA: 3:20 - loss: 0.3353 - iou_score: 0.6527 - f1-score: 0.7881For batch 16, tr_loss is    0.34.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 18/200 [=>............................] - ETA: 3:19 - loss: 0.3320 - iou_score: 0.6562 - f1-score: 0.7906For batch 17, tr_loss is    0.33.\n",
      " 19/200 [=>............................] - ETA: 3:17 - loss: 0.3341 - iou_score: 0.6533 - f1-score: 0.7883For batch 18, tr_loss is    0.33.\n",
      " 20/200 [==>...........................] - ETA: 3:16 - loss: 0.3308 - iou_score: 0.6577 - f1-score: 0.7914For batch 19, tr_loss is    0.33.\n",
      " 21/200 [==>...........................] - ETA: 3:14 - loss: 0.3291 - iou_score: 0.6603 - f1-score: 0.7933For batch 20, tr_loss is    0.33.\n",
      " 22/200 [==>...........................] - ETA: 3:12 - loss: 0.3281 - iou_score: 0.6614 - f1-score: 0.7941For batch 21, tr_loss is    0.33.\n",
      " 23/200 [==>...........................] - ETA: 3:06 - loss: 0.3268 - iou_score: 0.6625 - f1-score: 0.7950For batch 22, tr_loss is    0.33.\n",
      " 24/200 [==>...........................] - ETA: 3:07 - loss: 0.3263 - iou_score: 0.6630 - f1-score: 0.7954For batch 23, tr_loss is    0.33.\n",
      " 25/200 [==>...........................] - ETA: 3:05 - loss: 0.3243 - iou_score: 0.6646 - f1-score: 0.7966For batch 24, tr_loss is    0.32.\n",
      " 26/200 [==>...........................] - ETA: 3:04 - loss: 0.3281 - iou_score: 0.6616 - f1-score: 0.7944For batch 25, tr_loss is    0.33.\n",
      " 27/200 [===>..........................] - ETA: 2:59 - loss: 0.3272 - iou_score: 0.6627 - f1-score: 0.7952For batch 26, tr_loss is    0.33.\n",
      " 28/200 [===>..........................] - ETA: 2:57 - loss: 0.3280 - iou_score: 0.6625 - f1-score: 0.7951For batch 27, tr_loss is    0.33.\n",
      " 29/200 [===>..........................] - ETA: 2:53 - loss: 0.3279 - iou_score: 0.6623 - f1-score: 0.7950For batch 28, tr_loss is    0.33.\n",
      " 30/200 [===>..........................] - ETA: 2:51 - loss: 0.3260 - iou_score: 0.6647 - f1-score: 0.7967For batch 29, tr_loss is    0.33.\n",
      " 31/200 [===>..........................] - ETA: 2:48 - loss: 0.3242 - iou_score: 0.6668 - f1-score: 0.7982For batch 30, tr_loss is    0.32.\n",
      " 32/200 [===>..........................] - ETA: 2:44 - loss: 0.3231 - iou_score: 0.6684 - f1-score: 0.7994For batch 31, tr_loss is    0.32.\n",
      " 33/200 [===>..........................] - ETA: 2:44 - loss: 0.3220 - iou_score: 0.6694 - f1-score: 0.8001For batch 32, tr_loss is    0.32.\n",
      " 34/200 [====>.........................] - ETA: 2:43 - loss: 0.3228 - iou_score: 0.6681 - f1-score: 0.7992For batch 33, tr_loss is    0.32.\n",
      " 35/200 [====>.........................] - ETA: 2:40 - loss: 0.3219 - iou_score: 0.6691 - f1-score: 0.7999For batch 34, tr_loss is    0.32.\n",
      " 36/200 [====>.........................] - ETA: 2:39 - loss: 0.3213 - iou_score: 0.6698 - f1-score: 0.8004For batch 35, tr_loss is    0.32.\n",
      " 37/200 [====>.........................] - ETA: 2:38 - loss: 0.3219 - iou_score: 0.6691 - f1-score: 0.7999For batch 36, tr_loss is    0.32.\n",
      " 38/200 [====>.........................] - ETA: 2:37 - loss: 0.3230 - iou_score: 0.6675 - f1-score: 0.7987For batch 37, tr_loss is    0.32.\n",
      " 39/200 [====>.........................] - ETA: 2:35 - loss: 0.3223 - iou_score: 0.6683 - f1-score: 0.7994For batch 38, tr_loss is    0.32.\n",
      " 40/200 [=====>........................] - ETA: 2:32 - loss: 0.3210 - iou_score: 0.6697 - f1-score: 0.8004For batch 39, tr_loss is    0.32.\n",
      " 41/200 [=====>........................] - ETA: 2:32 - loss: 0.3204 - iou_score: 0.6699 - f1-score: 0.8005For batch 40, tr_loss is    0.32.\n",
      " 42/200 [=====>........................] - ETA: 2:31 - loss: 0.3217 - iou_score: 0.6687 - f1-score: 0.7997For batch 41, tr_loss is    0.32.\n",
      " 43/200 [=====>........................] - ETA: 2:31 - loss: 0.3215 - iou_score: 0.6690 - f1-score: 0.7999For batch 42, tr_loss is    0.32.\n",
      " 44/200 [=====>........................] - ETA: 2:30 - loss: 0.3207 - iou_score: 0.6701 - f1-score: 0.8007For batch 43, tr_loss is    0.32.\n",
      " 45/200 [=====>........................] - ETA: 2:28 - loss: 0.3209 - iou_score: 0.6699 - f1-score: 0.8006For batch 44, tr_loss is    0.32.\n",
      " 46/200 [=====>........................] - ETA: 2:27 - loss: 0.3217 - iou_score: 0.6693 - f1-score: 0.8000For batch 45, tr_loss is    0.32.\n",
      " 47/200 [======>.......................] - ETA: 2:27 - loss: 0.3222 - iou_score: 0.6687 - f1-score: 0.7996For batch 46, tr_loss is    0.32.\n",
      " 48/200 [======>.......................] - ETA: 2:26 - loss: 0.3226 - iou_score: 0.6682 - f1-score: 0.7992For batch 47, tr_loss is    0.32.\n",
      " 49/200 [======>.......................] - ETA: 2:25 - loss: 0.3223 - iou_score: 0.6684 - f1-score: 0.7994For batch 48, tr_loss is    0.32.\n",
      " 50/200 [======>.......................] - ETA: 2:24 - loss: 0.3207 - iou_score: 0.6702 - f1-score: 0.8007For batch 49, tr_loss is    0.32.\n",
      " 51/200 [======>.......................] - ETA: 2:22 - loss: 0.3203 - iou_score: 0.6712 - f1-score: 0.8014For batch 50, tr_loss is    0.32.\n",
      " 52/200 [======>.......................] - ETA: 2:22 - loss: 0.3204 - iou_score: 0.6710 - f1-score: 0.8012For batch 51, tr_loss is    0.32.\n",
      " 53/200 [======>.......................] - ETA: 2:21 - loss: 0.3202 - iou_score: 0.6712 - f1-score: 0.8014For batch 52, tr_loss is    0.32.\n",
      " 54/200 [=======>......................] - ETA: 2:20 - loss: 0.3203 - iou_score: 0.6710 - f1-score: 0.8013For batch 53, tr_loss is    0.32.\n",
      " 55/200 [=======>......................] - ETA: 2:19 - loss: 0.3192 - iou_score: 0.6719 - f1-score: 0.8019For batch 54, tr_loss is    0.32.\n",
      " 56/200 [=======>......................] - ETA: 2:18 - loss: 0.3190 - iou_score: 0.6720 - f1-score: 0.8020For batch 55, tr_loss is    0.32.\n",
      " 57/200 [=======>......................] - ETA: 2:17 - loss: 0.3186 - iou_score: 0.6717 - f1-score: 0.8018For batch 56, tr_loss is    0.32.\n",
      " 58/200 [=======>......................] - ETA: 2:16 - loss: 0.3185 - iou_score: 0.6716 - f1-score: 0.8017For batch 57, tr_loss is    0.32.\n",
      " 59/200 [=======>......................] - ETA: 2:14 - loss: 0.3177 - iou_score: 0.6724 - f1-score: 0.8023For batch 58, tr_loss is    0.32.\n",
      " 60/200 [========>.....................] - ETA: 2:13 - loss: 0.3169 - iou_score: 0.6727 - f1-score: 0.8025For batch 59, tr_loss is    0.32.\n",
      " 61/200 [========>.....................] - ETA: 2:12 - loss: 0.3180 - iou_score: 0.6715 - f1-score: 0.8017For batch 60, tr_loss is    0.32.\n",
      " 62/200 [========>.....................] - ETA: 2:11 - loss: 0.3179 - iou_score: 0.6714 - f1-score: 0.8017For batch 61, tr_loss is    0.32.\n",
      " 63/200 [========>.....................] - ETA: 2:10 - loss: 0.3173 - iou_score: 0.6719 - f1-score: 0.8020For batch 62, tr_loss is    0.32.\n",
      " 64/200 [========>.....................] - ETA: 2:08 - loss: 0.3184 - iou_score: 0.6705 - f1-score: 0.8010For batch 63, tr_loss is    0.32.\n",
      " 65/200 [========>.....................] - ETA: 2:07 - loss: 0.3170 - iou_score: 0.6722 - f1-score: 0.8022For batch 64, tr_loss is    0.32.\n",
      " 66/200 [========>.....................] - ETA: 2:05 - loss: 0.3187 - iou_score: 0.6703 - f1-score: 0.8006For batch 65, tr_loss is    0.32.\n",
      " 67/200 [=========>....................] - ETA: 2:05 - loss: 0.3180 - iou_score: 0.6710 - f1-score: 0.8012For batch 66, tr_loss is    0.32.\n",
      " 68/200 [=========>....................] - ETA: 2:04 - loss: 0.3176 - iou_score: 0.6711 - f1-score: 0.8012For batch 67, tr_loss is    0.32.\n",
      " 69/200 [=========>....................] - ETA: 2:02 - loss: 0.3190 - iou_score: 0.6695 - f1-score: 0.8000For batch 68, tr_loss is    0.32.\n",
      " 70/200 [=========>....................] - ETA: 2:02 - loss: 0.3189 - iou_score: 0.6695 - f1-score: 0.8000For batch 69, tr_loss is    0.32.\n",
      " 71/200 [=========>....................] - ETA: 2:01 - loss: 0.3187 - iou_score: 0.6700 - f1-score: 0.8004For batch 70, tr_loss is    0.32.\n",
      " 72/200 [=========>....................] - ETA: 2:00 - loss: 0.3191 - iou_score: 0.6698 - f1-score: 0.8003For batch 71, tr_loss is    0.32.\n",
      " 73/200 [=========>....................] - ETA: 1:58 - loss: 0.3186 - iou_score: 0.6702 - f1-score: 0.8006For batch 72, tr_loss is    0.32.\n",
      " 74/200 [==========>...................] - ETA: 1:58 - loss: 0.3194 - iou_score: 0.6691 - f1-score: 0.7997For batch 73, tr_loss is    0.32.\n",
      " 75/200 [==========>...................] - ETA: 1:57 - loss: 0.3205 - iou_score: 0.6681 - f1-score: 0.7990For batch 74, tr_loss is    0.32.\n",
      " 76/200 [==========>...................] - ETA: 1:56 - loss: 0.3205 - iou_score: 0.6677 - f1-score: 0.7987For batch 75, tr_loss is    0.32.\n",
      " 77/200 [==========>...................] - ETA: 1:55 - loss: 0.3204 - iou_score: 0.6677 - f1-score: 0.7987For batch 76, tr_loss is    0.32.\n",
      " 78/200 [==========>...................] - ETA: 1:55 - loss: 0.3199 - iou_score: 0.6679 - f1-score: 0.7989For batch 77, tr_loss is    0.32.\n",
      " 79/200 [==========>...................] - ETA: 1:53 - loss: 0.3201 - iou_score: 0.6680 - f1-score: 0.7990For batch 78, tr_loss is    0.32.\n",
      " 80/200 [===========>..................] - ETA: 1:52 - loss: 0.3198 - iou_score: 0.6684 - f1-score: 0.7993For batch 79, tr_loss is    0.32.\n",
      " 81/200 [===========>..................] - ETA: 1:50 - loss: 0.3187 - iou_score: 0.6698 - f1-score: 0.8003For batch 80, tr_loss is    0.32.\n",
      " 82/200 [===========>..................] - ETA: 1:49 - loss: 0.3185 - iou_score: 0.6702 - f1-score: 0.8005For batch 81, tr_loss is    0.32.\n",
      " 83/200 [===========>..................] - ETA: 1:48 - loss: 0.3186 - iou_score: 0.6700 - f1-score: 0.8004For batch 82, tr_loss is    0.32.\n",
      " 84/200 [===========>..................] - ETA: 1:47 - loss: 0.3181 - iou_score: 0.6705 - f1-score: 0.8007For batch 83, tr_loss is    0.32.\n",
      " 85/200 [===========>..................] - ETA: 1:46 - loss: 0.3187 - iou_score: 0.6696 - f1-score: 0.8001For batch 84, tr_loss is    0.32.\n",
      " 86/200 [===========>..................] - ETA: 1:44 - loss: 0.3190 - iou_score: 0.6691 - f1-score: 0.7997For batch 85, tr_loss is    0.32.\n",
      " 87/200 [============>.................] - ETA: 1:43 - loss: 0.3184 - iou_score: 0.6699 - f1-score: 0.8002For batch 86, tr_loss is    0.32.\n",
      " 88/200 [============>.................] - ETA: 1:43 - loss: 0.3179 - iou_score: 0.6704 - f1-score: 0.8006For batch 87, tr_loss is    0.32.\n",
      " 89/200 [============>.................] - ETA: 1:42 - loss: 0.3184 - iou_score: 0.6699 - f1-score: 0.8003For batch 88, tr_loss is    0.32.\n",
      " 90/200 [============>.................] - ETA: 1:41 - loss: 0.3186 - iou_score: 0.6697 - f1-score: 0.8001For batch 89, tr_loss is    0.32.\n",
      " 91/200 [============>.................] - ETA: 1:40 - loss: 0.3186 - iou_score: 0.6696 - f1-score: 0.8001For batch 90, tr_loss is    0.32.\n",
      " 92/200 [============>.................] - ETA: 1:39 - loss: 0.3193 - iou_score: 0.6689 - f1-score: 0.7996For batch 91, tr_loss is    0.32.\n",
      " 93/200 [============>.................] - ETA: 1:38 - loss: 0.3196 - iou_score: 0.6687 - f1-score: 0.7995For batch 92, tr_loss is    0.32.\n",
      " 94/200 [=============>................] - ETA: 1:37 - loss: 0.3209 - iou_score: 0.6672 - f1-score: 0.7983For batch 93, tr_loss is    0.32.\n",
      " 95/200 [=============>................] - ETA: 1:36 - loss: 0.3214 - iou_score: 0.6667 - f1-score: 0.7979For batch 94, tr_loss is    0.32.\n",
      " 96/200 [=============>................] - ETA: 1:35 - loss: 0.3210 - iou_score: 0.6674 - f1-score: 0.7985For batch 95, tr_loss is    0.32.\n",
      " 97/200 [=============>................] - ETA: 1:34 - loss: 0.3216 - iou_score: 0.6666 - f1-score: 0.7979For batch 96, tr_loss is    0.32.\n",
      " 98/200 [=============>................] - ETA: 1:33 - loss: 0.3215 - iou_score: 0.6667 - f1-score: 0.7979For batch 97, tr_loss is    0.32.\n",
      " 99/200 [=============>................] - ETA: 1:32 - loss: 0.3213 - iou_score: 0.6669 - f1-score: 0.7981For batch 98, tr_loss is    0.32.\n",
      "100/200 [==============>...............] - ETA: 1:31 - loss: 0.3215 - iou_score: 0.6669 - f1-score: 0.7981For batch 99, tr_loss is    0.32.\n",
      "101/200 [==============>...............] - ETA: 1:29 - loss: 0.3214 - iou_score: 0.6671 - f1-score: 0.7982For batch 100, tr_loss is    0.32.\n",
      "102/200 [==============>...............] - ETA: 1:29 - loss: 0.3217 - iou_score: 0.6665 - f1-score: 0.7979For batch 101, tr_loss is    0.32.\n",
      "103/200 [==============>...............] - ETA: 1:27 - loss: 0.3220 - iou_score: 0.6663 - f1-score: 0.7977For batch 102, tr_loss is    0.32.\n",
      "104/200 [==============>...............] - ETA: 1:26 - loss: 0.3222 - iou_score: 0.6659 - f1-score: 0.7974For batch 103, tr_loss is    0.32.\n",
      "105/200 [==============>...............] - ETA: 1:25 - loss: 0.3224 - iou_score: 0.6657 - f1-score: 0.7973For batch 104, tr_loss is    0.32.\n",
      "106/200 [==============>...............] - ETA: 1:24 - loss: 0.3229 - iou_score: 0.6654 - f1-score: 0.7971For batch 105, tr_loss is    0.32.\n",
      "107/200 [===============>..............] - ETA: 1:24 - loss: 0.3231 - iou_score: 0.6651 - f1-score: 0.7969For batch 106, tr_loss is    0.32.\n",
      "108/200 [===============>..............] - ETA: 1:23 - loss: 0.3231 - iou_score: 0.6653 - f1-score: 0.7970For batch 107, tr_loss is    0.32.\n",
      "109/200 [===============>..............] - ETA: 1:22 - loss: 0.3230 - iou_score: 0.6654 - f1-score: 0.7970For batch 108, tr_loss is    0.32.\n",
      "110/200 [===============>..............] - ETA: 1:21 - loss: 0.3228 - iou_score: 0.6656 - f1-score: 0.7972For batch 109, tr_loss is    0.32.\n",
      "111/200 [===============>..............] - ETA: 1:20 - loss: 0.3223 - iou_score: 0.6661 - f1-score: 0.7976For batch 110, tr_loss is    0.32.\n",
      "112/200 [===============>..............] - ETA: 1:19 - loss: 0.3222 - iou_score: 0.6663 - f1-score: 0.7977For batch 111, tr_loss is    0.32.\n",
      "113/200 [===============>..............] - ETA: 1:18 - loss: 0.3230 - iou_score: 0.6652 - f1-score: 0.7969For batch 112, tr_loss is    0.32.\n",
      "114/200 [================>.............] - ETA: 1:17 - loss: 0.3235 - iou_score: 0.6647 - f1-score: 0.7965For batch 113, tr_loss is    0.32.\n",
      "115/200 [================>.............] - ETA: 1:16 - loss: 0.3235 - iou_score: 0.6648 - f1-score: 0.7965For batch 114, tr_loss is    0.32.\n",
      "116/200 [================>.............] - ETA: 1:16 - loss: 0.3237 - iou_score: 0.6644 - f1-score: 0.7963For batch 115, tr_loss is    0.32.\n",
      "117/200 [================>.............] - ETA: 1:14 - loss: 0.3239 - iou_score: 0.6641 - f1-score: 0.7960For batch 116, tr_loss is    0.32.\n",
      "118/200 [================>.............] - ETA: 1:13 - loss: 0.3238 - iou_score: 0.6642 - f1-score: 0.7961For batch 117, tr_loss is    0.32.\n",
      "119/200 [================>.............] - ETA: 1:13 - loss: 0.3239 - iou_score: 0.6640 - f1-score: 0.7960For batch 118, tr_loss is    0.32.\n",
      "120/200 [=================>............] - ETA: 1:12 - loss: 0.3235 - iou_score: 0.6645 - f1-score: 0.7963For batch 119, tr_loss is    0.32.\n",
      "121/200 [=================>............] - ETA: 1:11 - loss: 0.3232 - iou_score: 0.6650 - f1-score: 0.7967For batch 120, tr_loss is    0.32.\n",
      "122/200 [=================>............] - ETA: 1:10 - loss: 0.3230 - iou_score: 0.6651 - f1-score: 0.7968For batch 121, tr_loss is    0.32.\n",
      "123/200 [=================>............] - ETA: 1:09 - loss: 0.3236 - iou_score: 0.6643 - f1-score: 0.7961For batch 122, tr_loss is    0.32.\n",
      "124/200 [=================>............] - ETA: 1:08 - loss: 0.3237 - iou_score: 0.6640 - f1-score: 0.7960For batch 123, tr_loss is    0.32.\n",
      "125/200 [=================>............] - ETA: 1:07 - loss: 0.3239 - iou_score: 0.6639 - f1-score: 0.7959For batch 124, tr_loss is    0.32.\n",
      "126/200 [=================>............] - ETA: 1:06 - loss: 0.3238 - iou_score: 0.6641 - f1-score: 0.7961For batch 125, tr_loss is    0.32.\n",
      "127/200 [==================>...........] - ETA: 1:05 - loss: 0.3237 - iou_score: 0.6641 - f1-score: 0.7961For batch 126, tr_loss is    0.32.\n",
      "128/200 [==================>...........] - ETA: 1:04 - loss: 0.3246 - iou_score: 0.6628 - f1-score: 0.7950For batch 127, tr_loss is    0.32.\n",
      "129/200 [==================>...........] - ETA: 1:03 - loss: 0.3246 - iou_score: 0.6628 - f1-score: 0.7951For batch 128, tr_loss is    0.32.\n",
      "130/200 [==================>...........] - ETA: 1:02 - loss: 0.3243 - iou_score: 0.6632 - f1-score: 0.7953For batch 129, tr_loss is    0.32.\n",
      "131/200 [==================>...........] - ETA: 1:02 - loss: 0.3238 - iou_score: 0.6636 - f1-score: 0.7956For batch 130, tr_loss is    0.32.\n",
      "132/200 [==================>...........] - ETA: 1:01 - loss: 0.3235 - iou_score: 0.6640 - f1-score: 0.7959For batch 131, tr_loss is    0.32.\n",
      "133/200 [==================>...........] - ETA: 1:00 - loss: 0.3235 - iou_score: 0.6638 - f1-score: 0.7958For batch 132, tr_loss is    0.32.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/200 [===================>..........] - ETA: 59s - loss: 0.3240 - iou_score: 0.6632 - f1-score: 0.7954 For batch 133, tr_loss is    0.32.\n",
      "135/200 [===================>..........] - ETA: 58s - loss: 0.3243 - iou_score: 0.6629 - f1-score: 0.7951For batch 134, tr_loss is    0.32.\n",
      "136/200 [===================>..........] - ETA: 57s - loss: 0.3241 - iou_score: 0.6630 - f1-score: 0.7952For batch 135, tr_loss is    0.32.\n",
      "137/200 [===================>..........] - ETA: 56s - loss: 0.3253 - iou_score: 0.6620 - f1-score: 0.7944For batch 136, tr_loss is    0.33.\n",
      "138/200 [===================>..........] - ETA: 56s - loss: 0.3254 - iou_score: 0.6618 - f1-score: 0.7943For batch 137, tr_loss is    0.33.\n",
      "139/200 [===================>..........] - ETA: 55s - loss: 0.3251 - iou_score: 0.6622 - f1-score: 0.7946For batch 138, tr_loss is    0.33.\n",
      "140/200 [====================>.........] - ETA: 54s - loss: 0.3263 - iou_score: 0.6611 - f1-score: 0.7936For batch 139, tr_loss is    0.33.\n",
      "141/200 [====================>.........] - ETA: 53s - loss: 0.3266 - iou_score: 0.6607 - f1-score: 0.7934For batch 140, tr_loss is    0.33.\n",
      "142/200 [====================>.........] - ETA: 52s - loss: 0.3264 - iou_score: 0.6611 - f1-score: 0.7937For batch 141, tr_loss is    0.33.\n",
      "143/200 [====================>.........] - ETA: 51s - loss: 0.3264 - iou_score: 0.6610 - f1-score: 0.7936For batch 142, tr_loss is    0.33.\n",
      "144/200 [====================>.........] - ETA: 50s - loss: 0.3264 - iou_score: 0.6609 - f1-score: 0.7935For batch 143, tr_loss is    0.33.\n",
      "145/200 [====================>.........] - ETA: 49s - loss: 0.3265 - iou_score: 0.6607 - f1-score: 0.7934For batch 144, tr_loss is    0.33.\n",
      "146/200 [====================>.........] - ETA: 48s - loss: 0.3260 - iou_score: 0.6615 - f1-score: 0.7939For batch 145, tr_loss is    0.33.\n",
      "147/200 [=====================>........] - ETA: 48s - loss: 0.3262 - iou_score: 0.6612 - f1-score: 0.7937For batch 146, tr_loss is    0.33.\n",
      "148/200 [=====================>........] - ETA: 47s - loss: 0.3257 - iou_score: 0.6620 - f1-score: 0.7942For batch 147, tr_loss is    0.33.\n",
      "149/200 [=====================>........] - ETA: 46s - loss: 0.3254 - iou_score: 0.6622 - f1-score: 0.7943For batch 148, tr_loss is    0.33.\n",
      "150/200 [=====================>........] - ETA: 45s - loss: 0.3249 - iou_score: 0.6628 - f1-score: 0.7948For batch 149, tr_loss is    0.32.\n",
      "151/200 [=====================>........] - ETA: 44s - loss: 0.3253 - iou_score: 0.6626 - f1-score: 0.7946For batch 150, tr_loss is    0.33.\n",
      "152/200 [=====================>........] - ETA: 43s - loss: 0.3251 - iou_score: 0.6627 - f1-score: 0.7947For batch 151, tr_loss is    0.33.\n",
      "153/200 [=====================>........] - ETA: 42s - loss: 0.3249 - iou_score: 0.6629 - f1-score: 0.7949For batch 152, tr_loss is    0.32.\n",
      "154/200 [======================>.......] - ETA: 41s - loss: 0.3249 - iou_score: 0.6629 - f1-score: 0.7949For batch 153, tr_loss is    0.32.\n",
      "155/200 [======================>.......] - ETA: 40s - loss: 0.3247 - iou_score: 0.6631 - f1-score: 0.7951For batch 154, tr_loss is    0.32.\n",
      "156/200 [======================>.......] - ETA: 39s - loss: 0.3245 - iou_score: 0.6634 - f1-score: 0.7952For batch 155, tr_loss is    0.32.\n",
      "157/200 [======================>.......] - ETA: 38s - loss: 0.3246 - iou_score: 0.6632 - f1-score: 0.7951For batch 156, tr_loss is    0.32.\n",
      "158/200 [======================>.......] - ETA: 38s - loss: 0.3248 - iou_score: 0.6629 - f1-score: 0.7949For batch 157, tr_loss is    0.32.\n",
      "159/200 [======================>.......] - ETA: 37s - loss: 0.3250 - iou_score: 0.6626 - f1-score: 0.7947For batch 158, tr_loss is    0.33.\n",
      "160/200 [=======================>......] - ETA: 36s - loss: 0.3249 - iou_score: 0.6626 - f1-score: 0.7947For batch 159, tr_loss is    0.32.\n",
      "161/200 [=======================>......] - ETA: 35s - loss: 0.3250 - iou_score: 0.6622 - f1-score: 0.7945For batch 160, tr_loss is    0.33.\n",
      "162/200 [=======================>......] - ETA: 34s - loss: 0.3252 - iou_score: 0.6620 - f1-score: 0.7943For batch 161, tr_loss is    0.33.\n",
      "163/200 [=======================>......] - ETA: 33s - loss: 0.3246 - iou_score: 0.6626 - f1-score: 0.7947For batch 162, tr_loss is    0.32.\n",
      "164/200 [=======================>......] - ETA: 32s - loss: 0.3245 - iou_score: 0.6626 - f1-score: 0.7947For batch 163, tr_loss is    0.32.\n",
      "165/200 [=======================>......] - ETA: 31s - loss: 0.3242 - iou_score: 0.6630 - f1-score: 0.7950For batch 164, tr_loss is    0.32.\n",
      "166/200 [=======================>......] - ETA: 30s - loss: 0.3243 - iou_score: 0.6630 - f1-score: 0.7950For batch 165, tr_loss is    0.32.\n",
      "167/200 [========================>.....] - ETA: 29s - loss: 0.3236 - iou_score: 0.6639 - f1-score: 0.7957For batch 166, tr_loss is    0.32.\n",
      "168/200 [========================>.....] - ETA: 28s - loss: 0.3238 - iou_score: 0.6635 - f1-score: 0.7953For batch 167, tr_loss is    0.32.\n",
      "169/200 [========================>.....] - ETA: 27s - loss: 0.3238 - iou_score: 0.6633 - f1-score: 0.7952For batch 168, tr_loss is    0.32.\n",
      "170/200 [========================>.....] - ETA: 26s - loss: 0.3234 - iou_score: 0.6637 - f1-score: 0.7955For batch 169, tr_loss is    0.32.\n",
      "171/200 [========================>.....] - ETA: 26s - loss: 0.3233 - iou_score: 0.6637 - f1-score: 0.7955For batch 170, tr_loss is    0.32.\n",
      "172/200 [========================>.....] - ETA: 25s - loss: 0.3230 - iou_score: 0.6642 - f1-score: 0.7958For batch 171, tr_loss is    0.32.\n",
      "173/200 [========================>.....] - ETA: 24s - loss: 0.3230 - iou_score: 0.6642 - f1-score: 0.7958For batch 172, tr_loss is    0.32.\n",
      "174/200 [=========================>....] - ETA: 23s - loss: 0.3228 - iou_score: 0.6644 - f1-score: 0.7959For batch 173, tr_loss is    0.32.\n",
      "175/200 [=========================>....] - ETA: 22s - loss: 0.3226 - iou_score: 0.6647 - f1-score: 0.7962For batch 174, tr_loss is    0.32.\n",
      "176/200 [=========================>....] - ETA: 21s - loss: 0.3227 - iou_score: 0.6645 - f1-score: 0.7960For batch 175, tr_loss is    0.32.\n",
      "177/200 [=========================>....] - ETA: 20s - loss: 0.3226 - iou_score: 0.6647 - f1-score: 0.7962For batch 176, tr_loss is    0.32.\n",
      "178/200 [=========================>....] - ETA: 19s - loss: 0.3228 - iou_score: 0.6642 - f1-score: 0.7958For batch 177, tr_loss is    0.32.\n",
      "179/200 [=========================>....] - ETA: 18s - loss: 0.3224 - iou_score: 0.6647 - f1-score: 0.7962For batch 178, tr_loss is    0.32.\n",
      "180/200 [==========================>...] - ETA: 17s - loss: 0.3226 - iou_score: 0.6646 - f1-score: 0.7961For batch 179, tr_loss is    0.32.\n",
      "181/200 [==========================>...] - ETA: 16s - loss: 0.3227 - iou_score: 0.6644 - f1-score: 0.7960For batch 180, tr_loss is    0.32.\n",
      "182/200 [==========================>...] - ETA: 16s - loss: 0.3228 - iou_score: 0.6642 - f1-score: 0.7959For batch 181, tr_loss is    0.32.\n",
      "183/200 [==========================>...] - ETA: 15s - loss: 0.3227 - iou_score: 0.6642 - f1-score: 0.7958For batch 182, tr_loss is    0.32.\n",
      "184/200 [==========================>...] - ETA: 14s - loss: 0.3224 - iou_score: 0.6645 - f1-score: 0.7961For batch 183, tr_loss is    0.32.\n",
      "185/200 [==========================>...] - ETA: 13s - loss: 0.3223 - iou_score: 0.6646 - f1-score: 0.7961For batch 184, tr_loss is    0.32.\n",
      "186/200 [==========================>...] - ETA: 12s - loss: 0.3221 - iou_score: 0.6648 - f1-score: 0.7963For batch 185, tr_loss is    0.32.\n",
      "187/200 [===========================>..] - ETA: 11s - loss: 0.3219 - iou_score: 0.6651 - f1-score: 0.7965For batch 186, tr_loss is    0.32.\n",
      "188/200 [===========================>..] - ETA: 10s - loss: 0.3217 - iou_score: 0.6653 - f1-score: 0.7966For batch 187, tr_loss is    0.32.\n",
      "189/200 [===========================>..] - ETA: 9s - loss: 0.3220 - iou_score: 0.6650 - f1-score: 0.7964 For batch 188, tr_loss is    0.32.\n",
      "190/200 [===========================>..] - ETA: 8s - loss: 0.3220 - iou_score: 0.6650 - f1-score: 0.7964For batch 189, tr_loss is    0.32.\n",
      "191/200 [===========================>..] - ETA: 8s - loss: 0.3226 - iou_score: 0.6644 - f1-score: 0.7960For batch 190, tr_loss is    0.32.\n",
      "192/200 [===========================>..] - ETA: 7s - loss: 0.3230 - iou_score: 0.6640 - f1-score: 0.7956For batch 191, tr_loss is    0.32.\n",
      "193/200 [===========================>..] - ETA: 6s - loss: 0.3227 - iou_score: 0.6643 - f1-score: 0.7959For batch 192, tr_loss is    0.32.\n",
      "194/200 [============================>.] - ETA: 5s - loss: 0.3230 - iou_score: 0.6641 - f1-score: 0.7957For batch 193, tr_loss is    0.32.\n",
      "195/200 [============================>.] - ETA: 4s - loss: 0.3231 - iou_score: 0.6640 - f1-score: 0.7956For batch 194, tr_loss is    0.32.\n",
      "196/200 [============================>.] - ETA: 3s - loss: 0.3233 - iou_score: 0.6637 - f1-score: 0.7954For batch 195, tr_loss is    0.32.\n",
      "197/200 [============================>.] - ETA: 2s - loss: 0.3229 - iou_score: 0.6643 - f1-score: 0.7958For batch 196, tr_loss is    0.32.\n",
      "198/200 [============================>.] - ETA: 1s - loss: 0.3229 - iou_score: 0.6643 - f1-score: 0.7958For batch 197, tr_loss is    0.32.\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.3232 - iou_score: 0.6639 - f1-score: 0.7955For batch 198, tr_loss is    0.32.\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.3231 - iou_score: 0.6639 - f1-score: 0.7956For batch 199, tr_loss is    0.32.\n",
      "For batch 0, vl_loss is    0.34.\n",
      "For batch 1, vl_loss is    0.35.\n",
      "For batch 2, vl_loss is    0.34.\n",
      "For batch 3, vl_loss is    0.34.\n",
      "For batch 4, vl_loss is    0.33.\n",
      "For batch 5, vl_loss is    0.33.\n",
      "For batch 6, vl_loss is    0.34.\n",
      "For batch 7, vl_loss is    0.33.\n",
      "For batch 8, vl_loss is    0.34.\n",
      "For batch 9, vl_loss is    0.34.\n",
      "For batch 10, vl_loss is    0.35.\n",
      "For batch 11, vl_loss is    0.35.\n",
      "For batch 12, vl_loss is    0.35.\n",
      "For batch 13, vl_loss is    0.34.\n",
      "For batch 14, vl_loss is    0.34.\n",
      "For batch 15, vl_loss is    0.34.\n",
      "For batch 16, vl_loss is    0.33.\n",
      "For batch 17, vl_loss is    0.34.\n",
      "For batch 18, vl_loss is    0.34.\n",
      "For batch 19, vl_loss is    0.33.\n",
      "For batch 20, vl_loss is    0.34.\n",
      "For batch 21, vl_loss is    0.34.\n",
      "For batch 22, vl_loss is    0.34.\n",
      "For batch 23, vl_loss is    0.34.\n",
      "For batch 24, vl_loss is    0.34.\n",
      "For batch 25, vl_loss is    0.35.\n",
      "For batch 26, vl_loss is    0.34.\n",
      "For batch 27, vl_loss is    0.35.\n",
      "For batch 28, vl_loss is    0.35.\n",
      "For batch 29, vl_loss is    0.35.\n",
      "For batch 30, vl_loss is    0.35.\n",
      "For batch 31, vl_loss is    0.34.\n",
      "For batch 32, vl_loss is    0.35.\n",
      "For batch 33, vl_loss is    0.34.\n",
      "For batch 34, vl_loss is    0.34.\n",
      "For batch 35, vl_loss is    0.34.\n",
      "For batch 36, vl_loss is    0.34.\n",
      "For batch 37, vl_loss is    0.34.\n",
      "For batch 38, vl_loss is    0.34.\n",
      "For batch 39, vl_loss is    0.34.\n",
      "For batch 40, vl_loss is    0.34.\n",
      "For batch 41, vl_loss is    0.34.\n",
      "For batch 42, vl_loss is    0.34.\n",
      "For batch 43, vl_loss is    0.34.\n",
      "For batch 44, vl_loss is    0.34.\n",
      "For batch 45, vl_loss is    0.34.\n",
      "For batch 46, vl_loss is    0.34.\n",
      "For batch 47, vl_loss is    0.34.\n",
      "For batch 48, vl_loss is    0.34.\n",
      "For batch 49, vl_loss is    0.34.\n",
      "For batch 50, vl_loss is    0.34.\n",
      "For batch 51, vl_loss is    0.34.\n",
      "For batch 52, vl_loss is    0.34.\n",
      "For batch 53, vl_loss is    0.34.\n",
      "For batch 54, vl_loss is    0.34.\n",
      "For batch 55, vl_loss is    0.34.\n",
      "For batch 56, vl_loss is    0.34.\n",
      "For batch 57, vl_loss is    0.34.\n",
      "For batch 58, vl_loss is    0.34.\n",
      "For batch 59, vl_loss is    0.34.\n",
      "For batch 60, vl_loss is    0.34.\n",
      "For batch 61, vl_loss is    0.34.\n",
      "For batch 62, vl_loss is    0.34.\n",
      "For batch 63, vl_loss is    0.34.\n",
      "For batch 64, vl_loss is    0.34.\n",
      "For batch 65, vl_loss is    0.34.\n",
      "For batch 66, vl_loss is    0.34.\n",
      "For batch 67, vl_loss is    0.34.\n",
      "For batch 68, vl_loss is    0.34.\n",
      "For batch 69, vl_loss is    0.34.\n",
      "For batch 70, vl_loss is    0.34.\n",
      "For batch 71, vl_loss is    0.34.\n",
      "For batch 72, vl_loss is    0.34.\n",
      "For batch 73, vl_loss is    0.34.\n",
      "For batch 74, vl_loss is    0.34.\n",
      "For batch 75, vl_loss is    0.34.\n",
      "For batch 76, vl_loss is    0.34.\n",
      "For batch 77, vl_loss is    0.34.\n",
      "For batch 78, vl_loss is    0.34.\n",
      "For batch 79, vl_loss is    0.34.\n",
      "For batch 80, vl_loss is    0.34.\n",
      "For batch 81, vl_loss is    0.34.\n",
      "For batch 82, vl_loss is    0.34.\n",
      "For batch 83, vl_loss is    0.34.\n",
      "For batch 84, vl_loss is    0.34.\n",
      "For batch 85, vl_loss is    0.34.\n",
      "For batch 86, vl_loss is    0.34.\n",
      "For batch 87, vl_loss is    0.34.\n",
      "For batch 88, vl_loss is    0.34.\n",
      "For batch 89, vl_loss is    0.34.\n",
      "For batch 90, vl_loss is    0.34.\n",
      "For batch 91, vl_loss is    0.34.\n",
      "For batch 92, vl_loss is    0.34.\n",
      "For batch 93, vl_loss is    0.34.\n",
      "For batch 94, vl_loss is    0.34.\n",
      "For batch 95, vl_loss is    0.34.\n",
      "For batch 96, vl_loss is    0.34.\n",
      "For batch 97, vl_loss is    0.34.\n",
      "For batch 98, vl_loss is    0.34.\n",
      "For batch 99, vl_loss is    0.34.\n",
      "200/200 [==============================] - 184s 913ms/step - loss: 0.3231 - iou_score: 0.6639 - f1-score: 0.7956 - val_loss: 0.3449 - val_iou_score: 0.6769 - val_f1-score: 0.8055\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.33218\n",
      "The average loss for epoch 4 is    0.32 \n",
      "Epoch 6/200\n",
      "  1/200 [..............................] - ETA: 8:43 - loss: 0.3091 - iou_score: 0.6820 - f1-score: 0.8100For batch 0, tr_loss is    0.31.\n",
      "  2/200 [..............................] - ETA: 4:40 - loss: 0.2985 - iou_score: 0.6960 - f1-score: 0.8197For batch 1, tr_loss is    0.30.\n",
      "  3/200 [..............................] - ETA: 4:31 - loss: 0.2999 - iou_score: 0.6949 - f1-score: 0.8191For batch 2, tr_loss is    0.30.\n",
      "  4/200 [..............................] - ETA: 4:03 - loss: 0.3034 - iou_score: 0.6835 - f1-score: 0.8110For batch 3, tr_loss is    0.30.\n",
      "  5/200 [..............................] - ETA: 3:56 - loss: 0.2990 - iou_score: 0.6897 - f1-score: 0.8154For batch 4, tr_loss is    0.30.\n",
      "  6/200 [..............................] - ETA: 3:49 - loss: 0.3123 - iou_score: 0.6752 - f1-score: 0.8048For batch 5, tr_loss is    0.31.\n",
      "  7/200 [>.............................] - ETA: 3:55 - loss: 0.3221 - iou_score: 0.6640 - f1-score: 0.7958For batch 6, tr_loss is    0.32.\n",
      "  8/200 [>.............................] - ETA: 3:39 - loss: 0.3262 - iou_score: 0.6607 - f1-score: 0.7935For batch 7, tr_loss is    0.33.\n",
      "  9/200 [>.............................] - ETA: 3:42 - loss: 0.3215 - iou_score: 0.6664 - f1-score: 0.7976For batch 8, tr_loss is    0.32.\n",
      " 10/200 [>.............................] - ETA: 3:45 - loss: 0.3215 - iou_score: 0.6660 - f1-score: 0.7971For batch 9, tr_loss is    0.32.\n",
      " 11/200 [>.............................] - ETA: 3:39 - loss: 0.3212 - iou_score: 0.6680 - f1-score: 0.7987For batch 10, tr_loss is    0.32.\n",
      " 12/200 [>.............................] - ETA: 3:34 - loss: 0.3251 - iou_score: 0.6620 - f1-score: 0.7942For batch 11, tr_loss is    0.33.\n",
      " 13/200 [>.............................] - ETA: 3:31 - loss: 0.3259 - iou_score: 0.6599 - f1-score: 0.7927For batch 12, tr_loss is    0.33.\n",
      " 14/200 [=>............................] - ETA: 3:25 - loss: 0.3262 - iou_score: 0.6595 - f1-score: 0.7925For batch 13, tr_loss is    0.33.\n",
      " 15/200 [=>............................] - ETA: 3:16 - loss: 0.3240 - iou_score: 0.6612 - f1-score: 0.7938For batch 14, tr_loss is    0.32.\n",
      " 16/200 [=>............................] - ETA: 3:10 - loss: 0.3234 - iou_score: 0.6609 - f1-score: 0.7937For batch 15, tr_loss is    0.32.\n",
      " 17/200 [=>............................] - ETA: 3:05 - loss: 0.3214 - iou_score: 0.6628 - f1-score: 0.7953For batch 16, tr_loss is    0.32.\n",
      " 18/200 [=>............................] - ETA: 3:05 - loss: 0.3188 - iou_score: 0.6649 - f1-score: 0.7968For batch 17, tr_loss is    0.32.\n",
      " 19/200 [=>............................] - ETA: 3:04 - loss: 0.3213 - iou_score: 0.6623 - f1-score: 0.7948For batch 18, tr_loss is    0.32.\n",
      " 20/200 [==>...........................] - ETA: 3:03 - loss: 0.3178 - iou_score: 0.6673 - f1-score: 0.7982For batch 19, tr_loss is    0.32.\n",
      " 21/200 [==>...........................] - ETA: 3:01 - loss: 0.3160 - iou_score: 0.6700 - f1-score: 0.8002For batch 20, tr_loss is    0.32.\n",
      " 22/200 [==>...........................] - ETA: 2:57 - loss: 0.3148 - iou_score: 0.6711 - f1-score: 0.8010For batch 21, tr_loss is    0.31.\n",
      " 23/200 [==>...........................] - ETA: 2:57 - loss: 0.3136 - iou_score: 0.6724 - f1-score: 0.8020For batch 22, tr_loss is    0.31.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 24/200 [==>...........................] - ETA: 2:54 - loss: 0.3145 - iou_score: 0.6722 - f1-score: 0.8020For batch 23, tr_loss is    0.31.\n",
      " 25/200 [==>...........................] - ETA: 2:54 - loss: 0.3129 - iou_score: 0.6738 - f1-score: 0.8032For batch 24, tr_loss is    0.31.\n",
      " 26/200 [==>...........................] - ETA: 2:49 - loss: 0.3159 - iou_score: 0.6710 - f1-score: 0.8011For batch 25, tr_loss is    0.32.\n",
      " 27/200 [===>..........................] - ETA: 2:47 - loss: 0.3151 - iou_score: 0.6719 - f1-score: 0.8017For batch 26, tr_loss is    0.32.\n",
      " 28/200 [===>..........................] - ETA: 2:47 - loss: 0.3167 - iou_score: 0.6706 - f1-score: 0.8008For batch 27, tr_loss is    0.32.\n",
      " 29/200 [===>..........................] - ETA: 2:43 - loss: 0.3169 - iou_score: 0.6697 - f1-score: 0.8002For batch 28, tr_loss is    0.32.\n",
      " 30/200 [===>..........................] - ETA: 2:42 - loss: 0.3158 - iou_score: 0.6712 - f1-score: 0.8013For batch 29, tr_loss is    0.32.\n",
      " 31/200 [===>..........................] - ETA: 2:42 - loss: 0.3140 - iou_score: 0.6737 - f1-score: 0.8031For batch 30, tr_loss is    0.31.\n",
      " 32/200 [===>..........................] - ETA: 2:38 - loss: 0.3135 - iou_score: 0.6752 - f1-score: 0.8041For batch 31, tr_loss is    0.31.\n",
      " 33/200 [===>..........................] - ETA: 2:38 - loss: 0.3122 - iou_score: 0.6763 - f1-score: 0.8050For batch 32, tr_loss is    0.31.\n",
      " 34/200 [====>.........................] - ETA: 2:37 - loss: 0.3132 - iou_score: 0.6749 - f1-score: 0.8039For batch 33, tr_loss is    0.31.\n",
      " 35/200 [====>.........................] - ETA: 2:36 - loss: 0.3124 - iou_score: 0.6763 - f1-score: 0.8049For batch 34, tr_loss is    0.31.\n",
      " 36/200 [====>.........................] - ETA: 2:34 - loss: 0.3121 - iou_score: 0.6767 - f1-score: 0.8053For batch 35, tr_loss is    0.31.\n",
      " 37/200 [====>.........................] - ETA: 2:34 - loss: 0.3134 - iou_score: 0.6756 - f1-score: 0.8044For batch 36, tr_loss is    0.31.\n",
      " 38/200 [====>.........................] - ETA: 2:32 - loss: 0.3143 - iou_score: 0.6737 - f1-score: 0.8031For batch 37, tr_loss is    0.31.\n",
      " 39/200 [====>.........................] - ETA: 2:31 - loss: 0.3132 - iou_score: 0.6748 - f1-score: 0.8039For batch 38, tr_loss is    0.31.\n",
      " 40/200 [=====>........................] - ETA: 2:30 - loss: 0.3121 - iou_score: 0.6763 - f1-score: 0.8050For batch 39, tr_loss is    0.31.\n",
      " 41/200 [=====>........................] - ETA: 2:30 - loss: 0.3112 - iou_score: 0.6769 - f1-score: 0.8054For batch 40, tr_loss is    0.31.\n",
      " 42/200 [=====>........................] - ETA: 2:29 - loss: 0.3118 - iou_score: 0.6765 - f1-score: 0.8051For batch 41, tr_loss is    0.31.\n",
      " 43/200 [=====>........................] - ETA: 2:28 - loss: 0.3121 - iou_score: 0.6766 - f1-score: 0.8052For batch 42, tr_loss is    0.31.\n",
      " 44/200 [=====>........................] - ETA: 2:28 - loss: 0.3113 - iou_score: 0.6776 - f1-score: 0.8060For batch 43, tr_loss is    0.31.\n",
      " 45/200 [=====>........................] - ETA: 2:27 - loss: 0.3108 - iou_score: 0.6781 - f1-score: 0.8063For batch 44, tr_loss is    0.31.\n",
      " 46/200 [=====>........................] - ETA: 2:26 - loss: 0.3120 - iou_score: 0.6771 - f1-score: 0.8055For batch 45, tr_loss is    0.31.\n",
      " 47/200 [======>.......................] - ETA: 2:25 - loss: 0.3128 - iou_score: 0.6762 - f1-score: 0.8048For batch 46, tr_loss is    0.31.\n",
      " 48/200 [======>.......................] - ETA: 2:24 - loss: 0.3132 - iou_score: 0.6757 - f1-score: 0.8045For batch 47, tr_loss is    0.31.\n",
      " 49/200 [======>.......................] - ETA: 2:22 - loss: 0.3128 - iou_score: 0.6760 - f1-score: 0.8047For batch 48, tr_loss is    0.31.\n",
      " 50/200 [======>.......................] - ETA: 2:20 - loss: 0.3118 - iou_score: 0.6772 - f1-score: 0.8056For batch 49, tr_loss is    0.31.\n",
      " 51/200 [======>.......................] - ETA: 2:19 - loss: 0.3120 - iou_score: 0.6774 - f1-score: 0.8058For batch 50, tr_loss is    0.31.\n",
      " 52/200 [======>.......................] - ETA: 2:18 - loss: 0.3119 - iou_score: 0.6773 - f1-score: 0.8056For batch 51, tr_loss is    0.31.\n",
      " 53/200 [======>.......................] - ETA: 2:16 - loss: 0.3113 - iou_score: 0.6778 - f1-score: 0.8060For batch 52, tr_loss is    0.31.\n",
      " 54/200 [=======>......................] - ETA: 2:15 - loss: 0.3117 - iou_score: 0.6772 - f1-score: 0.8056For batch 53, tr_loss is    0.31.\n",
      " 55/200 [=======>......................] - ETA: 2:13 - loss: 0.3106 - iou_score: 0.6783 - f1-score: 0.8063For batch 54, tr_loss is    0.31.\n",
      " 56/200 [=======>......................] - ETA: 2:13 - loss: 0.3106 - iou_score: 0.6780 - f1-score: 0.8062For batch 55, tr_loss is    0.31.\n",
      " 57/200 [=======>......................] - ETA: 2:10 - loss: 0.3105 - iou_score: 0.6776 - f1-score: 0.8059For batch 56, tr_loss is    0.31.\n",
      " 58/200 [=======>......................] - ETA: 2:09 - loss: 0.3104 - iou_score: 0.6773 - f1-score: 0.8057For batch 57, tr_loss is    0.31.\n",
      " 59/200 [=======>......................] - ETA: 2:08 - loss: 0.3095 - iou_score: 0.6781 - f1-score: 0.8063For batch 58, tr_loss is    0.31.\n",
      " 60/200 [========>.....................] - ETA: 2:06 - loss: 0.3092 - iou_score: 0.6783 - f1-score: 0.8064For batch 59, tr_loss is    0.31.\n",
      " 61/200 [========>.....................] - ETA: 2:05 - loss: 0.3109 - iou_score: 0.6772 - f1-score: 0.8057For batch 60, tr_loss is    0.31.\n",
      " 62/200 [========>.....................] - ETA: 2:04 - loss: 0.3108 - iou_score: 0.6772 - f1-score: 0.8057For batch 61, tr_loss is    0.31.\n",
      " 63/200 [========>.....................] - ETA: 2:02 - loss: 0.3101 - iou_score: 0.6779 - f1-score: 0.8062For batch 62, tr_loss is    0.31.\n",
      " 64/200 [========>.....................] - ETA: 2:02 - loss: 0.3108 - iou_score: 0.6767 - f1-score: 0.8054For batch 63, tr_loss is    0.31.\n",
      " 65/200 [========>.....................] - ETA: 2:01 - loss: 0.3094 - iou_score: 0.6783 - f1-score: 0.8065For batch 64, tr_loss is    0.31.\n",
      " 66/200 [========>.....................] - ETA: 1:59 - loss: 0.3115 - iou_score: 0.6763 - f1-score: 0.8048For batch 65, tr_loss is    0.31.\n",
      " 67/200 [=========>....................] - ETA: 1:58 - loss: 0.3107 - iou_score: 0.6770 - f1-score: 0.8054For batch 66, tr_loss is    0.31.\n",
      " 68/200 [=========>....................] - ETA: 1:57 - loss: 0.3103 - iou_score: 0.6772 - f1-score: 0.8056For batch 67, tr_loss is    0.31.\n",
      " 69/200 [=========>....................] - ETA: 1:57 - loss: 0.3118 - iou_score: 0.6756 - f1-score: 0.8043For batch 68, tr_loss is    0.31.\n",
      " 70/200 [=========>....................] - ETA: 1:56 - loss: 0.3116 - iou_score: 0.6757 - f1-score: 0.8044For batch 69, tr_loss is    0.31.\n",
      " 71/200 [=========>....................] - ETA: 1:55 - loss: 0.3112 - iou_score: 0.6761 - f1-score: 0.8047For batch 70, tr_loss is    0.31.\n",
      " 72/200 [=========>....................] - ETA: 1:54 - loss: 0.3111 - iou_score: 0.6761 - f1-score: 0.8047For batch 71, tr_loss is    0.31.\n",
      " 73/200 [=========>....................] - ETA: 1:53 - loss: 0.3107 - iou_score: 0.6765 - f1-score: 0.8050For batch 72, tr_loss is    0.31.\n",
      " 74/200 [==========>...................] - ETA: 1:53 - loss: 0.3110 - iou_score: 0.6761 - f1-score: 0.8047For batch 73, tr_loss is    0.31.\n",
      " 75/200 [==========>...................] - ETA: 1:51 - loss: 0.3118 - iou_score: 0.6752 - f1-score: 0.8040For batch 74, tr_loss is    0.31.\n",
      " 76/200 [==========>...................] - ETA: 1:51 - loss: 0.3118 - iou_score: 0.6749 - f1-score: 0.8039For batch 75, tr_loss is    0.31.\n",
      " 77/200 [==========>...................] - ETA: 1:50 - loss: 0.3117 - iou_score: 0.6749 - f1-score: 0.8039For batch 76, tr_loss is    0.31.\n",
      " 78/200 [==========>...................] - ETA: 1:49 - loss: 0.3112 - iou_score: 0.6753 - f1-score: 0.8042For batch 77, tr_loss is    0.31.\n",
      " 79/200 [==========>...................] - ETA: 1:48 - loss: 0.3114 - iou_score: 0.6752 - f1-score: 0.8041For batch 78, tr_loss is    0.31.\n",
      " 80/200 [===========>..................] - ETA: 1:48 - loss: 0.3110 - iou_score: 0.6756 - f1-score: 0.8044For batch 79, tr_loss is    0.31.\n",
      " 81/200 [===========>..................] - ETA: 1:47 - loss: 0.3102 - iou_score: 0.6767 - f1-score: 0.8052For batch 80, tr_loss is    0.31.\n",
      " 82/200 [===========>..................] - ETA: 1:45 - loss: 0.3099 - iou_score: 0.6771 - f1-score: 0.8055For batch 81, tr_loss is    0.31.\n",
      " 83/200 [===========>..................] - ETA: 1:45 - loss: 0.3101 - iou_score: 0.6769 - f1-score: 0.8053For batch 82, tr_loss is    0.31.\n",
      " 84/200 [===========>..................] - ETA: 1:44 - loss: 0.3098 - iou_score: 0.6770 - f1-score: 0.8054For batch 83, tr_loss is    0.31.\n",
      " 85/200 [===========>..................] - ETA: 1:43 - loss: 0.3105 - iou_score: 0.6759 - f1-score: 0.8046For batch 84, tr_loss is    0.31.\n",
      " 86/200 [===========>..................] - ETA: 1:41 - loss: 0.3109 - iou_score: 0.6753 - f1-score: 0.8042For batch 85, tr_loss is    0.31.\n",
      " 87/200 [============>.................] - ETA: 1:41 - loss: 0.3102 - iou_score: 0.6761 - f1-score: 0.8047For batch 86, tr_loss is    0.31.\n",
      " 88/200 [============>.................] - ETA: 1:40 - loss: 0.3099 - iou_score: 0.6765 - f1-score: 0.8051For batch 87, tr_loss is    0.31.\n",
      " 89/200 [============>.................] - ETA: 1:39 - loss: 0.3103 - iou_score: 0.6761 - f1-score: 0.8048For batch 88, tr_loss is    0.31.\n",
      " 90/200 [============>.................] - ETA: 1:38 - loss: 0.3104 - iou_score: 0.6757 - f1-score: 0.8045For batch 89, tr_loss is    0.31.\n",
      " 91/200 [============>.................] - ETA: 1:38 - loss: 0.3103 - iou_score: 0.6757 - f1-score: 0.8045For batch 90, tr_loss is    0.31.\n",
      " 92/200 [============>.................] - ETA: 1:37 - loss: 0.3111 - iou_score: 0.6751 - f1-score: 0.8040For batch 91, tr_loss is    0.31.\n",
      " 93/200 [============>.................] - ETA: 1:36 - loss: 0.3115 - iou_score: 0.6749 - f1-score: 0.8039For batch 92, tr_loss is    0.31.\n",
      " 94/200 [=============>................] - ETA: 1:35 - loss: 0.3126 - iou_score: 0.6731 - f1-score: 0.8026For batch 93, tr_loss is    0.31.\n",
      " 95/200 [=============>................] - ETA: 1:34 - loss: 0.3137 - iou_score: 0.6724 - f1-score: 0.8020For batch 94, tr_loss is    0.31.\n",
      " 96/200 [=============>................] - ETA: 1:33 - loss: 0.3134 - iou_score: 0.6728 - f1-score: 0.8024For batch 95, tr_loss is    0.31.\n",
      " 97/200 [=============>................] - ETA: 1:32 - loss: 0.3139 - iou_score: 0.6720 - f1-score: 0.8017For batch 96, tr_loss is    0.31.\n",
      " 98/200 [=============>................] - ETA: 1:31 - loss: 0.3141 - iou_score: 0.6719 - f1-score: 0.8017For batch 97, tr_loss is    0.31.\n",
      " 99/200 [=============>................] - ETA: 1:30 - loss: 0.3138 - iou_score: 0.6723 - f1-score: 0.8020For batch 98, tr_loss is    0.31.\n",
      "100/200 [==============>...............] - ETA: 1:29 - loss: 0.3140 - iou_score: 0.6723 - f1-score: 0.8020For batch 99, tr_loss is    0.31.\n",
      "101/200 [==============>...............] - ETA: 1:29 - loss: 0.3141 - iou_score: 0.6722 - f1-score: 0.8020For batch 100, tr_loss is    0.31.\n",
      "102/200 [==============>...............] - ETA: 1:28 - loss: 0.3144 - iou_score: 0.6717 - f1-score: 0.8016For batch 101, tr_loss is    0.31.\n",
      "103/200 [==============>...............] - ETA: 1:27 - loss: 0.3147 - iou_score: 0.6713 - f1-score: 0.8013For batch 102, tr_loss is    0.31.\n",
      "104/200 [==============>...............] - ETA: 1:26 - loss: 0.3151 - iou_score: 0.6706 - f1-score: 0.8008For batch 103, tr_loss is    0.32.\n",
      "105/200 [==============>...............] - ETA: 1:25 - loss: 0.3154 - iou_score: 0.6703 - f1-score: 0.8006For batch 104, tr_loss is    0.32.\n",
      "106/200 [==============>...............] - ETA: 1:24 - loss: 0.3156 - iou_score: 0.6702 - f1-score: 0.8005For batch 105, tr_loss is    0.32.\n",
      "107/200 [===============>..............] - ETA: 1:23 - loss: 0.3159 - iou_score: 0.6698 - f1-score: 0.8002For batch 106, tr_loss is    0.32.\n",
      "108/200 [===============>..............] - ETA: 1:22 - loss: 0.3157 - iou_score: 0.6700 - f1-score: 0.8004For batch 107, tr_loss is    0.32.\n",
      "109/200 [===============>..............] - ETA: 1:22 - loss: 0.3159 - iou_score: 0.6699 - f1-score: 0.8003For batch 108, tr_loss is    0.32.\n",
      "110/200 [===============>..............] - ETA: 1:21 - loss: 0.3158 - iou_score: 0.6701 - f1-score: 0.8005For batch 109, tr_loss is    0.32.\n",
      "111/200 [===============>..............] - ETA: 1:20 - loss: 0.3152 - iou_score: 0.6708 - f1-score: 0.8009For batch 110, tr_loss is    0.32.\n",
      "112/200 [===============>..............] - ETA: 1:19 - loss: 0.3153 - iou_score: 0.6706 - f1-score: 0.8008For batch 111, tr_loss is    0.32.\n",
      "113/200 [===============>..............] - ETA: 1:18 - loss: 0.3163 - iou_score: 0.6694 - f1-score: 0.7998For batch 112, tr_loss is    0.32.\n",
      "114/200 [================>.............] - ETA: 1:17 - loss: 0.3168 - iou_score: 0.6688 - f1-score: 0.7994For batch 113, tr_loss is    0.32.\n",
      "115/200 [================>.............] - ETA: 1:16 - loss: 0.3167 - iou_score: 0.6690 - f1-score: 0.7995For batch 114, tr_loss is    0.32.\n",
      "116/200 [================>.............] - ETA: 1:15 - loss: 0.3170 - iou_score: 0.6685 - f1-score: 0.7992For batch 115, tr_loss is    0.32.\n",
      "117/200 [================>.............] - ETA: 1:14 - loss: 0.3169 - iou_score: 0.6686 - f1-score: 0.7992For batch 116, tr_loss is    0.32.\n",
      "118/200 [================>.............] - ETA: 1:13 - loss: 0.3168 - iou_score: 0.6687 - f1-score: 0.7993For batch 117, tr_loss is    0.32.\n",
      "119/200 [================>.............] - ETA: 1:12 - loss: 0.3171 - iou_score: 0.6683 - f1-score: 0.7990For batch 118, tr_loss is    0.32.\n",
      "120/200 [=================>............] - ETA: 1:11 - loss: 0.3167 - iou_score: 0.6688 - f1-score: 0.7994For batch 119, tr_loss is    0.32.\n",
      "121/200 [=================>............] - ETA: 1:10 - loss: 0.3164 - iou_score: 0.6692 - f1-score: 0.7997For batch 120, tr_loss is    0.32.\n",
      "122/200 [=================>............] - ETA: 1:09 - loss: 0.3161 - iou_score: 0.6694 - f1-score: 0.7998For batch 121, tr_loss is    0.32.\n",
      "123/200 [=================>............] - ETA: 1:08 - loss: 0.3168 - iou_score: 0.6684 - f1-score: 0.7991For batch 122, tr_loss is    0.32.\n",
      "124/200 [=================>............] - ETA: 1:07 - loss: 0.3171 - iou_score: 0.6681 - f1-score: 0.7989For batch 123, tr_loss is    0.32.\n",
      "125/200 [=================>............] - ETA: 1:07 - loss: 0.3172 - iou_score: 0.6680 - f1-score: 0.7988For batch 124, tr_loss is    0.32.\n",
      "126/200 [=================>............] - ETA: 1:06 - loss: 0.3171 - iou_score: 0.6682 - f1-score: 0.7989For batch 125, tr_loss is    0.32.\n",
      "127/200 [==================>...........] - ETA: 1:05 - loss: 0.3170 - iou_score: 0.6683 - f1-score: 0.7990For batch 126, tr_loss is    0.32.\n",
      "128/200 [==================>...........] - ETA: 1:04 - loss: 0.3178 - iou_score: 0.6672 - f1-score: 0.7982For batch 127, tr_loss is    0.32.\n",
      "129/200 [==================>...........] - ETA: 1:03 - loss: 0.3179 - iou_score: 0.6670 - f1-score: 0.7981For batch 128, tr_loss is    0.32.\n",
      "130/200 [==================>...........] - ETA: 1:02 - loss: 0.3177 - iou_score: 0.6673 - f1-score: 0.7983For batch 129, tr_loss is    0.32.\n",
      "131/200 [==================>...........] - ETA: 1:01 - loss: 0.3173 - iou_score: 0.6677 - f1-score: 0.7985For batch 130, tr_loss is    0.32.\n",
      "132/200 [==================>...........] - ETA: 1:00 - loss: 0.3169 - iou_score: 0.6682 - f1-score: 0.7989For batch 131, tr_loss is    0.32.\n",
      "133/200 [==================>...........] - ETA: 59s - loss: 0.3172 - iou_score: 0.6681 - f1-score: 0.7989 For batch 132, tr_loss is    0.32.\n",
      "134/200 [===================>..........] - ETA: 58s - loss: 0.3175 - iou_score: 0.6676 - f1-score: 0.7985For batch 133, tr_loss is    0.32.\n",
      "135/200 [===================>..........] - ETA: 57s - loss: 0.3178 - iou_score: 0.6674 - f1-score: 0.7983For batch 134, tr_loss is    0.32.\n",
      "136/200 [===================>..........] - ETA: 56s - loss: 0.3177 - iou_score: 0.6674 - f1-score: 0.7983For batch 135, tr_loss is    0.32.\n",
      "137/200 [===================>..........] - ETA: 55s - loss: 0.3187 - iou_score: 0.6664 - f1-score: 0.7976For batch 136, tr_loss is    0.32.\n",
      "138/200 [===================>..........] - ETA: 55s - loss: 0.3189 - iou_score: 0.6662 - f1-score: 0.7975For batch 137, tr_loss is    0.32.\n",
      "139/200 [===================>..........] - ETA: 54s - loss: 0.3185 - iou_score: 0.6666 - f1-score: 0.7978For batch 138, tr_loss is    0.32.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/200 [====================>.........] - ETA: 53s - loss: 0.3197 - iou_score: 0.6654 - f1-score: 0.7967For batch 139, tr_loss is    0.32.\n",
      "141/200 [====================>.........] - ETA: 52s - loss: 0.3201 - iou_score: 0.6650 - f1-score: 0.7964For batch 140, tr_loss is    0.32.\n",
      "142/200 [====================>.........] - ETA: 51s - loss: 0.3198 - iou_score: 0.6655 - f1-score: 0.7968For batch 141, tr_loss is    0.32.\n",
      "143/200 [====================>.........] - ETA: 50s - loss: 0.3196 - iou_score: 0.6656 - f1-score: 0.7968For batch 142, tr_loss is    0.32.\n",
      "144/200 [====================>.........] - ETA: 49s - loss: 0.3196 - iou_score: 0.6656 - f1-score: 0.7968For batch 143, tr_loss is    0.32.\n",
      "145/200 [====================>.........] - ETA: 48s - loss: 0.3197 - iou_score: 0.6653 - f1-score: 0.7967For batch 144, tr_loss is    0.32.\n",
      "146/200 [====================>.........] - ETA: 47s - loss: 0.3193 - iou_score: 0.6662 - f1-score: 0.7972For batch 145, tr_loss is    0.32.\n",
      "147/200 [=====================>........] - ETA: 46s - loss: 0.3194 - iou_score: 0.6659 - f1-score: 0.7970For batch 146, tr_loss is    0.32.\n",
      "148/200 [=====================>........] - ETA: 45s - loss: 0.3188 - iou_score: 0.6669 - f1-score: 0.7977For batch 147, tr_loss is    0.32.\n",
      "149/200 [=====================>........] - ETA: 45s - loss: 0.3185 - iou_score: 0.6671 - f1-score: 0.7978For batch 148, tr_loss is    0.32.\n",
      "150/200 [=====================>........] - ETA: 44s - loss: 0.3180 - iou_score: 0.6677 - f1-score: 0.7983For batch 149, tr_loss is    0.32.\n",
      "151/200 [=====================>........] - ETA: 43s - loss: 0.3184 - iou_score: 0.6676 - f1-score: 0.7981For batch 150, tr_loss is    0.32.\n",
      "152/200 [=====================>........] - ETA: 42s - loss: 0.3182 - iou_score: 0.6679 - f1-score: 0.7984For batch 151, tr_loss is    0.32.\n",
      "153/200 [=====================>........] - ETA: 41s - loss: 0.3180 - iou_score: 0.6680 - f1-score: 0.7985For batch 152, tr_loss is    0.32.\n",
      "154/200 [======================>.......] - ETA: 40s - loss: 0.3181 - iou_score: 0.6680 - f1-score: 0.7985For batch 153, tr_loss is    0.32.\n",
      "155/200 [======================>.......] - ETA: 39s - loss: 0.3179 - iou_score: 0.6682 - f1-score: 0.7986For batch 154, tr_loss is    0.32.\n",
      "156/200 [======================>.......] - ETA: 38s - loss: 0.3177 - iou_score: 0.6685 - f1-score: 0.7988For batch 155, tr_loss is    0.32.\n",
      "157/200 [======================>.......] - ETA: 37s - loss: 0.3178 - iou_score: 0.6683 - f1-score: 0.7987For batch 156, tr_loss is    0.32.\n",
      "158/200 [======================>.......] - ETA: 37s - loss: 0.3179 - iou_score: 0.6682 - f1-score: 0.7987For batch 157, tr_loss is    0.32.\n",
      "159/200 [======================>.......] - ETA: 36s - loss: 0.3181 - iou_score: 0.6679 - f1-score: 0.7984For batch 158, tr_loss is    0.32.\n",
      "160/200 [=======================>......] - ETA: 35s - loss: 0.3180 - iou_score: 0.6679 - f1-score: 0.7985For batch 159, tr_loss is    0.32.\n",
      "161/200 [=======================>......] - ETA: 34s - loss: 0.3181 - iou_score: 0.6677 - f1-score: 0.7983For batch 160, tr_loss is    0.32.\n",
      "162/200 [=======================>......] - ETA: 33s - loss: 0.3181 - iou_score: 0.6674 - f1-score: 0.7982For batch 161, tr_loss is    0.32.\n",
      "163/200 [=======================>......] - ETA: 32s - loss: 0.3177 - iou_score: 0.6680 - f1-score: 0.7985For batch 162, tr_loss is    0.32.\n",
      "164/200 [=======================>......] - ETA: 31s - loss: 0.3178 - iou_score: 0.6679 - f1-score: 0.7985For batch 163, tr_loss is    0.32.\n",
      "165/200 [=======================>......] - ETA: 30s - loss: 0.3174 - iou_score: 0.6684 - f1-score: 0.7988For batch 164, tr_loss is    0.32.\n",
      "166/200 [=======================>......] - ETA: 29s - loss: 0.3176 - iou_score: 0.6683 - f1-score: 0.7988For batch 165, tr_loss is    0.32.\n",
      "167/200 [========================>.....] - ETA: 29s - loss: 0.3170 - iou_score: 0.6692 - f1-score: 0.7993For batch 166, tr_loss is    0.32.\n",
      "168/200 [========================>.....] - ETA: 28s - loss: 0.3173 - iou_score: 0.6688 - f1-score: 0.7991For batch 167, tr_loss is    0.32.\n",
      "169/200 [========================>.....] - ETA: 27s - loss: 0.3173 - iou_score: 0.6686 - f1-score: 0.7990For batch 168, tr_loss is    0.32.\n",
      "170/200 [========================>.....] - ETA: 26s - loss: 0.3169 - iou_score: 0.6691 - f1-score: 0.7993For batch 169, tr_loss is    0.32.\n",
      "171/200 [========================>.....] - ETA: 25s - loss: 0.3169 - iou_score: 0.6690 - f1-score: 0.7992For batch 170, tr_loss is    0.32.\n",
      "172/200 [========================>.....] - ETA: 24s - loss: 0.3165 - iou_score: 0.6694 - f1-score: 0.7995For batch 171, tr_loss is    0.32.\n",
      "173/200 [========================>.....] - ETA: 23s - loss: 0.3165 - iou_score: 0.6694 - f1-score: 0.7995For batch 172, tr_loss is    0.32.\n",
      "174/200 [=========================>....] - ETA: 22s - loss: 0.3163 - iou_score: 0.6698 - f1-score: 0.7998For batch 173, tr_loss is    0.32.\n",
      "175/200 [=========================>....] - ETA: 22s - loss: 0.3159 - iou_score: 0.6701 - f1-score: 0.8000For batch 174, tr_loss is    0.32.\n",
      "176/200 [=========================>....] - ETA: 21s - loss: 0.3162 - iou_score: 0.6698 - f1-score: 0.7998For batch 175, tr_loss is    0.32.\n",
      "177/200 [=========================>....] - ETA: 20s - loss: 0.3159 - iou_score: 0.6702 - f1-score: 0.8001For batch 176, tr_loss is    0.32.\n",
      "178/200 [=========================>....] - ETA: 19s - loss: 0.3163 - iou_score: 0.6696 - f1-score: 0.7996For batch 177, tr_loss is    0.32.\n",
      "179/200 [=========================>....] - ETA: 18s - loss: 0.3159 - iou_score: 0.6700 - f1-score: 0.7999For batch 178, tr_loss is    0.32.\n",
      "180/200 [==========================>...] - ETA: 17s - loss: 0.3161 - iou_score: 0.6698 - f1-score: 0.7998For batch 179, tr_loss is    0.32.\n",
      "181/200 [==========================>...] - ETA: 16s - loss: 0.3161 - iou_score: 0.6696 - f1-score: 0.7997For batch 180, tr_loss is    0.32.\n",
      "182/200 [==========================>...] - ETA: 15s - loss: 0.3162 - iou_score: 0.6696 - f1-score: 0.7996For batch 181, tr_loss is    0.32.\n",
      "183/200 [==========================>...] - ETA: 15s - loss: 0.3161 - iou_score: 0.6695 - f1-score: 0.7996For batch 182, tr_loss is    0.32.\n",
      "184/200 [==========================>...] - ETA: 14s - loss: 0.3160 - iou_score: 0.6697 - f1-score: 0.7997For batch 183, tr_loss is    0.32.\n",
      "185/200 [==========================>...] - ETA: 13s - loss: 0.3159 - iou_score: 0.6697 - f1-score: 0.7998For batch 184, tr_loss is    0.32.\n",
      "186/200 [==========================>...] - ETA: 12s - loss: 0.3157 - iou_score: 0.6700 - f1-score: 0.7999For batch 185, tr_loss is    0.32.\n",
      "187/200 [===========================>..] - ETA: 11s - loss: 0.3155 - iou_score: 0.6703 - f1-score: 0.8002For batch 186, tr_loss is    0.32.\n",
      "188/200 [===========================>..] - ETA: 10s - loss: 0.3153 - iou_score: 0.6705 - f1-score: 0.8003For batch 187, tr_loss is    0.32.\n",
      "189/200 [===========================>..] - ETA: 9s - loss: 0.3156 - iou_score: 0.6702 - f1-score: 0.8001 For batch 188, tr_loss is    0.32.\n",
      "190/200 [===========================>..] - ETA: 8s - loss: 0.3156 - iou_score: 0.6703 - f1-score: 0.8002For batch 189, tr_loss is    0.32.\n",
      "191/200 [===========================>..] - ETA: 7s - loss: 0.3161 - iou_score: 0.6698 - f1-score: 0.7998For batch 190, tr_loss is    0.32.\n",
      "192/200 [===========================>..] - ETA: 7s - loss: 0.3165 - iou_score: 0.6694 - f1-score: 0.7995For batch 191, tr_loss is    0.32.\n",
      "193/200 [===========================>..] - ETA: 6s - loss: 0.3162 - iou_score: 0.6697 - f1-score: 0.7997For batch 192, tr_loss is    0.32.\n",
      "194/200 [============================>.] - ETA: 5s - loss: 0.3164 - iou_score: 0.6694 - f1-score: 0.7995For batch 193, tr_loss is    0.32.\n",
      "195/200 [============================>.] - ETA: 4s - loss: 0.3164 - iou_score: 0.6693 - f1-score: 0.7994For batch 194, tr_loss is    0.32.\n",
      "196/200 [============================>.] - ETA: 3s - loss: 0.3167 - iou_score: 0.6690 - f1-score: 0.7992For batch 195, tr_loss is    0.32.\n",
      "197/200 [============================>.] - ETA: 2s - loss: 0.3163 - iou_score: 0.6696 - f1-score: 0.7996For batch 196, tr_loss is    0.32.\n",
      "198/200 [============================>.] - ETA: 1s - loss: 0.3162 - iou_score: 0.6697 - f1-score: 0.7997For batch 197, tr_loss is    0.32.\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.3165 - iou_score: 0.6694 - f1-score: 0.7994For batch 198, tr_loss is    0.32.\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.3163 - iou_score: 0.6694 - f1-score: 0.7995For batch 199, tr_loss is    0.32.\n",
      "For batch 0, vl_loss is    0.34.\n",
      "For batch 1, vl_loss is    0.34.\n",
      "For batch 2, vl_loss is    0.33.\n",
      "For batch 3, vl_loss is    0.33.\n",
      "For batch 4, vl_loss is    0.32.\n",
      "For batch 5, vl_loss is    0.32.\n",
      "For batch 6, vl_loss is    0.32.\n",
      "For batch 7, vl_loss is    0.32.\n",
      "For batch 8, vl_loss is    0.33.\n",
      "For batch 9, vl_loss is    0.33.\n",
      "For batch 10, vl_loss is    0.34.\n",
      "For batch 11, vl_loss is    0.33.\n",
      "For batch 12, vl_loss is    0.33.\n",
      "For batch 13, vl_loss is    0.33.\n",
      "For batch 14, vl_loss is    0.33.\n",
      "For batch 15, vl_loss is    0.33.\n",
      "For batch 16, vl_loss is    0.32.\n",
      "For batch 17, vl_loss is    0.33.\n",
      "For batch 18, vl_loss is    0.32.\n",
      "For batch 19, vl_loss is    0.32.\n",
      "For batch 20, vl_loss is    0.32.\n",
      "For batch 21, vl_loss is    0.32.\n",
      "For batch 22, vl_loss is    0.32.\n",
      "For batch 23, vl_loss is    0.33.\n",
      "For batch 24, vl_loss is    0.33.\n",
      "For batch 25, vl_loss is    0.33.\n",
      "For batch 26, vl_loss is    0.33.\n",
      "For batch 27, vl_loss is    0.33.\n",
      "For batch 28, vl_loss is    0.33.\n",
      "For batch 29, vl_loss is    0.33.\n",
      "For batch 30, vl_loss is    0.33.\n",
      "For batch 31, vl_loss is    0.33.\n",
      "For batch 32, vl_loss is    0.33.\n",
      "For batch 33, vl_loss is    0.33.\n",
      "For batch 34, vl_loss is    0.33.\n",
      "For batch 35, vl_loss is    0.33.\n",
      "For batch 36, vl_loss is    0.33.\n",
      "For batch 37, vl_loss is    0.33.\n",
      "For batch 38, vl_loss is    0.33.\n",
      "For batch 39, vl_loss is    0.33.\n",
      "For batch 40, vl_loss is    0.33.\n",
      "For batch 41, vl_loss is    0.33.\n",
      "For batch 42, vl_loss is    0.33.\n",
      "For batch 43, vl_loss is    0.33.\n",
      "For batch 44, vl_loss is    0.33.\n",
      "For batch 45, vl_loss is    0.33.\n",
      "For batch 46, vl_loss is    0.33.\n",
      "For batch 47, vl_loss is    0.33.\n",
      "For batch 48, vl_loss is    0.33.\n",
      "For batch 49, vl_loss is    0.33.\n",
      "For batch 50, vl_loss is    0.33.\n",
      "For batch 51, vl_loss is    0.33.\n",
      "For batch 52, vl_loss is    0.33.\n",
      "For batch 53, vl_loss is    0.33.\n",
      "For batch 54, vl_loss is    0.33.\n",
      "For batch 55, vl_loss is    0.33.\n",
      "For batch 56, vl_loss is    0.33.\n",
      "For batch 57, vl_loss is    0.33.\n",
      "For batch 58, vl_loss is    0.33.\n",
      "For batch 59, vl_loss is    0.33.\n",
      "For batch 60, vl_loss is    0.33.\n",
      "For batch 61, vl_loss is    0.33.\n",
      "For batch 62, vl_loss is    0.33.\n",
      "For batch 63, vl_loss is    0.33.\n",
      "For batch 64, vl_loss is    0.33.\n",
      "For batch 65, vl_loss is    0.33.\n",
      "For batch 66, vl_loss is    0.33.\n",
      "For batch 67, vl_loss is    0.33.\n",
      "For batch 68, vl_loss is    0.33.\n",
      "For batch 69, vl_loss is    0.33.\n",
      "For batch 70, vl_loss is    0.33.\n",
      "For batch 71, vl_loss is    0.33.\n",
      "For batch 72, vl_loss is    0.33.\n",
      "For batch 73, vl_loss is    0.33.\n",
      "For batch 74, vl_loss is    0.33.\n",
      "For batch 75, vl_loss is    0.33.\n",
      "For batch 76, vl_loss is    0.33.\n",
      "For batch 77, vl_loss is    0.33.\n",
      "For batch 78, vl_loss is    0.33.\n",
      "For batch 79, vl_loss is    0.33.\n",
      "For batch 80, vl_loss is    0.33.\n",
      "For batch 81, vl_loss is    0.33.\n",
      "For batch 82, vl_loss is    0.33.\n",
      "For batch 83, vl_loss is    0.33.\n",
      "For batch 84, vl_loss is    0.33.\n",
      "For batch 85, vl_loss is    0.33.\n",
      "For batch 86, vl_loss is    0.33.\n",
      "For batch 87, vl_loss is    0.33.\n",
      "For batch 88, vl_loss is    0.33.\n",
      "For batch 89, vl_loss is    0.33.\n",
      "For batch 90, vl_loss is    0.33.\n",
      "For batch 91, vl_loss is    0.33.\n",
      "For batch 92, vl_loss is    0.33.\n",
      "For batch 93, vl_loss is    0.33.\n",
      "For batch 94, vl_loss is    0.33.\n",
      "For batch 95, vl_loss is    0.33.\n",
      "For batch 96, vl_loss is    0.33.\n",
      "For batch 97, vl_loss is    0.33.\n",
      "For batch 98, vl_loss is    0.33.\n",
      "For batch 99, vl_loss is    0.33.\n",
      "200/200 [==============================] - 182s 903ms/step - loss: 0.3163 - iou_score: 0.6694 - f1-score: 0.7995 - val_loss: 0.3340 - val_iou_score: 0.6925 - val_f1-score: 0.8162\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.33218\n",
      "The average loss for epoch 5 is    0.32 \n",
      "Epoch 7/200\n",
      "  1/200 [..............................] - ETA: 7:24 - loss: 0.2989 - iou_score: 0.6853 - f1-score: 0.8127For batch 0, tr_loss is    0.30.\n",
      "  2/200 [..............................] - ETA: 3:51 - loss: 0.2983 - iou_score: 0.6891 - f1-score: 0.8154For batch 1, tr_loss is    0.30.\n",
      "  3/200 [..............................] - ETA: 4:34 - loss: 0.2979 - iou_score: 0.6923 - f1-score: 0.8176For batch 2, tr_loss is    0.30.\n",
      "  4/200 [..............................] - ETA: 4:15 - loss: 0.3023 - iou_score: 0.6818 - f1-score: 0.8101For batch 3, tr_loss is    0.30.\n",
      "  5/200 [..............................] - ETA: 4:14 - loss: 0.3048 - iou_score: 0.6796 - f1-score: 0.8086For batch 4, tr_loss is    0.30.\n",
      "  6/200 [..............................] - ETA: 4:12 - loss: 0.3147 - iou_score: 0.6693 - f1-score: 0.8010For batch 5, tr_loss is    0.31.\n",
      "  7/200 [>.............................] - ETA: 4:01 - loss: 0.3189 - iou_score: 0.6617 - f1-score: 0.7951For batch 6, tr_loss is    0.32.\n",
      "  8/200 [>.............................] - ETA: 3:49 - loss: 0.3189 - iou_score: 0.6619 - f1-score: 0.7951For batch 7, tr_loss is    0.32.\n",
      "  9/200 [>.............................] - ETA: 3:56 - loss: 0.3170 - iou_score: 0.6661 - f1-score: 0.7982For batch 8, tr_loss is    0.32.\n",
      " 10/200 [>.............................] - ETA: 3:55 - loss: 0.3173 - iou_score: 0.6653 - f1-score: 0.7971For batch 9, tr_loss is    0.32.\n",
      " 11/200 [>.............................] - ETA: 3:51 - loss: 0.3144 - iou_score: 0.6677 - f1-score: 0.7989For batch 10, tr_loss is    0.31.\n",
      " 12/200 [>.............................] - ETA: 3:39 - loss: 0.3171 - iou_score: 0.6629 - f1-score: 0.7954For batch 11, tr_loss is    0.32.\n",
      " 13/200 [>.............................] - ETA: 3:36 - loss: 0.3187 - iou_score: 0.6607 - f1-score: 0.7939For batch 12, tr_loss is    0.32.\n",
      " 14/200 [=>............................] - ETA: 3:32 - loss: 0.3175 - iou_score: 0.6614 - f1-score: 0.7945For batch 13, tr_loss is    0.32.\n",
      " 15/200 [=>............................] - ETA: 3:22 - loss: 0.3156 - iou_score: 0.6628 - f1-score: 0.7955For batch 14, tr_loss is    0.32.\n",
      " 16/200 [=>............................] - ETA: 3:22 - loss: 0.3152 - iou_score: 0.6621 - f1-score: 0.7952For batch 15, tr_loss is    0.32.\n",
      " 17/200 [=>............................] - ETA: 3:20 - loss: 0.3135 - iou_score: 0.6642 - f1-score: 0.7967For batch 16, tr_loss is    0.31.\n",
      " 18/200 [=>............................] - ETA: 3:18 - loss: 0.3110 - iou_score: 0.6671 - f1-score: 0.7988For batch 17, tr_loss is    0.31.\n",
      " 19/200 [=>............................] - ETA: 3:11 - loss: 0.3145 - iou_score: 0.6634 - f1-score: 0.7959For batch 18, tr_loss is    0.31.\n",
      " 20/200 [==>...........................] - ETA: 3:10 - loss: 0.3110 - iou_score: 0.6682 - f1-score: 0.7993For batch 19, tr_loss is    0.31.\n",
      " 21/200 [==>...........................] - ETA: 3:08 - loss: 0.3098 - iou_score: 0.6702 - f1-score: 0.8007For batch 20, tr_loss is    0.31.\n",
      " 22/200 [==>...........................] - ETA: 3:07 - loss: 0.3085 - iou_score: 0.6720 - f1-score: 0.8020For batch 21, tr_loss is    0.31.\n",
      " 23/200 [==>...........................] - ETA: 3:03 - loss: 0.3077 - iou_score: 0.6727 - f1-score: 0.8026For batch 22, tr_loss is    0.31.\n",
      " 24/200 [==>...........................] - ETA: 2:58 - loss: 0.3068 - iou_score: 0.6741 - f1-score: 0.8037For batch 23, tr_loss is    0.31.\n",
      " 25/200 [==>...........................] - ETA: 2:57 - loss: 0.3063 - iou_score: 0.6747 - f1-score: 0.8042For batch 24, tr_loss is    0.31.\n",
      " 26/200 [==>...........................] - ETA: 2:52 - loss: 0.3082 - iou_score: 0.6728 - f1-score: 0.8028For batch 25, tr_loss is    0.31.\n",
      " 27/200 [===>..........................] - ETA: 2:52 - loss: 0.3071 - iou_score: 0.6741 - f1-score: 0.8037For batch 26, tr_loss is    0.31.\n",
      " 28/200 [===>..........................] - ETA: 2:52 - loss: 0.3075 - iou_score: 0.6738 - f1-score: 0.8035For batch 27, tr_loss is    0.31.\n",
      " 29/200 [===>..........................] - ETA: 2:50 - loss: 0.3079 - iou_score: 0.6730 - f1-score: 0.8030For batch 28, tr_loss is    0.31.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30/200 [===>..........................] - ETA: 2:49 - loss: 0.3069 - iou_score: 0.6746 - f1-score: 0.8041For batch 29, tr_loss is    0.31.\n",
      " 31/200 [===>..........................] - ETA: 2:45 - loss: 0.3046 - iou_score: 0.6772 - f1-score: 0.8059For batch 30, tr_loss is    0.30.\n",
      " 32/200 [===>..........................] - ETA: 2:43 - loss: 0.3044 - iou_score: 0.6787 - f1-score: 0.8070For batch 31, tr_loss is    0.30.\n",
      " 33/200 [===>..........................] - ETA: 2:41 - loss: 0.3031 - iou_score: 0.6798 - f1-score: 0.8078For batch 32, tr_loss is    0.30.\n",
      " 34/200 [====>.........................] - ETA: 2:41 - loss: 0.3038 - iou_score: 0.6788 - f1-score: 0.8071For batch 33, tr_loss is    0.30.\n",
      " 35/200 [====>.........................] - ETA: 2:39 - loss: 0.3034 - iou_score: 0.6796 - f1-score: 0.8078For batch 34, tr_loss is    0.30.\n",
      " 36/200 [====>.........................] - ETA: 2:38 - loss: 0.3037 - iou_score: 0.6802 - f1-score: 0.8082For batch 35, tr_loss is    0.30.\n",
      " 37/200 [====>.........................] - ETA: 2:35 - loss: 0.3049 - iou_score: 0.6792 - f1-score: 0.8074For batch 36, tr_loss is    0.30.\n",
      " 38/200 [====>.........................] - ETA: 2:34 - loss: 0.3052 - iou_score: 0.6778 - f1-score: 0.8064For batch 37, tr_loss is    0.31.\n",
      " 39/200 [====>.........................] - ETA: 2:33 - loss: 0.3047 - iou_score: 0.6784 - f1-score: 0.8068For batch 38, tr_loss is    0.30.\n",
      " 40/200 [=====>........................] - ETA: 2:32 - loss: 0.3035 - iou_score: 0.6798 - f1-score: 0.8079For batch 39, tr_loss is    0.30.\n",
      " 41/200 [=====>........................] - ETA: 2:32 - loss: 0.3028 - iou_score: 0.6805 - f1-score: 0.8084For batch 40, tr_loss is    0.30.\n",
      " 42/200 [=====>........................] - ETA: 2:29 - loss: 0.3028 - iou_score: 0.6805 - f1-score: 0.8084For batch 41, tr_loss is    0.30.\n",
      " 43/200 [=====>........................] - ETA: 2:27 - loss: 0.3032 - iou_score: 0.6805 - f1-score: 0.8084For batch 42, tr_loss is    0.30.\n",
      " 44/200 [=====>........................] - ETA: 2:26 - loss: 0.3031 - iou_score: 0.6812 - f1-score: 0.8089For batch 43, tr_loss is    0.30.\n",
      " 45/200 [=====>........................] - ETA: 2:25 - loss: 0.3035 - iou_score: 0.6807 - f1-score: 0.8085For batch 44, tr_loss is    0.30.\n",
      " 46/200 [=====>........................] - ETA: 2:23 - loss: 0.3055 - iou_score: 0.6796 - f1-score: 0.8076For batch 45, tr_loss is    0.31.\n",
      " 47/200 [======>.......................] - ETA: 2:21 - loss: 0.3058 - iou_score: 0.6793 - f1-score: 0.8074For batch 46, tr_loss is    0.31.\n",
      " 48/200 [======>.......................] - ETA: 2:20 - loss: 0.3062 - iou_score: 0.6788 - f1-score: 0.8071For batch 47, tr_loss is    0.31.\n",
      " 49/200 [======>.......................] - ETA: 2:19 - loss: 0.3063 - iou_score: 0.6790 - f1-score: 0.8072For batch 48, tr_loss is    0.31.\n",
      " 50/200 [======>.......................] - ETA: 2:18 - loss: 0.3051 - iou_score: 0.6804 - f1-score: 0.8082For batch 49, tr_loss is    0.31.\n",
      " 51/200 [======>.......................] - ETA: 2:17 - loss: 0.3052 - iou_score: 0.6806 - f1-score: 0.8083For batch 50, tr_loss is    0.31.\n",
      " 52/200 [======>.......................] - ETA: 2:16 - loss: 0.3057 - iou_score: 0.6802 - f1-score: 0.8080For batch 51, tr_loss is    0.31.\n",
      " 53/200 [======>.......................] - ETA: 2:16 - loss: 0.3058 - iou_score: 0.6800 - f1-score: 0.8079For batch 52, tr_loss is    0.31.\n",
      " 54/200 [=======>......................] - ETA: 2:14 - loss: 0.3061 - iou_score: 0.6796 - f1-score: 0.8076For batch 53, tr_loss is    0.31.\n",
      " 55/200 [=======>......................] - ETA: 2:13 - loss: 0.3054 - iou_score: 0.6803 - f1-score: 0.8081For batch 54, tr_loss is    0.31.\n",
      " 56/200 [=======>......................] - ETA: 2:11 - loss: 0.3054 - iou_score: 0.6804 - f1-score: 0.8082For batch 55, tr_loss is    0.31.\n",
      " 57/200 [=======>......................] - ETA: 2:10 - loss: 0.3048 - iou_score: 0.6805 - f1-score: 0.8083For batch 56, tr_loss is    0.30.\n",
      " 58/200 [=======>......................] - ETA: 2:09 - loss: 0.3047 - iou_score: 0.6807 - f1-score: 0.8084For batch 57, tr_loss is    0.30.\n",
      " 59/200 [=======>......................] - ETA: 2:07 - loss: 0.3040 - iou_score: 0.6816 - f1-score: 0.8090For batch 58, tr_loss is    0.30.\n",
      " 60/200 [========>.....................] - ETA: 2:07 - loss: 0.3034 - iou_score: 0.6819 - f1-score: 0.8093For batch 59, tr_loss is    0.30.\n",
      " 61/200 [========>.....................] - ETA: 2:06 - loss: 0.3045 - iou_score: 0.6811 - f1-score: 0.8087For batch 60, tr_loss is    0.30.\n",
      " 62/200 [========>.....................] - ETA: 2:04 - loss: 0.3048 - iou_score: 0.6807 - f1-score: 0.8085For batch 61, tr_loss is    0.30.\n",
      " 63/200 [========>.....................] - ETA: 2:04 - loss: 0.3047 - iou_score: 0.6811 - f1-score: 0.8087For batch 62, tr_loss is    0.30.\n",
      " 64/200 [========>.....................] - ETA: 2:03 - loss: 0.3059 - iou_score: 0.6797 - f1-score: 0.8078For batch 63, tr_loss is    0.31.\n",
      " 65/200 [========>.....................] - ETA: 2:03 - loss: 0.3043 - iou_score: 0.6816 - f1-score: 0.8090For batch 64, tr_loss is    0.30.\n",
      " 66/200 [========>.....................] - ETA: 2:01 - loss: 0.3058 - iou_score: 0.6799 - f1-score: 0.8077For batch 65, tr_loss is    0.31.\n",
      " 67/200 [=========>....................] - ETA: 2:01 - loss: 0.3049 - iou_score: 0.6809 - f1-score: 0.8084For batch 66, tr_loss is    0.30.\n",
      " 68/200 [=========>....................] - ETA: 2:00 - loss: 0.3048 - iou_score: 0.6809 - f1-score: 0.8084For batch 67, tr_loss is    0.30.\n",
      " 69/200 [=========>....................] - ETA: 1:59 - loss: 0.3061 - iou_score: 0.6793 - f1-score: 0.8072For batch 68, tr_loss is    0.31.\n",
      " 70/200 [=========>....................] - ETA: 1:58 - loss: 0.3057 - iou_score: 0.6798 - f1-score: 0.8076For batch 69, tr_loss is    0.31.\n",
      " 71/200 [=========>....................] - ETA: 1:56 - loss: 0.3056 - iou_score: 0.6799 - f1-score: 0.8077For batch 70, tr_loss is    0.31.\n",
      " 72/200 [=========>....................] - ETA: 1:56 - loss: 0.3055 - iou_score: 0.6798 - f1-score: 0.8076For batch 71, tr_loss is    0.31.\n",
      " 73/200 [=========>....................] - ETA: 1:55 - loss: 0.3049 - iou_score: 0.6805 - f1-score: 0.8081For batch 72, tr_loss is    0.30.\n",
      " 74/200 [==========>...................] - ETA: 1:54 - loss: 0.3052 - iou_score: 0.6801 - f1-score: 0.8078For batch 73, tr_loss is    0.31.\n",
      " 75/200 [==========>...................] - ETA: 1:54 - loss: 0.3065 - iou_score: 0.6791 - f1-score: 0.8071For batch 74, tr_loss is    0.31.\n",
      " 76/200 [==========>...................] - ETA: 1:53 - loss: 0.3065 - iou_score: 0.6789 - f1-score: 0.8069For batch 75, tr_loss is    0.31.\n",
      " 77/200 [==========>...................] - ETA: 1:52 - loss: 0.3064 - iou_score: 0.6789 - f1-score: 0.8070For batch 76, tr_loss is    0.31.\n",
      " 78/200 [==========>...................] - ETA: 1:51 - loss: 0.3061 - iou_score: 0.6790 - f1-score: 0.8070For batch 77, tr_loss is    0.31.\n",
      " 79/200 [==========>...................] - ETA: 1:50 - loss: 0.3060 - iou_score: 0.6791 - f1-score: 0.8072For batch 78, tr_loss is    0.31.\n",
      " 80/200 [===========>..................] - ETA: 1:49 - loss: 0.3058 - iou_score: 0.6792 - f1-score: 0.8072For batch 79, tr_loss is    0.31.\n",
      " 81/200 [===========>..................] - ETA: 1:48 - loss: 0.3050 - iou_score: 0.6803 - f1-score: 0.8080For batch 80, tr_loss is    0.30.\n",
      " 82/200 [===========>..................] - ETA: 1:48 - loss: 0.3046 - iou_score: 0.6807 - f1-score: 0.8083For batch 81, tr_loss is    0.30.\n",
      " 83/200 [===========>..................] - ETA: 1:47 - loss: 0.3048 - iou_score: 0.6806 - f1-score: 0.8082For batch 82, tr_loss is    0.30.\n",
      " 84/200 [===========>..................] - ETA: 1:46 - loss: 0.3045 - iou_score: 0.6808 - f1-score: 0.8084For batch 83, tr_loss is    0.30.\n",
      " 85/200 [===========>..................] - ETA: 1:45 - loss: 0.3051 - iou_score: 0.6799 - f1-score: 0.8077For batch 84, tr_loss is    0.31.\n",
      " 86/200 [===========>..................] - ETA: 1:44 - loss: 0.3056 - iou_score: 0.6792 - f1-score: 0.8072For batch 85, tr_loss is    0.31.\n",
      " 87/200 [============>.................] - ETA: 1:43 - loss: 0.3051 - iou_score: 0.6798 - f1-score: 0.8077For batch 86, tr_loss is    0.31.\n",
      " 88/200 [============>.................] - ETA: 1:42 - loss: 0.3050 - iou_score: 0.6803 - f1-score: 0.8080For batch 87, tr_loss is    0.30.\n",
      " 89/200 [============>.................] - ETA: 1:41 - loss: 0.3051 - iou_score: 0.6798 - f1-score: 0.8077For batch 88, tr_loss is    0.31.\n",
      " 90/200 [============>.................] - ETA: 1:40 - loss: 0.3056 - iou_score: 0.6795 - f1-score: 0.8074For batch 89, tr_loss is    0.31.\n",
      " 91/200 [============>.................] - ETA: 1:40 - loss: 0.3052 - iou_score: 0.6796 - f1-score: 0.8075For batch 90, tr_loss is    0.31.\n",
      " 92/200 [============>.................] - ETA: 1:39 - loss: 0.3058 - iou_score: 0.6790 - f1-score: 0.8071For batch 91, tr_loss is    0.31.\n",
      " 93/200 [============>.................] - ETA: 1:38 - loss: 0.3059 - iou_score: 0.6789 - f1-score: 0.8070For batch 92, tr_loss is    0.31.\n",
      " 94/200 [=============>................] - ETA: 1:37 - loss: 0.3069 - iou_score: 0.6774 - f1-score: 0.8059For batch 93, tr_loss is    0.31.\n",
      " 95/200 [=============>................] - ETA: 1:35 - loss: 0.3077 - iou_score: 0.6767 - f1-score: 0.8054For batch 94, tr_loss is    0.31.\n",
      " 96/200 [=============>................] - ETA: 1:34 - loss: 0.3073 - iou_score: 0.6773 - f1-score: 0.8058For batch 95, tr_loss is    0.31.\n",
      " 97/200 [=============>................] - ETA: 1:33 - loss: 0.3078 - iou_score: 0.6765 - f1-score: 0.8052For batch 96, tr_loss is    0.31.\n",
      " 98/200 [=============>................] - ETA: 1:33 - loss: 0.3082 - iou_score: 0.6764 - f1-score: 0.8052For batch 97, tr_loss is    0.31.\n",
      " 99/200 [=============>................] - ETA: 1:32 - loss: 0.3078 - iou_score: 0.6768 - f1-score: 0.8054For batch 98, tr_loss is    0.31.\n",
      "100/200 [==============>...............] - ETA: 1:30 - loss: 0.3083 - iou_score: 0.6764 - f1-score: 0.8052For batch 99, tr_loss is    0.31.\n",
      "101/200 [==============>...............] - ETA: 1:29 - loss: 0.3082 - iou_score: 0.6766 - f1-score: 0.8053For batch 100, tr_loss is    0.31.\n",
      "102/200 [==============>...............] - ETA: 1:28 - loss: 0.3085 - iou_score: 0.6761 - f1-score: 0.8050For batch 101, tr_loss is    0.31.\n",
      "103/200 [==============>...............] - ETA: 1:27 - loss: 0.3088 - iou_score: 0.6758 - f1-score: 0.8047For batch 102, tr_loss is    0.31.\n",
      "104/200 [==============>...............] - ETA: 1:26 - loss: 0.3089 - iou_score: 0.6754 - f1-score: 0.8045For batch 103, tr_loss is    0.31.\n",
      "105/200 [==============>...............] - ETA: 1:25 - loss: 0.3091 - iou_score: 0.6751 - f1-score: 0.8042For batch 104, tr_loss is    0.31.\n",
      "106/200 [==============>...............] - ETA: 1:24 - loss: 0.3097 - iou_score: 0.6746 - f1-score: 0.8039For batch 105, tr_loss is    0.31.\n",
      "107/200 [===============>..............] - ETA: 1:23 - loss: 0.3099 - iou_score: 0.6743 - f1-score: 0.8037For batch 106, tr_loss is    0.31.\n",
      "108/200 [===============>..............] - ETA: 1:22 - loss: 0.3097 - iou_score: 0.6746 - f1-score: 0.8039For batch 107, tr_loss is    0.31.\n",
      "109/200 [===============>..............] - ETA: 1:21 - loss: 0.3096 - iou_score: 0.6748 - f1-score: 0.8040For batch 108, tr_loss is    0.31.\n",
      "110/200 [===============>..............] - ETA: 1:21 - loss: 0.3095 - iou_score: 0.6750 - f1-score: 0.8042For batch 109, tr_loss is    0.31.\n",
      "111/200 [===============>..............] - ETA: 1:20 - loss: 0.3090 - iou_score: 0.6754 - f1-score: 0.8045For batch 110, tr_loss is    0.31.\n",
      "112/200 [===============>..............] - ETA: 1:19 - loss: 0.3088 - iou_score: 0.6756 - f1-score: 0.8046For batch 111, tr_loss is    0.31.\n",
      "113/200 [===============>..............] - ETA: 1:18 - loss: 0.3095 - iou_score: 0.6746 - f1-score: 0.8038For batch 112, tr_loss is    0.31.\n",
      "114/200 [================>.............] - ETA: 1:17 - loss: 0.3100 - iou_score: 0.6741 - f1-score: 0.8034For batch 113, tr_loss is    0.31.\n",
      "115/200 [================>.............] - ETA: 1:16 - loss: 0.3100 - iou_score: 0.6741 - f1-score: 0.8034For batch 114, tr_loss is    0.31.\n",
      "116/200 [================>.............] - ETA: 1:15 - loss: 0.3103 - iou_score: 0.6737 - f1-score: 0.8031For batch 115, tr_loss is    0.31.\n",
      "117/200 [================>.............] - ETA: 1:14 - loss: 0.3104 - iou_score: 0.6736 - f1-score: 0.8031For batch 116, tr_loss is    0.31.\n",
      "118/200 [================>.............] - ETA: 1:13 - loss: 0.3103 - iou_score: 0.6736 - f1-score: 0.8031For batch 117, tr_loss is    0.31.\n",
      "119/200 [================>.............] - ETA: 1:12 - loss: 0.3104 - iou_score: 0.6735 - f1-score: 0.8030For batch 118, tr_loss is    0.31.\n",
      "120/200 [=================>............] - ETA: 1:11 - loss: 0.3101 - iou_score: 0.6738 - f1-score: 0.8033For batch 119, tr_loss is    0.31.\n",
      "121/200 [=================>............] - ETA: 1:11 - loss: 0.3098 - iou_score: 0.6743 - f1-score: 0.8036For batch 120, tr_loss is    0.31.\n",
      "122/200 [=================>............] - ETA: 1:10 - loss: 0.3097 - iou_score: 0.6743 - f1-score: 0.8036For batch 121, tr_loss is    0.31.\n",
      "123/200 [=================>............] - ETA: 1:09 - loss: 0.3102 - iou_score: 0.6736 - f1-score: 0.8031For batch 122, tr_loss is    0.31.\n",
      "124/200 [=================>............] - ETA: 1:07 - loss: 0.3104 - iou_score: 0.6734 - f1-score: 0.8030For batch 123, tr_loss is    0.31.\n",
      "125/200 [=================>............] - ETA: 1:07 - loss: 0.3105 - iou_score: 0.6732 - f1-score: 0.8028For batch 124, tr_loss is    0.31.\n",
      "126/200 [=================>............] - ETA: 1:06 - loss: 0.3104 - iou_score: 0.6735 - f1-score: 0.8030For batch 125, tr_loss is    0.31.\n",
      "127/200 [==================>...........] - ETA: 1:05 - loss: 0.3104 - iou_score: 0.6735 - f1-score: 0.8030For batch 126, tr_loss is    0.31.\n",
      "128/200 [==================>...........] - ETA: 1:04 - loss: 0.3113 - iou_score: 0.6723 - f1-score: 0.8021For batch 127, tr_loss is    0.31.\n",
      "129/200 [==================>...........] - ETA: 1:03 - loss: 0.3116 - iou_score: 0.6721 - f1-score: 0.8020For batch 128, tr_loss is    0.31.\n",
      "130/200 [==================>...........] - ETA: 1:02 - loss: 0.3114 - iou_score: 0.6723 - f1-score: 0.8021For batch 129, tr_loss is    0.31.\n",
      "131/200 [==================>...........] - ETA: 1:01 - loss: 0.3109 - iou_score: 0.6727 - f1-score: 0.8025For batch 130, tr_loss is    0.31.\n",
      "132/200 [==================>...........] - ETA: 1:00 - loss: 0.3106 - iou_score: 0.6732 - f1-score: 0.8028For batch 131, tr_loss is    0.31.\n",
      "133/200 [==================>...........] - ETA: 59s - loss: 0.3106 - iou_score: 0.6732 - f1-score: 0.8027 For batch 132, tr_loss is    0.31.\n",
      "134/200 [===================>..........] - ETA: 58s - loss: 0.3110 - iou_score: 0.6727 - f1-score: 0.8024For batch 133, tr_loss is    0.31.\n",
      "135/200 [===================>..........] - ETA: 57s - loss: 0.3113 - iou_score: 0.6722 - f1-score: 0.8020For batch 134, tr_loss is    0.31.\n",
      "136/200 [===================>..........] - ETA: 57s - loss: 0.3113 - iou_score: 0.6721 - f1-score: 0.8020For batch 135, tr_loss is    0.31.\n",
      "137/200 [===================>..........] - ETA: 56s - loss: 0.3123 - iou_score: 0.6712 - f1-score: 0.8012For batch 136, tr_loss is    0.31.\n",
      "138/200 [===================>..........] - ETA: 55s - loss: 0.3124 - iou_score: 0.6710 - f1-score: 0.8011For batch 137, tr_loss is    0.31.\n",
      "139/200 [===================>..........] - ETA: 54s - loss: 0.3120 - iou_score: 0.6714 - f1-score: 0.8014For batch 138, tr_loss is    0.31.\n",
      "140/200 [====================>.........] - ETA: 53s - loss: 0.3130 - iou_score: 0.6703 - f1-score: 0.8006For batch 139, tr_loss is    0.31.\n",
      "141/200 [====================>.........] - ETA: 52s - loss: 0.3137 - iou_score: 0.6696 - f1-score: 0.8000For batch 140, tr_loss is    0.31.\n",
      "142/200 [====================>.........] - ETA: 51s - loss: 0.3135 - iou_score: 0.6700 - f1-score: 0.8003For batch 141, tr_loss is    0.31.\n",
      "143/200 [====================>.........] - ETA: 50s - loss: 0.3135 - iou_score: 0.6700 - f1-score: 0.8003For batch 142, tr_loss is    0.31.\n",
      "144/200 [====================>.........] - ETA: 50s - loss: 0.3136 - iou_score: 0.6700 - f1-score: 0.8002For batch 143, tr_loss is    0.31.\n",
      "145/200 [====================>.........] - ETA: 49s - loss: 0.3137 - iou_score: 0.6697 - f1-score: 0.8001For batch 144, tr_loss is    0.31.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/200 [====================>.........] - ETA: 48s - loss: 0.3133 - iou_score: 0.6704 - f1-score: 0.8005For batch 145, tr_loss is    0.31.\n",
      "147/200 [=====================>........] - ETA: 47s - loss: 0.3136 - iou_score: 0.6701 - f1-score: 0.8003For batch 146, tr_loss is    0.31.\n",
      "148/200 [=====================>........] - ETA: 46s - loss: 0.3130 - iou_score: 0.6709 - f1-score: 0.8008For batch 147, tr_loss is    0.31.\n",
      "149/200 [=====================>........] - ETA: 45s - loss: 0.3128 - iou_score: 0.6711 - f1-score: 0.8010For batch 148, tr_loss is    0.31.\n",
      "150/200 [=====================>........] - ETA: 44s - loss: 0.3124 - iou_score: 0.6717 - f1-score: 0.8014For batch 149, tr_loss is    0.31.\n",
      "151/200 [=====================>........] - ETA: 43s - loss: 0.3128 - iou_score: 0.6712 - f1-score: 0.8010For batch 150, tr_loss is    0.31.\n",
      "152/200 [=====================>........] - ETA: 42s - loss: 0.3128 - iou_score: 0.6713 - f1-score: 0.8011For batch 151, tr_loss is    0.31.\n",
      "153/200 [=====================>........] - ETA: 41s - loss: 0.3126 - iou_score: 0.6715 - f1-score: 0.8013For batch 152, tr_loss is    0.31.\n",
      "154/200 [======================>.......] - ETA: 40s - loss: 0.3126 - iou_score: 0.6715 - f1-score: 0.8013For batch 153, tr_loss is    0.31.\n",
      "155/200 [======================>.......] - ETA: 39s - loss: 0.3125 - iou_score: 0.6717 - f1-score: 0.8014For batch 154, tr_loss is    0.31.\n",
      "156/200 [======================>.......] - ETA: 39s - loss: 0.3122 - iou_score: 0.6720 - f1-score: 0.8016For batch 155, tr_loss is    0.31.\n",
      "157/200 [======================>.......] - ETA: 38s - loss: 0.3123 - iou_score: 0.6719 - f1-score: 0.8015For batch 156, tr_loss is    0.31.\n",
      "158/200 [======================>.......] - ETA: 37s - loss: 0.3124 - iou_score: 0.6717 - f1-score: 0.8015For batch 157, tr_loss is    0.31.\n",
      "159/200 [======================>.......] - ETA: 36s - loss: 0.3126 - iou_score: 0.6715 - f1-score: 0.8013For batch 158, tr_loss is    0.31.\n",
      "160/200 [=======================>......] - ETA: 35s - loss: 0.3126 - iou_score: 0.6714 - f1-score: 0.8012For batch 159, tr_loss is    0.31.\n",
      "161/200 [=======================>......] - ETA: 34s - loss: 0.3128 - iou_score: 0.6711 - f1-score: 0.8010For batch 160, tr_loss is    0.31.\n",
      "162/200 [=======================>......] - ETA: 33s - loss: 0.3126 - iou_score: 0.6711 - f1-score: 0.8010For batch 161, tr_loss is    0.31.\n",
      "163/200 [=======================>......] - ETA: 32s - loss: 0.3122 - iou_score: 0.6717 - f1-score: 0.8014For batch 162, tr_loss is    0.31.\n",
      "164/200 [=======================>......] - ETA: 31s - loss: 0.3123 - iou_score: 0.6716 - f1-score: 0.8014For batch 163, tr_loss is    0.31.\n",
      "165/200 [=======================>......] - ETA: 30s - loss: 0.3119 - iou_score: 0.6719 - f1-score: 0.8016For batch 164, tr_loss is    0.31.\n",
      "166/200 [=======================>......] - ETA: 29s - loss: 0.3119 - iou_score: 0.6719 - f1-score: 0.8016For batch 165, tr_loss is    0.31.\n",
      "167/200 [========================>.....] - ETA: 28s - loss: 0.3113 - iou_score: 0.6728 - f1-score: 0.8022For batch 166, tr_loss is    0.31.\n",
      "168/200 [========================>.....] - ETA: 28s - loss: 0.3115 - iou_score: 0.6726 - f1-score: 0.8020For batch 167, tr_loss is    0.31.\n",
      "169/200 [========================>.....] - ETA: 27s - loss: 0.3116 - iou_score: 0.6723 - f1-score: 0.8018For batch 168, tr_loss is    0.31.\n",
      "170/200 [========================>.....] - ETA: 26s - loss: 0.3113 - iou_score: 0.6727 - f1-score: 0.8021For batch 169, tr_loss is    0.31.\n",
      "171/200 [========================>.....] - ETA: 25s - loss: 0.3113 - iou_score: 0.6727 - f1-score: 0.8021For batch 170, tr_loss is    0.31.\n",
      "172/200 [========================>.....] - ETA: 24s - loss: 0.3111 - iou_score: 0.6731 - f1-score: 0.8024For batch 171, tr_loss is    0.31.\n",
      "173/200 [========================>.....] - ETA: 23s - loss: 0.3111 - iou_score: 0.6731 - f1-score: 0.8024For batch 172, tr_loss is    0.31.\n",
      "174/200 [=========================>....] - ETA: 22s - loss: 0.3109 - iou_score: 0.6733 - f1-score: 0.8026For batch 173, tr_loss is    0.31.\n",
      "175/200 [=========================>....] - ETA: 22s - loss: 0.3106 - iou_score: 0.6736 - f1-score: 0.8028For batch 174, tr_loss is    0.31.\n",
      "176/200 [=========================>....] - ETA: 21s - loss: 0.3107 - iou_score: 0.6733 - f1-score: 0.8026For batch 175, tr_loss is    0.31.\n",
      "177/200 [=========================>....] - ETA: 20s - loss: 0.3104 - iou_score: 0.6736 - f1-score: 0.8028For batch 176, tr_loss is    0.31.\n",
      "178/200 [=========================>....] - ETA: 19s - loss: 0.3107 - iou_score: 0.6732 - f1-score: 0.8025For batch 177, tr_loss is    0.31.\n",
      "179/200 [=========================>....] - ETA: 18s - loss: 0.3103 - iou_score: 0.6737 - f1-score: 0.8028For batch 178, tr_loss is    0.31.\n",
      "180/200 [==========================>...] - ETA: 17s - loss: 0.3104 - iou_score: 0.6735 - f1-score: 0.8027For batch 179, tr_loss is    0.31.\n",
      "181/200 [==========================>...] - ETA: 16s - loss: 0.3106 - iou_score: 0.6732 - f1-score: 0.8025For batch 180, tr_loss is    0.31.\n",
      "182/200 [==========================>...] - ETA: 15s - loss: 0.3105 - iou_score: 0.6732 - f1-score: 0.8025For batch 181, tr_loss is    0.31.\n",
      "183/200 [==========================>...] - ETA: 14s - loss: 0.3105 - iou_score: 0.6731 - f1-score: 0.8024For batch 182, tr_loss is    0.31.\n",
      "184/200 [==========================>...] - ETA: 14s - loss: 0.3103 - iou_score: 0.6734 - f1-score: 0.8026For batch 183, tr_loss is    0.31.\n",
      "185/200 [==========================>...] - ETA: 13s - loss: 0.3101 - iou_score: 0.6735 - f1-score: 0.8027For batch 184, tr_loss is    0.31.\n",
      "186/200 [==========================>...] - ETA: 12s - loss: 0.3099 - iou_score: 0.6737 - f1-score: 0.8029For batch 185, tr_loss is    0.31.\n",
      "187/200 [===========================>..] - ETA: 11s - loss: 0.3097 - iou_score: 0.6740 - f1-score: 0.8031For batch 186, tr_loss is    0.31.\n",
      "188/200 [===========================>..] - ETA: 10s - loss: 0.3094 - iou_score: 0.6743 - f1-score: 0.8033For batch 187, tr_loss is    0.31.\n",
      "189/200 [===========================>..] - ETA: 9s - loss: 0.3096 - iou_score: 0.6741 - f1-score: 0.8031 For batch 188, tr_loss is    0.31.\n",
      "190/200 [===========================>..] - ETA: 8s - loss: 0.3096 - iou_score: 0.6740 - f1-score: 0.8031For batch 189, tr_loss is    0.31.\n",
      "191/200 [===========================>..] - ETA: 7s - loss: 0.3101 - iou_score: 0.6735 - f1-score: 0.8027For batch 190, tr_loss is    0.31.\n",
      "192/200 [===========================>..] - ETA: 7s - loss: 0.3106 - iou_score: 0.6730 - f1-score: 0.8023For batch 191, tr_loss is    0.31.\n",
      "193/200 [===========================>..] - ETA: 6s - loss: 0.3103 - iou_score: 0.6733 - f1-score: 0.8025For batch 192, tr_loss is    0.31.\n",
      "194/200 [============================>.] - ETA: 5s - loss: 0.3105 - iou_score: 0.6731 - f1-score: 0.8023For batch 193, tr_loss is    0.31.\n",
      "195/200 [============================>.] - ETA: 4s - loss: 0.3106 - iou_score: 0.6729 - f1-score: 0.8022For batch 194, tr_loss is    0.31.\n",
      "196/200 [============================>.] - ETA: 3s - loss: 0.3108 - iou_score: 0.6726 - f1-score: 0.8020For batch 195, tr_loss is    0.31.\n",
      "197/200 [============================>.] - ETA: 2s - loss: 0.3104 - iou_score: 0.6731 - f1-score: 0.8023For batch 196, tr_loss is    0.31.\n",
      "198/200 [============================>.] - ETA: 1s - loss: 0.3105 - iou_score: 0.6731 - f1-score: 0.8024For batch 197, tr_loss is    0.31.\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.3108 - iou_score: 0.6727 - f1-score: 0.8021For batch 198, tr_loss is    0.31.\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.3107 - iou_score: 0.6727 - f1-score: 0.8020For batch 199, tr_loss is    0.31.\n",
      "For batch 0, vl_loss is    0.40.\n",
      "For batch 1, vl_loss is    0.43.\n",
      "For batch 2, vl_loss is    0.43.\n",
      "For batch 3, vl_loss is    0.44.\n",
      "For batch 4, vl_loss is    0.43.\n",
      "For batch 5, vl_loss is    0.43.\n",
      "For batch 6, vl_loss is    0.45.\n",
      "For batch 7, vl_loss is    0.45.\n",
      "For batch 8, vl_loss is    0.45.\n",
      "For batch 9, vl_loss is    0.45.\n",
      "For batch 10, vl_loss is    0.45.\n",
      "For batch 11, vl_loss is    0.45.\n",
      "For batch 12, vl_loss is    0.45.\n",
      "For batch 13, vl_loss is    0.44.\n",
      "For batch 14, vl_loss is    0.45.\n",
      "For batch 15, vl_loss is    0.45.\n",
      "For batch 16, vl_loss is    0.44.\n",
      "For batch 17, vl_loss is    0.44.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 18, vl_loss is    0.44.\n",
      "For batch 19, vl_loss is    0.45.\n",
      "For batch 20, vl_loss is    0.44.\n",
      "For batch 21, vl_loss is    0.44.\n",
      "For batch 22, vl_loss is    0.44.\n",
      "For batch 23, vl_loss is    0.44.\n",
      "For batch 24, vl_loss is    0.44.\n",
      "For batch 25, vl_loss is    0.44.\n",
      "For batch 26, vl_loss is    0.44.\n",
      "For batch 27, vl_loss is    0.44.\n",
      "For batch 28, vl_loss is    0.44.\n",
      "For batch 29, vl_loss is    0.44.\n",
      "For batch 30, vl_loss is    0.44.\n",
      "For batch 31, vl_loss is    0.44.\n",
      "For batch 32, vl_loss is    0.44.\n",
      "For batch 33, vl_loss is    0.44.\n",
      "For batch 34, vl_loss is    0.44.\n",
      "For batch 35, vl_loss is    0.44.\n",
      "For batch 36, vl_loss is    0.44.\n",
      "For batch 37, vl_loss is    0.44.\n",
      "For batch 38, vl_loss is    0.43.\n",
      "For batch 39, vl_loss is    0.44.\n",
      "For batch 40, vl_loss is    0.44.\n",
      "For batch 41, vl_loss is    0.44.\n",
      "For batch 42, vl_loss is    0.43.\n",
      "For batch 43, vl_loss is    0.43.\n",
      "For batch 44, vl_loss is    0.43.\n",
      "For batch 45, vl_loss is    0.43.\n",
      "For batch 46, vl_loss is    0.44.\n",
      "For batch 47, vl_loss is    0.43.\n",
      "For batch 48, vl_loss is    0.43.\n",
      "For batch 49, vl_loss is    0.43.\n",
      "For batch 50, vl_loss is    0.43.\n",
      "For batch 51, vl_loss is    0.43.\n",
      "For batch 52, vl_loss is    0.43.\n",
      "For batch 53, vl_loss is    0.43.\n",
      "For batch 54, vl_loss is    0.43.\n",
      "For batch 55, vl_loss is    0.43.\n",
      "For batch 56, vl_loss is    0.43.\n",
      "For batch 57, vl_loss is    0.43.\n",
      "For batch 58, vl_loss is    0.43.\n",
      "For batch 59, vl_loss is    0.43.\n",
      "For batch 60, vl_loss is    0.43.\n",
      "For batch 61, vl_loss is    0.43.\n",
      "For batch 62, vl_loss is    0.43.\n",
      "For batch 63, vl_loss is    0.43.\n",
      "For batch 64, vl_loss is    0.43.\n",
      "For batch 65, vl_loss is    0.43.\n",
      "For batch 66, vl_loss is    0.43.\n",
      "For batch 67, vl_loss is    0.43.\n",
      "For batch 68, vl_loss is    0.43.\n",
      "For batch 69, vl_loss is    0.43.\n",
      "For batch 70, vl_loss is    0.43.\n",
      "For batch 71, vl_loss is    0.43.\n",
      "For batch 72, vl_loss is    0.43.\n",
      "For batch 73, vl_loss is    0.43.\n",
      "For batch 74, vl_loss is    0.43.\n",
      "For batch 75, vl_loss is    0.43.\n",
      "For batch 76, vl_loss is    0.43.\n",
      "For batch 77, vl_loss is    0.44.\n",
      "For batch 78, vl_loss is    0.44.\n",
      "For batch 79, vl_loss is    0.44.\n",
      "For batch 80, vl_loss is    0.44.\n",
      "For batch 81, vl_loss is    0.44.\n",
      "For batch 82, vl_loss is    0.44.\n",
      "For batch 83, vl_loss is    0.44.\n",
      "For batch 84, vl_loss is    0.43.\n",
      "For batch 85, vl_loss is    0.43.\n",
      "For batch 86, vl_loss is    0.44.\n",
      "For batch 87, vl_loss is    0.44.\n",
      "For batch 88, vl_loss is    0.44.\n",
      "For batch 89, vl_loss is    0.44.\n",
      "For batch 90, vl_loss is    0.44.\n",
      "For batch 91, vl_loss is    0.44.\n",
      "For batch 92, vl_loss is    0.43.\n",
      "For batch 93, vl_loss is    0.44.\n",
      "For batch 94, vl_loss is    0.43.\n",
      "For batch 95, vl_loss is    0.43.\n",
      "For batch 96, vl_loss is    0.44.\n",
      "For batch 97, vl_loss is    0.44.\n",
      "For batch 98, vl_loss is    0.44.\n",
      "For batch 99, vl_loss is    0.44.\n",
      "200/200 [==============================] - 182s 902ms/step - loss: 0.3107 - iou_score: 0.6727 - f1-score: 0.8020 - val_loss: 0.4353 - val_iou_score: 0.5711 - val_f1-score: 0.7241\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.33218\n",
      "The average loss for epoch 6 is    0.31 \n",
      "Epoch 8/200\n",
      "  1/200 [..............................] - ETA: 9:49 - loss: 0.2906 - iou_score: 0.6867 - f1-score: 0.8139For batch 0, tr_loss is    0.29.\n",
      "  2/200 [..............................] - ETA: 3:43 - loss: 0.2892 - iou_score: 0.6947 - f1-score: 0.8192For batch 1, tr_loss is    0.29.\n",
      "  3/200 [..............................] - ETA: 3:44 - loss: 0.2943 - iou_score: 0.6897 - f1-score: 0.8151For batch 2, tr_loss is    0.29.\n",
      "  4/200 [..............................] - ETA: 3:28 - loss: 0.2979 - iou_score: 0.6804 - f1-score: 0.8086For batch 3, tr_loss is    0.30.\n",
      "  5/200 [..............................] - ETA: 3:31 - loss: 0.2973 - iou_score: 0.6826 - f1-score: 0.8103For batch 4, tr_loss is    0.30.\n",
      "  6/200 [..............................] - ETA: 3:35 - loss: 0.3065 - iou_score: 0.6749 - f1-score: 0.8048For batch 5, tr_loss is    0.31.\n",
      "  7/200 [>.............................] - ETA: 3:39 - loss: 0.3156 - iou_score: 0.6631 - f1-score: 0.7955For batch 6, tr_loss is    0.32.\n",
      "  8/200 [>.............................] - ETA: 3:49 - loss: 0.3155 - iou_score: 0.6634 - f1-score: 0.7957For batch 7, tr_loss is    0.32.\n",
      "  9/200 [>.............................] - ETA: 3:49 - loss: 0.3118 - iou_score: 0.6676 - f1-score: 0.7987For batch 8, tr_loss is    0.31.\n",
      " 10/200 [>.............................] - ETA: 3:45 - loss: 0.3104 - iou_score: 0.6676 - f1-score: 0.7985For batch 9, tr_loss is    0.31.\n",
      " 11/200 [>.............................] - ETA: 3:41 - loss: 0.3062 - iou_score: 0.6701 - f1-score: 0.8003For batch 10, tr_loss is    0.31.\n",
      " 12/200 [>.............................] - ETA: 3:30 - loss: 0.3111 - iou_score: 0.6640 - f1-score: 0.7958For batch 11, tr_loss is    0.31.\n",
      " 13/200 [>.............................] - ETA: 3:29 - loss: 0.3117 - iou_score: 0.6629 - f1-score: 0.7951For batch 12, tr_loss is    0.31.\n",
      " 14/200 [=>............................] - ETA: 3:27 - loss: 0.3100 - iou_score: 0.6646 - f1-score: 0.7964For batch 13, tr_loss is    0.31.\n",
      " 15/200 [=>............................] - ETA: 3:25 - loss: 0.3088 - iou_score: 0.6638 - f1-score: 0.7959For batch 14, tr_loss is    0.31.\n",
      " 16/200 [=>............................] - ETA: 3:16 - loss: 0.3082 - iou_score: 0.6639 - f1-score: 0.7961For batch 15, tr_loss is    0.31.\n",
      " 17/200 [=>............................] - ETA: 3:16 - loss: 0.3056 - iou_score: 0.6675 - f1-score: 0.7987For batch 16, tr_loss is    0.31.\n",
      " 18/200 [=>............................] - ETA: 3:14 - loss: 0.3030 - iou_score: 0.6701 - f1-score: 0.8006For batch 17, tr_loss is    0.30.\n",
      " 19/200 [=>............................] - ETA: 3:07 - loss: 0.3049 - iou_score: 0.6678 - f1-score: 0.7988For batch 18, tr_loss is    0.30.\n",
      " 20/200 [==>...........................] - ETA: 3:08 - loss: 0.3018 - iou_score: 0.6719 - f1-score: 0.8017For batch 19, tr_loss is    0.30.\n",
      " 21/200 [==>...........................] - ETA: 3:02 - loss: 0.3001 - iou_score: 0.6748 - f1-score: 0.8038For batch 20, tr_loss is    0.30.\n",
      " 22/200 [==>...........................] - ETA: 2:59 - loss: 0.2992 - iou_score: 0.6756 - f1-score: 0.8044For batch 21, tr_loss is    0.30.\n",
      " 23/200 [==>...........................] - ETA: 2:56 - loss: 0.2982 - iou_score: 0.6778 - f1-score: 0.8060For batch 22, tr_loss is    0.30.\n",
      " 24/200 [==>...........................] - ETA: 2:52 - loss: 0.2986 - iou_score: 0.6786 - f1-score: 0.8067For batch 23, tr_loss is    0.30.\n",
      " 25/200 [==>...........................] - ETA: 2:50 - loss: 0.2975 - iou_score: 0.6801 - f1-score: 0.8078For batch 24, tr_loss is    0.30.\n",
      " 26/200 [==>...........................] - ETA: 2:49 - loss: 0.3018 - iou_score: 0.6776 - f1-score: 0.8060For batch 25, tr_loss is    0.30.\n",
      " 27/200 [===>..........................] - ETA: 2:49 - loss: 0.3005 - iou_score: 0.6793 - f1-score: 0.8071For batch 26, tr_loss is    0.30.\n",
      " 28/200 [===>..........................] - ETA: 2:48 - loss: 0.3012 - iou_score: 0.6791 - f1-score: 0.8070For batch 27, tr_loss is    0.30.\n",
      " 29/200 [===>..........................] - ETA: 2:44 - loss: 0.3019 - iou_score: 0.6781 - f1-score: 0.8064For batch 28, tr_loss is    0.30.\n",
      " 30/200 [===>..........................] - ETA: 2:44 - loss: 0.3003 - iou_score: 0.6805 - f1-score: 0.8080For batch 29, tr_loss is    0.30.\n",
      " 31/200 [===>..........................] - ETA: 2:41 - loss: 0.2987 - iou_score: 0.6824 - f1-score: 0.8094For batch 30, tr_loss is    0.30.\n",
      " 32/200 [===>..........................] - ETA: 2:41 - loss: 0.2970 - iou_score: 0.6845 - f1-score: 0.8109For batch 31, tr_loss is    0.30.\n",
      " 33/200 [===>..........................] - ETA: 2:37 - loss: 0.2962 - iou_score: 0.6856 - f1-score: 0.8116For batch 32, tr_loss is    0.30.\n",
      " 34/200 [====>.........................] - ETA: 2:35 - loss: 0.2966 - iou_score: 0.6845 - f1-score: 0.8109For batch 33, tr_loss is    0.30.\n",
      " 35/200 [====>.........................] - ETA: 2:32 - loss: 0.2963 - iou_score: 0.6853 - f1-score: 0.8115For batch 34, tr_loss is    0.30.\n",
      " 36/200 [====>.........................] - ETA: 2:32 - loss: 0.2961 - iou_score: 0.6859 - f1-score: 0.8119For batch 35, tr_loss is    0.30.\n",
      " 37/200 [====>.........................] - ETA: 2:31 - loss: 0.2972 - iou_score: 0.6848 - f1-score: 0.8111For batch 36, tr_loss is    0.30.\n",
      " 38/200 [====>.........................] - ETA: 2:29 - loss: 0.2978 - iou_score: 0.6836 - f1-score: 0.8103For batch 37, tr_loss is    0.30.\n",
      " 39/200 [====>.........................] - ETA: 2:27 - loss: 0.2970 - iou_score: 0.6848 - f1-score: 0.8112For batch 38, tr_loss is    0.30.\n",
      " 40/200 [=====>........................] - ETA: 2:27 - loss: 0.2958 - iou_score: 0.6862 - f1-score: 0.8122For batch 39, tr_loss is    0.30.\n",
      " 41/200 [=====>........................] - ETA: 2:26 - loss: 0.2951 - iou_score: 0.6867 - f1-score: 0.8125For batch 40, tr_loss is    0.30.\n",
      " 42/200 [=====>........................] - ETA: 2:26 - loss: 0.2956 - iou_score: 0.6861 - f1-score: 0.8121For batch 41, tr_loss is    0.30.\n",
      " 43/200 [=====>........................] - ETA: 2:23 - loss: 0.2960 - iou_score: 0.6859 - f1-score: 0.8120For batch 42, tr_loss is    0.30.\n",
      " 44/200 [=====>........................] - ETA: 2:22 - loss: 0.2950 - iou_score: 0.6870 - f1-score: 0.8128For batch 43, tr_loss is    0.29.\n",
      " 45/200 [=====>........................] - ETA: 2:21 - loss: 0.2950 - iou_score: 0.6869 - f1-score: 0.8127For batch 44, tr_loss is    0.30.\n",
      " 46/200 [=====>........................] - ETA: 2:18 - loss: 0.2962 - iou_score: 0.6865 - f1-score: 0.8124For batch 45, tr_loss is    0.30.\n",
      " 47/200 [======>.......................] - ETA: 2:18 - loss: 0.2966 - iou_score: 0.6861 - f1-score: 0.8121For batch 46, tr_loss is    0.30.\n",
      " 48/200 [======>.......................] - ETA: 2:17 - loss: 0.2970 - iou_score: 0.6859 - f1-score: 0.8120For batch 47, tr_loss is    0.30.\n",
      " 49/200 [======>.......................] - ETA: 2:15 - loss: 0.2970 - iou_score: 0.6861 - f1-score: 0.8122For batch 48, tr_loss is    0.30.\n",
      " 50/200 [======>.......................] - ETA: 2:13 - loss: 0.2955 - iou_score: 0.6881 - f1-score: 0.8135For batch 49, tr_loss is    0.30.\n",
      " 51/200 [======>.......................] - ETA: 2:13 - loss: 0.2954 - iou_score: 0.6891 - f1-score: 0.8142For batch 50, tr_loss is    0.30.\n",
      " 52/200 [======>.......................] - ETA: 2:13 - loss: 0.2955 - iou_score: 0.6889 - f1-score: 0.8140For batch 51, tr_loss is    0.30.\n",
      " 53/200 [======>.......................] - ETA: 2:10 - loss: 0.2950 - iou_score: 0.6893 - f1-score: 0.8143For batch 52, tr_loss is    0.29.\n",
      " 54/200 [=======>......................] - ETA: 2:10 - loss: 0.2953 - iou_score: 0.6889 - f1-score: 0.8141For batch 53, tr_loss is    0.30.\n",
      " 55/200 [=======>......................] - ETA: 2:08 - loss: 0.2944 - iou_score: 0.6899 - f1-score: 0.8148For batch 54, tr_loss is    0.29.\n",
      " 56/200 [=======>......................] - ETA: 2:08 - loss: 0.2943 - iou_score: 0.6899 - f1-score: 0.8148For batch 55, tr_loss is    0.29.\n",
      " 57/200 [=======>......................] - ETA: 2:06 - loss: 0.2939 - iou_score: 0.6899 - f1-score: 0.8148For batch 56, tr_loss is    0.29.\n",
      " 58/200 [=======>......................] - ETA: 2:06 - loss: 0.2934 - iou_score: 0.6903 - f1-score: 0.8151For batch 57, tr_loss is    0.29.\n",
      " 59/200 [=======>......................] - ETA: 2:05 - loss: 0.2927 - iou_score: 0.6912 - f1-score: 0.8157For batch 58, tr_loss is    0.29.\n",
      " 60/200 [========>.....................] - ETA: 2:05 - loss: 0.2924 - iou_score: 0.6914 - f1-score: 0.8159For batch 59, tr_loss is    0.29.\n",
      " 61/200 [========>.....................] - ETA: 2:04 - loss: 0.2930 - iou_score: 0.6912 - f1-score: 0.8158For batch 60, tr_loss is    0.29.\n",
      " 62/200 [========>.....................] - ETA: 2:03 - loss: 0.2929 - iou_score: 0.6911 - f1-score: 0.8157For batch 61, tr_loss is    0.29.\n",
      " 63/200 [========>.....................] - ETA: 2:02 - loss: 0.2922 - iou_score: 0.6920 - f1-score: 0.8163For batch 62, tr_loss is    0.29.\n",
      " 64/200 [========>.....................] - ETA: 2:02 - loss: 0.2936 - iou_score: 0.6903 - f1-score: 0.8151For batch 63, tr_loss is    0.29.\n",
      " 65/200 [========>.....................] - ETA: 2:01 - loss: 0.2923 - iou_score: 0.6918 - f1-score: 0.8161For batch 64, tr_loss is    0.29.\n",
      " 66/200 [========>.....................] - ETA: 2:00 - loss: 0.2942 - iou_score: 0.6898 - f1-score: 0.8145For batch 65, tr_loss is    0.29.\n",
      " 67/200 [=========>....................] - ETA: 1:59 - loss: 0.2935 - iou_score: 0.6906 - f1-score: 0.8151For batch 66, tr_loss is    0.29.\n",
      " 68/200 [=========>....................] - ETA: 1:58 - loss: 0.2934 - iou_score: 0.6909 - f1-score: 0.8153For batch 67, tr_loss is    0.29.\n",
      " 69/200 [=========>....................] - ETA: 1:56 - loss: 0.2946 - iou_score: 0.6892 - f1-score: 0.8141For batch 68, tr_loss is    0.29.\n",
      " 70/200 [=========>....................] - ETA: 1:55 - loss: 0.2944 - iou_score: 0.6894 - f1-score: 0.8142For batch 69, tr_loss is    0.29.\n",
      " 71/200 [=========>....................] - ETA: 1:55 - loss: 0.2942 - iou_score: 0.6898 - f1-score: 0.8145For batch 70, tr_loss is    0.29.\n",
      " 72/200 [=========>....................] - ETA: 1:53 - loss: 0.2943 - iou_score: 0.6895 - f1-score: 0.8143For batch 71, tr_loss is    0.29.\n",
      " 73/200 [=========>....................] - ETA: 1:53 - loss: 0.2940 - iou_score: 0.6897 - f1-score: 0.8145For batch 72, tr_loss is    0.29.\n",
      " 74/200 [==========>...................] - ETA: 1:51 - loss: 0.2944 - iou_score: 0.6892 - f1-score: 0.8141For batch 73, tr_loss is    0.29.\n",
      " 75/200 [==========>...................] - ETA: 1:50 - loss: 0.2956 - iou_score: 0.6883 - f1-score: 0.8135For batch 74, tr_loss is    0.30.\n",
      " 76/200 [==========>...................] - ETA: 1:50 - loss: 0.2957 - iou_score: 0.6879 - f1-score: 0.8132For batch 75, tr_loss is    0.30.\n",
      " 77/200 [==========>...................] - ETA: 1:49 - loss: 0.2956 - iou_score: 0.6879 - f1-score: 0.8132For batch 76, tr_loss is    0.30.\n",
      " 78/200 [==========>...................] - ETA: 1:48 - loss: 0.2955 - iou_score: 0.6879 - f1-score: 0.8133For batch 77, tr_loss is    0.30.\n",
      " 79/200 [==========>...................] - ETA: 1:47 - loss: 0.2954 - iou_score: 0.6880 - f1-score: 0.8134For batch 78, tr_loss is    0.30.\n",
      " 80/200 [===========>..................] - ETA: 1:47 - loss: 0.2951 - iou_score: 0.6883 - f1-score: 0.8136For batch 79, tr_loss is    0.30.\n",
      " 81/200 [===========>..................] - ETA: 1:46 - loss: 0.2940 - iou_score: 0.6898 - f1-score: 0.8146For batch 80, tr_loss is    0.29.\n",
      " 82/200 [===========>..................] - ETA: 1:45 - loss: 0.2940 - iou_score: 0.6899 - f1-score: 0.8146For batch 81, tr_loss is    0.29.\n",
      " 83/200 [===========>..................] - ETA: 1:44 - loss: 0.2941 - iou_score: 0.6896 - f1-score: 0.8144For batch 82, tr_loss is    0.29.\n",
      " 84/200 [===========>..................] - ETA: 1:42 - loss: 0.2938 - iou_score: 0.6897 - f1-score: 0.8145For batch 83, tr_loss is    0.29.\n",
      " 85/200 [===========>..................] - ETA: 1:41 - loss: 0.2945 - iou_score: 0.6885 - f1-score: 0.8136For batch 84, tr_loss is    0.29.\n",
      " 86/200 [===========>..................] - ETA: 1:40 - loss: 0.2950 - iou_score: 0.6877 - f1-score: 0.8131For batch 85, tr_loss is    0.30.\n",
      " 87/200 [============>.................] - ETA: 1:39 - loss: 0.2947 - iou_score: 0.6883 - f1-score: 0.8135For batch 86, tr_loss is    0.29.\n",
      " 88/200 [============>.................] - ETA: 1:38 - loss: 0.2946 - iou_score: 0.6887 - f1-score: 0.8138For batch 87, tr_loss is    0.29.\n",
      " 89/200 [============>.................] - ETA: 1:38 - loss: 0.2951 - iou_score: 0.6880 - f1-score: 0.8133For batch 88, tr_loss is    0.30.\n",
      " 90/200 [============>.................] - ETA: 1:37 - loss: 0.2952 - iou_score: 0.6879 - f1-score: 0.8132For batch 89, tr_loss is    0.30.\n",
      " 91/200 [============>.................] - ETA: 1:36 - loss: 0.2952 - iou_score: 0.6878 - f1-score: 0.8131For batch 90, tr_loss is    0.30.\n",
      " 92/200 [============>.................] - ETA: 1:35 - loss: 0.2961 - iou_score: 0.6869 - f1-score: 0.8125For batch 91, tr_loss is    0.30.\n",
      " 93/200 [============>.................] - ETA: 1:35 - loss: 0.2963 - iou_score: 0.6866 - f1-score: 0.8123For batch 92, tr_loss is    0.30.\n",
      " 94/200 [=============>................] - ETA: 1:34 - loss: 0.2977 - iou_score: 0.6848 - f1-score: 0.8109For batch 93, tr_loss is    0.30.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 95/200 [=============>................] - ETA: 1:33 - loss: 0.2983 - iou_score: 0.6842 - f1-score: 0.8105For batch 94, tr_loss is    0.30.\n",
      " 96/200 [=============>................] - ETA: 1:32 - loss: 0.2981 - iou_score: 0.6845 - f1-score: 0.8107For batch 95, tr_loss is    0.30.\n",
      " 97/200 [=============>................] - ETA: 1:32 - loss: 0.2987 - iou_score: 0.6836 - f1-score: 0.8101For batch 96, tr_loss is    0.30.\n",
      " 98/200 [=============>................] - ETA: 1:30 - loss: 0.2989 - iou_score: 0.6834 - f1-score: 0.8100For batch 97, tr_loss is    0.30.\n",
      " 99/200 [=============>................] - ETA: 1:30 - loss: 0.2985 - iou_score: 0.6838 - f1-score: 0.8102For batch 98, tr_loss is    0.30.\n",
      "100/200 [==============>...............] - ETA: 1:29 - loss: 0.2988 - iou_score: 0.6836 - f1-score: 0.8101For batch 99, tr_loss is    0.30.\n",
      "101/200 [==============>...............] - ETA: 1:28 - loss: 0.2989 - iou_score: 0.6836 - f1-score: 0.8101For batch 100, tr_loss is    0.30.\n",
      "102/200 [==============>...............] - ETA: 1:27 - loss: 0.2993 - iou_score: 0.6829 - f1-score: 0.8096For batch 101, tr_loss is    0.30.\n",
      "103/200 [==============>...............] - ETA: 1:26 - loss: 0.2994 - iou_score: 0.6828 - f1-score: 0.8096For batch 102, tr_loss is    0.30.\n",
      "104/200 [==============>...............] - ETA: 1:25 - loss: 0.2999 - iou_score: 0.6821 - f1-score: 0.8091For batch 103, tr_loss is    0.30.\n",
      "105/200 [==============>...............] - ETA: 1:24 - loss: 0.3000 - iou_score: 0.6819 - f1-score: 0.8089For batch 104, tr_loss is    0.30.\n",
      "106/200 [==============>...............] - ETA: 1:23 - loss: 0.3003 - iou_score: 0.6816 - f1-score: 0.8087For batch 105, tr_loss is    0.30.\n",
      "107/200 [===============>..............] - ETA: 1:22 - loss: 0.3007 - iou_score: 0.6811 - f1-score: 0.8084For batch 106, tr_loss is    0.30.\n",
      "108/200 [===============>..............] - ETA: 1:21 - loss: 0.3009 - iou_score: 0.6812 - f1-score: 0.8084For batch 107, tr_loss is    0.30.\n",
      "109/200 [===============>..............] - ETA: 1:21 - loss: 0.3009 - iou_score: 0.6812 - f1-score: 0.8084For batch 108, tr_loss is    0.30.\n",
      "110/200 [===============>..............] - ETA: 1:19 - loss: 0.3007 - iou_score: 0.6815 - f1-score: 0.8087For batch 109, tr_loss is    0.30.\n",
      "111/200 [===============>..............] - ETA: 1:19 - loss: 0.3001 - iou_score: 0.6823 - f1-score: 0.8091For batch 110, tr_loss is    0.30.\n",
      "112/200 [===============>..............] - ETA: 1:18 - loss: 0.3002 - iou_score: 0.6821 - f1-score: 0.8091For batch 111, tr_loss is    0.30.\n",
      "113/200 [===============>..............] - ETA: 1:17 - loss: 0.3011 - iou_score: 0.6809 - f1-score: 0.8081For batch 112, tr_loss is    0.30.\n",
      "114/200 [================>.............] - ETA: 1:16 - loss: 0.3017 - iou_score: 0.6802 - f1-score: 0.8075For batch 113, tr_loss is    0.30.\n",
      "115/200 [================>.............] - ETA: 1:16 - loss: 0.3016 - iou_score: 0.6803 - f1-score: 0.8076For batch 114, tr_loss is    0.30.\n",
      "116/200 [================>.............] - ETA: 1:14 - loss: 0.3021 - iou_score: 0.6796 - f1-score: 0.8071For batch 115, tr_loss is    0.30.\n",
      "117/200 [================>.............] - ETA: 1:14 - loss: 0.3022 - iou_score: 0.6797 - f1-score: 0.8072For batch 116, tr_loss is    0.30.\n",
      "118/200 [================>.............] - ETA: 1:12 - loss: 0.3020 - iou_score: 0.6798 - f1-score: 0.8073For batch 117, tr_loss is    0.30.\n",
      "119/200 [================>.............] - ETA: 1:12 - loss: 0.3025 - iou_score: 0.6794 - f1-score: 0.8070For batch 118, tr_loss is    0.30.\n",
      "120/200 [=================>............] - ETA: 1:11 - loss: 0.3021 - iou_score: 0.6798 - f1-score: 0.8073For batch 119, tr_loss is    0.30.\n",
      "121/200 [=================>............] - ETA: 1:10 - loss: 0.3019 - iou_score: 0.6801 - f1-score: 0.8075For batch 120, tr_loss is    0.30.\n",
      "122/200 [=================>............] - ETA: 1:09 - loss: 0.3018 - iou_score: 0.6802 - f1-score: 0.8076For batch 121, tr_loss is    0.30.\n",
      "123/200 [=================>............] - ETA: 1:08 - loss: 0.3027 - iou_score: 0.6793 - f1-score: 0.8069For batch 122, tr_loss is    0.30.\n",
      "124/200 [=================>............] - ETA: 1:07 - loss: 0.3029 - iou_score: 0.6792 - f1-score: 0.8068For batch 123, tr_loss is    0.30.\n",
      "125/200 [=================>............] - ETA: 1:06 - loss: 0.3031 - iou_score: 0.6790 - f1-score: 0.8067For batch 124, tr_loss is    0.30.\n",
      "126/200 [=================>............] - ETA: 1:05 - loss: 0.3032 - iou_score: 0.6788 - f1-score: 0.8066For batch 125, tr_loss is    0.30.\n",
      "127/200 [==================>...........] - ETA: 1:04 - loss: 0.3032 - iou_score: 0.6788 - f1-score: 0.8066For batch 126, tr_loss is    0.30.\n",
      "128/200 [==================>...........] - ETA: 1:03 - loss: 0.3042 - iou_score: 0.6776 - f1-score: 0.8056For batch 127, tr_loss is    0.30.\n",
      "129/200 [==================>...........] - ETA: 1:03 - loss: 0.3041 - iou_score: 0.6778 - f1-score: 0.8058For batch 128, tr_loss is    0.30.\n",
      "130/200 [==================>...........] - ETA: 1:02 - loss: 0.3039 - iou_score: 0.6780 - f1-score: 0.8059For batch 129, tr_loss is    0.30.\n",
      "131/200 [==================>...........] - ETA: 1:01 - loss: 0.3035 - iou_score: 0.6784 - f1-score: 0.8062For batch 130, tr_loss is    0.30.\n",
      "132/200 [==================>...........] - ETA: 1:00 - loss: 0.3032 - iou_score: 0.6789 - f1-score: 0.8065For batch 131, tr_loss is    0.30.\n",
      "133/200 [==================>...........] - ETA: 59s - loss: 0.3034 - iou_score: 0.6787 - f1-score: 0.8064 For batch 132, tr_loss is    0.30.\n",
      "134/200 [===================>..........] - ETA: 58s - loss: 0.3039 - iou_score: 0.6780 - f1-score: 0.8059For batch 133, tr_loss is    0.30.\n",
      "135/200 [===================>..........] - ETA: 57s - loss: 0.3043 - iou_score: 0.6777 - f1-score: 0.8057For batch 134, tr_loss is    0.30.\n",
      "136/200 [===================>..........] - ETA: 56s - loss: 0.3042 - iou_score: 0.6777 - f1-score: 0.8057For batch 135, tr_loss is    0.30.\n",
      "137/200 [===================>..........] - ETA: 55s - loss: 0.3049 - iou_score: 0.6768 - f1-score: 0.8051For batch 136, tr_loss is    0.30.\n",
      "138/200 [===================>..........] - ETA: 54s - loss: 0.3051 - iou_score: 0.6765 - f1-score: 0.8048For batch 137, tr_loss is    0.31.\n",
      "139/200 [===================>..........] - ETA: 53s - loss: 0.3048 - iou_score: 0.6769 - f1-score: 0.8051For batch 138, tr_loss is    0.30.\n",
      "140/200 [====================>.........] - ETA: 52s - loss: 0.3060 - iou_score: 0.6757 - f1-score: 0.8042For batch 139, tr_loss is    0.31.\n",
      "141/200 [====================>.........] - ETA: 52s - loss: 0.3064 - iou_score: 0.6752 - f1-score: 0.8038For batch 140, tr_loss is    0.31.\n",
      "142/200 [====================>.........] - ETA: 51s - loss: 0.3062 - iou_score: 0.6755 - f1-score: 0.8040For batch 141, tr_loss is    0.31.\n",
      "143/200 [====================>.........] - ETA: 50s - loss: 0.3063 - iou_score: 0.6755 - f1-score: 0.8040For batch 142, tr_loss is    0.31.\n",
      "144/200 [====================>.........] - ETA: 49s - loss: 0.3064 - iou_score: 0.6752 - f1-score: 0.8038For batch 143, tr_loss is    0.31.\n",
      "145/200 [====================>.........] - ETA: 48s - loss: 0.3065 - iou_score: 0.6751 - f1-score: 0.8037For batch 144, tr_loss is    0.31.\n",
      "146/200 [====================>.........] - ETA: 47s - loss: 0.3061 - iou_score: 0.6759 - f1-score: 0.8043For batch 145, tr_loss is    0.31.\n",
      "147/200 [=====================>........] - ETA: 46s - loss: 0.3063 - iou_score: 0.6756 - f1-score: 0.8040For batch 146, tr_loss is    0.31.\n",
      "148/200 [=====================>........] - ETA: 45s - loss: 0.3059 - iou_score: 0.6763 - f1-score: 0.8044For batch 147, tr_loss is    0.31.\n",
      "149/200 [=====================>........] - ETA: 44s - loss: 0.3056 - iou_score: 0.6765 - f1-score: 0.8046For batch 148, tr_loss is    0.31.\n",
      "150/200 [=====================>........] - ETA: 43s - loss: 0.3052 - iou_score: 0.6770 - f1-score: 0.8050For batch 149, tr_loss is    0.31.\n",
      "151/200 [=====================>........] - ETA: 42s - loss: 0.3054 - iou_score: 0.6767 - f1-score: 0.8047For batch 150, tr_loss is    0.31.\n",
      "152/200 [=====================>........] - ETA: 42s - loss: 0.3054 - iou_score: 0.6767 - f1-score: 0.8048For batch 151, tr_loss is    0.31.\n",
      "153/200 [=====================>........] - ETA: 41s - loss: 0.3051 - iou_score: 0.6769 - f1-score: 0.8049For batch 152, tr_loss is    0.31.\n",
      "154/200 [======================>.......] - ETA: 40s - loss: 0.3051 - iou_score: 0.6769 - f1-score: 0.8049For batch 153, tr_loss is    0.31.\n",
      "155/200 [======================>.......] - ETA: 39s - loss: 0.3050 - iou_score: 0.6770 - f1-score: 0.8050For batch 154, tr_loss is    0.31.\n",
      "156/200 [======================>.......] - ETA: 38s - loss: 0.3049 - iou_score: 0.6771 - f1-score: 0.8051For batch 155, tr_loss is    0.30.\n",
      "157/200 [======================>.......] - ETA: 37s - loss: 0.3050 - iou_score: 0.6770 - f1-score: 0.8050For batch 156, tr_loss is    0.30.\n",
      "158/200 [======================>.......] - ETA: 36s - loss: 0.3050 - iou_score: 0.6768 - f1-score: 0.8049For batch 157, tr_loss is    0.31.\n",
      "159/200 [======================>.......] - ETA: 35s - loss: 0.3052 - iou_score: 0.6767 - f1-score: 0.8048For batch 158, tr_loss is    0.31.\n",
      "160/200 [=======================>......] - ETA: 34s - loss: 0.3053 - iou_score: 0.6766 - f1-score: 0.8048For batch 159, tr_loss is    0.31.\n",
      "161/200 [=======================>......] - ETA: 34s - loss: 0.3054 - iou_score: 0.6763 - f1-score: 0.8046For batch 160, tr_loss is    0.31.\n",
      "162/200 [=======================>......] - ETA: 33s - loss: 0.3053 - iou_score: 0.6762 - f1-score: 0.8045For batch 161, tr_loss is    0.31.\n",
      "163/200 [=======================>......] - ETA: 32s - loss: 0.3050 - iou_score: 0.6767 - f1-score: 0.8049For batch 162, tr_loss is    0.30.\n",
      "164/200 [=======================>......] - ETA: 31s - loss: 0.3053 - iou_score: 0.6763 - f1-score: 0.8046For batch 163, tr_loss is    0.31.\n",
      "165/200 [=======================>......] - ETA: 30s - loss: 0.3049 - iou_score: 0.6768 - f1-score: 0.8050For batch 164, tr_loss is    0.30.\n",
      "166/200 [=======================>......] - ETA: 29s - loss: 0.3049 - iou_score: 0.6769 - f1-score: 0.8050For batch 165, tr_loss is    0.30.\n",
      "167/200 [========================>.....] - ETA: 28s - loss: 0.3044 - iou_score: 0.6776 - f1-score: 0.8055For batch 166, tr_loss is    0.30.\n",
      "168/200 [========================>.....] - ETA: 27s - loss: 0.3046 - iou_score: 0.6773 - f1-score: 0.8053For batch 167, tr_loss is    0.30.\n",
      "169/200 [========================>.....] - ETA: 26s - loss: 0.3048 - iou_score: 0.6770 - f1-score: 0.8050For batch 168, tr_loss is    0.30.\n",
      "170/200 [========================>.....] - ETA: 25s - loss: 0.3043 - iou_score: 0.6775 - f1-score: 0.8054For batch 169, tr_loss is    0.30.\n",
      "171/200 [========================>.....] - ETA: 25s - loss: 0.3042 - iou_score: 0.6775 - f1-score: 0.8054For batch 170, tr_loss is    0.30.\n",
      "172/200 [========================>.....] - ETA: 24s - loss: 0.3039 - iou_score: 0.6779 - f1-score: 0.8057For batch 171, tr_loss is    0.30.\n",
      "173/200 [========================>.....] - ETA: 23s - loss: 0.3038 - iou_score: 0.6780 - f1-score: 0.8058For batch 172, tr_loss is    0.30.\n",
      "174/200 [=========================>....] - ETA: 22s - loss: 0.3035 - iou_score: 0.6784 - f1-score: 0.8060For batch 173, tr_loss is    0.30.\n",
      "175/200 [=========================>....] - ETA: 21s - loss: 0.3034 - iou_score: 0.6786 - f1-score: 0.8062For batch 174, tr_loss is    0.30.\n",
      "176/200 [=========================>....] - ETA: 20s - loss: 0.3036 - iou_score: 0.6783 - f1-score: 0.8060For batch 175, tr_loss is    0.30.\n",
      "177/200 [=========================>....] - ETA: 19s - loss: 0.3034 - iou_score: 0.6785 - f1-score: 0.8061For batch 176, tr_loss is    0.30.\n",
      "178/200 [=========================>....] - ETA: 19s - loss: 0.3037 - iou_score: 0.6780 - f1-score: 0.8058For batch 177, tr_loss is    0.30.\n",
      "179/200 [=========================>....] - ETA: 18s - loss: 0.3033 - iou_score: 0.6786 - f1-score: 0.8061For batch 178, tr_loss is    0.30.\n",
      "180/200 [==========================>...] - ETA: 17s - loss: 0.3033 - iou_score: 0.6785 - f1-score: 0.8061For batch 179, tr_loss is    0.30.\n",
      "181/200 [==========================>...] - ETA: 16s - loss: 0.3038 - iou_score: 0.6781 - f1-score: 0.8058For batch 180, tr_loss is    0.30.\n",
      "182/200 [==========================>...] - ETA: 15s - loss: 0.3038 - iou_score: 0.6781 - f1-score: 0.8058For batch 181, tr_loss is    0.30.\n",
      "183/200 [==========================>...] - ETA: 14s - loss: 0.3039 - iou_score: 0.6778 - f1-score: 0.8056For batch 182, tr_loss is    0.30.\n",
      "184/200 [==========================>...] - ETA: 13s - loss: 0.3036 - iou_score: 0.6781 - f1-score: 0.8058For batch 183, tr_loss is    0.30.\n",
      "185/200 [==========================>...] - ETA: 12s - loss: 0.3035 - iou_score: 0.6783 - f1-score: 0.8059For batch 184, tr_loss is    0.30.\n",
      "186/200 [==========================>...] - ETA: 12s - loss: 0.3033 - iou_score: 0.6786 - f1-score: 0.8061For batch 185, tr_loss is    0.30.\n",
      "187/200 [===========================>..] - ETA: 11s - loss: 0.3031 - iou_score: 0.6788 - f1-score: 0.8063For batch 186, tr_loss is    0.30.\n",
      "188/200 [===========================>..] - ETA: 10s - loss: 0.3031 - iou_score: 0.6788 - f1-score: 0.8063For batch 187, tr_loss is    0.30.\n",
      "189/200 [===========================>..] - ETA: 9s - loss: 0.3034 - iou_score: 0.6785 - f1-score: 0.8061 For batch 188, tr_loss is    0.30.\n",
      "190/200 [===========================>..] - ETA: 8s - loss: 0.3033 - iou_score: 0.6785 - f1-score: 0.8061For batch 189, tr_loss is    0.30.\n",
      "191/200 [===========================>..] - ETA: 7s - loss: 0.3040 - iou_score: 0.6778 - f1-score: 0.8056For batch 190, tr_loss is    0.30.\n",
      "192/200 [===========================>..] - ETA: 6s - loss: 0.3046 - iou_score: 0.6773 - f1-score: 0.8052For batch 191, tr_loss is    0.30.\n",
      "193/200 [===========================>..] - ETA: 6s - loss: 0.3043 - iou_score: 0.6777 - f1-score: 0.8055For batch 192, tr_loss is    0.30.\n",
      "194/200 [============================>.] - ETA: 5s - loss: 0.3046 - iou_score: 0.6774 - f1-score: 0.8053For batch 193, tr_loss is    0.30.\n",
      "195/200 [============================>.] - ETA: 4s - loss: 0.3047 - iou_score: 0.6773 - f1-score: 0.8052For batch 194, tr_loss is    0.30.\n",
      "196/200 [============================>.] - ETA: 3s - loss: 0.3050 - iou_score: 0.6770 - f1-score: 0.8050For batch 195, tr_loss is    0.30.\n",
      "197/200 [============================>.] - ETA: 2s - loss: 0.3047 - iou_score: 0.6775 - f1-score: 0.8053For batch 196, tr_loss is    0.30.\n",
      "198/200 [============================>.] - ETA: 1s - loss: 0.3046 - iou_score: 0.6776 - f1-score: 0.8054For batch 197, tr_loss is    0.30.\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.3048 - iou_score: 0.6773 - f1-score: 0.8051For batch 198, tr_loss is    0.30.\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.3047 - iou_score: 0.6772 - f1-score: 0.8051For batch 199, tr_loss is    0.30.\n",
      "For batch 0, vl_loss is    0.35.\n",
      "For batch 1, vl_loss is    0.34.\n",
      "For batch 2, vl_loss is    0.33.\n",
      "For batch 3, vl_loss is    0.33.\n",
      "For batch 4, vl_loss is    0.32.\n",
      "For batch 5, vl_loss is    0.32.\n",
      "For batch 6, vl_loss is    0.33.\n",
      "For batch 7, vl_loss is    0.32.\n",
      "For batch 8, vl_loss is    0.33.\n",
      "For batch 9, vl_loss is    0.33.\n",
      "For batch 10, vl_loss is    0.34.\n",
      "For batch 11, vl_loss is    0.33.\n",
      "For batch 12, vl_loss is    0.33.\n",
      "For batch 13, vl_loss is    0.33.\n",
      "For batch 14, vl_loss is    0.33.\n",
      "For batch 15, vl_loss is    0.32.\n",
      "For batch 16, vl_loss is    0.32.\n",
      "For batch 17, vl_loss is    0.32.\n",
      "For batch 18, vl_loss is    0.32.\n",
      "For batch 19, vl_loss is    0.32.\n",
      "For batch 20, vl_loss is    0.32.\n",
      "For batch 21, vl_loss is    0.32.\n",
      "For batch 22, vl_loss is    0.32.\n",
      "For batch 23, vl_loss is    0.32.\n",
      "For batch 24, vl_loss is    0.32.\n",
      "For batch 25, vl_loss is    0.33.\n",
      "For batch 26, vl_loss is    0.33.\n",
      "For batch 27, vl_loss is    0.33.\n",
      "For batch 28, vl_loss is    0.33.\n",
      "For batch 29, vl_loss is    0.33.\n",
      "For batch 30, vl_loss is    0.33.\n",
      "For batch 31, vl_loss is    0.33.\n",
      "For batch 32, vl_loss is    0.33.\n",
      "For batch 33, vl_loss is    0.33.\n",
      "For batch 34, vl_loss is    0.33.\n",
      "For batch 35, vl_loss is    0.33.\n",
      "For batch 36, vl_loss is    0.33.\n",
      "For batch 37, vl_loss is    0.32.\n",
      "For batch 38, vl_loss is    0.32.\n",
      "For batch 39, vl_loss is    0.32.\n",
      "For batch 40, vl_loss is    0.32.\n",
      "For batch 41, vl_loss is    0.32.\n",
      "For batch 42, vl_loss is    0.32.\n",
      "For batch 43, vl_loss is    0.32.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 44, vl_loss is    0.32.\n",
      "For batch 45, vl_loss is    0.32.\n",
      "For batch 46, vl_loss is    0.32.\n",
      "For batch 47, vl_loss is    0.32.\n",
      "For batch 48, vl_loss is    0.32.\n",
      "For batch 49, vl_loss is    0.32.\n",
      "For batch 50, vl_loss is    0.32.\n",
      "For batch 51, vl_loss is    0.32.\n",
      "For batch 52, vl_loss is    0.32.\n",
      "For batch 53, vl_loss is    0.32.\n",
      "For batch 54, vl_loss is    0.32.\n",
      "For batch 55, vl_loss is    0.32.\n",
      "For batch 56, vl_loss is    0.32.\n",
      "For batch 57, vl_loss is    0.32.\n",
      "For batch 58, vl_loss is    0.32.\n",
      "For batch 59, vl_loss is    0.32.\n",
      "For batch 60, vl_loss is    0.32.\n",
      "For batch 61, vl_loss is    0.32.\n",
      "For batch 62, vl_loss is    0.32.\n",
      "For batch 63, vl_loss is    0.32.\n",
      "For batch 64, vl_loss is    0.32.\n",
      "For batch 65, vl_loss is    0.32.\n",
      "For batch 66, vl_loss is    0.32.\n",
      "For batch 67, vl_loss is    0.32.\n",
      "For batch 68, vl_loss is    0.32.\n",
      "For batch 69, vl_loss is    0.32.\n",
      "For batch 70, vl_loss is    0.32.\n",
      "For batch 71, vl_loss is    0.32.\n",
      "For batch 72, vl_loss is    0.32.\n",
      "For batch 73, vl_loss is    0.32.\n",
      "For batch 74, vl_loss is    0.32.\n",
      "For batch 75, vl_loss is    0.32.\n",
      "For batch 76, vl_loss is    0.32.\n",
      "For batch 77, vl_loss is    0.32.\n",
      "For batch 78, vl_loss is    0.32.\n",
      "For batch 79, vl_loss is    0.32.\n",
      "For batch 80, vl_loss is    0.32.\n",
      "For batch 81, vl_loss is    0.32.\n",
      "For batch 82, vl_loss is    0.32.\n",
      "For batch 83, vl_loss is    0.32.\n",
      "For batch 84, vl_loss is    0.32.\n",
      "For batch 85, vl_loss is    0.32.\n",
      "For batch 86, vl_loss is    0.32.\n",
      "For batch 87, vl_loss is    0.32.\n",
      "For batch 88, vl_loss is    0.32.\n",
      "For batch 89, vl_loss is    0.32.\n",
      "For batch 90, vl_loss is    0.32.\n",
      "For batch 91, vl_loss is    0.32.\n",
      "For batch 92, vl_loss is    0.32.\n",
      "For batch 93, vl_loss is    0.32.\n",
      "For batch 94, vl_loss is    0.32.\n",
      "For batch 95, vl_loss is    0.32.\n",
      "For batch 96, vl_loss is    0.32.\n",
      "For batch 97, vl_loss is    0.32.\n",
      "For batch 98, vl_loss is    0.32.\n",
      "For batch 99, vl_loss is    0.32.\n",
      "200/200 [==============================] - 179s 887ms/step - loss: 0.3047 - iou_score: 0.6772 - f1-score: 0.8051 - val_loss: 0.3244 - val_iou_score: 0.6899 - val_f1-score: 0.8144\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.33218 to 0.32441, saving model to ./model/tumor_100_unet_efficientnetb0_imagenet_09290.hdf5\n",
      "The average loss for epoch 7 is    0.30 \n",
      "Epoch 9/200\n",
      "  1/200 [..............................] - ETA: 8:48 - loss: 0.3022 - iou_score: 0.6758 - f1-score: 0.8063For batch 0, tr_loss is    0.30.\n",
      "  2/200 [..............................] - ETA: 5:00 - loss: 0.2918 - iou_score: 0.6922 - f1-score: 0.8177For batch 1, tr_loss is    0.29.\n",
      "  3/200 [..............................] - ETA: 4:57 - loss: 0.2929 - iou_score: 0.6928 - f1-score: 0.8181For batch 2, tr_loss is    0.29.\n",
      "  4/200 [..............................] - ETA: 5:02 - loss: 0.2996 - iou_score: 0.6787 - f1-score: 0.8079For batch 3, tr_loss is    0.30.\n",
      "  5/200 [..............................] - ETA: 4:54 - loss: 0.2958 - iou_score: 0.6869 - f1-score: 0.8136For batch 4, tr_loss is    0.30.\n",
      "  6/200 [..............................] - ETA: 4:58 - loss: 0.3084 - iou_score: 0.6745 - f1-score: 0.8045For batch 5, tr_loss is    0.31.\n",
      "  7/200 [>.............................] - ETA: 4:31 - loss: 0.3139 - iou_score: 0.6659 - f1-score: 0.7977For batch 6, tr_loss is    0.31.\n",
      "  8/200 [>.............................] - ETA: 4:19 - loss: 0.3134 - iou_score: 0.6663 - f1-score: 0.7981For batch 7, tr_loss is    0.31.\n",
      "  9/200 [>.............................] - ETA: 3:57 - loss: 0.3132 - iou_score: 0.6693 - f1-score: 0.8002For batch 8, tr_loss is    0.31.\n",
      " 10/200 [>.............................] - ETA: 3:44 - loss: 0.3142 - iou_score: 0.6685 - f1-score: 0.7993For batch 9, tr_loss is    0.31.\n",
      " 11/200 [>.............................] - ETA: 3:41 - loss: 0.3109 - iou_score: 0.6702 - f1-score: 0.8006For batch 10, tr_loss is    0.31.\n",
      " 12/200 [>.............................] - ETA: 3:38 - loss: 0.3150 - iou_score: 0.6637 - f1-score: 0.7958For batch 11, tr_loss is    0.32.\n",
      " 13/200 [>.............................] - ETA: 3:30 - loss: 0.3161 - iou_score: 0.6619 - f1-score: 0.7944For batch 12, tr_loss is    0.32.\n",
      " 14/200 [=>............................] - ETA: 3:24 - loss: 0.3152 - iou_score: 0.6627 - f1-score: 0.7951For batch 13, tr_loss is    0.32.\n",
      " 15/200 [=>............................] - ETA: 3:22 - loss: 0.3127 - iou_score: 0.6644 - f1-score: 0.7964For batch 14, tr_loss is    0.31.\n",
      " 16/200 [=>............................] - ETA: 3:20 - loss: 0.3118 - iou_score: 0.6638 - f1-score: 0.7961For batch 15, tr_loss is    0.31.\n",
      " 17/200 [=>............................] - ETA: 3:18 - loss: 0.3093 - iou_score: 0.6664 - f1-score: 0.7980For batch 16, tr_loss is    0.31.\n",
      " 18/200 [=>............................] - ETA: 3:11 - loss: 0.3075 - iou_score: 0.6685 - f1-score: 0.7996For batch 17, tr_loss is    0.31.\n",
      " 19/200 [=>............................] - ETA: 3:09 - loss: 0.3099 - iou_score: 0.6656 - f1-score: 0.7974For batch 18, tr_loss is    0.31.\n",
      " 20/200 [==>...........................] - ETA: 3:08 - loss: 0.3069 - iou_score: 0.6700 - f1-score: 0.8004For batch 19, tr_loss is    0.31.\n",
      " 21/200 [==>...........................] - ETA: 3:04 - loss: 0.3057 - iou_score: 0.6722 - f1-score: 0.8020For batch 20, tr_loss is    0.31.\n",
      " 22/200 [==>...........................] - ETA: 3:03 - loss: 0.3043 - iou_score: 0.6739 - f1-score: 0.8033For batch 21, tr_loss is    0.30.\n",
      " 23/200 [==>...........................] - ETA: 3:02 - loss: 0.3031 - iou_score: 0.6756 - f1-score: 0.8045For batch 22, tr_loss is    0.30.\n",
      " 24/200 [==>...........................] - ETA: 2:56 - loss: 0.3017 - iou_score: 0.6774 - f1-score: 0.8058For batch 23, tr_loss is    0.30.\n",
      " 25/200 [==>...........................] - ETA: 2:54 - loss: 0.2999 - iou_score: 0.6793 - f1-score: 0.8072For batch 24, tr_loss is    0.30.\n",
      " 26/200 [==>...........................] - ETA: 2:54 - loss: 0.3022 - iou_score: 0.6777 - f1-score: 0.8061For batch 25, tr_loss is    0.30.\n",
      " 27/200 [===>..........................] - ETA: 2:53 - loss: 0.3016 - iou_score: 0.6786 - f1-score: 0.8067For batch 26, tr_loss is    0.30.\n",
      " 28/200 [===>..........................] - ETA: 2:52 - loss: 0.3018 - iou_score: 0.6784 - f1-score: 0.8066For batch 27, tr_loss is    0.30.\n",
      " 29/200 [===>..........................] - ETA: 2:48 - loss: 0.3019 - iou_score: 0.6780 - f1-score: 0.8064For batch 28, tr_loss is    0.30.\n",
      " 30/200 [===>..........................] - ETA: 2:48 - loss: 0.3004 - iou_score: 0.6801 - f1-score: 0.8078For batch 29, tr_loss is    0.30.\n",
      " 31/200 [===>..........................] - ETA: 2:47 - loss: 0.2992 - iou_score: 0.6813 - f1-score: 0.8087For batch 30, tr_loss is    0.30.\n",
      " 32/200 [===>..........................] - ETA: 2:43 - loss: 0.2985 - iou_score: 0.6828 - f1-score: 0.8098For batch 31, tr_loss is    0.30.\n",
      " 33/200 [===>..........................] - ETA: 2:43 - loss: 0.2972 - iou_score: 0.6836 - f1-score: 0.8104For batch 32, tr_loss is    0.30.\n",
      " 34/200 [====>.........................] - ETA: 2:42 - loss: 0.2981 - iou_score: 0.6825 - f1-score: 0.8096For batch 33, tr_loss is    0.30.\n",
      " 35/200 [====>.........................] - ETA: 2:38 - loss: 0.2982 - iou_score: 0.6835 - f1-score: 0.8103For batch 34, tr_loss is    0.30.\n",
      " 36/200 [====>.........................] - ETA: 2:38 - loss: 0.2982 - iou_score: 0.6836 - f1-score: 0.8104For batch 35, tr_loss is    0.30.\n",
      " 37/200 [====>.........................] - ETA: 2:37 - loss: 0.2992 - iou_score: 0.6825 - f1-score: 0.8096For batch 36, tr_loss is    0.30.\n",
      " 38/200 [====>.........................] - ETA: 2:36 - loss: 0.2999 - iou_score: 0.6810 - f1-score: 0.8085For batch 37, tr_loss is    0.30.\n",
      " 39/200 [====>.........................] - ETA: 2:32 - loss: 0.2989 - iou_score: 0.6820 - f1-score: 0.8093For batch 38, tr_loss is    0.30.\n",
      " 40/200 [=====>........................] - ETA: 2:31 - loss: 0.2972 - iou_score: 0.6838 - f1-score: 0.8105For batch 39, tr_loss is    0.30.\n",
      " 41/200 [=====>........................] - ETA: 2:29 - loss: 0.2964 - iou_score: 0.6846 - f1-score: 0.8111For batch 40, tr_loss is    0.30.\n",
      " 42/200 [=====>........................] - ETA: 2:28 - loss: 0.2967 - iou_score: 0.6841 - f1-score: 0.8108For batch 41, tr_loss is    0.30.\n",
      " 43/200 [=====>........................] - ETA: 2:27 - loss: 0.2966 - iou_score: 0.6845 - f1-score: 0.8110For batch 42, tr_loss is    0.30.\n",
      " 44/200 [=====>........................] - ETA: 2:25 - loss: 0.2958 - iou_score: 0.6857 - f1-score: 0.8118For batch 43, tr_loss is    0.30.\n",
      " 45/200 [=====>........................] - ETA: 2:23 - loss: 0.2960 - iou_score: 0.6854 - f1-score: 0.8117For batch 44, tr_loss is    0.30.\n",
      " 46/200 [=====>........................] - ETA: 2:21 - loss: 0.2979 - iou_score: 0.6847 - f1-score: 0.8111For batch 45, tr_loss is    0.30.\n",
      " 47/200 [======>.......................] - ETA: 2:20 - loss: 0.2979 - iou_score: 0.6846 - f1-score: 0.8110For batch 46, tr_loss is    0.30.\n",
      " 48/200 [======>.......................] - ETA: 2:20 - loss: 0.2978 - iou_score: 0.6846 - f1-score: 0.8110For batch 47, tr_loss is    0.30.\n",
      " 49/200 [======>.......................] - ETA: 2:19 - loss: 0.2975 - iou_score: 0.6851 - f1-score: 0.8114For batch 48, tr_loss is    0.30.\n",
      " 50/200 [======>.......................] - ETA: 2:18 - loss: 0.2956 - iou_score: 0.6871 - f1-score: 0.8128For batch 49, tr_loss is    0.30.\n",
      " 51/200 [======>.......................] - ETA: 2:16 - loss: 0.2957 - iou_score: 0.6872 - f1-score: 0.8128For batch 50, tr_loss is    0.30.\n",
      " 52/200 [======>.......................] - ETA: 2:15 - loss: 0.2960 - iou_score: 0.6869 - f1-score: 0.8125For batch 51, tr_loss is    0.30.\n",
      " 53/200 [======>.......................] - ETA: 2:14 - loss: 0.2958 - iou_score: 0.6868 - f1-score: 0.8124For batch 52, tr_loss is    0.30.\n",
      " 54/200 [=======>......................] - ETA: 2:14 - loss: 0.2965 - iou_score: 0.6861 - f1-score: 0.8120For batch 53, tr_loss is    0.30.\n",
      " 55/200 [=======>......................] - ETA: 2:12 - loss: 0.2959 - iou_score: 0.6870 - f1-score: 0.8126For batch 54, tr_loss is    0.30.\n",
      " 56/200 [=======>......................] - ETA: 2:10 - loss: 0.2958 - iou_score: 0.6872 - f1-score: 0.8128For batch 55, tr_loss is    0.30.\n",
      " 57/200 [=======>......................] - ETA: 2:09 - loss: 0.2954 - iou_score: 0.6871 - f1-score: 0.8127For batch 56, tr_loss is    0.30.\n",
      " 58/200 [=======>......................] - ETA: 2:09 - loss: 0.2950 - iou_score: 0.6876 - f1-score: 0.8131For batch 57, tr_loss is    0.30.\n",
      " 59/200 [=======>......................] - ETA: 2:08 - loss: 0.2944 - iou_score: 0.6884 - f1-score: 0.8137For batch 58, tr_loss is    0.29.\n",
      " 60/200 [========>.....................] - ETA: 2:07 - loss: 0.2939 - iou_score: 0.6885 - f1-score: 0.8138For batch 59, tr_loss is    0.29.\n",
      " 61/200 [========>.....................] - ETA: 2:06 - loss: 0.2954 - iou_score: 0.6874 - f1-score: 0.8130For batch 60, tr_loss is    0.30.\n",
      " 62/200 [========>.....................] - ETA: 2:06 - loss: 0.2953 - iou_score: 0.6874 - f1-score: 0.8130For batch 61, tr_loss is    0.30.\n",
      " 63/200 [========>.....................] - ETA: 2:05 - loss: 0.2946 - iou_score: 0.6879 - f1-score: 0.8134For batch 62, tr_loss is    0.29.\n",
      " 64/200 [========>.....................] - ETA: 2:04 - loss: 0.2956 - iou_score: 0.6866 - f1-score: 0.8125For batch 63, tr_loss is    0.30.\n",
      " 65/200 [========>.....................] - ETA: 2:03 - loss: 0.2943 - iou_score: 0.6883 - f1-score: 0.8136For batch 64, tr_loss is    0.29.\n",
      " 66/200 [========>.....................] - ETA: 2:02 - loss: 0.2962 - iou_score: 0.6862 - f1-score: 0.8120For batch 65, tr_loss is    0.30.\n",
      " 67/200 [=========>....................] - ETA: 2:00 - loss: 0.2954 - iou_score: 0.6869 - f1-score: 0.8125For batch 66, tr_loss is    0.30.\n",
      " 68/200 [=========>....................] - ETA: 1:59 - loss: 0.2951 - iou_score: 0.6872 - f1-score: 0.8127For batch 67, tr_loss is    0.30.\n",
      " 69/200 [=========>....................] - ETA: 1:58 - loss: 0.2963 - iou_score: 0.6856 - f1-score: 0.8115For batch 68, tr_loss is    0.30.\n",
      " 70/200 [=========>....................] - ETA: 1:58 - loss: 0.2964 - iou_score: 0.6855 - f1-score: 0.8115For batch 69, tr_loss is    0.30.\n",
      " 71/200 [=========>....................] - ETA: 1:56 - loss: 0.2961 - iou_score: 0.6857 - f1-score: 0.8117For batch 70, tr_loss is    0.30.\n",
      " 72/200 [=========>....................] - ETA: 1:55 - loss: 0.2960 - iou_score: 0.6857 - f1-score: 0.8117For batch 71, tr_loss is    0.30.\n",
      " 73/200 [=========>....................] - ETA: 1:53 - loss: 0.2956 - iou_score: 0.6859 - f1-score: 0.8119For batch 72, tr_loss is    0.30.\n",
      " 74/200 [==========>...................] - ETA: 1:52 - loss: 0.2955 - iou_score: 0.6859 - f1-score: 0.8118For batch 73, tr_loss is    0.30.\n",
      " 75/200 [==========>...................] - ETA: 1:51 - loss: 0.2962 - iou_score: 0.6851 - f1-score: 0.8113For batch 74, tr_loss is    0.30.\n",
      " 76/200 [==========>...................] - ETA: 1:49 - loss: 0.2962 - iou_score: 0.6850 - f1-score: 0.8112For batch 75, tr_loss is    0.30.\n",
      " 77/200 [==========>...................] - ETA: 1:48 - loss: 0.2961 - iou_score: 0.6848 - f1-score: 0.8111For batch 76, tr_loss is    0.30.\n",
      " 78/200 [==========>...................] - ETA: 1:47 - loss: 0.2953 - iou_score: 0.6857 - f1-score: 0.8117For batch 77, tr_loss is    0.30.\n",
      " 79/200 [==========>...................] - ETA: 1:46 - loss: 0.2955 - iou_score: 0.6855 - f1-score: 0.8116For batch 78, tr_loss is    0.30.\n",
      " 80/200 [===========>..................] - ETA: 1:45 - loss: 0.2950 - iou_score: 0.6859 - f1-score: 0.8119For batch 79, tr_loss is    0.30.\n",
      " 81/200 [===========>..................] - ETA: 1:44 - loss: 0.2940 - iou_score: 0.6873 - f1-score: 0.8129For batch 80, tr_loss is    0.29.\n",
      " 82/200 [===========>..................] - ETA: 1:43 - loss: 0.2941 - iou_score: 0.6876 - f1-score: 0.8130For batch 81, tr_loss is    0.29.\n",
      " 83/200 [===========>..................] - ETA: 1:42 - loss: 0.2941 - iou_score: 0.6875 - f1-score: 0.8130For batch 82, tr_loss is    0.29.\n",
      " 84/200 [===========>..................] - ETA: 1:41 - loss: 0.2936 - iou_score: 0.6879 - f1-score: 0.8133For batch 83, tr_loss is    0.29.\n",
      " 85/200 [===========>..................] - ETA: 1:40 - loss: 0.2943 - iou_score: 0.6869 - f1-score: 0.8125For batch 84, tr_loss is    0.29.\n",
      " 86/200 [===========>..................] - ETA: 1:39 - loss: 0.2948 - iou_score: 0.6862 - f1-score: 0.8120For batch 85, tr_loss is    0.29.\n",
      " 87/200 [============>.................] - ETA: 1:38 - loss: 0.2942 - iou_score: 0.6868 - f1-score: 0.8125For batch 86, tr_loss is    0.29.\n",
      " 88/200 [============>.................] - ETA: 1:37 - loss: 0.2937 - iou_score: 0.6875 - f1-score: 0.8129For batch 87, tr_loss is    0.29.\n",
      " 89/200 [============>.................] - ETA: 1:36 - loss: 0.2940 - iou_score: 0.6870 - f1-score: 0.8126For batch 88, tr_loss is    0.29.\n",
      " 90/200 [============>.................] - ETA: 1:35 - loss: 0.2940 - iou_score: 0.6870 - f1-score: 0.8126For batch 89, tr_loss is    0.29.\n",
      " 91/200 [============>.................] - ETA: 1:34 - loss: 0.2940 - iou_score: 0.6867 - f1-score: 0.8124For batch 90, tr_loss is    0.29.\n",
      " 92/200 [============>.................] - ETA: 1:33 - loss: 0.2949 - iou_score: 0.6859 - f1-score: 0.8118For batch 91, tr_loss is    0.29.\n",
      " 93/200 [============>.................] - ETA: 1:33 - loss: 0.2950 - iou_score: 0.6859 - f1-score: 0.8118For batch 92, tr_loss is    0.29.\n",
      " 94/200 [=============>................] - ETA: 1:32 - loss: 0.2959 - iou_score: 0.6845 - f1-score: 0.8108For batch 93, tr_loss is    0.30.\n",
      " 95/200 [=============>................] - ETA: 1:31 - loss: 0.2970 - iou_score: 0.6839 - f1-score: 0.8104For batch 94, tr_loss is    0.30.\n",
      " 96/200 [=============>................] - ETA: 1:30 - loss: 0.2968 - iou_score: 0.6840 - f1-score: 0.8105For batch 95, tr_loss is    0.30.\n",
      " 97/200 [=============>................] - ETA: 1:29 - loss: 0.2976 - iou_score: 0.6831 - f1-score: 0.8098For batch 96, tr_loss is    0.30.\n",
      " 98/200 [=============>................] - ETA: 1:28 - loss: 0.2976 - iou_score: 0.6831 - f1-score: 0.8098For batch 97, tr_loss is    0.30.\n",
      " 99/200 [=============>................] - ETA: 1:28 - loss: 0.2973 - iou_score: 0.6834 - f1-score: 0.8100For batch 98, tr_loss is    0.30.\n",
      "100/200 [==============>...............] - ETA: 1:27 - loss: 0.2975 - iou_score: 0.6832 - f1-score: 0.8099For batch 99, tr_loss is    0.30.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/200 [==============>...............] - ETA: 1:26 - loss: 0.2975 - iou_score: 0.6833 - f1-score: 0.8100For batch 100, tr_loss is    0.30.\n",
      "102/200 [==============>...............] - ETA: 1:26 - loss: 0.2981 - iou_score: 0.6825 - f1-score: 0.8094For batch 101, tr_loss is    0.30.\n",
      "103/200 [==============>...............] - ETA: 1:25 - loss: 0.2984 - iou_score: 0.6822 - f1-score: 0.8092For batch 102, tr_loss is    0.30.\n",
      "104/200 [==============>...............] - ETA: 1:24 - loss: 0.2987 - iou_score: 0.6816 - f1-score: 0.8088For batch 103, tr_loss is    0.30.\n",
      "105/200 [==============>...............] - ETA: 1:23 - loss: 0.2988 - iou_score: 0.6813 - f1-score: 0.8086For batch 104, tr_loss is    0.30.\n",
      "106/200 [==============>...............] - ETA: 1:22 - loss: 0.2994 - iou_score: 0.6811 - f1-score: 0.8084For batch 105, tr_loss is    0.30.\n",
      "107/200 [===============>..............] - ETA: 1:22 - loss: 0.2996 - iou_score: 0.6806 - f1-score: 0.8081For batch 106, tr_loss is    0.30.\n",
      "108/200 [===============>..............] - ETA: 1:21 - loss: 0.2997 - iou_score: 0.6808 - f1-score: 0.8082For batch 107, tr_loss is    0.30.\n",
      "109/200 [===============>..............] - ETA: 1:20 - loss: 0.2998 - iou_score: 0.6807 - f1-score: 0.8082For batch 108, tr_loss is    0.30.\n",
      "110/200 [===============>..............] - ETA: 1:19 - loss: 0.2999 - iou_score: 0.6808 - f1-score: 0.8082For batch 109, tr_loss is    0.30.\n",
      "111/200 [===============>..............] - ETA: 1:18 - loss: 0.2992 - iou_score: 0.6816 - f1-score: 0.8088For batch 110, tr_loss is    0.30.\n",
      "112/200 [===============>..............] - ETA: 1:17 - loss: 0.2993 - iou_score: 0.6815 - f1-score: 0.8087For batch 111, tr_loss is    0.30.\n",
      "113/200 [===============>..............] - ETA: 1:17 - loss: 0.2999 - iou_score: 0.6804 - f1-score: 0.8079For batch 112, tr_loss is    0.30.\n",
      "114/200 [================>.............] - ETA: 1:15 - loss: 0.3004 - iou_score: 0.6798 - f1-score: 0.8074For batch 113, tr_loss is    0.30.\n",
      "115/200 [================>.............] - ETA: 1:14 - loss: 0.3006 - iou_score: 0.6797 - f1-score: 0.8073For batch 114, tr_loss is    0.30.\n",
      "116/200 [================>.............] - ETA: 1:13 - loss: 0.3009 - iou_score: 0.6791 - f1-score: 0.8069For batch 115, tr_loss is    0.30.\n",
      "117/200 [================>.............] - ETA: 1:13 - loss: 0.3010 - iou_score: 0.6791 - f1-score: 0.8069For batch 116, tr_loss is    0.30.\n",
      "118/200 [================>.............] - ETA: 1:12 - loss: 0.3009 - iou_score: 0.6793 - f1-score: 0.8071For batch 117, tr_loss is    0.30.\n",
      "119/200 [================>.............] - ETA: 1:11 - loss: 0.3012 - iou_score: 0.6789 - f1-score: 0.8068For batch 118, tr_loss is    0.30.\n",
      "120/200 [=================>............] - ETA: 1:10 - loss: 0.3009 - iou_score: 0.6793 - f1-score: 0.8071For batch 119, tr_loss is    0.30.\n",
      "121/200 [=================>............] - ETA: 1:09 - loss: 0.3008 - iou_score: 0.6795 - f1-score: 0.8072For batch 120, tr_loss is    0.30.\n",
      "122/200 [=================>............] - ETA: 1:08 - loss: 0.3007 - iou_score: 0.6797 - f1-score: 0.8073For batch 121, tr_loss is    0.30.\n",
      "123/200 [=================>............] - ETA: 1:07 - loss: 0.3014 - iou_score: 0.6790 - f1-score: 0.8068For batch 122, tr_loss is    0.30.\n",
      "124/200 [=================>............] - ETA: 1:06 - loss: 0.3016 - iou_score: 0.6788 - f1-score: 0.8066For batch 123, tr_loss is    0.30.\n",
      "125/200 [=================>............] - ETA: 1:06 - loss: 0.3017 - iou_score: 0.6786 - f1-score: 0.8065For batch 124, tr_loss is    0.30.\n",
      "126/200 [=================>............] - ETA: 1:05 - loss: 0.3015 - iou_score: 0.6788 - f1-score: 0.8067For batch 125, tr_loss is    0.30.\n",
      "127/200 [==================>...........] - ETA: 1:04 - loss: 0.3014 - iou_score: 0.6789 - f1-score: 0.8068For batch 126, tr_loss is    0.30.\n",
      "128/200 [==================>...........] - ETA: 1:03 - loss: 0.3024 - iou_score: 0.6777 - f1-score: 0.8058For batch 127, tr_loss is    0.30.\n",
      "129/200 [==================>...........] - ETA: 1:02 - loss: 0.3024 - iou_score: 0.6777 - f1-score: 0.8058For batch 128, tr_loss is    0.30.\n",
      "130/200 [==================>...........] - ETA: 1:01 - loss: 0.3022 - iou_score: 0.6779 - f1-score: 0.8060For batch 129, tr_loss is    0.30.\n",
      "131/200 [==================>...........] - ETA: 1:00 - loss: 0.3019 - iou_score: 0.6782 - f1-score: 0.8062For batch 130, tr_loss is    0.30.\n",
      "132/200 [==================>...........] - ETA: 59s - loss: 0.3015 - iou_score: 0.6787 - f1-score: 0.8066 For batch 131, tr_loss is    0.30.\n",
      "133/200 [==================>...........] - ETA: 59s - loss: 0.3017 - iou_score: 0.6784 - f1-score: 0.8063For batch 132, tr_loss is    0.30.\n",
      "134/200 [===================>..........] - ETA: 58s - loss: 0.3020 - iou_score: 0.6779 - f1-score: 0.8060For batch 133, tr_loss is    0.30.\n",
      "135/200 [===================>..........] - ETA: 57s - loss: 0.3024 - iou_score: 0.6776 - f1-score: 0.8057For batch 134, tr_loss is    0.30.\n",
      "136/200 [===================>..........] - ETA: 56s - loss: 0.3022 - iou_score: 0.6776 - f1-score: 0.8058For batch 135, tr_loss is    0.30.\n",
      "137/200 [===================>..........] - ETA: 55s - loss: 0.3032 - iou_score: 0.6767 - f1-score: 0.8051For batch 136, tr_loss is    0.30.\n",
      "138/200 [===================>..........] - ETA: 54s - loss: 0.3032 - iou_score: 0.6766 - f1-score: 0.8050For batch 137, tr_loss is    0.30.\n",
      "139/200 [===================>..........] - ETA: 53s - loss: 0.3029 - iou_score: 0.6769 - f1-score: 0.8052For batch 138, tr_loss is    0.30.\n",
      "140/200 [====================>.........] - ETA: 52s - loss: 0.3043 - iou_score: 0.6756 - f1-score: 0.8042For batch 139, tr_loss is    0.30.\n",
      "141/200 [====================>.........] - ETA: 52s - loss: 0.3047 - iou_score: 0.6753 - f1-score: 0.8039For batch 140, tr_loss is    0.30.\n",
      "142/200 [====================>.........] - ETA: 51s - loss: 0.3045 - iou_score: 0.6756 - f1-score: 0.8041For batch 141, tr_loss is    0.30.\n",
      "143/200 [====================>.........] - ETA: 50s - loss: 0.3044 - iou_score: 0.6756 - f1-score: 0.8042For batch 142, tr_loss is    0.30.\n",
      "144/200 [====================>.........] - ETA: 49s - loss: 0.3044 - iou_score: 0.6755 - f1-score: 0.8041For batch 143, tr_loss is    0.30.\n",
      "145/200 [====================>.........] - ETA: 48s - loss: 0.3045 - iou_score: 0.6753 - f1-score: 0.8039For batch 144, tr_loss is    0.30.\n",
      "146/200 [====================>.........] - ETA: 47s - loss: 0.3040 - iou_score: 0.6759 - f1-score: 0.8044For batch 145, tr_loss is    0.30.\n",
      "147/200 [=====================>........] - ETA: 46s - loss: 0.3042 - iou_score: 0.6757 - f1-score: 0.8042For batch 146, tr_loss is    0.30.\n",
      "148/200 [=====================>........] - ETA: 45s - loss: 0.3036 - iou_score: 0.6766 - f1-score: 0.8047For batch 147, tr_loss is    0.30.\n",
      "149/200 [=====================>........] - ETA: 44s - loss: 0.3032 - iou_score: 0.6769 - f1-score: 0.8050For batch 148, tr_loss is    0.30.\n",
      "150/200 [=====================>........] - ETA: 44s - loss: 0.3026 - iou_score: 0.6777 - f1-score: 0.8055For batch 149, tr_loss is    0.30.\n",
      "151/200 [=====================>........] - ETA: 43s - loss: 0.3028 - iou_score: 0.6774 - f1-score: 0.8053For batch 150, tr_loss is    0.30.\n",
      "152/200 [=====================>........] - ETA: 42s - loss: 0.3027 - iou_score: 0.6777 - f1-score: 0.8055For batch 151, tr_loss is    0.30.\n",
      "153/200 [=====================>........] - ETA: 41s - loss: 0.3024 - iou_score: 0.6779 - f1-score: 0.8057For batch 152, tr_loss is    0.30.\n",
      "154/200 [======================>.......] - ETA: 40s - loss: 0.3024 - iou_score: 0.6779 - f1-score: 0.8057For batch 153, tr_loss is    0.30.\n",
      "155/200 [======================>.......] - ETA: 39s - loss: 0.3023 - iou_score: 0.6781 - f1-score: 0.8058For batch 154, tr_loss is    0.30.\n",
      "156/200 [======================>.......] - ETA: 38s - loss: 0.3021 - iou_score: 0.6784 - f1-score: 0.8061For batch 155, tr_loss is    0.30.\n",
      "157/200 [======================>.......] - ETA: 37s - loss: 0.3023 - iou_score: 0.6783 - f1-score: 0.8060For batch 156, tr_loss is    0.30.\n",
      "158/200 [======================>.......] - ETA: 36s - loss: 0.3023 - iou_score: 0.6782 - f1-score: 0.8060For batch 157, tr_loss is    0.30.\n",
      "159/200 [======================>.......] - ETA: 35s - loss: 0.3025 - iou_score: 0.6780 - f1-score: 0.8058For batch 158, tr_loss is    0.30.\n",
      "160/200 [=======================>......] - ETA: 35s - loss: 0.3024 - iou_score: 0.6781 - f1-score: 0.8058For batch 159, tr_loss is    0.30.\n",
      "161/200 [=======================>......] - ETA: 34s - loss: 0.3024 - iou_score: 0.6780 - f1-score: 0.8058For batch 160, tr_loss is    0.30.\n",
      "162/200 [=======================>......] - ETA: 33s - loss: 0.3023 - iou_score: 0.6780 - f1-score: 0.8058For batch 161, tr_loss is    0.30.\n",
      "163/200 [=======================>......] - ETA: 32s - loss: 0.3020 - iou_score: 0.6782 - f1-score: 0.8060For batch 162, tr_loss is    0.30.\n",
      "164/200 [=======================>......] - ETA: 31s - loss: 0.3020 - iou_score: 0.6782 - f1-score: 0.8060For batch 163, tr_loss is    0.30.\n",
      "165/200 [=======================>......] - ETA: 30s - loss: 0.3018 - iou_score: 0.6784 - f1-score: 0.8061For batch 164, tr_loss is    0.30.\n",
      "166/200 [=======================>......] - ETA: 29s - loss: 0.3019 - iou_score: 0.6782 - f1-score: 0.8060For batch 165, tr_loss is    0.30.\n",
      "167/200 [========================>.....] - ETA: 29s - loss: 0.3013 - iou_score: 0.6790 - f1-score: 0.8066For batch 166, tr_loss is    0.30.\n",
      "168/200 [========================>.....] - ETA: 28s - loss: 0.3016 - iou_score: 0.6787 - f1-score: 0.8063For batch 167, tr_loss is    0.30.\n",
      "169/200 [========================>.....] - ETA: 27s - loss: 0.3018 - iou_score: 0.6783 - f1-score: 0.8060For batch 168, tr_loss is    0.30.\n",
      "170/200 [========================>.....] - ETA: 26s - loss: 0.3014 - iou_score: 0.6788 - f1-score: 0.8064For batch 169, tr_loss is    0.30.\n",
      "171/200 [========================>.....] - ETA: 25s - loss: 0.3015 - iou_score: 0.6787 - f1-score: 0.8063For batch 170, tr_loss is    0.30.\n",
      "172/200 [========================>.....] - ETA: 24s - loss: 0.3013 - iou_score: 0.6791 - f1-score: 0.8066For batch 171, tr_loss is    0.30.\n",
      "173/200 [========================>.....] - ETA: 23s - loss: 0.3013 - iou_score: 0.6792 - f1-score: 0.8067For batch 172, tr_loss is    0.30.\n",
      "174/200 [=========================>....] - ETA: 22s - loss: 0.3010 - iou_score: 0.6795 - f1-score: 0.8068For batch 173, tr_loss is    0.30.\n",
      "175/200 [=========================>....] - ETA: 22s - loss: 0.3008 - iou_score: 0.6797 - f1-score: 0.8070For batch 174, tr_loss is    0.30.\n",
      "176/200 [=========================>....] - ETA: 21s - loss: 0.3010 - iou_score: 0.6795 - f1-score: 0.8069For batch 175, tr_loss is    0.30.\n",
      "177/200 [=========================>....] - ETA: 20s - loss: 0.3008 - iou_score: 0.6797 - f1-score: 0.8070For batch 176, tr_loss is    0.30.\n",
      "178/200 [=========================>....] - ETA: 19s - loss: 0.3010 - iou_score: 0.6792 - f1-score: 0.8067For batch 177, tr_loss is    0.30.\n",
      "179/200 [=========================>....] - ETA: 18s - loss: 0.3007 - iou_score: 0.6796 - f1-score: 0.8070For batch 178, tr_loss is    0.30.\n",
      "180/200 [==========================>...] - ETA: 17s - loss: 0.3006 - iou_score: 0.6796 - f1-score: 0.8070For batch 179, tr_loss is    0.30.\n",
      "181/200 [==========================>...] - ETA: 16s - loss: 0.3009 - iou_score: 0.6794 - f1-score: 0.8068For batch 180, tr_loss is    0.30.\n",
      "182/200 [==========================>...] - ETA: 15s - loss: 0.3009 - iou_score: 0.6793 - f1-score: 0.8068For batch 181, tr_loss is    0.30.\n",
      "183/200 [==========================>...] - ETA: 14s - loss: 0.3010 - iou_score: 0.6792 - f1-score: 0.8067For batch 182, tr_loss is    0.30.\n",
      "184/200 [==========================>...] - ETA: 14s - loss: 0.3007 - iou_score: 0.6795 - f1-score: 0.8069For batch 183, tr_loss is    0.30.\n",
      "185/200 [==========================>...] - ETA: 13s - loss: 0.3005 - iou_score: 0.6797 - f1-score: 0.8070For batch 184, tr_loss is    0.30.\n",
      "186/200 [==========================>...] - ETA: 12s - loss: 0.3004 - iou_score: 0.6799 - f1-score: 0.8072For batch 185, tr_loss is    0.30.\n",
      "187/200 [===========================>..] - ETA: 11s - loss: 0.3001 - iou_score: 0.6802 - f1-score: 0.8074For batch 186, tr_loss is    0.30.\n",
      "188/200 [===========================>..] - ETA: 10s - loss: 0.3000 - iou_score: 0.6803 - f1-score: 0.8075For batch 187, tr_loss is    0.30.\n",
      "189/200 [===========================>..] - ETA: 9s - loss: 0.3002 - iou_score: 0.6801 - f1-score: 0.8073 For batch 188, tr_loss is    0.30.\n",
      "190/200 [===========================>..] - ETA: 8s - loss: 0.3001 - iou_score: 0.6802 - f1-score: 0.8074For batch 189, tr_loss is    0.30.\n",
      "191/200 [===========================>..] - ETA: 7s - loss: 0.3006 - iou_score: 0.6797 - f1-score: 0.8070For batch 190, tr_loss is    0.30.\n",
      "192/200 [===========================>..] - ETA: 7s - loss: 0.3010 - iou_score: 0.6793 - f1-score: 0.8067For batch 191, tr_loss is    0.30.\n",
      "193/200 [===========================>..] - ETA: 6s - loss: 0.3008 - iou_score: 0.6796 - f1-score: 0.8069For batch 192, tr_loss is    0.30.\n",
      "194/200 [============================>.] - ETA: 5s - loss: 0.3012 - iou_score: 0.6793 - f1-score: 0.8067For batch 193, tr_loss is    0.30.\n",
      "195/200 [============================>.] - ETA: 4s - loss: 0.3014 - iou_score: 0.6792 - f1-score: 0.8067For batch 194, tr_loss is    0.30.\n",
      "196/200 [============================>.] - ETA: 3s - loss: 0.3016 - iou_score: 0.6789 - f1-score: 0.8065For batch 195, tr_loss is    0.30.\n",
      "197/200 [============================>.] - ETA: 2s - loss: 0.3012 - iou_score: 0.6795 - f1-score: 0.8068For batch 196, tr_loss is    0.30.\n",
      "198/200 [============================>.] - ETA: 1s - loss: 0.3012 - iou_score: 0.6796 - f1-score: 0.8070For batch 197, tr_loss is    0.30.\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.3015 - iou_score: 0.6794 - f1-score: 0.8068For batch 198, tr_loss is    0.30.\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.3014 - iou_score: 0.6793 - f1-score: 0.8067For batch 199, tr_loss is    0.30.\n",
      "For batch 0, vl_loss is    0.40.\n",
      "For batch 1, vl_loss is    0.42.\n",
      "For batch 2, vl_loss is    0.42.\n",
      "For batch 3, vl_loss is    0.41.\n",
      "For batch 4, vl_loss is    0.40.\n",
      "For batch 5, vl_loss is    0.41.\n",
      "For batch 6, vl_loss is    0.42.\n",
      "For batch 7, vl_loss is    0.42.\n",
      "For batch 8, vl_loss is    0.43.\n",
      "For batch 9, vl_loss is    0.42.\n",
      "For batch 10, vl_loss is    0.44.\n",
      "For batch 11, vl_loss is    0.43.\n",
      "For batch 12, vl_loss is    0.43.\n",
      "For batch 13, vl_loss is    0.43.\n",
      "For batch 14, vl_loss is    0.43.\n",
      "For batch 15, vl_loss is    0.43.\n",
      "For batch 16, vl_loss is    0.42.\n",
      "For batch 17, vl_loss is    0.42.\n",
      "For batch 18, vl_loss is    0.42.\n",
      "For batch 19, vl_loss is    0.42.\n",
      "For batch 20, vl_loss is    0.42.\n",
      "For batch 21, vl_loss is    0.42.\n",
      "For batch 22, vl_loss is    0.42.\n",
      "For batch 23, vl_loss is    0.42.\n",
      "For batch 24, vl_loss is    0.42.\n",
      "For batch 25, vl_loss is    0.42.\n",
      "For batch 26, vl_loss is    0.42.\n",
      "For batch 27, vl_loss is    0.42.\n",
      "For batch 28, vl_loss is    0.42.\n",
      "For batch 29, vl_loss is    0.42.\n",
      "For batch 30, vl_loss is    0.42.\n",
      "For batch 31, vl_loss is    0.42.\n",
      "For batch 32, vl_loss is    0.42.\n",
      "For batch 33, vl_loss is    0.42.\n",
      "For batch 34, vl_loss is    0.42.\n",
      "For batch 35, vl_loss is    0.42.\n",
      "For batch 36, vl_loss is    0.42.\n",
      "For batch 37, vl_loss is    0.42.\n",
      "For batch 38, vl_loss is    0.41.\n",
      "For batch 39, vl_loss is    0.42.\n",
      "For batch 40, vl_loss is    0.42.\n",
      "For batch 41, vl_loss is    0.42.\n",
      "For batch 42, vl_loss is    0.41.\n",
      "For batch 43, vl_loss is    0.41.\n",
      "For batch 44, vl_loss is    0.41.\n",
      "For batch 45, vl_loss is    0.41.\n",
      "For batch 46, vl_loss is    0.42.\n",
      "For batch 47, vl_loss is    0.41.\n",
      "For batch 48, vl_loss is    0.41.\n",
      "For batch 49, vl_loss is    0.41.\n",
      "For batch 50, vl_loss is    0.41.\n",
      "For batch 51, vl_loss is    0.41.\n",
      "For batch 52, vl_loss is    0.41.\n",
      "For batch 53, vl_loss is    0.41.\n",
      "For batch 54, vl_loss is    0.41.\n",
      "For batch 55, vl_loss is    0.41.\n",
      "For batch 56, vl_loss is    0.41.\n",
      "For batch 57, vl_loss is    0.41.\n",
      "For batch 58, vl_loss is    0.41.\n",
      "For batch 59, vl_loss is    0.41.\n",
      "For batch 60, vl_loss is    0.41.\n",
      "For batch 61, vl_loss is    0.41.\n",
      "For batch 62, vl_loss is    0.41.\n",
      "For batch 63, vl_loss is    0.41.\n",
      "For batch 64, vl_loss is    0.41.\n",
      "For batch 65, vl_loss is    0.41.\n",
      "For batch 66, vl_loss is    0.41.\n",
      "For batch 67, vl_loss is    0.41.\n",
      "For batch 68, vl_loss is    0.41.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 69, vl_loss is    0.42.\n",
      "For batch 70, vl_loss is    0.41.\n",
      "For batch 71, vl_loss is    0.41.\n",
      "For batch 72, vl_loss is    0.41.\n",
      "For batch 73, vl_loss is    0.41.\n",
      "For batch 74, vl_loss is    0.41.\n",
      "For batch 75, vl_loss is    0.41.\n",
      "For batch 76, vl_loss is    0.41.\n",
      "For batch 77, vl_loss is    0.41.\n",
      "For batch 78, vl_loss is    0.42.\n",
      "For batch 79, vl_loss is    0.42.\n",
      "For batch 80, vl_loss is    0.41.\n",
      "For batch 81, vl_loss is    0.41.\n",
      "For batch 82, vl_loss is    0.41.\n",
      "For batch 83, vl_loss is    0.41.\n",
      "For batch 84, vl_loss is    0.41.\n",
      "For batch 85, vl_loss is    0.41.\n",
      "For batch 86, vl_loss is    0.41.\n",
      "For batch 87, vl_loss is    0.41.\n",
      "For batch 88, vl_loss is    0.41.\n",
      "For batch 89, vl_loss is    0.41.\n",
      "For batch 90, vl_loss is    0.41.\n",
      "For batch 91, vl_loss is    0.41.\n",
      "For batch 92, vl_loss is    0.41.\n",
      "For batch 93, vl_loss is    0.41.\n",
      "For batch 94, vl_loss is    0.41.\n",
      "For batch 95, vl_loss is    0.41.\n",
      "For batch 96, vl_loss is    0.41.\n",
      "For batch 97, vl_loss is    0.41.\n",
      "For batch 98, vl_loss is    0.41.\n",
      "For batch 99, vl_loss is    0.42.\n",
      "200/200 [==============================] - 181s 897ms/step - loss: 0.3014 - iou_score: 0.6793 - f1-score: 0.8067 - val_loss: 0.4154 - val_iou_score: 0.5645 - val_f1-score: 0.7179\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.32441\n",
      "The average loss for epoch 8 is    0.30 \n",
      "Epoch 10/200\n",
      "  1/200 [..............................] - ETA: 10:32 - loss: 0.2874 - iou_score: 0.6891 - f1-score: 0.8159For batch 0, tr_loss is    0.29.\n",
      "  2/200 [..............................] - ETA: 4:29 - loss: 0.2857 - iou_score: 0.6961 - f1-score: 0.8207 For batch 1, tr_loss is    0.29.\n",
      "  3/200 [..............................] - ETA: 4:19 - loss: 0.2833 - iou_score: 0.7012 - f1-score: 0.8241For batch 2, tr_loss is    0.28.\n",
      "  4/200 [..............................] - ETA: 4:23 - loss: 0.2893 - iou_score: 0.6900 - f1-score: 0.8161For batch 3, tr_loss is    0.29.\n",
      "  5/200 [..............................] - ETA: 4:11 - loss: 0.2868 - iou_score: 0.6957 - f1-score: 0.8199For batch 4, tr_loss is    0.29.\n",
      "  6/200 [..............................] - ETA: 4:14 - loss: 0.2971 - iou_score: 0.6833 - f1-score: 0.8109For batch 5, tr_loss is    0.30.\n",
      "  7/200 [>.............................] - ETA: 4:10 - loss: 0.3004 - iou_score: 0.6766 - f1-score: 0.8056For batch 6, tr_loss is    0.30.\n",
      "  8/200 [>.............................] - ETA: 3:56 - loss: 0.3040 - iou_score: 0.6729 - f1-score: 0.8028For batch 7, tr_loss is    0.30.\n",
      "  9/200 [>.............................] - ETA: 3:42 - loss: 0.3016 - iou_score: 0.6786 - f1-score: 0.8068For batch 8, tr_loss is    0.30.\n",
      " 10/200 [>.............................] - ETA: 3:32 - loss: 0.3015 - iou_score: 0.6788 - f1-score: 0.8067For batch 9, tr_loss is    0.30.\n",
      " 11/200 [>.............................] - ETA: 3:21 - loss: 0.2995 - iou_score: 0.6799 - f1-score: 0.8076For batch 10, tr_loss is    0.30.\n",
      " 12/200 [>.............................] - ETA: 3:21 - loss: 0.3027 - iou_score: 0.6743 - f1-score: 0.8035For batch 11, tr_loss is    0.30.\n",
      " 13/200 [>.............................] - ETA: 3:13 - loss: 0.3049 - iou_score: 0.6703 - f1-score: 0.8006For batch 12, tr_loss is    0.30.\n",
      " 14/200 [=>............................] - ETA: 3:12 - loss: 0.3037 - iou_score: 0.6717 - f1-score: 0.8017For batch 13, tr_loss is    0.30.\n",
      " 15/200 [=>............................] - ETA: 3:06 - loss: 0.3014 - iou_score: 0.6733 - f1-score: 0.8029For batch 14, tr_loss is    0.30.\n",
      " 16/200 [=>............................] - ETA: 3:05 - loss: 0.3019 - iou_score: 0.6722 - f1-score: 0.8022For batch 15, tr_loss is    0.30.\n",
      " 17/200 [=>............................] - ETA: 3:03 - loss: 0.3007 - iou_score: 0.6746 - f1-score: 0.8039For batch 16, tr_loss is    0.30.\n",
      " 18/200 [=>............................] - ETA: 3:03 - loss: 0.2986 - iou_score: 0.6774 - f1-score: 0.8060For batch 17, tr_loss is    0.30.\n",
      " 19/200 [=>............................] - ETA: 3:03 - loss: 0.2993 - iou_score: 0.6755 - f1-score: 0.8043For batch 18, tr_loss is    0.30.\n",
      " 20/200 [==>...........................] - ETA: 3:02 - loss: 0.2963 - iou_score: 0.6796 - f1-score: 0.8072For batch 19, tr_loss is    0.30.\n",
      " 21/200 [==>...........................] - ETA: 2:56 - loss: 0.2942 - iou_score: 0.6829 - f1-score: 0.8095For batch 20, tr_loss is    0.29.\n",
      " 22/200 [==>...........................] - ETA: 2:54 - loss: 0.2923 - iou_score: 0.6851 - f1-score: 0.8111For batch 21, tr_loss is    0.29.\n",
      " 23/200 [==>...........................] - ETA: 2:51 - loss: 0.2909 - iou_score: 0.6871 - f1-score: 0.8125For batch 22, tr_loss is    0.29.\n",
      " 24/200 [==>...........................] - ETA: 2:48 - loss: 0.2904 - iou_score: 0.6886 - f1-score: 0.8136For batch 23, tr_loss is    0.29.\n",
      " 25/200 [==>...........................] - ETA: 2:46 - loss: 0.2895 - iou_score: 0.6898 - f1-score: 0.8145For batch 24, tr_loss is    0.29.\n",
      " 26/200 [==>...........................] - ETA: 2:46 - loss: 0.2929 - iou_score: 0.6879 - f1-score: 0.8132For batch 25, tr_loss is    0.29.\n",
      " 27/200 [===>..........................] - ETA: 2:44 - loss: 0.2920 - iou_score: 0.6886 - f1-score: 0.8138For batch 26, tr_loss is    0.29.\n",
      " 28/200 [===>..........................] - ETA: 2:40 - loss: 0.2930 - iou_score: 0.6885 - f1-score: 0.8137For batch 27, tr_loss is    0.29.\n",
      " 29/200 [===>..........................] - ETA: 2:37 - loss: 0.2941 - iou_score: 0.6867 - f1-score: 0.8124For batch 28, tr_loss is    0.29.\n",
      " 30/200 [===>..........................] - ETA: 2:39 - loss: 0.2924 - iou_score: 0.6893 - f1-score: 0.8142For batch 29, tr_loss is    0.29.\n",
      " 31/200 [===>..........................] - ETA: 2:36 - loss: 0.2912 - iou_score: 0.6908 - f1-score: 0.8152For batch 30, tr_loss is    0.29.\n",
      " 32/200 [===>..........................] - ETA: 2:34 - loss: 0.2899 - iou_score: 0.6923 - f1-score: 0.8163For batch 31, tr_loss is    0.29.\n",
      " 33/200 [===>..........................] - ETA: 2:32 - loss: 0.2882 - iou_score: 0.6937 - f1-score: 0.8173For batch 32, tr_loss is    0.29.\n",
      " 34/200 [====>.........................] - ETA: 2:32 - loss: 0.2892 - iou_score: 0.6927 - f1-score: 0.8167For batch 33, tr_loss is    0.29.\n",
      " 35/200 [====>.........................] - ETA: 2:30 - loss: 0.2883 - iou_score: 0.6942 - f1-score: 0.8177For batch 34, tr_loss is    0.29.\n",
      " 36/200 [====>.........................] - ETA: 2:30 - loss: 0.2883 - iou_score: 0.6941 - f1-score: 0.8176For batch 35, tr_loss is    0.29.\n",
      " 37/200 [====>.........................] - ETA: 2:29 - loss: 0.2899 - iou_score: 0.6931 - f1-score: 0.8169For batch 36, tr_loss is    0.29.\n",
      " 38/200 [====>.........................] - ETA: 2:26 - loss: 0.2905 - iou_score: 0.6914 - f1-score: 0.8158For batch 37, tr_loss is    0.29.\n",
      " 39/200 [====>.........................] - ETA: 2:24 - loss: 0.2905 - iou_score: 0.6916 - f1-score: 0.8159For batch 38, tr_loss is    0.29.\n",
      " 40/200 [=====>........................] - ETA: 2:23 - loss: 0.2894 - iou_score: 0.6929 - f1-score: 0.8168For batch 39, tr_loss is    0.29.\n",
      " 41/200 [=====>........................] - ETA: 2:23 - loss: 0.2888 - iou_score: 0.6930 - f1-score: 0.8169For batch 40, tr_loss is    0.29.\n",
      " 42/200 [=====>........................] - ETA: 2:21 - loss: 0.2894 - iou_score: 0.6923 - f1-score: 0.8164For batch 41, tr_loss is    0.29.\n",
      " 43/200 [=====>........................] - ETA: 2:21 - loss: 0.2896 - iou_score: 0.6922 - f1-score: 0.8163For batch 42, tr_loss is    0.29.\n",
      " 44/200 [=====>........................] - ETA: 2:20 - loss: 0.2886 - iou_score: 0.6937 - f1-score: 0.8174For batch 43, tr_loss is    0.29.\n",
      " 45/200 [=====>........................] - ETA: 2:20 - loss: 0.2886 - iou_score: 0.6935 - f1-score: 0.8172For batch 44, tr_loss is    0.29.\n",
      " 46/200 [=====>........................] - ETA: 2:19 - loss: 0.2896 - iou_score: 0.6929 - f1-score: 0.8168For batch 45, tr_loss is    0.29.\n",
      " 47/200 [======>.......................] - ETA: 2:18 - loss: 0.2897 - iou_score: 0.6926 - f1-score: 0.8165For batch 46, tr_loss is    0.29.\n",
      " 48/200 [======>.......................] - ETA: 2:16 - loss: 0.2897 - iou_score: 0.6926 - f1-score: 0.8166For batch 47, tr_loss is    0.29.\n",
      " 49/200 [======>.......................] - ETA: 2:16 - loss: 0.2896 - iou_score: 0.6926 - f1-score: 0.8165For batch 48, tr_loss is    0.29.\n",
      " 50/200 [======>.......................] - ETA: 2:15 - loss: 0.2876 - iou_score: 0.6950 - f1-score: 0.8182For batch 49, tr_loss is    0.29.\n",
      " 51/200 [======>.......................] - ETA: 2:14 - loss: 0.2871 - iou_score: 0.6960 - f1-score: 0.8188For batch 50, tr_loss is    0.29.\n",
      " 52/200 [======>.......................] - ETA: 2:13 - loss: 0.2876 - iou_score: 0.6955 - f1-score: 0.8184For batch 51, tr_loss is    0.29.\n",
      " 53/200 [======>.......................] - ETA: 2:13 - loss: 0.2876 - iou_score: 0.6955 - f1-score: 0.8184For batch 52, tr_loss is    0.29.\n",
      " 54/200 [=======>......................] - ETA: 2:12 - loss: 0.2882 - iou_score: 0.6949 - f1-score: 0.8180For batch 53, tr_loss is    0.29.\n",
      " 55/200 [=======>......................] - ETA: 2:11 - loss: 0.2873 - iou_score: 0.6957 - f1-score: 0.8186For batch 54, tr_loss is    0.29.\n",
      " 56/200 [=======>......................] - ETA: 2:11 - loss: 0.2878 - iou_score: 0.6954 - f1-score: 0.8185For batch 55, tr_loss is    0.29.\n",
      " 57/200 [=======>......................] - ETA: 2:10 - loss: 0.2874 - iou_score: 0.6954 - f1-score: 0.8185For batch 56, tr_loss is    0.29.\n",
      " 58/200 [=======>......................] - ETA: 2:10 - loss: 0.2871 - iou_score: 0.6959 - f1-score: 0.8188For batch 57, tr_loss is    0.29.\n",
      " 59/200 [=======>......................] - ETA: 2:09 - loss: 0.2863 - iou_score: 0.6970 - f1-score: 0.8196For batch 58, tr_loss is    0.29.\n",
      " 60/200 [========>.....................] - ETA: 2:07 - loss: 0.2859 - iou_score: 0.6970 - f1-score: 0.8196For batch 59, tr_loss is    0.29.\n",
      " 61/200 [========>.....................] - ETA: 2:05 - loss: 0.2868 - iou_score: 0.6960 - f1-score: 0.8190For batch 60, tr_loss is    0.29.\n",
      " 62/200 [========>.....................] - ETA: 2:05 - loss: 0.2872 - iou_score: 0.6955 - f1-score: 0.8186For batch 61, tr_loss is    0.29.\n",
      " 63/200 [========>.....................] - ETA: 2:04 - loss: 0.2867 - iou_score: 0.6961 - f1-score: 0.8190For batch 62, tr_loss is    0.29.\n",
      " 64/200 [========>.....................] - ETA: 2:02 - loss: 0.2878 - iou_score: 0.6947 - f1-score: 0.8180For batch 63, tr_loss is    0.29.\n",
      " 65/200 [========>.....................] - ETA: 2:01 - loss: 0.2866 - iou_score: 0.6961 - f1-score: 0.8190For batch 64, tr_loss is    0.29.\n",
      " 66/200 [========>.....................] - ETA: 2:00 - loss: 0.2881 - iou_score: 0.6942 - f1-score: 0.8175For batch 65, tr_loss is    0.29.\n",
      " 67/200 [=========>....................] - ETA: 1:59 - loss: 0.2875 - iou_score: 0.6952 - f1-score: 0.8183For batch 66, tr_loss is    0.29.\n",
      " 68/200 [=========>....................] - ETA: 1:58 - loss: 0.2874 - iou_score: 0.6953 - f1-score: 0.8183For batch 67, tr_loss is    0.29.\n",
      " 69/200 [=========>....................] - ETA: 1:56 - loss: 0.2884 - iou_score: 0.6937 - f1-score: 0.8171For batch 68, tr_loss is    0.29.\n",
      " 70/200 [=========>....................] - ETA: 1:56 - loss: 0.2880 - iou_score: 0.6942 - f1-score: 0.8175For batch 69, tr_loss is    0.29.\n",
      " 71/200 [=========>....................] - ETA: 1:55 - loss: 0.2880 - iou_score: 0.6947 - f1-score: 0.8179For batch 70, tr_loss is    0.29.\n",
      " 72/200 [=========>....................] - ETA: 1:55 - loss: 0.2881 - iou_score: 0.6946 - f1-score: 0.8178For batch 71, tr_loss is    0.29.\n",
      " 73/200 [=========>....................] - ETA: 1:54 - loss: 0.2876 - iou_score: 0.6952 - f1-score: 0.8182For batch 72, tr_loss is    0.29.\n",
      " 74/200 [==========>...................] - ETA: 1:53 - loss: 0.2878 - iou_score: 0.6948 - f1-score: 0.8180For batch 73, tr_loss is    0.29.\n",
      " 75/200 [==========>...................] - ETA: 1:52 - loss: 0.2886 - iou_score: 0.6939 - f1-score: 0.8173For batch 74, tr_loss is    0.29.\n",
      " 76/200 [==========>...................] - ETA: 1:51 - loss: 0.2887 - iou_score: 0.6937 - f1-score: 0.8172For batch 75, tr_loss is    0.29.\n",
      " 77/200 [==========>...................] - ETA: 1:50 - loss: 0.2888 - iou_score: 0.6934 - f1-score: 0.8170For batch 76, tr_loss is    0.29.\n",
      " 78/200 [==========>...................] - ETA: 1:49 - loss: 0.2883 - iou_score: 0.6937 - f1-score: 0.8172For batch 77, tr_loss is    0.29.\n",
      " 79/200 [==========>...................] - ETA: 1:48 - loss: 0.2883 - iou_score: 0.6938 - f1-score: 0.8173For batch 78, tr_loss is    0.29.\n",
      " 80/200 [===========>..................] - ETA: 1:47 - loss: 0.2881 - iou_score: 0.6941 - f1-score: 0.8175For batch 79, tr_loss is    0.29.\n",
      " 81/200 [===========>..................] - ETA: 1:46 - loss: 0.2870 - iou_score: 0.6954 - f1-score: 0.8184For batch 80, tr_loss is    0.29.\n",
      " 82/200 [===========>..................] - ETA: 1:45 - loss: 0.2869 - iou_score: 0.6954 - f1-score: 0.8184For batch 81, tr_loss is    0.29.\n",
      " 83/200 [===========>..................] - ETA: 1:45 - loss: 0.2872 - iou_score: 0.6951 - f1-score: 0.8182For batch 82, tr_loss is    0.29.\n",
      " 84/200 [===========>..................] - ETA: 1:44 - loss: 0.2870 - iou_score: 0.6952 - f1-score: 0.8183For batch 83, tr_loss is    0.29.\n",
      " 85/200 [===========>..................] - ETA: 1:43 - loss: 0.2878 - iou_score: 0.6942 - f1-score: 0.8175For batch 84, tr_loss is    0.29.\n",
      " 86/200 [===========>..................] - ETA: 1:42 - loss: 0.2883 - iou_score: 0.6933 - f1-score: 0.8169For batch 85, tr_loss is    0.29.\n",
      " 87/200 [============>.................] - ETA: 1:42 - loss: 0.2879 - iou_score: 0.6938 - f1-score: 0.8172For batch 86, tr_loss is    0.29.\n",
      " 88/200 [============>.................] - ETA: 1:41 - loss: 0.2879 - iou_score: 0.6939 - f1-score: 0.8173For batch 87, tr_loss is    0.29.\n",
      " 89/200 [============>.................] - ETA: 1:40 - loss: 0.2886 - iou_score: 0.6931 - f1-score: 0.8168For batch 88, tr_loss is    0.29.\n",
      " 90/200 [============>.................] - ETA: 1:39 - loss: 0.2889 - iou_score: 0.6930 - f1-score: 0.8167For batch 89, tr_loss is    0.29.\n",
      " 91/200 [============>.................] - ETA: 1:39 - loss: 0.2888 - iou_score: 0.6928 - f1-score: 0.8166For batch 90, tr_loss is    0.29.\n",
      " 92/200 [============>.................] - ETA: 1:37 - loss: 0.2893 - iou_score: 0.6921 - f1-score: 0.8161For batch 91, tr_loss is    0.29.\n",
      " 93/200 [============>.................] - ETA: 1:36 - loss: 0.2894 - iou_score: 0.6920 - f1-score: 0.8160For batch 92, tr_loss is    0.29.\n",
      " 94/200 [=============>................] - ETA: 1:35 - loss: 0.2907 - iou_score: 0.6902 - f1-score: 0.8147For batch 93, tr_loss is    0.29.\n",
      " 95/200 [=============>................] - ETA: 1:34 - loss: 0.2912 - iou_score: 0.6897 - f1-score: 0.8143For batch 94, tr_loss is    0.29.\n",
      " 96/200 [=============>................] - ETA: 1:33 - loss: 0.2908 - iou_score: 0.6900 - f1-score: 0.8146For batch 95, tr_loss is    0.29.\n",
      " 97/200 [=============>................] - ETA: 1:33 - loss: 0.2913 - iou_score: 0.6893 - f1-score: 0.8140For batch 96, tr_loss is    0.29.\n",
      " 98/200 [=============>................] - ETA: 1:31 - loss: 0.2916 - iou_score: 0.6892 - f1-score: 0.8139For batch 97, tr_loss is    0.29.\n",
      " 99/200 [=============>................] - ETA: 1:31 - loss: 0.2914 - iou_score: 0.6894 - f1-score: 0.8141For batch 98, tr_loss is    0.29.\n",
      "100/200 [==============>...............] - ETA: 1:30 - loss: 0.2917 - iou_score: 0.6893 - f1-score: 0.8141For batch 99, tr_loss is    0.29.\n",
      "101/200 [==============>...............] - ETA: 1:29 - loss: 0.2919 - iou_score: 0.6893 - f1-score: 0.8141For batch 100, tr_loss is    0.29.\n",
      "102/200 [==============>...............] - ETA: 1:28 - loss: 0.2923 - iou_score: 0.6887 - f1-score: 0.8137For batch 101, tr_loss is    0.29.\n",
      "103/200 [==============>...............] - ETA: 1:27 - loss: 0.2927 - iou_score: 0.6884 - f1-score: 0.8135For batch 102, tr_loss is    0.29.\n",
      "104/200 [==============>...............] - ETA: 1:26 - loss: 0.2929 - iou_score: 0.6879 - f1-score: 0.8131For batch 103, tr_loss is    0.29.\n",
      "105/200 [==============>...............] - ETA: 1:26 - loss: 0.2931 - iou_score: 0.6877 - f1-score: 0.8130For batch 104, tr_loss is    0.29.\n",
      "106/200 [==============>...............] - ETA: 1:25 - loss: 0.2934 - iou_score: 0.6874 - f1-score: 0.8128For batch 105, tr_loss is    0.29.\n",
      "107/200 [===============>..............] - ETA: 1:24 - loss: 0.2938 - iou_score: 0.6868 - f1-score: 0.8123For batch 106, tr_loss is    0.29.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/200 [===============>..............] - ETA: 1:23 - loss: 0.2935 - iou_score: 0.6871 - f1-score: 0.8126For batch 107, tr_loss is    0.29.\n",
      "109/200 [===============>..............] - ETA: 1:22 - loss: 0.2935 - iou_score: 0.6873 - f1-score: 0.8127For batch 108, tr_loss is    0.29.\n",
      "110/200 [===============>..............] - ETA: 1:21 - loss: 0.2933 - iou_score: 0.6876 - f1-score: 0.8130For batch 109, tr_loss is    0.29.\n",
      "111/200 [===============>..............] - ETA: 1:21 - loss: 0.2927 - iou_score: 0.6882 - f1-score: 0.8134For batch 110, tr_loss is    0.29.\n",
      "112/200 [===============>..............] - ETA: 1:20 - loss: 0.2927 - iou_score: 0.6881 - f1-score: 0.8133For batch 111, tr_loss is    0.29.\n",
      "113/200 [===============>..............] - ETA: 1:19 - loss: 0.2936 - iou_score: 0.6869 - f1-score: 0.8123For batch 112, tr_loss is    0.29.\n",
      "114/200 [================>.............] - ETA: 1:18 - loss: 0.2947 - iou_score: 0.6860 - f1-score: 0.8116For batch 113, tr_loss is    0.29.\n",
      "115/200 [================>.............] - ETA: 1:17 - loss: 0.2947 - iou_score: 0.6860 - f1-score: 0.8116For batch 114, tr_loss is    0.29.\n",
      "116/200 [================>.............] - ETA: 1:16 - loss: 0.2952 - iou_score: 0.6853 - f1-score: 0.8111For batch 115, tr_loss is    0.30.\n",
      "117/200 [================>.............] - ETA: 1:15 - loss: 0.2954 - iou_score: 0.6852 - f1-score: 0.8111For batch 116, tr_loss is    0.30.\n",
      "118/200 [================>.............] - ETA: 1:14 - loss: 0.2952 - iou_score: 0.6854 - f1-score: 0.8112For batch 117, tr_loss is    0.30.\n",
      "119/200 [================>.............] - ETA: 1:13 - loss: 0.2956 - iou_score: 0.6850 - f1-score: 0.8109For batch 118, tr_loss is    0.30.\n",
      "120/200 [=================>............] - ETA: 1:12 - loss: 0.2954 - iou_score: 0.6852 - f1-score: 0.8111For batch 119, tr_loss is    0.30.\n",
      "121/200 [=================>............] - ETA: 1:11 - loss: 0.2953 - iou_score: 0.6856 - f1-score: 0.8114For batch 120, tr_loss is    0.30.\n",
      "122/200 [=================>............] - ETA: 1:10 - loss: 0.2951 - iou_score: 0.6857 - f1-score: 0.8114For batch 121, tr_loss is    0.30.\n",
      "123/200 [=================>............] - ETA: 1:09 - loss: 0.2958 - iou_score: 0.6849 - f1-score: 0.8109For batch 122, tr_loss is    0.30.\n",
      "124/200 [=================>............] - ETA: 1:08 - loss: 0.2960 - iou_score: 0.6847 - f1-score: 0.8107For batch 123, tr_loss is    0.30.\n",
      "125/200 [=================>............] - ETA: 1:07 - loss: 0.2961 - iou_score: 0.6845 - f1-score: 0.8106For batch 124, tr_loss is    0.30.\n",
      "126/200 [=================>............] - ETA: 1:06 - loss: 0.2960 - iou_score: 0.6847 - f1-score: 0.8108For batch 125, tr_loss is    0.30.\n",
      "127/200 [==================>...........] - ETA: 1:05 - loss: 0.2959 - iou_score: 0.6848 - f1-score: 0.8108For batch 126, tr_loss is    0.30.\n",
      "128/200 [==================>...........] - ETA: 1:04 - loss: 0.2967 - iou_score: 0.6838 - f1-score: 0.8101For batch 127, tr_loss is    0.30.\n",
      "129/200 [==================>...........] - ETA: 1:03 - loss: 0.2967 - iou_score: 0.6838 - f1-score: 0.8101For batch 128, tr_loss is    0.30.\n",
      "130/200 [==================>...........] - ETA: 1:03 - loss: 0.2965 - iou_score: 0.6840 - f1-score: 0.8103For batch 129, tr_loss is    0.30.\n",
      "131/200 [==================>...........] - ETA: 1:02 - loss: 0.2961 - iou_score: 0.6843 - f1-score: 0.8105For batch 130, tr_loss is    0.30.\n",
      "132/200 [==================>...........] - ETA: 1:01 - loss: 0.2957 - iou_score: 0.6848 - f1-score: 0.8108For batch 131, tr_loss is    0.30.\n",
      "133/200 [==================>...........] - ETA: 1:00 - loss: 0.2957 - iou_score: 0.6847 - f1-score: 0.8108For batch 132, tr_loss is    0.30.\n",
      "134/200 [===================>..........] - ETA: 59s - loss: 0.2962 - iou_score: 0.6840 - f1-score: 0.8103 For batch 133, tr_loss is    0.30.\n",
      "135/200 [===================>..........] - ETA: 58s - loss: 0.2967 - iou_score: 0.6836 - f1-score: 0.8099For batch 134, tr_loss is    0.30.\n",
      "136/200 [===================>..........] - ETA: 57s - loss: 0.2966 - iou_score: 0.6835 - f1-score: 0.8099For batch 135, tr_loss is    0.30.\n",
      "137/200 [===================>..........] - ETA: 56s - loss: 0.2975 - iou_score: 0.6826 - f1-score: 0.8092For batch 136, tr_loss is    0.30.\n",
      "138/200 [===================>..........] - ETA: 55s - loss: 0.2977 - iou_score: 0.6823 - f1-score: 0.8090For batch 137, tr_loss is    0.30.\n",
      "139/200 [===================>..........] - ETA: 55s - loss: 0.2974 - iou_score: 0.6826 - f1-score: 0.8092For batch 138, tr_loss is    0.30.\n",
      "140/200 [====================>.........] - ETA: 54s - loss: 0.2985 - iou_score: 0.6815 - f1-score: 0.8084For batch 139, tr_loss is    0.30.\n",
      "141/200 [====================>.........] - ETA: 53s - loss: 0.2990 - iou_score: 0.6811 - f1-score: 0.8080For batch 140, tr_loss is    0.30.\n",
      "142/200 [====================>.........] - ETA: 52s - loss: 0.2989 - iou_score: 0.6813 - f1-score: 0.8082For batch 141, tr_loss is    0.30.\n",
      "143/200 [====================>.........] - ETA: 51s - loss: 0.2989 - iou_score: 0.6813 - f1-score: 0.8082For batch 142, tr_loss is    0.30.\n",
      "144/200 [====================>.........] - ETA: 50s - loss: 0.2990 - iou_score: 0.6812 - f1-score: 0.8081For batch 143, tr_loss is    0.30.\n",
      "145/200 [====================>.........] - ETA: 49s - loss: 0.2991 - iou_score: 0.6809 - f1-score: 0.8079For batch 144, tr_loss is    0.30.\n",
      "146/200 [====================>.........] - ETA: 48s - loss: 0.2990 - iou_score: 0.6813 - f1-score: 0.8082For batch 145, tr_loss is    0.30.\n",
      "147/200 [=====================>........] - ETA: 47s - loss: 0.2992 - iou_score: 0.6810 - f1-score: 0.8080For batch 146, tr_loss is    0.30.\n",
      "148/200 [=====================>........] - ETA: 46s - loss: 0.2986 - iou_score: 0.6818 - f1-score: 0.8085For batch 147, tr_loss is    0.30.\n",
      "149/200 [=====================>........] - ETA: 46s - loss: 0.2982 - iou_score: 0.6821 - f1-score: 0.8087For batch 148, tr_loss is    0.30.\n",
      "150/200 [=====================>........] - ETA: 45s - loss: 0.2978 - iou_score: 0.6828 - f1-score: 0.8092For batch 149, tr_loss is    0.30.\n",
      "151/200 [=====================>........] - ETA: 44s - loss: 0.2977 - iou_score: 0.6827 - f1-score: 0.8091For batch 150, tr_loss is    0.30.\n",
      "152/200 [=====================>........] - ETA: 43s - loss: 0.2976 - iou_score: 0.6829 - f1-score: 0.8092For batch 151, tr_loss is    0.30.\n",
      "153/200 [=====================>........] - ETA: 42s - loss: 0.2976 - iou_score: 0.6828 - f1-score: 0.8092For batch 152, tr_loss is    0.30.\n",
      "154/200 [======================>.......] - ETA: 41s - loss: 0.2975 - iou_score: 0.6830 - f1-score: 0.8094For batch 153, tr_loss is    0.30.\n",
      "155/200 [======================>.......] - ETA: 40s - loss: 0.2976 - iou_score: 0.6830 - f1-score: 0.8094For batch 154, tr_loss is    0.30.\n",
      "156/200 [======================>.......] - ETA: 39s - loss: 0.2976 - iou_score: 0.6831 - f1-score: 0.8095For batch 155, tr_loss is    0.30.\n",
      "157/200 [======================>.......] - ETA: 38s - loss: 0.2976 - iou_score: 0.6830 - f1-score: 0.8094For batch 156, tr_loss is    0.30.\n",
      "158/200 [======================>.......] - ETA: 37s - loss: 0.2978 - iou_score: 0.6827 - f1-score: 0.8092For batch 157, tr_loss is    0.30.\n",
      "159/200 [======================>.......] - ETA: 37s - loss: 0.2980 - iou_score: 0.6826 - f1-score: 0.8091For batch 158, tr_loss is    0.30.\n",
      "160/200 [=======================>......] - ETA: 36s - loss: 0.2979 - iou_score: 0.6826 - f1-score: 0.8092For batch 159, tr_loss is    0.30.\n",
      "161/200 [=======================>......] - ETA: 35s - loss: 0.2981 - iou_score: 0.6822 - f1-score: 0.8089For batch 160, tr_loss is    0.30.\n",
      "162/200 [=======================>......] - ETA: 34s - loss: 0.2981 - iou_score: 0.6822 - f1-score: 0.8088For batch 161, tr_loss is    0.30.\n",
      "163/200 [=======================>......] - ETA: 33s - loss: 0.2976 - iou_score: 0.6828 - f1-score: 0.8093For batch 162, tr_loss is    0.30.\n",
      "164/200 [=======================>......] - ETA: 32s - loss: 0.2975 - iou_score: 0.6829 - f1-score: 0.8094For batch 163, tr_loss is    0.30.\n",
      "165/200 [=======================>......] - ETA: 31s - loss: 0.2973 - iou_score: 0.6832 - f1-score: 0.8096For batch 164, tr_loss is    0.30.\n",
      "166/200 [=======================>......] - ETA: 30s - loss: 0.2972 - iou_score: 0.6833 - f1-score: 0.8096For batch 165, tr_loss is    0.30.\n",
      "167/200 [========================>.....] - ETA: 29s - loss: 0.2967 - iou_score: 0.6841 - f1-score: 0.8101For batch 166, tr_loss is    0.30.\n",
      "168/200 [========================>.....] - ETA: 28s - loss: 0.2970 - iou_score: 0.6837 - f1-score: 0.8099For batch 167, tr_loss is    0.30.\n",
      "169/200 [========================>.....] - ETA: 27s - loss: 0.2972 - iou_score: 0.6835 - f1-score: 0.8097For batch 168, tr_loss is    0.30.\n",
      "170/200 [========================>.....] - ETA: 27s - loss: 0.2969 - iou_score: 0.6838 - f1-score: 0.8100For batch 169, tr_loss is    0.30.\n",
      "171/200 [========================>.....] - ETA: 26s - loss: 0.2969 - iou_score: 0.6838 - f1-score: 0.8100For batch 170, tr_loss is    0.30.\n",
      "172/200 [========================>.....] - ETA: 25s - loss: 0.2966 - iou_score: 0.6841 - f1-score: 0.8102For batch 171, tr_loss is    0.30.\n",
      "173/200 [========================>.....] - ETA: 24s - loss: 0.2966 - iou_score: 0.6841 - f1-score: 0.8102For batch 172, tr_loss is    0.30.\n",
      "174/200 [=========================>....] - ETA: 23s - loss: 0.2964 - iou_score: 0.6844 - f1-score: 0.8104For batch 173, tr_loss is    0.30.\n",
      "175/200 [=========================>....] - ETA: 22s - loss: 0.2961 - iou_score: 0.6847 - f1-score: 0.8106For batch 174, tr_loss is    0.30.\n",
      "176/200 [=========================>....] - ETA: 21s - loss: 0.2960 - iou_score: 0.6846 - f1-score: 0.8105For batch 175, tr_loss is    0.30.\n",
      "177/200 [=========================>....] - ETA: 20s - loss: 0.2956 - iou_score: 0.6850 - f1-score: 0.8108For batch 176, tr_loss is    0.30.\n",
      "178/200 [=========================>....] - ETA: 19s - loss: 0.2959 - iou_score: 0.6845 - f1-score: 0.8104For batch 177, tr_loss is    0.30.\n",
      "179/200 [=========================>....] - ETA: 18s - loss: 0.2956 - iou_score: 0.6849 - f1-score: 0.8107For batch 178, tr_loss is    0.30.\n",
      "180/200 [==========================>...] - ETA: 17s - loss: 0.2957 - iou_score: 0.6847 - f1-score: 0.8106For batch 179, tr_loss is    0.30.\n",
      "181/200 [==========================>...] - ETA: 17s - loss: 0.2958 - iou_score: 0.6845 - f1-score: 0.8104For batch 180, tr_loss is    0.30.\n",
      "182/200 [==========================>...] - ETA: 16s - loss: 0.2958 - iou_score: 0.6845 - f1-score: 0.8105For batch 181, tr_loss is    0.30.\n",
      "183/200 [==========================>...] - ETA: 15s - loss: 0.2958 - iou_score: 0.6844 - f1-score: 0.8104For batch 182, tr_loss is    0.30.\n",
      "184/200 [==========================>...] - ETA: 14s - loss: 0.2956 - iou_score: 0.6846 - f1-score: 0.8105For batch 183, tr_loss is    0.30.\n",
      "185/200 [==========================>...] - ETA: 13s - loss: 0.2954 - iou_score: 0.6848 - f1-score: 0.8107For batch 184, tr_loss is    0.30.\n",
      "186/200 [==========================>...] - ETA: 12s - loss: 0.2952 - iou_score: 0.6851 - f1-score: 0.8109For batch 185, tr_loss is    0.30.\n",
      "187/200 [===========================>..] - ETA: 11s - loss: 0.2949 - iou_score: 0.6853 - f1-score: 0.8111For batch 186, tr_loss is    0.29.\n",
      "188/200 [===========================>..] - ETA: 10s - loss: 0.2947 - iou_score: 0.6855 - f1-score: 0.8112For batch 187, tr_loss is    0.29.\n",
      "189/200 [===========================>..] - ETA: 9s - loss: 0.2951 - iou_score: 0.6850 - f1-score: 0.8108 For batch 188, tr_loss is    0.30.\n",
      "190/200 [===========================>..] - ETA: 8s - loss: 0.2950 - iou_score: 0.6851 - f1-score: 0.8109For batch 189, tr_loss is    0.30.\n",
      "191/200 [===========================>..] - ETA: 8s - loss: 0.2956 - iou_score: 0.6846 - f1-score: 0.8105For batch 190, tr_loss is    0.30.\n",
      "192/200 [===========================>..] - ETA: 7s - loss: 0.2961 - iou_score: 0.6842 - f1-score: 0.8102For batch 191, tr_loss is    0.30.\n",
      "193/200 [===========================>..] - ETA: 6s - loss: 0.2957 - iou_score: 0.6847 - f1-score: 0.8105For batch 192, tr_loss is    0.30.\n",
      "194/200 [============================>.] - ETA: 5s - loss: 0.2960 - iou_score: 0.6844 - f1-score: 0.8103For batch 193, tr_loss is    0.30.\n",
      "195/200 [============================>.] - ETA: 4s - loss: 0.2961 - iou_score: 0.6843 - f1-score: 0.8103For batch 194, tr_loss is    0.30.\n",
      "196/200 [============================>.] - ETA: 3s - loss: 0.2962 - iou_score: 0.6841 - f1-score: 0.8101For batch 195, tr_loss is    0.30.\n",
      "197/200 [============================>.] - ETA: 2s - loss: 0.2960 - iou_score: 0.6845 - f1-score: 0.8104For batch 196, tr_loss is    0.30.\n",
      "198/200 [============================>.] - ETA: 1s - loss: 0.2960 - iou_score: 0.6846 - f1-score: 0.8105For batch 197, tr_loss is    0.30.\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.2962 - iou_score: 0.6843 - f1-score: 0.8102For batch 198, tr_loss is    0.30.\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.2962 - iou_score: 0.6842 - f1-score: 0.8102For batch 199, tr_loss is    0.30.\n",
      "For batch 0, vl_loss is    0.39.\n",
      "For batch 1, vl_loss is    0.41.\n",
      "For batch 2, vl_loss is    0.39.\n",
      "For batch 3, vl_loss is    0.39.\n",
      "For batch 4, vl_loss is    0.38.\n",
      "For batch 5, vl_loss is    0.38.\n",
      "For batch 6, vl_loss is    0.40.\n",
      "For batch 7, vl_loss is    0.40.\n",
      "For batch 8, vl_loss is    0.40.\n",
      "For batch 9, vl_loss is    0.39.\n",
      "For batch 10, vl_loss is    0.40.\n",
      "For batch 11, vl_loss is    0.40.\n",
      "For batch 12, vl_loss is    0.39.\n",
      "For batch 13, vl_loss is    0.39.\n",
      "For batch 14, vl_loss is    0.39.\n",
      "For batch 15, vl_loss is    0.39.\n",
      "For batch 16, vl_loss is    0.39.\n",
      "For batch 17, vl_loss is    0.39.\n",
      "For batch 18, vl_loss is    0.39.\n",
      "For batch 19, vl_loss is    0.39.\n",
      "For batch 20, vl_loss is    0.39.\n",
      "For batch 21, vl_loss is    0.39.\n",
      "For batch 22, vl_loss is    0.38.\n",
      "For batch 23, vl_loss is    0.39.\n",
      "For batch 24, vl_loss is    0.38.\n",
      "For batch 25, vl_loss is    0.38.\n",
      "For batch 26, vl_loss is    0.38.\n",
      "For batch 27, vl_loss is    0.38.\n",
      "For batch 28, vl_loss is    0.38.\n",
      "For batch 29, vl_loss is    0.38.\n",
      "For batch 30, vl_loss is    0.38.\n",
      "For batch 31, vl_loss is    0.38.\n",
      "For batch 32, vl_loss is    0.38.\n",
      "For batch 33, vl_loss is    0.38.\n",
      "For batch 34, vl_loss is    0.38.\n",
      "For batch 35, vl_loss is    0.38.\n",
      "For batch 36, vl_loss is    0.38.\n",
      "For batch 37, vl_loss is    0.38.\n",
      "For batch 38, vl_loss is    0.38.\n",
      "For batch 39, vl_loss is    0.38.\n",
      "For batch 40, vl_loss is    0.38.\n",
      "For batch 41, vl_loss is    0.38.\n",
      "For batch 42, vl_loss is    0.38.\n",
      "For batch 43, vl_loss is    0.38.\n",
      "For batch 44, vl_loss is    0.38.\n",
      "For batch 45, vl_loss is    0.38.\n",
      "For batch 46, vl_loss is    0.38.\n",
      "For batch 47, vl_loss is    0.38.\n",
      "For batch 48, vl_loss is    0.38.\n",
      "For batch 49, vl_loss is    0.38.\n",
      "For batch 50, vl_loss is    0.38.\n",
      "For batch 51, vl_loss is    0.38.\n",
      "For batch 52, vl_loss is    0.38.\n",
      "For batch 53, vl_loss is    0.38.\n",
      "For batch 54, vl_loss is    0.38.\n",
      "For batch 55, vl_loss is    0.38.\n",
      "For batch 56, vl_loss is    0.38.\n",
      "For batch 57, vl_loss is    0.38.\n",
      "For batch 58, vl_loss is    0.37.\n",
      "For batch 59, vl_loss is    0.38.\n",
      "For batch 60, vl_loss is    0.38.\n",
      "For batch 61, vl_loss is    0.38.\n",
      "For batch 62, vl_loss is    0.38.\n",
      "For batch 63, vl_loss is    0.37.\n",
      "For batch 64, vl_loss is    0.38.\n",
      "For batch 65, vl_loss is    0.38.\n",
      "For batch 66, vl_loss is    0.38.\n",
      "For batch 67, vl_loss is    0.38.\n",
      "For batch 68, vl_loss is    0.38.\n",
      "For batch 69, vl_loss is    0.38.\n",
      "For batch 70, vl_loss is    0.38.\n",
      "For batch 71, vl_loss is    0.38.\n",
      "For batch 72, vl_loss is    0.38.\n",
      "For batch 73, vl_loss is    0.38.\n",
      "For batch 74, vl_loss is    0.38.\n",
      "For batch 75, vl_loss is    0.38.\n",
      "For batch 76, vl_loss is    0.38.\n",
      "For batch 77, vl_loss is    0.38.\n",
      "For batch 78, vl_loss is    0.38.\n",
      "For batch 79, vl_loss is    0.38.\n",
      "For batch 80, vl_loss is    0.38.\n",
      "For batch 81, vl_loss is    0.38.\n",
      "For batch 82, vl_loss is    0.38.\n",
      "For batch 83, vl_loss is    0.38.\n",
      "For batch 84, vl_loss is    0.38.\n",
      "For batch 85, vl_loss is    0.38.\n",
      "For batch 86, vl_loss is    0.38.\n",
      "For batch 87, vl_loss is    0.38.\n",
      "For batch 88, vl_loss is    0.38.\n",
      "For batch 89, vl_loss is    0.38.\n",
      "For batch 90, vl_loss is    0.38.\n",
      "For batch 91, vl_loss is    0.38.\n",
      "For batch 92, vl_loss is    0.38.\n",
      "For batch 93, vl_loss is    0.38.\n",
      "For batch 94, vl_loss is    0.38.\n",
      "For batch 95, vl_loss is    0.38.\n",
      "For batch 96, vl_loss is    0.38.\n",
      "For batch 97, vl_loss is    0.38.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 98, vl_loss is    0.38.\n",
      "For batch 99, vl_loss is    0.38.\n",
      "200/200 [==============================] - 186s 918ms/step - loss: 0.2962 - iou_score: 0.6842 - f1-score: 0.8102 - val_loss: 0.3795 - val_iou_score: 0.6248 - val_f1-score: 0.7666\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.32441\n",
      "The average loss for epoch 9 is    0.30 \n",
      "Epoch 11/200\n",
      "  1/200 [..............................] - ETA: 9:40 - loss: 0.2813 - iou_score: 0.6885 - f1-score: 0.8154For batch 0, tr_loss is    0.28.\n",
      "  2/200 [..............................] - ETA: 4:03 - loss: 0.2770 - iou_score: 0.7010 - f1-score: 0.8238For batch 1, tr_loss is    0.28.\n",
      "  3/200 [..............................] - ETA: 5:02 - loss: 0.2785 - iou_score: 0.7028 - f1-score: 0.8246For batch 2, tr_loss is    0.28.\n",
      "  4/200 [..............................] - ETA: 4:35 - loss: 0.2881 - iou_score: 0.6897 - f1-score: 0.8154For batch 3, tr_loss is    0.29.\n",
      "  5/200 [..............................] - ETA: 4:55 - loss: 0.2855 - iou_score: 0.6949 - f1-score: 0.8191For batch 4, tr_loss is    0.29.\n",
      "  6/200 [..............................] - ETA: 4:46 - loss: 0.2943 - iou_score: 0.6845 - f1-score: 0.8116For batch 5, tr_loss is    0.29.\n",
      "  7/200 [>.............................] - ETA: 4:51 - loss: 0.2996 - iou_score: 0.6756 - f1-score: 0.8048For batch 6, tr_loss is    0.30.\n",
      "  8/200 [>.............................] - ETA: 4:26 - loss: 0.3011 - iou_score: 0.6751 - f1-score: 0.8044For batch 7, tr_loss is    0.30.\n",
      "  9/200 [>.............................] - ETA: 4:18 - loss: 0.3024 - iou_score: 0.6789 - f1-score: 0.8070For batch 8, tr_loss is    0.30.\n",
      " 10/200 [>.............................] - ETA: 4:00 - loss: 0.3023 - iou_score: 0.6778 - f1-score: 0.8059For batch 9, tr_loss is    0.30.\n",
      " 11/200 [>.............................] - ETA: 3:55 - loss: 0.2995 - iou_score: 0.6799 - f1-score: 0.8074For batch 10, tr_loss is    0.30.\n",
      " 12/200 [>.............................] - ETA: 3:50 - loss: 0.3042 - iou_score: 0.6732 - f1-score: 0.8025For batch 11, tr_loss is    0.30.\n",
      " 13/200 [>.............................] - ETA: 3:46 - loss: 0.3044 - iou_score: 0.6715 - f1-score: 0.8013For batch 12, tr_loss is    0.30.\n",
      " 14/200 [=>............................] - ETA: 3:40 - loss: 0.3029 - iou_score: 0.6728 - f1-score: 0.8024For batch 13, tr_loss is    0.30.\n",
      " 15/200 [=>............................] - ETA: 3:37 - loss: 0.3011 - iou_score: 0.6748 - f1-score: 0.8039For batch 14, tr_loss is    0.30.\n",
      " 16/200 [=>............................] - ETA: 3:27 - loss: 0.2997 - iou_score: 0.6753 - f1-score: 0.8044For batch 15, tr_loss is    0.30.\n",
      " 17/200 [=>............................] - ETA: 3:25 - loss: 0.2975 - iou_score: 0.6777 - f1-score: 0.8060For batch 16, tr_loss is    0.30.\n",
      " 18/200 [=>............................] - ETA: 3:19 - loss: 0.2963 - iou_score: 0.6792 - f1-score: 0.8072For batch 17, tr_loss is    0.30.\n",
      " 19/200 [=>............................] - ETA: 3:18 - loss: 0.2993 - iou_score: 0.6763 - f1-score: 0.8050For batch 18, tr_loss is    0.30.\n",
      " 20/200 [==>...........................] - ETA: 3:16 - loss: 0.2961 - iou_score: 0.6815 - f1-score: 0.8086For batch 19, tr_loss is    0.30.\n",
      " 21/200 [==>...........................] - ETA: 3:14 - loss: 0.2947 - iou_score: 0.6840 - f1-score: 0.8104For batch 20, tr_loss is    0.29.\n",
      " 22/200 [==>...........................] - ETA: 3:08 - loss: 0.2931 - iou_score: 0.6859 - f1-score: 0.8118For batch 21, tr_loss is    0.29.\n",
      " 23/200 [==>...........................] - ETA: 3:07 - loss: 0.2911 - iou_score: 0.6880 - f1-score: 0.8133For batch 22, tr_loss is    0.29.\n",
      " 24/200 [==>...........................] - ETA: 3:02 - loss: 0.2908 - iou_score: 0.6883 - f1-score: 0.8136For batch 23, tr_loss is    0.29.\n",
      " 25/200 [==>...........................] - ETA: 2:58 - loss: 0.2906 - iou_score: 0.6886 - f1-score: 0.8139For batch 24, tr_loss is    0.29.\n",
      " 26/200 [==>...........................] - ETA: 2:58 - loss: 0.2930 - iou_score: 0.6874 - f1-score: 0.8131For batch 25, tr_loss is    0.29.\n",
      " 27/200 [===>..........................] - ETA: 2:55 - loss: 0.2914 - iou_score: 0.6888 - f1-score: 0.8140For batch 26, tr_loss is    0.29.\n",
      " 28/200 [===>..........................] - ETA: 2:54 - loss: 0.2912 - iou_score: 0.6887 - f1-score: 0.8140For batch 27, tr_loss is    0.29.\n",
      " 29/200 [===>..........................] - ETA: 2:50 - loss: 0.2914 - iou_score: 0.6879 - f1-score: 0.8135For batch 28, tr_loss is    0.29.\n",
      " 30/200 [===>..........................] - ETA: 2:47 - loss: 0.2898 - iou_score: 0.6901 - f1-score: 0.8150For batch 29, tr_loss is    0.29.\n",
      " 31/200 [===>..........................] - ETA: 2:47 - loss: 0.2883 - iou_score: 0.6921 - f1-score: 0.8164For batch 30, tr_loss is    0.29.\n",
      " 32/200 [===>..........................] - ETA: 2:46 - loss: 0.2878 - iou_score: 0.6936 - f1-score: 0.8174For batch 31, tr_loss is    0.29.\n",
      " 33/200 [===>..........................] - ETA: 2:46 - loss: 0.2867 - iou_score: 0.6946 - f1-score: 0.8181For batch 32, tr_loss is    0.29.\n",
      " 34/200 [====>.........................] - ETA: 2:45 - loss: 0.2874 - iou_score: 0.6935 - f1-score: 0.8174For batch 33, tr_loss is    0.29.\n",
      " 35/200 [====>.........................] - ETA: 2:43 - loss: 0.2869 - iou_score: 0.6946 - f1-score: 0.8182For batch 34, tr_loss is    0.29.\n",
      " 36/200 [====>.........................] - ETA: 2:40 - loss: 0.2875 - iou_score: 0.6948 - f1-score: 0.8183For batch 35, tr_loss is    0.29.\n",
      " 37/200 [====>.........................] - ETA: 2:40 - loss: 0.2891 - iou_score: 0.6935 - f1-score: 0.8174For batch 36, tr_loss is    0.29.\n",
      " 38/200 [====>.........................] - ETA: 2:39 - loss: 0.2897 - iou_score: 0.6916 - f1-score: 0.8160For batch 37, tr_loss is    0.29.\n",
      " 39/200 [====>.........................] - ETA: 2:38 - loss: 0.2891 - iou_score: 0.6919 - f1-score: 0.8163For batch 38, tr_loss is    0.29.\n",
      " 40/200 [=====>........................] - ETA: 2:37 - loss: 0.2878 - iou_score: 0.6937 - f1-score: 0.8175For batch 39, tr_loss is    0.29.\n",
      " 41/200 [=====>........................] - ETA: 2:35 - loss: 0.2872 - iou_score: 0.6946 - f1-score: 0.8181For batch 40, tr_loss is    0.29.\n",
      " 42/200 [=====>........................] - ETA: 2:34 - loss: 0.2876 - iou_score: 0.6942 - f1-score: 0.8179For batch 41, tr_loss is    0.29.\n",
      " 43/200 [=====>........................] - ETA: 2:33 - loss: 0.2879 - iou_score: 0.6941 - f1-score: 0.8177For batch 42, tr_loss is    0.29.\n",
      " 44/200 [=====>........................] - ETA: 2:31 - loss: 0.2870 - iou_score: 0.6954 - f1-score: 0.8186For batch 43, tr_loss is    0.29.\n",
      " 45/200 [=====>........................] - ETA: 2:31 - loss: 0.2867 - iou_score: 0.6955 - f1-score: 0.8187For batch 44, tr_loss is    0.29.\n",
      " 46/200 [=====>........................] - ETA: 2:28 - loss: 0.2876 - iou_score: 0.6948 - f1-score: 0.8182For batch 45, tr_loss is    0.29.\n",
      " 47/200 [======>.......................] - ETA: 2:28 - loss: 0.2880 - iou_score: 0.6942 - f1-score: 0.8177For batch 46, tr_loss is    0.29.\n",
      " 48/200 [======>.......................] - ETA: 2:27 - loss: 0.2883 - iou_score: 0.6937 - f1-score: 0.8174For batch 47, tr_loss is    0.29.\n",
      " 49/200 [======>.......................] - ETA: 2:26 - loss: 0.2880 - iou_score: 0.6941 - f1-score: 0.8177For batch 48, tr_loss is    0.29.\n",
      " 50/200 [======>.......................] - ETA: 2:25 - loss: 0.2864 - iou_score: 0.6960 - f1-score: 0.8190For batch 49, tr_loss is    0.29.\n",
      " 51/200 [======>.......................] - ETA: 2:25 - loss: 0.2858 - iou_score: 0.6970 - f1-score: 0.8197For batch 50, tr_loss is    0.29.\n",
      " 52/200 [======>.......................] - ETA: 2:23 - loss: 0.2862 - iou_score: 0.6970 - f1-score: 0.8196For batch 51, tr_loss is    0.29.\n",
      " 53/200 [======>.......................] - ETA: 2:22 - loss: 0.2858 - iou_score: 0.6973 - f1-score: 0.8199For batch 52, tr_loss is    0.29.\n",
      " 54/200 [=======>......................] - ETA: 2:19 - loss: 0.2862 - iou_score: 0.6969 - f1-score: 0.8196For batch 53, tr_loss is    0.29.\n",
      " 55/200 [=======>......................] - ETA: 2:18 - loss: 0.2853 - iou_score: 0.6977 - f1-score: 0.8202For batch 54, tr_loss is    0.29.\n",
      " 56/200 [=======>......................] - ETA: 2:17 - loss: 0.2854 - iou_score: 0.6974 - f1-score: 0.8200For batch 55, tr_loss is    0.29.\n",
      " 57/200 [=======>......................] - ETA: 2:16 - loss: 0.2845 - iou_score: 0.6979 - f1-score: 0.8204For batch 56, tr_loss is    0.28.\n",
      " 58/200 [=======>......................] - ETA: 2:15 - loss: 0.2837 - iou_score: 0.6986 - f1-score: 0.8208For batch 57, tr_loss is    0.28.\n",
      " 59/200 [=======>......................] - ETA: 2:15 - loss: 0.2831 - iou_score: 0.6994 - f1-score: 0.8214For batch 58, tr_loss is    0.28.\n",
      " 60/200 [========>.....................] - ETA: 2:14 - loss: 0.2825 - iou_score: 0.6996 - f1-score: 0.8216For batch 59, tr_loss is    0.28.\n",
      " 61/200 [========>.....................] - ETA: 2:13 - loss: 0.2833 - iou_score: 0.6993 - f1-score: 0.8214For batch 60, tr_loss is    0.28.\n",
      " 62/200 [========>.....................] - ETA: 2:12 - loss: 0.2834 - iou_score: 0.6990 - f1-score: 0.8212For batch 61, tr_loss is    0.28.\n",
      " 63/200 [========>.....................] - ETA: 2:10 - loss: 0.2829 - iou_score: 0.6993 - f1-score: 0.8215For batch 62, tr_loss is    0.28.\n",
      " 64/200 [========>.....................] - ETA: 2:09 - loss: 0.2840 - iou_score: 0.6982 - f1-score: 0.8206For batch 63, tr_loss is    0.28.\n",
      " 65/200 [========>.....................] - ETA: 2:09 - loss: 0.2828 - iou_score: 0.6995 - f1-score: 0.8215For batch 64, tr_loss is    0.28.\n",
      " 66/200 [========>.....................] - ETA: 2:08 - loss: 0.2849 - iou_score: 0.6975 - f1-score: 0.8200For batch 65, tr_loss is    0.28.\n",
      " 67/200 [=========>....................] - ETA: 2:07 - loss: 0.2845 - iou_score: 0.6980 - f1-score: 0.8204For batch 66, tr_loss is    0.28.\n",
      " 68/200 [=========>....................] - ETA: 2:06 - loss: 0.2843 - iou_score: 0.6982 - f1-score: 0.8205For batch 67, tr_loss is    0.28.\n",
      " 69/200 [=========>....................] - ETA: 2:05 - loss: 0.2856 - iou_score: 0.6965 - f1-score: 0.8193For batch 68, tr_loss is    0.29.\n",
      " 70/200 [=========>....................] - ETA: 2:03 - loss: 0.2853 - iou_score: 0.6969 - f1-score: 0.8195For batch 69, tr_loss is    0.29.\n",
      " 71/200 [=========>....................] - ETA: 2:02 - loss: 0.2850 - iou_score: 0.6976 - f1-score: 0.8200For batch 70, tr_loss is    0.28.\n",
      " 72/200 [=========>....................] - ETA: 2:01 - loss: 0.2849 - iou_score: 0.6975 - f1-score: 0.8200For batch 71, tr_loss is    0.28.\n",
      " 73/200 [=========>....................] - ETA: 2:00 - loss: 0.2844 - iou_score: 0.6979 - f1-score: 0.8203For batch 72, tr_loss is    0.28.\n",
      " 74/200 [==========>...................] - ETA: 1:59 - loss: 0.2844 - iou_score: 0.6977 - f1-score: 0.8202For batch 73, tr_loss is    0.28.\n",
      " 75/200 [==========>...................] - ETA: 1:58 - loss: 0.2853 - iou_score: 0.6968 - f1-score: 0.8195For batch 74, tr_loss is    0.29.\n",
      " 76/200 [==========>...................] - ETA: 1:57 - loss: 0.2856 - iou_score: 0.6961 - f1-score: 0.8190For batch 75, tr_loss is    0.29.\n",
      " 77/200 [==========>...................] - ETA: 1:56 - loss: 0.2855 - iou_score: 0.6959 - f1-score: 0.8189For batch 76, tr_loss is    0.29.\n",
      " 78/200 [==========>...................] - ETA: 1:55 - loss: 0.2851 - iou_score: 0.6960 - f1-score: 0.8190For batch 77, tr_loss is    0.29.\n",
      " 79/200 [==========>...................] - ETA: 1:54 - loss: 0.2853 - iou_score: 0.6959 - f1-score: 0.8190For batch 78, tr_loss is    0.29.\n",
      " 80/200 [===========>..................] - ETA: 1:53 - loss: 0.2850 - iou_score: 0.6964 - f1-score: 0.8193For batch 79, tr_loss is    0.28.\n",
      " 81/200 [===========>..................] - ETA: 1:51 - loss: 0.2839 - iou_score: 0.6976 - f1-score: 0.8201For batch 80, tr_loss is    0.28.\n",
      " 82/200 [===========>..................] - ETA: 1:51 - loss: 0.2838 - iou_score: 0.6978 - f1-score: 0.8202For batch 81, tr_loss is    0.28.\n",
      " 83/200 [===========>..................] - ETA: 1:49 - loss: 0.2840 - iou_score: 0.6977 - f1-score: 0.8202For batch 82, tr_loss is    0.28.\n",
      " 84/200 [===========>..................] - ETA: 1:48 - loss: 0.2840 - iou_score: 0.6976 - f1-score: 0.8201For batch 83, tr_loss is    0.28.\n",
      " 85/200 [===========>..................] - ETA: 1:47 - loss: 0.2848 - iou_score: 0.6963 - f1-score: 0.8192For batch 84, tr_loss is    0.28.\n",
      " 86/200 [===========>..................] - ETA: 1:46 - loss: 0.2851 - iou_score: 0.6957 - f1-score: 0.8188For batch 85, tr_loss is    0.29.\n",
      " 87/200 [============>.................] - ETA: 1:44 - loss: 0.2847 - iou_score: 0.6964 - f1-score: 0.8192For batch 86, tr_loss is    0.28.\n",
      " 88/200 [============>.................] - ETA: 1:43 - loss: 0.2844 - iou_score: 0.6970 - f1-score: 0.8196For batch 87, tr_loss is    0.28.\n",
      " 89/200 [============>.................] - ETA: 1:43 - loss: 0.2854 - iou_score: 0.6962 - f1-score: 0.8191For batch 88, tr_loss is    0.29.\n",
      " 90/200 [============>.................] - ETA: 1:41 - loss: 0.2854 - iou_score: 0.6961 - f1-score: 0.8191For batch 89, tr_loss is    0.29.\n",
      " 91/200 [============>.................] - ETA: 1:41 - loss: 0.2852 - iou_score: 0.6961 - f1-score: 0.8190For batch 90, tr_loss is    0.29.\n",
      " 92/200 [============>.................] - ETA: 1:39 - loss: 0.2860 - iou_score: 0.6953 - f1-score: 0.8185For batch 91, tr_loss is    0.29.\n",
      " 93/200 [============>.................] - ETA: 1:38 - loss: 0.2859 - iou_score: 0.6954 - f1-score: 0.8185For batch 92, tr_loss is    0.29.\n",
      " 94/200 [=============>................] - ETA: 1:37 - loss: 0.2869 - iou_score: 0.6939 - f1-score: 0.8175For batch 93, tr_loss is    0.29.\n",
      " 95/200 [=============>................] - ETA: 1:36 - loss: 0.2872 - iou_score: 0.6936 - f1-score: 0.8173For batch 94, tr_loss is    0.29.\n",
      " 96/200 [=============>................] - ETA: 1:35 - loss: 0.2869 - iou_score: 0.6938 - f1-score: 0.8174For batch 95, tr_loss is    0.29.\n",
      " 97/200 [=============>................] - ETA: 1:34 - loss: 0.2875 - iou_score: 0.6928 - f1-score: 0.8167For batch 96, tr_loss is    0.29.\n",
      " 98/200 [=============>................] - ETA: 1:33 - loss: 0.2879 - iou_score: 0.6925 - f1-score: 0.8165For batch 97, tr_loss is    0.29.\n",
      " 99/200 [=============>................] - ETA: 1:32 - loss: 0.2875 - iou_score: 0.6930 - f1-score: 0.8168For batch 98, tr_loss is    0.29.\n",
      "100/200 [==============>...............] - ETA: 1:31 - loss: 0.2879 - iou_score: 0.6928 - f1-score: 0.8167For batch 99, tr_loss is    0.29.\n",
      "101/200 [==============>...............] - ETA: 1:30 - loss: 0.2879 - iou_score: 0.6928 - f1-score: 0.8167For batch 100, tr_loss is    0.29.\n",
      "102/200 [==============>...............] - ETA: 1:29 - loss: 0.2883 - iou_score: 0.6922 - f1-score: 0.8163For batch 101, tr_loss is    0.29.\n",
      "103/200 [==============>...............] - ETA: 1:28 - loss: 0.2885 - iou_score: 0.6918 - f1-score: 0.8160For batch 102, tr_loss is    0.29.\n",
      "104/200 [==============>...............] - ETA: 1:27 - loss: 0.2889 - iou_score: 0.6911 - f1-score: 0.8155For batch 103, tr_loss is    0.29.\n",
      "105/200 [==============>...............] - ETA: 1:26 - loss: 0.2890 - iou_score: 0.6908 - f1-score: 0.8154For batch 104, tr_loss is    0.29.\n",
      "106/200 [==============>...............] - ETA: 1:26 - loss: 0.2894 - iou_score: 0.6904 - f1-score: 0.8151For batch 105, tr_loss is    0.29.\n",
      "107/200 [===============>..............] - ETA: 1:25 - loss: 0.2896 - iou_score: 0.6902 - f1-score: 0.8149For batch 106, tr_loss is    0.29.\n",
      "108/200 [===============>..............] - ETA: 1:24 - loss: 0.2892 - iou_score: 0.6905 - f1-score: 0.8151For batch 107, tr_loss is    0.29.\n",
      "109/200 [===============>..............] - ETA: 1:23 - loss: 0.2892 - iou_score: 0.6906 - f1-score: 0.8152For batch 108, tr_loss is    0.29.\n",
      "110/200 [===============>..............] - ETA: 1:22 - loss: 0.2892 - iou_score: 0.6908 - f1-score: 0.8154For batch 109, tr_loss is    0.29.\n",
      "111/200 [===============>..............] - ETA: 1:21 - loss: 0.2887 - iou_score: 0.6913 - f1-score: 0.8157For batch 110, tr_loss is    0.29.\n",
      "112/200 [===============>..............] - ETA: 1:20 - loss: 0.2887 - iou_score: 0.6913 - f1-score: 0.8157For batch 111, tr_loss is    0.29.\n",
      "113/200 [===============>..............] - ETA: 1:19 - loss: 0.2894 - iou_score: 0.6902 - f1-score: 0.8148For batch 112, tr_loss is    0.29.\n",
      "114/200 [================>.............] - ETA: 1:18 - loss: 0.2903 - iou_score: 0.6896 - f1-score: 0.8144For batch 113, tr_loss is    0.29.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/200 [================>.............] - ETA: 1:17 - loss: 0.2904 - iou_score: 0.6893 - f1-score: 0.8142For batch 114, tr_loss is    0.29.\n",
      "116/200 [================>.............] - ETA: 1:16 - loss: 0.2909 - iou_score: 0.6886 - f1-score: 0.8137For batch 115, tr_loss is    0.29.\n",
      "117/200 [================>.............] - ETA: 1:15 - loss: 0.2909 - iou_score: 0.6887 - f1-score: 0.8137For batch 116, tr_loss is    0.29.\n",
      "118/200 [================>.............] - ETA: 1:14 - loss: 0.2909 - iou_score: 0.6887 - f1-score: 0.8137For batch 117, tr_loss is    0.29.\n",
      "119/200 [================>.............] - ETA: 1:13 - loss: 0.2909 - iou_score: 0.6884 - f1-score: 0.8136For batch 118, tr_loss is    0.29.\n",
      "120/200 [=================>............] - ETA: 1:12 - loss: 0.2907 - iou_score: 0.6889 - f1-score: 0.8139For batch 119, tr_loss is    0.29.\n",
      "121/200 [=================>............] - ETA: 1:11 - loss: 0.2904 - iou_score: 0.6893 - f1-score: 0.8142For batch 120, tr_loss is    0.29.\n",
      "122/200 [=================>............] - ETA: 1:10 - loss: 0.2904 - iou_score: 0.6893 - f1-score: 0.8142For batch 121, tr_loss is    0.29.\n",
      "123/200 [=================>............] - ETA: 1:09 - loss: 0.2912 - iou_score: 0.6883 - f1-score: 0.8134For batch 122, tr_loss is    0.29.\n",
      "124/200 [=================>............] - ETA: 1:08 - loss: 0.2915 - iou_score: 0.6881 - f1-score: 0.8133For batch 123, tr_loss is    0.29.\n",
      "125/200 [=================>............] - ETA: 1:07 - loss: 0.2915 - iou_score: 0.6881 - f1-score: 0.8133For batch 124, tr_loss is    0.29.\n",
      "126/200 [=================>............] - ETA: 1:06 - loss: 0.2915 - iou_score: 0.6882 - f1-score: 0.8134For batch 125, tr_loss is    0.29.\n",
      "127/200 [==================>...........] - ETA: 1:05 - loss: 0.2915 - iou_score: 0.6881 - f1-score: 0.8133For batch 126, tr_loss is    0.29.\n",
      "128/200 [==================>...........] - ETA: 1:04 - loss: 0.2922 - iou_score: 0.6871 - f1-score: 0.8126For batch 127, tr_loss is    0.29.\n",
      "129/200 [==================>...........] - ETA: 1:03 - loss: 0.2920 - iou_score: 0.6872 - f1-score: 0.8126For batch 128, tr_loss is    0.29.\n",
      "130/200 [==================>...........] - ETA: 1:02 - loss: 0.2920 - iou_score: 0.6873 - f1-score: 0.8127For batch 129, tr_loss is    0.29.\n",
      "131/200 [==================>...........] - ETA: 1:01 - loss: 0.2916 - iou_score: 0.6875 - f1-score: 0.8129For batch 130, tr_loss is    0.29.\n",
      "132/200 [==================>...........] - ETA: 1:00 - loss: 0.2913 - iou_score: 0.6877 - f1-score: 0.8130For batch 131, tr_loss is    0.29.\n",
      "133/200 [==================>...........] - ETA: 59s - loss: 0.2914 - iou_score: 0.6878 - f1-score: 0.8131 For batch 132, tr_loss is    0.29.\n",
      "134/200 [===================>..........] - ETA: 58s - loss: 0.2919 - iou_score: 0.6872 - f1-score: 0.8126For batch 133, tr_loss is    0.29.\n",
      "135/200 [===================>..........] - ETA: 58s - loss: 0.2924 - iou_score: 0.6868 - f1-score: 0.8124For batch 134, tr_loss is    0.29.\n",
      "136/200 [===================>..........] - ETA: 57s - loss: 0.2922 - iou_score: 0.6868 - f1-score: 0.8124For batch 135, tr_loss is    0.29.\n",
      "137/200 [===================>..........] - ETA: 56s - loss: 0.2931 - iou_score: 0.6859 - f1-score: 0.8117For batch 136, tr_loss is    0.29.\n",
      "138/200 [===================>..........] - ETA: 55s - loss: 0.2933 - iou_score: 0.6855 - f1-score: 0.8114For batch 137, tr_loss is    0.29.\n",
      "139/200 [===================>..........] - ETA: 54s - loss: 0.2929 - iou_score: 0.6859 - f1-score: 0.8117For batch 138, tr_loss is    0.29.\n",
      "140/200 [====================>.........] - ETA: 53s - loss: 0.2941 - iou_score: 0.6846 - f1-score: 0.8106For batch 139, tr_loss is    0.29.\n",
      "141/200 [====================>.........] - ETA: 52s - loss: 0.2946 - iou_score: 0.6842 - f1-score: 0.8103For batch 140, tr_loss is    0.29.\n",
      "142/200 [====================>.........] - ETA: 51s - loss: 0.2945 - iou_score: 0.6843 - f1-score: 0.8104For batch 141, tr_loss is    0.29.\n",
      "143/200 [====================>.........] - ETA: 50s - loss: 0.2945 - iou_score: 0.6842 - f1-score: 0.8104For batch 142, tr_loss is    0.29.\n",
      "144/200 [====================>.........] - ETA: 49s - loss: 0.2947 - iou_score: 0.6840 - f1-score: 0.8102For batch 143, tr_loss is    0.29.\n",
      "145/200 [====================>.........] - ETA: 48s - loss: 0.2949 - iou_score: 0.6837 - f1-score: 0.8100For batch 144, tr_loss is    0.29.\n",
      "146/200 [====================>.........] - ETA: 48s - loss: 0.2945 - iou_score: 0.6844 - f1-score: 0.8104For batch 145, tr_loss is    0.29.\n",
      "147/200 [=====================>........] - ETA: 47s - loss: 0.2948 - iou_score: 0.6841 - f1-score: 0.8102For batch 146, tr_loss is    0.29.\n",
      "148/200 [=====================>........] - ETA: 46s - loss: 0.2943 - iou_score: 0.6848 - f1-score: 0.8107For batch 147, tr_loss is    0.29.\n",
      "149/200 [=====================>........] - ETA: 45s - loss: 0.2940 - iou_score: 0.6850 - f1-score: 0.8109For batch 148, tr_loss is    0.29.\n",
      "150/200 [=====================>........] - ETA: 44s - loss: 0.2935 - iou_score: 0.6857 - f1-score: 0.8113For batch 149, tr_loss is    0.29.\n",
      "151/200 [=====================>........] - ETA: 43s - loss: 0.2937 - iou_score: 0.6855 - f1-score: 0.8111For batch 150, tr_loss is    0.29.\n",
      "152/200 [=====================>........] - ETA: 42s - loss: 0.2935 - iou_score: 0.6859 - f1-score: 0.8114For batch 151, tr_loss is    0.29.\n",
      "153/200 [=====================>........] - ETA: 41s - loss: 0.2932 - iou_score: 0.6860 - f1-score: 0.8115For batch 152, tr_loss is    0.29.\n",
      "154/200 [======================>.......] - ETA: 40s - loss: 0.2933 - iou_score: 0.6860 - f1-score: 0.8115For batch 153, tr_loss is    0.29.\n",
      "155/200 [======================>.......] - ETA: 39s - loss: 0.2934 - iou_score: 0.6860 - f1-score: 0.8115For batch 154, tr_loss is    0.29.\n",
      "156/200 [======================>.......] - ETA: 39s - loss: 0.2933 - iou_score: 0.6861 - f1-score: 0.8116For batch 155, tr_loss is    0.29.\n",
      "157/200 [======================>.......] - ETA: 38s - loss: 0.2933 - iou_score: 0.6861 - f1-score: 0.8116For batch 156, tr_loss is    0.29.\n",
      "158/200 [======================>.......] - ETA: 37s - loss: 0.2936 - iou_score: 0.6859 - f1-score: 0.8115For batch 157, tr_loss is    0.29.\n",
      "159/200 [======================>.......] - ETA: 36s - loss: 0.2938 - iou_score: 0.6857 - f1-score: 0.8113For batch 158, tr_loss is    0.29.\n",
      "160/200 [=======================>......] - ETA: 35s - loss: 0.2937 - iou_score: 0.6858 - f1-score: 0.8114For batch 159, tr_loss is    0.29.\n",
      "161/200 [=======================>......] - ETA: 34s - loss: 0.2939 - iou_score: 0.6855 - f1-score: 0.8112For batch 160, tr_loss is    0.29.\n",
      "162/200 [=======================>......] - ETA: 33s - loss: 0.2939 - iou_score: 0.6852 - f1-score: 0.8110For batch 161, tr_loss is    0.29.\n",
      "163/200 [=======================>......] - ETA: 32s - loss: 0.2936 - iou_score: 0.6857 - f1-score: 0.8114For batch 162, tr_loss is    0.29.\n",
      "164/200 [=======================>......] - ETA: 31s - loss: 0.2937 - iou_score: 0.6855 - f1-score: 0.8113For batch 163, tr_loss is    0.29.\n",
      "165/200 [=======================>......] - ETA: 31s - loss: 0.2935 - iou_score: 0.6859 - f1-score: 0.8115For batch 164, tr_loss is    0.29.\n",
      "166/200 [=======================>......] - ETA: 30s - loss: 0.2934 - iou_score: 0.6860 - f1-score: 0.8116For batch 165, tr_loss is    0.29.\n",
      "167/200 [========================>.....] - ETA: 29s - loss: 0.2929 - iou_score: 0.6868 - f1-score: 0.8121For batch 166, tr_loss is    0.29.\n",
      "168/200 [========================>.....] - ETA: 28s - loss: 0.2930 - iou_score: 0.6866 - f1-score: 0.8120For batch 167, tr_loss is    0.29.\n",
      "169/200 [========================>.....] - ETA: 27s - loss: 0.2933 - iou_score: 0.6864 - f1-score: 0.8118For batch 168, tr_loss is    0.29.\n",
      "170/200 [========================>.....] - ETA: 26s - loss: 0.2930 - iou_score: 0.6866 - f1-score: 0.8120For batch 169, tr_loss is    0.29.\n",
      "171/200 [========================>.....] - ETA: 25s - loss: 0.2932 - iou_score: 0.6865 - f1-score: 0.8120For batch 170, tr_loss is    0.29.\n",
      "172/200 [========================>.....] - ETA: 24s - loss: 0.2929 - iou_score: 0.6869 - f1-score: 0.8122For batch 171, tr_loss is    0.29.\n",
      "173/200 [========================>.....] - ETA: 23s - loss: 0.2928 - iou_score: 0.6870 - f1-score: 0.8123For batch 172, tr_loss is    0.29.\n",
      "174/200 [=========================>....] - ETA: 23s - loss: 0.2927 - iou_score: 0.6872 - f1-score: 0.8124For batch 173, tr_loss is    0.29.\n",
      "175/200 [=========================>....] - ETA: 22s - loss: 0.2924 - iou_score: 0.6875 - f1-score: 0.8126For batch 174, tr_loss is    0.29.\n",
      "176/200 [=========================>....] - ETA: 21s - loss: 0.2925 - iou_score: 0.6873 - f1-score: 0.8125For batch 175, tr_loss is    0.29.\n",
      "177/200 [=========================>....] - ETA: 20s - loss: 0.2924 - iou_score: 0.6874 - f1-score: 0.8126For batch 176, tr_loss is    0.29.\n",
      "178/200 [=========================>....] - ETA: 19s - loss: 0.2927 - iou_score: 0.6869 - f1-score: 0.8122For batch 177, tr_loss is    0.29.\n",
      "179/200 [=========================>....] - ETA: 18s - loss: 0.2924 - iou_score: 0.6873 - f1-score: 0.8125For batch 178, tr_loss is    0.29.\n",
      "180/200 [==========================>...] - ETA: 17s - loss: 0.2925 - iou_score: 0.6871 - f1-score: 0.8123For batch 179, tr_loss is    0.29.\n",
      "181/200 [==========================>...] - ETA: 16s - loss: 0.2928 - iou_score: 0.6868 - f1-score: 0.8121For batch 180, tr_loss is    0.29.\n",
      "182/200 [==========================>...] - ETA: 15s - loss: 0.2927 - iou_score: 0.6869 - f1-score: 0.8122For batch 181, tr_loss is    0.29.\n",
      "183/200 [==========================>...] - ETA: 15s - loss: 0.2928 - iou_score: 0.6865 - f1-score: 0.8120For batch 182, tr_loss is    0.29.\n",
      "184/200 [==========================>...] - ETA: 14s - loss: 0.2926 - iou_score: 0.6869 - f1-score: 0.8122For batch 183, tr_loss is    0.29.\n",
      "185/200 [==========================>...] - ETA: 13s - loss: 0.2924 - iou_score: 0.6871 - f1-score: 0.8124For batch 184, tr_loss is    0.29.\n",
      "186/200 [==========================>...] - ETA: 12s - loss: 0.2922 - iou_score: 0.6874 - f1-score: 0.8126For batch 185, tr_loss is    0.29.\n",
      "187/200 [===========================>..] - ETA: 11s - loss: 0.2921 - iou_score: 0.6877 - f1-score: 0.8127For batch 186, tr_loss is    0.29.\n",
      "188/200 [===========================>..] - ETA: 10s - loss: 0.2919 - iou_score: 0.6878 - f1-score: 0.8128For batch 187, tr_loss is    0.29.\n",
      "189/200 [===========================>..] - ETA: 9s - loss: 0.2924 - iou_score: 0.6875 - f1-score: 0.8126 For batch 188, tr_loss is    0.29.\n",
      "190/200 [===========================>..] - ETA: 8s - loss: 0.2923 - iou_score: 0.6875 - f1-score: 0.8126For batch 189, tr_loss is    0.29.\n",
      "191/200 [===========================>..] - ETA: 7s - loss: 0.2928 - iou_score: 0.6869 - f1-score: 0.8122For batch 190, tr_loss is    0.29.\n",
      "192/200 [===========================>..] - ETA: 7s - loss: 0.2933 - iou_score: 0.6864 - f1-score: 0.8118For batch 191, tr_loss is    0.29.\n",
      "193/200 [===========================>..] - ETA: 6s - loss: 0.2931 - iou_score: 0.6867 - f1-score: 0.8121For batch 192, tr_loss is    0.29.\n",
      "194/200 [============================>.] - ETA: 5s - loss: 0.2933 - iou_score: 0.6865 - f1-score: 0.8119For batch 193, tr_loss is    0.29.\n",
      "195/200 [============================>.] - ETA: 4s - loss: 0.2934 - iou_score: 0.6863 - f1-score: 0.8118For batch 194, tr_loss is    0.29.\n",
      "196/200 [============================>.] - ETA: 3s - loss: 0.2934 - iou_score: 0.6861 - f1-score: 0.8116For batch 195, tr_loss is    0.29.\n",
      "197/200 [============================>.] - ETA: 2s - loss: 0.2932 - iou_score: 0.6865 - f1-score: 0.8119For batch 196, tr_loss is    0.29.\n",
      "198/200 [============================>.] - ETA: 1s - loss: 0.2932 - iou_score: 0.6866 - f1-score: 0.8120For batch 197, tr_loss is    0.29.\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.2934 - iou_score: 0.6863 - f1-score: 0.8117For batch 198, tr_loss is    0.29.\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.2933 - iou_score: 0.6863 - f1-score: 0.8118For batch 199, tr_loss is    0.29.\n",
      "For batch 0, vl_loss is    0.37.\n",
      "For batch 1, vl_loss is    0.40.\n",
      "For batch 2, vl_loss is    0.40.\n",
      "For batch 3, vl_loss is    0.41.\n",
      "For batch 4, vl_loss is    0.41.\n",
      "For batch 5, vl_loss is    0.41.\n",
      "For batch 6, vl_loss is    0.43.\n",
      "For batch 7, vl_loss is    0.43.\n",
      "For batch 8, vl_loss is    0.43.\n",
      "For batch 9, vl_loss is    0.42.\n",
      "For batch 10, vl_loss is    0.43.\n",
      "For batch 11, vl_loss is    0.42.\n",
      "For batch 12, vl_loss is    0.42.\n",
      "For batch 13, vl_loss is    0.42.\n",
      "For batch 14, vl_loss is    0.42.\n",
      "For batch 15, vl_loss is    0.42.\n",
      "For batch 16, vl_loss is    0.41.\n",
      "For batch 17, vl_loss is    0.41.\n",
      "For batch 18, vl_loss is    0.41.\n",
      "For batch 19, vl_loss is    0.41.\n",
      "For batch 20, vl_loss is    0.41.\n",
      "For batch 21, vl_loss is    0.41.\n",
      "For batch 22, vl_loss is    0.41.\n",
      "For batch 23, vl_loss is    0.41.\n",
      "For batch 24, vl_loss is    0.41.\n",
      "For batch 25, vl_loss is    0.41.\n",
      "For batch 26, vl_loss is    0.41.\n",
      "For batch 27, vl_loss is    0.41.\n",
      "For batch 28, vl_loss is    0.41.\n",
      "For batch 29, vl_loss is    0.41.\n",
      "For batch 30, vl_loss is    0.41.\n",
      "For batch 31, vl_loss is    0.41.\n",
      "For batch 32, vl_loss is    0.41.\n",
      "For batch 33, vl_loss is    0.41.\n",
      "For batch 34, vl_loss is    0.41.\n",
      "For batch 35, vl_loss is    0.41.\n",
      "For batch 36, vl_loss is    0.41.\n",
      "For batch 37, vl_loss is    0.40.\n",
      "For batch 38, vl_loss is    0.40.\n",
      "For batch 39, vl_loss is    0.40.\n",
      "For batch 40, vl_loss is    0.41.\n",
      "For batch 41, vl_loss is    0.40.\n",
      "For batch 42, vl_loss is    0.40.\n",
      "For batch 43, vl_loss is    0.40.\n",
      "For batch 44, vl_loss is    0.40.\n",
      "For batch 45, vl_loss is    0.41.\n",
      "For batch 46, vl_loss is    0.41.\n",
      "For batch 47, vl_loss is    0.41.\n",
      "For batch 48, vl_loss is    0.40.\n",
      "For batch 49, vl_loss is    0.40.\n",
      "For batch 50, vl_loss is    0.40.\n",
      "For batch 51, vl_loss is    0.40.\n",
      "For batch 52, vl_loss is    0.40.\n",
      "For batch 53, vl_loss is    0.40.\n",
      "For batch 54, vl_loss is    0.40.\n",
      "For batch 55, vl_loss is    0.40.\n",
      "For batch 56, vl_loss is    0.40.\n",
      "For batch 57, vl_loss is    0.40.\n",
      "For batch 58, vl_loss is    0.40.\n",
      "For batch 59, vl_loss is    0.40.\n",
      "For batch 60, vl_loss is    0.40.\n",
      "For batch 61, vl_loss is    0.40.\n",
      "For batch 62, vl_loss is    0.40.\n",
      "For batch 63, vl_loss is    0.40.\n",
      "For batch 64, vl_loss is    0.40.\n",
      "For batch 65, vl_loss is    0.40.\n",
      "For batch 66, vl_loss is    0.40.\n",
      "For batch 67, vl_loss is    0.40.\n",
      "For batch 68, vl_loss is    0.41.\n",
      "For batch 69, vl_loss is    0.41.\n",
      "For batch 70, vl_loss is    0.41.\n",
      "For batch 71, vl_loss is    0.41.\n",
      "For batch 72, vl_loss is    0.41.\n",
      "For batch 73, vl_loss is    0.41.\n",
      "For batch 74, vl_loss is    0.41.\n",
      "For batch 75, vl_loss is    0.41.\n",
      "For batch 76, vl_loss is    0.41.\n",
      "For batch 77, vl_loss is    0.41.\n",
      "For batch 78, vl_loss is    0.41.\n",
      "For batch 79, vl_loss is    0.41.\n",
      "For batch 80, vl_loss is    0.41.\n",
      "For batch 81, vl_loss is    0.41.\n",
      "For batch 82, vl_loss is    0.41.\n",
      "For batch 83, vl_loss is    0.41.\n",
      "For batch 84, vl_loss is    0.41.\n",
      "For batch 85, vl_loss is    0.41.\n",
      "For batch 86, vl_loss is    0.41.\n",
      "For batch 87, vl_loss is    0.41.\n",
      "For batch 88, vl_loss is    0.41.\n",
      "For batch 89, vl_loss is    0.41.\n",
      "For batch 90, vl_loss is    0.41.\n",
      "For batch 91, vl_loss is    0.41.\n",
      "For batch 92, vl_loss is    0.41.\n",
      "For batch 93, vl_loss is    0.41.\n",
      "For batch 94, vl_loss is    0.41.\n",
      "For batch 95, vl_loss is    0.41.\n",
      "For batch 96, vl_loss is    0.41.\n",
      "For batch 97, vl_loss is    0.41.\n",
      "For batch 98, vl_loss is    0.41.\n",
      "For batch 99, vl_loss is    0.41.\n",
      "200/200 [==============================] - 183s 906ms/step - loss: 0.2933 - iou_score: 0.6863 - f1-score: 0.8118 - val_loss: 0.4082 - val_iou_score: 0.5840 - val_f1-score: 0.7342\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.32441\n",
      "The average loss for epoch 10 is    0.29 \n",
      "Epoch 12/200\n",
      "  1/200 [..............................] - ETA: 8:36 - loss: 0.2818 - iou_score: 0.6915 - f1-score: 0.8174For batch 0, tr_loss is    0.28.\n",
      "  2/200 [..............................] - ETA: 4:55 - loss: 0.2826 - iou_score: 0.6991 - f1-score: 0.8227For batch 1, tr_loss is    0.28.\n",
      "  3/200 [..............................] - ETA: 4:31 - loss: 0.2798 - iou_score: 0.7064 - f1-score: 0.8273For batch 2, tr_loss is    0.28.\n",
      "  4/200 [..............................] - ETA: 4:15 - loss: 0.2824 - iou_score: 0.6942 - f1-score: 0.8187For batch 3, tr_loss is    0.28.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5/200 [..............................] - ETA: 4:08 - loss: 0.2828 - iou_score: 0.6947 - f1-score: 0.8190For batch 4, tr_loss is    0.28.\n",
      "  6/200 [..............................] - ETA: 4:04 - loss: 0.2935 - iou_score: 0.6834 - f1-score: 0.8109For batch 5, tr_loss is    0.29.\n",
      "  7/200 [>.............................] - ETA: 3:51 - loss: 0.3053 - iou_score: 0.6730 - f1-score: 0.8030For batch 6, tr_loss is    0.31.\n",
      "  8/200 [>.............................] - ETA: 3:42 - loss: 0.3049 - iou_score: 0.6733 - f1-score: 0.8032For batch 7, tr_loss is    0.30.\n",
      "  9/200 [>.............................] - ETA: 3:58 - loss: 0.3016 - iou_score: 0.6781 - f1-score: 0.8065For batch 8, tr_loss is    0.30.\n",
      " 10/200 [>.............................] - ETA: 3:56 - loss: 0.3006 - iou_score: 0.6778 - f1-score: 0.8060For batch 9, tr_loss is    0.30.\n",
      " 11/200 [>.............................] - ETA: 3:42 - loss: 0.2990 - iou_score: 0.6811 - f1-score: 0.8083For batch 10, tr_loss is    0.30.\n",
      " 12/200 [>.............................] - ETA: 3:41 - loss: 0.3015 - iou_score: 0.6768 - f1-score: 0.8052For batch 11, tr_loss is    0.30.\n",
      " 13/200 [>.............................] - ETA: 3:33 - loss: 0.3027 - iou_score: 0.6742 - f1-score: 0.8034For batch 12, tr_loss is    0.30.\n",
      " 14/200 [=>............................] - ETA: 3:30 - loss: 0.3043 - iou_score: 0.6735 - f1-score: 0.8029For batch 13, tr_loss is    0.30.\n",
      " 15/200 [=>............................] - ETA: 3:20 - loss: 0.3009 - iou_score: 0.6763 - f1-score: 0.8050For batch 14, tr_loss is    0.30.\n",
      " 16/200 [=>............................] - ETA: 3:15 - loss: 0.3004 - iou_score: 0.6759 - f1-score: 0.8048For batch 15, tr_loss is    0.30.\n",
      " 17/200 [=>............................] - ETA: 3:14 - loss: 0.2982 - iou_score: 0.6790 - f1-score: 0.8071For batch 16, tr_loss is    0.30.\n",
      " 18/200 [=>............................] - ETA: 3:12 - loss: 0.2963 - iou_score: 0.6808 - f1-score: 0.8084For batch 17, tr_loss is    0.30.\n",
      " 19/200 [=>............................] - ETA: 3:11 - loss: 0.2976 - iou_score: 0.6785 - f1-score: 0.8066For batch 18, tr_loss is    0.30.\n",
      " 20/200 [==>...........................] - ETA: 3:04 - loss: 0.2944 - iou_score: 0.6831 - f1-score: 0.8098For batch 19, tr_loss is    0.29.\n",
      " 21/200 [==>...........................] - ETA: 3:03 - loss: 0.2923 - iou_score: 0.6857 - f1-score: 0.8116For batch 20, tr_loss is    0.29.\n",
      " 22/200 [==>...........................] - ETA: 3:02 - loss: 0.2910 - iou_score: 0.6868 - f1-score: 0.8125For batch 21, tr_loss is    0.29.\n",
      " 23/200 [==>...........................] - ETA: 2:59 - loss: 0.2895 - iou_score: 0.6891 - f1-score: 0.8141For batch 22, tr_loss is    0.29.\n",
      " 24/200 [==>...........................] - ETA: 2:58 - loss: 0.2886 - iou_score: 0.6899 - f1-score: 0.8147For batch 23, tr_loss is    0.29.\n",
      " 25/200 [==>...........................] - ETA: 2:57 - loss: 0.2875 - iou_score: 0.6911 - f1-score: 0.8156For batch 24, tr_loss is    0.29.\n",
      " 26/200 [==>...........................] - ETA: 2:56 - loss: 0.2906 - iou_score: 0.6892 - f1-score: 0.8143For batch 25, tr_loss is    0.29.\n",
      " 27/200 [===>..........................] - ETA: 2:55 - loss: 0.2896 - iou_score: 0.6906 - f1-score: 0.8152For batch 26, tr_loss is    0.29.\n",
      " 28/200 [===>..........................] - ETA: 2:54 - loss: 0.2897 - iou_score: 0.6914 - f1-score: 0.8158For batch 27, tr_loss is    0.29.\n",
      " 29/200 [===>..........................] - ETA: 2:53 - loss: 0.2899 - iou_score: 0.6908 - f1-score: 0.8155For batch 28, tr_loss is    0.29.\n",
      " 30/200 [===>..........................] - ETA: 2:52 - loss: 0.2883 - iou_score: 0.6929 - f1-score: 0.8169For batch 29, tr_loss is    0.29.\n",
      " 31/200 [===>..........................] - ETA: 2:51 - loss: 0.2863 - iou_score: 0.6948 - f1-score: 0.8183For batch 30, tr_loss is    0.29.\n",
      " 32/200 [===>..........................] - ETA: 2:47 - loss: 0.2854 - iou_score: 0.6962 - f1-score: 0.8193For batch 31, tr_loss is    0.29.\n",
      " 33/200 [===>..........................] - ETA: 2:44 - loss: 0.2846 - iou_score: 0.6968 - f1-score: 0.8197For batch 32, tr_loss is    0.28.\n",
      " 34/200 [====>.........................] - ETA: 2:42 - loss: 0.2851 - iou_score: 0.6958 - f1-score: 0.8190For batch 33, tr_loss is    0.29.\n",
      " 35/200 [====>.........................] - ETA: 2:39 - loss: 0.2848 - iou_score: 0.6966 - f1-score: 0.8196For batch 34, tr_loss is    0.28.\n",
      " 36/200 [====>.........................] - ETA: 2:38 - loss: 0.2847 - iou_score: 0.6968 - f1-score: 0.8197For batch 35, tr_loss is    0.28.\n",
      " 37/200 [====>.........................] - ETA: 2:37 - loss: 0.2858 - iou_score: 0.6956 - f1-score: 0.8188For batch 36, tr_loss is    0.29.\n",
      " 38/200 [====>.........................] - ETA: 2:36 - loss: 0.2867 - iou_score: 0.6942 - f1-score: 0.8179For batch 37, tr_loss is    0.29.\n",
      " 39/200 [====>.........................] - ETA: 2:36 - loss: 0.2859 - iou_score: 0.6947 - f1-score: 0.8183For batch 38, tr_loss is    0.29.\n",
      " 40/200 [=====>........................] - ETA: 2:35 - loss: 0.2845 - iou_score: 0.6965 - f1-score: 0.8195For batch 39, tr_loss is    0.28.\n",
      " 41/200 [=====>........................] - ETA: 2:34 - loss: 0.2838 - iou_score: 0.6971 - f1-score: 0.8199For batch 40, tr_loss is    0.28.\n",
      " 42/200 [=====>........................] - ETA: 2:33 - loss: 0.2845 - iou_score: 0.6961 - f1-score: 0.8192For batch 41, tr_loss is    0.28.\n",
      " 43/200 [=====>........................] - ETA: 2:31 - loss: 0.2845 - iou_score: 0.6959 - f1-score: 0.8191For batch 42, tr_loss is    0.28.\n",
      " 44/200 [=====>........................] - ETA: 2:29 - loss: 0.2837 - iou_score: 0.6971 - f1-score: 0.8199For batch 43, tr_loss is    0.28.\n",
      " 45/200 [=====>........................] - ETA: 2:27 - loss: 0.2836 - iou_score: 0.6970 - f1-score: 0.8199For batch 44, tr_loss is    0.28.\n",
      " 46/200 [=====>........................] - ETA: 2:26 - loss: 0.2855 - iou_score: 0.6959 - f1-score: 0.8190For batch 45, tr_loss is    0.29.\n",
      " 47/200 [======>.......................] - ETA: 2:25 - loss: 0.2856 - iou_score: 0.6958 - f1-score: 0.8190For batch 46, tr_loss is    0.29.\n",
      " 48/200 [======>.......................] - ETA: 2:25 - loss: 0.2855 - iou_score: 0.6961 - f1-score: 0.8191For batch 47, tr_loss is    0.29.\n",
      " 49/200 [======>.......................] - ETA: 2:22 - loss: 0.2850 - iou_score: 0.6963 - f1-score: 0.8193For batch 48, tr_loss is    0.29.\n",
      " 50/200 [======>.......................] - ETA: 2:21 - loss: 0.2832 - iou_score: 0.6985 - f1-score: 0.8208For batch 49, tr_loss is    0.28.\n",
      " 51/200 [======>.......................] - ETA: 2:19 - loss: 0.2826 - iou_score: 0.6995 - f1-score: 0.8215For batch 50, tr_loss is    0.28.\n",
      " 52/200 [======>.......................] - ETA: 2:17 - loss: 0.2825 - iou_score: 0.6993 - f1-score: 0.8212For batch 51, tr_loss is    0.28.\n",
      " 53/200 [======>.......................] - ETA: 2:16 - loss: 0.2822 - iou_score: 0.6995 - f1-score: 0.8214For batch 52, tr_loss is    0.28.\n",
      " 54/200 [=======>......................] - ETA: 2:16 - loss: 0.2826 - iou_score: 0.6990 - f1-score: 0.8211For batch 53, tr_loss is    0.28.\n",
      " 55/200 [=======>......................] - ETA: 2:15 - loss: 0.2816 - iou_score: 0.7001 - f1-score: 0.8218For batch 54, tr_loss is    0.28.\n",
      " 56/200 [=======>......................] - ETA: 2:14 - loss: 0.2816 - iou_score: 0.6999 - f1-score: 0.8217For batch 55, tr_loss is    0.28.\n",
      " 57/200 [=======>......................] - ETA: 2:12 - loss: 0.2813 - iou_score: 0.6997 - f1-score: 0.8216For batch 56, tr_loss is    0.28.\n",
      " 58/200 [=======>......................] - ETA: 2:11 - loss: 0.2808 - iou_score: 0.7002 - f1-score: 0.8220For batch 57, tr_loss is    0.28.\n",
      " 59/200 [=======>......................] - ETA: 2:10 - loss: 0.2799 - iou_score: 0.7014 - f1-score: 0.8228For batch 58, tr_loss is    0.28.\n",
      " 60/200 [========>.....................] - ETA: 2:10 - loss: 0.2791 - iou_score: 0.7016 - f1-score: 0.8229For batch 59, tr_loss is    0.28.\n",
      " 61/200 [========>.....................] - ETA: 2:09 - loss: 0.2801 - iou_score: 0.7012 - f1-score: 0.8227For batch 60, tr_loss is    0.28.\n",
      " 62/200 [========>.....................] - ETA: 2:08 - loss: 0.2801 - iou_score: 0.7008 - f1-score: 0.8224For batch 61, tr_loss is    0.28.\n",
      " 63/200 [========>.....................] - ETA: 2:07 - loss: 0.2793 - iou_score: 0.7014 - f1-score: 0.8228For batch 62, tr_loss is    0.28.\n",
      " 64/200 [========>.....................] - ETA: 2:06 - loss: 0.2806 - iou_score: 0.7000 - f1-score: 0.8218For batch 63, tr_loss is    0.28.\n",
      " 65/200 [========>.....................] - ETA: 2:04 - loss: 0.2794 - iou_score: 0.7013 - f1-score: 0.8227For batch 64, tr_loss is    0.28.\n",
      " 66/200 [========>.....................] - ETA: 2:04 - loss: 0.2812 - iou_score: 0.6995 - f1-score: 0.8213For batch 65, tr_loss is    0.28.\n",
      " 67/200 [=========>....................] - ETA: 2:03 - loss: 0.2804 - iou_score: 0.7002 - f1-score: 0.8218For batch 66, tr_loss is    0.28.\n",
      " 68/200 [=========>....................] - ETA: 2:02 - loss: 0.2802 - iou_score: 0.7004 - f1-score: 0.8220For batch 67, tr_loss is    0.28.\n",
      " 69/200 [=========>....................] - ETA: 2:01 - loss: 0.2812 - iou_score: 0.6990 - f1-score: 0.8209For batch 68, tr_loss is    0.28.\n",
      " 70/200 [=========>....................] - ETA: 2:00 - loss: 0.2810 - iou_score: 0.6993 - f1-score: 0.8212For batch 69, tr_loss is    0.28.\n",
      " 71/200 [=========>....................] - ETA: 1:59 - loss: 0.2807 - iou_score: 0.6996 - f1-score: 0.8215For batch 70, tr_loss is    0.28.\n",
      " 72/200 [=========>....................] - ETA: 1:58 - loss: 0.2807 - iou_score: 0.6995 - f1-score: 0.8214For batch 71, tr_loss is    0.28.\n",
      " 73/200 [=========>....................] - ETA: 1:57 - loss: 0.2801 - iou_score: 0.7001 - f1-score: 0.8218For batch 72, tr_loss is    0.28.\n",
      " 74/200 [==========>...................] - ETA: 1:56 - loss: 0.2802 - iou_score: 0.6996 - f1-score: 0.8215For batch 73, tr_loss is    0.28.\n",
      " 75/200 [==========>...................] - ETA: 1:55 - loss: 0.2810 - iou_score: 0.6989 - f1-score: 0.8209For batch 74, tr_loss is    0.28.\n",
      " 76/200 [==========>...................] - ETA: 1:54 - loss: 0.2814 - iou_score: 0.6982 - f1-score: 0.8205For batch 75, tr_loss is    0.28.\n",
      " 77/200 [==========>...................] - ETA: 1:53 - loss: 0.2812 - iou_score: 0.6981 - f1-score: 0.8204For batch 76, tr_loss is    0.28.\n",
      " 78/200 [==========>...................] - ETA: 1:53 - loss: 0.2806 - iou_score: 0.6987 - f1-score: 0.8209For batch 77, tr_loss is    0.28.\n",
      " 79/200 [==========>...................] - ETA: 1:52 - loss: 0.2809 - iou_score: 0.6985 - f1-score: 0.8207For batch 78, tr_loss is    0.28.\n",
      " 80/200 [===========>..................] - ETA: 1:51 - loss: 0.2803 - iou_score: 0.6990 - f1-score: 0.8211For batch 79, tr_loss is    0.28.\n",
      " 81/200 [===========>..................] - ETA: 1:49 - loss: 0.2794 - iou_score: 0.7004 - f1-score: 0.8220For batch 80, tr_loss is    0.28.\n",
      " 82/200 [===========>..................] - ETA: 1:48 - loss: 0.2791 - iou_score: 0.7007 - f1-score: 0.8222For batch 81, tr_loss is    0.28.\n",
      " 83/200 [===========>..................] - ETA: 1:47 - loss: 0.2795 - iou_score: 0.7003 - f1-score: 0.8219For batch 82, tr_loss is    0.28.\n",
      " 84/200 [===========>..................] - ETA: 1:46 - loss: 0.2791 - iou_score: 0.7004 - f1-score: 0.8220For batch 83, tr_loss is    0.28.\n",
      " 85/200 [===========>..................] - ETA: 1:46 - loss: 0.2800 - iou_score: 0.6991 - f1-score: 0.8210For batch 84, tr_loss is    0.28.\n",
      " 86/200 [===========>..................] - ETA: 1:44 - loss: 0.2804 - iou_score: 0.6984 - f1-score: 0.8206For batch 85, tr_loss is    0.28.\n",
      " 87/200 [============>.................] - ETA: 1:43 - loss: 0.2800 - iou_score: 0.6989 - f1-score: 0.8209For batch 86, tr_loss is    0.28.\n",
      " 88/200 [============>.................] - ETA: 1:42 - loss: 0.2796 - iou_score: 0.6995 - f1-score: 0.8213For batch 87, tr_loss is    0.28.\n",
      " 89/200 [============>.................] - ETA: 1:41 - loss: 0.2802 - iou_score: 0.6989 - f1-score: 0.8209For batch 88, tr_loss is    0.28.\n",
      " 90/200 [============>.................] - ETA: 1:40 - loss: 0.2803 - iou_score: 0.6987 - f1-score: 0.8208For batch 89, tr_loss is    0.28.\n",
      " 91/200 [============>.................] - ETA: 1:39 - loss: 0.2807 - iou_score: 0.6984 - f1-score: 0.8206For batch 90, tr_loss is    0.28.\n",
      " 92/200 [============>.................] - ETA: 1:38 - loss: 0.2817 - iou_score: 0.6975 - f1-score: 0.8200For batch 91, tr_loss is    0.28.\n",
      " 93/200 [============>.................] - ETA: 1:37 - loss: 0.2816 - iou_score: 0.6976 - f1-score: 0.8201For batch 92, tr_loss is    0.28.\n",
      " 94/200 [=============>................] - ETA: 1:36 - loss: 0.2827 - iou_score: 0.6959 - f1-score: 0.8188For batch 93, tr_loss is    0.28.\n",
      " 95/200 [=============>................] - ETA: 1:34 - loss: 0.2830 - iou_score: 0.6956 - f1-score: 0.8185For batch 94, tr_loss is    0.28.\n",
      " 96/200 [=============>................] - ETA: 1:34 - loss: 0.2826 - iou_score: 0.6958 - f1-score: 0.8187For batch 95, tr_loss is    0.28.\n",
      " 97/200 [=============>................] - ETA: 1:33 - loss: 0.2830 - iou_score: 0.6949 - f1-score: 0.8181For batch 96, tr_loss is    0.28.\n",
      " 98/200 [=============>................] - ETA: 1:32 - loss: 0.2834 - iou_score: 0.6948 - f1-score: 0.8180For batch 97, tr_loss is    0.28.\n",
      " 99/200 [=============>................] - ETA: 1:31 - loss: 0.2829 - iou_score: 0.6954 - f1-score: 0.8184For batch 98, tr_loss is    0.28.\n",
      "100/200 [==============>...............] - ETA: 1:31 - loss: 0.2834 - iou_score: 0.6949 - f1-score: 0.8181For batch 99, tr_loss is    0.28.\n",
      "101/200 [==============>...............] - ETA: 1:30 - loss: 0.2834 - iou_score: 0.6950 - f1-score: 0.8182For batch 100, tr_loss is    0.28.\n",
      "102/200 [==============>...............] - ETA: 1:28 - loss: 0.2839 - iou_score: 0.6943 - f1-score: 0.8177For batch 101, tr_loss is    0.28.\n",
      "103/200 [==============>...............] - ETA: 1:27 - loss: 0.2840 - iou_score: 0.6942 - f1-score: 0.8176For batch 102, tr_loss is    0.28.\n",
      "104/200 [==============>...............] - ETA: 1:27 - loss: 0.2843 - iou_score: 0.6937 - f1-score: 0.8173For batch 103, tr_loss is    0.28.\n",
      "105/200 [==============>...............] - ETA: 1:26 - loss: 0.2844 - iou_score: 0.6935 - f1-score: 0.8172For batch 104, tr_loss is    0.28.\n",
      "106/200 [==============>...............] - ETA: 1:25 - loss: 0.2849 - iou_score: 0.6932 - f1-score: 0.8169For batch 105, tr_loss is    0.28.\n",
      "107/200 [===============>..............] - ETA: 1:24 - loss: 0.2849 - iou_score: 0.6930 - f1-score: 0.8168For batch 106, tr_loss is    0.28.\n",
      "108/200 [===============>..............] - ETA: 1:23 - loss: 0.2849 - iou_score: 0.6932 - f1-score: 0.8169For batch 107, tr_loss is    0.28.\n",
      "109/200 [===============>..............] - ETA: 1:23 - loss: 0.2849 - iou_score: 0.6932 - f1-score: 0.8170For batch 108, tr_loss is    0.28.\n",
      "110/200 [===============>..............] - ETA: 1:22 - loss: 0.2848 - iou_score: 0.6934 - f1-score: 0.8171For batch 109, tr_loss is    0.28.\n",
      "111/200 [===============>..............] - ETA: 1:21 - loss: 0.2844 - iou_score: 0.6938 - f1-score: 0.8174For batch 110, tr_loss is    0.28.\n",
      "112/200 [===============>..............] - ETA: 1:20 - loss: 0.2841 - iou_score: 0.6940 - f1-score: 0.8175For batch 111, tr_loss is    0.28.\n",
      "113/200 [===============>..............] - ETA: 1:19 - loss: 0.2851 - iou_score: 0.6927 - f1-score: 0.8165For batch 112, tr_loss is    0.29.\n",
      "114/200 [================>.............] - ETA: 1:18 - loss: 0.2860 - iou_score: 0.6920 - f1-score: 0.8160For batch 113, tr_loss is    0.29.\n",
      "115/200 [================>.............] - ETA: 1:18 - loss: 0.2860 - iou_score: 0.6920 - f1-score: 0.8160For batch 114, tr_loss is    0.29.\n",
      "116/200 [================>.............] - ETA: 1:16 - loss: 0.2866 - iou_score: 0.6913 - f1-score: 0.8155For batch 115, tr_loss is    0.29.\n",
      "117/200 [================>.............] - ETA: 1:15 - loss: 0.2867 - iou_score: 0.6913 - f1-score: 0.8155For batch 116, tr_loss is    0.29.\n",
      "118/200 [================>.............] - ETA: 1:14 - loss: 0.2865 - iou_score: 0.6915 - f1-score: 0.8156For batch 117, tr_loss is    0.29.\n",
      "119/200 [================>.............] - ETA: 1:14 - loss: 0.2868 - iou_score: 0.6912 - f1-score: 0.8155For batch 118, tr_loss is    0.29.\n",
      "120/200 [=================>............] - ETA: 1:12 - loss: 0.2865 - iou_score: 0.6916 - f1-score: 0.8157For batch 119, tr_loss is    0.29.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/200 [=================>............] - ETA: 1:12 - loss: 0.2864 - iou_score: 0.6919 - f1-score: 0.8160For batch 120, tr_loss is    0.29.\n",
      "122/200 [=================>............] - ETA: 1:11 - loss: 0.2863 - iou_score: 0.6920 - f1-score: 0.8160For batch 121, tr_loss is    0.29.\n",
      "123/200 [=================>............] - ETA: 1:10 - loss: 0.2872 - iou_score: 0.6910 - f1-score: 0.8153For batch 122, tr_loss is    0.29.\n",
      "124/200 [=================>............] - ETA: 1:09 - loss: 0.2874 - iou_score: 0.6908 - f1-score: 0.8152For batch 123, tr_loss is    0.29.\n",
      "125/200 [=================>............] - ETA: 1:08 - loss: 0.2875 - iou_score: 0.6906 - f1-score: 0.8150For batch 124, tr_loss is    0.29.\n",
      "126/200 [=================>............] - ETA: 1:07 - loss: 0.2875 - iou_score: 0.6908 - f1-score: 0.8151For batch 125, tr_loss is    0.29.\n",
      "127/200 [==================>...........] - ETA: 1:06 - loss: 0.2875 - iou_score: 0.6908 - f1-score: 0.8152For batch 126, tr_loss is    0.29.\n",
      "128/200 [==================>...........] - ETA: 1:05 - loss: 0.2882 - iou_score: 0.6898 - f1-score: 0.8144For batch 127, tr_loss is    0.29.\n",
      "129/200 [==================>...........] - ETA: 1:04 - loss: 0.2882 - iou_score: 0.6897 - f1-score: 0.8144For batch 128, tr_loss is    0.29.\n",
      "130/200 [==================>...........] - ETA: 1:03 - loss: 0.2880 - iou_score: 0.6901 - f1-score: 0.8147For batch 129, tr_loss is    0.29.\n",
      "131/200 [==================>...........] - ETA: 1:02 - loss: 0.2877 - iou_score: 0.6904 - f1-score: 0.8149For batch 130, tr_loss is    0.29.\n",
      "132/200 [==================>...........] - ETA: 1:01 - loss: 0.2875 - iou_score: 0.6907 - f1-score: 0.8151For batch 131, tr_loss is    0.29.\n",
      "133/200 [==================>...........] - ETA: 1:00 - loss: 0.2879 - iou_score: 0.6905 - f1-score: 0.8149For batch 132, tr_loss is    0.29.\n",
      "134/200 [===================>..........] - ETA: 1:00 - loss: 0.2885 - iou_score: 0.6898 - f1-score: 0.8144For batch 133, tr_loss is    0.29.\n",
      "135/200 [===================>..........] - ETA: 59s - loss: 0.2889 - iou_score: 0.6895 - f1-score: 0.8142 For batch 134, tr_loss is    0.29.\n",
      "136/200 [===================>..........] - ETA: 58s - loss: 0.2889 - iou_score: 0.6893 - f1-score: 0.8141For batch 135, tr_loss is    0.29.\n",
      "137/200 [===================>..........] - ETA: 57s - loss: 0.2897 - iou_score: 0.6883 - f1-score: 0.8134For batch 136, tr_loss is    0.29.\n",
      "138/200 [===================>..........] - ETA: 56s - loss: 0.2898 - iou_score: 0.6882 - f1-score: 0.8132For batch 137, tr_loss is    0.29.\n",
      "139/200 [===================>..........] - ETA: 55s - loss: 0.2895 - iou_score: 0.6886 - f1-score: 0.8135For batch 138, tr_loss is    0.29.\n",
      "140/200 [====================>.........] - ETA: 54s - loss: 0.2909 - iou_score: 0.6873 - f1-score: 0.8125For batch 139, tr_loss is    0.29.\n",
      "141/200 [====================>.........] - ETA: 53s - loss: 0.2913 - iou_score: 0.6867 - f1-score: 0.8121For batch 140, tr_loss is    0.29.\n",
      "142/200 [====================>.........] - ETA: 52s - loss: 0.2913 - iou_score: 0.6868 - f1-score: 0.8121For batch 141, tr_loss is    0.29.\n",
      "143/200 [====================>.........] - ETA: 51s - loss: 0.2913 - iou_score: 0.6868 - f1-score: 0.8121For batch 142, tr_loss is    0.29.\n",
      "144/200 [====================>.........] - ETA: 50s - loss: 0.2913 - iou_score: 0.6865 - f1-score: 0.8119For batch 143, tr_loss is    0.29.\n",
      "145/200 [====================>.........] - ETA: 49s - loss: 0.2915 - iou_score: 0.6862 - f1-score: 0.8117For batch 144, tr_loss is    0.29.\n",
      "146/200 [====================>.........] - ETA: 48s - loss: 0.2913 - iou_score: 0.6868 - f1-score: 0.8121For batch 145, tr_loss is    0.29.\n",
      "147/200 [=====================>........] - ETA: 47s - loss: 0.2914 - iou_score: 0.6866 - f1-score: 0.8120For batch 146, tr_loss is    0.29.\n",
      "148/200 [=====================>........] - ETA: 46s - loss: 0.2909 - iou_score: 0.6874 - f1-score: 0.8125For batch 147, tr_loss is    0.29.\n",
      "149/200 [=====================>........] - ETA: 45s - loss: 0.2906 - iou_score: 0.6877 - f1-score: 0.8127For batch 148, tr_loss is    0.29.\n",
      "150/200 [=====================>........] - ETA: 44s - loss: 0.2901 - iou_score: 0.6884 - f1-score: 0.8131For batch 149, tr_loss is    0.29.\n",
      "151/200 [=====================>........] - ETA: 43s - loss: 0.2902 - iou_score: 0.6884 - f1-score: 0.8131For batch 150, tr_loss is    0.29.\n",
      "152/200 [=====================>........] - ETA: 43s - loss: 0.2901 - iou_score: 0.6885 - f1-score: 0.8132For batch 151, tr_loss is    0.29.\n",
      "153/200 [=====================>........] - ETA: 42s - loss: 0.2900 - iou_score: 0.6885 - f1-score: 0.8133For batch 152, tr_loss is    0.29.\n",
      "154/200 [======================>.......] - ETA: 41s - loss: 0.2899 - iou_score: 0.6886 - f1-score: 0.8134For batch 153, tr_loss is    0.29.\n",
      "155/200 [======================>.......] - ETA: 40s - loss: 0.2900 - iou_score: 0.6886 - f1-score: 0.8134For batch 154, tr_loss is    0.29.\n",
      "156/200 [======================>.......] - ETA: 39s - loss: 0.2898 - iou_score: 0.6889 - f1-score: 0.8135For batch 155, tr_loss is    0.29.\n",
      "157/200 [======================>.......] - ETA: 38s - loss: 0.2900 - iou_score: 0.6886 - f1-score: 0.8133For batch 156, tr_loss is    0.29.\n",
      "158/200 [======================>.......] - ETA: 37s - loss: 0.2902 - iou_score: 0.6884 - f1-score: 0.8132For batch 157, tr_loss is    0.29.\n",
      "159/200 [======================>.......] - ETA: 36s - loss: 0.2904 - iou_score: 0.6881 - f1-score: 0.8130For batch 158, tr_loss is    0.29.\n",
      "160/200 [=======================>......] - ETA: 36s - loss: 0.2903 - iou_score: 0.6881 - f1-score: 0.8131For batch 159, tr_loss is    0.29.\n",
      "161/200 [=======================>......] - ETA: 35s - loss: 0.2906 - iou_score: 0.6878 - f1-score: 0.8128For batch 160, tr_loss is    0.29.\n",
      "162/200 [=======================>......] - ETA: 34s - loss: 0.2905 - iou_score: 0.6877 - f1-score: 0.8128For batch 161, tr_loss is    0.29.\n",
      "163/200 [=======================>......] - ETA: 33s - loss: 0.2901 - iou_score: 0.6881 - f1-score: 0.8130For batch 162, tr_loss is    0.29.\n",
      "164/200 [=======================>......] - ETA: 32s - loss: 0.2901 - iou_score: 0.6881 - f1-score: 0.8131For batch 163, tr_loss is    0.29.\n",
      "165/200 [=======================>......] - ETA: 31s - loss: 0.2899 - iou_score: 0.6885 - f1-score: 0.8134For batch 164, tr_loss is    0.29.\n",
      "166/200 [=======================>......] - ETA: 30s - loss: 0.2899 - iou_score: 0.6885 - f1-score: 0.8133For batch 165, tr_loss is    0.29.\n",
      "167/200 [========================>.....] - ETA: 29s - loss: 0.2895 - iou_score: 0.6891 - f1-score: 0.8137For batch 166, tr_loss is    0.29.\n",
      "168/200 [========================>.....] - ETA: 28s - loss: 0.2899 - iou_score: 0.6886 - f1-score: 0.8134For batch 167, tr_loss is    0.29.\n",
      "169/200 [========================>.....] - ETA: 27s - loss: 0.2901 - iou_score: 0.6882 - f1-score: 0.8131For batch 168, tr_loss is    0.29.\n",
      "170/200 [========================>.....] - ETA: 26s - loss: 0.2899 - iou_score: 0.6885 - f1-score: 0.8133For batch 169, tr_loss is    0.29.\n",
      "171/200 [========================>.....] - ETA: 26s - loss: 0.2900 - iou_score: 0.6883 - f1-score: 0.8132For batch 170, tr_loss is    0.29.\n",
      "172/200 [========================>.....] - ETA: 25s - loss: 0.2897 - iou_score: 0.6887 - f1-score: 0.8135For batch 171, tr_loss is    0.29.\n",
      "173/200 [========================>.....] - ETA: 24s - loss: 0.2898 - iou_score: 0.6887 - f1-score: 0.8134For batch 172, tr_loss is    0.29.\n",
      "174/200 [=========================>....] - ETA: 23s - loss: 0.2896 - iou_score: 0.6888 - f1-score: 0.8135For batch 173, tr_loss is    0.29.\n",
      "175/200 [=========================>....] - ETA: 22s - loss: 0.2893 - iou_score: 0.6892 - f1-score: 0.8138For batch 174, tr_loss is    0.29.\n",
      "176/200 [=========================>....] - ETA: 21s - loss: 0.2896 - iou_score: 0.6889 - f1-score: 0.8135For batch 175, tr_loss is    0.29.\n",
      "177/200 [=========================>....] - ETA: 20s - loss: 0.2893 - iou_score: 0.6892 - f1-score: 0.8138For batch 176, tr_loss is    0.29.\n",
      "178/200 [=========================>....] - ETA: 19s - loss: 0.2893 - iou_score: 0.6889 - f1-score: 0.8136For batch 177, tr_loss is    0.29.\n",
      "179/200 [=========================>....] - ETA: 18s - loss: 0.2890 - iou_score: 0.6893 - f1-score: 0.8138For batch 178, tr_loss is    0.29.\n",
      "180/200 [==========================>...] - ETA: 17s - loss: 0.2891 - iou_score: 0.6892 - f1-score: 0.8138For batch 179, tr_loss is    0.29.\n",
      "181/200 [==========================>...] - ETA: 17s - loss: 0.2893 - iou_score: 0.6889 - f1-score: 0.8135For batch 180, tr_loss is    0.29.\n",
      "182/200 [==========================>...] - ETA: 16s - loss: 0.2892 - iou_score: 0.6889 - f1-score: 0.8136For batch 181, tr_loss is    0.29.\n",
      "183/200 [==========================>...] - ETA: 15s - loss: 0.2893 - iou_score: 0.6887 - f1-score: 0.8134For batch 182, tr_loss is    0.29.\n",
      "184/200 [==========================>...] - ETA: 14s - loss: 0.2890 - iou_score: 0.6890 - f1-score: 0.8136For batch 183, tr_loss is    0.29.\n",
      "185/200 [==========================>...] - ETA: 13s - loss: 0.2889 - iou_score: 0.6891 - f1-score: 0.8137For batch 184, tr_loss is    0.29.\n",
      "186/200 [==========================>...] - ETA: 12s - loss: 0.2887 - iou_score: 0.6893 - f1-score: 0.8139For batch 185, tr_loss is    0.29.\n",
      "187/200 [===========================>..] - ETA: 11s - loss: 0.2886 - iou_score: 0.6895 - f1-score: 0.8140For batch 186, tr_loss is    0.29.\n",
      "188/200 [===========================>..] - ETA: 10s - loss: 0.2883 - iou_score: 0.6897 - f1-score: 0.8142For batch 187, tr_loss is    0.29.\n",
      "189/200 [===========================>..] - ETA: 9s - loss: 0.2886 - iou_score: 0.6895 - f1-score: 0.8140 For batch 188, tr_loss is    0.29.\n",
      "190/200 [===========================>..] - ETA: 8s - loss: 0.2886 - iou_score: 0.6896 - f1-score: 0.8141For batch 189, tr_loss is    0.29.\n",
      "191/200 [===========================>..] - ETA: 8s - loss: 0.2895 - iou_score: 0.6890 - f1-score: 0.8137For batch 190, tr_loss is    0.29.\n",
      "192/200 [===========================>..] - ETA: 7s - loss: 0.2899 - iou_score: 0.6886 - f1-score: 0.8133For batch 191, tr_loss is    0.29.\n",
      "193/200 [===========================>..] - ETA: 6s - loss: 0.2896 - iou_score: 0.6889 - f1-score: 0.8136For batch 192, tr_loss is    0.29.\n",
      "194/200 [============================>.] - ETA: 5s - loss: 0.2898 - iou_score: 0.6887 - f1-score: 0.8134For batch 193, tr_loss is    0.29.\n",
      "195/200 [============================>.] - ETA: 4s - loss: 0.2900 - iou_score: 0.6885 - f1-score: 0.8133For batch 194, tr_loss is    0.29.\n",
      "196/200 [============================>.] - ETA: 3s - loss: 0.2902 - iou_score: 0.6882 - f1-score: 0.8131For batch 195, tr_loss is    0.29.\n",
      "197/200 [============================>.] - ETA: 2s - loss: 0.2900 - iou_score: 0.6885 - f1-score: 0.8133For batch 196, tr_loss is    0.29.\n",
      "198/200 [============================>.] - ETA: 1s - loss: 0.2900 - iou_score: 0.6886 - f1-score: 0.8134For batch 197, tr_loss is    0.29.\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.2902 - iou_score: 0.6883 - f1-score: 0.8131For batch 198, tr_loss is    0.29.\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.2901 - iou_score: 0.6884 - f1-score: 0.8132For batch 199, tr_loss is    0.29.\n",
      "For batch 0, vl_loss is    0.38.\n",
      "For batch 1, vl_loss is    0.41.\n",
      "For batch 2, vl_loss is    0.40.\n",
      "For batch 3, vl_loss is    0.40.\n",
      "For batch 4, vl_loss is    0.39.\n",
      "For batch 5, vl_loss is    0.39.\n",
      "For batch 6, vl_loss is    0.41.\n",
      "For batch 7, vl_loss is    0.40.\n",
      "For batch 8, vl_loss is    0.41.\n",
      "For batch 9, vl_loss is    0.41.\n",
      "For batch 10, vl_loss is    0.41.\n",
      "For batch 11, vl_loss is    0.41.\n",
      "For batch 12, vl_loss is    0.41.\n",
      "For batch 13, vl_loss is    0.40.\n",
      "For batch 14, vl_loss is    0.41.\n",
      "For batch 15, vl_loss is    0.40.\n",
      "For batch 16, vl_loss is    0.40.\n",
      "For batch 17, vl_loss is    0.40.\n",
      "For batch 18, vl_loss is    0.40.\n",
      "For batch 19, vl_loss is    0.40.\n",
      "For batch 20, vl_loss is    0.40.\n",
      "For batch 21, vl_loss is    0.40.\n",
      "For batch 22, vl_loss is    0.40.\n",
      "For batch 23, vl_loss is    0.40.\n",
      "For batch 24, vl_loss is    0.40.\n",
      "For batch 25, vl_loss is    0.40.\n",
      "For batch 26, vl_loss is    0.40.\n",
      "For batch 27, vl_loss is    0.40.\n",
      "For batch 28, vl_loss is    0.40.\n",
      "For batch 29, vl_loss is    0.40.\n",
      "For batch 30, vl_loss is    0.40.\n",
      "For batch 31, vl_loss is    0.40.\n",
      "For batch 32, vl_loss is    0.40.\n",
      "For batch 33, vl_loss is    0.40.\n",
      "For batch 34, vl_loss is    0.40.\n",
      "For batch 35, vl_loss is    0.40.\n",
      "For batch 36, vl_loss is    0.40.\n",
      "For batch 37, vl_loss is    0.40.\n",
      "For batch 38, vl_loss is    0.39.\n",
      "For batch 39, vl_loss is    0.40.\n",
      "For batch 40, vl_loss is    0.40.\n",
      "For batch 41, vl_loss is    0.40.\n",
      "For batch 42, vl_loss is    0.39.\n",
      "For batch 43, vl_loss is    0.39.\n",
      "For batch 44, vl_loss is    0.39.\n",
      "For batch 45, vl_loss is    0.39.\n",
      "For batch 46, vl_loss is    0.40.\n",
      "For batch 47, vl_loss is    0.39.\n",
      "For batch 48, vl_loss is    0.39.\n",
      "For batch 49, vl_loss is    0.39.\n",
      "For batch 50, vl_loss is    0.39.\n",
      "For batch 51, vl_loss is    0.39.\n",
      "For batch 52, vl_loss is    0.39.\n",
      "For batch 53, vl_loss is    0.39.\n",
      "For batch 54, vl_loss is    0.39.\n",
      "For batch 55, vl_loss is    0.39.\n",
      "For batch 56, vl_loss is    0.39.\n",
      "For batch 57, vl_loss is    0.39.\n",
      "For batch 58, vl_loss is    0.39.\n",
      "For batch 59, vl_loss is    0.39.\n",
      "For batch 60, vl_loss is    0.39.\n",
      "For batch 61, vl_loss is    0.39.\n",
      "For batch 62, vl_loss is    0.39.\n",
      "For batch 63, vl_loss is    0.39.\n",
      "For batch 64, vl_loss is    0.39.\n",
      "For batch 65, vl_loss is    0.39.\n",
      "For batch 66, vl_loss is    0.39.\n",
      "For batch 67, vl_loss is    0.39.\n",
      "For batch 68, vl_loss is    0.39.\n",
      "For batch 69, vl_loss is    0.39.\n",
      "For batch 70, vl_loss is    0.39.\n",
      "For batch 71, vl_loss is    0.39.\n",
      "For batch 72, vl_loss is    0.39.\n",
      "For batch 73, vl_loss is    0.39.\n",
      "For batch 74, vl_loss is    0.39.\n",
      "For batch 75, vl_loss is    0.39.\n",
      "For batch 76, vl_loss is    0.39.\n",
      "For batch 77, vl_loss is    0.39.\n",
      "For batch 78, vl_loss is    0.39.\n",
      "For batch 79, vl_loss is    0.39.\n",
      "For batch 80, vl_loss is    0.39.\n",
      "For batch 81, vl_loss is    0.39.\n",
      "For batch 82, vl_loss is    0.39.\n",
      "For batch 83, vl_loss is    0.39.\n",
      "For batch 84, vl_loss is    0.39.\n",
      "For batch 85, vl_loss is    0.39.\n",
      "For batch 86, vl_loss is    0.39.\n",
      "For batch 87, vl_loss is    0.39.\n",
      "For batch 88, vl_loss is    0.39.\n",
      "For batch 89, vl_loss is    0.39.\n",
      "For batch 90, vl_loss is    0.39.\n",
      "For batch 91, vl_loss is    0.39.\n",
      "For batch 92, vl_loss is    0.39.\n",
      "For batch 93, vl_loss is    0.39.\n",
      "For batch 94, vl_loss is    0.39.\n",
      "For batch 95, vl_loss is    0.39.\n",
      "For batch 96, vl_loss is    0.39.\n",
      "For batch 97, vl_loss is    0.39.\n",
      "For batch 98, vl_loss is    0.39.\n",
      "For batch 99, vl_loss is    0.39.\n",
      "200/200 [==============================] - 185s 916ms/step - loss: 0.2901 - iou_score: 0.6884 - f1-score: 0.8132 - val_loss: 0.3922 - val_iou_score: 0.6215 - val_f1-score: 0.7638\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.32441\n",
      "The average loss for epoch 11 is    0.29 \n",
      "Epoch 13/200\n",
      "  1/200 [..............................] - ETA: 8:14 - loss: 0.2783 - iou_score: 0.7015 - f1-score: 0.8242For batch 0, tr_loss is    0.28.\n",
      "  2/200 [..............................] - ETA: 4:12 - loss: 0.2759 - iou_score: 0.7059 - f1-score: 0.8271For batch 1, tr_loss is    0.28.\n",
      "  3/200 [..............................] - ETA: 3:43 - loss: 0.2848 - iou_score: 0.6995 - f1-score: 0.8225For batch 2, tr_loss is    0.28.\n",
      "  4/200 [..............................] - ETA: 3:50 - loss: 0.2873 - iou_score: 0.6896 - f1-score: 0.8156For batch 3, tr_loss is    0.29.\n",
      "  5/200 [..............................] - ETA: 3:45 - loss: 0.2887 - iou_score: 0.6891 - f1-score: 0.8153For batch 4, tr_loss is    0.29.\n",
      "  6/200 [..............................] - ETA: 3:57 - loss: 0.2945 - iou_score: 0.6822 - f1-score: 0.8103For batch 5, tr_loss is    0.29.\n",
      "  7/200 [>.............................] - ETA: 4:04 - loss: 0.3007 - iou_score: 0.6708 - f1-score: 0.8015For batch 6, tr_loss is    0.30.\n",
      "  8/200 [>.............................] - ETA: 4:10 - loss: 0.3016 - iou_score: 0.6717 - f1-score: 0.8021For batch 7, tr_loss is    0.30.\n",
      "  9/200 [>.............................] - ETA: 4:02 - loss: 0.2995 - iou_score: 0.6759 - f1-score: 0.8051For batch 8, tr_loss is    0.30.\n",
      " 10/200 [>.............................] - ETA: 3:57 - loss: 0.2991 - iou_score: 0.6759 - f1-score: 0.8046For batch 9, tr_loss is    0.30.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11/200 [>.............................] - ETA: 3:51 - loss: 0.2952 - iou_score: 0.6789 - f1-score: 0.8069For batch 10, tr_loss is    0.30.\n",
      " 12/200 [>.............................] - ETA: 3:45 - loss: 0.2978 - iou_score: 0.6748 - f1-score: 0.8040For batch 11, tr_loss is    0.30.\n",
      " 13/200 [>.............................] - ETA: 3:40 - loss: 0.3003 - iou_score: 0.6704 - f1-score: 0.8008For batch 12, tr_loss is    0.30.\n",
      " 14/200 [=>............................] - ETA: 3:37 - loss: 0.2970 - iou_score: 0.6749 - f1-score: 0.8039For batch 13, tr_loss is    0.30.\n",
      " 15/200 [=>............................] - ETA: 3:32 - loss: 0.2936 - iou_score: 0.6785 - f1-score: 0.8065For batch 14, tr_loss is    0.29.\n",
      " 16/200 [=>............................] - ETA: 3:29 - loss: 0.2927 - iou_score: 0.6782 - f1-score: 0.8064For batch 15, tr_loss is    0.29.\n",
      " 17/200 [=>............................] - ETA: 3:26 - loss: 0.2900 - iou_score: 0.6816 - f1-score: 0.8088For batch 16, tr_loss is    0.29.\n",
      " 18/200 [=>............................] - ETA: 3:24 - loss: 0.2877 - iou_score: 0.6846 - f1-score: 0.8109For batch 17, tr_loss is    0.29.\n",
      " 19/200 [=>............................] - ETA: 3:22 - loss: 0.2911 - iou_score: 0.6810 - f1-score: 0.8081For batch 18, tr_loss is    0.29.\n",
      " 20/200 [==>...........................] - ETA: 3:19 - loss: 0.2881 - iou_score: 0.6851 - f1-score: 0.8109For batch 19, tr_loss is    0.29.\n",
      " 21/200 [==>...........................] - ETA: 3:14 - loss: 0.2863 - iou_score: 0.6881 - f1-score: 0.8131For batch 20, tr_loss is    0.29.\n",
      " 22/200 [==>...........................] - ETA: 3:09 - loss: 0.2846 - iou_score: 0.6899 - f1-score: 0.8144For batch 21, tr_loss is    0.28.\n",
      " 23/200 [==>...........................] - ETA: 3:06 - loss: 0.2843 - iou_score: 0.6915 - f1-score: 0.8156For batch 22, tr_loss is    0.28.\n",
      " 24/200 [==>...........................] - ETA: 3:03 - loss: 0.2838 - iou_score: 0.6929 - f1-score: 0.8166For batch 23, tr_loss is    0.28.\n",
      " 25/200 [==>...........................] - ETA: 3:02 - loss: 0.2823 - iou_score: 0.6943 - f1-score: 0.8176For batch 24, tr_loss is    0.28.\n",
      " 26/200 [==>...........................] - ETA: 3:01 - loss: 0.2855 - iou_score: 0.6929 - f1-score: 0.8166For batch 25, tr_loss is    0.29.\n",
      " 27/200 [===>..........................] - ETA: 3:00 - loss: 0.2847 - iou_score: 0.6940 - f1-score: 0.8175For batch 26, tr_loss is    0.28.\n",
      " 28/200 [===>..........................] - ETA: 2:59 - loss: 0.2852 - iou_score: 0.6938 - f1-score: 0.8174For batch 27, tr_loss is    0.29.\n",
      " 29/200 [===>..........................] - ETA: 2:55 - loss: 0.2862 - iou_score: 0.6925 - f1-score: 0.8165For batch 28, tr_loss is    0.29.\n",
      " 30/200 [===>..........................] - ETA: 2:54 - loss: 0.2846 - iou_score: 0.6947 - f1-score: 0.8180For batch 29, tr_loss is    0.28.\n",
      " 31/200 [===>..........................] - ETA: 2:53 - loss: 0.2829 - iou_score: 0.6966 - f1-score: 0.8193For batch 30, tr_loss is    0.28.\n",
      " 32/200 [===>..........................] - ETA: 2:52 - loss: 0.2817 - iou_score: 0.6980 - f1-score: 0.8203For batch 31, tr_loss is    0.28.\n",
      " 33/200 [===>..........................] - ETA: 2:48 - loss: 0.2811 - iou_score: 0.6983 - f1-score: 0.8206For batch 32, tr_loss is    0.28.\n",
      " 34/200 [====>.........................] - ETA: 2:47 - loss: 0.2821 - iou_score: 0.6974 - f1-score: 0.8199For batch 33, tr_loss is    0.28.\n",
      " 35/200 [====>.........................] - ETA: 2:44 - loss: 0.2824 - iou_score: 0.6982 - f1-score: 0.8206For batch 34, tr_loss is    0.28.\n",
      " 36/200 [====>.........................] - ETA: 2:44 - loss: 0.2820 - iou_score: 0.6987 - f1-score: 0.8209For batch 35, tr_loss is    0.28.\n",
      " 37/200 [====>.........................] - ETA: 2:41 - loss: 0.2833 - iou_score: 0.6973 - f1-score: 0.8199For batch 36, tr_loss is    0.28.\n",
      " 38/200 [====>.........................] - ETA: 2:40 - loss: 0.2836 - iou_score: 0.6965 - f1-score: 0.8194For batch 37, tr_loss is    0.28.\n",
      " 39/200 [====>.........................] - ETA: 2:39 - loss: 0.2831 - iou_score: 0.6971 - f1-score: 0.8198For batch 38, tr_loss is    0.28.\n",
      " 40/200 [=====>........................] - ETA: 2:38 - loss: 0.2820 - iou_score: 0.6985 - f1-score: 0.8207For batch 39, tr_loss is    0.28.\n",
      " 41/200 [=====>........................] - ETA: 2:37 - loss: 0.2812 - iou_score: 0.6989 - f1-score: 0.8211For batch 40, tr_loss is    0.28.\n",
      " 42/200 [=====>........................] - ETA: 2:34 - loss: 0.2818 - iou_score: 0.6983 - f1-score: 0.8207For batch 41, tr_loss is    0.28.\n",
      " 43/200 [=====>........................] - ETA: 2:32 - loss: 0.2819 - iou_score: 0.6987 - f1-score: 0.8209For batch 42, tr_loss is    0.28.\n",
      " 44/200 [=====>........................] - ETA: 2:30 - loss: 0.2806 - iou_score: 0.7005 - f1-score: 0.8221For batch 43, tr_loss is    0.28.\n",
      " 45/200 [=====>........................] - ETA: 2:28 - loss: 0.2803 - iou_score: 0.7004 - f1-score: 0.8221For batch 44, tr_loss is    0.28.\n",
      " 46/200 [=====>........................] - ETA: 2:27 - loss: 0.2813 - iou_score: 0.6996 - f1-score: 0.8215For batch 45, tr_loss is    0.28.\n",
      " 47/200 [======>.......................] - ETA: 2:26 - loss: 0.2814 - iou_score: 0.6992 - f1-score: 0.8212For batch 46, tr_loss is    0.28.\n",
      " 48/200 [======>.......................] - ETA: 2:24 - loss: 0.2818 - iou_score: 0.6989 - f1-score: 0.8209For batch 47, tr_loss is    0.28.\n",
      " 49/200 [======>.......................] - ETA: 2:24 - loss: 0.2818 - iou_score: 0.6991 - f1-score: 0.8212For batch 48, tr_loss is    0.28.\n",
      " 50/200 [======>.......................] - ETA: 2:23 - loss: 0.2799 - iou_score: 0.7013 - f1-score: 0.8226For batch 49, tr_loss is    0.28.\n",
      " 51/200 [======>.......................] - ETA: 2:22 - loss: 0.2799 - iou_score: 0.7018 - f1-score: 0.8230For batch 50, tr_loss is    0.28.\n",
      " 52/200 [======>.......................] - ETA: 2:21 - loss: 0.2805 - iou_score: 0.7016 - f1-score: 0.8228For batch 51, tr_loss is    0.28.\n",
      " 53/200 [======>.......................] - ETA: 2:19 - loss: 0.2802 - iou_score: 0.7020 - f1-score: 0.8231For batch 52, tr_loss is    0.28.\n",
      " 54/200 [=======>......................] - ETA: 2:18 - loss: 0.2806 - iou_score: 0.7014 - f1-score: 0.8227For batch 53, tr_loss is    0.28.\n",
      " 55/200 [=======>......................] - ETA: 2:16 - loss: 0.2801 - iou_score: 0.7020 - f1-score: 0.8231For batch 54, tr_loss is    0.28.\n",
      " 56/200 [=======>......................] - ETA: 2:14 - loss: 0.2799 - iou_score: 0.7022 - f1-score: 0.8233For batch 55, tr_loss is    0.28.\n",
      " 57/200 [=======>......................] - ETA: 2:14 - loss: 0.2792 - iou_score: 0.7026 - f1-score: 0.8235For batch 56, tr_loss is    0.28.\n",
      " 58/200 [=======>......................] - ETA: 2:13 - loss: 0.2788 - iou_score: 0.7028 - f1-score: 0.8237For batch 57, tr_loss is    0.28.\n",
      " 59/200 [=======>......................] - ETA: 2:12 - loss: 0.2779 - iou_score: 0.7041 - f1-score: 0.8246For batch 58, tr_loss is    0.28.\n",
      " 60/200 [========>.....................] - ETA: 2:12 - loss: 0.2772 - iou_score: 0.7044 - f1-score: 0.8249For batch 59, tr_loss is    0.28.\n",
      " 61/200 [========>.....................] - ETA: 2:10 - loss: 0.2779 - iou_score: 0.7036 - f1-score: 0.8243For batch 60, tr_loss is    0.28.\n",
      " 62/200 [========>.....................] - ETA: 2:09 - loss: 0.2778 - iou_score: 0.7035 - f1-score: 0.8243For batch 61, tr_loss is    0.28.\n",
      " 63/200 [========>.....................] - ETA: 2:08 - loss: 0.2771 - iou_score: 0.7042 - f1-score: 0.8247For batch 62, tr_loss is    0.28.\n",
      " 64/200 [========>.....................] - ETA: 2:07 - loss: 0.2782 - iou_score: 0.7028 - f1-score: 0.8237For batch 63, tr_loss is    0.28.\n",
      " 65/200 [========>.....................] - ETA: 2:07 - loss: 0.2768 - iou_score: 0.7043 - f1-score: 0.8247For batch 64, tr_loss is    0.28.\n",
      " 66/200 [========>.....................] - ETA: 2:05 - loss: 0.2786 - iou_score: 0.7024 - f1-score: 0.8233For batch 65, tr_loss is    0.28.\n",
      " 67/200 [=========>....................] - ETA: 2:04 - loss: 0.2778 - iou_score: 0.7033 - f1-score: 0.8240For batch 66, tr_loss is    0.28.\n",
      " 68/200 [=========>....................] - ETA: 2:02 - loss: 0.2774 - iou_score: 0.7039 - f1-score: 0.8244For batch 67, tr_loss is    0.28.\n",
      " 69/200 [=========>....................] - ETA: 2:01 - loss: 0.2787 - iou_score: 0.7023 - f1-score: 0.8232For batch 68, tr_loss is    0.28.\n",
      " 70/200 [=========>....................] - ETA: 1:59 - loss: 0.2784 - iou_score: 0.7026 - f1-score: 0.8234For batch 69, tr_loss is    0.28.\n",
      " 71/200 [=========>....................] - ETA: 1:59 - loss: 0.2780 - iou_score: 0.7028 - f1-score: 0.8236For batch 70, tr_loss is    0.28.\n",
      " 72/200 [=========>....................] - ETA: 1:58 - loss: 0.2781 - iou_score: 0.7027 - f1-score: 0.8235For batch 71, tr_loss is    0.28.\n",
      " 73/200 [=========>....................] - ETA: 1:57 - loss: 0.2776 - iou_score: 0.7030 - f1-score: 0.8238For batch 72, tr_loss is    0.28.\n",
      " 74/200 [==========>...................] - ETA: 1:56 - loss: 0.2773 - iou_score: 0.7032 - f1-score: 0.8239For batch 73, tr_loss is    0.28.\n",
      " 75/200 [==========>...................] - ETA: 1:55 - loss: 0.2783 - iou_score: 0.7024 - f1-score: 0.8233For batch 74, tr_loss is    0.28.\n",
      " 76/200 [==========>...................] - ETA: 1:54 - loss: 0.2787 - iou_score: 0.7019 - f1-score: 0.8230For batch 75, tr_loss is    0.28.\n",
      " 77/200 [==========>...................] - ETA: 1:54 - loss: 0.2785 - iou_score: 0.7018 - f1-score: 0.8230For batch 76, tr_loss is    0.28.\n",
      " 78/200 [==========>...................] - ETA: 1:52 - loss: 0.2780 - iou_score: 0.7021 - f1-score: 0.8232For batch 77, tr_loss is    0.28.\n",
      " 79/200 [==========>...................] - ETA: 1:51 - loss: 0.2781 - iou_score: 0.7023 - f1-score: 0.8233For batch 78, tr_loss is    0.28.\n",
      " 80/200 [===========>..................] - ETA: 1:51 - loss: 0.2774 - iou_score: 0.7030 - f1-score: 0.8238For batch 79, tr_loss is    0.28.\n",
      " 81/200 [===========>..................] - ETA: 1:50 - loss: 0.2764 - iou_score: 0.7044 - f1-score: 0.8247For batch 80, tr_loss is    0.28.\n",
      " 82/200 [===========>..................] - ETA: 1:49 - loss: 0.2760 - iou_score: 0.7047 - f1-score: 0.8250For batch 81, tr_loss is    0.28.\n",
      " 83/200 [===========>..................] - ETA: 1:48 - loss: 0.2762 - iou_score: 0.7044 - f1-score: 0.8248For batch 82, tr_loss is    0.28.\n",
      " 84/200 [===========>..................] - ETA: 1:47 - loss: 0.2761 - iou_score: 0.7045 - f1-score: 0.8248For batch 83, tr_loss is    0.28.\n",
      " 85/200 [===========>..................] - ETA: 1:46 - loss: 0.2767 - iou_score: 0.7034 - f1-score: 0.8240For batch 84, tr_loss is    0.28.\n",
      " 86/200 [===========>..................] - ETA: 1:45 - loss: 0.2770 - iou_score: 0.7030 - f1-score: 0.8238For batch 85, tr_loss is    0.28.\n",
      " 87/200 [============>.................] - ETA: 1:44 - loss: 0.2768 - iou_score: 0.7032 - f1-score: 0.8239For batch 86, tr_loss is    0.28.\n",
      " 88/200 [============>.................] - ETA: 1:44 - loss: 0.2767 - iou_score: 0.7035 - f1-score: 0.8241For batch 87, tr_loss is    0.28.\n",
      " 89/200 [============>.................] - ETA: 1:43 - loss: 0.2772 - iou_score: 0.7030 - f1-score: 0.8238For batch 88, tr_loss is    0.28.\n",
      " 90/200 [============>.................] - ETA: 1:42 - loss: 0.2774 - iou_score: 0.7027 - f1-score: 0.8236For batch 89, tr_loss is    0.28.\n",
      " 91/200 [============>.................] - ETA: 1:41 - loss: 0.2772 - iou_score: 0.7029 - f1-score: 0.8237For batch 90, tr_loss is    0.28.\n",
      " 92/200 [============>.................] - ETA: 1:39 - loss: 0.2782 - iou_score: 0.7022 - f1-score: 0.8232For batch 91, tr_loss is    0.28.\n",
      " 93/200 [============>.................] - ETA: 1:39 - loss: 0.2782 - iou_score: 0.7021 - f1-score: 0.8232For batch 92, tr_loss is    0.28.\n",
      " 94/200 [=============>................] - ETA: 1:38 - loss: 0.2798 - iou_score: 0.7003 - f1-score: 0.8218For batch 93, tr_loss is    0.28.\n",
      " 95/200 [=============>................] - ETA: 1:37 - loss: 0.2800 - iou_score: 0.6999 - f1-score: 0.8215For batch 94, tr_loss is    0.28.\n",
      " 96/200 [=============>................] - ETA: 1:36 - loss: 0.2797 - iou_score: 0.7003 - f1-score: 0.8218For batch 95, tr_loss is    0.28.\n",
      " 97/200 [=============>................] - ETA: 1:35 - loss: 0.2803 - iou_score: 0.6993 - f1-score: 0.8211For batch 96, tr_loss is    0.28.\n",
      " 98/200 [=============>................] - ETA: 1:34 - loss: 0.2805 - iou_score: 0.6990 - f1-score: 0.8209For batch 97, tr_loss is    0.28.\n",
      " 99/200 [=============>................] - ETA: 1:34 - loss: 0.2801 - iou_score: 0.6994 - f1-score: 0.8212For batch 98, tr_loss is    0.28.\n",
      "100/200 [==============>...............] - ETA: 1:33 - loss: 0.2805 - iou_score: 0.6991 - f1-score: 0.8210For batch 99, tr_loss is    0.28.\n",
      "101/200 [==============>...............] - ETA: 1:31 - loss: 0.2804 - iou_score: 0.6992 - f1-score: 0.8210For batch 100, tr_loss is    0.28.\n",
      "102/200 [==============>...............] - ETA: 1:31 - loss: 0.2807 - iou_score: 0.6988 - f1-score: 0.8208For batch 101, tr_loss is    0.28.\n",
      "103/200 [==============>...............] - ETA: 1:30 - loss: 0.2809 - iou_score: 0.6986 - f1-score: 0.8206For batch 102, tr_loss is    0.28.\n",
      "104/200 [==============>...............] - ETA: 1:29 - loss: 0.2812 - iou_score: 0.6983 - f1-score: 0.8205For batch 103, tr_loss is    0.28.\n",
      "105/200 [==============>...............] - ETA: 1:28 - loss: 0.2813 - iou_score: 0.6980 - f1-score: 0.8203For batch 104, tr_loss is    0.28.\n",
      "106/200 [==============>...............] - ETA: 1:26 - loss: 0.2820 - iou_score: 0.6974 - f1-score: 0.8199For batch 105, tr_loss is    0.28.\n",
      "107/200 [===============>..............] - ETA: 1:25 - loss: 0.2825 - iou_score: 0.6968 - f1-score: 0.8195For batch 106, tr_loss is    0.28.\n",
      "108/200 [===============>..............] - ETA: 1:24 - loss: 0.2822 - iou_score: 0.6972 - f1-score: 0.8197For batch 107, tr_loss is    0.28.\n",
      "109/200 [===============>..............] - ETA: 1:23 - loss: 0.2821 - iou_score: 0.6974 - f1-score: 0.8198For batch 108, tr_loss is    0.28.\n",
      "110/200 [===============>..............] - ETA: 1:22 - loss: 0.2819 - iou_score: 0.6976 - f1-score: 0.8200For batch 109, tr_loss is    0.28.\n",
      "111/200 [===============>..............] - ETA: 1:22 - loss: 0.2814 - iou_score: 0.6981 - f1-score: 0.8203For batch 110, tr_loss is    0.28.\n",
      "112/200 [===============>..............] - ETA: 1:20 - loss: 0.2813 - iou_score: 0.6981 - f1-score: 0.8203For batch 111, tr_loss is    0.28.\n",
      "113/200 [===============>..............] - ETA: 1:19 - loss: 0.2823 - iou_score: 0.6968 - f1-score: 0.8193For batch 112, tr_loss is    0.28.\n",
      "114/200 [================>.............] - ETA: 1:19 - loss: 0.2831 - iou_score: 0.6961 - f1-score: 0.8188For batch 113, tr_loss is    0.28.\n",
      "115/200 [================>.............] - ETA: 1:18 - loss: 0.2831 - iou_score: 0.6962 - f1-score: 0.8188For batch 114, tr_loss is    0.28.\n",
      "116/200 [================>.............] - ETA: 1:17 - loss: 0.2835 - iou_score: 0.6955 - f1-score: 0.8184For batch 115, tr_loss is    0.28.\n",
      "117/200 [================>.............] - ETA: 1:16 - loss: 0.2835 - iou_score: 0.6957 - f1-score: 0.8185For batch 116, tr_loss is    0.28.\n",
      "118/200 [================>.............] - ETA: 1:15 - loss: 0.2834 - iou_score: 0.6958 - f1-score: 0.8186For batch 117, tr_loss is    0.28.\n",
      "119/200 [================>.............] - ETA: 1:14 - loss: 0.2835 - iou_score: 0.6957 - f1-score: 0.8185For batch 118, tr_loss is    0.28.\n",
      "120/200 [=================>............] - ETA: 1:13 - loss: 0.2833 - iou_score: 0.6958 - f1-score: 0.8186For batch 119, tr_loss is    0.28.\n",
      "121/200 [=================>............] - ETA: 1:12 - loss: 0.2831 - iou_score: 0.6960 - f1-score: 0.8188For batch 120, tr_loss is    0.28.\n",
      "122/200 [=================>............] - ETA: 1:11 - loss: 0.2830 - iou_score: 0.6961 - f1-score: 0.8189For batch 121, tr_loss is    0.28.\n",
      "123/200 [=================>............] - ETA: 1:10 - loss: 0.2835 - iou_score: 0.6955 - f1-score: 0.8183For batch 122, tr_loss is    0.28.\n",
      "124/200 [=================>............] - ETA: 1:09 - loss: 0.2837 - iou_score: 0.6952 - f1-score: 0.8182For batch 123, tr_loss is    0.28.\n",
      "125/200 [=================>............] - ETA: 1:08 - loss: 0.2838 - iou_score: 0.6951 - f1-score: 0.8181For batch 124, tr_loss is    0.28.\n",
      "126/200 [=================>............] - ETA: 1:07 - loss: 0.2837 - iou_score: 0.6953 - f1-score: 0.8182For batch 125, tr_loss is    0.28.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/200 [==================>...........] - ETA: 1:07 - loss: 0.2836 - iou_score: 0.6953 - f1-score: 0.8183For batch 126, tr_loss is    0.28.\n",
      "128/200 [==================>...........] - ETA: 1:06 - loss: 0.2841 - iou_score: 0.6945 - f1-score: 0.8177For batch 127, tr_loss is    0.28.\n",
      "129/200 [==================>...........] - ETA: 1:05 - loss: 0.2840 - iou_score: 0.6945 - f1-score: 0.8177For batch 128, tr_loss is    0.28.\n",
      "130/200 [==================>...........] - ETA: 1:04 - loss: 0.2838 - iou_score: 0.6947 - f1-score: 0.8178For batch 129, tr_loss is    0.28.\n",
      "131/200 [==================>...........] - ETA: 1:03 - loss: 0.2835 - iou_score: 0.6948 - f1-score: 0.8179For batch 130, tr_loss is    0.28.\n",
      "132/200 [==================>...........] - ETA: 1:02 - loss: 0.2832 - iou_score: 0.6950 - f1-score: 0.8180For batch 131, tr_loss is    0.28.\n",
      "133/200 [==================>...........] - ETA: 1:01 - loss: 0.2831 - iou_score: 0.6950 - f1-score: 0.8181For batch 132, tr_loss is    0.28.\n",
      "134/200 [===================>..........] - ETA: 1:00 - loss: 0.2836 - iou_score: 0.6944 - f1-score: 0.8177For batch 133, tr_loss is    0.28.\n",
      "135/200 [===================>..........] - ETA: 59s - loss: 0.2839 - iou_score: 0.6941 - f1-score: 0.8174 For batch 134, tr_loss is    0.28.\n",
      "136/200 [===================>..........] - ETA: 59s - loss: 0.2837 - iou_score: 0.6940 - f1-score: 0.8173For batch 135, tr_loss is    0.28.\n",
      "137/200 [===================>..........] - ETA: 58s - loss: 0.2846 - iou_score: 0.6931 - f1-score: 0.8167For batch 136, tr_loss is    0.28.\n",
      "138/200 [===================>..........] - ETA: 57s - loss: 0.2847 - iou_score: 0.6929 - f1-score: 0.8166For batch 137, tr_loss is    0.28.\n",
      "139/200 [===================>..........] - ETA: 56s - loss: 0.2844 - iou_score: 0.6932 - f1-score: 0.8168For batch 138, tr_loss is    0.28.\n",
      "140/200 [====================>.........] - ETA: 55s - loss: 0.2857 - iou_score: 0.6921 - f1-score: 0.8159For batch 139, tr_loss is    0.29.\n",
      "141/200 [====================>.........] - ETA: 54s - loss: 0.2862 - iou_score: 0.6916 - f1-score: 0.8156For batch 140, tr_loss is    0.29.\n",
      "142/200 [====================>.........] - ETA: 53s - loss: 0.2861 - iou_score: 0.6918 - f1-score: 0.8157For batch 141, tr_loss is    0.29.\n",
      "143/200 [====================>.........] - ETA: 52s - loss: 0.2862 - iou_score: 0.6918 - f1-score: 0.8157For batch 142, tr_loss is    0.29.\n",
      "144/200 [====================>.........] - ETA: 51s - loss: 0.2864 - iou_score: 0.6915 - f1-score: 0.8155For batch 143, tr_loss is    0.29.\n",
      "145/200 [====================>.........] - ETA: 50s - loss: 0.2864 - iou_score: 0.6914 - f1-score: 0.8155For batch 144, tr_loss is    0.29.\n",
      "146/200 [====================>.........] - ETA: 49s - loss: 0.2861 - iou_score: 0.6920 - f1-score: 0.8159For batch 145, tr_loss is    0.29.\n",
      "147/200 [=====================>........] - ETA: 48s - loss: 0.2862 - iou_score: 0.6918 - f1-score: 0.8157For batch 146, tr_loss is    0.29.\n",
      "148/200 [=====================>........] - ETA: 47s - loss: 0.2857 - iou_score: 0.6925 - f1-score: 0.8162For batch 147, tr_loss is    0.29.\n",
      "149/200 [=====================>........] - ETA: 46s - loss: 0.2856 - iou_score: 0.6926 - f1-score: 0.8162For batch 148, tr_loss is    0.29.\n",
      "150/200 [=====================>........] - ETA: 45s - loss: 0.2851 - iou_score: 0.6933 - f1-score: 0.8166For batch 149, tr_loss is    0.29.\n",
      "151/200 [=====================>........] - ETA: 44s - loss: 0.2854 - iou_score: 0.6931 - f1-score: 0.8165For batch 150, tr_loss is    0.29.\n",
      "152/200 [=====================>........] - ETA: 43s - loss: 0.2853 - iou_score: 0.6933 - f1-score: 0.8167For batch 151, tr_loss is    0.29.\n",
      "153/200 [=====================>........] - ETA: 42s - loss: 0.2850 - iou_score: 0.6936 - f1-score: 0.8168For batch 152, tr_loss is    0.28.\n",
      "154/200 [======================>.......] - ETA: 41s - loss: 0.2850 - iou_score: 0.6936 - f1-score: 0.8169For batch 153, tr_loss is    0.28.\n",
      "155/200 [======================>.......] - ETA: 41s - loss: 0.2848 - iou_score: 0.6938 - f1-score: 0.8171For batch 154, tr_loss is    0.28.\n",
      "156/200 [======================>.......] - ETA: 40s - loss: 0.2847 - iou_score: 0.6939 - f1-score: 0.8171For batch 155, tr_loss is    0.28.\n",
      "157/200 [======================>.......] - ETA: 39s - loss: 0.2849 - iou_score: 0.6939 - f1-score: 0.8171For batch 156, tr_loss is    0.28.\n",
      "158/200 [======================>.......] - ETA: 38s - loss: 0.2851 - iou_score: 0.6936 - f1-score: 0.8170For batch 157, tr_loss is    0.29.\n",
      "159/200 [======================>.......] - ETA: 37s - loss: 0.2852 - iou_score: 0.6935 - f1-score: 0.8169For batch 158, tr_loss is    0.29.\n",
      "160/200 [=======================>......] - ETA: 36s - loss: 0.2852 - iou_score: 0.6936 - f1-score: 0.8170For batch 159, tr_loss is    0.29.\n",
      "161/200 [=======================>......] - ETA: 35s - loss: 0.2852 - iou_score: 0.6934 - f1-score: 0.8169For batch 160, tr_loss is    0.29.\n",
      "162/200 [=======================>......] - ETA: 34s - loss: 0.2853 - iou_score: 0.6933 - f1-score: 0.8167For batch 161, tr_loss is    0.29.\n",
      "163/200 [=======================>......] - ETA: 33s - loss: 0.2850 - iou_score: 0.6936 - f1-score: 0.8170For batch 162, tr_loss is    0.28.\n",
      "164/200 [=======================>......] - ETA: 32s - loss: 0.2852 - iou_score: 0.6936 - f1-score: 0.8169For batch 163, tr_loss is    0.29.\n",
      "165/200 [=======================>......] - ETA: 31s - loss: 0.2849 - iou_score: 0.6939 - f1-score: 0.8172For batch 164, tr_loss is    0.28.\n",
      "166/200 [=======================>......] - ETA: 30s - loss: 0.2848 - iou_score: 0.6940 - f1-score: 0.8173For batch 165, tr_loss is    0.28.\n",
      "167/200 [========================>.....] - ETA: 30s - loss: 0.2843 - iou_score: 0.6947 - f1-score: 0.8177For batch 166, tr_loss is    0.28.\n",
      "168/200 [========================>.....] - ETA: 29s - loss: 0.2845 - iou_score: 0.6944 - f1-score: 0.8175For batch 167, tr_loss is    0.28.\n",
      "169/200 [========================>.....] - ETA: 28s - loss: 0.2847 - iou_score: 0.6941 - f1-score: 0.8173For batch 168, tr_loss is    0.28.\n",
      "170/200 [========================>.....] - ETA: 27s - loss: 0.2844 - iou_score: 0.6944 - f1-score: 0.8175For batch 169, tr_loss is    0.28.\n",
      "171/200 [========================>.....] - ETA: 26s - loss: 0.2843 - iou_score: 0.6944 - f1-score: 0.8175For batch 170, tr_loss is    0.28.\n",
      "172/200 [========================>.....] - ETA: 25s - loss: 0.2840 - iou_score: 0.6948 - f1-score: 0.8178For batch 171, tr_loss is    0.28.\n",
      "173/200 [========================>.....] - ETA: 24s - loss: 0.2839 - iou_score: 0.6950 - f1-score: 0.8180For batch 172, tr_loss is    0.28.\n",
      "174/200 [=========================>....] - ETA: 23s - loss: 0.2837 - iou_score: 0.6952 - f1-score: 0.8181For batch 173, tr_loss is    0.28.\n",
      "175/200 [=========================>....] - ETA: 22s - loss: 0.2836 - iou_score: 0.6953 - f1-score: 0.8182For batch 174, tr_loss is    0.28.\n",
      "176/200 [=========================>....] - ETA: 21s - loss: 0.2836 - iou_score: 0.6952 - f1-score: 0.8181For batch 175, tr_loss is    0.28.\n",
      "177/200 [=========================>....] - ETA: 20s - loss: 0.2833 - iou_score: 0.6956 - f1-score: 0.8184For batch 176, tr_loss is    0.28.\n",
      "178/200 [=========================>....] - ETA: 19s - loss: 0.2837 - iou_score: 0.6952 - f1-score: 0.8181For batch 177, tr_loss is    0.28.\n",
      "179/200 [=========================>....] - ETA: 19s - loss: 0.2834 - iou_score: 0.6955 - f1-score: 0.8183For batch 178, tr_loss is    0.28.\n",
      "180/200 [==========================>...] - ETA: 18s - loss: 0.2837 - iou_score: 0.6952 - f1-score: 0.8181For batch 179, tr_loss is    0.28.\n",
      "181/200 [==========================>...] - ETA: 17s - loss: 0.2837 - iou_score: 0.6950 - f1-score: 0.8180For batch 180, tr_loss is    0.28.\n",
      "182/200 [==========================>...] - ETA: 16s - loss: 0.2837 - iou_score: 0.6950 - f1-score: 0.8179For batch 181, tr_loss is    0.28.\n",
      "183/200 [==========================>...] - ETA: 15s - loss: 0.2838 - iou_score: 0.6948 - f1-score: 0.8178For batch 182, tr_loss is    0.28.\n",
      "184/200 [==========================>...] - ETA: 14s - loss: 0.2836 - iou_score: 0.6950 - f1-score: 0.8180For batch 183, tr_loss is    0.28.\n",
      "185/200 [==========================>...] - ETA: 13s - loss: 0.2835 - iou_score: 0.6952 - f1-score: 0.8181For batch 184, tr_loss is    0.28.\n",
      "186/200 [==========================>...] - ETA: 12s - loss: 0.2832 - iou_score: 0.6955 - f1-score: 0.8183For batch 185, tr_loss is    0.28.\n",
      "187/200 [===========================>..] - ETA: 11s - loss: 0.2831 - iou_score: 0.6956 - f1-score: 0.8184For batch 186, tr_loss is    0.28.\n",
      "188/200 [===========================>..] - ETA: 10s - loss: 0.2829 - iou_score: 0.6958 - f1-score: 0.8185For batch 187, tr_loss is    0.28.\n",
      "189/200 [===========================>..] - ETA: 9s - loss: 0.2832 - iou_score: 0.6954 - f1-score: 0.8183 For batch 188, tr_loss is    0.28.\n",
      "190/200 [===========================>..] - ETA: 9s - loss: 0.2832 - iou_score: 0.6954 - f1-score: 0.8182For batch 189, tr_loss is    0.28.\n",
      "191/200 [===========================>..] - ETA: 8s - loss: 0.2839 - iou_score: 0.6949 - f1-score: 0.8179For batch 190, tr_loss is    0.28.\n",
      "192/200 [===========================>..] - ETA: 7s - loss: 0.2842 - iou_score: 0.6945 - f1-score: 0.8176For batch 191, tr_loss is    0.28.\n",
      "193/200 [===========================>..] - ETA: 6s - loss: 0.2839 - iou_score: 0.6949 - f1-score: 0.8179For batch 192, tr_loss is    0.28.\n",
      "194/200 [============================>.] - ETA: 5s - loss: 0.2842 - iou_score: 0.6946 - f1-score: 0.8177For batch 193, tr_loss is    0.28.\n",
      "195/200 [============================>.] - ETA: 4s - loss: 0.2844 - iou_score: 0.6944 - f1-score: 0.8175For batch 194, tr_loss is    0.28.\n",
      "196/200 [============================>.] - ETA: 3s - loss: 0.2846 - iou_score: 0.6940 - f1-score: 0.8172For batch 195, tr_loss is    0.28.\n",
      "197/200 [============================>.] - ETA: 2s - loss: 0.2844 - iou_score: 0.6945 - f1-score: 0.8176For batch 196, tr_loss is    0.28.\n",
      "198/200 [============================>.] - ETA: 1s - loss: 0.2844 - iou_score: 0.6945 - f1-score: 0.8176For batch 197, tr_loss is    0.28.\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.2848 - iou_score: 0.6941 - f1-score: 0.8173For batch 198, tr_loss is    0.28.\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.2847 - iou_score: 0.6941 - f1-score: 0.8173For batch 199, tr_loss is    0.28.\n",
      "For batch 0, vl_loss is    0.38.\n",
      "For batch 1, vl_loss is    0.40.\n",
      "For batch 2, vl_loss is    0.41.\n",
      "For batch 3, vl_loss is    0.41.\n",
      "For batch 4, vl_loss is    0.41.\n",
      "For batch 5, vl_loss is    0.40.\n",
      "For batch 6, vl_loss is    0.42.\n",
      "For batch 7, vl_loss is    0.42.\n",
      "For batch 8, vl_loss is    0.42.\n",
      "For batch 9, vl_loss is    0.42.\n",
      "For batch 10, vl_loss is    0.42.\n",
      "For batch 11, vl_loss is    0.42.\n",
      "For batch 12, vl_loss is    0.42.\n",
      "For batch 13, vl_loss is    0.41.\n",
      "For batch 14, vl_loss is    0.42.\n",
      "For batch 15, vl_loss is    0.42.\n",
      "For batch 16, vl_loss is    0.41.\n",
      "For batch 17, vl_loss is    0.41.\n",
      "For batch 18, vl_loss is    0.41.\n",
      "For batch 19, vl_loss is    0.41.\n",
      "For batch 20, vl_loss is    0.41.\n",
      "For batch 21, vl_loss is    0.40.\n",
      "For batch 22, vl_loss is    0.41.\n",
      "For batch 23, vl_loss is    0.41.\n",
      "For batch 24, vl_loss is    0.41.\n",
      "For batch 25, vl_loss is    0.41.\n",
      "For batch 26, vl_loss is    0.41.\n",
      "For batch 27, vl_loss is    0.41.\n",
      "For batch 28, vl_loss is    0.41.\n",
      "For batch 29, vl_loss is    0.41.\n",
      "For batch 30, vl_loss is    0.41.\n",
      "For batch 31, vl_loss is    0.41.\n",
      "For batch 32, vl_loss is    0.41.\n",
      "For batch 33, vl_loss is    0.41.\n",
      "For batch 34, vl_loss is    0.41.\n",
      "For batch 35, vl_loss is    0.41.\n",
      "For batch 36, vl_loss is    0.41.\n",
      "For batch 37, vl_loss is    0.40.\n",
      "For batch 38, vl_loss is    0.40.\n",
      "For batch 39, vl_loss is    0.40.\n",
      "For batch 40, vl_loss is    0.40.\n",
      "For batch 41, vl_loss is    0.40.\n",
      "For batch 42, vl_loss is    0.40.\n",
      "For batch 43, vl_loss is    0.40.\n",
      "For batch 44, vl_loss is    0.40.\n",
      "For batch 45, vl_loss is    0.40.\n",
      "For batch 46, vl_loss is    0.40.\n",
      "For batch 47, vl_loss is    0.40.\n",
      "For batch 48, vl_loss is    0.40.\n",
      "For batch 49, vl_loss is    0.40.\n",
      "For batch 50, vl_loss is    0.40.\n",
      "For batch 51, vl_loss is    0.40.\n",
      "For batch 52, vl_loss is    0.40.\n",
      "For batch 53, vl_loss is    0.40.\n",
      "For batch 54, vl_loss is    0.40.\n",
      "For batch 55, vl_loss is    0.40.\n",
      "For batch 56, vl_loss is    0.40.\n",
      "For batch 57, vl_loss is    0.40.\n",
      "For batch 58, vl_loss is    0.40.\n",
      "For batch 59, vl_loss is    0.40.\n",
      "For batch 60, vl_loss is    0.40.\n",
      "For batch 61, vl_loss is    0.40.\n",
      "For batch 62, vl_loss is    0.40.\n",
      "For batch 63, vl_loss is    0.40.\n",
      "For batch 64, vl_loss is    0.40.\n",
      "For batch 65, vl_loss is    0.40.\n",
      "For batch 66, vl_loss is    0.40.\n",
      "For batch 67, vl_loss is    0.40.\n",
      "For batch 68, vl_loss is    0.40.\n",
      "For batch 69, vl_loss is    0.40.\n",
      "For batch 70, vl_loss is    0.40.\n",
      "For batch 71, vl_loss is    0.40.\n",
      "For batch 72, vl_loss is    0.40.\n",
      "For batch 73, vl_loss is    0.40.\n",
      "For batch 74, vl_loss is    0.40.\n",
      "For batch 75, vl_loss is    0.40.\n",
      "For batch 76, vl_loss is    0.40.\n",
      "For batch 77, vl_loss is    0.40.\n",
      "For batch 78, vl_loss is    0.41.\n",
      "For batch 79, vl_loss is    0.40.\n",
      "For batch 80, vl_loss is    0.40.\n",
      "For batch 81, vl_loss is    0.40.\n",
      "For batch 82, vl_loss is    0.40.\n",
      "For batch 83, vl_loss is    0.40.\n",
      "For batch 84, vl_loss is    0.40.\n",
      "For batch 85, vl_loss is    0.40.\n",
      "For batch 86, vl_loss is    0.40.\n",
      "For batch 87, vl_loss is    0.40.\n",
      "For batch 88, vl_loss is    0.40.\n",
      "For batch 89, vl_loss is    0.40.\n",
      "For batch 90, vl_loss is    0.40.\n",
      "For batch 91, vl_loss is    0.40.\n",
      "For batch 92, vl_loss is    0.40.\n",
      "For batch 93, vl_loss is    0.40.\n",
      "For batch 94, vl_loss is    0.40.\n",
      "For batch 95, vl_loss is    0.40.\n",
      "For batch 96, vl_loss is    0.40.\n",
      "For batch 97, vl_loss is    0.40.\n",
      "For batch 98, vl_loss is    0.40.\n",
      "For batch 99, vl_loss is    0.40.\n",
      "200/200 [==============================] - 186s 923ms/step - loss: 0.2847 - iou_score: 0.6941 - f1-score: 0.8173 - val_loss: 0.4020 - val_iou_score: 0.5897 - val_f1-score: 0.7384\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.32441\n",
      "The average loss for epoch 12 is    0.28 \n",
      "Epoch 14/200\n",
      "  1/200 [..............................] - ETA: 8:04 - loss: 0.2763 - iou_score: 0.6951 - f1-score: 0.8193For batch 0, tr_loss is    0.28.\n",
      "  2/200 [..............................] - ETA: 3:52 - loss: 0.2772 - iou_score: 0.7018 - f1-score: 0.8242For batch 1, tr_loss is    0.28.\n",
      "  3/200 [..............................] - ETA: 3:37 - loss: 0.2776 - iou_score: 0.7030 - f1-score: 0.8248For batch 2, tr_loss is    0.28.\n",
      "  4/200 [..............................] - ETA: 4:10 - loss: 0.2812 - iou_score: 0.6935 - f1-score: 0.8182For batch 3, tr_loss is    0.28.\n",
      "  5/200 [..............................] - ETA: 4:14 - loss: 0.2805 - iou_score: 0.6952 - f1-score: 0.8195For batch 4, tr_loss is    0.28.\n",
      "  6/200 [..............................] - ETA: 4:23 - loss: 0.2898 - iou_score: 0.6865 - f1-score: 0.8131For batch 5, tr_loss is    0.29.\n",
      "  7/200 [>.............................] - ETA: 4:33 - loss: 0.2966 - iou_score: 0.6777 - f1-score: 0.8062For batch 6, tr_loss is    0.30.\n",
      "  8/200 [>.............................] - ETA: 4:20 - loss: 0.2959 - iou_score: 0.6786 - f1-score: 0.8069For batch 7, tr_loss is    0.30.\n",
      "  9/200 [>.............................] - ETA: 4:10 - loss: 0.2920 - iou_score: 0.6846 - f1-score: 0.8110For batch 8, tr_loss is    0.29.\n",
      " 10/200 [>.............................] - ETA: 4:02 - loss: 0.2924 - iou_score: 0.6835 - f1-score: 0.8097For batch 9, tr_loss is    0.29.\n",
      " 11/200 [>.............................] - ETA: 3:48 - loss: 0.2882 - iou_score: 0.6865 - f1-score: 0.8119For batch 10, tr_loss is    0.29.\n",
      " 12/200 [>.............................] - ETA: 3:45 - loss: 0.2920 - iou_score: 0.6828 - f1-score: 0.8094For batch 11, tr_loss is    0.29.\n",
      " 13/200 [>.............................] - ETA: 3:39 - loss: 0.2936 - iou_score: 0.6800 - f1-score: 0.8074For batch 12, tr_loss is    0.29.\n",
      " 14/200 [=>............................] - ETA: 3:28 - loss: 0.2933 - iou_score: 0.6804 - f1-score: 0.8077For batch 13, tr_loss is    0.29.\n",
      " 15/200 [=>............................] - ETA: 3:27 - loss: 0.2906 - iou_score: 0.6827 - f1-score: 0.8094For batch 14, tr_loss is    0.29.\n",
      " 16/200 [=>............................] - ETA: 3:18 - loss: 0.2895 - iou_score: 0.6838 - f1-score: 0.8103For batch 15, tr_loss is    0.29.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 17/200 [=>............................] - ETA: 3:13 - loss: 0.2870 - iou_score: 0.6875 - f1-score: 0.8129For batch 16, tr_loss is    0.29.\n",
      " 18/200 [=>............................] - ETA: 3:14 - loss: 0.2847 - iou_score: 0.6900 - f1-score: 0.8148For batch 17, tr_loss is    0.28.\n",
      " 19/200 [=>............................] - ETA: 3:12 - loss: 0.2862 - iou_score: 0.6880 - f1-score: 0.8132For batch 18, tr_loss is    0.29.\n",
      " 20/200 [==>...........................] - ETA: 3:07 - loss: 0.2833 - iou_score: 0.6924 - f1-score: 0.8162For batch 19, tr_loss is    0.28.\n",
      " 21/200 [==>...........................] - ETA: 3:06 - loss: 0.2809 - iou_score: 0.6956 - f1-score: 0.8185For batch 20, tr_loss is    0.28.\n",
      " 22/200 [==>...........................] - ETA: 3:03 - loss: 0.2793 - iou_score: 0.6974 - f1-score: 0.8198For batch 21, tr_loss is    0.28.\n",
      " 23/200 [==>...........................] - ETA: 3:02 - loss: 0.2777 - iou_score: 0.6995 - f1-score: 0.8212For batch 22, tr_loss is    0.28.\n",
      " 24/200 [==>...........................] - ETA: 2:58 - loss: 0.2766 - iou_score: 0.7001 - f1-score: 0.8217For batch 23, tr_loss is    0.28.\n",
      " 25/200 [==>...........................] - ETA: 2:57 - loss: 0.2747 - iou_score: 0.7025 - f1-score: 0.8234For batch 24, tr_loss is    0.27.\n",
      " 26/200 [==>...........................] - ETA: 2:56 - loss: 0.2784 - iou_score: 0.7001 - f1-score: 0.8217For batch 25, tr_loss is    0.28.\n",
      " 27/200 [===>..........................] - ETA: 2:54 - loss: 0.2769 - iou_score: 0.7018 - f1-score: 0.8229For batch 26, tr_loss is    0.28.\n",
      " 28/200 [===>..........................] - ETA: 2:53 - loss: 0.2768 - iou_score: 0.7016 - f1-score: 0.8228For batch 27, tr_loss is    0.28.\n",
      " 29/200 [===>..........................] - ETA: 2:49 - loss: 0.2772 - iou_score: 0.7006 - f1-score: 0.8221For batch 28, tr_loss is    0.28.\n",
      " 30/200 [===>..........................] - ETA: 2:46 - loss: 0.2756 - iou_score: 0.7032 - f1-score: 0.8239For batch 29, tr_loss is    0.28.\n",
      " 31/200 [===>..........................] - ETA: 2:44 - loss: 0.2740 - iou_score: 0.7051 - f1-score: 0.8252For batch 30, tr_loss is    0.27.\n",
      " 32/200 [===>..........................] - ETA: 2:43 - loss: 0.2736 - iou_score: 0.7060 - f1-score: 0.8259For batch 31, tr_loss is    0.27.\n",
      " 33/200 [===>..........................] - ETA: 2:43 - loss: 0.2724 - iou_score: 0.7070 - f1-score: 0.8266For batch 32, tr_loss is    0.27.\n",
      " 34/200 [====>.........................] - ETA: 2:42 - loss: 0.2734 - iou_score: 0.7059 - f1-score: 0.8258For batch 33, tr_loss is    0.27.\n",
      " 35/200 [====>.........................] - ETA: 2:41 - loss: 0.2730 - iou_score: 0.7072 - f1-score: 0.8268For batch 34, tr_loss is    0.27.\n",
      " 36/200 [====>.........................] - ETA: 2:40 - loss: 0.2728 - iou_score: 0.7071 - f1-score: 0.8267For batch 35, tr_loss is    0.27.\n",
      " 37/200 [====>.........................] - ETA: 2:38 - loss: 0.2749 - iou_score: 0.7055 - f1-score: 0.8255For batch 36, tr_loss is    0.27.\n",
      " 38/200 [====>.........................] - ETA: 2:35 - loss: 0.2759 - iou_score: 0.7039 - f1-score: 0.8244For batch 37, tr_loss is    0.28.\n",
      " 39/200 [====>.........................] - ETA: 2:33 - loss: 0.2748 - iou_score: 0.7046 - f1-score: 0.8249For batch 38, tr_loss is    0.27.\n",
      " 40/200 [=====>........................] - ETA: 2:33 - loss: 0.2735 - iou_score: 0.7060 - f1-score: 0.8259For batch 39, tr_loss is    0.27.\n",
      " 41/200 [=====>........................] - ETA: 2:31 - loss: 0.2730 - iou_score: 0.7062 - f1-score: 0.8260For batch 40, tr_loss is    0.27.\n",
      " 42/200 [=====>........................] - ETA: 2:31 - loss: 0.2733 - iou_score: 0.7058 - f1-score: 0.8258For batch 41, tr_loss is    0.27.\n",
      " 43/200 [=====>........................] - ETA: 2:28 - loss: 0.2731 - iou_score: 0.7062 - f1-score: 0.8260For batch 42, tr_loss is    0.27.\n",
      " 44/200 [=====>........................] - ETA: 2:27 - loss: 0.2723 - iou_score: 0.7074 - f1-score: 0.8268For batch 43, tr_loss is    0.27.\n",
      " 45/200 [=====>........................] - ETA: 2:26 - loss: 0.2726 - iou_score: 0.7072 - f1-score: 0.8267For batch 44, tr_loss is    0.27.\n",
      " 46/200 [=====>........................] - ETA: 2:25 - loss: 0.2743 - iou_score: 0.7058 - f1-score: 0.8257For batch 45, tr_loss is    0.27.\n",
      " 47/200 [======>.......................] - ETA: 2:25 - loss: 0.2750 - iou_score: 0.7051 - f1-score: 0.8252For batch 46, tr_loss is    0.28.\n",
      " 48/200 [======>.......................] - ETA: 2:22 - loss: 0.2754 - iou_score: 0.7049 - f1-score: 0.8250For batch 47, tr_loss is    0.28.\n",
      " 49/200 [======>.......................] - ETA: 2:22 - loss: 0.2750 - iou_score: 0.7053 - f1-score: 0.8253For batch 48, tr_loss is    0.27.\n",
      " 50/200 [======>.......................] - ETA: 2:21 - loss: 0.2732 - iou_score: 0.7072 - f1-score: 0.8266For batch 49, tr_loss is    0.27.\n",
      " 51/200 [======>.......................] - ETA: 2:20 - loss: 0.2727 - iou_score: 0.7082 - f1-score: 0.8273For batch 50, tr_loss is    0.27.\n",
      " 52/200 [======>.......................] - ETA: 2:18 - loss: 0.2729 - iou_score: 0.7079 - f1-score: 0.8270For batch 51, tr_loss is    0.27.\n",
      " 53/200 [======>.......................] - ETA: 2:17 - loss: 0.2728 - iou_score: 0.7075 - f1-score: 0.8268For batch 52, tr_loss is    0.27.\n",
      " 54/200 [=======>......................] - ETA: 2:15 - loss: 0.2732 - iou_score: 0.7069 - f1-score: 0.8264For batch 53, tr_loss is    0.27.\n",
      " 55/200 [=======>......................] - ETA: 2:15 - loss: 0.2725 - iou_score: 0.7078 - f1-score: 0.8271For batch 54, tr_loss is    0.27.\n",
      " 56/200 [=======>......................] - ETA: 2:12 - loss: 0.2723 - iou_score: 0.7080 - f1-score: 0.8272For batch 55, tr_loss is    0.27.\n",
      " 57/200 [=======>......................] - ETA: 2:12 - loss: 0.2723 - iou_score: 0.7075 - f1-score: 0.8268For batch 56, tr_loss is    0.27.\n",
      " 58/200 [=======>......................] - ETA: 2:11 - loss: 0.2716 - iou_score: 0.7081 - f1-score: 0.8273For batch 57, tr_loss is    0.27.\n",
      " 59/200 [=======>......................] - ETA: 2:10 - loss: 0.2707 - iou_score: 0.7092 - f1-score: 0.8281For batch 58, tr_loss is    0.27.\n",
      " 60/200 [========>.....................] - ETA: 2:08 - loss: 0.2700 - iou_score: 0.7096 - f1-score: 0.8283For batch 59, tr_loss is    0.27.\n",
      " 61/200 [========>.....................] - ETA: 2:07 - loss: 0.2716 - iou_score: 0.7091 - f1-score: 0.8281For batch 60, tr_loss is    0.27.\n",
      " 62/200 [========>.....................] - ETA: 2:07 - loss: 0.2717 - iou_score: 0.7091 - f1-score: 0.8280For batch 61, tr_loss is    0.27.\n",
      " 63/200 [========>.....................] - ETA: 2:06 - loss: 0.2712 - iou_score: 0.7095 - f1-score: 0.8284For batch 62, tr_loss is    0.27.\n",
      " 64/200 [========>.....................] - ETA: 2:04 - loss: 0.2724 - iou_score: 0.7086 - f1-score: 0.8277For batch 63, tr_loss is    0.27.\n",
      " 65/200 [========>.....................] - ETA: 2:04 - loss: 0.2713 - iou_score: 0.7099 - f1-score: 0.8286For batch 64, tr_loss is    0.27.\n",
      " 66/200 [========>.....................] - ETA: 2:03 - loss: 0.2728 - iou_score: 0.7084 - f1-score: 0.8275For batch 65, tr_loss is    0.27.\n",
      " 67/200 [=========>....................] - ETA: 2:02 - loss: 0.2723 - iou_score: 0.7090 - f1-score: 0.8279For batch 66, tr_loss is    0.27.\n",
      " 68/200 [=========>....................] - ETA: 2:01 - loss: 0.2720 - iou_score: 0.7092 - f1-score: 0.8281For batch 67, tr_loss is    0.27.\n",
      " 69/200 [=========>....................] - ETA: 2:01 - loss: 0.2729 - iou_score: 0.7078 - f1-score: 0.8270For batch 68, tr_loss is    0.27.\n",
      " 70/200 [=========>....................] - ETA: 2:00 - loss: 0.2725 - iou_score: 0.7081 - f1-score: 0.8273For batch 69, tr_loss is    0.27.\n",
      " 71/200 [=========>....................] - ETA: 1:59 - loss: 0.2725 - iou_score: 0.7083 - f1-score: 0.8274For batch 70, tr_loss is    0.27.\n",
      " 72/200 [=========>....................] - ETA: 1:58 - loss: 0.2723 - iou_score: 0.7080 - f1-score: 0.8273For batch 71, tr_loss is    0.27.\n",
      " 73/200 [=========>....................] - ETA: 1:56 - loss: 0.2721 - iou_score: 0.7082 - f1-score: 0.8274For batch 72, tr_loss is    0.27.\n",
      " 74/200 [==========>...................] - ETA: 1:55 - loss: 0.2720 - iou_score: 0.7081 - f1-score: 0.8273For batch 73, tr_loss is    0.27.\n",
      " 75/200 [==========>...................] - ETA: 1:54 - loss: 0.2728 - iou_score: 0.7074 - f1-score: 0.8268For batch 74, tr_loss is    0.27.\n",
      " 76/200 [==========>...................] - ETA: 1:53 - loss: 0.2730 - iou_score: 0.7069 - f1-score: 0.8265For batch 75, tr_loss is    0.27.\n",
      " 77/200 [==========>...................] - ETA: 1:52 - loss: 0.2728 - iou_score: 0.7070 - f1-score: 0.8266For batch 76, tr_loss is    0.27.\n",
      " 78/200 [==========>...................] - ETA: 1:52 - loss: 0.2721 - iou_score: 0.7076 - f1-score: 0.8270For batch 77, tr_loss is    0.27.\n",
      " 79/200 [==========>...................] - ETA: 1:50 - loss: 0.2720 - iou_score: 0.7079 - f1-score: 0.8272For batch 78, tr_loss is    0.27.\n",
      " 80/200 [===========>..................] - ETA: 1:49 - loss: 0.2715 - iou_score: 0.7083 - f1-score: 0.8275For batch 79, tr_loss is    0.27.\n",
      " 81/200 [===========>..................] - ETA: 1:49 - loss: 0.2706 - iou_score: 0.7097 - f1-score: 0.8285For batch 80, tr_loss is    0.27.\n",
      " 82/200 [===========>..................] - ETA: 1:47 - loss: 0.2704 - iou_score: 0.7101 - f1-score: 0.8287For batch 81, tr_loss is    0.27.\n",
      " 83/200 [===========>..................] - ETA: 1:46 - loss: 0.2707 - iou_score: 0.7098 - f1-score: 0.8285For batch 82, tr_loss is    0.27.\n",
      " 84/200 [===========>..................] - ETA: 1:45 - loss: 0.2704 - iou_score: 0.7100 - f1-score: 0.8287For batch 83, tr_loss is    0.27.\n",
      " 85/200 [===========>..................] - ETA: 1:44 - loss: 0.2709 - iou_score: 0.7090 - f1-score: 0.8280For batch 84, tr_loss is    0.27.\n",
      " 86/200 [===========>..................] - ETA: 1:43 - loss: 0.2713 - iou_score: 0.7085 - f1-score: 0.8276For batch 85, tr_loss is    0.27.\n",
      " 87/200 [============>.................] - ETA: 1:42 - loss: 0.2708 - iou_score: 0.7091 - f1-score: 0.8280For batch 86, tr_loss is    0.27.\n",
      " 88/200 [============>.................] - ETA: 1:41 - loss: 0.2707 - iou_score: 0.7094 - f1-score: 0.8282For batch 87, tr_loss is    0.27.\n",
      " 89/200 [============>.................] - ETA: 1:40 - loss: 0.2711 - iou_score: 0.7089 - f1-score: 0.8279For batch 88, tr_loss is    0.27.\n",
      " 90/200 [============>.................] - ETA: 1:39 - loss: 0.2713 - iou_score: 0.7086 - f1-score: 0.8277For batch 89, tr_loss is    0.27.\n",
      " 91/200 [============>.................] - ETA: 1:38 - loss: 0.2712 - iou_score: 0.7087 - f1-score: 0.8278For batch 90, tr_loss is    0.27.\n",
      " 92/200 [============>.................] - ETA: 1:37 - loss: 0.2717 - iou_score: 0.7082 - f1-score: 0.8274For batch 91, tr_loss is    0.27.\n",
      " 93/200 [============>.................] - ETA: 1:36 - loss: 0.2717 - iou_score: 0.7080 - f1-score: 0.8273For batch 92, tr_loss is    0.27.\n",
      " 94/200 [=============>................] - ETA: 1:35 - loss: 0.2728 - iou_score: 0.7065 - f1-score: 0.8262For batch 93, tr_loss is    0.27.\n",
      " 95/200 [=============>................] - ETA: 1:34 - loss: 0.2732 - iou_score: 0.7062 - f1-score: 0.8260For batch 94, tr_loss is    0.27.\n",
      " 96/200 [=============>................] - ETA: 1:33 - loss: 0.2727 - iou_score: 0.7067 - f1-score: 0.8263For batch 95, tr_loss is    0.27.\n",
      " 97/200 [=============>................] - ETA: 1:32 - loss: 0.2732 - iou_score: 0.7061 - f1-score: 0.8259For batch 96, tr_loss is    0.27.\n",
      " 98/200 [=============>................] - ETA: 1:30 - loss: 0.2740 - iou_score: 0.7054 - f1-score: 0.8254For batch 97, tr_loss is    0.27.\n",
      " 99/200 [=============>................] - ETA: 1:30 - loss: 0.2737 - iou_score: 0.7060 - f1-score: 0.8259For batch 98, tr_loss is    0.27.\n",
      "100/200 [==============>...............] - ETA: 1:29 - loss: 0.2741 - iou_score: 0.7056 - f1-score: 0.8257For batch 99, tr_loss is    0.27.\n",
      "101/200 [==============>...............] - ETA: 1:28 - loss: 0.2742 - iou_score: 0.7059 - f1-score: 0.8258For batch 100, tr_loss is    0.27.\n",
      "102/200 [==============>...............] - ETA: 1:27 - loss: 0.2745 - iou_score: 0.7055 - f1-score: 0.8255For batch 101, tr_loss is    0.27.\n",
      "103/200 [==============>...............] - ETA: 1:26 - loss: 0.2748 - iou_score: 0.7050 - f1-score: 0.8252For batch 102, tr_loss is    0.27.\n",
      "104/200 [==============>...............] - ETA: 1:25 - loss: 0.2749 - iou_score: 0.7046 - f1-score: 0.8249For batch 103, tr_loss is    0.27.\n",
      "105/200 [==============>...............] - ETA: 1:24 - loss: 0.2751 - iou_score: 0.7043 - f1-score: 0.8247For batch 104, tr_loss is    0.28.\n",
      "106/200 [==============>...............] - ETA: 1:23 - loss: 0.2755 - iou_score: 0.7040 - f1-score: 0.8245For batch 105, tr_loss is    0.28.\n",
      "107/200 [===============>..............] - ETA: 1:23 - loss: 0.2760 - iou_score: 0.7035 - f1-score: 0.8242For batch 106, tr_loss is    0.28.\n",
      "108/200 [===============>..............] - ETA: 1:22 - loss: 0.2760 - iou_score: 0.7038 - f1-score: 0.8244For batch 107, tr_loss is    0.28.\n",
      "109/200 [===============>..............] - ETA: 1:21 - loss: 0.2760 - iou_score: 0.7037 - f1-score: 0.8243For batch 108, tr_loss is    0.28.\n",
      "110/200 [===============>..............] - ETA: 1:20 - loss: 0.2758 - iou_score: 0.7041 - f1-score: 0.8246For batch 109, tr_loss is    0.28.\n",
      "111/200 [===============>..............] - ETA: 1:19 - loss: 0.2753 - iou_score: 0.7048 - f1-score: 0.8250For batch 110, tr_loss is    0.28.\n",
      "112/200 [===============>..............] - ETA: 1:18 - loss: 0.2752 - iou_score: 0.7048 - f1-score: 0.8250For batch 111, tr_loss is    0.28.\n",
      "113/200 [===============>..............] - ETA: 1:17 - loss: 0.2756 - iou_score: 0.7040 - f1-score: 0.8244For batch 112, tr_loss is    0.28.\n",
      "114/200 [================>.............] - ETA: 1:17 - loss: 0.2762 - iou_score: 0.7032 - f1-score: 0.8239For batch 113, tr_loss is    0.28.\n",
      "115/200 [================>.............] - ETA: 1:16 - loss: 0.2764 - iou_score: 0.7031 - f1-score: 0.8238For batch 114, tr_loss is    0.28.\n",
      "116/200 [================>.............] - ETA: 1:15 - loss: 0.2769 - iou_score: 0.7023 - f1-score: 0.8232For batch 115, tr_loss is    0.28.\n",
      "117/200 [================>.............] - ETA: 1:14 - loss: 0.2770 - iou_score: 0.7022 - f1-score: 0.8231For batch 116, tr_loss is    0.28.\n",
      "118/200 [================>.............] - ETA: 1:13 - loss: 0.2769 - iou_score: 0.7021 - f1-score: 0.8231For batch 117, tr_loss is    0.28.\n",
      "119/200 [================>.............] - ETA: 1:13 - loss: 0.2770 - iou_score: 0.7019 - f1-score: 0.8230For batch 118, tr_loss is    0.28.\n",
      "120/200 [=================>............] - ETA: 1:12 - loss: 0.2766 - iou_score: 0.7023 - f1-score: 0.8232For batch 119, tr_loss is    0.28.\n",
      "121/200 [=================>............] - ETA: 1:11 - loss: 0.2762 - iou_score: 0.7028 - f1-score: 0.8236For batch 120, tr_loss is    0.28.\n",
      "122/200 [=================>............] - ETA: 1:10 - loss: 0.2760 - iou_score: 0.7030 - f1-score: 0.8237For batch 121, tr_loss is    0.28.\n",
      "123/200 [=================>............] - ETA: 1:09 - loss: 0.2766 - iou_score: 0.7023 - f1-score: 0.8232For batch 122, tr_loss is    0.28.\n",
      "124/200 [=================>............] - ETA: 1:08 - loss: 0.2767 - iou_score: 0.7022 - f1-score: 0.8231For batch 123, tr_loss is    0.28.\n",
      "125/200 [=================>............] - ETA: 1:07 - loss: 0.2770 - iou_score: 0.7020 - f1-score: 0.8230For batch 124, tr_loss is    0.28.\n",
      "126/200 [=================>............] - ETA: 1:06 - loss: 0.2769 - iou_score: 0.7021 - f1-score: 0.8231For batch 125, tr_loss is    0.28.\n",
      "127/200 [==================>...........] - ETA: 1:06 - loss: 0.2769 - iou_score: 0.7019 - f1-score: 0.8230For batch 126, tr_loss is    0.28.\n",
      "128/200 [==================>...........] - ETA: 1:05 - loss: 0.2774 - iou_score: 0.7011 - f1-score: 0.8224For batch 127, tr_loss is    0.28.\n",
      "129/200 [==================>...........] - ETA: 1:04 - loss: 0.2774 - iou_score: 0.7010 - f1-score: 0.8223For batch 128, tr_loss is    0.28.\n",
      "130/200 [==================>...........] - ETA: 1:03 - loss: 0.2772 - iou_score: 0.7012 - f1-score: 0.8225For batch 129, tr_loss is    0.28.\n",
      "131/200 [==================>...........] - ETA: 1:02 - loss: 0.2767 - iou_score: 0.7016 - f1-score: 0.8228For batch 130, tr_loss is    0.28.\n",
      "132/200 [==================>...........] - ETA: 1:01 - loss: 0.2764 - iou_score: 0.7020 - f1-score: 0.8230For batch 131, tr_loss is    0.28.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/200 [==================>...........] - ETA: 1:00 - loss: 0.2766 - iou_score: 0.7018 - f1-score: 0.8229For batch 132, tr_loss is    0.28.\n",
      "134/200 [===================>..........] - ETA: 59s - loss: 0.2770 - iou_score: 0.7013 - f1-score: 0.8225 For batch 133, tr_loss is    0.28.\n",
      "135/200 [===================>..........] - ETA: 58s - loss: 0.2771 - iou_score: 0.7010 - f1-score: 0.8223For batch 134, tr_loss is    0.28.\n",
      "136/200 [===================>..........] - ETA: 57s - loss: 0.2770 - iou_score: 0.7008 - f1-score: 0.8222For batch 135, tr_loss is    0.28.\n",
      "137/200 [===================>..........] - ETA: 56s - loss: 0.2778 - iou_score: 0.6999 - f1-score: 0.8216For batch 136, tr_loss is    0.28.\n",
      "138/200 [===================>..........] - ETA: 55s - loss: 0.2778 - iou_score: 0.6998 - f1-score: 0.8215For batch 137, tr_loss is    0.28.\n",
      "139/200 [===================>..........] - ETA: 54s - loss: 0.2776 - iou_score: 0.6999 - f1-score: 0.8216For batch 138, tr_loss is    0.28.\n",
      "140/200 [====================>.........] - ETA: 54s - loss: 0.2788 - iou_score: 0.6989 - f1-score: 0.8208For batch 139, tr_loss is    0.28.\n",
      "141/200 [====================>.........] - ETA: 53s - loss: 0.2794 - iou_score: 0.6983 - f1-score: 0.8203For batch 140, tr_loss is    0.28.\n",
      "142/200 [====================>.........] - ETA: 52s - loss: 0.2795 - iou_score: 0.6981 - f1-score: 0.8202For batch 141, tr_loss is    0.28.\n",
      "143/200 [====================>.........] - ETA: 51s - loss: 0.2793 - iou_score: 0.6982 - f1-score: 0.8203For batch 142, tr_loss is    0.28.\n",
      "144/200 [====================>.........] - ETA: 50s - loss: 0.2794 - iou_score: 0.6980 - f1-score: 0.8201For batch 143, tr_loss is    0.28.\n",
      "145/200 [====================>.........] - ETA: 49s - loss: 0.2795 - iou_score: 0.6978 - f1-score: 0.8200For batch 144, tr_loss is    0.28.\n",
      "146/200 [====================>.........] - ETA: 48s - loss: 0.2791 - iou_score: 0.6983 - f1-score: 0.8204For batch 145, tr_loss is    0.28.\n",
      "147/200 [=====================>........] - ETA: 47s - loss: 0.2793 - iou_score: 0.6982 - f1-score: 0.8202For batch 146, tr_loss is    0.28.\n",
      "148/200 [=====================>........] - ETA: 46s - loss: 0.2789 - iou_score: 0.6988 - f1-score: 0.8206For batch 147, tr_loss is    0.28.\n",
      "149/200 [=====================>........] - ETA: 45s - loss: 0.2787 - iou_score: 0.6990 - f1-score: 0.8208For batch 148, tr_loss is    0.28.\n",
      "150/200 [=====================>........] - ETA: 44s - loss: 0.2782 - iou_score: 0.6997 - f1-score: 0.8212For batch 149, tr_loss is    0.28.\n",
      "151/200 [=====================>........] - ETA: 43s - loss: 0.2783 - iou_score: 0.6995 - f1-score: 0.8211For batch 150, tr_loss is    0.28.\n",
      "152/200 [=====================>........] - ETA: 43s - loss: 0.2782 - iou_score: 0.6997 - f1-score: 0.8212For batch 151, tr_loss is    0.28.\n",
      "153/200 [=====================>........] - ETA: 42s - loss: 0.2779 - iou_score: 0.7001 - f1-score: 0.8215For batch 152, tr_loss is    0.28.\n",
      "154/200 [======================>.......] - ETA: 41s - loss: 0.2778 - iou_score: 0.7003 - f1-score: 0.8216For batch 153, tr_loss is    0.28.\n",
      "155/200 [======================>.......] - ETA: 40s - loss: 0.2777 - iou_score: 0.7004 - f1-score: 0.8217For batch 154, tr_loss is    0.28.\n",
      "156/200 [======================>.......] - ETA: 39s - loss: 0.2774 - iou_score: 0.7007 - f1-score: 0.8219For batch 155, tr_loss is    0.28.\n",
      "157/200 [======================>.......] - ETA: 38s - loss: 0.2777 - iou_score: 0.7005 - f1-score: 0.8218For batch 156, tr_loss is    0.28.\n",
      "158/200 [======================>.......] - ETA: 37s - loss: 0.2777 - iou_score: 0.7002 - f1-score: 0.8217For batch 157, tr_loss is    0.28.\n",
      "159/200 [======================>.......] - ETA: 36s - loss: 0.2779 - iou_score: 0.7000 - f1-score: 0.8215For batch 158, tr_loss is    0.28.\n",
      "160/200 [=======================>......] - ETA: 36s - loss: 0.2778 - iou_score: 0.7001 - f1-score: 0.8215For batch 159, tr_loss is    0.28.\n",
      "161/200 [=======================>......] - ETA: 35s - loss: 0.2779 - iou_score: 0.6999 - f1-score: 0.8214For batch 160, tr_loss is    0.28.\n",
      "162/200 [=======================>......] - ETA: 34s - loss: 0.2778 - iou_score: 0.6998 - f1-score: 0.8214For batch 161, tr_loss is    0.28.\n",
      "163/200 [=======================>......] - ETA: 33s - loss: 0.2773 - iou_score: 0.7004 - f1-score: 0.8218For batch 162, tr_loss is    0.28.\n",
      "164/200 [=======================>......] - ETA: 32s - loss: 0.2771 - iou_score: 0.7007 - f1-score: 0.8220For batch 163, tr_loss is    0.28.\n",
      "165/200 [=======================>......] - ETA: 31s - loss: 0.2768 - iou_score: 0.7010 - f1-score: 0.8222For batch 164, tr_loss is    0.28.\n",
      "166/200 [=======================>......] - ETA: 30s - loss: 0.2765 - iou_score: 0.7012 - f1-score: 0.8224For batch 165, tr_loss is    0.28.\n",
      "167/200 [========================>.....] - ETA: 29s - loss: 0.2760 - iou_score: 0.7019 - f1-score: 0.8228For batch 166, tr_loss is    0.28.\n",
      "168/200 [========================>.....] - ETA: 28s - loss: 0.2761 - iou_score: 0.7017 - f1-score: 0.8227For batch 167, tr_loss is    0.28.\n",
      "169/200 [========================>.....] - ETA: 27s - loss: 0.2762 - iou_score: 0.7015 - f1-score: 0.8225For batch 168, tr_loss is    0.28.\n",
      "170/200 [========================>.....] - ETA: 26s - loss: 0.2757 - iou_score: 0.7021 - f1-score: 0.8230For batch 169, tr_loss is    0.28.\n",
      "171/200 [========================>.....] - ETA: 25s - loss: 0.2758 - iou_score: 0.7020 - f1-score: 0.8229For batch 170, tr_loss is    0.28.\n",
      "172/200 [========================>.....] - ETA: 24s - loss: 0.2754 - iou_score: 0.7025 - f1-score: 0.8232For batch 171, tr_loss is    0.28.\n",
      "173/200 [========================>.....] - ETA: 24s - loss: 0.2753 - iou_score: 0.7027 - f1-score: 0.8233For batch 172, tr_loss is    0.28.\n",
      "174/200 [=========================>....] - ETA: 23s - loss: 0.2750 - iou_score: 0.7030 - f1-score: 0.8236For batch 173, tr_loss is    0.28.\n",
      "175/200 [=========================>....] - ETA: 22s - loss: 0.2747 - iou_score: 0.7032 - f1-score: 0.8237For batch 174, tr_loss is    0.27.\n",
      "176/200 [=========================>....] - ETA: 21s - loss: 0.2748 - iou_score: 0.7031 - f1-score: 0.8236For batch 175, tr_loss is    0.27.\n",
      "177/200 [=========================>....] - ETA: 20s - loss: 0.2746 - iou_score: 0.7033 - f1-score: 0.8238For batch 176, tr_loss is    0.27.\n",
      "178/200 [=========================>....] - ETA: 19s - loss: 0.2747 - iou_score: 0.7030 - f1-score: 0.8236For batch 177, tr_loss is    0.27.\n",
      "179/200 [=========================>....] - ETA: 18s - loss: 0.2744 - iou_score: 0.7032 - f1-score: 0.8237For batch 178, tr_loss is    0.27.\n",
      "180/200 [==========================>...] - ETA: 17s - loss: 0.2745 - iou_score: 0.7031 - f1-score: 0.8237For batch 179, tr_loss is    0.27.\n",
      "181/200 [==========================>...] - ETA: 17s - loss: 0.2748 - iou_score: 0.7028 - f1-score: 0.8234For batch 180, tr_loss is    0.27.\n",
      "182/200 [==========================>...] - ETA: 16s - loss: 0.2746 - iou_score: 0.7029 - f1-score: 0.8235For batch 181, tr_loss is    0.27.\n",
      "183/200 [==========================>...] - ETA: 15s - loss: 0.2746 - iou_score: 0.7029 - f1-score: 0.8235For batch 182, tr_loss is    0.27.\n",
      "184/200 [==========================>...] - ETA: 14s - loss: 0.2743 - iou_score: 0.7032 - f1-score: 0.8238For batch 183, tr_loss is    0.27.\n",
      "185/200 [==========================>...] - ETA: 13s - loss: 0.2742 - iou_score: 0.7034 - f1-score: 0.8239For batch 184, tr_loss is    0.27.\n",
      "186/200 [==========================>...] - ETA: 12s - loss: 0.2740 - iou_score: 0.7036 - f1-score: 0.8241For batch 185, tr_loss is    0.27.\n",
      "187/200 [===========================>..] - ETA: 11s - loss: 0.2738 - iou_score: 0.7039 - f1-score: 0.8242For batch 186, tr_loss is    0.27.\n",
      "188/200 [===========================>..] - ETA: 10s - loss: 0.2735 - iou_score: 0.7041 - f1-score: 0.8244For batch 187, tr_loss is    0.27.\n",
      "189/200 [===========================>..] - ETA: 9s - loss: 0.2738 - iou_score: 0.7039 - f1-score: 0.8242 For batch 188, tr_loss is    0.27.\n",
      "190/200 [===========================>..] - ETA: 8s - loss: 0.2736 - iou_score: 0.7040 - f1-score: 0.8243For batch 189, tr_loss is    0.27.\n",
      "191/200 [===========================>..] - ETA: 8s - loss: 0.2742 - iou_score: 0.7035 - f1-score: 0.8240For batch 190, tr_loss is    0.27.\n",
      "192/200 [===========================>..] - ETA: 7s - loss: 0.2746 - iou_score: 0.7030 - f1-score: 0.8236For batch 191, tr_loss is    0.27.\n",
      "193/200 [===========================>..] - ETA: 6s - loss: 0.2743 - iou_score: 0.7034 - f1-score: 0.8239For batch 192, tr_loss is    0.27.\n",
      "194/200 [============================>.] - ETA: 5s - loss: 0.2746 - iou_score: 0.7032 - f1-score: 0.8237For batch 193, tr_loss is    0.27.\n",
      "195/200 [============================>.] - ETA: 4s - loss: 0.2747 - iou_score: 0.7030 - f1-score: 0.8236For batch 194, tr_loss is    0.27.\n",
      "196/200 [============================>.] - ETA: 3s - loss: 0.2751 - iou_score: 0.7026 - f1-score: 0.8233For batch 195, tr_loss is    0.28.\n",
      "197/200 [============================>.] - ETA: 2s - loss: 0.2747 - iou_score: 0.7029 - f1-score: 0.8235For batch 196, tr_loss is    0.27.\n",
      "198/200 [============================>.] - ETA: 1s - loss: 0.2745 - iou_score: 0.7031 - f1-score: 0.8236For batch 197, tr_loss is    0.27.\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.2747 - iou_score: 0.7028 - f1-score: 0.8235For batch 198, tr_loss is    0.27.\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.2748 - iou_score: 0.7026 - f1-score: 0.8233For batch 199, tr_loss is    0.27.\n",
      "For batch 0, vl_loss is    0.37.\n",
      "For batch 1, vl_loss is    0.39.\n",
      "For batch 2, vl_loss is    0.38.\n",
      "For batch 3, vl_loss is    0.39.\n",
      "For batch 4, vl_loss is    0.38.\n",
      "For batch 5, vl_loss is    0.38.\n",
      "For batch 6, vl_loss is    0.40.\n",
      "For batch 7, vl_loss is    0.39.\n",
      "For batch 8, vl_loss is    0.40.\n",
      "For batch 9, vl_loss is    0.39.\n",
      "For batch 10, vl_loss is    0.40.\n",
      "For batch 11, vl_loss is    0.39.\n",
      "For batch 12, vl_loss is    0.39.\n",
      "For batch 13, vl_loss is    0.39.\n",
      "For batch 14, vl_loss is    0.39.\n",
      "For batch 15, vl_loss is    0.39.\n",
      "For batch 16, vl_loss is    0.38.\n",
      "For batch 17, vl_loss is    0.39.\n",
      "For batch 18, vl_loss is    0.38.\n",
      "For batch 19, vl_loss is    0.38.\n",
      "For batch 20, vl_loss is    0.38.\n",
      "For batch 21, vl_loss is    0.38.\n",
      "For batch 22, vl_loss is    0.38.\n",
      "For batch 23, vl_loss is    0.39.\n",
      "For batch 24, vl_loss is    0.38.\n",
      "For batch 25, vl_loss is    0.38.\n",
      "For batch 26, vl_loss is    0.38.\n",
      "For batch 27, vl_loss is    0.38.\n",
      "For batch 28, vl_loss is    0.38.\n",
      "For batch 29, vl_loss is    0.38.\n",
      "For batch 30, vl_loss is    0.38.\n",
      "For batch 31, vl_loss is    0.38.\n",
      "For batch 32, vl_loss is    0.38.\n",
      "For batch 33, vl_loss is    0.38.\n",
      "For batch 34, vl_loss is    0.38.\n",
      "For batch 35, vl_loss is    0.38.\n",
      "For batch 36, vl_loss is    0.38.\n",
      "For batch 37, vl_loss is    0.38.\n",
      "For batch 38, vl_loss is    0.38.\n",
      "For batch 39, vl_loss is    0.38.\n",
      "For batch 40, vl_loss is    0.38.\n",
      "For batch 41, vl_loss is    0.38.\n",
      "For batch 42, vl_loss is    0.38.\n",
      "For batch 43, vl_loss is    0.38.\n",
      "For batch 44, vl_loss is    0.38.\n",
      "For batch 45, vl_loss is    0.38.\n",
      "For batch 46, vl_loss is    0.38.\n",
      "For batch 47, vl_loss is    0.38.\n",
      "For batch 48, vl_loss is    0.38.\n",
      "For batch 49, vl_loss is    0.38.\n",
      "For batch 50, vl_loss is    0.38.\n",
      "For batch 51, vl_loss is    0.38.\n",
      "For batch 52, vl_loss is    0.37.\n",
      "For batch 53, vl_loss is    0.38.\n",
      "For batch 54, vl_loss is    0.38.\n",
      "For batch 55, vl_loss is    0.38.\n",
      "For batch 56, vl_loss is    0.38.\n",
      "For batch 57, vl_loss is    0.37.\n",
      "For batch 58, vl_loss is    0.37.\n",
      "For batch 59, vl_loss is    0.37.\n",
      "For batch 60, vl_loss is    0.37.\n",
      "For batch 61, vl_loss is    0.37.\n",
      "For batch 62, vl_loss is    0.37.\n",
      "For batch 63, vl_loss is    0.37.\n",
      "For batch 64, vl_loss is    0.37.\n",
      "For batch 65, vl_loss is    0.38.\n",
      "For batch 66, vl_loss is    0.38.\n",
      "For batch 67, vl_loss is    0.38.\n",
      "For batch 68, vl_loss is    0.38.\n",
      "For batch 69, vl_loss is    0.38.\n",
      "For batch 70, vl_loss is    0.38.\n",
      "For batch 71, vl_loss is    0.38.\n",
      "For batch 72, vl_loss is    0.38.\n",
      "For batch 73, vl_loss is    0.38.\n",
      "For batch 74, vl_loss is    0.38.\n",
      "For batch 75, vl_loss is    0.38.\n",
      "For batch 76, vl_loss is    0.38.\n",
      "For batch 77, vl_loss is    0.38.\n",
      "For batch 78, vl_loss is    0.38.\n",
      "For batch 79, vl_loss is    0.38.\n",
      "For batch 80, vl_loss is    0.38.\n",
      "For batch 81, vl_loss is    0.38.\n",
      "For batch 82, vl_loss is    0.38.\n",
      "For batch 83, vl_loss is    0.38.\n",
      "For batch 84, vl_loss is    0.38.\n",
      "For batch 85, vl_loss is    0.38.\n",
      "For batch 86, vl_loss is    0.38.\n",
      "For batch 87, vl_loss is    0.38.\n",
      "For batch 88, vl_loss is    0.38.\n",
      "For batch 89, vl_loss is    0.38.\n",
      "For batch 90, vl_loss is    0.38.\n",
      "For batch 91, vl_loss is    0.38.\n",
      "For batch 92, vl_loss is    0.37.\n",
      "For batch 93, vl_loss is    0.38.\n",
      "For batch 94, vl_loss is    0.38.\n",
      "For batch 95, vl_loss is    0.37.\n",
      "For batch 96, vl_loss is    0.38.\n",
      "For batch 97, vl_loss is    0.38.\n",
      "For batch 98, vl_loss is    0.38.\n",
      "For batch 99, vl_loss is    0.38.\n",
      "200/200 [==============================] - 185s 915ms/step - loss: 0.2748 - iou_score: 0.7026 - f1-score: 0.8233 - val_loss: 0.3766 - val_iou_score: 0.5995 - val_f1-score: 0.7459\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.32441\n",
      "The average loss for epoch 13 is    0.27 \n",
      "Epoch 15/200\n",
      "  1/200 [..............................] - ETA: 8:38 - loss: 0.2681 - iou_score: 0.6974 - f1-score: 0.8214For batch 0, tr_loss is    0.27.\n",
      "  2/200 [..............................] - ETA: 4:33 - loss: 0.2664 - iou_score: 0.6995 - f1-score: 0.8227For batch 1, tr_loss is    0.27.\n",
      "  3/200 [..............................] - ETA: 4:57 - loss: 0.2674 - iou_score: 0.7021 - f1-score: 0.8244For batch 2, tr_loss is    0.27.\n",
      "  4/200 [..............................] - ETA: 4:57 - loss: 0.2708 - iou_score: 0.6946 - f1-score: 0.8188For batch 3, tr_loss is    0.27.\n",
      "  5/200 [..............................] - ETA: 4:51 - loss: 0.2664 - iou_score: 0.7045 - f1-score: 0.8255For batch 4, tr_loss is    0.27.\n",
      "  6/200 [..............................] - ETA: 4:53 - loss: 0.2742 - iou_score: 0.6952 - f1-score: 0.8190For batch 5, tr_loss is    0.27.\n",
      "  7/200 [>.............................] - ETA: 4:46 - loss: 0.2840 - iou_score: 0.6853 - f1-score: 0.8117For batch 6, tr_loss is    0.28.\n",
      "  8/200 [>.............................] - ETA: 4:30 - loss: 0.2836 - iou_score: 0.6854 - f1-score: 0.8118For batch 7, tr_loss is    0.28.\n",
      "  9/200 [>.............................] - ETA: 4:18 - loss: 0.2803 - iou_score: 0.6896 - f1-score: 0.8148For batch 8, tr_loss is    0.28.\n",
      " 10/200 [>.............................] - ETA: 4:10 - loss: 0.2835 - iou_score: 0.6867 - f1-score: 0.8123For batch 9, tr_loss is    0.28.\n",
      " 11/200 [>.............................] - ETA: 3:58 - loss: 0.2835 - iou_score: 0.6883 - f1-score: 0.8136For batch 10, tr_loss is    0.28.\n",
      " 12/200 [>.............................] - ETA: 3:52 - loss: 0.2857 - iou_score: 0.6846 - f1-score: 0.8109For batch 11, tr_loss is    0.29.\n",
      " 13/200 [>.............................] - ETA: 3:47 - loss: 0.2872 - iou_score: 0.6814 - f1-score: 0.8086For batch 12, tr_loss is    0.29.\n",
      " 14/200 [=>............................] - ETA: 3:43 - loss: 0.2857 - iou_score: 0.6838 - f1-score: 0.8103For batch 13, tr_loss is    0.29.\n",
      " 15/200 [=>............................] - ETA: 3:36 - loss: 0.2840 - iou_score: 0.6848 - f1-score: 0.8111For batch 14, tr_loss is    0.28.\n",
      " 16/200 [=>............................] - ETA: 3:33 - loss: 0.2827 - iou_score: 0.6857 - f1-score: 0.8118For batch 15, tr_loss is    0.28.\n",
      " 17/200 [=>............................] - ETA: 3:25 - loss: 0.2809 - iou_score: 0.6891 - f1-score: 0.8142For batch 16, tr_loss is    0.28.\n",
      " 18/200 [=>............................] - ETA: 3:23 - loss: 0.2796 - iou_score: 0.6905 - f1-score: 0.8153For batch 17, tr_loss is    0.28.\n",
      " 19/200 [=>............................] - ETA: 3:21 - loss: 0.2808 - iou_score: 0.6886 - f1-score: 0.8138For batch 18, tr_loss is    0.28.\n",
      " 20/200 [==>...........................] - ETA: 3:19 - loss: 0.2780 - iou_score: 0.6938 - f1-score: 0.8173For batch 19, tr_loss is    0.28.\n",
      " 21/200 [==>...........................] - ETA: 3:18 - loss: 0.2760 - iou_score: 0.6968 - f1-score: 0.8194For batch 20, tr_loss is    0.28.\n",
      " 22/200 [==>...........................] - ETA: 3:16 - loss: 0.2745 - iou_score: 0.6990 - f1-score: 0.8209For batch 21, tr_loss is    0.27.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 23/200 [==>...........................] - ETA: 3:09 - loss: 0.2724 - iou_score: 0.7020 - f1-score: 0.8230For batch 22, tr_loss is    0.27.\n",
      " 24/200 [==>...........................] - ETA: 3:08 - loss: 0.2712 - iou_score: 0.7030 - f1-score: 0.8238For batch 23, tr_loss is    0.27.\n",
      " 25/200 [==>...........................] - ETA: 3:07 - loss: 0.2705 - iou_score: 0.7041 - f1-score: 0.8245For batch 24, tr_loss is    0.27.\n",
      " 26/200 [==>...........................] - ETA: 3:05 - loss: 0.2723 - iou_score: 0.7025 - f1-score: 0.8235For batch 25, tr_loss is    0.27.\n",
      " 27/200 [===>..........................] - ETA: 3:00 - loss: 0.2717 - iou_score: 0.7029 - f1-score: 0.8237For batch 26, tr_loss is    0.27.\n",
      " 28/200 [===>..........................] - ETA: 2:58 - loss: 0.2714 - iou_score: 0.7035 - f1-score: 0.8242For batch 27, tr_loss is    0.27.\n",
      " 29/200 [===>..........................] - ETA: 2:56 - loss: 0.2717 - iou_score: 0.7028 - f1-score: 0.8238For batch 28, tr_loss is    0.27.\n",
      " 30/200 [===>..........................] - ETA: 2:55 - loss: 0.2702 - iou_score: 0.7054 - f1-score: 0.8255For batch 29, tr_loss is    0.27.\n",
      " 31/200 [===>..........................] - ETA: 2:50 - loss: 0.2683 - iou_score: 0.7080 - f1-score: 0.8273For batch 30, tr_loss is    0.27.\n",
      " 32/200 [===>..........................] - ETA: 2:49 - loss: 0.2674 - iou_score: 0.7097 - f1-score: 0.8284For batch 31, tr_loss is    0.27.\n",
      " 33/200 [===>..........................] - ETA: 2:49 - loss: 0.2661 - iou_score: 0.7108 - f1-score: 0.8293For batch 32, tr_loss is    0.27.\n",
      " 34/200 [====>.........................] - ETA: 2:46 - loss: 0.2666 - iou_score: 0.7095 - f1-score: 0.8284For batch 33, tr_loss is    0.27.\n",
      " 35/200 [====>.........................] - ETA: 2:45 - loss: 0.2662 - iou_score: 0.7101 - f1-score: 0.8289For batch 34, tr_loss is    0.27.\n",
      " 36/200 [====>.........................] - ETA: 2:42 - loss: 0.2662 - iou_score: 0.7105 - f1-score: 0.8291For batch 35, tr_loss is    0.27.\n",
      " 37/200 [====>.........................] - ETA: 2:40 - loss: 0.2673 - iou_score: 0.7097 - f1-score: 0.8286For batch 36, tr_loss is    0.27.\n",
      " 38/200 [====>.........................] - ETA: 2:38 - loss: 0.2681 - iou_score: 0.7086 - f1-score: 0.8278For batch 37, tr_loss is    0.27.\n",
      " 39/200 [====>.........................] - ETA: 2:36 - loss: 0.2668 - iou_score: 0.7102 - f1-score: 0.8289For batch 38, tr_loss is    0.27.\n",
      " 40/200 [=====>........................] - ETA: 2:33 - loss: 0.2655 - iou_score: 0.7114 - f1-score: 0.8297For batch 39, tr_loss is    0.27.\n",
      " 41/200 [=====>........................] - ETA: 2:32 - loss: 0.2658 - iou_score: 0.7109 - f1-score: 0.8294For batch 40, tr_loss is    0.27.\n",
      " 42/200 [=====>........................] - ETA: 2:31 - loss: 0.2657 - iou_score: 0.7108 - f1-score: 0.8293For batch 41, tr_loss is    0.27.\n",
      " 43/200 [=====>........................] - ETA: 2:30 - loss: 0.2656 - iou_score: 0.7112 - f1-score: 0.8296For batch 42, tr_loss is    0.27.\n",
      " 44/200 [=====>........................] - ETA: 2:29 - loss: 0.2649 - iou_score: 0.7122 - f1-score: 0.8303For batch 43, tr_loss is    0.26.\n",
      " 45/200 [=====>........................] - ETA: 2:28 - loss: 0.2648 - iou_score: 0.7120 - f1-score: 0.8301For batch 44, tr_loss is    0.26.\n",
      " 46/200 [=====>........................] - ETA: 2:28 - loss: 0.2660 - iou_score: 0.7109 - f1-score: 0.8294For batch 45, tr_loss is    0.27.\n",
      " 47/200 [======>.......................] - ETA: 2:25 - loss: 0.2669 - iou_score: 0.7102 - f1-score: 0.8289For batch 46, tr_loss is    0.27.\n",
      " 48/200 [======>.......................] - ETA: 2:23 - loss: 0.2675 - iou_score: 0.7095 - f1-score: 0.8284For batch 47, tr_loss is    0.27.\n",
      " 49/200 [======>.......................] - ETA: 2:23 - loss: 0.2672 - iou_score: 0.7099 - f1-score: 0.8287For batch 48, tr_loss is    0.27.\n",
      " 50/200 [======>.......................] - ETA: 2:21 - loss: 0.2655 - iou_score: 0.7119 - f1-score: 0.8300For batch 49, tr_loss is    0.27.\n",
      " 51/200 [======>.......................] - ETA: 2:21 - loss: 0.2652 - iou_score: 0.7125 - f1-score: 0.8305For batch 50, tr_loss is    0.27.\n",
      " 52/200 [======>.......................] - ETA: 2:20 - loss: 0.2662 - iou_score: 0.7120 - f1-score: 0.8300For batch 51, tr_loss is    0.27.\n",
      " 53/200 [======>.......................] - ETA: 2:19 - loss: 0.2661 - iou_score: 0.7120 - f1-score: 0.8300For batch 52, tr_loss is    0.27.\n",
      " 54/200 [=======>......................] - ETA: 2:18 - loss: 0.2665 - iou_score: 0.7114 - f1-score: 0.8296For batch 53, tr_loss is    0.27.\n",
      " 55/200 [=======>......................] - ETA: 2:17 - loss: 0.2657 - iou_score: 0.7122 - f1-score: 0.8302For batch 54, tr_loss is    0.27.\n",
      " 56/200 [=======>......................] - ETA: 2:15 - loss: 0.2655 - iou_score: 0.7125 - f1-score: 0.8304For batch 55, tr_loss is    0.27.\n",
      " 57/200 [=======>......................] - ETA: 2:14 - loss: 0.2653 - iou_score: 0.7124 - f1-score: 0.8304For batch 56, tr_loss is    0.27.\n",
      " 58/200 [=======>......................] - ETA: 2:13 - loss: 0.2647 - iou_score: 0.7128 - f1-score: 0.8307For batch 57, tr_loss is    0.26.\n",
      " 59/200 [=======>......................] - ETA: 2:11 - loss: 0.2640 - iou_score: 0.7137 - f1-score: 0.8313For batch 58, tr_loss is    0.26.\n",
      " 60/200 [========>.....................] - ETA: 2:10 - loss: 0.2633 - iou_score: 0.7142 - f1-score: 0.8317For batch 59, tr_loss is    0.26.\n",
      " 61/200 [========>.....................] - ETA: 2:09 - loss: 0.2638 - iou_score: 0.7139 - f1-score: 0.8314For batch 60, tr_loss is    0.26.\n",
      " 62/200 [========>.....................] - ETA: 2:07 - loss: 0.2636 - iou_score: 0.7136 - f1-score: 0.8313For batch 61, tr_loss is    0.26.\n",
      " 63/200 [========>.....................] - ETA: 2:07 - loss: 0.2631 - iou_score: 0.7142 - f1-score: 0.8317For batch 62, tr_loss is    0.26.\n",
      " 64/200 [========>.....................] - ETA: 2:06 - loss: 0.2644 - iou_score: 0.7130 - f1-score: 0.8309For batch 63, tr_loss is    0.26.\n",
      " 65/200 [========>.....................] - ETA: 2:04 - loss: 0.2637 - iou_score: 0.7138 - f1-score: 0.8314For batch 64, tr_loss is    0.26.\n",
      " 66/200 [========>.....................] - ETA: 2:02 - loss: 0.2650 - iou_score: 0.7124 - f1-score: 0.8304For batch 65, tr_loss is    0.27.\n",
      " 67/200 [=========>....................] - ETA: 2:01 - loss: 0.2645 - iou_score: 0.7130 - f1-score: 0.8308For batch 66, tr_loss is    0.26.\n",
      " 68/200 [=========>....................] - ETA: 2:00 - loss: 0.2640 - iou_score: 0.7134 - f1-score: 0.8311For batch 67, tr_loss is    0.26.\n",
      " 69/200 [=========>....................] - ETA: 2:00 - loss: 0.2648 - iou_score: 0.7119 - f1-score: 0.8301For batch 68, tr_loss is    0.26.\n",
      " 70/200 [=========>....................] - ETA: 1:59 - loss: 0.2646 - iou_score: 0.7122 - f1-score: 0.8302For batch 69, tr_loss is    0.26.\n",
      " 71/200 [=========>....................] - ETA: 1:58 - loss: 0.2641 - iou_score: 0.7129 - f1-score: 0.8308For batch 70, tr_loss is    0.26.\n",
      " 72/200 [=========>....................] - ETA: 1:58 - loss: 0.2640 - iou_score: 0.7128 - f1-score: 0.8307For batch 71, tr_loss is    0.26.\n",
      " 73/200 [=========>....................] - ETA: 1:57 - loss: 0.2636 - iou_score: 0.7132 - f1-score: 0.8310For batch 72, tr_loss is    0.26.\n",
      " 74/200 [==========>...................] - ETA: 1:55 - loss: 0.2639 - iou_score: 0.7129 - f1-score: 0.8308For batch 73, tr_loss is    0.26.\n",
      " 75/200 [==========>...................] - ETA: 1:54 - loss: 0.2649 - iou_score: 0.7121 - f1-score: 0.8302For batch 74, tr_loss is    0.26.\n",
      " 76/200 [==========>...................] - ETA: 1:53 - loss: 0.2651 - iou_score: 0.7119 - f1-score: 0.8301For batch 75, tr_loss is    0.27.\n",
      " 77/200 [==========>...................] - ETA: 1:52 - loss: 0.2646 - iou_score: 0.7123 - f1-score: 0.8304For batch 76, tr_loss is    0.26.\n",
      " 78/200 [==========>...................] - ETA: 1:51 - loss: 0.2642 - iou_score: 0.7126 - f1-score: 0.8306For batch 77, tr_loss is    0.26.\n",
      " 79/200 [==========>...................] - ETA: 1:50 - loss: 0.2642 - iou_score: 0.7128 - f1-score: 0.8308For batch 78, tr_loss is    0.26.\n",
      " 80/200 [===========>..................] - ETA: 1:49 - loss: 0.2637 - iou_score: 0.7131 - f1-score: 0.8309For batch 79, tr_loss is    0.26.\n",
      " 81/200 [===========>..................] - ETA: 1:48 - loss: 0.2629 - iou_score: 0.7142 - f1-score: 0.8317For batch 80, tr_loss is    0.26.\n",
      " 82/200 [===========>..................] - ETA: 1:47 - loss: 0.2628 - iou_score: 0.7144 - f1-score: 0.8318For batch 81, tr_loss is    0.26.\n",
      " 83/200 [===========>..................] - ETA: 1:47 - loss: 0.2629 - iou_score: 0.7141 - f1-score: 0.8317For batch 82, tr_loss is    0.26.\n",
      " 84/200 [===========>..................] - ETA: 1:45 - loss: 0.2626 - iou_score: 0.7143 - f1-score: 0.8318For batch 83, tr_loss is    0.26.\n",
      " 85/200 [===========>..................] - ETA: 1:44 - loss: 0.2632 - iou_score: 0.7133 - f1-score: 0.8311For batch 84, tr_loss is    0.26.\n",
      " 86/200 [===========>..................] - ETA: 1:43 - loss: 0.2631 - iou_score: 0.7131 - f1-score: 0.8310For batch 85, tr_loss is    0.26.\n",
      " 87/200 [============>.................] - ETA: 1:42 - loss: 0.2629 - iou_score: 0.7134 - f1-score: 0.8312For batch 86, tr_loss is    0.26.\n",
      " 88/200 [============>.................] - ETA: 1:41 - loss: 0.2628 - iou_score: 0.7137 - f1-score: 0.8313For batch 87, tr_loss is    0.26.\n",
      " 89/200 [============>.................] - ETA: 1:40 - loss: 0.2631 - iou_score: 0.7133 - f1-score: 0.8311For batch 88, tr_loss is    0.26.\n",
      " 90/200 [============>.................] - ETA: 1:39 - loss: 0.2630 - iou_score: 0.7132 - f1-score: 0.8311For batch 89, tr_loss is    0.26.\n",
      " 91/200 [============>.................] - ETA: 1:39 - loss: 0.2630 - iou_score: 0.7132 - f1-score: 0.8310For batch 90, tr_loss is    0.26.\n",
      " 92/200 [============>.................] - ETA: 1:38 - loss: 0.2634 - iou_score: 0.7126 - f1-score: 0.8307For batch 91, tr_loss is    0.26.\n",
      " 93/200 [============>.................] - ETA: 1:36 - loss: 0.2634 - iou_score: 0.7124 - f1-score: 0.8305For batch 92, tr_loss is    0.26.\n",
      " 94/200 [=============>................] - ETA: 1:35 - loss: 0.2645 - iou_score: 0.7112 - f1-score: 0.8296For batch 93, tr_loss is    0.26.\n",
      " 95/200 [=============>................] - ETA: 1:34 - loss: 0.2652 - iou_score: 0.7104 - f1-score: 0.8291For batch 94, tr_loss is    0.27.\n",
      " 96/200 [=============>................] - ETA: 1:34 - loss: 0.2647 - iou_score: 0.7110 - f1-score: 0.8295For batch 95, tr_loss is    0.26.\n",
      " 97/200 [=============>................] - ETA: 1:32 - loss: 0.2654 - iou_score: 0.7101 - f1-score: 0.8288For batch 96, tr_loss is    0.27.\n",
      " 98/200 [=============>................] - ETA: 1:31 - loss: 0.2659 - iou_score: 0.7097 - f1-score: 0.8286For batch 97, tr_loss is    0.27.\n",
      " 99/200 [=============>................] - ETA: 1:30 - loss: 0.2655 - iou_score: 0.7104 - f1-score: 0.8290For batch 98, tr_loss is    0.27.\n",
      "100/200 [==============>...............] - ETA: 1:30 - loss: 0.2657 - iou_score: 0.7102 - f1-score: 0.8289For batch 99, tr_loss is    0.27.\n",
      "101/200 [==============>...............] - ETA: 1:29 - loss: 0.2658 - iou_score: 0.7102 - f1-score: 0.8289For batch 100, tr_loss is    0.27.\n",
      "102/200 [==============>...............] - ETA: 1:28 - loss: 0.2659 - iou_score: 0.7097 - f1-score: 0.8286For batch 101, tr_loss is    0.27.\n",
      "103/200 [==============>...............] - ETA: 1:27 - loss: 0.2660 - iou_score: 0.7096 - f1-score: 0.8286For batch 102, tr_loss is    0.27.\n",
      "104/200 [==============>...............] - ETA: 1:26 - loss: 0.2660 - iou_score: 0.7094 - f1-score: 0.8284For batch 103, tr_loss is    0.27.\n",
      "105/200 [==============>...............] - ETA: 1:25 - loss: 0.2661 - iou_score: 0.7091 - f1-score: 0.8282For batch 104, tr_loss is    0.27.\n",
      "106/200 [==============>...............] - ETA: 1:25 - loss: 0.2668 - iou_score: 0.7086 - f1-score: 0.8279For batch 105, tr_loss is    0.27.\n",
      "107/200 [===============>..............] - ETA: 1:24 - loss: 0.2672 - iou_score: 0.7083 - f1-score: 0.8276For batch 106, tr_loss is    0.27.\n",
      "108/200 [===============>..............] - ETA: 1:23 - loss: 0.2671 - iou_score: 0.7085 - f1-score: 0.8278For batch 107, tr_loss is    0.27.\n",
      "109/200 [===============>..............] - ETA: 1:22 - loss: 0.2671 - iou_score: 0.7085 - f1-score: 0.8278For batch 108, tr_loss is    0.27.\n",
      "110/200 [===============>..............] - ETA: 1:21 - loss: 0.2668 - iou_score: 0.7091 - f1-score: 0.8282For batch 109, tr_loss is    0.27.\n",
      "111/200 [===============>..............] - ETA: 1:20 - loss: 0.2665 - iou_score: 0.7095 - f1-score: 0.8284For batch 110, tr_loss is    0.27.\n",
      "112/200 [===============>..............] - ETA: 1:19 - loss: 0.2666 - iou_score: 0.7094 - f1-score: 0.8284For batch 111, tr_loss is    0.27.\n",
      "113/200 [===============>..............] - ETA: 1:18 - loss: 0.2671 - iou_score: 0.7084 - f1-score: 0.8276For batch 112, tr_loss is    0.27.\n",
      "114/200 [================>.............] - ETA: 1:17 - loss: 0.2678 - iou_score: 0.7077 - f1-score: 0.8271For batch 113, tr_loss is    0.27.\n",
      "115/200 [================>.............] - ETA: 1:16 - loss: 0.2677 - iou_score: 0.7078 - f1-score: 0.8272For batch 114, tr_loss is    0.27.\n",
      "116/200 [================>.............] - ETA: 1:15 - loss: 0.2683 - iou_score: 0.7071 - f1-score: 0.8267For batch 115, tr_loss is    0.27.\n",
      "117/200 [================>.............] - ETA: 1:15 - loss: 0.2686 - iou_score: 0.7070 - f1-score: 0.8266For batch 116, tr_loss is    0.27.\n",
      "118/200 [================>.............] - ETA: 1:14 - loss: 0.2687 - iou_score: 0.7069 - f1-score: 0.8266For batch 117, tr_loss is    0.27.\n",
      "119/200 [================>.............] - ETA: 1:13 - loss: 0.2688 - iou_score: 0.7067 - f1-score: 0.8265For batch 118, tr_loss is    0.27.\n",
      "120/200 [=================>............] - ETA: 1:12 - loss: 0.2685 - iou_score: 0.7071 - f1-score: 0.8267For batch 119, tr_loss is    0.27.\n",
      "121/200 [=================>............] - ETA: 1:11 - loss: 0.2682 - iou_score: 0.7076 - f1-score: 0.8271For batch 120, tr_loss is    0.27.\n",
      "122/200 [=================>............] - ETA: 1:10 - loss: 0.2680 - iou_score: 0.7078 - f1-score: 0.8272For batch 121, tr_loss is    0.27.\n",
      "123/200 [=================>............] - ETA: 1:09 - loss: 0.2686 - iou_score: 0.7071 - f1-score: 0.8267For batch 122, tr_loss is    0.27.\n",
      "124/200 [=================>............] - ETA: 1:08 - loss: 0.2689 - iou_score: 0.7068 - f1-score: 0.8265For batch 123, tr_loss is    0.27.\n",
      "125/200 [=================>............] - ETA: 1:07 - loss: 0.2691 - iou_score: 0.7066 - f1-score: 0.8263For batch 124, tr_loss is    0.27.\n",
      "126/200 [=================>............] - ETA: 1:06 - loss: 0.2691 - iou_score: 0.7067 - f1-score: 0.8264For batch 125, tr_loss is    0.27.\n",
      "127/200 [==================>...........] - ETA: 1:05 - loss: 0.2691 - iou_score: 0.7066 - f1-score: 0.8264For batch 126, tr_loss is    0.27.\n",
      "128/200 [==================>...........] - ETA: 1:05 - loss: 0.2698 - iou_score: 0.7057 - f1-score: 0.8257For batch 127, tr_loss is    0.27.\n",
      "129/200 [==================>...........] - ETA: 1:04 - loss: 0.2698 - iou_score: 0.7058 - f1-score: 0.8258For batch 128, tr_loss is    0.27.\n",
      "130/200 [==================>...........] - ETA: 1:03 - loss: 0.2696 - iou_score: 0.7060 - f1-score: 0.8259For batch 129, tr_loss is    0.27.\n",
      "131/200 [==================>...........] - ETA: 1:02 - loss: 0.2693 - iou_score: 0.7063 - f1-score: 0.8262For batch 130, tr_loss is    0.27.\n",
      "132/200 [==================>...........] - ETA: 1:01 - loss: 0.2691 - iou_score: 0.7066 - f1-score: 0.8264For batch 131, tr_loss is    0.27.\n",
      "133/200 [==================>...........] - ETA: 1:00 - loss: 0.2692 - iou_score: 0.7065 - f1-score: 0.8263For batch 132, tr_loss is    0.27.\n",
      "134/200 [===================>..........] - ETA: 59s - loss: 0.2698 - iou_score: 0.7058 - f1-score: 0.8258 For batch 133, tr_loss is    0.27.\n",
      "135/200 [===================>..........] - ETA: 58s - loss: 0.2702 - iou_score: 0.7054 - f1-score: 0.8255For batch 134, tr_loss is    0.27.\n",
      "136/200 [===================>..........] - ETA: 58s - loss: 0.2702 - iou_score: 0.7053 - f1-score: 0.8254For batch 135, tr_loss is    0.27.\n",
      "137/200 [===================>..........] - ETA: 57s - loss: 0.2707 - iou_score: 0.7045 - f1-score: 0.8249For batch 136, tr_loss is    0.27.\n",
      "138/200 [===================>..........] - ETA: 56s - loss: 0.2707 - iou_score: 0.7044 - f1-score: 0.8248For batch 137, tr_loss is    0.27.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139/200 [===================>..........] - ETA: 55s - loss: 0.2705 - iou_score: 0.7047 - f1-score: 0.8251For batch 138, tr_loss is    0.27.\n",
      "140/200 [====================>.........] - ETA: 54s - loss: 0.2717 - iou_score: 0.7037 - f1-score: 0.8243For batch 139, tr_loss is    0.27.\n",
      "141/200 [====================>.........] - ETA: 53s - loss: 0.2721 - iou_score: 0.7033 - f1-score: 0.8239For batch 140, tr_loss is    0.27.\n",
      "142/200 [====================>.........] - ETA: 52s - loss: 0.2722 - iou_score: 0.7031 - f1-score: 0.8238For batch 141, tr_loss is    0.27.\n",
      "143/200 [====================>.........] - ETA: 51s - loss: 0.2722 - iou_score: 0.7031 - f1-score: 0.8238For batch 142, tr_loss is    0.27.\n",
      "144/200 [====================>.........] - ETA: 50s - loss: 0.2724 - iou_score: 0.7027 - f1-score: 0.8236For batch 143, tr_loss is    0.27.\n",
      "145/200 [====================>.........] - ETA: 50s - loss: 0.2725 - iou_score: 0.7025 - f1-score: 0.8234For batch 144, tr_loss is    0.27.\n",
      "146/200 [====================>.........] - ETA: 49s - loss: 0.2722 - iou_score: 0.7030 - f1-score: 0.8238For batch 145, tr_loss is    0.27.\n",
      "147/200 [=====================>........] - ETA: 48s - loss: 0.2724 - iou_score: 0.7028 - f1-score: 0.8236For batch 146, tr_loss is    0.27.\n",
      "148/200 [=====================>........] - ETA: 47s - loss: 0.2718 - iou_score: 0.7037 - f1-score: 0.8241For batch 147, tr_loss is    0.27.\n",
      "149/200 [=====================>........] - ETA: 46s - loss: 0.2715 - iou_score: 0.7040 - f1-score: 0.8244For batch 148, tr_loss is    0.27.\n",
      "150/200 [=====================>........] - ETA: 45s - loss: 0.2711 - iou_score: 0.7046 - f1-score: 0.8247For batch 149, tr_loss is    0.27.\n",
      "151/200 [=====================>........] - ETA: 44s - loss: 0.2712 - iou_score: 0.7044 - f1-score: 0.8246For batch 150, tr_loss is    0.27.\n",
      "152/200 [=====================>........] - ETA: 43s - loss: 0.2710 - iou_score: 0.7046 - f1-score: 0.8248For batch 151, tr_loss is    0.27.\n",
      "153/200 [=====================>........] - ETA: 42s - loss: 0.2707 - iou_score: 0.7048 - f1-score: 0.8249For batch 152, tr_loss is    0.27.\n",
      "154/200 [======================>.......] - ETA: 41s - loss: 0.2708 - iou_score: 0.7049 - f1-score: 0.8250For batch 153, tr_loss is    0.27.\n",
      "155/200 [======================>.......] - ETA: 40s - loss: 0.2707 - iou_score: 0.7050 - f1-score: 0.8250For batch 154, tr_loss is    0.27.\n",
      "156/200 [======================>.......] - ETA: 39s - loss: 0.2706 - iou_score: 0.7051 - f1-score: 0.8252For batch 155, tr_loss is    0.27.\n",
      "157/200 [======================>.......] - ETA: 38s - loss: 0.2706 - iou_score: 0.7052 - f1-score: 0.8252For batch 156, tr_loss is    0.27.\n",
      "158/200 [======================>.......] - ETA: 37s - loss: 0.2707 - iou_score: 0.7050 - f1-score: 0.8251For batch 157, tr_loss is    0.27.\n",
      "159/200 [======================>.......] - ETA: 36s - loss: 0.2709 - iou_score: 0.7048 - f1-score: 0.8250For batch 158, tr_loss is    0.27.\n",
      "160/200 [=======================>......] - ETA: 36s - loss: 0.2708 - iou_score: 0.7048 - f1-score: 0.8250For batch 159, tr_loss is    0.27.\n",
      "161/200 [=======================>......] - ETA: 35s - loss: 0.2712 - iou_score: 0.7043 - f1-score: 0.8246For batch 160, tr_loss is    0.27.\n",
      "162/200 [=======================>......] - ETA: 34s - loss: 0.2713 - iou_score: 0.7041 - f1-score: 0.8245For batch 161, tr_loss is    0.27.\n",
      "163/200 [=======================>......] - ETA: 33s - loss: 0.2708 - iou_score: 0.7048 - f1-score: 0.8249For batch 162, tr_loss is    0.27.\n",
      "164/200 [=======================>......] - ETA: 32s - loss: 0.2706 - iou_score: 0.7049 - f1-score: 0.8250For batch 163, tr_loss is    0.27.\n",
      "165/200 [=======================>......] - ETA: 31s - loss: 0.2705 - iou_score: 0.7052 - f1-score: 0.8252For batch 164, tr_loss is    0.27.\n",
      "166/200 [=======================>......] - ETA: 30s - loss: 0.2702 - iou_score: 0.7053 - f1-score: 0.8253For batch 165, tr_loss is    0.27.\n",
      "167/200 [========================>.....] - ETA: 29s - loss: 0.2698 - iou_score: 0.7059 - f1-score: 0.8257For batch 166, tr_loss is    0.27.\n",
      "168/200 [========================>.....] - ETA: 28s - loss: 0.2700 - iou_score: 0.7058 - f1-score: 0.8256For batch 167, tr_loss is    0.27.\n",
      "169/200 [========================>.....] - ETA: 27s - loss: 0.2703 - iou_score: 0.7054 - f1-score: 0.8254For batch 168, tr_loss is    0.27.\n",
      "170/200 [========================>.....] - ETA: 26s - loss: 0.2700 - iou_score: 0.7058 - f1-score: 0.8256For batch 169, tr_loss is    0.27.\n",
      "171/200 [========================>.....] - ETA: 25s - loss: 0.2700 - iou_score: 0.7057 - f1-score: 0.8256For batch 170, tr_loss is    0.27.\n",
      "172/200 [========================>.....] - ETA: 25s - loss: 0.2698 - iou_score: 0.7061 - f1-score: 0.8259For batch 171, tr_loss is    0.27.\n",
      "173/200 [========================>.....] - ETA: 24s - loss: 0.2698 - iou_score: 0.7063 - f1-score: 0.8260For batch 172, tr_loss is    0.27.\n",
      "174/200 [=========================>....] - ETA: 23s - loss: 0.2696 - iou_score: 0.7065 - f1-score: 0.8261For batch 173, tr_loss is    0.27.\n",
      "175/200 [=========================>....] - ETA: 22s - loss: 0.2693 - iou_score: 0.7069 - f1-score: 0.8264For batch 174, tr_loss is    0.27.\n",
      "176/200 [=========================>....] - ETA: 21s - loss: 0.2693 - iou_score: 0.7068 - f1-score: 0.8263For batch 175, tr_loss is    0.27.\n",
      "177/200 [=========================>....] - ETA: 20s - loss: 0.2690 - iou_score: 0.7072 - f1-score: 0.8266For batch 176, tr_loss is    0.27.\n",
      "178/200 [=========================>....] - ETA: 19s - loss: 0.2692 - iou_score: 0.7068 - f1-score: 0.8263For batch 177, tr_loss is    0.27.\n",
      "179/200 [=========================>....] - ETA: 18s - loss: 0.2690 - iou_score: 0.7072 - f1-score: 0.8266For batch 178, tr_loss is    0.27.\n",
      "180/200 [==========================>...] - ETA: 17s - loss: 0.2694 - iou_score: 0.7068 - f1-score: 0.8263For batch 179, tr_loss is    0.27.\n",
      "181/200 [==========================>...] - ETA: 16s - loss: 0.2699 - iou_score: 0.7063 - f1-score: 0.8260For batch 180, tr_loss is    0.27.\n",
      "182/200 [==========================>...] - ETA: 16s - loss: 0.2698 - iou_score: 0.7064 - f1-score: 0.8261For batch 181, tr_loss is    0.27.\n",
      "183/200 [==========================>...] - ETA: 15s - loss: 0.2699 - iou_score: 0.7061 - f1-score: 0.8258For batch 182, tr_loss is    0.27.\n",
      "184/200 [==========================>...] - ETA: 14s - loss: 0.2697 - iou_score: 0.7064 - f1-score: 0.8260For batch 183, tr_loss is    0.27.\n",
      "185/200 [==========================>...] - ETA: 13s - loss: 0.2697 - iou_score: 0.7065 - f1-score: 0.8261For batch 184, tr_loss is    0.27.\n",
      "186/200 [==========================>...] - ETA: 12s - loss: 0.2695 - iou_score: 0.7067 - f1-score: 0.8262For batch 185, tr_loss is    0.27.\n",
      "187/200 [===========================>..] - ETA: 11s - loss: 0.2694 - iou_score: 0.7068 - f1-score: 0.8263For batch 186, tr_loss is    0.27.\n",
      "188/200 [===========================>..] - ETA: 10s - loss: 0.2692 - iou_score: 0.7069 - f1-score: 0.8264For batch 187, tr_loss is    0.27.\n",
      "189/200 [===========================>..] - ETA: 9s - loss: 0.2695 - iou_score: 0.7066 - f1-score: 0.8262 For batch 188, tr_loss is    0.27.\n",
      "190/200 [===========================>..] - ETA: 8s - loss: 0.2695 - iou_score: 0.7067 - f1-score: 0.8262For batch 189, tr_loss is    0.27.\n",
      "191/200 [===========================>..] - ETA: 7s - loss: 0.2700 - iou_score: 0.7061 - f1-score: 0.8258For batch 190, tr_loss is    0.27.\n",
      "192/200 [===========================>..] - ETA: 7s - loss: 0.2703 - iou_score: 0.7057 - f1-score: 0.8255For batch 191, tr_loss is    0.27.\n",
      "193/200 [===========================>..] - ETA: 6s - loss: 0.2700 - iou_score: 0.7061 - f1-score: 0.8257For batch 192, tr_loss is    0.27.\n",
      "194/200 [============================>.] - ETA: 5s - loss: 0.2703 - iou_score: 0.7057 - f1-score: 0.8255For batch 193, tr_loss is    0.27.\n",
      "195/200 [============================>.] - ETA: 4s - loss: 0.2704 - iou_score: 0.7056 - f1-score: 0.8254For batch 194, tr_loss is    0.27.\n",
      "196/200 [============================>.] - ETA: 3s - loss: 0.2706 - iou_score: 0.7052 - f1-score: 0.8252For batch 195, tr_loss is    0.27.\n",
      "197/200 [============================>.] - ETA: 2s - loss: 0.2704 - iou_score: 0.7055 - f1-score: 0.8254For batch 196, tr_loss is    0.27.\n",
      "198/200 [============================>.] - ETA: 1s - loss: 0.2703 - iou_score: 0.7057 - f1-score: 0.8255For batch 197, tr_loss is    0.27.\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.2705 - iou_score: 0.7054 - f1-score: 0.8253For batch 198, tr_loss is    0.27.\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.2704 - iou_score: 0.7055 - f1-score: 0.8254For batch 199, tr_loss is    0.27.\n",
      "For batch 0, vl_loss is    0.37.\n",
      "For batch 1, vl_loss is    0.39.\n",
      "For batch 2, vl_loss is    0.39.\n",
      "For batch 3, vl_loss is    0.39.\n",
      "For batch 4, vl_loss is    0.39.\n",
      "For batch 5, vl_loss is    0.39.\n",
      "For batch 6, vl_loss is    0.40.\n",
      "For batch 7, vl_loss is    0.40.\n",
      "For batch 8, vl_loss is    0.40.\n",
      "For batch 9, vl_loss is    0.40.\n",
      "For batch 10, vl_loss is    0.40.\n",
      "For batch 11, vl_loss is    0.40.\n",
      "For batch 12, vl_loss is    0.40.\n",
      "For batch 13, vl_loss is    0.39.\n",
      "For batch 14, vl_loss is    0.40.\n",
      "For batch 15, vl_loss is    0.39.\n",
      "For batch 16, vl_loss is    0.39.\n",
      "For batch 17, vl_loss is    0.39.\n",
      "For batch 18, vl_loss is    0.39.\n",
      "For batch 19, vl_loss is    0.39.\n",
      "For batch 20, vl_loss is    0.39.\n",
      "For batch 21, vl_loss is    0.39.\n",
      "For batch 22, vl_loss is    0.39.\n",
      "For batch 23, vl_loss is    0.39.\n",
      "For batch 24, vl_loss is    0.39.\n",
      "For batch 25, vl_loss is    0.39.\n",
      "For batch 26, vl_loss is    0.39.\n",
      "For batch 27, vl_loss is    0.39.\n",
      "For batch 28, vl_loss is    0.39.\n",
      "For batch 29, vl_loss is    0.39.\n",
      "For batch 30, vl_loss is    0.39.\n",
      "For batch 31, vl_loss is    0.39.\n",
      "For batch 32, vl_loss is    0.39.\n",
      "For batch 33, vl_loss is    0.39.\n",
      "For batch 34, vl_loss is    0.39.\n",
      "For batch 35, vl_loss is    0.39.\n",
      "For batch 36, vl_loss is    0.39.\n",
      "For batch 37, vl_loss is    0.39.\n",
      "For batch 38, vl_loss is    0.38.\n",
      "For batch 39, vl_loss is    0.39.\n",
      "For batch 40, vl_loss is    0.39.\n",
      "For batch 41, vl_loss is    0.39.\n",
      "For batch 42, vl_loss is    0.39.\n",
      "For batch 43, vl_loss is    0.39.\n",
      "For batch 44, vl_loss is    0.39.\n",
      "For batch 45, vl_loss is    0.39.\n",
      "For batch 46, vl_loss is    0.39.\n",
      "For batch 47, vl_loss is    0.39.\n",
      "For batch 48, vl_loss is    0.39.\n",
      "For batch 49, vl_loss is    0.39.\n",
      "For batch 50, vl_loss is    0.39.\n",
      "For batch 51, vl_loss is    0.38.\n",
      "For batch 52, vl_loss is    0.38.\n",
      "For batch 53, vl_loss is    0.38.\n",
      "For batch 54, vl_loss is    0.39.\n",
      "For batch 55, vl_loss is    0.39.\n",
      "For batch 56, vl_loss is    0.39.\n",
      "For batch 57, vl_loss is    0.38.\n",
      "For batch 58, vl_loss is    0.38.\n",
      "For batch 59, vl_loss is    0.38.\n",
      "For batch 60, vl_loss is    0.38.\n",
      "For batch 61, vl_loss is    0.38.\n",
      "For batch 62, vl_loss is    0.38.\n",
      "For batch 63, vl_loss is    0.38.\n",
      "For batch 64, vl_loss is    0.39.\n",
      "For batch 65, vl_loss is    0.39.\n",
      "For batch 66, vl_loss is    0.39.\n",
      "For batch 67, vl_loss is    0.39.\n",
      "For batch 68, vl_loss is    0.39.\n",
      "For batch 69, vl_loss is    0.39.\n",
      "For batch 70, vl_loss is    0.39.\n",
      "For batch 71, vl_loss is    0.39.\n",
      "For batch 72, vl_loss is    0.39.\n",
      "For batch 73, vl_loss is    0.39.\n",
      "For batch 74, vl_loss is    0.39.\n",
      "For batch 75, vl_loss is    0.39.\n",
      "For batch 76, vl_loss is    0.39.\n",
      "For batch 77, vl_loss is    0.39.\n",
      "For batch 78, vl_loss is    0.39.\n",
      "For batch 79, vl_loss is    0.39.\n",
      "For batch 80, vl_loss is    0.39.\n",
      "For batch 81, vl_loss is    0.39.\n",
      "For batch 82, vl_loss is    0.39.\n",
      "For batch 83, vl_loss is    0.39.\n",
      "For batch 84, vl_loss is    0.39.\n",
      "For batch 85, vl_loss is    0.39.\n",
      "For batch 86, vl_loss is    0.39.\n",
      "For batch 87, vl_loss is    0.39.\n",
      "For batch 88, vl_loss is    0.39.\n",
      "For batch 89, vl_loss is    0.39.\n",
      "For batch 90, vl_loss is    0.39.\n",
      "For batch 91, vl_loss is    0.39.\n",
      "For batch 92, vl_loss is    0.39.\n",
      "For batch 93, vl_loss is    0.39.\n",
      "For batch 94, vl_loss is    0.39.\n",
      "For batch 95, vl_loss is    0.39.\n",
      "For batch 96, vl_loss is    0.39.\n",
      "For batch 97, vl_loss is    0.39.\n",
      "For batch 98, vl_loss is    0.39.\n",
      "For batch 99, vl_loss is    0.39.\n",
      "200/200 [==============================] - 184s 909ms/step - loss: 0.2704 - iou_score: 0.7055 - f1-score: 0.8254 - val_loss: 0.3883 - val_iou_score: 0.5697 - val_f1-score: 0.7213\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.32441\n",
      "The average loss for epoch 14 is    0.27 \n",
      "Epoch 16/200\n",
      "  1/200 [..............................] - ETA: 7:50 - loss: 0.2963 - iou_score: 0.6852 - f1-score: 0.8132For batch 0, tr_loss is    0.30.\n",
      "  2/200 [..............................] - ETA: 4:07 - loss: 0.2838 - iou_score: 0.6974 - f1-score: 0.8217For batch 1, tr_loss is    0.28.\n",
      "  3/200 [..............................] - ETA: 4:11 - loss: 0.2822 - iou_score: 0.7028 - f1-score: 0.8252For batch 2, tr_loss is    0.28.\n",
      "  4/200 [..............................] - ETA: 4:07 - loss: 0.2835 - iou_score: 0.6921 - f1-score: 0.8176For batch 3, tr_loss is    0.28.\n",
      "  5/200 [..............................] - ETA: 3:49 - loss: 0.2778 - iou_score: 0.6977 - f1-score: 0.8214For batch 4, tr_loss is    0.28.\n",
      "  6/200 [..............................] - ETA: 3:40 - loss: 0.2867 - iou_score: 0.6871 - f1-score: 0.8138For batch 5, tr_loss is    0.29.\n",
      "  7/200 [>.............................] - ETA: 3:49 - loss: 0.2894 - iou_score: 0.6812 - f1-score: 0.8093For batch 6, tr_loss is    0.29.\n",
      "  8/200 [>.............................] - ETA: 3:44 - loss: 0.2908 - iou_score: 0.6818 - f1-score: 0.8096For batch 7, tr_loss is    0.29.\n",
      "  9/200 [>.............................] - ETA: 3:41 - loss: 0.2847 - iou_score: 0.6899 - f1-score: 0.8152For batch 8, tr_loss is    0.28.\n",
      " 10/200 [>.............................] - ETA: 3:44 - loss: 0.2830 - iou_score: 0.6897 - f1-score: 0.8146For batch 9, tr_loss is    0.28.\n",
      " 11/200 [>.............................] - ETA: 3:49 - loss: 0.2814 - iou_score: 0.6907 - f1-score: 0.8154For batch 10, tr_loss is    0.28.\n",
      " 12/200 [>.............................] - ETA: 3:40 - loss: 0.2840 - iou_score: 0.6872 - f1-score: 0.8129For batch 11, tr_loss is    0.28.\n",
      " 13/200 [>.............................] - ETA: 3:34 - loss: 0.2863 - iou_score: 0.6837 - f1-score: 0.8104For batch 12, tr_loss is    0.29.\n",
      " 14/200 [=>............................] - ETA: 3:31 - loss: 0.2839 - iou_score: 0.6857 - f1-score: 0.8119For batch 13, tr_loss is    0.28.\n",
      " 15/200 [=>............................] - ETA: 3:22 - loss: 0.2818 - iou_score: 0.6877 - f1-score: 0.8133For batch 14, tr_loss is    0.28.\n",
      " 16/200 [=>............................] - ETA: 3:16 - loss: 0.2797 - iou_score: 0.6896 - f1-score: 0.8147For batch 15, tr_loss is    0.28.\n",
      " 17/200 [=>............................] - ETA: 3:17 - loss: 0.2782 - iou_score: 0.6935 - f1-score: 0.8174For batch 16, tr_loss is    0.28.\n",
      " 18/200 [=>............................] - ETA: 3:15 - loss: 0.2763 - iou_score: 0.6952 - f1-score: 0.8187For batch 17, tr_loss is    0.28.\n",
      " 19/200 [=>............................] - ETA: 3:14 - loss: 0.2779 - iou_score: 0.6931 - f1-score: 0.8170For batch 18, tr_loss is    0.28.\n",
      " 20/200 [==>...........................] - ETA: 3:12 - loss: 0.2759 - iou_score: 0.6971 - f1-score: 0.8197For batch 19, tr_loss is    0.28.\n",
      " 21/200 [==>...........................] - ETA: 3:11 - loss: 0.2742 - iou_score: 0.7003 - f1-score: 0.8219For batch 20, tr_loss is    0.27.\n",
      " 22/200 [==>...........................] - ETA: 3:09 - loss: 0.2727 - iou_score: 0.7026 - f1-score: 0.8235For batch 21, tr_loss is    0.27.\n",
      " 23/200 [==>...........................] - ETA: 3:02 - loss: 0.2718 - iou_score: 0.7046 - f1-score: 0.8249For batch 22, tr_loss is    0.27.\n",
      " 24/200 [==>...........................] - ETA: 2:59 - loss: 0.2695 - iou_score: 0.7071 - f1-score: 0.8267For batch 23, tr_loss is    0.27.\n",
      " 25/200 [==>...........................] - ETA: 2:56 - loss: 0.2687 - iou_score: 0.7082 - f1-score: 0.8275For batch 24, tr_loss is    0.27.\n",
      " 26/200 [==>...........................] - ETA: 2:55 - loss: 0.2713 - iou_score: 0.7061 - f1-score: 0.8260For batch 25, tr_loss is    0.27.\n",
      " 27/200 [===>..........................] - ETA: 2:53 - loss: 0.2704 - iou_score: 0.7077 - f1-score: 0.8271For batch 26, tr_loss is    0.27.\n",
      " 28/200 [===>..........................] - ETA: 2:49 - loss: 0.2696 - iou_score: 0.7085 - f1-score: 0.8277For batch 27, tr_loss is    0.27.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 29/200 [===>..........................] - ETA: 2:48 - loss: 0.2707 - iou_score: 0.7070 - f1-score: 0.8267For batch 28, tr_loss is    0.27.\n",
      " 30/200 [===>..........................] - ETA: 2:47 - loss: 0.2689 - iou_score: 0.7095 - f1-score: 0.8283For batch 29, tr_loss is    0.27.\n",
      " 31/200 [===>..........................] - ETA: 2:44 - loss: 0.2667 - iou_score: 0.7119 - f1-score: 0.8300For batch 30, tr_loss is    0.27.\n",
      " 32/200 [===>..........................] - ETA: 2:41 - loss: 0.2653 - iou_score: 0.7136 - f1-score: 0.8312For batch 31, tr_loss is    0.27.\n",
      " 33/200 [===>..........................] - ETA: 2:39 - loss: 0.2639 - iou_score: 0.7145 - f1-score: 0.8318For batch 32, tr_loss is    0.26.\n",
      " 34/200 [====>.........................] - ETA: 2:36 - loss: 0.2645 - iou_score: 0.7132 - f1-score: 0.8310For batch 33, tr_loss is    0.26.\n",
      " 35/200 [====>.........................] - ETA: 2:36 - loss: 0.2641 - iou_score: 0.7136 - f1-score: 0.8313For batch 34, tr_loss is    0.26.\n",
      " 36/200 [====>.........................] - ETA: 2:35 - loss: 0.2638 - iou_score: 0.7141 - f1-score: 0.8316For batch 35, tr_loss is    0.26.\n",
      " 37/200 [====>.........................] - ETA: 2:34 - loss: 0.2654 - iou_score: 0.7130 - f1-score: 0.8308For batch 36, tr_loss is    0.27.\n",
      " 38/200 [====>.........................] - ETA: 2:31 - loss: 0.2654 - iou_score: 0.7123 - f1-score: 0.8304For batch 37, tr_loss is    0.27.\n",
      " 39/200 [====>.........................] - ETA: 2:32 - loss: 0.2644 - iou_score: 0.7137 - f1-score: 0.8312For batch 38, tr_loss is    0.26.\n",
      " 40/200 [=====>........................] - ETA: 2:31 - loss: 0.2631 - iou_score: 0.7149 - f1-score: 0.8321For batch 39, tr_loss is    0.26.\n",
      " 41/200 [=====>........................] - ETA: 2:29 - loss: 0.2622 - iou_score: 0.7156 - f1-score: 0.8326For batch 40, tr_loss is    0.26.\n",
      " 42/200 [=====>........................] - ETA: 2:27 - loss: 0.2626 - iou_score: 0.7152 - f1-score: 0.8324For batch 41, tr_loss is    0.26.\n",
      " 43/200 [=====>........................] - ETA: 2:25 - loss: 0.2623 - iou_score: 0.7154 - f1-score: 0.8325For batch 42, tr_loss is    0.26.\n",
      " 44/200 [=====>........................] - ETA: 2:23 - loss: 0.2624 - iou_score: 0.7152 - f1-score: 0.8324For batch 43, tr_loss is    0.26.\n",
      " 45/200 [=====>........................] - ETA: 2:23 - loss: 0.2619 - iou_score: 0.7156 - f1-score: 0.8326For batch 44, tr_loss is    0.26.\n",
      " 46/200 [=====>........................] - ETA: 2:22 - loss: 0.2633 - iou_score: 0.7141 - f1-score: 0.8316For batch 45, tr_loss is    0.26.\n",
      " 47/200 [======>.......................] - ETA: 2:22 - loss: 0.2638 - iou_score: 0.7134 - f1-score: 0.8311For batch 46, tr_loss is    0.26.\n",
      " 48/200 [======>.......................] - ETA: 2:20 - loss: 0.2643 - iou_score: 0.7129 - f1-score: 0.8307For batch 47, tr_loss is    0.26.\n",
      " 49/200 [======>.......................] - ETA: 2:18 - loss: 0.2640 - iou_score: 0.7132 - f1-score: 0.8310For batch 48, tr_loss is    0.26.\n",
      " 50/200 [======>.......................] - ETA: 2:16 - loss: 0.2624 - iou_score: 0.7152 - f1-score: 0.8323For batch 49, tr_loss is    0.26.\n",
      " 51/200 [======>.......................] - ETA: 2:15 - loss: 0.2626 - iou_score: 0.7162 - f1-score: 0.8330For batch 50, tr_loss is    0.26.\n",
      " 52/200 [======>.......................] - ETA: 2:14 - loss: 0.2632 - iou_score: 0.7158 - f1-score: 0.8326For batch 51, tr_loss is    0.26.\n",
      " 53/200 [======>.......................] - ETA: 2:14 - loss: 0.2629 - iou_score: 0.7160 - f1-score: 0.8328For batch 52, tr_loss is    0.26.\n",
      " 54/200 [=======>......................] - ETA: 2:13 - loss: 0.2633 - iou_score: 0.7155 - f1-score: 0.8324For batch 53, tr_loss is    0.26.\n",
      " 55/200 [=======>......................] - ETA: 2:12 - loss: 0.2623 - iou_score: 0.7167 - f1-score: 0.8333For batch 54, tr_loss is    0.26.\n",
      " 56/200 [=======>......................] - ETA: 2:10 - loss: 0.2625 - iou_score: 0.7169 - f1-score: 0.8334For batch 55, tr_loss is    0.26.\n",
      " 57/200 [=======>......................] - ETA: 2:09 - loss: 0.2619 - iou_score: 0.7168 - f1-score: 0.8334For batch 56, tr_loss is    0.26.\n",
      " 58/200 [=======>......................] - ETA: 2:09 - loss: 0.2615 - iou_score: 0.7172 - f1-score: 0.8337For batch 57, tr_loss is    0.26.\n",
      " 59/200 [=======>......................] - ETA: 2:08 - loss: 0.2609 - iou_score: 0.7180 - f1-score: 0.8342For batch 58, tr_loss is    0.26.\n",
      " 60/200 [========>.....................] - ETA: 2:06 - loss: 0.2604 - iou_score: 0.7182 - f1-score: 0.8344For batch 59, tr_loss is    0.26.\n",
      " 61/200 [========>.....................] - ETA: 2:05 - loss: 0.2611 - iou_score: 0.7176 - f1-score: 0.8340For batch 60, tr_loss is    0.26.\n",
      " 62/200 [========>.....................] - ETA: 2:04 - loss: 0.2609 - iou_score: 0.7178 - f1-score: 0.8341For batch 61, tr_loss is    0.26.\n",
      " 63/200 [========>.....................] - ETA: 2:02 - loss: 0.2605 - iou_score: 0.7180 - f1-score: 0.8343For batch 62, tr_loss is    0.26.\n",
      " 64/200 [========>.....................] - ETA: 2:01 - loss: 0.2613 - iou_score: 0.7169 - f1-score: 0.8336For batch 63, tr_loss is    0.26.\n",
      " 65/200 [========>.....................] - ETA: 2:00 - loss: 0.2603 - iou_score: 0.7182 - f1-score: 0.8344For batch 64, tr_loss is    0.26.\n",
      " 66/200 [========>.....................] - ETA: 1:59 - loss: 0.2621 - iou_score: 0.7165 - f1-score: 0.8332For batch 65, tr_loss is    0.26.\n",
      " 67/200 [=========>....................] - ETA: 1:58 - loss: 0.2614 - iou_score: 0.7172 - f1-score: 0.8336For batch 66, tr_loss is    0.26.\n",
      " 68/200 [=========>....................] - ETA: 1:58 - loss: 0.2610 - iou_score: 0.7176 - f1-score: 0.8339For batch 67, tr_loss is    0.26.\n",
      " 69/200 [=========>....................] - ETA: 1:57 - loss: 0.2619 - iou_score: 0.7163 - f1-score: 0.8330For batch 68, tr_loss is    0.26.\n",
      " 70/200 [=========>....................] - ETA: 1:56 - loss: 0.2616 - iou_score: 0.7165 - f1-score: 0.8332For batch 69, tr_loss is    0.26.\n",
      " 71/200 [=========>....................] - ETA: 1:56 - loss: 0.2612 - iou_score: 0.7168 - f1-score: 0.8334For batch 70, tr_loss is    0.26.\n",
      " 72/200 [=========>....................] - ETA: 1:55 - loss: 0.2612 - iou_score: 0.7166 - f1-score: 0.8332For batch 71, tr_loss is    0.26.\n",
      " 73/200 [=========>....................] - ETA: 1:54 - loss: 0.2606 - iou_score: 0.7171 - f1-score: 0.8336For batch 72, tr_loss is    0.26.\n",
      " 74/200 [==========>...................] - ETA: 1:53 - loss: 0.2607 - iou_score: 0.7167 - f1-score: 0.8334For batch 73, tr_loss is    0.26.\n",
      " 75/200 [==========>...................] - ETA: 1:51 - loss: 0.2616 - iou_score: 0.7160 - f1-score: 0.8329For batch 74, tr_loss is    0.26.\n",
      " 76/200 [==========>...................] - ETA: 1:50 - loss: 0.2621 - iou_score: 0.7155 - f1-score: 0.8325For batch 75, tr_loss is    0.26.\n",
      " 77/200 [==========>...................] - ETA: 1:50 - loss: 0.2622 - iou_score: 0.7154 - f1-score: 0.8325For batch 76, tr_loss is    0.26.\n",
      " 78/200 [==========>...................] - ETA: 1:49 - loss: 0.2617 - iou_score: 0.7159 - f1-score: 0.8328For batch 77, tr_loss is    0.26.\n",
      " 79/200 [==========>...................] - ETA: 1:48 - loss: 0.2622 - iou_score: 0.7157 - f1-score: 0.8327For batch 78, tr_loss is    0.26.\n",
      " 80/200 [===========>..................] - ETA: 1:47 - loss: 0.2618 - iou_score: 0.7161 - f1-score: 0.8330For batch 79, tr_loss is    0.26.\n",
      " 81/200 [===========>..................] - ETA: 1:45 - loss: 0.2607 - iou_score: 0.7175 - f1-score: 0.8339For batch 80, tr_loss is    0.26.\n",
      " 82/200 [===========>..................] - ETA: 1:44 - loss: 0.2609 - iou_score: 0.7176 - f1-score: 0.8339For batch 81, tr_loss is    0.26.\n",
      " 83/200 [===========>..................] - ETA: 1:43 - loss: 0.2610 - iou_score: 0.7173 - f1-score: 0.8338For batch 82, tr_loss is    0.26.\n",
      " 84/200 [===========>..................] - ETA: 1:42 - loss: 0.2607 - iou_score: 0.7176 - f1-score: 0.8340For batch 83, tr_loss is    0.26.\n",
      " 85/200 [===========>..................] - ETA: 1:42 - loss: 0.2614 - iou_score: 0.7165 - f1-score: 0.8332For batch 84, tr_loss is    0.26.\n",
      " 86/200 [===========>..................] - ETA: 1:40 - loss: 0.2619 - iou_score: 0.7157 - f1-score: 0.8327For batch 85, tr_loss is    0.26.\n",
      " 87/200 [============>.................] - ETA: 1:39 - loss: 0.2615 - iou_score: 0.7165 - f1-score: 0.8332For batch 86, tr_loss is    0.26.\n",
      " 88/200 [============>.................] - ETA: 1:38 - loss: 0.2614 - iou_score: 0.7168 - f1-score: 0.8334For batch 87, tr_loss is    0.26.\n",
      " 89/200 [============>.................] - ETA: 1:37 - loss: 0.2618 - iou_score: 0.7162 - f1-score: 0.8330For batch 88, tr_loss is    0.26.\n",
      " 90/200 [============>.................] - ETA: 1:36 - loss: 0.2621 - iou_score: 0.7159 - f1-score: 0.8328For batch 89, tr_loss is    0.26.\n",
      " 91/200 [============>.................] - ETA: 1:35 - loss: 0.2616 - iou_score: 0.7162 - f1-score: 0.8330For batch 90, tr_loss is    0.26.\n",
      " 92/200 [============>.................] - ETA: 1:34 - loss: 0.2623 - iou_score: 0.7156 - f1-score: 0.8326For batch 91, tr_loss is    0.26.\n",
      " 93/200 [============>.................] - ETA: 1:33 - loss: 0.2625 - iou_score: 0.7154 - f1-score: 0.8324For batch 92, tr_loss is    0.26.\n",
      " 94/200 [=============>................] - ETA: 1:32 - loss: 0.2637 - iou_score: 0.7138 - f1-score: 0.8313For batch 93, tr_loss is    0.26.\n",
      " 95/200 [=============>................] - ETA: 1:31 - loss: 0.2642 - iou_score: 0.7133 - f1-score: 0.8309For batch 94, tr_loss is    0.26.\n",
      " 96/200 [=============>................] - ETA: 1:31 - loss: 0.2637 - iou_score: 0.7138 - f1-score: 0.8313For batch 95, tr_loss is    0.26.\n",
      " 97/200 [=============>................] - ETA: 1:29 - loss: 0.2640 - iou_score: 0.7130 - f1-score: 0.8307For batch 96, tr_loss is    0.26.\n",
      " 98/200 [=============>................] - ETA: 1:28 - loss: 0.2644 - iou_score: 0.7128 - f1-score: 0.8306For batch 97, tr_loss is    0.26.\n",
      " 99/200 [=============>................] - ETA: 1:27 - loss: 0.2639 - iou_score: 0.7133 - f1-score: 0.8310For batch 98, tr_loss is    0.26.\n",
      "100/200 [==============>...............] - ETA: 1:26 - loss: 0.2642 - iou_score: 0.7132 - f1-score: 0.8309For batch 99, tr_loss is    0.26.\n",
      "101/200 [==============>...............] - ETA: 1:26 - loss: 0.2641 - iou_score: 0.7133 - f1-score: 0.8310For batch 100, tr_loss is    0.26.\n",
      "102/200 [==============>...............] - ETA: 1:25 - loss: 0.2645 - iou_score: 0.7128 - f1-score: 0.8306For batch 101, tr_loss is    0.26.\n",
      "103/200 [==============>...............] - ETA: 1:24 - loss: 0.2647 - iou_score: 0.7125 - f1-score: 0.8304For batch 102, tr_loss is    0.26.\n",
      "104/200 [==============>...............] - ETA: 1:23 - loss: 0.2649 - iou_score: 0.7121 - f1-score: 0.8301For batch 103, tr_loss is    0.26.\n",
      "105/200 [==============>...............] - ETA: 1:22 - loss: 0.2650 - iou_score: 0.7116 - f1-score: 0.8298For batch 104, tr_loss is    0.27.\n",
      "106/200 [==============>...............] - ETA: 1:21 - loss: 0.2654 - iou_score: 0.7111 - f1-score: 0.8295For batch 105, tr_loss is    0.27.\n",
      "107/200 [===============>..............] - ETA: 1:21 - loss: 0.2655 - iou_score: 0.7109 - f1-score: 0.8293For batch 106, tr_loss is    0.27.\n",
      "108/200 [===============>..............] - ETA: 1:20 - loss: 0.2653 - iou_score: 0.7112 - f1-score: 0.8295For batch 107, tr_loss is    0.27.\n",
      "109/200 [===============>..............] - ETA: 1:19 - loss: 0.2653 - iou_score: 0.7112 - f1-score: 0.8295For batch 108, tr_loss is    0.27.\n",
      "110/200 [===============>..............] - ETA: 1:18 - loss: 0.2650 - iou_score: 0.7116 - f1-score: 0.8298For batch 109, tr_loss is    0.27.\n",
      "111/200 [===============>..............] - ETA: 1:17 - loss: 0.2645 - iou_score: 0.7122 - f1-score: 0.8302For batch 110, tr_loss is    0.26.\n",
      "112/200 [===============>..............] - ETA: 1:16 - loss: 0.2642 - iou_score: 0.7125 - f1-score: 0.8304For batch 111, tr_loss is    0.26.\n",
      "113/200 [===============>..............] - ETA: 1:16 - loss: 0.2648 - iou_score: 0.7115 - f1-score: 0.8297For batch 112, tr_loss is    0.26.\n",
      "114/200 [================>.............] - ETA: 1:15 - loss: 0.2654 - iou_score: 0.7108 - f1-score: 0.8292For batch 113, tr_loss is    0.27.\n",
      "115/200 [================>.............] - ETA: 1:14 - loss: 0.2657 - iou_score: 0.7105 - f1-score: 0.8289For batch 114, tr_loss is    0.27.\n",
      "116/200 [================>.............] - ETA: 1:13 - loss: 0.2660 - iou_score: 0.7100 - f1-score: 0.8286For batch 115, tr_loss is    0.27.\n",
      "117/200 [================>.............] - ETA: 1:12 - loss: 0.2661 - iou_score: 0.7097 - f1-score: 0.8284For batch 116, tr_loss is    0.27.\n",
      "118/200 [================>.............] - ETA: 1:11 - loss: 0.2661 - iou_score: 0.7097 - f1-score: 0.8284For batch 117, tr_loss is    0.27.\n",
      "119/200 [================>.............] - ETA: 1:10 - loss: 0.2663 - iou_score: 0.7097 - f1-score: 0.8285For batch 118, tr_loss is    0.27.\n",
      "120/200 [=================>............] - ETA: 1:09 - loss: 0.2660 - iou_score: 0.7099 - f1-score: 0.8286For batch 119, tr_loss is    0.27.\n",
      "121/200 [=================>............] - ETA: 1:09 - loss: 0.2657 - iou_score: 0.7103 - f1-score: 0.8289For batch 120, tr_loss is    0.27.\n",
      "122/200 [=================>............] - ETA: 1:08 - loss: 0.2656 - iou_score: 0.7104 - f1-score: 0.8290For batch 121, tr_loss is    0.27.\n",
      "123/200 [=================>............] - ETA: 1:07 - loss: 0.2663 - iou_score: 0.7096 - f1-score: 0.8283For batch 122, tr_loss is    0.27.\n",
      "124/200 [=================>............] - ETA: 1:06 - loss: 0.2663 - iou_score: 0.7097 - f1-score: 0.8284For batch 123, tr_loss is    0.27.\n",
      "125/200 [=================>............] - ETA: 1:05 - loss: 0.2664 - iou_score: 0.7095 - f1-score: 0.8283For batch 124, tr_loss is    0.27.\n",
      "126/200 [=================>............] - ETA: 1:05 - loss: 0.2664 - iou_score: 0.7095 - f1-score: 0.8283For batch 125, tr_loss is    0.27.\n",
      "127/200 [==================>...........] - ETA: 1:04 - loss: 0.2663 - iou_score: 0.7095 - f1-score: 0.8283For batch 126, tr_loss is    0.27.\n",
      "128/200 [==================>...........] - ETA: 1:03 - loss: 0.2669 - iou_score: 0.7087 - f1-score: 0.8277For batch 127, tr_loss is    0.27.\n",
      "129/200 [==================>...........] - ETA: 1:02 - loss: 0.2666 - iou_score: 0.7091 - f1-score: 0.8280For batch 128, tr_loss is    0.27.\n",
      "130/200 [==================>...........] - ETA: 1:01 - loss: 0.2663 - iou_score: 0.7093 - f1-score: 0.8282For batch 129, tr_loss is    0.27.\n",
      "131/200 [==================>...........] - ETA: 1:00 - loss: 0.2662 - iou_score: 0.7094 - f1-score: 0.8283For batch 130, tr_loss is    0.27.\n",
      "132/200 [==================>...........] - ETA: 59s - loss: 0.2661 - iou_score: 0.7096 - f1-score: 0.8284 For batch 131, tr_loss is    0.27.\n",
      "133/200 [==================>...........] - ETA: 58s - loss: 0.2661 - iou_score: 0.7096 - f1-score: 0.8284For batch 132, tr_loss is    0.27.\n",
      "134/200 [===================>..........] - ETA: 57s - loss: 0.2663 - iou_score: 0.7092 - f1-score: 0.8281For batch 133, tr_loss is    0.27.\n",
      "135/200 [===================>..........] - ETA: 57s - loss: 0.2668 - iou_score: 0.7088 - f1-score: 0.8278For batch 134, tr_loss is    0.27.\n",
      "136/200 [===================>..........] - ETA: 56s - loss: 0.2665 - iou_score: 0.7090 - f1-score: 0.8280For batch 135, tr_loss is    0.27.\n",
      "137/200 [===================>..........] - ETA: 55s - loss: 0.2671 - iou_score: 0.7083 - f1-score: 0.8275For batch 136, tr_loss is    0.27.\n",
      "138/200 [===================>..........] - ETA: 54s - loss: 0.2671 - iou_score: 0.7083 - f1-score: 0.8275For batch 137, tr_loss is    0.27.\n",
      "139/200 [===================>..........] - ETA: 53s - loss: 0.2668 - iou_score: 0.7085 - f1-score: 0.8276For batch 138, tr_loss is    0.27.\n",
      "140/200 [====================>.........] - ETA: 52s - loss: 0.2680 - iou_score: 0.7074 - f1-score: 0.8268For batch 139, tr_loss is    0.27.\n",
      "141/200 [====================>.........] - ETA: 51s - loss: 0.2687 - iou_score: 0.7067 - f1-score: 0.8263For batch 140, tr_loss is    0.27.\n",
      "142/200 [====================>.........] - ETA: 50s - loss: 0.2687 - iou_score: 0.7068 - f1-score: 0.8263For batch 141, tr_loss is    0.27.\n",
      "143/200 [====================>.........] - ETA: 50s - loss: 0.2686 - iou_score: 0.7068 - f1-score: 0.8264For batch 142, tr_loss is    0.27.\n",
      "144/200 [====================>.........] - ETA: 49s - loss: 0.2687 - iou_score: 0.7066 - f1-score: 0.8262For batch 143, tr_loss is    0.27.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/200 [====================>.........] - ETA: 48s - loss: 0.2687 - iou_score: 0.7064 - f1-score: 0.8261For batch 144, tr_loss is    0.27.\n",
      "146/200 [====================>.........] - ETA: 47s - loss: 0.2684 - iou_score: 0.7070 - f1-score: 0.8265For batch 145, tr_loss is    0.27.\n",
      "147/200 [=====================>........] - ETA: 46s - loss: 0.2686 - iou_score: 0.7067 - f1-score: 0.8262For batch 146, tr_loss is    0.27.\n",
      "148/200 [=====================>........] - ETA: 45s - loss: 0.2682 - iou_score: 0.7073 - f1-score: 0.8266For batch 147, tr_loss is    0.27.\n",
      "149/200 [=====================>........] - ETA: 44s - loss: 0.2679 - iou_score: 0.7076 - f1-score: 0.8268For batch 148, tr_loss is    0.27.\n",
      "150/200 [=====================>........] - ETA: 43s - loss: 0.2675 - iou_score: 0.7082 - f1-score: 0.8272For batch 149, tr_loss is    0.27.\n",
      "151/200 [=====================>........] - ETA: 43s - loss: 0.2678 - iou_score: 0.7079 - f1-score: 0.8270For batch 150, tr_loss is    0.27.\n",
      "152/200 [=====================>........] - ETA: 42s - loss: 0.2678 - iou_score: 0.7080 - f1-score: 0.8271For batch 151, tr_loss is    0.27.\n",
      "153/200 [=====================>........] - ETA: 41s - loss: 0.2676 - iou_score: 0.7082 - f1-score: 0.8273For batch 152, tr_loss is    0.27.\n",
      "154/200 [======================>.......] - ETA: 40s - loss: 0.2675 - iou_score: 0.7083 - f1-score: 0.8273For batch 153, tr_loss is    0.27.\n",
      "155/200 [======================>.......] - ETA: 39s - loss: 0.2673 - iou_score: 0.7085 - f1-score: 0.8275For batch 154, tr_loss is    0.27.\n",
      "156/200 [======================>.......] - ETA: 38s - loss: 0.2671 - iou_score: 0.7087 - f1-score: 0.8276For batch 155, tr_loss is    0.27.\n",
      "157/200 [======================>.......] - ETA: 37s - loss: 0.2671 - iou_score: 0.7087 - f1-score: 0.8276For batch 156, tr_loss is    0.27.\n",
      "158/200 [======================>.......] - ETA: 36s - loss: 0.2671 - iou_score: 0.7086 - f1-score: 0.8276For batch 157, tr_loss is    0.27.\n",
      "159/200 [======================>.......] - ETA: 36s - loss: 0.2673 - iou_score: 0.7084 - f1-score: 0.8274For batch 158, tr_loss is    0.27.\n",
      "160/200 [=======================>......] - ETA: 35s - loss: 0.2673 - iou_score: 0.7084 - f1-score: 0.8274For batch 159, tr_loss is    0.27.\n",
      "161/200 [=======================>......] - ETA: 34s - loss: 0.2673 - iou_score: 0.7083 - f1-score: 0.8274For batch 160, tr_loss is    0.27.\n",
      "162/200 [=======================>......] - ETA: 33s - loss: 0.2674 - iou_score: 0.7080 - f1-score: 0.8272For batch 161, tr_loss is    0.27.\n",
      "163/200 [=======================>......] - ETA: 32s - loss: 0.2669 - iou_score: 0.7086 - f1-score: 0.8276For batch 162, tr_loss is    0.27.\n",
      "164/200 [=======================>......] - ETA: 31s - loss: 0.2668 - iou_score: 0.7088 - f1-score: 0.8277For batch 163, tr_loss is    0.27.\n",
      "165/200 [=======================>......] - ETA: 30s - loss: 0.2666 - iou_score: 0.7091 - f1-score: 0.8279For batch 164, tr_loss is    0.27.\n",
      "166/200 [=======================>......] - ETA: 29s - loss: 0.2666 - iou_score: 0.7091 - f1-score: 0.8279For batch 165, tr_loss is    0.27.\n",
      "167/200 [========================>.....] - ETA: 28s - loss: 0.2661 - iou_score: 0.7097 - f1-score: 0.8283For batch 166, tr_loss is    0.27.\n",
      "168/200 [========================>.....] - ETA: 28s - loss: 0.2662 - iou_score: 0.7096 - f1-score: 0.8282For batch 167, tr_loss is    0.27.\n",
      "169/200 [========================>.....] - ETA: 27s - loss: 0.2663 - iou_score: 0.7094 - f1-score: 0.8281For batch 168, tr_loss is    0.27.\n",
      "170/200 [========================>.....] - ETA: 26s - loss: 0.2659 - iou_score: 0.7098 - f1-score: 0.8284For batch 169, tr_loss is    0.27.\n",
      "171/200 [========================>.....] - ETA: 25s - loss: 0.2660 - iou_score: 0.7097 - f1-score: 0.8283For batch 170, tr_loss is    0.27.\n",
      "172/200 [========================>.....] - ETA: 24s - loss: 0.2657 - iou_score: 0.7099 - f1-score: 0.8285For batch 171, tr_loss is    0.27.\n",
      "173/200 [========================>.....] - ETA: 23s - loss: 0.2657 - iou_score: 0.7101 - f1-score: 0.8286For batch 172, tr_loss is    0.27.\n",
      "174/200 [=========================>....] - ETA: 22s - loss: 0.2655 - iou_score: 0.7103 - f1-score: 0.8287For batch 173, tr_loss is    0.27.\n",
      "175/200 [=========================>....] - ETA: 21s - loss: 0.2652 - iou_score: 0.7107 - f1-score: 0.8290For batch 174, tr_loss is    0.27.\n",
      "176/200 [=========================>....] - ETA: 20s - loss: 0.2652 - iou_score: 0.7106 - f1-score: 0.8290For batch 175, tr_loss is    0.27.\n",
      "177/200 [=========================>....] - ETA: 20s - loss: 0.2650 - iou_score: 0.7109 - f1-score: 0.8291For batch 176, tr_loss is    0.26.\n",
      "178/200 [=========================>....] - ETA: 19s - loss: 0.2651 - iou_score: 0.7105 - f1-score: 0.8289For batch 177, tr_loss is    0.27.\n",
      "179/200 [=========================>....] - ETA: 18s - loss: 0.2649 - iou_score: 0.7107 - f1-score: 0.8290For batch 178, tr_loss is    0.26.\n",
      "180/200 [==========================>...] - ETA: 17s - loss: 0.2650 - iou_score: 0.7105 - f1-score: 0.8289For batch 179, tr_loss is    0.27.\n",
      "181/200 [==========================>...] - ETA: 16s - loss: 0.2653 - iou_score: 0.7102 - f1-score: 0.8287For batch 180, tr_loss is    0.27.\n",
      "182/200 [==========================>...] - ETA: 15s - loss: 0.2653 - iou_score: 0.7101 - f1-score: 0.8286For batch 181, tr_loss is    0.27.\n",
      "183/200 [==========================>...] - ETA: 14s - loss: 0.2655 - iou_score: 0.7098 - f1-score: 0.8284For batch 182, tr_loss is    0.27.\n",
      "184/200 [==========================>...] - ETA: 13s - loss: 0.2653 - iou_score: 0.7100 - f1-score: 0.8286For batch 183, tr_loss is    0.27.\n",
      "185/200 [==========================>...] - ETA: 13s - loss: 0.2652 - iou_score: 0.7102 - f1-score: 0.8287For batch 184, tr_loss is    0.27.\n",
      "186/200 [==========================>...] - ETA: 12s - loss: 0.2651 - iou_score: 0.7104 - f1-score: 0.8288For batch 185, tr_loss is    0.27.\n",
      "187/200 [===========================>..] - ETA: 11s - loss: 0.2648 - iou_score: 0.7108 - f1-score: 0.8291For batch 186, tr_loss is    0.26.\n",
      "188/200 [===========================>..] - ETA: 10s - loss: 0.2646 - iou_score: 0.7109 - f1-score: 0.8292For batch 187, tr_loss is    0.26.\n",
      "189/200 [===========================>..] - ETA: 9s - loss: 0.2650 - iou_score: 0.7106 - f1-score: 0.8289 For batch 188, tr_loss is    0.27.\n",
      "190/200 [===========================>..] - ETA: 8s - loss: 0.2650 - iou_score: 0.7105 - f1-score: 0.8289For batch 189, tr_loss is    0.26.\n",
      "191/200 [===========================>..] - ETA: 7s - loss: 0.2657 - iou_score: 0.7099 - f1-score: 0.8285For batch 190, tr_loss is    0.27.\n",
      "192/200 [===========================>..] - ETA: 6s - loss: 0.2661 - iou_score: 0.7094 - f1-score: 0.8281For batch 191, tr_loss is    0.27.\n",
      "193/200 [===========================>..] - ETA: 6s - loss: 0.2659 - iou_score: 0.7097 - f1-score: 0.8283For batch 192, tr_loss is    0.27.\n",
      "194/200 [============================>.] - ETA: 5s - loss: 0.2663 - iou_score: 0.7093 - f1-score: 0.8280For batch 193, tr_loss is    0.27.\n",
      "195/200 [============================>.] - ETA: 4s - loss: 0.2665 - iou_score: 0.7090 - f1-score: 0.8278For batch 194, tr_loss is    0.27.\n",
      "196/200 [============================>.] - ETA: 3s - loss: 0.2668 - iou_score: 0.7086 - f1-score: 0.8275For batch 195, tr_loss is    0.27.\n",
      "197/200 [============================>.] - ETA: 2s - loss: 0.2666 - iou_score: 0.7089 - f1-score: 0.8277For batch 196, tr_loss is    0.27.\n",
      "198/200 [============================>.] - ETA: 1s - loss: 0.2665 - iou_score: 0.7089 - f1-score: 0.8277For batch 197, tr_loss is    0.27.\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.2668 - iou_score: 0.7086 - f1-score: 0.8275For batch 198, tr_loss is    0.27.\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.2668 - iou_score: 0.7086 - f1-score: 0.8275For batch 199, tr_loss is    0.27.\n",
      "For batch 0, vl_loss is    0.38.\n",
      "For batch 1, vl_loss is    0.40.\n",
      "For batch 2, vl_loss is    0.40.\n",
      "For batch 3, vl_loss is    0.40.\n",
      "For batch 4, vl_loss is    0.39.\n",
      "For batch 5, vl_loss is    0.39.\n",
      "For batch 6, vl_loss is    0.40.\n",
      "For batch 7, vl_loss is    0.40.\n",
      "For batch 8, vl_loss is    0.40.\n",
      "For batch 9, vl_loss is    0.40.\n",
      "For batch 10, vl_loss is    0.41.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 11, vl_loss is    0.40.\n",
      "For batch 12, vl_loss is    0.40.\n",
      "For batch 13, vl_loss is    0.40.\n",
      "For batch 14, vl_loss is    0.40.\n",
      "For batch 15, vl_loss is    0.39.\n",
      "For batch 16, vl_loss is    0.39.\n",
      "For batch 17, vl_loss is    0.39.\n",
      "For batch 18, vl_loss is    0.39.\n",
      "For batch 19, vl_loss is    0.39.\n",
      "For batch 20, vl_loss is    0.39.\n",
      "For batch 21, vl_loss is    0.39.\n",
      "For batch 22, vl_loss is    0.39.\n",
      "For batch 23, vl_loss is    0.39.\n",
      "For batch 24, vl_loss is    0.39.\n",
      "For batch 25, vl_loss is    0.40.\n",
      "For batch 26, vl_loss is    0.39.\n",
      "For batch 27, vl_loss is    0.39.\n",
      "For batch 28, vl_loss is    0.39.\n",
      "For batch 29, vl_loss is    0.39.\n",
      "For batch 30, vl_loss is    0.39.\n",
      "For batch 31, vl_loss is    0.39.\n",
      "For batch 32, vl_loss is    0.39.\n",
      "For batch 33, vl_loss is    0.39.\n",
      "For batch 34, vl_loss is    0.39.\n",
      "For batch 35, vl_loss is    0.39.\n",
      "For batch 36, vl_loss is    0.39.\n",
      "For batch 37, vl_loss is    0.39.\n",
      "For batch 38, vl_loss is    0.38.\n",
      "For batch 39, vl_loss is    0.39.\n",
      "For batch 40, vl_loss is    0.39.\n",
      "For batch 41, vl_loss is    0.39.\n",
      "For batch 42, vl_loss is    0.38.\n",
      "For batch 43, vl_loss is    0.38.\n",
      "For batch 44, vl_loss is    0.39.\n",
      "For batch 45, vl_loss is    0.39.\n",
      "For batch 46, vl_loss is    0.39.\n",
      "For batch 47, vl_loss is    0.39.\n",
      "For batch 48, vl_loss is    0.39.\n",
      "For batch 49, vl_loss is    0.39.\n",
      "For batch 50, vl_loss is    0.39.\n",
      "For batch 51, vl_loss is    0.39.\n",
      "For batch 52, vl_loss is    0.38.\n",
      "For batch 53, vl_loss is    0.38.\n",
      "For batch 54, vl_loss is    0.39.\n",
      "For batch 55, vl_loss is    0.39.\n",
      "For batch 56, vl_loss is    0.39.\n",
      "For batch 57, vl_loss is    0.38.\n",
      "For batch 58, vl_loss is    0.38.\n",
      "For batch 59, vl_loss is    0.39.\n",
      "For batch 60, vl_loss is    0.38.\n",
      "For batch 61, vl_loss is    0.38.\n",
      "For batch 62, vl_loss is    0.38.\n",
      "For batch 63, vl_loss is    0.38.\n",
      "For batch 64, vl_loss is    0.39.\n",
      "For batch 65, vl_loss is    0.39.\n",
      "For batch 66, vl_loss is    0.39.\n",
      "For batch 67, vl_loss is    0.39.\n",
      "For batch 68, vl_loss is    0.39.\n",
      "For batch 69, vl_loss is    0.39.\n",
      "For batch 70, vl_loss is    0.39.\n",
      "For batch 71, vl_loss is    0.39.\n",
      "For batch 72, vl_loss is    0.39.\n",
      "For batch 73, vl_loss is    0.39.\n",
      "For batch 74, vl_loss is    0.39.\n",
      "For batch 75, vl_loss is    0.39.\n",
      "For batch 76, vl_loss is    0.39.\n",
      "For batch 77, vl_loss is    0.39.\n",
      "For batch 78, vl_loss is    0.39.\n",
      "For batch 79, vl_loss is    0.39.\n",
      "For batch 80, vl_loss is    0.39.\n",
      "For batch 81, vl_loss is    0.39.\n",
      "For batch 82, vl_loss is    0.39.\n",
      "For batch 83, vl_loss is    0.39.\n",
      "For batch 84, vl_loss is    0.39.\n",
      "For batch 85, vl_loss is    0.39.\n",
      "For batch 86, vl_loss is    0.39.\n",
      "For batch 87, vl_loss is    0.39.\n",
      "For batch 88, vl_loss is    0.39.\n",
      "For batch 89, vl_loss is    0.39.\n",
      "For batch 90, vl_loss is    0.39.\n",
      "For batch 91, vl_loss is    0.39.\n",
      "For batch 92, vl_loss is    0.39.\n",
      "For batch 93, vl_loss is    0.39.\n",
      "For batch 94, vl_loss is    0.39.\n",
      "For batch 95, vl_loss is    0.39.\n",
      "For batch 96, vl_loss is    0.39.\n",
      "For batch 97, vl_loss is    0.39.\n",
      "For batch 98, vl_loss is    0.39.\n",
      "For batch 99, vl_loss is    0.39.\n",
      "200/200 [==============================] - 179s 890ms/step - loss: 0.2668 - iou_score: 0.7086 - f1-score: 0.8275 - val_loss: 0.3880 - val_iou_score: 0.6049 - val_f1-score: 0.7501\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.32441\n",
      "The average loss for epoch 15 is    0.27 \n",
      "Epoch 17/200\n",
      "  1/200 [..............................] - ETA: 8:02 - loss: 0.2510 - iou_score: 0.7419 - f1-score: 0.8510For batch 0, tr_loss is    0.25.\n",
      "  2/200 [..............................] - ETA: 5:05 - loss: 0.2512 - iou_score: 0.7354 - f1-score: 0.8471For batch 1, tr_loss is    0.25.\n",
      "  3/200 [..............................] - ETA: 4:32 - loss: 0.2528 - iou_score: 0.7331 - f1-score: 0.8452For batch 2, tr_loss is    0.25.\n",
      "  4/200 [..............................] - ETA: 4:06 - loss: 0.2557 - iou_score: 0.7214 - f1-score: 0.8374For batch 3, tr_loss is    0.26.\n",
      "  5/200 [..............................] - ETA: 4:05 - loss: 0.2594 - iou_score: 0.7176 - f1-score: 0.8348For batch 4, tr_loss is    0.26.\n",
      "  6/200 [..............................] - ETA: 4:21 - loss: 0.2685 - iou_score: 0.7093 - f1-score: 0.8291For batch 5, tr_loss is    0.27.\n",
      "  7/200 [>.............................] - ETA: 4:13 - loss: 0.2778 - iou_score: 0.6978 - f1-score: 0.8205For batch 6, tr_loss is    0.28.\n",
      "  8/200 [>.............................] - ETA: 3:53 - loss: 0.2788 - iou_score: 0.6969 - f1-score: 0.8199For batch 7, tr_loss is    0.28.\n",
      "  9/200 [>.............................] - ETA: 3:49 - loss: 0.2761 - iou_score: 0.7014 - f1-score: 0.8230For batch 8, tr_loss is    0.28.\n",
      " 10/200 [>.............................] - ETA: 3:43 - loss: 0.2764 - iou_score: 0.6996 - f1-score: 0.8213For batch 9, tr_loss is    0.28.\n",
      " 11/200 [>.............................] - ETA: 3:30 - loss: 0.2739 - iou_score: 0.7007 - f1-score: 0.8222For batch 10, tr_loss is    0.27.\n",
      " 12/200 [>.............................] - ETA: 3:22 - loss: 0.2765 - iou_score: 0.6961 - f1-score: 0.8189For batch 11, tr_loss is    0.28.\n",
      " 13/200 [>.............................] - ETA: 3:15 - loss: 0.2779 - iou_score: 0.6931 - f1-score: 0.8168For batch 12, tr_loss is    0.28.\n",
      " 14/200 [=>............................] - ETA: 3:14 - loss: 0.2767 - iou_score: 0.6955 - f1-score: 0.8185For batch 13, tr_loss is    0.28.\n",
      " 15/200 [=>............................] - ETA: 3:05 - loss: 0.2740 - iou_score: 0.6987 - f1-score: 0.8208For batch 14, tr_loss is    0.27.\n",
      " 16/200 [=>............................] - ETA: 3:04 - loss: 0.2733 - iou_score: 0.6988 - f1-score: 0.8209For batch 15, tr_loss is    0.27.\n",
      " 17/200 [=>............................] - ETA: 2:57 - loss: 0.2706 - iou_score: 0.7025 - f1-score: 0.8235For batch 16, tr_loss is    0.27.\n",
      " 18/200 [=>............................] - ETA: 2:59 - loss: 0.2701 - iou_score: 0.7025 - f1-score: 0.8236For batch 17, tr_loss is    0.27.\n",
      " 19/200 [=>............................] - ETA: 2:56 - loss: 0.2717 - iou_score: 0.7005 - f1-score: 0.8220For batch 18, tr_loss is    0.27.\n",
      " 20/200 [==>...........................] - ETA: 2:56 - loss: 0.2691 - iou_score: 0.7052 - f1-score: 0.8252For batch 19, tr_loss is    0.27.\n",
      " 21/200 [==>...........................] - ETA: 2:53 - loss: 0.2667 - iou_score: 0.7086 - f1-score: 0.8275For batch 20, tr_loss is    0.27.\n",
      " 22/200 [==>...........................] - ETA: 2:52 - loss: 0.2649 - iou_score: 0.7111 - f1-score: 0.8292For batch 21, tr_loss is    0.26.\n",
      " 23/200 [==>...........................] - ETA: 2:51 - loss: 0.2641 - iou_score: 0.7120 - f1-score: 0.8299For batch 22, tr_loss is    0.26.\n",
      " 24/200 [==>...........................] - ETA: 2:50 - loss: 0.2630 - iou_score: 0.7131 - f1-score: 0.8307For batch 23, tr_loss is    0.26.\n",
      " 25/200 [==>...........................] - ETA: 2:50 - loss: 0.2620 - iou_score: 0.7143 - f1-score: 0.8316For batch 24, tr_loss is    0.26.\n",
      " 26/200 [==>...........................] - ETA: 2:47 - loss: 0.2639 - iou_score: 0.7132 - f1-score: 0.8309For batch 25, tr_loss is    0.26.\n",
      " 27/200 [===>..........................] - ETA: 2:47 - loss: 0.2637 - iou_score: 0.7137 - f1-score: 0.8312For batch 26, tr_loss is    0.26.\n",
      " 28/200 [===>..........................] - ETA: 2:46 - loss: 0.2632 - iou_score: 0.7137 - f1-score: 0.8313For batch 27, tr_loss is    0.26.\n",
      " 29/200 [===>..........................] - ETA: 2:45 - loss: 0.2644 - iou_score: 0.7120 - f1-score: 0.8301For batch 28, tr_loss is    0.26.\n",
      " 30/200 [===>..........................] - ETA: 2:43 - loss: 0.2623 - iou_score: 0.7148 - f1-score: 0.8320For batch 29, tr_loss is    0.26.\n",
      " 31/200 [===>..........................] - ETA: 2:42 - loss: 0.2602 - iou_score: 0.7175 - f1-score: 0.8338For batch 30, tr_loss is    0.26.\n",
      " 32/200 [===>..........................] - ETA: 2:40 - loss: 0.2589 - iou_score: 0.7192 - f1-score: 0.8350For batch 31, tr_loss is    0.26.\n",
      " 33/200 [===>..........................] - ETA: 2:37 - loss: 0.2573 - iou_score: 0.7206 - f1-score: 0.8360For batch 32, tr_loss is    0.26.\n",
      " 34/200 [====>.........................] - ETA: 2:36 - loss: 0.2580 - iou_score: 0.7196 - f1-score: 0.8353For batch 33, tr_loss is    0.26.\n",
      " 35/200 [====>.........................] - ETA: 2:36 - loss: 0.2578 - iou_score: 0.7199 - f1-score: 0.8355For batch 34, tr_loss is    0.26.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 36/200 [====>.........................] - ETA: 2:35 - loss: 0.2575 - iou_score: 0.7203 - f1-score: 0.8358For batch 35, tr_loss is    0.26.\n",
      " 37/200 [====>.........................] - ETA: 2:32 - loss: 0.2596 - iou_score: 0.7194 - f1-score: 0.8352For batch 36, tr_loss is    0.26.\n",
      " 38/200 [====>.........................] - ETA: 2:30 - loss: 0.2598 - iou_score: 0.7187 - f1-score: 0.8347For batch 37, tr_loss is    0.26.\n",
      " 39/200 [====>.........................] - ETA: 2:30 - loss: 0.2593 - iou_score: 0.7191 - f1-score: 0.8350For batch 38, tr_loss is    0.26.\n",
      " 40/200 [=====>........................] - ETA: 2:29 - loss: 0.2581 - iou_score: 0.7206 - f1-score: 0.8360For batch 39, tr_loss is    0.26.\n",
      " 41/200 [=====>........................] - ETA: 2:28 - loss: 0.2575 - iou_score: 0.7209 - f1-score: 0.8362For batch 40, tr_loss is    0.26.\n",
      " 42/200 [=====>........................] - ETA: 2:28 - loss: 0.2571 - iou_score: 0.7213 - f1-score: 0.8365For batch 41, tr_loss is    0.26.\n",
      " 43/200 [=====>........................] - ETA: 2:26 - loss: 0.2577 - iou_score: 0.7209 - f1-score: 0.8363For batch 42, tr_loss is    0.26.\n",
      " 44/200 [=====>........................] - ETA: 2:25 - loss: 0.2571 - iou_score: 0.7216 - f1-score: 0.8368For batch 43, tr_loss is    0.26.\n",
      " 45/200 [=====>........................] - ETA: 2:25 - loss: 0.2569 - iou_score: 0.7217 - f1-score: 0.8368For batch 44, tr_loss is    0.26.\n",
      " 46/200 [=====>........................] - ETA: 2:24 - loss: 0.2581 - iou_score: 0.7205 - f1-score: 0.8360For batch 45, tr_loss is    0.26.\n",
      " 47/200 [======>.......................] - ETA: 2:22 - loss: 0.2587 - iou_score: 0.7194 - f1-score: 0.8353For batch 46, tr_loss is    0.26.\n",
      " 48/200 [======>.......................] - ETA: 2:22 - loss: 0.2590 - iou_score: 0.7193 - f1-score: 0.8352For batch 47, tr_loss is    0.26.\n",
      " 49/200 [======>.......................] - ETA: 2:21 - loss: 0.2586 - iou_score: 0.7196 - f1-score: 0.8354For batch 48, tr_loss is    0.26.\n",
      " 50/200 [======>.......................] - ETA: 2:19 - loss: 0.2567 - iou_score: 0.7222 - f1-score: 0.8370For batch 49, tr_loss is    0.26.\n",
      " 51/200 [======>.......................] - ETA: 2:19 - loss: 0.2565 - iou_score: 0.7226 - f1-score: 0.8373For batch 50, tr_loss is    0.26.\n",
      " 52/200 [======>.......................] - ETA: 2:18 - loss: 0.2568 - iou_score: 0.7224 - f1-score: 0.8371For batch 51, tr_loss is    0.26.\n",
      " 53/200 [======>.......................] - ETA: 2:17 - loss: 0.2568 - iou_score: 0.7221 - f1-score: 0.8370For batch 52, tr_loss is    0.26.\n",
      " 54/200 [=======>......................] - ETA: 2:17 - loss: 0.2577 - iou_score: 0.7215 - f1-score: 0.8366For batch 53, tr_loss is    0.26.\n",
      " 55/200 [=======>......................] - ETA: 2:16 - loss: 0.2568 - iou_score: 0.7224 - f1-score: 0.8372For batch 54, tr_loss is    0.26.\n",
      " 56/200 [=======>......................] - ETA: 2:15 - loss: 0.2572 - iou_score: 0.7222 - f1-score: 0.8370For batch 55, tr_loss is    0.26.\n",
      " 57/200 [=======>......................] - ETA: 2:14 - loss: 0.2569 - iou_score: 0.7222 - f1-score: 0.8371For batch 56, tr_loss is    0.26.\n",
      " 58/200 [=======>......................] - ETA: 2:13 - loss: 0.2564 - iou_score: 0.7226 - f1-score: 0.8374For batch 57, tr_loss is    0.26.\n",
      " 59/200 [=======>......................] - ETA: 2:12 - loss: 0.2556 - iou_score: 0.7234 - f1-score: 0.8379For batch 58, tr_loss is    0.26.\n",
      " 60/200 [========>.....................] - ETA: 2:11 - loss: 0.2551 - iou_score: 0.7236 - f1-score: 0.8381For batch 59, tr_loss is    0.26.\n",
      " 61/200 [========>.....................] - ETA: 2:11 - loss: 0.2556 - iou_score: 0.7232 - f1-score: 0.8378For batch 60, tr_loss is    0.26.\n",
      " 62/200 [========>.....................] - ETA: 2:10 - loss: 0.2557 - iou_score: 0.7231 - f1-score: 0.8377For batch 61, tr_loss is    0.26.\n",
      " 63/200 [========>.....................] - ETA: 2:08 - loss: 0.2551 - iou_score: 0.7237 - f1-score: 0.8382For batch 62, tr_loss is    0.26.\n",
      " 64/200 [========>.....................] - ETA: 2:07 - loss: 0.2560 - iou_score: 0.7226 - f1-score: 0.8374For batch 63, tr_loss is    0.26.\n",
      " 65/200 [========>.....................] - ETA: 2:05 - loss: 0.2552 - iou_score: 0.7236 - f1-score: 0.8381For batch 64, tr_loss is    0.26.\n",
      " 66/200 [========>.....................] - ETA: 2:04 - loss: 0.2563 - iou_score: 0.7221 - f1-score: 0.8370For batch 65, tr_loss is    0.26.\n",
      " 67/200 [=========>....................] - ETA: 2:02 - loss: 0.2558 - iou_score: 0.7226 - f1-score: 0.8374For batch 66, tr_loss is    0.26.\n",
      " 68/200 [=========>....................] - ETA: 2:02 - loss: 0.2554 - iou_score: 0.7230 - f1-score: 0.8377For batch 67, tr_loss is    0.26.\n",
      " 69/200 [=========>....................] - ETA: 2:01 - loss: 0.2563 - iou_score: 0.7216 - f1-score: 0.8367For batch 68, tr_loss is    0.26.\n",
      " 70/200 [=========>....................] - ETA: 2:00 - loss: 0.2559 - iou_score: 0.7221 - f1-score: 0.8370For batch 69, tr_loss is    0.26.\n",
      " 71/200 [=========>....................] - ETA: 1:59 - loss: 0.2553 - iou_score: 0.7227 - f1-score: 0.8374For batch 70, tr_loss is    0.26.\n",
      " 72/200 [=========>....................] - ETA: 1:59 - loss: 0.2550 - iou_score: 0.7226 - f1-score: 0.8374For batch 71, tr_loss is    0.25.\n",
      " 73/200 [=========>....................] - ETA: 1:58 - loss: 0.2545 - iou_score: 0.7230 - f1-score: 0.8376For batch 72, tr_loss is    0.25.\n",
      " 74/200 [==========>...................] - ETA: 1:57 - loss: 0.2546 - iou_score: 0.7229 - f1-score: 0.8376For batch 73, tr_loss is    0.25.\n",
      " 75/200 [==========>...................] - ETA: 1:56 - loss: 0.2557 - iou_score: 0.7220 - f1-score: 0.8369For batch 74, tr_loss is    0.26.\n",
      " 76/200 [==========>...................] - ETA: 1:56 - loss: 0.2561 - iou_score: 0.7214 - f1-score: 0.8365For batch 75, tr_loss is    0.26.\n",
      " 77/200 [==========>...................] - ETA: 1:55 - loss: 0.2559 - iou_score: 0.7216 - f1-score: 0.8367For batch 76, tr_loss is    0.26.\n",
      " 78/200 [==========>...................] - ETA: 1:53 - loss: 0.2555 - iou_score: 0.7220 - f1-score: 0.8370For batch 77, tr_loss is    0.26.\n",
      " 79/200 [==========>...................] - ETA: 1:53 - loss: 0.2560 - iou_score: 0.7216 - f1-score: 0.8367For batch 78, tr_loss is    0.26.\n",
      " 80/200 [===========>..................] - ETA: 1:51 - loss: 0.2555 - iou_score: 0.7220 - f1-score: 0.8370For batch 79, tr_loss is    0.26.\n",
      " 81/200 [===========>..................] - ETA: 1:50 - loss: 0.2548 - iou_score: 0.7229 - f1-score: 0.8376For batch 80, tr_loss is    0.25.\n",
      " 82/200 [===========>..................] - ETA: 1:49 - loss: 0.2544 - iou_score: 0.7234 - f1-score: 0.8380For batch 81, tr_loss is    0.25.\n",
      " 83/200 [===========>..................] - ETA: 1:47 - loss: 0.2546 - iou_score: 0.7230 - f1-score: 0.8377For batch 82, tr_loss is    0.25.\n",
      " 84/200 [===========>..................] - ETA: 1:47 - loss: 0.2543 - iou_score: 0.7232 - f1-score: 0.8378For batch 83, tr_loss is    0.25.\n",
      " 85/200 [===========>..................] - ETA: 1:46 - loss: 0.2550 - iou_score: 0.7222 - f1-score: 0.8372For batch 84, tr_loss is    0.26.\n",
      " 86/200 [===========>..................] - ETA: 1:45 - loss: 0.2555 - iou_score: 0.7216 - f1-score: 0.8367For batch 85, tr_loss is    0.26.\n",
      " 87/200 [============>.................] - ETA: 1:44 - loss: 0.2552 - iou_score: 0.7219 - f1-score: 0.8370For batch 86, tr_loss is    0.26.\n",
      " 88/200 [============>.................] - ETA: 1:44 - loss: 0.2552 - iou_score: 0.7219 - f1-score: 0.8370For batch 87, tr_loss is    0.26.\n",
      " 89/200 [============>.................] - ETA: 1:42 - loss: 0.2558 - iou_score: 0.7212 - f1-score: 0.8365For batch 88, tr_loss is    0.26.\n",
      " 90/200 [============>.................] - ETA: 1:41 - loss: 0.2560 - iou_score: 0.7209 - f1-score: 0.8363For batch 89, tr_loss is    0.26.\n",
      " 91/200 [============>.................] - ETA: 1:40 - loss: 0.2558 - iou_score: 0.7209 - f1-score: 0.8363For batch 90, tr_loss is    0.26.\n",
      " 92/200 [============>.................] - ETA: 1:39 - loss: 0.2566 - iou_score: 0.7202 - f1-score: 0.8358For batch 91, tr_loss is    0.26.\n",
      " 93/200 [============>.................] - ETA: 1:38 - loss: 0.2565 - iou_score: 0.7203 - f1-score: 0.8359For batch 92, tr_loss is    0.26.\n",
      " 94/200 [=============>................] - ETA: 1:37 - loss: 0.2573 - iou_score: 0.7191 - f1-score: 0.8350For batch 93, tr_loss is    0.26.\n",
      " 95/200 [=============>................] - ETA: 1:36 - loss: 0.2575 - iou_score: 0.7190 - f1-score: 0.8350For batch 94, tr_loss is    0.26.\n",
      " 96/200 [=============>................] - ETA: 1:35 - loss: 0.2573 - iou_score: 0.7192 - f1-score: 0.8351For batch 95, tr_loss is    0.26.\n",
      " 97/200 [=============>................] - ETA: 1:34 - loss: 0.2576 - iou_score: 0.7187 - f1-score: 0.8348For batch 96, tr_loss is    0.26.\n",
      " 98/200 [=============>................] - ETA: 1:33 - loss: 0.2582 - iou_score: 0.7181 - f1-score: 0.8344For batch 97, tr_loss is    0.26.\n",
      " 99/200 [=============>................] - ETA: 1:32 - loss: 0.2578 - iou_score: 0.7187 - f1-score: 0.8348For batch 98, tr_loss is    0.26.\n",
      "100/200 [==============>...............] - ETA: 1:31 - loss: 0.2580 - iou_score: 0.7185 - f1-score: 0.8346For batch 99, tr_loss is    0.26.\n",
      "101/200 [==============>...............] - ETA: 1:30 - loss: 0.2579 - iou_score: 0.7184 - f1-score: 0.8346For batch 100, tr_loss is    0.26.\n",
      "102/200 [==============>...............] - ETA: 1:30 - loss: 0.2580 - iou_score: 0.7183 - f1-score: 0.8345For batch 101, tr_loss is    0.26.\n",
      "103/200 [==============>...............] - ETA: 1:28 - loss: 0.2582 - iou_score: 0.7180 - f1-score: 0.8343For batch 102, tr_loss is    0.26.\n",
      "104/200 [==============>...............] - ETA: 1:27 - loss: 0.2584 - iou_score: 0.7174 - f1-score: 0.8340For batch 103, tr_loss is    0.26.\n",
      "105/200 [==============>...............] - ETA: 1:26 - loss: 0.2587 - iou_score: 0.7171 - f1-score: 0.8337For batch 104, tr_loss is    0.26.\n",
      "106/200 [==============>...............] - ETA: 1:25 - loss: 0.2591 - iou_score: 0.7167 - f1-score: 0.8334For batch 105, tr_loss is    0.26.\n",
      "107/200 [===============>..............] - ETA: 1:25 - loss: 0.2594 - iou_score: 0.7163 - f1-score: 0.8332For batch 106, tr_loss is    0.26.\n",
      "108/200 [===============>..............] - ETA: 1:24 - loss: 0.2592 - iou_score: 0.7166 - f1-score: 0.8334For batch 107, tr_loss is    0.26.\n",
      "109/200 [===============>..............] - ETA: 1:22 - loss: 0.2595 - iou_score: 0.7166 - f1-score: 0.8333For batch 108, tr_loss is    0.26.\n",
      "110/200 [===============>..............] - ETA: 1:22 - loss: 0.2592 - iou_score: 0.7170 - f1-score: 0.8336For batch 109, tr_loss is    0.26.\n",
      "111/200 [===============>..............] - ETA: 1:20 - loss: 0.2587 - iou_score: 0.7175 - f1-score: 0.8340For batch 110, tr_loss is    0.26.\n",
      "112/200 [===============>..............] - ETA: 1:19 - loss: 0.2586 - iou_score: 0.7175 - f1-score: 0.8339For batch 111, tr_loss is    0.26.\n",
      "113/200 [===============>..............] - ETA: 1:18 - loss: 0.2592 - iou_score: 0.7164 - f1-score: 0.8332For batch 112, tr_loss is    0.26.\n",
      "114/200 [================>.............] - ETA: 1:17 - loss: 0.2599 - iou_score: 0.7157 - f1-score: 0.8326For batch 113, tr_loss is    0.26.\n",
      "115/200 [================>.............] - ETA: 1:17 - loss: 0.2600 - iou_score: 0.7156 - f1-score: 0.8326For batch 114, tr_loss is    0.26.\n",
      "116/200 [================>.............] - ETA: 1:16 - loss: 0.2604 - iou_score: 0.7151 - f1-score: 0.8322For batch 115, tr_loss is    0.26.\n",
      "117/200 [================>.............] - ETA: 1:14 - loss: 0.2605 - iou_score: 0.7150 - f1-score: 0.8321For batch 116, tr_loss is    0.26.\n",
      "118/200 [================>.............] - ETA: 1:14 - loss: 0.2605 - iou_score: 0.7150 - f1-score: 0.8321For batch 117, tr_loss is    0.26.\n",
      "119/200 [================>.............] - ETA: 1:12 - loss: 0.2606 - iou_score: 0.7147 - f1-score: 0.8320For batch 118, tr_loss is    0.26.\n",
      "120/200 [=================>............] - ETA: 1:12 - loss: 0.2603 - iou_score: 0.7152 - f1-score: 0.8323For batch 119, tr_loss is    0.26.\n",
      "121/200 [=================>............] - ETA: 1:11 - loss: 0.2599 - iou_score: 0.7158 - f1-score: 0.8327For batch 120, tr_loss is    0.26.\n",
      "122/200 [=================>............] - ETA: 1:10 - loss: 0.2598 - iou_score: 0.7158 - f1-score: 0.8327For batch 121, tr_loss is    0.26.\n",
      "123/200 [=================>............] - ETA: 1:09 - loss: 0.2606 - iou_score: 0.7149 - f1-score: 0.8321For batch 122, tr_loss is    0.26.\n",
      "124/200 [=================>............] - ETA: 1:08 - loss: 0.2608 - iou_score: 0.7145 - f1-score: 0.8318For batch 123, tr_loss is    0.26.\n",
      "125/200 [=================>............] - ETA: 1:07 - loss: 0.2609 - iou_score: 0.7143 - f1-score: 0.8317For batch 124, tr_loss is    0.26.\n",
      "126/200 [=================>............] - ETA: 1:06 - loss: 0.2608 - iou_score: 0.7145 - f1-score: 0.8318For batch 125, tr_loss is    0.26.\n",
      "127/200 [==================>...........] - ETA: 1:05 - loss: 0.2608 - iou_score: 0.7145 - f1-score: 0.8319For batch 126, tr_loss is    0.26.\n",
      "128/200 [==================>...........] - ETA: 1:04 - loss: 0.2615 - iou_score: 0.7137 - f1-score: 0.8313For batch 127, tr_loss is    0.26.\n",
      "129/200 [==================>...........] - ETA: 1:03 - loss: 0.2615 - iou_score: 0.7136 - f1-score: 0.8312For batch 128, tr_loss is    0.26.\n",
      "130/200 [==================>...........] - ETA: 1:02 - loss: 0.2614 - iou_score: 0.7137 - f1-score: 0.8313For batch 129, tr_loss is    0.26.\n",
      "131/200 [==================>...........] - ETA: 1:01 - loss: 0.2610 - iou_score: 0.7142 - f1-score: 0.8316For batch 130, tr_loss is    0.26.\n",
      "132/200 [==================>...........] - ETA: 1:00 - loss: 0.2608 - iou_score: 0.7144 - f1-score: 0.8318For batch 131, tr_loss is    0.26.\n",
      "133/200 [==================>...........] - ETA: 59s - loss: 0.2608 - iou_score: 0.7142 - f1-score: 0.8317 For batch 132, tr_loss is    0.26.\n",
      "134/200 [===================>..........] - ETA: 58s - loss: 0.2616 - iou_score: 0.7136 - f1-score: 0.8312For batch 133, tr_loss is    0.26.\n",
      "135/200 [===================>..........] - ETA: 58s - loss: 0.2619 - iou_score: 0.7133 - f1-score: 0.8310For batch 134, tr_loss is    0.26.\n",
      "136/200 [===================>..........] - ETA: 57s - loss: 0.2617 - iou_score: 0.7135 - f1-score: 0.8311For batch 135, tr_loss is    0.26.\n",
      "137/200 [===================>..........] - ETA: 56s - loss: 0.2622 - iou_score: 0.7128 - f1-score: 0.8306For batch 136, tr_loss is    0.26.\n",
      "138/200 [===================>..........] - ETA: 55s - loss: 0.2625 - iou_score: 0.7123 - f1-score: 0.8303For batch 137, tr_loss is    0.26.\n",
      "139/200 [===================>..........] - ETA: 54s - loss: 0.2623 - iou_score: 0.7125 - f1-score: 0.8304For batch 138, tr_loss is    0.26.\n",
      "140/200 [====================>.........] - ETA: 53s - loss: 0.2636 - iou_score: 0.7114 - f1-score: 0.8296For batch 139, tr_loss is    0.26.\n",
      "141/200 [====================>.........] - ETA: 52s - loss: 0.2642 - iou_score: 0.7106 - f1-score: 0.8290For batch 140, tr_loss is    0.26.\n",
      "142/200 [====================>.........] - ETA: 51s - loss: 0.2643 - iou_score: 0.7104 - f1-score: 0.8289For batch 141, tr_loss is    0.26.\n",
      "143/200 [====================>.........] - ETA: 50s - loss: 0.2642 - iou_score: 0.7106 - f1-score: 0.8290For batch 142, tr_loss is    0.26.\n",
      "144/200 [====================>.........] - ETA: 49s - loss: 0.2645 - iou_score: 0.7102 - f1-score: 0.8287For batch 143, tr_loss is    0.26.\n",
      "145/200 [====================>.........] - ETA: 48s - loss: 0.2646 - iou_score: 0.7100 - f1-score: 0.8286For batch 144, tr_loss is    0.26.\n",
      "146/200 [====================>.........] - ETA: 48s - loss: 0.2642 - iou_score: 0.7107 - f1-score: 0.8290For batch 145, tr_loss is    0.26.\n",
      "147/200 [=====================>........] - ETA: 47s - loss: 0.2645 - iou_score: 0.7103 - f1-score: 0.8288For batch 146, tr_loss is    0.26.\n",
      "148/200 [=====================>........] - ETA: 46s - loss: 0.2640 - iou_score: 0.7111 - f1-score: 0.8293For batch 147, tr_loss is    0.26.\n",
      "149/200 [=====================>........] - ETA: 45s - loss: 0.2637 - iou_score: 0.7114 - f1-score: 0.8295For batch 148, tr_loss is    0.26.\n",
      "150/200 [=====================>........] - ETA: 44s - loss: 0.2633 - iou_score: 0.7119 - f1-score: 0.8298For batch 149, tr_loss is    0.26.\n",
      "151/200 [=====================>........] - ETA: 43s - loss: 0.2633 - iou_score: 0.7119 - f1-score: 0.8298For batch 150, tr_loss is    0.26.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/200 [=====================>........] - ETA: 42s - loss: 0.2632 - iou_score: 0.7122 - f1-score: 0.8300For batch 151, tr_loss is    0.26.\n",
      "153/200 [=====================>........] - ETA: 41s - loss: 0.2629 - iou_score: 0.7124 - f1-score: 0.8302For batch 152, tr_loss is    0.26.\n",
      "154/200 [======================>.......] - ETA: 40s - loss: 0.2629 - iou_score: 0.7126 - f1-score: 0.8303For batch 153, tr_loss is    0.26.\n",
      "155/200 [======================>.......] - ETA: 39s - loss: 0.2627 - iou_score: 0.7127 - f1-score: 0.8304For batch 154, tr_loss is    0.26.\n",
      "156/200 [======================>.......] - ETA: 38s - loss: 0.2625 - iou_score: 0.7130 - f1-score: 0.8306For batch 155, tr_loss is    0.26.\n",
      "157/200 [======================>.......] - ETA: 37s - loss: 0.2624 - iou_score: 0.7131 - f1-score: 0.8306For batch 156, tr_loss is    0.26.\n",
      "158/200 [======================>.......] - ETA: 37s - loss: 0.2623 - iou_score: 0.7131 - f1-score: 0.8307For batch 157, tr_loss is    0.26.\n",
      "159/200 [======================>.......] - ETA: 36s - loss: 0.2625 - iou_score: 0.7128 - f1-score: 0.8305For batch 158, tr_loss is    0.26.\n",
      "160/200 [=======================>......] - ETA: 35s - loss: 0.2624 - iou_score: 0.7128 - f1-score: 0.8305For batch 159, tr_loss is    0.26.\n",
      "161/200 [=======================>......] - ETA: 34s - loss: 0.2626 - iou_score: 0.7127 - f1-score: 0.8304For batch 160, tr_loss is    0.26.\n",
      "162/200 [=======================>......] - ETA: 33s - loss: 0.2624 - iou_score: 0.7127 - f1-score: 0.8304For batch 161, tr_loss is    0.26.\n",
      "163/200 [=======================>......] - ETA: 32s - loss: 0.2620 - iou_score: 0.7132 - f1-score: 0.8307For batch 162, tr_loss is    0.26.\n",
      "164/200 [=======================>......] - ETA: 31s - loss: 0.2619 - iou_score: 0.7133 - f1-score: 0.8308For batch 163, tr_loss is    0.26.\n",
      "165/200 [=======================>......] - ETA: 31s - loss: 0.2617 - iou_score: 0.7136 - f1-score: 0.8310For batch 164, tr_loss is    0.26.\n",
      "166/200 [=======================>......] - ETA: 30s - loss: 0.2616 - iou_score: 0.7135 - f1-score: 0.8310For batch 165, tr_loss is    0.26.\n",
      "167/200 [========================>.....] - ETA: 29s - loss: 0.2610 - iou_score: 0.7142 - f1-score: 0.8315For batch 166, tr_loss is    0.26.\n",
      "168/200 [========================>.....] - ETA: 28s - loss: 0.2613 - iou_score: 0.7141 - f1-score: 0.8313For batch 167, tr_loss is    0.26.\n",
      "169/200 [========================>.....] - ETA: 27s - loss: 0.2614 - iou_score: 0.7138 - f1-score: 0.8312For batch 168, tr_loss is    0.26.\n",
      "170/200 [========================>.....] - ETA: 26s - loss: 0.2611 - iou_score: 0.7142 - f1-score: 0.8314For batch 169, tr_loss is    0.26.\n",
      "171/200 [========================>.....] - ETA: 25s - loss: 0.2612 - iou_score: 0.7140 - f1-score: 0.8313For batch 170, tr_loss is    0.26.\n",
      "172/200 [========================>.....] - ETA: 24s - loss: 0.2610 - iou_score: 0.7143 - f1-score: 0.8315For batch 171, tr_loss is    0.26.\n",
      "173/200 [========================>.....] - ETA: 23s - loss: 0.2609 - iou_score: 0.7145 - f1-score: 0.8316For batch 172, tr_loss is    0.26.\n",
      "174/200 [=========================>....] - ETA: 22s - loss: 0.2606 - iou_score: 0.7148 - f1-score: 0.8318For batch 173, tr_loss is    0.26.\n",
      "175/200 [=========================>....] - ETA: 22s - loss: 0.2602 - iou_score: 0.7152 - f1-score: 0.8321For batch 174, tr_loss is    0.26.\n",
      "176/200 [=========================>....] - ETA: 21s - loss: 0.2603 - iou_score: 0.7151 - f1-score: 0.8321For batch 175, tr_loss is    0.26.\n",
      "177/200 [=========================>....] - ETA: 20s - loss: 0.2600 - iou_score: 0.7154 - f1-score: 0.8323For batch 176, tr_loss is    0.26.\n",
      "178/200 [=========================>....] - ETA: 19s - loss: 0.2602 - iou_score: 0.7150 - f1-score: 0.8320For batch 177, tr_loss is    0.26.\n",
      "179/200 [=========================>....] - ETA: 18s - loss: 0.2600 - iou_score: 0.7152 - f1-score: 0.8321For batch 178, tr_loss is    0.26.\n",
      "180/200 [==========================>...] - ETA: 17s - loss: 0.2601 - iou_score: 0.7150 - f1-score: 0.8320For batch 179, tr_loss is    0.26.\n",
      "181/200 [==========================>...] - ETA: 16s - loss: 0.2603 - iou_score: 0.7147 - f1-score: 0.8318For batch 180, tr_loss is    0.26.\n",
      "182/200 [==========================>...] - ETA: 15s - loss: 0.2602 - iou_score: 0.7147 - f1-score: 0.8318For batch 181, tr_loss is    0.26.\n",
      "183/200 [==========================>...] - ETA: 15s - loss: 0.2602 - iou_score: 0.7145 - f1-score: 0.8317For batch 182, tr_loss is    0.26.\n",
      "184/200 [==========================>...] - ETA: 14s - loss: 0.2601 - iou_score: 0.7147 - f1-score: 0.8318For batch 183, tr_loss is    0.26.\n",
      "185/200 [==========================>...] - ETA: 13s - loss: 0.2602 - iou_score: 0.7147 - f1-score: 0.8318For batch 184, tr_loss is    0.26.\n",
      "186/200 [==========================>...] - ETA: 12s - loss: 0.2600 - iou_score: 0.7149 - f1-score: 0.8320For batch 185, tr_loss is    0.26.\n",
      "187/200 [===========================>..] - ETA: 11s - loss: 0.2597 - iou_score: 0.7152 - f1-score: 0.8322For batch 186, tr_loss is    0.26.\n",
      "188/200 [===========================>..] - ETA: 10s - loss: 0.2596 - iou_score: 0.7153 - f1-score: 0.8322For batch 187, tr_loss is    0.26.\n",
      "189/200 [===========================>..] - ETA: 9s - loss: 0.2600 - iou_score: 0.7149 - f1-score: 0.8319 For batch 188, tr_loss is    0.26.\n",
      "190/200 [===========================>..] - ETA: 8s - loss: 0.2599 - iou_score: 0.7150 - f1-score: 0.8320For batch 189, tr_loss is    0.26.\n",
      "191/200 [===========================>..] - ETA: 7s - loss: 0.2606 - iou_score: 0.7144 - f1-score: 0.8316For batch 190, tr_loss is    0.26.\n",
      "192/200 [===========================>..] - ETA: 7s - loss: 0.2610 - iou_score: 0.7140 - f1-score: 0.8313For batch 191, tr_loss is    0.26.\n",
      "193/200 [===========================>..] - ETA: 6s - loss: 0.2607 - iou_score: 0.7143 - f1-score: 0.8315For batch 192, tr_loss is    0.26.\n",
      "194/200 [============================>.] - ETA: 5s - loss: 0.2611 - iou_score: 0.7140 - f1-score: 0.8313For batch 193, tr_loss is    0.26.\n",
      "195/200 [============================>.] - ETA: 4s - loss: 0.2611 - iou_score: 0.7140 - f1-score: 0.8312For batch 194, tr_loss is    0.26.\n",
      "196/200 [============================>.] - ETA: 3s - loss: 0.2613 - iou_score: 0.7137 - f1-score: 0.8311For batch 195, tr_loss is    0.26.\n",
      "197/200 [============================>.] - ETA: 2s - loss: 0.2610 - iou_score: 0.7140 - f1-score: 0.8313For batch 196, tr_loss is    0.26.\n",
      "198/200 [============================>.] - ETA: 1s - loss: 0.2610 - iou_score: 0.7141 - f1-score: 0.8313For batch 197, tr_loss is    0.26.\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.2612 - iou_score: 0.7138 - f1-score: 0.8312For batch 198, tr_loss is    0.26.\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.2611 - iou_score: 0.7138 - f1-score: 0.8312For batch 199, tr_loss is    0.26.\n",
      "For batch 0, vl_loss is    0.38.\n",
      "For batch 1, vl_loss is    0.38.\n",
      "For batch 2, vl_loss is    0.37.\n",
      "For batch 3, vl_loss is    0.38.\n",
      "For batch 4, vl_loss is    0.37.\n",
      "For batch 5, vl_loss is    0.37.\n",
      "For batch 6, vl_loss is    0.39.\n",
      "For batch 7, vl_loss is    0.37.\n",
      "For batch 8, vl_loss is    0.38.\n",
      "For batch 9, vl_loss is    0.37.\n",
      "For batch 10, vl_loss is    0.37.\n",
      "For batch 11, vl_loss is    0.37.\n",
      "For batch 12, vl_loss is    0.36.\n",
      "For batch 13, vl_loss is    0.36.\n",
      "For batch 14, vl_loss is    0.36.\n",
      "For batch 15, vl_loss is    0.35.\n",
      "For batch 16, vl_loss is    0.35.\n",
      "For batch 17, vl_loss is    0.35.\n",
      "For batch 18, vl_loss is    0.35.\n",
      "For batch 19, vl_loss is    0.35.\n",
      "For batch 20, vl_loss is    0.35.\n",
      "For batch 21, vl_loss is    0.35.\n",
      "For batch 22, vl_loss is    0.35.\n",
      "For batch 23, vl_loss is    0.35.\n",
      "For batch 24, vl_loss is    0.35.\n",
      "For batch 25, vl_loss is    0.35.\n",
      "For batch 26, vl_loss is    0.35.\n",
      "For batch 27, vl_loss is    0.35.\n",
      "For batch 28, vl_loss is    0.35.\n",
      "For batch 29, vl_loss is    0.35.\n",
      "For batch 30, vl_loss is    0.35.\n",
      "For batch 31, vl_loss is    0.35.\n",
      "For batch 32, vl_loss is    0.35.\n",
      "For batch 33, vl_loss is    0.35.\n",
      "For batch 34, vl_loss is    0.35.\n",
      "For batch 35, vl_loss is    0.35.\n",
      "For batch 36, vl_loss is    0.35.\n",
      "For batch 37, vl_loss is    0.35.\n",
      "For batch 38, vl_loss is    0.34.\n",
      "For batch 39, vl_loss is    0.35.\n",
      "For batch 40, vl_loss is    0.35.\n",
      "For batch 41, vl_loss is    0.35.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 42, vl_loss is    0.35.\n",
      "For batch 43, vl_loss is    0.35.\n",
      "For batch 44, vl_loss is    0.35.\n",
      "For batch 45, vl_loss is    0.35.\n",
      "For batch 46, vl_loss is    0.35.\n",
      "For batch 47, vl_loss is    0.35.\n",
      "For batch 48, vl_loss is    0.35.\n",
      "For batch 49, vl_loss is    0.35.\n",
      "For batch 50, vl_loss is    0.35.\n",
      "For batch 51, vl_loss is    0.35.\n",
      "For batch 52, vl_loss is    0.35.\n",
      "For batch 53, vl_loss is    0.35.\n",
      "For batch 54, vl_loss is    0.35.\n",
      "For batch 55, vl_loss is    0.35.\n",
      "For batch 56, vl_loss is    0.35.\n",
      "For batch 57, vl_loss is    0.35.\n",
      "For batch 58, vl_loss is    0.35.\n",
      "For batch 59, vl_loss is    0.35.\n",
      "For batch 60, vl_loss is    0.35.\n",
      "For batch 61, vl_loss is    0.35.\n",
      "For batch 62, vl_loss is    0.35.\n",
      "For batch 63, vl_loss is    0.35.\n",
      "For batch 64, vl_loss is    0.35.\n",
      "For batch 65, vl_loss is    0.35.\n",
      "For batch 66, vl_loss is    0.35.\n",
      "For batch 67, vl_loss is    0.35.\n",
      "For batch 68, vl_loss is    0.35.\n",
      "For batch 69, vl_loss is    0.35.\n",
      "For batch 70, vl_loss is    0.35.\n",
      "For batch 71, vl_loss is    0.35.\n",
      "For batch 72, vl_loss is    0.35.\n",
      "For batch 73, vl_loss is    0.35.\n",
      "For batch 74, vl_loss is    0.35.\n",
      "For batch 75, vl_loss is    0.36.\n",
      "For batch 76, vl_loss is    0.35.\n",
      "For batch 77, vl_loss is    0.35.\n",
      "For batch 78, vl_loss is    0.36.\n",
      "For batch 79, vl_loss is    0.36.\n",
      "For batch 80, vl_loss is    0.35.\n",
      "For batch 81, vl_loss is    0.35.\n",
      "For batch 82, vl_loss is    0.35.\n",
      "For batch 83, vl_loss is    0.35.\n",
      "For batch 84, vl_loss is    0.35.\n",
      "For batch 85, vl_loss is    0.35.\n",
      "For batch 86, vl_loss is    0.35.\n",
      "For batch 87, vl_loss is    0.35.\n",
      "For batch 88, vl_loss is    0.35.\n",
      "For batch 89, vl_loss is    0.35.\n",
      "For batch 90, vl_loss is    0.35.\n",
      "For batch 91, vl_loss is    0.35.\n",
      "For batch 92, vl_loss is    0.35.\n",
      "For batch 93, vl_loss is    0.35.\n",
      "For batch 94, vl_loss is    0.35.\n",
      "For batch 95, vl_loss is    0.35.\n",
      "For batch 96, vl_loss is    0.35.\n",
      "For batch 97, vl_loss is    0.35.\n",
      "For batch 98, vl_loss is    0.35.\n",
      "For batch 99, vl_loss is    0.35.\n",
      "200/200 [==============================] - 183s 908ms/step - loss: 0.2611 - iou_score: 0.7138 - f1-score: 0.8312 - val_loss: 0.3543 - val_iou_score: 0.6608 - val_f1-score: 0.7930\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.32441\n",
      "The average loss for epoch 16 is    0.26 \n",
      "Epoch 18/200\n",
      "  1/200 [..............................] - ETA: 9:34 - loss: 0.2750 - iou_score: 0.7022 - f1-score: 0.8250For batch 0, tr_loss is    0.28.\n",
      "  2/200 [..............................] - ETA: 4:05 - loss: 0.2629 - iou_score: 0.7159 - f1-score: 0.8342For batch 1, tr_loss is    0.26.\n",
      "  3/200 [..............................] - ETA: 4:07 - loss: 0.2608 - iou_score: 0.7210 - f1-score: 0.8375For batch 2, tr_loss is    0.26.\n",
      "  4/200 [..............................] - ETA: 3:55 - loss: 0.2648 - iou_score: 0.7107 - f1-score: 0.8304For batch 3, tr_loss is    0.26.\n",
      "  5/200 [..............................] - ETA: 4:13 - loss: 0.2618 - iou_score: 0.7161 - f1-score: 0.8340For batch 4, tr_loss is    0.26.\n",
      "  6/200 [..............................] - ETA: 3:52 - loss: 0.2672 - iou_score: 0.7077 - f1-score: 0.8282For batch 5, tr_loss is    0.27.\n",
      "  7/200 [>.............................] - ETA: 3:45 - loss: 0.2750 - iou_score: 0.6971 - f1-score: 0.8202For batch 6, tr_loss is    0.27.\n",
      "  8/200 [>.............................] - ETA: 4:08 - loss: 0.2737 - iou_score: 0.6991 - f1-score: 0.8215For batch 7, tr_loss is    0.27.\n",
      "  9/200 [>.............................] - ETA: 4:10 - loss: 0.2709 - iou_score: 0.7042 - f1-score: 0.8249For batch 8, tr_loss is    0.27.\n",
      " 10/200 [>.............................] - ETA: 3:54 - loss: 0.2709 - iou_score: 0.7029 - f1-score: 0.8236For batch 9, tr_loss is    0.27.\n",
      " 11/200 [>.............................] - ETA: 3:41 - loss: 0.2672 - iou_score: 0.7057 - f1-score: 0.8256For batch 10, tr_loss is    0.27.\n",
      " 12/200 [>.............................] - ETA: 3:39 - loss: 0.2710 - iou_score: 0.7013 - f1-score: 0.8224For batch 11, tr_loss is    0.27.\n",
      " 13/200 [>.............................] - ETA: 3:36 - loss: 0.2722 - iou_score: 0.6982 - f1-score: 0.8203For batch 12, tr_loss is    0.27.\n",
      " 14/200 [=>............................] - ETA: 3:33 - loss: 0.2722 - iou_score: 0.6982 - f1-score: 0.8203For batch 13, tr_loss is    0.27.\n",
      " 15/200 [=>............................] - ETA: 3:28 - loss: 0.2689 - iou_score: 0.7014 - f1-score: 0.8226For batch 14, tr_loss is    0.27.\n",
      " 16/200 [=>............................] - ETA: 3:21 - loss: 0.2676 - iou_score: 0.7021 - f1-score: 0.8232For batch 15, tr_loss is    0.27.\n",
      " 17/200 [=>............................] - ETA: 3:20 - loss: 0.2649 - iou_score: 0.7058 - f1-score: 0.8257For batch 16, tr_loss is    0.26.\n",
      " 18/200 [=>............................] - ETA: 3:11 - loss: 0.2637 - iou_score: 0.7073 - f1-score: 0.8269For batch 17, tr_loss is    0.26.\n",
      " 19/200 [=>............................] - ETA: 3:11 - loss: 0.2649 - iou_score: 0.7057 - f1-score: 0.8256For batch 18, tr_loss is    0.26.\n",
      " 20/200 [==>...........................] - ETA: 3:10 - loss: 0.2621 - iou_score: 0.7106 - f1-score: 0.8289For batch 19, tr_loss is    0.26.\n",
      " 21/200 [==>...........................] - ETA: 3:08 - loss: 0.2608 - iou_score: 0.7128 - f1-score: 0.8304For batch 20, tr_loss is    0.26.\n",
      " 22/200 [==>...........................] - ETA: 3:02 - loss: 0.2593 - iou_score: 0.7148 - f1-score: 0.8318For batch 21, tr_loss is    0.26.\n",
      " 23/200 [==>...........................] - ETA: 3:02 - loss: 0.2585 - iou_score: 0.7161 - f1-score: 0.8328For batch 22, tr_loss is    0.26.\n",
      " 24/200 [==>...........................] - ETA: 3:01 - loss: 0.2575 - iou_score: 0.7171 - f1-score: 0.8335For batch 23, tr_loss is    0.26.\n",
      " 25/200 [==>...........................] - ETA: 3:00 - loss: 0.2574 - iou_score: 0.7176 - f1-score: 0.8339For batch 24, tr_loss is    0.26.\n",
      " 26/200 [==>...........................] - ETA: 2:54 - loss: 0.2592 - iou_score: 0.7164 - f1-score: 0.8332For batch 25, tr_loss is    0.26.\n",
      " 27/200 [===>..........................] - ETA: 2:52 - loss: 0.2588 - iou_score: 0.7170 - f1-score: 0.8335For batch 26, tr_loss is    0.26.\n",
      " 28/200 [===>..........................] - ETA: 2:52 - loss: 0.2594 - iou_score: 0.7164 - f1-score: 0.8331For batch 27, tr_loss is    0.26.\n",
      " 29/200 [===>..........................] - ETA: 2:48 - loss: 0.2598 - iou_score: 0.7152 - f1-score: 0.8324For batch 28, tr_loss is    0.26.\n",
      " 30/200 [===>..........................] - ETA: 2:45 - loss: 0.2578 - iou_score: 0.7178 - f1-score: 0.8341For batch 29, tr_loss is    0.26.\n",
      " 31/200 [===>..........................] - ETA: 2:44 - loss: 0.2561 - iou_score: 0.7200 - f1-score: 0.8356For batch 30, tr_loss is    0.26.\n",
      " 32/200 [===>..........................] - ETA: 2:44 - loss: 0.2544 - iou_score: 0.7223 - f1-score: 0.8371For batch 31, tr_loss is    0.25.\n",
      " 33/200 [===>..........................] - ETA: 2:43 - loss: 0.2532 - iou_score: 0.7240 - f1-score: 0.8383For batch 32, tr_loss is    0.25.\n",
      " 34/200 [====>.........................] - ETA: 2:39 - loss: 0.2540 - iou_score: 0.7231 - f1-score: 0.8377For batch 33, tr_loss is    0.25.\n",
      " 35/200 [====>.........................] - ETA: 2:38 - loss: 0.2540 - iou_score: 0.7236 - f1-score: 0.8380For batch 34, tr_loss is    0.25.\n",
      " 36/200 [====>.........................] - ETA: 2:37 - loss: 0.2540 - iou_score: 0.7235 - f1-score: 0.8380For batch 35, tr_loss is    0.25.\n",
      " 37/200 [====>.........................] - ETA: 2:34 - loss: 0.2570 - iou_score: 0.7217 - f1-score: 0.8367For batch 36, tr_loss is    0.26.\n",
      " 38/200 [====>.........................] - ETA: 2:34 - loss: 0.2574 - iou_score: 0.7205 - f1-score: 0.8360For batch 37, tr_loss is    0.26.\n",
      " 39/200 [====>.........................] - ETA: 2:31 - loss: 0.2565 - iou_score: 0.7213 - f1-score: 0.8365For batch 38, tr_loss is    0.26.\n",
      " 40/200 [=====>........................] - ETA: 2:30 - loss: 0.2560 - iou_score: 0.7219 - f1-score: 0.8369For batch 39, tr_loss is    0.26.\n",
      " 41/200 [=====>........................] - ETA: 2:28 - loss: 0.2557 - iou_score: 0.7223 - f1-score: 0.8372For batch 40, tr_loss is    0.26.\n",
      " 42/200 [=====>........................] - ETA: 2:28 - loss: 0.2558 - iou_score: 0.7219 - f1-score: 0.8369For batch 41, tr_loss is    0.26.\n",
      " 43/200 [=====>........................] - ETA: 2:27 - loss: 0.2555 - iou_score: 0.7226 - f1-score: 0.8374For batch 42, tr_loss is    0.26.\n",
      " 44/200 [=====>........................] - ETA: 2:26 - loss: 0.2551 - iou_score: 0.7229 - f1-score: 0.8376For batch 43, tr_loss is    0.26.\n",
      " 45/200 [=====>........................] - ETA: 2:25 - loss: 0.2546 - iou_score: 0.7233 - f1-score: 0.8379For batch 44, tr_loss is    0.25.\n",
      " 46/200 [=====>........................] - ETA: 2:25 - loss: 0.2555 - iou_score: 0.7221 - f1-score: 0.8370For batch 45, tr_loss is    0.26.\n",
      " 47/200 [======>.......................] - ETA: 2:24 - loss: 0.2564 - iou_score: 0.7207 - f1-score: 0.8361For batch 46, tr_loss is    0.26.\n",
      " 48/200 [======>.......................] - ETA: 2:22 - loss: 0.2571 - iou_score: 0.7201 - f1-score: 0.8357For batch 47, tr_loss is    0.26.\n",
      " 49/200 [======>.......................] - ETA: 2:20 - loss: 0.2563 - iou_score: 0.7208 - f1-score: 0.8362For batch 48, tr_loss is    0.26.\n",
      " 50/200 [======>.......................] - ETA: 2:19 - loss: 0.2544 - iou_score: 0.7234 - f1-score: 0.8378For batch 49, tr_loss is    0.25.\n",
      " 51/200 [======>.......................] - ETA: 2:19 - loss: 0.2541 - iou_score: 0.7243 - f1-score: 0.8384For batch 50, tr_loss is    0.25.\n",
      " 52/200 [======>.......................] - ETA: 2:18 - loss: 0.2540 - iou_score: 0.7241 - f1-score: 0.8383For batch 51, tr_loss is    0.25.\n",
      " 53/200 [======>.......................] - ETA: 2:16 - loss: 0.2541 - iou_score: 0.7240 - f1-score: 0.8382For batch 52, tr_loss is    0.25.\n",
      " 54/200 [=======>......................] - ETA: 2:15 - loss: 0.2548 - iou_score: 0.7232 - f1-score: 0.8377For batch 53, tr_loss is    0.25.\n",
      " 55/200 [=======>......................] - ETA: 2:13 - loss: 0.2538 - iou_score: 0.7242 - f1-score: 0.8384For batch 54, tr_loss is    0.25.\n",
      " 56/200 [=======>......................] - ETA: 2:12 - loss: 0.2541 - iou_score: 0.7238 - f1-score: 0.8381For batch 55, tr_loss is    0.25.\n",
      " 57/200 [=======>......................] - ETA: 2:11 - loss: 0.2538 - iou_score: 0.7241 - f1-score: 0.8383For batch 56, tr_loss is    0.25.\n",
      " 58/200 [=======>......................] - ETA: 2:10 - loss: 0.2533 - iou_score: 0.7246 - f1-score: 0.8387For batch 57, tr_loss is    0.25.\n",
      " 59/200 [=======>......................] - ETA: 2:08 - loss: 0.2528 - iou_score: 0.7252 - f1-score: 0.8391For batch 58, tr_loss is    0.25.\n",
      " 60/200 [========>.....................] - ETA: 2:07 - loss: 0.2524 - iou_score: 0.7255 - f1-score: 0.8394For batch 59, tr_loss is    0.25.\n",
      " 61/200 [========>.....................] - ETA: 2:06 - loss: 0.2528 - iou_score: 0.7252 - f1-score: 0.8392For batch 60, tr_loss is    0.25.\n",
      " 62/200 [========>.....................] - ETA: 2:05 - loss: 0.2527 - iou_score: 0.7250 - f1-score: 0.8390For batch 61, tr_loss is    0.25.\n",
      " 63/200 [========>.....................] - ETA: 2:04 - loss: 0.2521 - iou_score: 0.7257 - f1-score: 0.8396For batch 62, tr_loss is    0.25.\n",
      " 64/200 [========>.....................] - ETA: 2:04 - loss: 0.2528 - iou_score: 0.7249 - f1-score: 0.8390For batch 63, tr_loss is    0.25.\n",
      " 65/200 [========>.....................] - ETA: 2:03 - loss: 0.2520 - iou_score: 0.7258 - f1-score: 0.8396For batch 64, tr_loss is    0.25.\n",
      " 66/200 [========>.....................] - ETA: 2:02 - loss: 0.2535 - iou_score: 0.7243 - f1-score: 0.8385For batch 65, tr_loss is    0.25.\n",
      " 67/200 [=========>....................] - ETA: 2:01 - loss: 0.2531 - iou_score: 0.7245 - f1-score: 0.8387For batch 66, tr_loss is    0.25.\n",
      " 68/200 [=========>....................] - ETA: 2:00 - loss: 0.2527 - iou_score: 0.7252 - f1-score: 0.8391For batch 67, tr_loss is    0.25.\n",
      " 69/200 [=========>....................] - ETA: 1:58 - loss: 0.2534 - iou_score: 0.7240 - f1-score: 0.8383For batch 68, tr_loss is    0.25.\n",
      " 70/200 [=========>....................] - ETA: 1:57 - loss: 0.2529 - iou_score: 0.7245 - f1-score: 0.8386For batch 69, tr_loss is    0.25.\n",
      " 71/200 [=========>....................] - ETA: 1:57 - loss: 0.2526 - iou_score: 0.7249 - f1-score: 0.8389For batch 70, tr_loss is    0.25.\n",
      " 72/200 [=========>....................] - ETA: 1:56 - loss: 0.2526 - iou_score: 0.7247 - f1-score: 0.8388For batch 71, tr_loss is    0.25.\n",
      " 73/200 [=========>....................] - ETA: 1:55 - loss: 0.2521 - iou_score: 0.7252 - f1-score: 0.8391For batch 72, tr_loss is    0.25.\n",
      " 74/200 [==========>...................] - ETA: 1:54 - loss: 0.2521 - iou_score: 0.7252 - f1-score: 0.8392For batch 73, tr_loss is    0.25.\n",
      " 75/200 [==========>...................] - ETA: 1:52 - loss: 0.2533 - iou_score: 0.7242 - f1-score: 0.8384For batch 74, tr_loss is    0.25.\n",
      " 76/200 [==========>...................] - ETA: 1:51 - loss: 0.2537 - iou_score: 0.7236 - f1-score: 0.8380For batch 75, tr_loss is    0.25.\n",
      " 77/200 [==========>...................] - ETA: 1:50 - loss: 0.2536 - iou_score: 0.7236 - f1-score: 0.8381For batch 76, tr_loss is    0.25.\n",
      " 78/200 [==========>...................] - ETA: 1:50 - loss: 0.2531 - iou_score: 0.7243 - f1-score: 0.8385For batch 77, tr_loss is    0.25.\n",
      " 79/200 [==========>...................] - ETA: 1:49 - loss: 0.2534 - iou_score: 0.7242 - f1-score: 0.8385For batch 78, tr_loss is    0.25.\n",
      " 80/200 [===========>..................] - ETA: 1:48 - loss: 0.2530 - iou_score: 0.7246 - f1-score: 0.8388For batch 79, tr_loss is    0.25.\n",
      " 81/200 [===========>..................] - ETA: 1:48 - loss: 0.2522 - iou_score: 0.7257 - f1-score: 0.8395For batch 80, tr_loss is    0.25.\n",
      " 82/200 [===========>..................] - ETA: 1:46 - loss: 0.2520 - iou_score: 0.7257 - f1-score: 0.8395For batch 81, tr_loss is    0.25.\n",
      " 83/200 [===========>..................] - ETA: 1:46 - loss: 0.2527 - iou_score: 0.7252 - f1-score: 0.8392For batch 82, tr_loss is    0.25.\n",
      " 84/200 [===========>..................] - ETA: 1:44 - loss: 0.2526 - iou_score: 0.7252 - f1-score: 0.8391For batch 83, tr_loss is    0.25.\n",
      " 85/200 [===========>..................] - ETA: 1:44 - loss: 0.2532 - iou_score: 0.7241 - f1-score: 0.8384For batch 84, tr_loss is    0.25.\n",
      " 86/200 [===========>..................] - ETA: 1:43 - loss: 0.2534 - iou_score: 0.7235 - f1-score: 0.8380For batch 85, tr_loss is    0.25.\n",
      " 87/200 [============>.................] - ETA: 1:42 - loss: 0.2529 - iou_score: 0.7241 - f1-score: 0.8384For batch 86, tr_loss is    0.25.\n",
      " 88/200 [============>.................] - ETA: 1:41 - loss: 0.2526 - iou_score: 0.7246 - f1-score: 0.8387For batch 87, tr_loss is    0.25.\n",
      " 89/200 [============>.................] - ETA: 1:41 - loss: 0.2530 - iou_score: 0.7241 - f1-score: 0.8384For batch 88, tr_loss is    0.25.\n",
      " 90/200 [============>.................] - ETA: 1:40 - loss: 0.2535 - iou_score: 0.7236 - f1-score: 0.8380For batch 89, tr_loss is    0.25.\n",
      " 91/200 [============>.................] - ETA: 1:38 - loss: 0.2533 - iou_score: 0.7237 - f1-score: 0.8381For batch 90, tr_loss is    0.25.\n",
      " 92/200 [============>.................] - ETA: 1:38 - loss: 0.2540 - iou_score: 0.7231 - f1-score: 0.8377For batch 91, tr_loss is    0.25.\n",
      " 93/200 [============>.................] - ETA: 1:37 - loss: 0.2539 - iou_score: 0.7230 - f1-score: 0.8377For batch 92, tr_loss is    0.25.\n",
      " 94/200 [=============>................] - ETA: 1:36 - loss: 0.2555 - iou_score: 0.7212 - f1-score: 0.8364For batch 93, tr_loss is    0.26.\n",
      " 95/200 [=============>................] - ETA: 1:35 - loss: 0.2557 - iou_score: 0.7208 - f1-score: 0.8361For batch 94, tr_loss is    0.26.\n",
      " 96/200 [=============>................] - ETA: 1:34 - loss: 0.2553 - iou_score: 0.7214 - f1-score: 0.8365For batch 95, tr_loss is    0.26.\n",
      " 97/200 [=============>................] - ETA: 1:33 - loss: 0.2558 - iou_score: 0.7205 - f1-score: 0.8359For batch 96, tr_loss is    0.26.\n",
      " 98/200 [=============>................] - ETA: 1:33 - loss: 0.2568 - iou_score: 0.7197 - f1-score: 0.8353For batch 97, tr_loss is    0.26.\n",
      " 99/200 [=============>................] - ETA: 1:32 - loss: 0.2565 - iou_score: 0.7201 - f1-score: 0.8356For batch 98, tr_loss is    0.26.\n",
      "100/200 [==============>...............] - ETA: 1:30 - loss: 0.2571 - iou_score: 0.7193 - f1-score: 0.8350For batch 99, tr_loss is    0.26.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/200 [==============>...............] - ETA: 1:29 - loss: 0.2569 - iou_score: 0.7196 - f1-score: 0.8352For batch 100, tr_loss is    0.26.\n",
      "102/200 [==============>...............] - ETA: 1:28 - loss: 0.2575 - iou_score: 0.7192 - f1-score: 0.8350For batch 101, tr_loss is    0.26.\n",
      "103/200 [==============>...............] - ETA: 1:27 - loss: 0.2577 - iou_score: 0.7189 - f1-score: 0.8348For batch 102, tr_loss is    0.26.\n",
      "104/200 [==============>...............] - ETA: 1:26 - loss: 0.2579 - iou_score: 0.7184 - f1-score: 0.8345For batch 103, tr_loss is    0.26.\n",
      "105/200 [==============>...............] - ETA: 1:25 - loss: 0.2584 - iou_score: 0.7181 - f1-score: 0.8342For batch 104, tr_loss is    0.26.\n",
      "106/200 [==============>...............] - ETA: 1:24 - loss: 0.2585 - iou_score: 0.7177 - f1-score: 0.8340For batch 105, tr_loss is    0.26.\n",
      "107/200 [===============>..............] - ETA: 1:24 - loss: 0.2588 - iou_score: 0.7173 - f1-score: 0.8337For batch 106, tr_loss is    0.26.\n",
      "108/200 [===============>..............] - ETA: 1:23 - loss: 0.2586 - iou_score: 0.7177 - f1-score: 0.8339For batch 107, tr_loss is    0.26.\n",
      "109/200 [===============>..............] - ETA: 1:22 - loss: 0.2586 - iou_score: 0.7176 - f1-score: 0.8339For batch 108, tr_loss is    0.26.\n",
      "110/200 [===============>..............] - ETA: 1:21 - loss: 0.2584 - iou_score: 0.7180 - f1-score: 0.8342For batch 109, tr_loss is    0.26.\n",
      "111/200 [===============>..............] - ETA: 1:19 - loss: 0.2578 - iou_score: 0.7187 - f1-score: 0.8347For batch 110, tr_loss is    0.26.\n",
      "112/200 [===============>..............] - ETA: 1:18 - loss: 0.2577 - iou_score: 0.7189 - f1-score: 0.8348For batch 111, tr_loss is    0.26.\n",
      "113/200 [===============>..............] - ETA: 1:17 - loss: 0.2584 - iou_score: 0.7178 - f1-score: 0.8339For batch 112, tr_loss is    0.26.\n",
      "114/200 [================>.............] - ETA: 1:17 - loss: 0.2593 - iou_score: 0.7170 - f1-score: 0.8334For batch 113, tr_loss is    0.26.\n",
      "115/200 [================>.............] - ETA: 1:16 - loss: 0.2596 - iou_score: 0.7168 - f1-score: 0.8332For batch 114, tr_loss is    0.26.\n",
      "116/200 [================>.............] - ETA: 1:15 - loss: 0.2602 - iou_score: 0.7162 - f1-score: 0.8328For batch 115, tr_loss is    0.26.\n",
      "117/200 [================>.............] - ETA: 1:14 - loss: 0.2602 - iou_score: 0.7162 - f1-score: 0.8328For batch 116, tr_loss is    0.26.\n",
      "118/200 [================>.............] - ETA: 1:13 - loss: 0.2602 - iou_score: 0.7162 - f1-score: 0.8329For batch 117, tr_loss is    0.26.\n",
      "119/200 [================>.............] - ETA: 1:12 - loss: 0.2604 - iou_score: 0.7159 - f1-score: 0.8327For batch 118, tr_loss is    0.26.\n",
      "120/200 [=================>............] - ETA: 1:11 - loss: 0.2600 - iou_score: 0.7164 - f1-score: 0.8330For batch 119, tr_loss is    0.26.\n",
      "121/200 [=================>............] - ETA: 1:10 - loss: 0.2597 - iou_score: 0.7169 - f1-score: 0.8333For batch 120, tr_loss is    0.26.\n",
      "122/200 [=================>............] - ETA: 1:09 - loss: 0.2595 - iou_score: 0.7169 - f1-score: 0.8334For batch 121, tr_loss is    0.26.\n",
      "123/200 [=================>............] - ETA: 1:08 - loss: 0.2602 - iou_score: 0.7162 - f1-score: 0.8328For batch 122, tr_loss is    0.26.\n",
      "124/200 [=================>............] - ETA: 1:07 - loss: 0.2604 - iou_score: 0.7160 - f1-score: 0.8327For batch 123, tr_loss is    0.26.\n",
      "125/200 [=================>............] - ETA: 1:06 - loss: 0.2605 - iou_score: 0.7159 - f1-score: 0.8327For batch 124, tr_loss is    0.26.\n",
      "126/200 [=================>............] - ETA: 1:05 - loss: 0.2605 - iou_score: 0.7159 - f1-score: 0.8327For batch 125, tr_loss is    0.26.\n",
      "127/200 [==================>...........] - ETA: 1:05 - loss: 0.2604 - iou_score: 0.7159 - f1-score: 0.8326For batch 126, tr_loss is    0.26.\n",
      "128/200 [==================>...........] - ETA: 1:04 - loss: 0.2612 - iou_score: 0.7147 - f1-score: 0.8318For batch 127, tr_loss is    0.26.\n",
      "129/200 [==================>...........] - ETA: 1:03 - loss: 0.2610 - iou_score: 0.7149 - f1-score: 0.8319For batch 128, tr_loss is    0.26.\n",
      "130/200 [==================>...........] - ETA: 1:02 - loss: 0.2608 - iou_score: 0.7151 - f1-score: 0.8321For batch 129, tr_loss is    0.26.\n",
      "131/200 [==================>...........] - ETA: 1:01 - loss: 0.2606 - iou_score: 0.7154 - f1-score: 0.8323For batch 130, tr_loss is    0.26.\n",
      "132/200 [==================>...........] - ETA: 1:00 - loss: 0.2603 - iou_score: 0.7158 - f1-score: 0.8325For batch 131, tr_loss is    0.26.\n",
      "133/200 [==================>...........] - ETA: 1:00 - loss: 0.2602 - iou_score: 0.7159 - f1-score: 0.8326For batch 132, tr_loss is    0.26.\n",
      "134/200 [===================>..........] - ETA: 59s - loss: 0.2607 - iou_score: 0.7153 - f1-score: 0.8322 For batch 133, tr_loss is    0.26.\n",
      "135/200 [===================>..........] - ETA: 58s - loss: 0.2610 - iou_score: 0.7150 - f1-score: 0.8320For batch 134, tr_loss is    0.26.\n",
      "136/200 [===================>..........] - ETA: 57s - loss: 0.2609 - iou_score: 0.7149 - f1-score: 0.8319For batch 135, tr_loss is    0.26.\n",
      "137/200 [===================>..........] - ETA: 56s - loss: 0.2616 - iou_score: 0.7141 - f1-score: 0.8314For batch 136, tr_loss is    0.26.\n",
      "138/200 [===================>..........] - ETA: 55s - loss: 0.2615 - iou_score: 0.7142 - f1-score: 0.8315For batch 137, tr_loss is    0.26.\n",
      "139/200 [===================>..........] - ETA: 54s - loss: 0.2611 - iou_score: 0.7146 - f1-score: 0.8317For batch 138, tr_loss is    0.26.\n",
      "140/200 [====================>.........] - ETA: 53s - loss: 0.2622 - iou_score: 0.7136 - f1-score: 0.8309For batch 139, tr_loss is    0.26.\n",
      "141/200 [====================>.........] - ETA: 52s - loss: 0.2624 - iou_score: 0.7133 - f1-score: 0.8308For batch 140, tr_loss is    0.26.\n",
      "142/200 [====================>.........] - ETA: 51s - loss: 0.2624 - iou_score: 0.7134 - f1-score: 0.8308For batch 141, tr_loss is    0.26.\n",
      "143/200 [====================>.........] - ETA: 50s - loss: 0.2622 - iou_score: 0.7136 - f1-score: 0.8309For batch 142, tr_loss is    0.26.\n",
      "144/200 [====================>.........] - ETA: 50s - loss: 0.2624 - iou_score: 0.7133 - f1-score: 0.8307For batch 143, tr_loss is    0.26.\n",
      "145/200 [====================>.........] - ETA: 49s - loss: 0.2624 - iou_score: 0.7131 - f1-score: 0.8307For batch 144, tr_loss is    0.26.\n",
      "146/200 [====================>.........] - ETA: 48s - loss: 0.2620 - iou_score: 0.7138 - f1-score: 0.8311For batch 145, tr_loss is    0.26.\n",
      "147/200 [=====================>........] - ETA: 47s - loss: 0.2621 - iou_score: 0.7136 - f1-score: 0.8309For batch 146, tr_loss is    0.26.\n",
      "148/200 [=====================>........] - ETA: 46s - loss: 0.2616 - iou_score: 0.7142 - f1-score: 0.8314For batch 147, tr_loss is    0.26.\n",
      "149/200 [=====================>........] - ETA: 45s - loss: 0.2612 - iou_score: 0.7147 - f1-score: 0.8316For batch 148, tr_loss is    0.26.\n",
      "150/200 [=====================>........] - ETA: 44s - loss: 0.2607 - iou_score: 0.7153 - f1-score: 0.8321For batch 149, tr_loss is    0.26.\n",
      "151/200 [=====================>........] - ETA: 43s - loss: 0.2609 - iou_score: 0.7151 - f1-score: 0.8319For batch 150, tr_loss is    0.26.\n",
      "152/200 [=====================>........] - ETA: 42s - loss: 0.2608 - iou_score: 0.7152 - f1-score: 0.8320For batch 151, tr_loss is    0.26.\n",
      "153/200 [=====================>........] - ETA: 42s - loss: 0.2606 - iou_score: 0.7153 - f1-score: 0.8321For batch 152, tr_loss is    0.26.\n",
      "154/200 [======================>.......] - ETA: 41s - loss: 0.2605 - iou_score: 0.7155 - f1-score: 0.8322For batch 153, tr_loss is    0.26.\n",
      "155/200 [======================>.......] - ETA: 40s - loss: 0.2604 - iou_score: 0.7158 - f1-score: 0.8324For batch 154, tr_loss is    0.26.\n",
      "156/200 [======================>.......] - ETA: 39s - loss: 0.2600 - iou_score: 0.7161 - f1-score: 0.8326For batch 155, tr_loss is    0.26.\n",
      "157/200 [======================>.......] - ETA: 38s - loss: 0.2601 - iou_score: 0.7160 - f1-score: 0.8326For batch 156, tr_loss is    0.26.\n",
      "158/200 [======================>.......] - ETA: 37s - loss: 0.2601 - iou_score: 0.7159 - f1-score: 0.8325For batch 157, tr_loss is    0.26.\n",
      "159/200 [======================>.......] - ETA: 36s - loss: 0.2602 - iou_score: 0.7157 - f1-score: 0.8323For batch 158, tr_loss is    0.26.\n",
      "160/200 [=======================>......] - ETA: 35s - loss: 0.2601 - iou_score: 0.7158 - f1-score: 0.8324For batch 159, tr_loss is    0.26.\n",
      "161/200 [=======================>......] - ETA: 34s - loss: 0.2605 - iou_score: 0.7153 - f1-score: 0.8321For batch 160, tr_loss is    0.26.\n",
      "162/200 [=======================>......] - ETA: 33s - loss: 0.2604 - iou_score: 0.7152 - f1-score: 0.8320For batch 161, tr_loss is    0.26.\n",
      "163/200 [=======================>......] - ETA: 32s - loss: 0.2601 - iou_score: 0.7156 - f1-score: 0.8323For batch 162, tr_loss is    0.26.\n",
      "164/200 [=======================>......] - ETA: 31s - loss: 0.2600 - iou_score: 0.7157 - f1-score: 0.8324For batch 163, tr_loss is    0.26.\n",
      "165/200 [=======================>......] - ETA: 31s - loss: 0.2598 - iou_score: 0.7159 - f1-score: 0.8325For batch 164, tr_loss is    0.26.\n",
      "166/200 [=======================>......] - ETA: 30s - loss: 0.2596 - iou_score: 0.7159 - f1-score: 0.8326For batch 165, tr_loss is    0.26.\n",
      "167/200 [========================>.....] - ETA: 29s - loss: 0.2592 - iou_score: 0.7165 - f1-score: 0.8329For batch 166, tr_loss is    0.26.\n",
      "168/200 [========================>.....] - ETA: 28s - loss: 0.2596 - iou_score: 0.7161 - f1-score: 0.8326For batch 167, tr_loss is    0.26.\n",
      "169/200 [========================>.....] - ETA: 27s - loss: 0.2597 - iou_score: 0.7157 - f1-score: 0.8324For batch 168, tr_loss is    0.26.\n",
      "170/200 [========================>.....] - ETA: 26s - loss: 0.2593 - iou_score: 0.7163 - f1-score: 0.8328For batch 169, tr_loss is    0.26.\n",
      "171/200 [========================>.....] - ETA: 25s - loss: 0.2594 - iou_score: 0.7163 - f1-score: 0.8328For batch 170, tr_loss is    0.26.\n",
      "172/200 [========================>.....] - ETA: 24s - loss: 0.2590 - iou_score: 0.7167 - f1-score: 0.8330For batch 171, tr_loss is    0.26.\n",
      "173/200 [========================>.....] - ETA: 24s - loss: 0.2592 - iou_score: 0.7168 - f1-score: 0.8331For batch 172, tr_loss is    0.26.\n",
      "174/200 [=========================>....] - ETA: 23s - loss: 0.2591 - iou_score: 0.7171 - f1-score: 0.8333For batch 173, tr_loss is    0.26.\n",
      "175/200 [=========================>....] - ETA: 22s - loss: 0.2588 - iou_score: 0.7174 - f1-score: 0.8335For batch 174, tr_loss is    0.26.\n",
      "176/200 [=========================>....] - ETA: 21s - loss: 0.2588 - iou_score: 0.7173 - f1-score: 0.8334For batch 175, tr_loss is    0.26.\n",
      "177/200 [=========================>....] - ETA: 20s - loss: 0.2585 - iou_score: 0.7176 - f1-score: 0.8337For batch 176, tr_loss is    0.26.\n",
      "178/200 [=========================>....] - ETA: 19s - loss: 0.2588 - iou_score: 0.7171 - f1-score: 0.8333For batch 177, tr_loss is    0.26.\n",
      "179/200 [=========================>....] - ETA: 18s - loss: 0.2584 - iou_score: 0.7175 - f1-score: 0.8336For batch 178, tr_loss is    0.26.\n",
      "180/200 [==========================>...] - ETA: 17s - loss: 0.2585 - iou_score: 0.7174 - f1-score: 0.8335For batch 179, tr_loss is    0.26.\n",
      "181/200 [==========================>...] - ETA: 16s - loss: 0.2588 - iou_score: 0.7171 - f1-score: 0.8333For batch 180, tr_loss is    0.26.\n",
      "182/200 [==========================>...] - ETA: 15s - loss: 0.2586 - iou_score: 0.7173 - f1-score: 0.8334For batch 181, tr_loss is    0.26.\n",
      "183/200 [==========================>...] - ETA: 15s - loss: 0.2585 - iou_score: 0.7173 - f1-score: 0.8335For batch 182, tr_loss is    0.26.\n",
      "184/200 [==========================>...] - ETA: 14s - loss: 0.2584 - iou_score: 0.7174 - f1-score: 0.8335For batch 183, tr_loss is    0.26.\n",
      "185/200 [==========================>...] - ETA: 13s - loss: 0.2582 - iou_score: 0.7176 - f1-score: 0.8336For batch 184, tr_loss is    0.26.\n",
      "186/200 [==========================>...] - ETA: 12s - loss: 0.2583 - iou_score: 0.7176 - f1-score: 0.8337For batch 185, tr_loss is    0.26.\n",
      "187/200 [===========================>..] - ETA: 11s - loss: 0.2581 - iou_score: 0.7178 - f1-score: 0.8338For batch 186, tr_loss is    0.26.\n",
      "188/200 [===========================>..] - ETA: 10s - loss: 0.2580 - iou_score: 0.7179 - f1-score: 0.8339For batch 187, tr_loss is    0.26.\n",
      "189/200 [===========================>..] - ETA: 9s - loss: 0.2584 - iou_score: 0.7177 - f1-score: 0.8337 For batch 188, tr_loss is    0.26.\n",
      "190/200 [===========================>..] - ETA: 8s - loss: 0.2584 - iou_score: 0.7176 - f1-score: 0.8337For batch 189, tr_loss is    0.26.\n",
      "191/200 [===========================>..] - ETA: 8s - loss: 0.2590 - iou_score: 0.7170 - f1-score: 0.8332For batch 190, tr_loss is    0.26.\n",
      "192/200 [===========================>..] - ETA: 7s - loss: 0.2595 - iou_score: 0.7165 - f1-score: 0.8329For batch 191, tr_loss is    0.26.\n",
      "193/200 [===========================>..] - ETA: 6s - loss: 0.2593 - iou_score: 0.7167 - f1-score: 0.8331For batch 192, tr_loss is    0.26.\n",
      "194/200 [============================>.] - ETA: 5s - loss: 0.2598 - iou_score: 0.7163 - f1-score: 0.8327For batch 193, tr_loss is    0.26.\n",
      "195/200 [============================>.] - ETA: 4s - loss: 0.2597 - iou_score: 0.7163 - f1-score: 0.8328For batch 194, tr_loss is    0.26.\n",
      "196/200 [============================>.] - ETA: 3s - loss: 0.2600 - iou_score: 0.7160 - f1-score: 0.8325For batch 195, tr_loss is    0.26.\n",
      "197/200 [============================>.] - ETA: 2s - loss: 0.2598 - iou_score: 0.7161 - f1-score: 0.8326For batch 196, tr_loss is    0.26.\n",
      "198/200 [============================>.] - ETA: 1s - loss: 0.2599 - iou_score: 0.7160 - f1-score: 0.8325For batch 197, tr_loss is    0.26.\n",
      "199/200 [============================>.] - ETA: 0s - loss: 0.2602 - iou_score: 0.7156 - f1-score: 0.8322For batch 198, tr_loss is    0.26.\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.2601 - iou_score: 0.7156 - f1-score: 0.8323For batch 199, tr_loss is    0.26.\n",
      "For batch 0, vl_loss is    0.40.\n",
      "For batch 1, vl_loss is    0.42.\n",
      "For batch 2, vl_loss is    0.42.\n",
      "For batch 3, vl_loss is    0.41.\n",
      "For batch 4, vl_loss is    0.41.\n",
      "For batch 5, vl_loss is    0.41.\n",
      "For batch 6, vl_loss is    0.42.\n",
      "For batch 7, vl_loss is    0.43.\n",
      "For batch 8, vl_loss is    0.44.\n",
      "For batch 9, vl_loss is    0.44.\n",
      "For batch 10, vl_loss is    0.44.\n",
      "For batch 11, vl_loss is    0.44.\n",
      "For batch 12, vl_loss is    0.43.\n",
      "For batch 13, vl_loss is    0.43.\n",
      "For batch 14, vl_loss is    0.44.\n",
      "For batch 15, vl_loss is    0.43.\n",
      "For batch 16, vl_loss is    0.42.\n",
      "For batch 17, vl_loss is    0.43.\n",
      "For batch 18, vl_loss is    0.42.\n",
      "For batch 19, vl_loss is    0.42.\n",
      "For batch 20, vl_loss is    0.42.\n",
      "For batch 21, vl_loss is    0.42.\n",
      "For batch 22, vl_loss is    0.42.\n",
      "For batch 23, vl_loss is    0.43.\n",
      "For batch 24, vl_loss is    0.43.\n",
      "For batch 25, vl_loss is    0.43.\n",
      "For batch 26, vl_loss is    0.43.\n",
      "For batch 27, vl_loss is    0.42.\n",
      "For batch 28, vl_loss is    0.43.\n",
      "For batch 29, vl_loss is    0.43.\n",
      "For batch 30, vl_loss is    0.43.\n",
      "For batch 31, vl_loss is    0.42.\n",
      "For batch 32, vl_loss is    0.43.\n",
      "For batch 33, vl_loss is    0.42.\n",
      "For batch 34, vl_loss is    0.42.\n",
      "For batch 35, vl_loss is    0.42.\n",
      "For batch 36, vl_loss is    0.42.\n",
      "For batch 37, vl_loss is    0.42.\n",
      "For batch 38, vl_loss is    0.41.\n",
      "For batch 39, vl_loss is    0.42.\n",
      "For batch 40, vl_loss is    0.42.\n",
      "For batch 41, vl_loss is    0.42.\n",
      "For batch 42, vl_loss is    0.42.\n",
      "For batch 43, vl_loss is    0.42.\n",
      "For batch 44, vl_loss is    0.42.\n",
      "For batch 45, vl_loss is    0.42.\n",
      "For batch 46, vl_loss is    0.42.\n",
      "For batch 47, vl_loss is    0.42.\n",
      "For batch 48, vl_loss is    0.42.\n",
      "For batch 49, vl_loss is    0.42.\n",
      "For batch 50, vl_loss is    0.42.\n",
      "For batch 51, vl_loss is    0.42.\n",
      "For batch 52, vl_loss is    0.42.\n",
      "For batch 53, vl_loss is    0.42.\n",
      "For batch 54, vl_loss is    0.42.\n",
      "For batch 55, vl_loss is    0.42.\n",
      "For batch 56, vl_loss is    0.42.\n",
      "For batch 57, vl_loss is    0.42.\n",
      "For batch 58, vl_loss is    0.42.\n",
      "For batch 59, vl_loss is    0.42.\n",
      "For batch 60, vl_loss is    0.42.\n",
      "For batch 61, vl_loss is    0.42.\n",
      "For batch 62, vl_loss is    0.42.\n",
      "For batch 63, vl_loss is    0.42.\n",
      "For batch 64, vl_loss is    0.42.\n",
      "For batch 65, vl_loss is    0.42.\n",
      "For batch 66, vl_loss is    0.42.\n",
      "For batch 67, vl_loss is    0.42.\n",
      "For batch 68, vl_loss is    0.42.\n",
      "For batch 69, vl_loss is    0.42.\n",
      "For batch 70, vl_loss is    0.42.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 71, vl_loss is    0.42.\n",
      "For batch 72, vl_loss is    0.42.\n",
      "For batch 73, vl_loss is    0.42.\n",
      "For batch 74, vl_loss is    0.42.\n",
      "For batch 75, vl_loss is    0.42.\n",
      "For batch 76, vl_loss is    0.42.\n",
      "For batch 77, vl_loss is    0.42.\n",
      "For batch 78, vl_loss is    0.42.\n",
      "For batch 79, vl_loss is    0.42.\n",
      "For batch 80, vl_loss is    0.42.\n",
      "For batch 81, vl_loss is    0.42.\n",
      "For batch 82, vl_loss is    0.42.\n",
      "For batch 83, vl_loss is    0.42.\n",
      "For batch 84, vl_loss is    0.42.\n",
      "For batch 85, vl_loss is    0.42.\n",
      "For batch 86, vl_loss is    0.42.\n",
      "For batch 87, vl_loss is    0.42.\n",
      "For batch 88, vl_loss is    0.42.\n",
      "For batch 89, vl_loss is    0.42.\n",
      "For batch 90, vl_loss is    0.42.\n",
      "For batch 91, vl_loss is    0.42.\n",
      "For batch 92, vl_loss is    0.42.\n",
      "For batch 93, vl_loss is    0.42.\n",
      "For batch 94, vl_loss is    0.42.\n",
      "For batch 95, vl_loss is    0.42.\n",
      "For batch 96, vl_loss is    0.42.\n",
      "For batch 97, vl_loss is    0.42.\n",
      "For batch 98, vl_loss is    0.42.\n",
      "For batch 99, vl_loss is    0.42.\n",
      "200/200 [==============================] - 184s 910ms/step - loss: 0.2601 - iou_score: 0.7156 - f1-score: 0.8323 - val_loss: 0.4204 - val_iou_score: 0.5573 - val_f1-score: 0.7112\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.32441\n",
      "The average loss for epoch 17 is    0.26 \n",
      "47/47 [==============================] - 4s 86ms/step - loss: 0.3646 - iou_score: 0.5956 - f1-score: 0.7437\n",
      "./model/tumor_100_unet_efficientnetb0_imagenet_09291.hdf5\n",
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Number of devices: 2\n",
      "Epoch 1/200\n",
      "INFO:tensorflow:batch_all_reduce: 130 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 130 all-reduces with algorithm = nccl, num_packs = 1\n",
      "      1/Unknown - 47s 47s/step - loss: 0.5553 - iou_score: 0.2600 - f1-score: 0.4127For batch 0, tr_loss is    0.56.\n",
      "      2/Unknown - 48s 992ms/step - loss: 0.5672 - iou_score: 0.2788 - f1-score: 0.4352For batch 1, tr_loss is    0.57.\n",
      "      3/Unknown - 49s 1s/step - loss: 0.5719 - iou_score: 0.3023 - f1-score: 0.4627   For batch 2, tr_loss is    0.57.\n",
      "      4/Unknown - 50s 1s/step - loss: 0.5411 - iou_score: 0.3545 - f1-score: 0.5156For batch 3, tr_loss is    0.54.\n",
      "      5/Unknown - 52s 1s/step - loss: 0.5358 - iou_score: 0.3717 - f1-score: 0.5348For batch 4, tr_loss is    0.54.\n",
      "      6/Unknown - 53s 1s/step - loss: 0.5288 - iou_score: 0.3887 - f1-score: 0.5527For batch 5, tr_loss is    0.53.\n",
      "      7/Unknown - 54s 1s/step - loss: 0.5212 - iou_score: 0.4048 - f1-score: 0.5691For batch 6, tr_loss is    0.52.\n",
      "      8/Unknown - 56s 1s/step - loss: 0.5241 - iou_score: 0.4075 - f1-score: 0.5726For batch 7, tr_loss is    0.52.\n",
      "      9/Unknown - 57s 1s/step - loss: 0.5109 - iou_score: 0.4264 - f1-score: 0.5901For batch 8, tr_loss is    0.51.\n",
      "     10/Unknown - 58s 1s/step - loss: 0.5059 - iou_score: 0.4347 - f1-score: 0.5985For batch 9, tr_loss is    0.51.\n",
      "     11/Unknown - 59s 1s/step - loss: 0.4992 - iou_score: 0.4456 - f1-score: 0.6090For batch 10, tr_loss is    0.50.\n",
      "     12/Unknown - 59s 1s/step - loss: 0.4912 - iou_score: 0.4583 - f1-score: 0.6206For batch 11, tr_loss is    0.49.\n",
      "     13/Unknown - 60s 1s/step - loss: 0.4838 - iou_score: 0.4714 - f1-score: 0.6318For batch 12, tr_loss is    0.48.\n",
      "     14/Unknown - 61s 1s/step - loss: 0.4763 - iou_score: 0.4829 - f1-score: 0.6421For batch 13, tr_loss is    0.48.\n",
      "     15/Unknown - 62s 1s/step - loss: 0.4708 - iou_score: 0.4905 - f1-score: 0.6490For batch 14, tr_loss is    0.47.\n",
      "     16/Unknown - 62s 1s/step - loss: 0.4648 - iou_score: 0.4999 - f1-score: 0.6571For batch 15, tr_loss is    0.46.\n",
      "     17/Unknown - 64s 1s/step - loss: 0.4600 - iou_score: 0.5078 - f1-score: 0.6641For batch 16, tr_loss is    0.46.\n",
      "     18/Unknown - 65s 1s/step - loss: 0.4561 - iou_score: 0.5131 - f1-score: 0.6690For batch 17, tr_loss is    0.46.\n",
      "     19/Unknown - 65s 1s/step - loss: 0.4549 - iou_score: 0.5158 - f1-score: 0.6717For batch 18, tr_loss is    0.45.\n",
      "     20/Unknown - 66s 1s/step - loss: 0.4523 - iou_score: 0.5199 - f1-score: 0.6755For batch 19, tr_loss is    0.45.\n",
      "     21/Unknown - 67s 1s/step - loss: 0.4520 - iou_score: 0.5215 - f1-score: 0.6772For batch 20, tr_loss is    0.45.\n",
      "     22/Unknown - 69s 1s/step - loss: 0.4540 - iou_score: 0.5202 - f1-score: 0.6761For batch 21, tr_loss is    0.45.\n",
      "     23/Unknown - 69s 1s/step - loss: 0.4514 - iou_score: 0.5242 - f1-score: 0.6797For batch 22, tr_loss is    0.45.\n",
      "     24/Unknown - 70s 1s/step - loss: 0.4487 - iou_score: 0.5280 - f1-score: 0.6830For batch 23, tr_loss is    0.45.\n",
      "     25/Unknown - 71s 1s/step - loss: 0.4476 - iou_score: 0.5291 - f1-score: 0.6842For batch 24, tr_loss is    0.45.\n",
      "     26/Unknown - 72s 1000ms/step - loss: 0.4445 - iou_score: 0.5339 - f1-score: 0.6883For batch 25, tr_loss is    0.44.\n",
      "     27/Unknown - 73s 1s/step - loss: 0.4398 - iou_score: 0.5402 - f1-score: 0.6933    For batch 26, tr_loss is    0.44.\n",
      "     28/Unknown - 74s 1s/step - loss: 0.4367 - iou_score: 0.5444 - f1-score: 0.6968For batch 27, tr_loss is    0.44.\n",
      "     29/Unknown - 74s 992ms/step - loss: 0.4373 - iou_score: 0.5438 - f1-score: 0.6964For batch 28, tr_loss is    0.44.\n",
      "     30/Unknown - 76s 999ms/step - loss: 0.4333 - iou_score: 0.5488 - f1-score: 0.7004For batch 29, tr_loss is    0.43.\n",
      "     31/Unknown - 76s 987ms/step - loss: 0.4321 - iou_score: 0.5510 - f1-score: 0.7024For batch 30, tr_loss is    0.43.\n",
      "     32/Unknown - 77s 987ms/step - loss: 0.4309 - iou_score: 0.5529 - f1-score: 0.7043For batch 31, tr_loss is    0.43.\n",
      "     33/Unknown - 78s 987ms/step - loss: 0.4315 - iou_score: 0.5521 - f1-score: 0.7038For batch 32, tr_loss is    0.43.\n",
      "     34/Unknown - 79s 973ms/step - loss: 0.4301 - iou_score: 0.5536 - f1-score: 0.7051For batch 33, tr_loss is    0.43.\n",
      "     35/Unknown - 79s 964ms/step - loss: 0.4287 - iou_score: 0.5550 - f1-score: 0.7065For batch 34, tr_loss is    0.43.\n",
      "     36/Unknown - 81s 969ms/step - loss: 0.4266 - iou_score: 0.5574 - f1-score: 0.7086For batch 35, tr_loss is    0.43.\n",
      "     37/Unknown - 81s 955ms/step - loss: 0.4250 - iou_score: 0.5594 - f1-score: 0.7103For batch 36, tr_loss is    0.42.\n",
      "     38/Unknown - 82s 954ms/step - loss: 0.4249 - iou_score: 0.5597 - f1-score: 0.7108For batch 37, tr_loss is    0.42.\n",
      "     39/Unknown - 83s 956ms/step - loss: 0.4255 - iou_score: 0.5590 - f1-score: 0.7103For batch 38, tr_loss is    0.43.\n",
      "     40/Unknown - 84s 957ms/step - loss: 0.4255 - iou_score: 0.5600 - f1-score: 0.7112For batch 39, tr_loss is    0.43.\n",
      "     41/Unknown - 85s 958ms/step - loss: 0.4248 - iou_score: 0.5608 - f1-score: 0.7121For batch 40, tr_loss is    0.42.\n",
      "     42/Unknown - 86s 953ms/step - loss: 0.4251 - iou_score: 0.5604 - f1-score: 0.7118For batch 41, tr_loss is    0.43.\n",
      "     43/Unknown - 86s 942ms/step - loss: 0.4231 - iou_score: 0.5628 - f1-score: 0.7139For batch 42, tr_loss is    0.42.\n",
      "     44/Unknown - 87s 936ms/step - loss: 0.4237 - iou_score: 0.5623 - f1-score: 0.7133For batch 43, tr_loss is    0.42.\n",
      "     45/Unknown - 88s 938ms/step - loss: 0.4236 - iou_score: 0.5629 - f1-score: 0.7139For batch 44, tr_loss is    0.42.\n",
      "     46/Unknown - 89s 940ms/step - loss: 0.4225 - iou_score: 0.5648 - f1-score: 0.7155For batch 45, tr_loss is    0.42.\n",
      "     47/Unknown - 89s 929ms/step - loss: 0.4215 - iou_score: 0.5665 - f1-score: 0.7170For batch 46, tr_loss is    0.42.\n",
      "     48/Unknown - 90s 924ms/step - loss: 0.4193 - iou_score: 0.5694 - f1-score: 0.7192For batch 47, tr_loss is    0.42.\n",
      "     49/Unknown - 91s 921ms/step - loss: 0.4186 - iou_score: 0.5704 - f1-score: 0.7201For batch 48, tr_loss is    0.42.\n",
      "     50/Unknown - 92s 924ms/step - loss: 0.4173 - iou_score: 0.5718 - f1-score: 0.7214For batch 49, tr_loss is    0.42.\n",
      "     51/Unknown - 93s 926ms/step - loss: 0.4191 - iou_score: 0.5699 - f1-score: 0.7199For batch 50, tr_loss is    0.42.\n",
      "     52/Unknown - 94s 928ms/step - loss: 0.4206 - iou_score: 0.5683 - f1-score: 0.7186For batch 51, tr_loss is    0.42.\n",
      "     53/Unknown - 95s 919ms/step - loss: 0.4189 - iou_score: 0.5702 - f1-score: 0.7201For batch 52, tr_loss is    0.42.\n",
      "     54/Unknown - 96s 922ms/step - loss: 0.4185 - iou_score: 0.5704 - f1-score: 0.7204For batch 53, tr_loss is    0.42.\n",
      "     55/Unknown - 97s 924ms/step - loss: 0.4169 - iou_score: 0.5724 - f1-score: 0.7220For batch 54, tr_loss is    0.42.\n",
      "     56/Unknown - 98s 926ms/step - loss: 0.4164 - iou_score: 0.5732 - f1-score: 0.7228For batch 55, tr_loss is    0.42.\n",
      "     57/Unknown - 99s 929ms/step - loss: 0.4165 - iou_score: 0.5731 - f1-score: 0.7227For batch 56, tr_loss is    0.42.\n",
      "     58/Unknown - 100s 930ms/step - loss: 0.4151 - iou_score: 0.5749 - f1-score: 0.7242For batch 57, tr_loss is    0.42.\n",
      "     59/Unknown - 100s 922ms/step - loss: 0.4139 - iou_score: 0.5766 - f1-score: 0.7255For batch 58, tr_loss is    0.41.\n",
      "     60/Unknown - 101s 924ms/step - loss: 0.4141 - iou_score: 0.5764 - f1-score: 0.7254For batch 59, tr_loss is    0.41.\n",
      "     61/Unknown - 102s 921ms/step - loss: 0.4141 - iou_score: 0.5764 - f1-score: 0.7254For batch 60, tr_loss is    0.41.\n",
      "     62/Unknown - 103s 923ms/step - loss: 0.4140 - iou_score: 0.5764 - f1-score: 0.7255For batch 61, tr_loss is    0.41.\n",
      "     63/Unknown - 104s 924ms/step - loss: 0.4127 - iou_score: 0.5783 - f1-score: 0.7269For batch 62, tr_loss is    0.41.\n",
      "     64/Unknown - 105s 922ms/step - loss: 0.4121 - iou_score: 0.5791 - f1-score: 0.7277For batch 63, tr_loss is    0.41.\n",
      "     65/Unknown - 106s 923ms/step - loss: 0.4115 - iou_score: 0.5799 - f1-score: 0.7283For batch 64, tr_loss is    0.41.\n",
      "     66/Unknown - 107s 925ms/step - loss: 0.4113 - iou_score: 0.5800 - f1-score: 0.7284For batch 65, tr_loss is    0.41.\n",
      "     67/Unknown - 108s 927ms/step - loss: 0.4098 - iou_score: 0.5815 - f1-score: 0.7297For batch 66, tr_loss is    0.41.\n",
      "     68/Unknown - 109s 928ms/step - loss: 0.4086 - iou_score: 0.5829 - f1-score: 0.7308For batch 67, tr_loss is    0.41.\n",
      "     69/Unknown - 110s 924ms/step - loss: 0.4080 - iou_score: 0.5836 - f1-score: 0.7314For batch 68, tr_loss is    0.41.\n",
      "     70/Unknown - 110s 920ms/step - loss: 0.4072 - iou_score: 0.5846 - f1-score: 0.7322For batch 69, tr_loss is    0.41.\n",
      "     71/Unknown - 111s 922ms/step - loss: 0.4062 - iou_score: 0.5859 - f1-score: 0.7333For batch 70, tr_loss is    0.41.\n",
      "     72/Unknown - 112s 915ms/step - loss: 0.4049 - iou_score: 0.5874 - f1-score: 0.7344For batch 71, tr_loss is    0.40.\n",
      "     73/Unknown - 113s 921ms/step - loss: 0.4047 - iou_score: 0.5877 - f1-score: 0.7347For batch 72, tr_loss is    0.40.\n",
      "     74/Unknown - 114s 923ms/step - loss: 0.4035 - iou_score: 0.5891 - f1-score: 0.7358For batch 73, tr_loss is    0.40.\n",
      "     75/Unknown - 115s 920ms/step - loss: 0.4028 - iou_score: 0.5897 - f1-score: 0.7364For batch 74, tr_loss is    0.40.\n",
      "     76/Unknown - 116s 919ms/step - loss: 0.4027 - iou_score: 0.5901 - f1-score: 0.7367For batch 75, tr_loss is    0.40.\n",
      "     77/Unknown - 117s 920ms/step - loss: 0.4014 - iou_score: 0.5914 - f1-score: 0.7378For batch 76, tr_loss is    0.40.\n",
      "     78/Unknown - 117s 918ms/step - loss: 0.4010 - iou_score: 0.5919 - f1-score: 0.7382For batch 77, tr_loss is    0.40.\n",
      "     79/Unknown - 118s 918ms/step - loss: 0.4000 - iou_score: 0.5929 - f1-score: 0.7390For batch 78, tr_loss is    0.40.\n",
      "     80/Unknown - 119s 913ms/step - loss: 0.3997 - iou_score: 0.5936 - f1-score: 0.7395For batch 79, tr_loss is    0.40.\n",
      "     81/Unknown - 120s 917ms/step - loss: 0.3993 - iou_score: 0.5940 - f1-score: 0.7399For batch 80, tr_loss is    0.40.\n",
      "     82/Unknown - 121s 916ms/step - loss: 0.3991 - iou_score: 0.5943 - f1-score: 0.7402For batch 81, tr_loss is    0.40.\n",
      "     83/Unknown - 122s 913ms/step - loss: 0.3995 - iou_score: 0.5937 - f1-score: 0.7398For batch 82, tr_loss is    0.40.\n",
      "     84/Unknown - 123s 914ms/step - loss: 0.3994 - iou_score: 0.5938 - f1-score: 0.7399For batch 83, tr_loss is    0.40.\n",
      "     85/Unknown - 123s 909ms/step - loss: 0.3992 - iou_score: 0.5940 - f1-score: 0.7400For batch 84, tr_loss is    0.40.\n",
      "     86/Unknown - 124s 904ms/step - loss: 0.3992 - iou_score: 0.5939 - f1-score: 0.7400For batch 85, tr_loss is    0.40.\n",
      "     87/Unknown - 125s 907ms/step - loss: 0.3985 - iou_score: 0.5947 - f1-score: 0.7407For batch 86, tr_loss is    0.40.\n",
      "     88/Unknown - 125s 903ms/step - loss: 0.3990 - iou_score: 0.5940 - f1-score: 0.7402For batch 87, tr_loss is    0.40.\n",
      "     89/Unknown - 126s 903ms/step - loss: 0.3983 - iou_score: 0.5951 - f1-score: 0.7411For batch 88, tr_loss is    0.40.\n",
      "     90/Unknown - 127s 905ms/step - loss: 0.3973 - iou_score: 0.5962 - f1-score: 0.7419For batch 89, tr_loss is    0.40.\n",
      "     91/Unknown - 128s 900ms/step - loss: 0.3967 - iou_score: 0.5971 - f1-score: 0.7426For batch 90, tr_loss is    0.40.\n",
      "     92/Unknown - 128s 898ms/step - loss: 0.3961 - iou_score: 0.5977 - f1-score: 0.7431For batch 91, tr_loss is    0.40.\n",
      "     93/Unknown - 129s 896ms/step - loss: 0.3966 - iou_score: 0.5972 - f1-score: 0.7428For batch 92, tr_loss is    0.40.\n",
      "     94/Unknown - 130s 898ms/step - loss: 0.3954 - iou_score: 0.5987 - f1-score: 0.7438For batch 93, tr_loss is    0.40.\n",
      "     95/Unknown - 131s 899ms/step - loss: 0.3953 - iou_score: 0.5988 - f1-score: 0.7440For batch 94, tr_loss is    0.40.\n",
      "     96/Unknown - 132s 900ms/step - loss: 0.3946 - iou_score: 0.5995 - f1-score: 0.7446For batch 95, tr_loss is    0.39.\n",
      "     97/Unknown - 133s 901ms/step - loss: 0.3948 - iou_score: 0.5993 - f1-score: 0.7444For batch 96, tr_loss is    0.39.\n",
      "     98/Unknown - 134s 898ms/step - loss: 0.3946 - iou_score: 0.5995 - f1-score: 0.7446For batch 97, tr_loss is    0.39.\n",
      "     99/Unknown - 135s 900ms/step - loss: 0.3938 - iou_score: 0.6005 - f1-score: 0.7454For batch 98, tr_loss is    0.39.\n",
      "    100/Unknown - 135s 895ms/step - loss: 0.3930 - iou_score: 0.6016 - f1-score: 0.7462For batch 99, tr_loss is    0.39.\n",
      "    101/Unknown - 136s 894ms/step - loss: 0.3919 - iou_score: 0.6030 - f1-score: 0.7473For batch 100, tr_loss is    0.39.\n",
      "    102/Unknown - 137s 893ms/step - loss: 0.3916 - iou_score: 0.6032 - f1-score: 0.7475For batch 101, tr_loss is    0.39.\n",
      "    103/Unknown - 138s 895ms/step - loss: 0.3912 - iou_score: 0.6037 - f1-score: 0.7479For batch 102, tr_loss is    0.39.\n",
      "    104/Unknown - 138s 891ms/step - loss: 0.3909 - iou_score: 0.6043 - f1-score: 0.7484For batch 103, tr_loss is    0.39.\n",
      "    105/Unknown - 139s 889ms/step - loss: 0.3898 - iou_score: 0.6055 - f1-score: 0.7493For batch 104, tr_loss is    0.39.\n",
      "    106/Unknown - 140s 890ms/step - loss: 0.3888 - iou_score: 0.6067 - f1-score: 0.7502For batch 105, tr_loss is    0.39.\n",
      "    107/Unknown - 141s 892ms/step - loss: 0.3887 - iou_score: 0.6069 - f1-score: 0.7504For batch 106, tr_loss is    0.39.\n",
      "    108/Unknown - 142s 893ms/step - loss: 0.3894 - iou_score: 0.6064 - f1-score: 0.7500For batch 107, tr_loss is    0.39.\n",
      "    109/Unknown - 143s 894ms/step - loss: 0.3885 - iou_score: 0.6074 - f1-score: 0.7507For batch 108, tr_loss is    0.39.\n",
      "    110/Unknown - 144s 895ms/step - loss: 0.3871 - iou_score: 0.6091 - f1-score: 0.7520For batch 109, tr_loss is    0.39.\n",
      "    111/Unknown - 145s 891ms/step - loss: 0.3872 - iou_score: 0.6090 - f1-score: 0.7519For batch 110, tr_loss is    0.39.\n",
      "    112/Unknown - 146s 892ms/step - loss: 0.3873 - iou_score: 0.6090 - f1-score: 0.7520For batch 111, tr_loss is    0.39.\n",
      "    113/Unknown - 147s 891ms/step - loss: 0.3873 - iou_score: 0.6089 - f1-score: 0.7520For batch 112, tr_loss is    0.39.\n",
      "    114/Unknown - 147s 888ms/step - loss: 0.3866 - iou_score: 0.6100 - f1-score: 0.7528For batch 113, tr_loss is    0.39.\n",
      "    115/Unknown - 148s 886ms/step - loss: 0.3860 - iou_score: 0.6107 - f1-score: 0.7533For batch 114, tr_loss is    0.39.\n",
      "    116/Unknown - 149s 888ms/step - loss: 0.3854 - iou_score: 0.6114 - f1-score: 0.7539For batch 115, tr_loss is    0.39.\n",
      "    117/Unknown - 150s 889ms/step - loss: 0.3849 - iou_score: 0.6120 - f1-score: 0.7543For batch 116, tr_loss is    0.38.\n",
      "    118/Unknown - 151s 888ms/step - loss: 0.3840 - iou_score: 0.6130 - f1-score: 0.7551For batch 117, tr_loss is    0.38.\n",
      "    119/Unknown - 151s 884ms/step - loss: 0.3831 - iou_score: 0.6140 - f1-score: 0.7559For batch 118, tr_loss is    0.38.\n",
      "    120/Unknown - 152s 883ms/step - loss: 0.3833 - iou_score: 0.6140 - f1-score: 0.7559For batch 119, tr_loss is    0.38.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    121/Unknown - 153s 882ms/step - loss: 0.3823 - iou_score: 0.6151 - f1-score: 0.7567For batch 120, tr_loss is    0.38.\n",
      "    122/Unknown - 154s 884ms/step - loss: 0.3825 - iou_score: 0.6149 - f1-score: 0.7565For batch 121, tr_loss is    0.38.\n",
      "    123/Unknown - 155s 884ms/step - loss: 0.3821 - iou_score: 0.6154 - f1-score: 0.7570For batch 122, tr_loss is    0.38.\n",
      "    124/Unknown - 156s 885ms/step - loss: 0.3820 - iou_score: 0.6157 - f1-score: 0.7572For batch 123, tr_loss is    0.38.\n",
      "    125/Unknown - 157s 886ms/step - loss: 0.3820 - iou_score: 0.6155 - f1-score: 0.7571For batch 124, tr_loss is    0.38.\n",
      "    126/Unknown - 157s 884ms/step - loss: 0.3816 - iou_score: 0.6161 - f1-score: 0.7576For batch 125, tr_loss is    0.38.\n",
      "    127/Unknown - 158s 883ms/step - loss: 0.3815 - iou_score: 0.6161 - f1-score: 0.7576For batch 126, tr_loss is    0.38.\n",
      "    128/Unknown - 158s 880ms/step - loss: 0.3818 - iou_score: 0.6157 - f1-score: 0.7573For batch 127, tr_loss is    0.38.\n",
      "    129/Unknown - 159s 881ms/step - loss: 0.3820 - iou_score: 0.6155 - f1-score: 0.7571For batch 128, tr_loss is    0.38.\n",
      "    130/Unknown - 160s 882ms/step - loss: 0.3814 - iou_score: 0.6163 - f1-score: 0.7578For batch 129, tr_loss is    0.38.\n",
      "    131/Unknown - 161s 879ms/step - loss: 0.3817 - iou_score: 0.6161 - f1-score: 0.7576For batch 130, tr_loss is    0.38.\n",
      "    132/Unknown - 162s 882ms/step - loss: 0.3817 - iou_score: 0.6162 - f1-score: 0.7577For batch 131, tr_loss is    0.38.\n",
      "    133/Unknown - 163s 883ms/step - loss: 0.3811 - iou_score: 0.6169 - f1-score: 0.7582For batch 132, tr_loss is    0.38.\n",
      "    134/Unknown - 164s 880ms/step - loss: 0.3814 - iou_score: 0.6164 - f1-score: 0.7579For batch 133, tr_loss is    0.38.\n",
      "    135/Unknown - 165s 883ms/step - loss: 0.3807 - iou_score: 0.6172 - f1-score: 0.7585For batch 134, tr_loss is    0.38.\n",
      "    136/Unknown - 166s 881ms/step - loss: 0.3807 - iou_score: 0.6170 - f1-score: 0.7584For batch 135, tr_loss is    0.38.\n",
      "    137/Unknown - 166s 879ms/step - loss: 0.3806 - iou_score: 0.6171 - f1-score: 0.7585For batch 136, tr_loss is    0.38.\n",
      "    138/Unknown - 167s 880ms/step - loss: 0.3804 - iou_score: 0.6174 - f1-score: 0.7587For batch 137, tr_loss is    0.38.\n",
      "    139/Unknown - 168s 878ms/step - loss: 0.3801 - iou_score: 0.6178 - f1-score: 0.7591For batch 138, tr_loss is    0.38.\n",
      "    140/Unknown - 169s 879ms/step - loss: 0.3798 - iou_score: 0.6181 - f1-score: 0.7593For batch 139, tr_loss is    0.38.\n",
      "    141/Unknown - 170s 880ms/step - loss: 0.3804 - iou_score: 0.6174 - f1-score: 0.7588For batch 140, tr_loss is    0.38.\n",
      "    142/Unknown - 171s 882ms/step - loss: 0.3805 - iou_score: 0.6172 - f1-score: 0.7586For batch 141, tr_loss is    0.38.\n",
      "    143/Unknown - 172s 881ms/step - loss: 0.3802 - iou_score: 0.6175 - f1-score: 0.7589For batch 142, tr_loss is    0.38.\n",
      "    144/Unknown - 172s 879ms/step - loss: 0.3799 - iou_score: 0.6177 - f1-score: 0.7590For batch 143, tr_loss is    0.38.\n",
      "    145/Unknown - 173s 877ms/step - loss: 0.3796 - iou_score: 0.6180 - f1-score: 0.7593For batch 144, tr_loss is    0.38.\n",
      "    146/Unknown - 174s 876ms/step - loss: 0.3794 - iou_score: 0.6181 - f1-score: 0.7594For batch 145, tr_loss is    0.38.\n",
      "    147/Unknown - 175s 877ms/step - loss: 0.3788 - iou_score: 0.6187 - f1-score: 0.7599For batch 146, tr_loss is    0.38.\n",
      "    148/Unknown - 175s 875ms/step - loss: 0.3790 - iou_score: 0.6186 - f1-score: 0.7598For batch 147, tr_loss is    0.38.\n",
      "    149/Unknown - 176s 877ms/step - loss: 0.3786 - iou_score: 0.6191 - f1-score: 0.7602For batch 148, tr_loss is    0.38.\n",
      "    150/Unknown - 178s 878ms/step - loss: 0.3794 - iou_score: 0.6184 - f1-score: 0.7597For batch 149, tr_loss is    0.38.\n",
      "    151/Unknown - 179s 879ms/step - loss: 0.3792 - iou_score: 0.6186 - f1-score: 0.7598For batch 150, tr_loss is    0.38.\n",
      "    152/Unknown - 179s 878ms/step - loss: 0.3787 - iou_score: 0.6192 - f1-score: 0.7603For batch 151, tr_loss is    0.38.\n",
      "    153/Unknown - 180s 879ms/step - loss: 0.3785 - iou_score: 0.6193 - f1-score: 0.7603For batch 152, tr_loss is    0.38.\n",
      "    154/Unknown - 181s 876ms/step - loss: 0.3783 - iou_score: 0.6195 - f1-score: 0.7605For batch 153, tr_loss is    0.38.\n",
      "    155/Unknown - 182s 878ms/step - loss: 0.3780 - iou_score: 0.6196 - f1-score: 0.7607For batch 154, tr_loss is    0.38.\n",
      "    156/Unknown - 183s 877ms/step - loss: 0.3778 - iou_score: 0.6197 - f1-score: 0.7607For batch 155, tr_loss is    0.38.\n",
      "    157/Unknown - 184s 878ms/step - loss: 0.3779 - iou_score: 0.6196 - f1-score: 0.7607For batch 156, tr_loss is    0.38.\n",
      "    158/Unknown - 185s 880ms/step - loss: 0.3774 - iou_score: 0.6203 - f1-score: 0.7612For batch 157, tr_loss is    0.38.\n",
      "    159/Unknown - 186s 881ms/step - loss: 0.3772 - iou_score: 0.6208 - f1-score: 0.7616For batch 158, tr_loss is    0.38.\n",
      "    160/Unknown - 187s 882ms/step - loss: 0.3772 - iou_score: 0.6206 - f1-score: 0.7614For batch 159, tr_loss is    0.38.\n",
      "    161/Unknown - 188s 883ms/step - loss: 0.3767 - iou_score: 0.6212 - f1-score: 0.7619For batch 160, tr_loss is    0.38.\n",
      "    162/Unknown - 188s 880ms/step - loss: 0.3766 - iou_score: 0.6212 - f1-score: 0.7619For batch 161, tr_loss is    0.38.\n",
      "    163/Unknown - 190s 882ms/step - loss: 0.3760 - iou_score: 0.6218 - f1-score: 0.7624For batch 162, tr_loss is    0.38.\n",
      "    164/Unknown - 190s 882ms/step - loss: 0.3760 - iou_score: 0.6217 - f1-score: 0.7623For batch 163, tr_loss is    0.38.\n",
      "    165/Unknown - 191s 880ms/step - loss: 0.3759 - iou_score: 0.6217 - f1-score: 0.7624For batch 164, tr_loss is    0.38.\n",
      "    166/Unknown - 192s 882ms/step - loss: 0.3759 - iou_score: 0.6218 - f1-score: 0.7624For batch 165, tr_loss is    0.38.\n",
      "    167/Unknown - 193s 883ms/step - loss: 0.3755 - iou_score: 0.6222 - f1-score: 0.7628For batch 166, tr_loss is    0.38.\n",
      "    168/Unknown - 194s 882ms/step - loss: 0.3756 - iou_score: 0.6221 - f1-score: 0.7626For batch 167, tr_loss is    0.38.\n",
      "    169/Unknown - 195s 881ms/step - loss: 0.3758 - iou_score: 0.6218 - f1-score: 0.7624For batch 168, tr_loss is    0.38.\n",
      "    170/Unknown - 196s 882ms/step - loss: 0.3757 - iou_score: 0.6220 - f1-score: 0.7626For batch 169, tr_loss is    0.38.\n",
      "    171/Unknown - 196s 880ms/step - loss: 0.3759 - iou_score: 0.6216 - f1-score: 0.7623For batch 170, tr_loss is    0.38.\n",
      "    172/Unknown - 197s 878ms/step - loss: 0.3759 - iou_score: 0.6215 - f1-score: 0.7623For batch 171, tr_loss is    0.38.\n",
      "    173/Unknown - 198s 878ms/step - loss: 0.3758 - iou_score: 0.6214 - f1-score: 0.7622For batch 172, tr_loss is    0.38.\n",
      "    174/Unknown - 198s 877ms/step - loss: 0.3754 - iou_score: 0.6219 - f1-score: 0.7626For batch 173, tr_loss is    0.38.\n",
      "    175/Unknown - 199s 878ms/step - loss: 0.3754 - iou_score: 0.6219 - f1-score: 0.7626For batch 174, tr_loss is    0.38.\n",
      "    176/Unknown - 200s 876ms/step - loss: 0.3755 - iou_score: 0.6217 - f1-score: 0.7625For batch 175, tr_loss is    0.38.\n",
      "    177/Unknown - 201s 875ms/step - loss: 0.3753 - iou_score: 0.6222 - f1-score: 0.7629For batch 176, tr_loss is    0.38.\n",
      "    178/Unknown - 202s 876ms/step - loss: 0.3750 - iou_score: 0.6226 - f1-score: 0.7632For batch 177, tr_loss is    0.37.\n",
      "    179/Unknown - 203s 877ms/step - loss: 0.3747 - iou_score: 0.6230 - f1-score: 0.7634For batch 178, tr_loss is    0.37.\n",
      "    180/Unknown - 204s 878ms/step - loss: 0.3746 - iou_score: 0.6231 - f1-score: 0.7636For batch 179, tr_loss is    0.37.\n",
      "    181/Unknown - 204s 876ms/step - loss: 0.3745 - iou_score: 0.6232 - f1-score: 0.7636For batch 180, tr_loss is    0.37.\n",
      "    182/Unknown - 205s 876ms/step - loss: 0.3742 - iou_score: 0.6235 - f1-score: 0.7639For batch 181, tr_loss is    0.37.\n",
      "    183/Unknown - 206s 877ms/step - loss: 0.3741 - iou_score: 0.6236 - f1-score: 0.7640For batch 182, tr_loss is    0.37.\n",
      "    184/Unknown - 207s 877ms/step - loss: 0.3737 - iou_score: 0.6241 - f1-score: 0.7644For batch 183, tr_loss is    0.37.\n",
      "    185/Unknown - 208s 877ms/step - loss: 0.3737 - iou_score: 0.6242 - f1-score: 0.7645For batch 184, tr_loss is    0.37.\n",
      "    186/Unknown - 209s 877ms/step - loss: 0.3735 - iou_score: 0.6244 - f1-score: 0.7646For batch 185, tr_loss is    0.37.\n",
      "    187/Unknown - 210s 878ms/step - loss: 0.3729 - iou_score: 0.6250 - f1-score: 0.7650For batch 186, tr_loss is    0.37.\n",
      "    188/Unknown - 211s 879ms/step - loss: 0.3730 - iou_score: 0.6250 - f1-score: 0.7651For batch 187, tr_loss is    0.37.\n",
      "    189/Unknown - 212s 879ms/step - loss: 0.3727 - iou_score: 0.6253 - f1-score: 0.7653For batch 188, tr_loss is    0.37.\n",
      "    190/Unknown - 213s 880ms/step - loss: 0.3724 - iou_score: 0.6256 - f1-score: 0.7655For batch 189, tr_loss is    0.37.\n",
      "    191/Unknown - 214s 879ms/step - loss: 0.3724 - iou_score: 0.6256 - f1-score: 0.7656For batch 190, tr_loss is    0.37.\n",
      "    192/Unknown - 215s 880ms/step - loss: 0.3723 - iou_score: 0.6257 - f1-score: 0.7656For batch 191, tr_loss is    0.37.\n",
      "    193/Unknown - 216s 881ms/step - loss: 0.3726 - iou_score: 0.6251 - f1-score: 0.7652For batch 192, tr_loss is    0.37.\n",
      "    194/Unknown - 216s 879ms/step - loss: 0.3726 - iou_score: 0.6250 - f1-score: 0.7651For batch 193, tr_loss is    0.37.\n",
      "    195/Unknown - 217s 878ms/step - loss: 0.3726 - iou_score: 0.6249 - f1-score: 0.7651For batch 194, tr_loss is    0.37.\n",
      "    196/Unknown - 218s 878ms/step - loss: 0.3724 - iou_score: 0.6250 - f1-score: 0.7651For batch 195, tr_loss is    0.37.\n",
      "    197/Unknown - 219s 877ms/step - loss: 0.3722 - iou_score: 0.6253 - f1-score: 0.7654For batch 196, tr_loss is    0.37.\n",
      "    198/Unknown - 220s 878ms/step - loss: 0.3715 - iou_score: 0.6262 - f1-score: 0.7660For batch 197, tr_loss is    0.37.\n",
      "    199/Unknown - 221s 879ms/step - loss: 0.3712 - iou_score: 0.6265 - f1-score: 0.7662For batch 198, tr_loss is    0.37.\n",
      "    200/Unknown - 222s 879ms/step - loss: 0.3706 - iou_score: 0.6272 - f1-score: 0.7668For batch 199, tr_loss is    0.37.\n",
      "    201/Unknown - 223s 880ms/step - loss: 0.3707 - iou_score: 0.6271 - f1-score: 0.7667For batch 200, tr_loss is    0.37.\n",
      "    202/Unknown - 224s 881ms/step - loss: 0.3704 - iou_score: 0.6273 - f1-score: 0.7669For batch 201, tr_loss is    0.37.\n",
      "    203/Unknown - 225s 881ms/step - loss: 0.3699 - iou_score: 0.6277 - f1-score: 0.7672For batch 202, tr_loss is    0.37.\n",
      "    204/Unknown - 225s 879ms/step - loss: 0.3693 - iou_score: 0.6284 - f1-score: 0.7677For batch 203, tr_loss is    0.37.\n",
      "    205/Unknown - 226s 878ms/step - loss: 0.3692 - iou_score: 0.6284 - f1-score: 0.7677For batch 204, tr_loss is    0.37.\n",
      "    206/Unknown - 227s 879ms/step - loss: 0.3694 - iou_score: 0.6284 - f1-score: 0.7677For batch 205, tr_loss is    0.37.\n",
      "    207/Unknown - 228s 880ms/step - loss: 0.3691 - iou_score: 0.6288 - f1-score: 0.7680For batch 206, tr_loss is    0.37.\n",
      "    208/Unknown - 229s 880ms/step - loss: 0.3689 - iou_score: 0.6289 - f1-score: 0.7680For batch 207, tr_loss is    0.37.\n",
      "    209/Unknown - 229s 878ms/step - loss: 0.3690 - iou_score: 0.6289 - f1-score: 0.7681For batch 208, tr_loss is    0.37.\n",
      "    210/Unknown - 230s 879ms/step - loss: 0.3691 - iou_score: 0.6287 - f1-score: 0.7679For batch 209, tr_loss is    0.37.\n",
      "    211/Unknown - 231s 880ms/step - loss: 0.3687 - iou_score: 0.6292 - f1-score: 0.7683For batch 210, tr_loss is    0.37.\n",
      "    212/Unknown - 232s 880ms/step - loss: 0.3683 - iou_score: 0.6296 - f1-score: 0.7686For batch 211, tr_loss is    0.37.\n",
      "    213/Unknown - 233s 881ms/step - loss: 0.3684 - iou_score: 0.6296 - f1-score: 0.7686For batch 212, tr_loss is    0.37.\n",
      "    214/Unknown - 235s 882ms/step - loss: 0.3680 - iou_score: 0.6300 - f1-score: 0.7689For batch 213, tr_loss is    0.37.\n",
      "    215/Unknown - 236s 882ms/step - loss: 0.3677 - iou_score: 0.6304 - f1-score: 0.7693For batch 214, tr_loss is    0.37.\n",
      "    216/Unknown - 237s 883ms/step - loss: 0.3674 - iou_score: 0.6307 - f1-score: 0.7695For batch 215, tr_loss is    0.37.\n",
      "    217/Unknown - 237s 882ms/step - loss: 0.3673 - iou_score: 0.6307 - f1-score: 0.7695For batch 216, tr_loss is    0.37.\n",
      "    218/Unknown - 238s 880ms/step - loss: 0.3673 - iou_score: 0.6308 - f1-score: 0.7695For batch 217, tr_loss is    0.37.\n",
      "    219/Unknown - 239s 880ms/step - loss: 0.3675 - iou_score: 0.6305 - f1-score: 0.7693For batch 218, tr_loss is    0.37.\n",
      "    220/Unknown - 240s 881ms/step - loss: 0.3673 - iou_score: 0.6307 - f1-score: 0.7695For batch 219, tr_loss is    0.37.\n",
      "    221/Unknown - 241s 881ms/step - loss: 0.3673 - iou_score: 0.6307 - f1-score: 0.7695For batch 220, tr_loss is    0.37.\n",
      "    222/Unknown - 242s 882ms/step - loss: 0.3669 - iou_score: 0.6311 - f1-score: 0.7698For batch 221, tr_loss is    0.37.\n",
      "    223/Unknown - 243s 882ms/step - loss: 0.3669 - iou_score: 0.6311 - f1-score: 0.7698For batch 222, tr_loss is    0.37.\n",
      "    224/Unknown - 244s 883ms/step - loss: 0.3665 - iou_score: 0.6316 - f1-score: 0.7702For batch 223, tr_loss is    0.37.\n",
      "    225/Unknown - 244s 881ms/step - loss: 0.3660 - iou_score: 0.6321 - f1-score: 0.7706For batch 224, tr_loss is    0.37.\n",
      "    226/Unknown - 244s 878ms/step - loss: 0.3658 - iou_score: 0.6322 - f1-score: 0.7707For batch 225, tr_loss is    0.37.\n",
      "    227/Unknown - 245s 876ms/step - loss: 0.3655 - iou_score: 0.6326 - f1-score: 0.7710For batch 226, tr_loss is    0.37.\n",
      "    228/Unknown - 245s 873ms/step - loss: 0.3654 - iou_score: 0.6326 - f1-score: 0.7710For batch 227, tr_loss is    0.37.\n",
      "    229/Unknown - 245s 871ms/step - loss: 0.3652 - iou_score: 0.6329 - f1-score: 0.7712For batch 228, tr_loss is    0.37.\n",
      "    230/Unknown - 246s 869ms/step - loss: 0.3654 - iou_score: 0.6327 - f1-score: 0.7710For batch 229, tr_loss is    0.37.\n",
      "    231/Unknown - 246s 866ms/step - loss: 0.3655 - iou_score: 0.6325 - f1-score: 0.7709For batch 230, tr_loss is    0.37.\n",
      "    232/Unknown - 246s 864ms/step - loss: 0.3651 - iou_score: 0.6330 - f1-score: 0.7713For batch 231, tr_loss is    0.37.\n",
      "For batch 0, vl_loss is    0.79.\n",
      "For batch 1, vl_loss is    0.74.\n",
      "For batch 2, vl_loss is    0.78.\n",
      "For batch 3, vl_loss is    0.81.\n",
      "For batch 4, vl_loss is    0.83.\n",
      "For batch 5, vl_loss is    0.82.\n",
      "For batch 6, vl_loss is    0.84.\n",
      "For batch 7, vl_loss is    0.84.\n",
      "For batch 8, vl_loss is    0.82.\n",
      "For batch 9, vl_loss is    0.80.\n",
      "For batch 10, vl_loss is    0.81.\n",
      "For batch 11, vl_loss is    0.81.\n",
      "For batch 12, vl_loss is    0.82.\n",
      "For batch 13, vl_loss is    0.85.\n",
      "For batch 14, vl_loss is    0.84.\n",
      "For batch 15, vl_loss is    0.82.\n",
      "For batch 16, vl_loss is    0.81.\n",
      "For batch 17, vl_loss is    0.82.\n",
      "For batch 18, vl_loss is    0.82.\n",
      "For batch 19, vl_loss is    0.81.\n",
      "For batch 20, vl_loss is    0.80.\n",
      "For batch 21, vl_loss is    0.80.\n",
      "For batch 22, vl_loss is    0.80.\n",
      "For batch 23, vl_loss is    0.80.\n",
      "For batch 24, vl_loss is    0.80.\n",
      "For batch 25, vl_loss is    0.79.\n",
      "For batch 26, vl_loss is    0.80.\n",
      "For batch 27, vl_loss is    0.81.\n",
      "For batch 28, vl_loss is    0.82.\n",
      "For batch 29, vl_loss is    0.83.\n",
      "For batch 30, vl_loss is    0.82.\n",
      "For batch 31, vl_loss is    0.82.\n",
      "For batch 32, vl_loss is    0.82.\n",
      "For batch 33, vl_loss is    0.83.\n",
      "For batch 34, vl_loss is    0.83.\n",
      "For batch 35, vl_loss is    0.83.\n",
      "For batch 36, vl_loss is    0.83.\n",
      "For batch 37, vl_loss is    0.82.\n",
      "For batch 38, vl_loss is    0.82.\n",
      "For batch 39, vl_loss is    0.82.\n",
      "For batch 40, vl_loss is    0.83.\n",
      "For batch 41, vl_loss is    0.84.\n",
      "For batch 42, vl_loss is    0.85.\n",
      "For batch 43, vl_loss is    0.85.\n",
      "For batch 44, vl_loss is    0.85.\n",
      "For batch 45, vl_loss is    0.85.\n",
      "For batch 46, vl_loss is    0.85.\n",
      "For batch 47, vl_loss is    0.85.\n",
      "For batch 48, vl_loss is    0.85.\n",
      "For batch 49, vl_loss is    0.85.\n",
      "For batch 50, vl_loss is    0.85.\n",
      "For batch 51, vl_loss is    0.85.\n",
      "For batch 52, vl_loss is    0.85.\n",
      "For batch 53, vl_loss is    0.85.\n",
      "For batch 54, vl_loss is    0.85.\n",
      "For batch 55, vl_loss is    0.85.\n",
      "For batch 56, vl_loss is    0.84.\n",
      "For batch 57, vl_loss is    0.85.\n",
      "For batch 58, vl_loss is    0.84.\n",
      "For batch 59, vl_loss is    0.84.\n",
      "For batch 60, vl_loss is    0.84.\n",
      "For batch 61, vl_loss is    0.83.\n",
      "For batch 62, vl_loss is    0.83.\n",
      "For batch 63, vl_loss is    0.83.\n",
      "For batch 64, vl_loss is    0.84.\n",
      "For batch 65, vl_loss is    0.83.\n",
      "For batch 66, vl_loss is    0.83.\n",
      "For batch 67, vl_loss is    0.83.\n",
      "232/232 [==============================] - 258s 914ms/step - loss: 0.3651 - iou_score: 0.6330 - f1-score: 0.7713 - val_loss: 0.8321 - val_iou_score: 0.5902 - val_f1-score: 0.7396\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.83207, saving model to ./model/tumor_100_unet_efficientnetb0_imagenet_09291.hdf5\n",
      "The average loss for epoch 0 is    0.37 \n",
      "Epoch 2/200\n",
      "INFO:tensorflow:batch_all_reduce: 130 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/232 [..............................] - ETA: 1:56:21 - loss: 0.2730 - iou_score: 0.7344 - f1-score: 0.8460For batch 0, tr_loss is    0.27.\n",
      "  2/232 [..............................] - ETA: 4:12 - loss: 0.2798 - iou_score: 0.7297 - f1-score: 0.8433   For batch 1, tr_loss is    0.28.\n",
      "  3/232 [..............................] - ETA: 4:14 - loss: 0.2960 - iou_score: 0.6965 - f1-score: 0.8198For batch 2, tr_loss is    0.30.\n",
      "  4/232 [..............................] - ETA: 4:29 - loss: 0.2995 - iou_score: 0.6967 - f1-score: 0.8201For batch 3, tr_loss is    0.30.\n",
      "  5/232 [..............................] - ETA: 4:30 - loss: 0.3099 - iou_score: 0.6872 - f1-score: 0.8132For batch 4, tr_loss is    0.31.\n",
      "  6/232 [..............................] - ETA: 4:25 - loss: 0.3178 - iou_score: 0.6813 - f1-score: 0.8085For batch 5, tr_loss is    0.32.\n",
      "  7/232 [..............................] - ETA: 4:30 - loss: 0.3290 - iou_score: 0.6710 - f1-score: 0.8012For batch 6, tr_loss is    0.33.\n",
      "  8/232 [>.............................] - ETA: 4:35 - loss: 0.3326 - iou_score: 0.6623 - f1-score: 0.7948For batch 7, tr_loss is    0.33.\n",
      "  9/232 [>.............................] - ETA: 4:21 - loss: 0.3235 - iou_score: 0.6731 - f1-score: 0.8024For batch 8, tr_loss is    0.32.\n",
      " 10/232 [>.............................] - ETA: 4:07 - loss: 0.3268 - iou_score: 0.6701 - f1-score: 0.8004For batch 9, tr_loss is    0.33.\n",
      " 11/232 [>.............................] - ETA: 3:54 - loss: 0.3233 - iou_score: 0.6722 - f1-score: 0.8021For batch 10, tr_loss is    0.32.\n",
      " 12/232 [>.............................] - ETA: 3:47 - loss: 0.3188 - iou_score: 0.6790 - f1-score: 0.8068For batch 11, tr_loss is    0.32.\n",
      " 13/232 [>.............................] - ETA: 3:42 - loss: 0.3167 - iou_score: 0.6816 - f1-score: 0.8086For batch 12, tr_loss is    0.32.\n",
      " 14/232 [>.............................] - ETA: 3:34 - loss: 0.3130 - iou_score: 0.6860 - f1-score: 0.8118For batch 13, tr_loss is    0.31.\n",
      " 15/232 [>.............................] - ETA: 3:34 - loss: 0.3114 - iou_score: 0.6877 - f1-score: 0.8131For batch 14, tr_loss is    0.31.\n",
      " 16/232 [=>............................] - ETA: 3:33 - loss: 0.3106 - iou_score: 0.6880 - f1-score: 0.8133For batch 15, tr_loss is    0.31.\n",
      " 17/232 [=>............................] - ETA: 3:30 - loss: 0.3082 - iou_score: 0.6909 - f1-score: 0.8154For batch 16, tr_loss is    0.31.\n",
      " 18/232 [=>............................] - ETA: 3:30 - loss: 0.3077 - iou_score: 0.6909 - f1-score: 0.8155For batch 17, tr_loss is    0.31.\n",
      " 19/232 [=>............................] - ETA: 3:26 - loss: 0.3102 - iou_score: 0.6873 - f1-score: 0.8129For batch 18, tr_loss is    0.31.\n",
      " 20/232 [=>............................] - ETA: 3:25 - loss: 0.3084 - iou_score: 0.6887 - f1-score: 0.8140For batch 19, tr_loss is    0.31.\n",
      " 21/232 [=>............................] - ETA: 3:23 - loss: 0.3132 - iou_score: 0.6850 - f1-score: 0.8113For batch 20, tr_loss is    0.31.\n",
      " 22/232 [=>............................] - ETA: 3:22 - loss: 0.3172 - iou_score: 0.6809 - f1-score: 0.8080For batch 21, tr_loss is    0.32.\n",
      " 23/232 [=>............................] - ETA: 3:17 - loss: 0.3170 - iou_score: 0.6815 - f1-score: 0.8085For batch 22, tr_loss is    0.32.\n",
      " 24/232 [==>...........................] - ETA: 3:13 - loss: 0.3169 - iou_score: 0.6811 - f1-score: 0.8082For batch 23, tr_loss is    0.32.\n",
      " 25/232 [==>...........................] - ETA: 3:10 - loss: 0.3179 - iou_score: 0.6782 - f1-score: 0.8062For batch 24, tr_loss is    0.32.\n",
      " 26/232 [==>...........................] - ETA: 3:09 - loss: 0.3181 - iou_score: 0.6784 - f1-score: 0.8064For batch 25, tr_loss is    0.32.\n",
      " 27/232 [==>...........................] - ETA: 3:05 - loss: 0.3162 - iou_score: 0.6816 - f1-score: 0.8086For batch 26, tr_loss is    0.32.\n",
      " 28/232 [==>...........................] - ETA: 3:06 - loss: 0.3164 - iou_score: 0.6814 - f1-score: 0.8085For batch 27, tr_loss is    0.32.\n",
      " 29/232 [==>...........................] - ETA: 3:06 - loss: 0.3175 - iou_score: 0.6787 - f1-score: 0.8064For batch 28, tr_loss is    0.32.\n",
      " 30/232 [==>...........................] - ETA: 3:06 - loss: 0.3162 - iou_score: 0.6806 - f1-score: 0.8077For batch 29, tr_loss is    0.32.\n",
      " 31/232 [===>..........................] - ETA: 3:05 - loss: 0.3168 - iou_score: 0.6806 - f1-score: 0.8078For batch 30, tr_loss is    0.32.\n",
      " 32/232 [===>..........................] - ETA: 3:05 - loss: 0.3165 - iou_score: 0.6809 - f1-score: 0.8081For batch 31, tr_loss is    0.32.\n",
      " 33/232 [===>..........................] - ETA: 3:01 - loss: 0.3184 - iou_score: 0.6782 - f1-score: 0.8061For batch 32, tr_loss is    0.32.\n",
      " 34/232 [===>..........................] - ETA: 2:59 - loss: 0.3180 - iou_score: 0.6786 - f1-score: 0.8064For batch 33, tr_loss is    0.32.\n",
      " 35/232 [===>..........................] - ETA: 2:57 - loss: 0.3182 - iou_score: 0.6775 - f1-score: 0.8057For batch 34, tr_loss is    0.32.\n",
      " 36/232 [===>..........................] - ETA: 2:57 - loss: 0.3179 - iou_score: 0.6778 - f1-score: 0.8059For batch 35, tr_loss is    0.32.\n",
      " 37/232 [===>..........................] - ETA: 2:57 - loss: 0.3177 - iou_score: 0.6776 - f1-score: 0.8059For batch 36, tr_loss is    0.32.\n",
      " 38/232 [===>..........................] - ETA: 2:57 - loss: 0.3188 - iou_score: 0.6764 - f1-score: 0.8051For batch 37, tr_loss is    0.32.\n",
      " 39/232 [====>.........................] - ETA: 2:55 - loss: 0.3223 - iou_score: 0.6733 - f1-score: 0.8027For batch 38, tr_loss is    0.32.\n",
      " 40/232 [====>.........................] - ETA: 2:55 - loss: 0.3233 - iou_score: 0.6729 - f1-score: 0.8023For batch 39, tr_loss is    0.32.\n",
      " 41/232 [====>.........................] - ETA: 2:54 - loss: 0.3245 - iou_score: 0.6720 - f1-score: 0.8017For batch 40, tr_loss is    0.32.\n",
      " 42/232 [====>.........................] - ETA: 2:53 - loss: 0.3251 - iou_score: 0.6705 - f1-score: 0.8006For batch 41, tr_loss is    0.33.\n",
      " 43/232 [====>.........................] - ETA: 2:52 - loss: 0.3243 - iou_score: 0.6717 - f1-score: 0.8015For batch 42, tr_loss is    0.32.\n",
      " 44/232 [====>.........................] - ETA: 2:50 - loss: 0.3268 - iou_score: 0.6690 - f1-score: 0.7993For batch 43, tr_loss is    0.33.\n",
      " 45/232 [====>.........................] - ETA: 2:50 - loss: 0.3280 - iou_score: 0.6680 - f1-score: 0.7986For batch 44, tr_loss is    0.33.\n",
      " 46/232 [====>.........................] - ETA: 2:48 - loss: 0.3281 - iou_score: 0.6684 - f1-score: 0.7989For batch 45, tr_loss is    0.33.\n",
      " 47/232 [=====>........................] - ETA: 2:46 - loss: 0.3280 - iou_score: 0.6688 - f1-score: 0.7992For batch 46, tr_loss is    0.33.\n",
      " 48/232 [=====>........................] - ETA: 2:44 - loss: 0.3270 - iou_score: 0.6703 - f1-score: 0.8003For batch 47, tr_loss is    0.33.\n",
      " 49/232 [=====>........................] - ETA: 2:42 - loss: 0.3268 - iou_score: 0.6705 - f1-score: 0.8005For batch 48, tr_loss is    0.33.\n",
      " 50/232 [=====>........................] - ETA: 2:42 - loss: 0.3264 - iou_score: 0.6708 - f1-score: 0.8007For batch 49, tr_loss is    0.33.\n",
      " 51/232 [=====>........................] - ETA: 2:40 - loss: 0.3289 - iou_score: 0.6683 - f1-score: 0.7989For batch 50, tr_loss is    0.33.\n",
      " 52/232 [=====>........................] - ETA: 2:38 - loss: 0.3311 - iou_score: 0.6661 - f1-score: 0.7972For batch 51, tr_loss is    0.33.\n",
      " 53/232 [=====>........................] - ETA: 2:38 - loss: 0.3301 - iou_score: 0.6672 - f1-score: 0.7979For batch 52, tr_loss is    0.33.\n",
      " 54/232 [=====>........................] - ETA: 2:37 - loss: 0.3304 - iou_score: 0.6664 - f1-score: 0.7974For batch 53, tr_loss is    0.33.\n",
      " 55/232 [======>.......................] - ETA: 2:36 - loss: 0.3298 - iou_score: 0.6668 - f1-score: 0.7977For batch 54, tr_loss is    0.33.\n",
      " 56/232 [======>.......................] - ETA: 2:36 - loss: 0.3296 - iou_score: 0.6669 - f1-score: 0.7978For batch 55, tr_loss is    0.33.\n",
      " 57/232 [======>.......................] - ETA: 2:35 - loss: 0.3307 - iou_score: 0.6657 - f1-score: 0.7969For batch 56, tr_loss is    0.33.\n",
      " 58/232 [======>.......................] - ETA: 2:35 - loss: 0.3301 - iou_score: 0.6664 - f1-score: 0.7974For batch 57, tr_loss is    0.33.\n",
      " 59/232 [======>.......................] - ETA: 2:33 - loss: 0.3295 - iou_score: 0.6670 - f1-score: 0.7979For batch 58, tr_loss is    0.33.\n",
      " 60/232 [======>.......................] - ETA: 2:33 - loss: 0.3307 - iou_score: 0.6659 - f1-score: 0.7971For batch 59, tr_loss is    0.33.\n",
      " 61/232 [======>.......................] - ETA: 2:32 - loss: 0.3318 - iou_score: 0.6649 - f1-score: 0.7962For batch 60, tr_loss is    0.33.\n",
      " 62/232 [=======>......................] - ETA: 2:31 - loss: 0.3327 - iou_score: 0.6640 - f1-score: 0.7955For batch 61, tr_loss is    0.33.\n",
      " 63/232 [=======>......................] - ETA: 2:31 - loss: 0.3322 - iou_score: 0.6646 - f1-score: 0.7960For batch 62, tr_loss is    0.33.\n",
      " 64/232 [=======>......................] - ETA: 2:30 - loss: 0.3325 - iou_score: 0.6642 - f1-score: 0.7958For batch 63, tr_loss is    0.33.\n",
      " 65/232 [=======>......................] - ETA: 2:29 - loss: 0.3327 - iou_score: 0.6641 - f1-score: 0.7957For batch 64, tr_loss is    0.33.\n",
      " 66/232 [=======>......................] - ETA: 2:28 - loss: 0.3330 - iou_score: 0.6634 - f1-score: 0.7951For batch 65, tr_loss is    0.33.\n",
      " 67/232 [=======>......................] - ETA: 2:28 - loss: 0.3320 - iou_score: 0.6644 - f1-score: 0.7958For batch 66, tr_loss is    0.33.\n",
      " 68/232 [=======>......................] - ETA: 2:27 - loss: 0.3316 - iou_score: 0.6648 - f1-score: 0.7961For batch 67, tr_loss is    0.33.\n",
      " 69/232 [=======>......................] - ETA: 2:26 - loss: 0.3315 - iou_score: 0.6650 - f1-score: 0.7963For batch 68, tr_loss is    0.33.\n",
      " 70/232 [========>.....................] - ETA: 2:25 - loss: 0.3308 - iou_score: 0.6655 - f1-score: 0.7967For batch 69, tr_loss is    0.33.\n",
      " 71/232 [========>.....................] - ETA: 2:25 - loss: 0.3304 - iou_score: 0.6661 - f1-score: 0.7972For batch 70, tr_loss is    0.33.\n",
      " 72/232 [========>.....................] - ETA: 2:24 - loss: 0.3295 - iou_score: 0.6672 - f1-score: 0.7979For batch 71, tr_loss is    0.33.\n",
      " 73/232 [========>.....................] - ETA: 2:22 - loss: 0.3296 - iou_score: 0.6670 - f1-score: 0.7978For batch 72, tr_loss is    0.33.\n",
      " 74/232 [========>.....................] - ETA: 2:22 - loss: 0.3289 - iou_score: 0.6679 - f1-score: 0.7984For batch 73, tr_loss is    0.33.\n",
      " 75/232 [========>.....................] - ETA: 2:21 - loss: 0.3289 - iou_score: 0.6680 - f1-score: 0.7985For batch 74, tr_loss is    0.33.\n",
      " 76/232 [========>.....................] - ETA: 2:20 - loss: 0.3287 - iou_score: 0.6679 - f1-score: 0.7984For batch 75, tr_loss is    0.33.\n",
      " 77/232 [========>.....................] - ETA: 2:19 - loss: 0.3278 - iou_score: 0.6686 - f1-score: 0.7990For batch 76, tr_loss is    0.33.\n",
      " 78/232 [=========>....................] - ETA: 2:19 - loss: 0.3278 - iou_score: 0.6682 - f1-score: 0.7987For batch 77, tr_loss is    0.33.\n",
      " 79/232 [=========>....................] - ETA: 2:18 - loss: 0.3270 - iou_score: 0.6690 - f1-score: 0.7993For batch 78, tr_loss is    0.33.\n",
      " 80/232 [=========>....................] - ETA: 2:17 - loss: 0.3269 - iou_score: 0.6691 - f1-score: 0.7994For batch 79, tr_loss is    0.33.\n",
      " 81/232 [=========>....................] - ETA: 2:16 - loss: 0.3269 - iou_score: 0.6689 - f1-score: 0.7992For batch 80, tr_loss is    0.33.\n",
      " 82/232 [=========>....................] - ETA: 2:16 - loss: 0.3270 - iou_score: 0.6689 - f1-score: 0.7992For batch 81, tr_loss is    0.33.\n",
      " 83/232 [=========>....................] - ETA: 2:15 - loss: 0.3281 - iou_score: 0.6674 - f1-score: 0.7981For batch 82, tr_loss is    0.33.\n",
      " 84/232 [=========>....................] - ETA: 2:14 - loss: 0.3286 - iou_score: 0.6670 - f1-score: 0.7978For batch 83, tr_loss is    0.33.\n",
      " 85/232 [=========>....................] - ETA: 2:14 - loss: 0.3289 - iou_score: 0.6666 - f1-score: 0.7975For batch 84, tr_loss is    0.33.\n",
      " 86/232 [==========>...................] - ETA: 2:13 - loss: 0.3293 - iou_score: 0.6661 - f1-score: 0.7972For batch 85, tr_loss is    0.33.\n",
      " 87/232 [==========>...................] - ETA: 2:12 - loss: 0.3292 - iou_score: 0.6662 - f1-score: 0.7973For batch 86, tr_loss is    0.33.\n",
      " 88/232 [==========>...................] - ETA: 2:11 - loss: 0.3299 - iou_score: 0.6652 - f1-score: 0.7965For batch 87, tr_loss is    0.33.\n",
      " 89/232 [==========>...................] - ETA: 2:09 - loss: 0.3298 - iou_score: 0.6655 - f1-score: 0.7968For batch 88, tr_loss is    0.33.\n",
      " 90/232 [==========>...................] - ETA: 2:09 - loss: 0.3292 - iou_score: 0.6663 - f1-score: 0.7974For batch 89, tr_loss is    0.33.\n",
      " 91/232 [==========>...................] - ETA: 2:08 - loss: 0.3290 - iou_score: 0.6666 - f1-score: 0.7976For batch 90, tr_loss is    0.33.\n",
      " 92/232 [==========>...................] - ETA: 2:07 - loss: 0.3290 - iou_score: 0.6665 - f1-score: 0.7975For batch 91, tr_loss is    0.33.\n",
      " 93/232 [===========>..................] - ETA: 2:05 - loss: 0.3299 - iou_score: 0.6654 - f1-score: 0.7967For batch 92, tr_loss is    0.33.\n",
      " 94/232 [===========>..................] - ETA: 2:05 - loss: 0.3289 - iou_score: 0.6664 - f1-score: 0.7974For batch 93, tr_loss is    0.33.\n",
      " 95/232 [===========>..................] - ETA: 2:04 - loss: 0.3292 - iou_score: 0.6662 - f1-score: 0.7972For batch 94, tr_loss is    0.33.\n",
      " 96/232 [===========>..................] - ETA: 2:03 - loss: 0.3289 - iou_score: 0.6665 - f1-score: 0.7974For batch 95, tr_loss is    0.33.\n",
      " 97/232 [===========>..................] - ETA: 2:02 - loss: 0.3294 - iou_score: 0.6658 - f1-score: 0.7970For batch 96, tr_loss is    0.33.\n",
      " 98/232 [===========>..................] - ETA: 2:01 - loss: 0.3293 - iou_score: 0.6659 - f1-score: 0.7971For batch 97, tr_loss is    0.33.\n",
      " 99/232 [===========>..................] - ETA: 1:59 - loss: 0.3288 - iou_score: 0.6666 - f1-score: 0.7975For batch 98, tr_loss is    0.33.\n",
      "100/232 [===========>..................] - ETA: 1:58 - loss: 0.3282 - iou_score: 0.6674 - f1-score: 0.7981For batch 99, tr_loss is    0.33.\n",
      "101/232 [============>.................] - ETA: 1:58 - loss: 0.3275 - iou_score: 0.6682 - f1-score: 0.7987For batch 100, tr_loss is    0.33.\n",
      "102/232 [============>.................] - ETA: 1:57 - loss: 0.3275 - iou_score: 0.6683 - f1-score: 0.7987For batch 101, tr_loss is    0.33.\n",
      "103/232 [============>.................] - ETA: 1:56 - loss: 0.3276 - iou_score: 0.6683 - f1-score: 0.7987For batch 102, tr_loss is    0.33.\n",
      "104/232 [============>.................] - ETA: 1:55 - loss: 0.3276 - iou_score: 0.6683 - f1-score: 0.7988For batch 103, tr_loss is    0.33.\n",
      "105/232 [============>.................] - ETA: 1:54 - loss: 0.3267 - iou_score: 0.6693 - f1-score: 0.7994For batch 104, tr_loss is    0.33.\n",
      "106/232 [============>.................] - ETA: 1:53 - loss: 0.3260 - iou_score: 0.6701 - f1-score: 0.8000For batch 105, tr_loss is    0.33.\n",
      "107/232 [============>.................] - ETA: 1:52 - loss: 0.3262 - iou_score: 0.6699 - f1-score: 0.7999For batch 106, tr_loss is    0.33.\n",
      "108/232 [============>.................] - ETA: 1:52 - loss: 0.3266 - iou_score: 0.6692 - f1-score: 0.7994For batch 107, tr_loss is    0.33.\n",
      "109/232 [=============>................] - ETA: 1:50 - loss: 0.3260 - iou_score: 0.6698 - f1-score: 0.7998For batch 108, tr_loss is    0.33.\n",
      "110/232 [=============>................] - ETA: 1:49 - loss: 0.3251 - iou_score: 0.6708 - f1-score: 0.8005For batch 109, tr_loss is    0.33.\n",
      "111/232 [=============>................] - ETA: 1:49 - loss: 0.3252 - iou_score: 0.6705 - f1-score: 0.8003For batch 110, tr_loss is    0.33.\n",
      "112/232 [=============>................] - ETA: 1:48 - loss: 0.3259 - iou_score: 0.6698 - f1-score: 0.7998For batch 111, tr_loss is    0.33.\n",
      "113/232 [=============>................] - ETA: 1:47 - loss: 0.3265 - iou_score: 0.6697 - f1-score: 0.7998For batch 112, tr_loss is    0.33.\n",
      "114/232 [=============>................] - ETA: 1:46 - loss: 0.3258 - iou_score: 0.6706 - f1-score: 0.8004For batch 113, tr_loss is    0.33.\n",
      "115/232 [=============>................] - ETA: 1:45 - loss: 0.3254 - iou_score: 0.6710 - f1-score: 0.8007For batch 114, tr_loss is    0.33.\n",
      "116/232 [==============>...............] - ETA: 1:44 - loss: 0.3249 - iou_score: 0.6715 - f1-score: 0.8010For batch 115, tr_loss is    0.32.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/232 [==============>...............] - ETA: 1:43 - loss: 0.3247 - iou_score: 0.6717 - f1-score: 0.8012For batch 116, tr_loss is    0.32.\n",
      "118/232 [==============>...............] - ETA: 1:42 - loss: 0.3241 - iou_score: 0.6724 - f1-score: 0.8017For batch 117, tr_loss is    0.32.\n",
      "119/232 [==============>...............] - ETA: 1:41 - loss: 0.3235 - iou_score: 0.6732 - f1-score: 0.8022For batch 118, tr_loss is    0.32.\n",
      "120/232 [==============>...............] - ETA: 1:40 - loss: 0.3238 - iou_score: 0.6729 - f1-score: 0.8021For batch 119, tr_loss is    0.32.\n",
      "121/232 [==============>...............] - ETA: 1:39 - loss: 0.3231 - iou_score: 0.6738 - f1-score: 0.8026For batch 120, tr_loss is    0.32.\n",
      "122/232 [==============>...............] - ETA: 1:39 - loss: 0.3236 - iou_score: 0.6732 - f1-score: 0.8022For batch 121, tr_loss is    0.32.\n",
      "123/232 [==============>...............] - ETA: 1:37 - loss: 0.3233 - iou_score: 0.6735 - f1-score: 0.8024For batch 122, tr_loss is    0.32.\n",
      "124/232 [===============>..............] - ETA: 1:36 - loss: 0.3233 - iou_score: 0.6735 - f1-score: 0.8025For batch 123, tr_loss is    0.32.\n",
      "125/232 [===============>..............] - ETA: 1:35 - loss: 0.3234 - iou_score: 0.6732 - f1-score: 0.8023For batch 124, tr_loss is    0.32.\n",
      "126/232 [===============>..............] - ETA: 1:35 - loss: 0.3232 - iou_score: 0.6736 - f1-score: 0.8025For batch 125, tr_loss is    0.32.\n",
      "127/232 [===============>..............] - ETA: 1:34 - loss: 0.3231 - iou_score: 0.6734 - f1-score: 0.8024For batch 126, tr_loss is    0.32.\n",
      "128/232 [===============>..............] - ETA: 1:33 - loss: 0.3234 - iou_score: 0.6728 - f1-score: 0.8019For batch 127, tr_loss is    0.32.\n",
      "129/232 [===============>..............] - ETA: 1:31 - loss: 0.3237 - iou_score: 0.6722 - f1-score: 0.8015For batch 128, tr_loss is    0.32.\n",
      "130/232 [===============>..............] - ETA: 1:31 - loss: 0.3238 - iou_score: 0.6727 - f1-score: 0.8019For batch 129, tr_loss is    0.32.\n",
      "131/232 [===============>..............] - ETA: 1:30 - loss: 0.3245 - iou_score: 0.6721 - f1-score: 0.8014For batch 130, tr_loss is    0.32.\n",
      "132/232 [================>.............] - ETA: 1:29 - loss: 0.3248 - iou_score: 0.6720 - f1-score: 0.8013For batch 131, tr_loss is    0.32.\n",
      "133/232 [================>.............] - ETA: 1:28 - loss: 0.3245 - iou_score: 0.6724 - f1-score: 0.8016For batch 132, tr_loss is    0.32.\n",
      "134/232 [================>.............] - ETA: 1:27 - loss: 0.3251 - iou_score: 0.6715 - f1-score: 0.8010For batch 133, tr_loss is    0.33.\n",
      "135/232 [================>.............] - ETA: 1:26 - loss: 0.3247 - iou_score: 0.6719 - f1-score: 0.8013For batch 134, tr_loss is    0.32.\n",
      "136/232 [================>.............] - ETA: 1:25 - loss: 0.3250 - iou_score: 0.6714 - f1-score: 0.8009For batch 135, tr_loss is    0.32.\n",
      "137/232 [================>.............] - ETA: 1:24 - loss: 0.3250 - iou_score: 0.6713 - f1-score: 0.8009For batch 136, tr_loss is    0.33.\n",
      "138/232 [================>.............] - ETA: 1:23 - loss: 0.3249 - iou_score: 0.6714 - f1-score: 0.8010For batch 137, tr_loss is    0.32.\n",
      "139/232 [================>.............] - ETA: 1:22 - loss: 0.3247 - iou_score: 0.6716 - f1-score: 0.8011For batch 138, tr_loss is    0.32.\n",
      "140/232 [=================>............] - ETA: 1:21 - loss: 0.3246 - iou_score: 0.6718 - f1-score: 0.8013For batch 139, tr_loss is    0.32.\n",
      "141/232 [=================>............] - ETA: 1:20 - loss: 0.3253 - iou_score: 0.6710 - f1-score: 0.8006For batch 140, tr_loss is    0.33.\n",
      "142/232 [=================>............] - ETA: 1:20 - loss: 0.3253 - iou_score: 0.6709 - f1-score: 0.8006For batch 141, tr_loss is    0.33.\n",
      "143/232 [=================>............] - ETA: 1:19 - loss: 0.3250 - iou_score: 0.6711 - f1-score: 0.8007For batch 142, tr_loss is    0.32.\n",
      "144/232 [=================>............] - ETA: 1:18 - loss: 0.3249 - iou_score: 0.6710 - f1-score: 0.8007For batch 143, tr_loss is    0.32.\n",
      "145/232 [=================>............] - ETA: 1:17 - loss: 0.3248 - iou_score: 0.6711 - f1-score: 0.8008For batch 144, tr_loss is    0.32.\n",
      "146/232 [=================>............] - ETA: 1:16 - loss: 0.3248 - iou_score: 0.6709 - f1-score: 0.8006For batch 145, tr_loss is    0.32.\n",
      "147/232 [==================>...........] - ETA: 1:16 - loss: 0.3246 - iou_score: 0.6713 - f1-score: 0.8009For batch 146, tr_loss is    0.32.\n",
      "148/232 [==================>...........] - ETA: 1:15 - loss: 0.3249 - iou_score: 0.6709 - f1-score: 0.8006For batch 147, tr_loss is    0.32.\n",
      "149/232 [==================>...........] - ETA: 1:14 - loss: 0.3247 - iou_score: 0.6713 - f1-score: 0.8009For batch 148, tr_loss is    0.32.\n",
      "150/232 [==================>...........] - ETA: 1:13 - loss: 0.3253 - iou_score: 0.6706 - f1-score: 0.8004For batch 149, tr_loss is    0.33.\n",
      "151/232 [==================>...........] - ETA: 1:12 - loss: 0.3255 - iou_score: 0.6704 - f1-score: 0.8002For batch 150, tr_loss is    0.33.\n",
      "152/232 [==================>...........] - ETA: 1:11 - loss: 0.3251 - iou_score: 0.6708 - f1-score: 0.8005For batch 151, tr_loss is    0.33.\n",
      "153/232 [==================>...........] - ETA: 1:10 - loss: 0.3250 - iou_score: 0.6707 - f1-score: 0.8004For batch 152, tr_loss is    0.33.\n",
      "154/232 [==================>...........] - ETA: 1:09 - loss: 0.3248 - iou_score: 0.6709 - f1-score: 0.8006For batch 153, tr_loss is    0.32.\n",
      "155/232 [===================>..........] - ETA: 1:08 - loss: 0.3247 - iou_score: 0.6707 - f1-score: 0.8005For batch 154, tr_loss is    0.32.\n",
      "156/232 [===================>..........] - ETA: 1:07 - loss: 0.3249 - iou_score: 0.6704 - f1-score: 0.8003For batch 155, tr_loss is    0.32.\n",
      "157/232 [===================>..........] - ETA: 1:06 - loss: 0.3253 - iou_score: 0.6701 - f1-score: 0.8000For batch 156, tr_loss is    0.33.\n",
      "158/232 [===================>..........] - ETA: 1:05 - loss: 0.3249 - iou_score: 0.6705 - f1-score: 0.8003For batch 157, tr_loss is    0.32.\n",
      "159/232 [===================>..........] - ETA: 1:04 - loss: 0.3248 - iou_score: 0.6708 - f1-score: 0.8005For batch 158, tr_loss is    0.32.\n",
      "160/232 [===================>..........] - ETA: 1:03 - loss: 0.3249 - iou_score: 0.6705 - f1-score: 0.8003For batch 159, tr_loss is    0.32.\n",
      "161/232 [===================>..........] - ETA: 1:02 - loss: 0.3245 - iou_score: 0.6709 - f1-score: 0.8006For batch 160, tr_loss is    0.32.\n",
      "162/232 [===================>..........] - ETA: 1:02 - loss: 0.3245 - iou_score: 0.6707 - f1-score: 0.8004For batch 161, tr_loss is    0.32.\n",
      "163/232 [====================>.........] - ETA: 1:01 - loss: 0.3241 - iou_score: 0.6711 - f1-score: 0.8007For batch 162, tr_loss is    0.32.\n",
      "164/232 [====================>.........] - ETA: 1:00 - loss: 0.3241 - iou_score: 0.6710 - f1-score: 0.8007For batch 163, tr_loss is    0.32.\n",
      "165/232 [====================>.........] - ETA: 59s - loss: 0.3242 - iou_score: 0.6709 - f1-score: 0.8006 For batch 164, tr_loss is    0.32.\n",
      "166/232 [====================>.........] - ETA: 58s - loss: 0.3241 - iou_score: 0.6710 - f1-score: 0.8007For batch 165, tr_loss is    0.32.\n",
      "167/232 [====================>.........] - ETA: 57s - loss: 0.3239 - iou_score: 0.6712 - f1-score: 0.8008For batch 166, tr_loss is    0.32.\n",
      "168/232 [====================>.........] - ETA: 56s - loss: 0.3242 - iou_score: 0.6709 - f1-score: 0.8006For batch 167, tr_loss is    0.32.\n",
      "169/232 [====================>.........] - ETA: 55s - loss: 0.3245 - iou_score: 0.6705 - f1-score: 0.8003For batch 168, tr_loss is    0.32.\n",
      "170/232 [====================>.........] - ETA: 54s - loss: 0.3246 - iou_score: 0.6705 - f1-score: 0.8003For batch 169, tr_loss is    0.32.\n",
      "171/232 [=====================>........] - ETA: 53s - loss: 0.3250 - iou_score: 0.6700 - f1-score: 0.7999For batch 170, tr_loss is    0.33.\n",
      "172/232 [=====================>........] - ETA: 53s - loss: 0.3252 - iou_score: 0.6697 - f1-score: 0.7997For batch 171, tr_loss is    0.33.\n",
      "173/232 [=====================>........] - ETA: 52s - loss: 0.3253 - iou_score: 0.6693 - f1-score: 0.7995For batch 172, tr_loss is    0.33.\n",
      "174/232 [=====================>........] - ETA: 51s - loss: 0.3250 - iou_score: 0.6697 - f1-score: 0.7997For batch 173, tr_loss is    0.33.\n",
      "175/232 [=====================>........] - ETA: 50s - loss: 0.3250 - iou_score: 0.6696 - f1-score: 0.7997For batch 174, tr_loss is    0.33.\n",
      "176/232 [=====================>........] - ETA: 49s - loss: 0.3252 - iou_score: 0.6693 - f1-score: 0.7995For batch 175, tr_loss is    0.33.\n",
      "177/232 [=====================>........] - ETA: 48s - loss: 0.3251 - iou_score: 0.6696 - f1-score: 0.7997For batch 176, tr_loss is    0.33.\n",
      "178/232 [======================>.......] - ETA: 47s - loss: 0.3252 - iou_score: 0.6697 - f1-score: 0.7997For batch 177, tr_loss is    0.33.\n",
      "179/232 [======================>.......] - ETA: 46s - loss: 0.3250 - iou_score: 0.6699 - f1-score: 0.7999For batch 178, tr_loss is    0.32.\n",
      "180/232 [======================>.......] - ETA: 45s - loss: 0.3250 - iou_score: 0.6699 - f1-score: 0.7999For batch 179, tr_loss is    0.32.\n",
      "181/232 [======================>.......] - ETA: 44s - loss: 0.3250 - iou_score: 0.6698 - f1-score: 0.7998For batch 180, tr_loss is    0.33.\n",
      "182/232 [======================>.......] - ETA: 43s - loss: 0.3248 - iou_score: 0.6699 - f1-score: 0.8000For batch 181, tr_loss is    0.32.\n",
      "183/232 [======================>.......] - ETA: 42s - loss: 0.3248 - iou_score: 0.6700 - f1-score: 0.8000For batch 182, tr_loss is    0.32.\n",
      "184/232 [======================>.......] - ETA: 42s - loss: 0.3245 - iou_score: 0.6704 - f1-score: 0.8003For batch 183, tr_loss is    0.32.\n",
      "185/232 [======================>.......] - ETA: 41s - loss: 0.3247 - iou_score: 0.6702 - f1-score: 0.8002For batch 184, tr_loss is    0.32.\n",
      "186/232 [=======================>......] - ETA: 40s - loss: 0.3248 - iou_score: 0.6702 - f1-score: 0.8002For batch 185, tr_loss is    0.32.\n",
      "187/232 [=======================>......] - ETA: 39s - loss: 0.3243 - iou_score: 0.6707 - f1-score: 0.8005For batch 186, tr_loss is    0.32.\n",
      "188/232 [=======================>......] - ETA: 38s - loss: 0.3245 - iou_score: 0.6705 - f1-score: 0.8003For batch 187, tr_loss is    0.32.\n",
      "189/232 [=======================>......] - ETA: 37s - loss: 0.3244 - iou_score: 0.6706 - f1-score: 0.8004For batch 188, tr_loss is    0.32.\n",
      "190/232 [=======================>......] - ETA: 36s - loss: 0.3242 - iou_score: 0.6707 - f1-score: 0.8005For batch 189, tr_loss is    0.32.\n",
      "191/232 [=======================>......] - ETA: 35s - loss: 0.3242 - iou_score: 0.6708 - f1-score: 0.8006For batch 190, tr_loss is    0.32.\n",
      "192/232 [=======================>......] - ETA: 35s - loss: 0.3243 - iou_score: 0.6705 - f1-score: 0.8004For batch 191, tr_loss is    0.32.\n",
      "193/232 [=======================>......] - ETA: 34s - loss: 0.3246 - iou_score: 0.6701 - f1-score: 0.8001For batch 192, tr_loss is    0.32.\n",
      "194/232 [========================>.....] - ETA: 33s - loss: 0.3246 - iou_score: 0.6699 - f1-score: 0.7999For batch 193, tr_loss is    0.32.\n",
      "195/232 [========================>.....] - ETA: 32s - loss: 0.3245 - iou_score: 0.6699 - f1-score: 0.7999For batch 194, tr_loss is    0.32.\n",
      "196/232 [========================>.....] - ETA: 31s - loss: 0.3244 - iou_score: 0.6698 - f1-score: 0.7999For batch 195, tr_loss is    0.32.\n",
      "197/232 [========================>.....] - ETA: 30s - loss: 0.3243 - iou_score: 0.6699 - f1-score: 0.7999For batch 196, tr_loss is    0.32.\n",
      "198/232 [========================>.....] - ETA: 29s - loss: 0.3239 - iou_score: 0.6706 - f1-score: 0.8004For batch 197, tr_loss is    0.32.\n",
      "199/232 [========================>.....] - ETA: 28s - loss: 0.3237 - iou_score: 0.6707 - f1-score: 0.8005For batch 198, tr_loss is    0.32.\n",
      "200/232 [========================>.....] - ETA: 28s - loss: 0.3233 - iou_score: 0.6712 - f1-score: 0.8008For batch 199, tr_loss is    0.32.\n",
      "201/232 [========================>.....] - ETA: 27s - loss: 0.3233 - iou_score: 0.6711 - f1-score: 0.8008For batch 200, tr_loss is    0.32.\n",
      "202/232 [=========================>....] - ETA: 26s - loss: 0.3231 - iou_score: 0.6712 - f1-score: 0.8008For batch 201, tr_loss is    0.32.\n",
      "203/232 [=========================>....] - ETA: 25s - loss: 0.3227 - iou_score: 0.6715 - f1-score: 0.8010For batch 202, tr_loss is    0.32.\n",
      "204/232 [=========================>....] - ETA: 24s - loss: 0.3222 - iou_score: 0.6721 - f1-score: 0.8014For batch 203, tr_loss is    0.32.\n",
      "205/232 [=========================>....] - ETA: 23s - loss: 0.3223 - iou_score: 0.6718 - f1-score: 0.8013For batch 204, tr_loss is    0.32.\n",
      "206/232 [=========================>....] - ETA: 22s - loss: 0.3227 - iou_score: 0.6717 - f1-score: 0.8011For batch 205, tr_loss is    0.32.\n",
      "207/232 [=========================>....] - ETA: 21s - loss: 0.3224 - iou_score: 0.6719 - f1-score: 0.8013For batch 206, tr_loss is    0.32.\n",
      "208/232 [=========================>....] - ETA: 20s - loss: 0.3224 - iou_score: 0.6719 - f1-score: 0.8013For batch 207, tr_loss is    0.32.\n",
      "209/232 [==========================>...] - ETA: 20s - loss: 0.3226 - iou_score: 0.6717 - f1-score: 0.8012For batch 208, tr_loss is    0.32.\n",
      "210/232 [==========================>...] - ETA: 19s - loss: 0.3228 - iou_score: 0.6715 - f1-score: 0.8010For batch 209, tr_loss is    0.32.\n",
      "211/232 [==========================>...] - ETA: 18s - loss: 0.3225 - iou_score: 0.6719 - f1-score: 0.8013For batch 210, tr_loss is    0.32.\n",
      "212/232 [==========================>...] - ETA: 17s - loss: 0.3222 - iou_score: 0.6722 - f1-score: 0.8015For batch 211, tr_loss is    0.32.\n",
      "213/232 [==========================>...] - ETA: 16s - loss: 0.3225 - iou_score: 0.6721 - f1-score: 0.8014For batch 212, tr_loss is    0.32.\n",
      "214/232 [==========================>...] - ETA: 15s - loss: 0.3222 - iou_score: 0.6723 - f1-score: 0.8016For batch 213, tr_loss is    0.32.\n",
      "215/232 [==========================>...] - ETA: 14s - loss: 0.3219 - iou_score: 0.6727 - f1-score: 0.8019For batch 214, tr_loss is    0.32.\n",
      "216/232 [==========================>...] - ETA: 14s - loss: 0.3218 - iou_score: 0.6728 - f1-score: 0.8020For batch 215, tr_loss is    0.32.\n",
      "217/232 [===========================>..] - ETA: 13s - loss: 0.3218 - iou_score: 0.6727 - f1-score: 0.8019For batch 216, tr_loss is    0.32.\n",
      "218/232 [===========================>..] - ETA: 12s - loss: 0.3217 - iou_score: 0.6727 - f1-score: 0.8019For batch 217, tr_loss is    0.32.\n",
      "219/232 [===========================>..] - ETA: 11s - loss: 0.3223 - iou_score: 0.6721 - f1-score: 0.8015For batch 218, tr_loss is    0.32.\n",
      "220/232 [===========================>..] - ETA: 10s - loss: 0.3222 - iou_score: 0.6721 - f1-score: 0.8015For batch 219, tr_loss is    0.32.\n",
      "221/232 [===========================>..] - ETA: 9s - loss: 0.3224 - iou_score: 0.6719 - f1-score: 0.8013 For batch 220, tr_loss is    0.32.\n",
      "222/232 [===========================>..] - ETA: 8s - loss: 0.3221 - iou_score: 0.6722 - f1-score: 0.8016For batch 221, tr_loss is    0.32.\n",
      "223/232 [===========================>..] - ETA: 7s - loss: 0.3222 - iou_score: 0.6721 - f1-score: 0.8015For batch 222, tr_loss is    0.32.\n",
      "224/232 [===========================>..] - ETA: 6s - loss: 0.3219 - iou_score: 0.6725 - f1-score: 0.8017For batch 223, tr_loss is    0.32.\n",
      "225/232 [============================>.] - ETA: 6s - loss: 0.3216 - iou_score: 0.6728 - f1-score: 0.8020For batch 224, tr_loss is    0.32.\n",
      "226/232 [============================>.] - ETA: 5s - loss: 0.3216 - iou_score: 0.6728 - f1-score: 0.8020For batch 225, tr_loss is    0.32.\n",
      "227/232 [============================>.] - ETA: 4s - loss: 0.3214 - iou_score: 0.6730 - f1-score: 0.8021For batch 226, tr_loss is    0.32.\n",
      "228/232 [============================>.] - ETA: 3s - loss: 0.3214 - iou_score: 0.6729 - f1-score: 0.8021For batch 227, tr_loss is    0.32.\n",
      "229/232 [============================>.] - ETA: 2s - loss: 0.3211 - iou_score: 0.6731 - f1-score: 0.8022For batch 228, tr_loss is    0.32.\n",
      "230/232 [============================>.] - ETA: 1s - loss: 0.3215 - iou_score: 0.6728 - f1-score: 0.8020For batch 229, tr_loss is    0.32.\n",
      "231/232 [============================>.] - ETA: 0s - loss: 0.3217 - iou_score: 0.6726 - f1-score: 0.8018For batch 230, tr_loss is    0.32.\n",
      "232/232 [==============================] - ETA: 0s - loss: 0.3214 - iou_score: 0.6729 - f1-score: 0.8021For batch 231, tr_loss is    0.32.\n",
      "For batch 0, vl_loss is    0.46.\n",
      "For batch 1, vl_loss is    0.44.\n",
      "For batch 2, vl_loss is    0.45.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 3, vl_loss is    0.46.\n",
      "For batch 4, vl_loss is    0.49.\n",
      "For batch 5, vl_loss is    0.47.\n",
      "For batch 6, vl_loss is    0.48.\n",
      "For batch 7, vl_loss is    0.47.\n",
      "For batch 8, vl_loss is    0.47.\n",
      "For batch 9, vl_loss is    0.45.\n",
      "For batch 10, vl_loss is    0.45.\n",
      "For batch 11, vl_loss is    0.46.\n",
      "For batch 12, vl_loss is    0.47.\n",
      "For batch 13, vl_loss is    0.48.\n",
      "For batch 14, vl_loss is    0.48.\n",
      "For batch 15, vl_loss is    0.47.\n",
      "For batch 16, vl_loss is    0.46.\n",
      "For batch 17, vl_loss is    0.46.\n",
      "For batch 18, vl_loss is    0.46.\n",
      "For batch 19, vl_loss is    0.46.\n",
      "For batch 20, vl_loss is    0.45.\n",
      "For batch 21, vl_loss is    0.46.\n",
      "For batch 22, vl_loss is    0.46.\n",
      "For batch 23, vl_loss is    0.45.\n",
      "For batch 24, vl_loss is    0.45.\n",
      "For batch 25, vl_loss is    0.45.\n",
      "For batch 26, vl_loss is    0.45.\n",
      "For batch 27, vl_loss is    0.45.\n",
      "For batch 28, vl_loss is    0.46.\n",
      "For batch 29, vl_loss is    0.46.\n",
      "For batch 30, vl_loss is    0.46.\n",
      "For batch 31, vl_loss is    0.46.\n",
      "For batch 32, vl_loss is    0.46.\n",
      "For batch 33, vl_loss is    0.46.\n",
      "For batch 34, vl_loss is    0.46.\n",
      "For batch 35, vl_loss is    0.46.\n",
      "For batch 36, vl_loss is    0.46.\n",
      "For batch 37, vl_loss is    0.46.\n",
      "For batch 38, vl_loss is    0.45.\n",
      "For batch 39, vl_loss is    0.45.\n",
      "For batch 40, vl_loss is    0.46.\n",
      "For batch 41, vl_loss is    0.46.\n",
      "For batch 42, vl_loss is    0.47.\n",
      "For batch 43, vl_loss is    0.47.\n",
      "For batch 44, vl_loss is    0.47.\n",
      "For batch 45, vl_loss is    0.47.\n",
      "For batch 46, vl_loss is    0.46.\n",
      "For batch 47, vl_loss is    0.46.\n",
      "For batch 48, vl_loss is    0.47.\n",
      "For batch 49, vl_loss is    0.47.\n",
      "For batch 50, vl_loss is    0.47.\n",
      "For batch 51, vl_loss is    0.47.\n",
      "For batch 52, vl_loss is    0.47.\n",
      "For batch 53, vl_loss is    0.47.\n",
      "For batch 54, vl_loss is    0.47.\n",
      "For batch 55, vl_loss is    0.47.\n",
      "For batch 56, vl_loss is    0.47.\n",
      "For batch 57, vl_loss is    0.47.\n",
      "For batch 58, vl_loss is    0.47.\n",
      "For batch 59, vl_loss is    0.46.\n",
      "For batch 60, vl_loss is    0.46.\n",
      "For batch 61, vl_loss is    0.46.\n",
      "For batch 62, vl_loss is    0.46.\n",
      "For batch 63, vl_loss is    0.46.\n",
      "For batch 64, vl_loss is    0.46.\n",
      "For batch 65, vl_loss is    0.46.\n",
      "For batch 66, vl_loss is    0.46.\n",
      "For batch 67, vl_loss is    0.46.\n",
      "232/232 [==============================] - 233s 878ms/step - loss: 0.3214 - iou_score: 0.6729 - f1-score: 0.8021 - val_loss: 0.4578 - val_iou_score: 0.6365 - val_f1-score: 0.7756\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.83207 to 0.45780, saving model to ./model/tumor_100_unet_efficientnetb0_imagenet_09291.hdf5\n",
      "The average loss for epoch 1 is    0.32 \n",
      "Epoch 3/200\n",
      "  1/232 [..............................] - ETA: 8:24 - loss: 0.2472 - iou_score: 0.7611 - f1-score: 0.8616For batch 0, tr_loss is    0.25.\n",
      "  2/232 [..............................] - ETA: 3:00 - loss: 0.2657 - iou_score: 0.7378 - f1-score: 0.8475For batch 1, tr_loss is    0.27.\n",
      "  3/232 [..............................] - ETA: 3:22 - loss: 0.2869 - iou_score: 0.7004 - f1-score: 0.8213For batch 2, tr_loss is    0.29.\n",
      "  4/232 [..............................] - ETA: 4:18 - loss: 0.2874 - iou_score: 0.7051 - f1-score: 0.8250For batch 3, tr_loss is    0.29.\n",
      "  5/232 [..............................] - ETA: 4:15 - loss: 0.2908 - iou_score: 0.7019 - f1-score: 0.8228For batch 4, tr_loss is    0.29.\n",
      "  6/232 [..............................] - ETA: 4:03 - loss: 0.2928 - iou_score: 0.6978 - f1-score: 0.8196For batch 5, tr_loss is    0.29.\n",
      "  7/232 [..............................] - ETA: 4:01 - loss: 0.3076 - iou_score: 0.6881 - f1-score: 0.8129For batch 6, tr_loss is    0.31.\n",
      "  8/232 [>.............................] - ETA: 4:02 - loss: 0.3149 - iou_score: 0.6754 - f1-score: 0.8037For batch 7, tr_loss is    0.31.\n",
      "  9/232 [>.............................] - ETA: 4:13 - loss: 0.3067 - iou_score: 0.6864 - f1-score: 0.8114For batch 8, tr_loss is    0.31.\n",
      " 10/232 [>.............................] - ETA: 4:17 - loss: 0.3066 - iou_score: 0.6854 - f1-score: 0.8109For batch 9, tr_loss is    0.31.\n",
      " 11/232 [>.............................] - ETA: 4:24 - loss: 0.3029 - iou_score: 0.6872 - f1-score: 0.8123For batch 10, tr_loss is    0.30.\n",
      " 12/232 [>.............................] - ETA: 4:13 - loss: 0.2989 - iou_score: 0.6934 - f1-score: 0.8167For batch 11, tr_loss is    0.30.\n",
      " 13/232 [>.............................] - ETA: 4:09 - loss: 0.2961 - iou_score: 0.6965 - f1-score: 0.8188For batch 12, tr_loss is    0.30.\n",
      " 14/232 [>.............................] - ETA: 4:06 - loss: 0.2930 - iou_score: 0.7007 - f1-score: 0.8218For batch 13, tr_loss is    0.29.\n",
      " 15/232 [>.............................] - ETA: 4:03 - loss: 0.2910 - iou_score: 0.7030 - f1-score: 0.8235For batch 14, tr_loss is    0.29.\n",
      " 16/232 [=>............................] - ETA: 3:57 - loss: 0.2898 - iou_score: 0.7037 - f1-score: 0.8240For batch 15, tr_loss is    0.29.\n",
      " 17/232 [=>............................] - ETA: 3:55 - loss: 0.2872 - iou_score: 0.7068 - f1-score: 0.8262For batch 16, tr_loss is    0.29.\n",
      " 18/232 [=>............................] - ETA: 3:53 - loss: 0.2882 - iou_score: 0.7063 - f1-score: 0.8259For batch 17, tr_loss is    0.29.\n",
      " 19/232 [=>............................] - ETA: 3:51 - loss: 0.2904 - iou_score: 0.7031 - f1-score: 0.8238For batch 18, tr_loss is    0.29.\n",
      " 20/232 [=>............................] - ETA: 3:49 - loss: 0.2890 - iou_score: 0.7037 - f1-score: 0.8243For batch 19, tr_loss is    0.29.\n",
      " 21/232 [=>............................] - ETA: 3:42 - loss: 0.2923 - iou_score: 0.7016 - f1-score: 0.8228For batch 20, tr_loss is    0.29.\n",
      " 22/232 [=>............................] - ETA: 3:38 - loss: 0.2970 - iou_score: 0.6968 - f1-score: 0.8191For batch 21, tr_loss is    0.30.\n",
      " 23/232 [=>............................] - ETA: 3:33 - loss: 0.2969 - iou_score: 0.6968 - f1-score: 0.8192For batch 22, tr_loss is    0.30.\n",
      " 24/232 [==>...........................] - ETA: 3:30 - loss: 0.2968 - iou_score: 0.6962 - f1-score: 0.8187For batch 23, tr_loss is    0.30.\n",
      " 25/232 [==>...........................] - ETA: 3:25 - loss: 0.2987 - iou_score: 0.6920 - f1-score: 0.8157For batch 24, tr_loss is    0.30.\n",
      " 26/232 [==>...........................] - ETA: 3:23 - loss: 0.2995 - iou_score: 0.6920 - f1-score: 0.8157For batch 25, tr_loss is    0.30.\n",
      " 27/232 [==>...........................] - ETA: 3:19 - loss: 0.2976 - iou_score: 0.6951 - f1-score: 0.8178For batch 26, tr_loss is    0.30.\n",
      " 28/232 [==>...........................] - ETA: 3:16 - loss: 0.2985 - iou_score: 0.6946 - f1-score: 0.8175For batch 27, tr_loss is    0.30.\n",
      " 29/232 [==>...........................] - ETA: 3:13 - loss: 0.2993 - iou_score: 0.6922 - f1-score: 0.8157For batch 28, tr_loss is    0.30.\n",
      " 30/232 [==>...........................] - ETA: 3:10 - loss: 0.2975 - iou_score: 0.6946 - f1-score: 0.8173For batch 29, tr_loss is    0.30.\n",
      " 31/232 [===>..........................] - ETA: 3:08 - loss: 0.2969 - iou_score: 0.6950 - f1-score: 0.8177For batch 30, tr_loss is    0.30.\n",
      " 32/232 [===>..........................] - ETA: 3:07 - loss: 0.2965 - iou_score: 0.6956 - f1-score: 0.8182For batch 31, tr_loss is    0.30.\n",
      " 33/232 [===>..........................] - ETA: 3:07 - loss: 0.2987 - iou_score: 0.6932 - f1-score: 0.8165For batch 32, tr_loss is    0.30.\n",
      " 34/232 [===>..........................] - ETA: 3:06 - loss: 0.2992 - iou_score: 0.6934 - f1-score: 0.8167For batch 33, tr_loss is    0.30.\n",
      " 35/232 [===>..........................] - ETA: 3:04 - loss: 0.3003 - iou_score: 0.6920 - f1-score: 0.8157For batch 34, tr_loss is    0.30.\n",
      " 36/232 [===>..........................] - ETA: 3:04 - loss: 0.3009 - iou_score: 0.6921 - f1-score: 0.8158For batch 35, tr_loss is    0.30.\n",
      " 37/232 [===>..........................] - ETA: 3:03 - loss: 0.3004 - iou_score: 0.6919 - f1-score: 0.8157For batch 36, tr_loss is    0.30.\n",
      " 38/232 [===>..........................] - ETA: 3:00 - loss: 0.3015 - iou_score: 0.6910 - f1-score: 0.8151For batch 37, tr_loss is    0.30.\n",
      " 39/232 [====>.........................] - ETA: 2:58 - loss: 0.3052 - iou_score: 0.6873 - f1-score: 0.8124For batch 38, tr_loss is    0.31.\n",
      " 40/232 [====>.........................] - ETA: 2:58 - loss: 0.3066 - iou_score: 0.6866 - f1-score: 0.8119For batch 39, tr_loss is    0.31.\n",
      " 41/232 [====>.........................] - ETA: 2:58 - loss: 0.3076 - iou_score: 0.6853 - f1-score: 0.8110For batch 40, tr_loss is    0.31.\n",
      " 42/232 [====>.........................] - ETA: 2:57 - loss: 0.3082 - iou_score: 0.6838 - f1-score: 0.8099For batch 41, tr_loss is    0.31.\n",
      " 43/232 [====>.........................] - ETA: 2:57 - loss: 0.3077 - iou_score: 0.6844 - f1-score: 0.8104For batch 42, tr_loss is    0.31.\n",
      " 44/232 [====>.........................] - ETA: 2:56 - loss: 0.3097 - iou_score: 0.6820 - f1-score: 0.8084For batch 43, tr_loss is    0.31.\n",
      " 45/232 [====>.........................] - ETA: 2:56 - loss: 0.3107 - iou_score: 0.6815 - f1-score: 0.8081For batch 44, tr_loss is    0.31.\n",
      " 46/232 [====>.........................] - ETA: 2:54 - loss: 0.3107 - iou_score: 0.6821 - f1-score: 0.8085For batch 45, tr_loss is    0.31.\n",
      " 47/232 [=====>........................] - ETA: 2:53 - loss: 0.3104 - iou_score: 0.6826 - f1-score: 0.8089For batch 46, tr_loss is    0.31.\n",
      " 48/232 [=====>........................] - ETA: 2:52 - loss: 0.3097 - iou_score: 0.6837 - f1-score: 0.8097For batch 47, tr_loss is    0.31.\n",
      " 49/232 [=====>........................] - ETA: 2:49 - loss: 0.3101 - iou_score: 0.6837 - f1-score: 0.8097For batch 48, tr_loss is    0.31.\n",
      " 50/232 [=====>........................] - ETA: 2:47 - loss: 0.3099 - iou_score: 0.6840 - f1-score: 0.8100For batch 49, tr_loss is    0.31.\n",
      " 51/232 [=====>........................] - ETA: 2:46 - loss: 0.3121 - iou_score: 0.6816 - f1-score: 0.8082For batch 50, tr_loss is    0.31.\n",
      " 52/232 [=====>........................] - ETA: 2:44 - loss: 0.3152 - iou_score: 0.6795 - f1-score: 0.8067For batch 51, tr_loss is    0.32.\n",
      " 53/232 [=====>........................] - ETA: 2:43 - loss: 0.3140 - iou_score: 0.6807 - f1-score: 0.8075For batch 52, tr_loss is    0.31.\n",
      " 54/232 [=====>........................] - ETA: 2:40 - loss: 0.3143 - iou_score: 0.6800 - f1-score: 0.8070For batch 53, tr_loss is    0.31.\n",
      " 55/232 [======>.......................] - ETA: 2:40 - loss: 0.3135 - iou_score: 0.6808 - f1-score: 0.8076For batch 54, tr_loss is    0.31.\n",
      " 56/232 [======>.......................] - ETA: 2:39 - loss: 0.3132 - iou_score: 0.6810 - f1-score: 0.8078For batch 55, tr_loss is    0.31.\n",
      " 57/232 [======>.......................] - ETA: 2:39 - loss: 0.3138 - iou_score: 0.6801 - f1-score: 0.8071For batch 56, tr_loss is    0.31.\n",
      " 58/232 [======>.......................] - ETA: 2:38 - loss: 0.3129 - iou_score: 0.6814 - f1-score: 0.8081For batch 57, tr_loss is    0.31.\n",
      " 59/232 [======>.......................] - ETA: 2:36 - loss: 0.3123 - iou_score: 0.6820 - f1-score: 0.8085For batch 58, tr_loss is    0.31.\n",
      " 60/232 [======>.......................] - ETA: 2:35 - loss: 0.3135 - iou_score: 0.6807 - f1-score: 0.8076For batch 59, tr_loss is    0.31.\n",
      " 61/232 [======>.......................] - ETA: 2:33 - loss: 0.3145 - iou_score: 0.6799 - f1-score: 0.8069For batch 60, tr_loss is    0.31.\n",
      " 62/232 [=======>......................] - ETA: 2:32 - loss: 0.3152 - iou_score: 0.6789 - f1-score: 0.8061For batch 61, tr_loss is    0.32.\n",
      " 63/232 [=======>......................] - ETA: 2:32 - loss: 0.3145 - iou_score: 0.6797 - f1-score: 0.8067For batch 62, tr_loss is    0.31.\n",
      " 64/232 [=======>......................] - ETA: 2:30 - loss: 0.3145 - iou_score: 0.6795 - f1-score: 0.8066For batch 63, tr_loss is    0.31.\n",
      " 65/232 [=======>......................] - ETA: 2:30 - loss: 0.3148 - iou_score: 0.6792 - f1-score: 0.8064For batch 64, tr_loss is    0.31.\n",
      " 66/232 [=======>......................] - ETA: 2:28 - loss: 0.3151 - iou_score: 0.6784 - f1-score: 0.8058For batch 65, tr_loss is    0.32.\n",
      " 67/232 [=======>......................] - ETA: 2:26 - loss: 0.3141 - iou_score: 0.6793 - f1-score: 0.8065For batch 66, tr_loss is    0.31.\n",
      " 68/232 [=======>......................] - ETA: 2:26 - loss: 0.3138 - iou_score: 0.6797 - f1-score: 0.8068For batch 67, tr_loss is    0.31.\n",
      " 69/232 [=======>......................] - ETA: 2:24 - loss: 0.3136 - iou_score: 0.6798 - f1-score: 0.8068For batch 68, tr_loss is    0.31.\n",
      " 70/232 [========>.....................] - ETA: 2:24 - loss: 0.3130 - iou_score: 0.6801 - f1-score: 0.8071For batch 69, tr_loss is    0.31.\n",
      " 71/232 [========>.....................] - ETA: 2:22 - loss: 0.3121 - iou_score: 0.6811 - f1-score: 0.8078For batch 70, tr_loss is    0.31.\n",
      " 72/232 [========>.....................] - ETA: 2:20 - loss: 0.3112 - iou_score: 0.6821 - f1-score: 0.8085For batch 71, tr_loss is    0.31.\n",
      " 73/232 [========>.....................] - ETA: 2:19 - loss: 0.3114 - iou_score: 0.6819 - f1-score: 0.8084For batch 72, tr_loss is    0.31.\n",
      " 74/232 [========>.....................] - ETA: 2:18 - loss: 0.3103 - iou_score: 0.6830 - f1-score: 0.8092For batch 73, tr_loss is    0.31.\n",
      " 75/232 [========>.....................] - ETA: 2:17 - loss: 0.3106 - iou_score: 0.6829 - f1-score: 0.8091For batch 74, tr_loss is    0.31.\n",
      " 76/232 [========>.....................] - ETA: 2:16 - loss: 0.3103 - iou_score: 0.6830 - f1-score: 0.8092For batch 75, tr_loss is    0.31.\n",
      " 77/232 [========>.....................] - ETA: 2:15 - loss: 0.3093 - iou_score: 0.6838 - f1-score: 0.8097For batch 76, tr_loss is    0.31.\n",
      " 78/232 [=========>....................] - ETA: 2:15 - loss: 0.3097 - iou_score: 0.6833 - f1-score: 0.8094For batch 77, tr_loss is    0.31.\n",
      " 79/232 [=========>....................] - ETA: 2:14 - loss: 0.3091 - iou_score: 0.6839 - f1-score: 0.8098For batch 78, tr_loss is    0.31.\n",
      " 80/232 [=========>....................] - ETA: 2:13 - loss: 0.3088 - iou_score: 0.6842 - f1-score: 0.8101For batch 79, tr_loss is    0.31.\n",
      " 81/232 [=========>....................] - ETA: 2:12 - loss: 0.3090 - iou_score: 0.6838 - f1-score: 0.8098For batch 80, tr_loss is    0.31.\n",
      " 82/232 [=========>....................] - ETA: 2:11 - loss: 0.3088 - iou_score: 0.6839 - f1-score: 0.8099For batch 81, tr_loss is    0.31.\n",
      " 83/232 [=========>....................] - ETA: 2:10 - loss: 0.3097 - iou_score: 0.6826 - f1-score: 0.8089For batch 82, tr_loss is    0.31.\n",
      " 84/232 [=========>....................] - ETA: 2:09 - loss: 0.3102 - iou_score: 0.6819 - f1-score: 0.8085For batch 83, tr_loss is    0.31.\n",
      " 85/232 [=========>....................] - ETA: 2:07 - loss: 0.3106 - iou_score: 0.6815 - f1-score: 0.8081For batch 84, tr_loss is    0.31.\n",
      " 86/232 [==========>...................] - ETA: 2:07 - loss: 0.3111 - iou_score: 0.6811 - f1-score: 0.8078For batch 85, tr_loss is    0.31.\n",
      " 87/232 [==========>...................] - ETA: 2:06 - loss: 0.3108 - iou_score: 0.6813 - f1-score: 0.8080For batch 86, tr_loss is    0.31.\n",
      " 88/232 [==========>...................] - ETA: 2:05 - loss: 0.3114 - iou_score: 0.6804 - f1-score: 0.8073For batch 87, tr_loss is    0.31.\n",
      " 89/232 [==========>...................] - ETA: 2:05 - loss: 0.3109 - iou_score: 0.6808 - f1-score: 0.8077For batch 88, tr_loss is    0.31.\n",
      " 90/232 [==========>...................] - ETA: 2:04 - loss: 0.3104 - iou_score: 0.6815 - f1-score: 0.8082For batch 89, tr_loss is    0.31.\n",
      " 91/232 [==========>...................] - ETA: 2:03 - loss: 0.3101 - iou_score: 0.6820 - f1-score: 0.8085For batch 90, tr_loss is    0.31.\n",
      " 92/232 [==========>...................] - ETA: 2:02 - loss: 0.3101 - iou_score: 0.6819 - f1-score: 0.8084For batch 91, tr_loss is    0.31.\n",
      " 93/232 [===========>..................] - ETA: 2:02 - loss: 0.3114 - iou_score: 0.6806 - f1-score: 0.8074For batch 92, tr_loss is    0.31.\n",
      " 94/232 [===========>..................] - ETA: 2:01 - loss: 0.3106 - iou_score: 0.6815 - f1-score: 0.8080For batch 93, tr_loss is    0.31.\n",
      " 95/232 [===========>..................] - ETA: 2:00 - loss: 0.3110 - iou_score: 0.6810 - f1-score: 0.8077For batch 94, tr_loss is    0.31.\n",
      " 96/232 [===========>..................] - ETA: 1:58 - loss: 0.3108 - iou_score: 0.6811 - f1-score: 0.8078For batch 95, tr_loss is    0.31.\n",
      " 97/232 [===========>..................] - ETA: 1:58 - loss: 0.3110 - iou_score: 0.6805 - f1-score: 0.8074For batch 96, tr_loss is    0.31.\n",
      " 98/232 [===========>..................] - ETA: 1:56 - loss: 0.3109 - iou_score: 0.6805 - f1-score: 0.8074For batch 97, tr_loss is    0.31.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 99/232 [===========>..................] - ETA: 1:56 - loss: 0.3102 - iou_score: 0.6813 - f1-score: 0.8080For batch 98, tr_loss is    0.31.\n",
      "100/232 [===========>..................] - ETA: 1:55 - loss: 0.3095 - iou_score: 0.6823 - f1-score: 0.8086For batch 99, tr_loss is    0.31.\n",
      "101/232 [============>.................] - ETA: 1:54 - loss: 0.3088 - iou_score: 0.6831 - f1-score: 0.8092For batch 100, tr_loss is    0.31.\n",
      "102/232 [============>.................] - ETA: 1:52 - loss: 0.3088 - iou_score: 0.6831 - f1-score: 0.8092For batch 101, tr_loss is    0.31.\n",
      "103/232 [============>.................] - ETA: 1:52 - loss: 0.3090 - iou_score: 0.6830 - f1-score: 0.8091For batch 102, tr_loss is    0.31.\n",
      "104/232 [============>.................] - ETA: 1:51 - loss: 0.3089 - iou_score: 0.6831 - f1-score: 0.8092For batch 103, tr_loss is    0.31.\n",
      "105/232 [============>.................] - ETA: 1:50 - loss: 0.3080 - iou_score: 0.6840 - f1-score: 0.8099For batch 104, tr_loss is    0.31.\n",
      "106/232 [============>.................] - ETA: 1:49 - loss: 0.3072 - iou_score: 0.6850 - f1-score: 0.8105For batch 105, tr_loss is    0.31.\n",
      "107/232 [============>.................] - ETA: 1:49 - loss: 0.3076 - iou_score: 0.6848 - f1-score: 0.8104For batch 106, tr_loss is    0.31.\n",
      "108/232 [============>.................] - ETA: 1:48 - loss: 0.3081 - iou_score: 0.6839 - f1-score: 0.8098For batch 107, tr_loss is    0.31.\n",
      "109/232 [=============>................] - ETA: 1:47 - loss: 0.3075 - iou_score: 0.6845 - f1-score: 0.8102For batch 108, tr_loss is    0.31.\n",
      "110/232 [=============>................] - ETA: 1:47 - loss: 0.3066 - iou_score: 0.6855 - f1-score: 0.8109For batch 109, tr_loss is    0.31.\n",
      "111/232 [=============>................] - ETA: 1:46 - loss: 0.3069 - iou_score: 0.6852 - f1-score: 0.8107For batch 110, tr_loss is    0.31.\n",
      "112/232 [=============>................] - ETA: 1:45 - loss: 0.3072 - iou_score: 0.6847 - f1-score: 0.8103For batch 111, tr_loss is    0.31.\n",
      "113/232 [=============>................] - ETA: 1:44 - loss: 0.3078 - iou_score: 0.6844 - f1-score: 0.8101For batch 112, tr_loss is    0.31.\n",
      "114/232 [=============>................] - ETA: 1:44 - loss: 0.3071 - iou_score: 0.6852 - f1-score: 0.8107For batch 113, tr_loss is    0.31.\n",
      "115/232 [=============>................] - ETA: 1:43 - loss: 0.3068 - iou_score: 0.6855 - f1-score: 0.8109For batch 114, tr_loss is    0.31.\n",
      "116/232 [==============>...............] - ETA: 1:42 - loss: 0.3064 - iou_score: 0.6858 - f1-score: 0.8111For batch 115, tr_loss is    0.31.\n",
      "117/232 [==============>...............] - ETA: 1:41 - loss: 0.3064 - iou_score: 0.6859 - f1-score: 0.8112For batch 116, tr_loss is    0.31.\n",
      "118/232 [==============>...............] - ETA: 1:40 - loss: 0.3060 - iou_score: 0.6865 - f1-score: 0.8116For batch 117, tr_loss is    0.31.\n",
      "119/232 [==============>...............] - ETA: 1:40 - loss: 0.3054 - iou_score: 0.6872 - f1-score: 0.8121For batch 118, tr_loss is    0.31.\n",
      "120/232 [==============>...............] - ETA: 1:39 - loss: 0.3057 - iou_score: 0.6868 - f1-score: 0.8119For batch 119, tr_loss is    0.31.\n",
      "121/232 [==============>...............] - ETA: 1:38 - loss: 0.3051 - iou_score: 0.6875 - f1-score: 0.8123For batch 120, tr_loss is    0.31.\n",
      "122/232 [==============>...............] - ETA: 1:37 - loss: 0.3054 - iou_score: 0.6870 - f1-score: 0.8119For batch 121, tr_loss is    0.31.\n",
      "123/232 [==============>...............] - ETA: 1:36 - loss: 0.3051 - iou_score: 0.6872 - f1-score: 0.8121For batch 122, tr_loss is    0.31.\n",
      "124/232 [===============>..............] - ETA: 1:36 - loss: 0.3051 - iou_score: 0.6872 - f1-score: 0.8121For batch 123, tr_loss is    0.31.\n",
      "125/232 [===============>..............] - ETA: 1:35 - loss: 0.3053 - iou_score: 0.6869 - f1-score: 0.8119For batch 124, tr_loss is    0.31.\n",
      "126/232 [===============>..............] - ETA: 1:34 - loss: 0.3055 - iou_score: 0.6869 - f1-score: 0.8119For batch 125, tr_loss is    0.31.\n",
      "127/232 [===============>..............] - ETA: 1:33 - loss: 0.3054 - iou_score: 0.6866 - f1-score: 0.8117For batch 126, tr_loss is    0.31.\n",
      "128/232 [===============>..............] - ETA: 1:32 - loss: 0.3060 - iou_score: 0.6860 - f1-score: 0.8113For batch 127, tr_loss is    0.31.\n",
      "129/232 [===============>..............] - ETA: 1:31 - loss: 0.3064 - iou_score: 0.6855 - f1-score: 0.8109For batch 128, tr_loss is    0.31.\n",
      "130/232 [===============>..............] - ETA: 1:30 - loss: 0.3065 - iou_score: 0.6859 - f1-score: 0.8112For batch 129, tr_loss is    0.31.\n",
      "131/232 [===============>..............] - ETA: 1:29 - loss: 0.3073 - iou_score: 0.6852 - f1-score: 0.8107For batch 130, tr_loss is    0.31.\n",
      "132/232 [================>.............] - ETA: 1:28 - loss: 0.3078 - iou_score: 0.6847 - f1-score: 0.8103For batch 131, tr_loss is    0.31.\n",
      "133/232 [================>.............] - ETA: 1:27 - loss: 0.3073 - iou_score: 0.6852 - f1-score: 0.8106For batch 132, tr_loss is    0.31.\n",
      "134/232 [================>.............] - ETA: 1:26 - loss: 0.3078 - iou_score: 0.6843 - f1-score: 0.8100For batch 133, tr_loss is    0.31.\n",
      "135/232 [================>.............] - ETA: 1:26 - loss: 0.3075 - iou_score: 0.6846 - f1-score: 0.8103For batch 134, tr_loss is    0.31.\n",
      "136/232 [================>.............] - ETA: 1:24 - loss: 0.3078 - iou_score: 0.6841 - f1-score: 0.8099For batch 135, tr_loss is    0.31.\n",
      "137/232 [================>.............] - ETA: 1:24 - loss: 0.3079 - iou_score: 0.6840 - f1-score: 0.8098For batch 136, tr_loss is    0.31.\n",
      "138/232 [================>.............] - ETA: 1:23 - loss: 0.3079 - iou_score: 0.6839 - f1-score: 0.8098For batch 137, tr_loss is    0.31.\n",
      "139/232 [================>.............] - ETA: 1:22 - loss: 0.3078 - iou_score: 0.6841 - f1-score: 0.8099For batch 138, tr_loss is    0.31.\n",
      "140/232 [=================>............] - ETA: 1:21 - loss: 0.3076 - iou_score: 0.6843 - f1-score: 0.8101For batch 139, tr_loss is    0.31.\n",
      "141/232 [=================>............] - ETA: 1:20 - loss: 0.3085 - iou_score: 0.6833 - f1-score: 0.8094For batch 140, tr_loss is    0.31.\n",
      "142/232 [=================>............] - ETA: 1:19 - loss: 0.3084 - iou_score: 0.6833 - f1-score: 0.8093For batch 141, tr_loss is    0.31.\n",
      "143/232 [=================>............] - ETA: 1:18 - loss: 0.3080 - iou_score: 0.6835 - f1-score: 0.8095For batch 142, tr_loss is    0.31.\n",
      "144/232 [=================>............] - ETA: 1:18 - loss: 0.3078 - iou_score: 0.6836 - f1-score: 0.8096For batch 143, tr_loss is    0.31.\n",
      "145/232 [=================>............] - ETA: 1:17 - loss: 0.3077 - iou_score: 0.6838 - f1-score: 0.8097For batch 144, tr_loss is    0.31.\n",
      "146/232 [=================>............] - ETA: 1:16 - loss: 0.3077 - iou_score: 0.6835 - f1-score: 0.8095For batch 145, tr_loss is    0.31.\n",
      "147/232 [==================>...........] - ETA: 1:15 - loss: 0.3075 - iou_score: 0.6839 - f1-score: 0.8098For batch 146, tr_loss is    0.31.\n",
      "148/232 [==================>...........] - ETA: 1:14 - loss: 0.3079 - iou_score: 0.6835 - f1-score: 0.8096For batch 147, tr_loss is    0.31.\n",
      "149/232 [==================>...........] - ETA: 1:13 - loss: 0.3077 - iou_score: 0.6839 - f1-score: 0.8098For batch 148, tr_loss is    0.31.\n",
      "150/232 [==================>...........] - ETA: 1:12 - loss: 0.3084 - iou_score: 0.6832 - f1-score: 0.8093For batch 149, tr_loss is    0.31.\n",
      "151/232 [==================>...........] - ETA: 1:11 - loss: 0.3085 - iou_score: 0.6830 - f1-score: 0.8091For batch 150, tr_loss is    0.31.\n",
      "152/232 [==================>...........] - ETA: 1:10 - loss: 0.3081 - iou_score: 0.6835 - f1-score: 0.8095For batch 151, tr_loss is    0.31.\n",
      "153/232 [==================>...........] - ETA: 1:09 - loss: 0.3081 - iou_score: 0.6835 - f1-score: 0.8095For batch 152, tr_loss is    0.31.\n",
      "154/232 [==================>...........] - ETA: 1:09 - loss: 0.3078 - iou_score: 0.6836 - f1-score: 0.8096For batch 153, tr_loss is    0.31.\n",
      "155/232 [===================>..........] - ETA: 1:08 - loss: 0.3078 - iou_score: 0.6835 - f1-score: 0.8096For batch 154, tr_loss is    0.31.\n",
      "156/232 [===================>..........] - ETA: 1:07 - loss: 0.3078 - iou_score: 0.6834 - f1-score: 0.8094For batch 155, tr_loss is    0.31.\n",
      "157/232 [===================>..........] - ETA: 1:06 - loss: 0.3081 - iou_score: 0.6830 - f1-score: 0.8091For batch 156, tr_loss is    0.31.\n",
      "158/232 [===================>..........] - ETA: 1:05 - loss: 0.3077 - iou_score: 0.6835 - f1-score: 0.8095For batch 157, tr_loss is    0.31.\n",
      "159/232 [===================>..........] - ETA: 1:04 - loss: 0.3075 - iou_score: 0.6839 - f1-score: 0.8098For batch 158, tr_loss is    0.31.\n",
      "160/232 [===================>..........] - ETA: 1:03 - loss: 0.3075 - iou_score: 0.6834 - f1-score: 0.8095For batch 159, tr_loss is    0.31.\n",
      "161/232 [===================>..........] - ETA: 1:02 - loss: 0.3072 - iou_score: 0.6838 - f1-score: 0.8097For batch 160, tr_loss is    0.31.\n",
      "162/232 [===================>..........] - ETA: 1:01 - loss: 0.3072 - iou_score: 0.6836 - f1-score: 0.8096For batch 161, tr_loss is    0.31.\n",
      "163/232 [====================>.........] - ETA: 1:00 - loss: 0.3069 - iou_score: 0.6840 - f1-score: 0.8099For batch 162, tr_loss is    0.31.\n",
      "164/232 [====================>.........] - ETA: 1:00 - loss: 0.3070 - iou_score: 0.6838 - f1-score: 0.8097For batch 163, tr_loss is    0.31.\n",
      "165/232 [====================>.........] - ETA: 59s - loss: 0.3070 - iou_score: 0.6836 - f1-score: 0.8096 For batch 164, tr_loss is    0.31.\n",
      "166/232 [====================>.........] - ETA: 58s - loss: 0.3069 - iou_score: 0.6836 - f1-score: 0.8096For batch 165, tr_loss is    0.31.\n",
      "167/232 [====================>.........] - ETA: 57s - loss: 0.3066 - iou_score: 0.6839 - f1-score: 0.8098For batch 166, tr_loss is    0.31.\n",
      "168/232 [====================>.........] - ETA: 56s - loss: 0.3073 - iou_score: 0.6834 - f1-score: 0.8094For batch 167, tr_loss is    0.31.\n",
      "169/232 [====================>.........] - ETA: 55s - loss: 0.3080 - iou_score: 0.6829 - f1-score: 0.8091For batch 168, tr_loss is    0.31.\n",
      "170/232 [====================>.........] - ETA: 54s - loss: 0.3080 - iou_score: 0.6829 - f1-score: 0.8091For batch 169, tr_loss is    0.31.\n",
      "171/232 [=====================>........] - ETA: 53s - loss: 0.3085 - iou_score: 0.6824 - f1-score: 0.8087For batch 170, tr_loss is    0.31.\n",
      "172/232 [=====================>........] - ETA: 52s - loss: 0.3087 - iou_score: 0.6821 - f1-score: 0.8085For batch 171, tr_loss is    0.31.\n",
      "173/232 [=====================>........] - ETA: 52s - loss: 0.3086 - iou_score: 0.6819 - f1-score: 0.8084For batch 172, tr_loss is    0.31.\n",
      "174/232 [=====================>........] - ETA: 51s - loss: 0.3083 - iou_score: 0.6822 - f1-score: 0.8086For batch 173, tr_loss is    0.31.\n",
      "175/232 [=====================>........] - ETA: 50s - loss: 0.3084 - iou_score: 0.6821 - f1-score: 0.8085For batch 174, tr_loss is    0.31.\n",
      "176/232 [=====================>........] - ETA: 49s - loss: 0.3087 - iou_score: 0.6818 - f1-score: 0.8083For batch 175, tr_loss is    0.31.\n",
      "177/232 [=====================>........] - ETA: 48s - loss: 0.3084 - iou_score: 0.6822 - f1-score: 0.8086For batch 176, tr_loss is    0.31.\n",
      "178/232 [======================>.......] - ETA: 47s - loss: 0.3084 - iou_score: 0.6823 - f1-score: 0.8087For batch 177, tr_loss is    0.31.\n",
      "179/232 [======================>.......] - ETA: 46s - loss: 0.3083 - iou_score: 0.6825 - f1-score: 0.8089For batch 178, tr_loss is    0.31.\n",
      "180/232 [======================>.......] - ETA: 45s - loss: 0.3082 - iou_score: 0.6826 - f1-score: 0.8089For batch 179, tr_loss is    0.31.\n",
      "181/232 [======================>.......] - ETA: 45s - loss: 0.3082 - iou_score: 0.6825 - f1-score: 0.8088For batch 180, tr_loss is    0.31.\n",
      "182/232 [======================>.......] - ETA: 44s - loss: 0.3081 - iou_score: 0.6826 - f1-score: 0.8089For batch 181, tr_loss is    0.31.\n",
      "183/232 [======================>.......] - ETA: 43s - loss: 0.3081 - iou_score: 0.6827 - f1-score: 0.8090For batch 182, tr_loss is    0.31.\n",
      "184/232 [======================>.......] - ETA: 42s - loss: 0.3078 - iou_score: 0.6831 - f1-score: 0.8093For batch 183, tr_loss is    0.31.\n",
      "185/232 [======================>.......] - ETA: 41s - loss: 0.3080 - iou_score: 0.6829 - f1-score: 0.8092For batch 184, tr_loss is    0.31.\n",
      "186/232 [=======================>......] - ETA: 40s - loss: 0.3080 - iou_score: 0.6829 - f1-score: 0.8092For batch 185, tr_loss is    0.31.\n",
      "187/232 [=======================>......] - ETA: 39s - loss: 0.3075 - iou_score: 0.6835 - f1-score: 0.8095For batch 186, tr_loss is    0.31.\n",
      "188/232 [=======================>......] - ETA: 38s - loss: 0.3076 - iou_score: 0.6833 - f1-score: 0.8094For batch 187, tr_loss is    0.31.\n",
      "189/232 [=======================>......] - ETA: 37s - loss: 0.3075 - iou_score: 0.6835 - f1-score: 0.8095For batch 188, tr_loss is    0.31.\n",
      "190/232 [=======================>......] - ETA: 37s - loss: 0.3074 - iou_score: 0.6834 - f1-score: 0.8095For batch 189, tr_loss is    0.31.\n",
      "191/232 [=======================>......] - ETA: 36s - loss: 0.3074 - iou_score: 0.6835 - f1-score: 0.8096For batch 190, tr_loss is    0.31.\n",
      "192/232 [=======================>......] - ETA: 35s - loss: 0.3075 - iou_score: 0.6833 - f1-score: 0.8094For batch 191, tr_loss is    0.31.\n",
      "193/232 [=======================>......] - ETA: 34s - loss: 0.3079 - iou_score: 0.6828 - f1-score: 0.8091For batch 192, tr_loss is    0.31.\n",
      "194/232 [========================>.....] - ETA: 33s - loss: 0.3080 - iou_score: 0.6827 - f1-score: 0.8090For batch 193, tr_loss is    0.31.\n",
      "195/232 [========================>.....] - ETA: 32s - loss: 0.3079 - iou_score: 0.6827 - f1-score: 0.8090For batch 194, tr_loss is    0.31.\n",
      "196/232 [========================>.....] - ETA: 31s - loss: 0.3078 - iou_score: 0.6828 - f1-score: 0.8091For batch 195, tr_loss is    0.31.\n",
      "197/232 [========================>.....] - ETA: 31s - loss: 0.3076 - iou_score: 0.6829 - f1-score: 0.8092For batch 196, tr_loss is    0.31.\n",
      "198/232 [========================>.....] - ETA: 30s - loss: 0.3072 - iou_score: 0.6836 - f1-score: 0.8096For batch 197, tr_loss is    0.31.\n",
      "199/232 [========================>.....] - ETA: 29s - loss: 0.3069 - iou_score: 0.6838 - f1-score: 0.8098For batch 198, tr_loss is    0.31.\n",
      "200/232 [========================>.....] - ETA: 28s - loss: 0.3065 - iou_score: 0.6843 - f1-score: 0.8101For batch 199, tr_loss is    0.31.\n",
      "201/232 [========================>.....] - ETA: 27s - loss: 0.3065 - iou_score: 0.6842 - f1-score: 0.8101For batch 200, tr_loss is    0.31.\n",
      "202/232 [=========================>....] - ETA: 26s - loss: 0.3064 - iou_score: 0.6843 - f1-score: 0.8102For batch 201, tr_loss is    0.31.\n",
      "203/232 [=========================>....] - ETA: 25s - loss: 0.3061 - iou_score: 0.6846 - f1-score: 0.8103For batch 202, tr_loss is    0.31.\n",
      "204/232 [=========================>....] - ETA: 24s - loss: 0.3057 - iou_score: 0.6850 - f1-score: 0.8106For batch 203, tr_loss is    0.31.\n",
      "205/232 [=========================>....] - ETA: 23s - loss: 0.3056 - iou_score: 0.6850 - f1-score: 0.8106For batch 204, tr_loss is    0.31.\n",
      "206/232 [=========================>....] - ETA: 22s - loss: 0.3058 - iou_score: 0.6849 - f1-score: 0.8106For batch 205, tr_loss is    0.31.\n",
      "207/232 [=========================>....] - ETA: 22s - loss: 0.3057 - iou_score: 0.6851 - f1-score: 0.8107For batch 206, tr_loss is    0.31.\n",
      "208/232 [=========================>....] - ETA: 21s - loss: 0.3057 - iou_score: 0.6851 - f1-score: 0.8107For batch 207, tr_loss is    0.31.\n",
      "209/232 [==========================>...] - ETA: 20s - loss: 0.3060 - iou_score: 0.6849 - f1-score: 0.8106For batch 208, tr_loss is    0.31.\n",
      "210/232 [==========================>...] - ETA: 19s - loss: 0.3062 - iou_score: 0.6847 - f1-score: 0.8104For batch 209, tr_loss is    0.31.\n",
      "211/232 [==========================>...] - ETA: 18s - loss: 0.3059 - iou_score: 0.6850 - f1-score: 0.8107For batch 210, tr_loss is    0.31.\n",
      "212/232 [==========================>...] - ETA: 17s - loss: 0.3057 - iou_score: 0.6853 - f1-score: 0.8108For batch 211, tr_loss is    0.31.\n",
      "213/232 [==========================>...] - ETA: 16s - loss: 0.3058 - iou_score: 0.6852 - f1-score: 0.8108For batch 212, tr_loss is    0.31.\n",
      "214/232 [==========================>...] - ETA: 15s - loss: 0.3056 - iou_score: 0.6854 - f1-score: 0.8109For batch 213, tr_loss is    0.31.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/232 [==========================>...] - ETA: 14s - loss: 0.3053 - iou_score: 0.6858 - f1-score: 0.8112For batch 214, tr_loss is    0.31.\n",
      "216/232 [==========================>...] - ETA: 14s - loss: 0.3051 - iou_score: 0.6860 - f1-score: 0.8114For batch 215, tr_loss is    0.31.\n",
      "217/232 [===========================>..] - ETA: 13s - loss: 0.3051 - iou_score: 0.6860 - f1-score: 0.8113For batch 216, tr_loss is    0.31.\n",
      "218/232 [===========================>..] - ETA: 12s - loss: 0.3051 - iou_score: 0.6859 - f1-score: 0.8113For batch 217, tr_loss is    0.31.\n",
      "219/232 [===========================>..] - ETA: 11s - loss: 0.3057 - iou_score: 0.6853 - f1-score: 0.8108For batch 218, tr_loss is    0.31.\n",
      "220/232 [===========================>..] - ETA: 10s - loss: 0.3057 - iou_score: 0.6853 - f1-score: 0.8108For batch 219, tr_loss is    0.31.\n",
      "221/232 [===========================>..] - ETA: 9s - loss: 0.3059 - iou_score: 0.6851 - f1-score: 0.8107 For batch 220, tr_loss is    0.31.\n",
      "222/232 [===========================>..] - ETA: 8s - loss: 0.3057 - iou_score: 0.6854 - f1-score: 0.8109For batch 221, tr_loss is    0.31.\n",
      "223/232 [===========================>..] - ETA: 7s - loss: 0.3057 - iou_score: 0.6852 - f1-score: 0.8108For batch 222, tr_loss is    0.31.\n",
      "224/232 [===========================>..] - ETA: 7s - loss: 0.3055 - iou_score: 0.6856 - f1-score: 0.8111For batch 223, tr_loss is    0.31.\n",
      "225/232 [============================>.] - ETA: 6s - loss: 0.3053 - iou_score: 0.6859 - f1-score: 0.8113For batch 224, tr_loss is    0.31.\n",
      "226/232 [============================>.] - ETA: 5s - loss: 0.3052 - iou_score: 0.6858 - f1-score: 0.8113For batch 225, tr_loss is    0.31.\n",
      "227/232 [============================>.] - ETA: 4s - loss: 0.3051 - iou_score: 0.6860 - f1-score: 0.8113For batch 226, tr_loss is    0.31.\n",
      "228/232 [============================>.] - ETA: 3s - loss: 0.3052 - iou_score: 0.6858 - f1-score: 0.8113For batch 227, tr_loss is    0.31.\n",
      "229/232 [============================>.] - ETA: 2s - loss: 0.3050 - iou_score: 0.6859 - f1-score: 0.8113For batch 228, tr_loss is    0.30.\n",
      "230/232 [============================>.] - ETA: 1s - loss: 0.3052 - iou_score: 0.6857 - f1-score: 0.8112For batch 229, tr_loss is    0.31.\n",
      "231/232 [============================>.] - ETA: 0s - loss: 0.3055 - iou_score: 0.6854 - f1-score: 0.8110For batch 230, tr_loss is    0.31.\n",
      "232/232 [==============================] - ETA: 0s - loss: 0.3053 - iou_score: 0.6857 - f1-score: 0.8112For batch 231, tr_loss is    0.31.\n",
      "For batch 0, vl_loss is    0.45.\n",
      "For batch 1, vl_loss is    0.40.\n",
      "For batch 2, vl_loss is    0.40.\n",
      "For batch 3, vl_loss is    0.42.\n",
      "For batch 4, vl_loss is    0.44.\n",
      "For batch 5, vl_loss is    0.43.\n",
      "For batch 6, vl_loss is    0.43.\n",
      "For batch 7, vl_loss is    0.42.\n",
      "For batch 8, vl_loss is    0.42.\n",
      "For batch 9, vl_loss is    0.41.\n",
      "For batch 10, vl_loss is    0.41.\n",
      "For batch 11, vl_loss is    0.42.\n",
      "For batch 12, vl_loss is    0.42.\n",
      "For batch 13, vl_loss is    0.43.\n",
      "For batch 14, vl_loss is    0.42.\n",
      "For batch 15, vl_loss is    0.42.\n",
      "For batch 16, vl_loss is    0.41.\n",
      "For batch 17, vl_loss is    0.41.\n",
      "For batch 18, vl_loss is    0.41.\n",
      "For batch 19, vl_loss is    0.41.\n",
      "For batch 20, vl_loss is    0.40.\n",
      "For batch 21, vl_loss is    0.41.\n",
      "For batch 22, vl_loss is    0.41.\n",
      "For batch 23, vl_loss is    0.40.\n",
      "For batch 24, vl_loss is    0.40.\n",
      "For batch 25, vl_loss is    0.40.\n",
      "For batch 26, vl_loss is    0.40.\n",
      "For batch 27, vl_loss is    0.40.\n",
      "For batch 28, vl_loss is    0.40.\n",
      "For batch 29, vl_loss is    0.41.\n",
      "For batch 30, vl_loss is    0.40.\n",
      "For batch 31, vl_loss is    0.41.\n",
      "For batch 32, vl_loss is    0.41.\n",
      "For batch 33, vl_loss is    0.41.\n",
      "For batch 34, vl_loss is    0.40.\n",
      "For batch 35, vl_loss is    0.40.\n",
      "For batch 36, vl_loss is    0.40.\n",
      "For batch 37, vl_loss is    0.40.\n",
      "For batch 38, vl_loss is    0.40.\n",
      "For batch 39, vl_loss is    0.40.\n",
      "For batch 40, vl_loss is    0.40.\n",
      "For batch 41, vl_loss is    0.41.\n",
      "For batch 42, vl_loss is    0.41.\n",
      "For batch 43, vl_loss is    0.41.\n",
      "For batch 44, vl_loss is    0.41.\n",
      "For batch 45, vl_loss is    0.41.\n",
      "For batch 46, vl_loss is    0.41.\n",
      "For batch 47, vl_loss is    0.41.\n",
      "For batch 48, vl_loss is    0.41.\n",
      "For batch 49, vl_loss is    0.41.\n",
      "For batch 50, vl_loss is    0.41.\n",
      "For batch 51, vl_loss is    0.41.\n",
      "For batch 52, vl_loss is    0.41.\n",
      "For batch 53, vl_loss is    0.41.\n",
      "For batch 54, vl_loss is    0.42.\n",
      "For batch 55, vl_loss is    0.41.\n",
      "For batch 56, vl_loss is    0.41.\n",
      "For batch 57, vl_loss is    0.41.\n",
      "For batch 58, vl_loss is    0.41.\n",
      "For batch 59, vl_loss is    0.41.\n",
      "For batch 60, vl_loss is    0.41.\n",
      "For batch 61, vl_loss is    0.41.\n",
      "For batch 62, vl_loss is    0.41.\n",
      "For batch 63, vl_loss is    0.41.\n",
      "For batch 64, vl_loss is    0.41.\n",
      "For batch 65, vl_loss is    0.41.\n",
      "For batch 66, vl_loss is    0.40.\n",
      "For batch 67, vl_loss is    0.41.\n",
      "232/232 [==============================] - 207s 888ms/step - loss: 0.3053 - iou_score: 0.6857 - f1-score: 0.8112 - val_loss: 0.4050 - val_iou_score: 0.6433 - val_f1-score: 0.7807\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.45780 to 0.40504, saving model to ./model/tumor_100_unet_efficientnetb0_imagenet_09291.hdf5\n",
      "The average loss for epoch 2 is    0.31 \n",
      "Epoch 4/200\n",
      "  1/232 [..............................] - ETA: 11:20 - loss: 0.2413 - iou_score: 0.7676 - f1-score: 0.8666For batch 0, tr_loss is    0.24.\n",
      "  2/232 [..............................] - ETA: 4:32 - loss: 0.2532 - iou_score: 0.7465 - f1-score: 0.8537 For batch 1, tr_loss is    0.25.\n",
      "  3/232 [..............................] - ETA: 4:38 - loss: 0.2740 - iou_score: 0.7128 - f1-score: 0.8306For batch 2, tr_loss is    0.27.\n",
      "  4/232 [..............................] - ETA: 4:33 - loss: 0.2720 - iou_score: 0.7184 - f1-score: 0.8346For batch 3, tr_loss is    0.27.\n",
      "  5/232 [..............................] - ETA: 4:37 - loss: 0.2769 - iou_score: 0.7126 - f1-score: 0.8305For batch 4, tr_loss is    0.28.\n",
      "  6/232 [..............................] - ETA: 4:47 - loss: 0.2807 - iou_score: 0.7089 - f1-score: 0.8276For batch 5, tr_loss is    0.28.\n",
      "  7/232 [..............................] - ETA: 4:33 - loss: 0.2954 - iou_score: 0.6984 - f1-score: 0.8204For batch 6, tr_loss is    0.30.\n",
      "  8/232 [>.............................] - ETA: 4:33 - loss: 0.3012 - iou_score: 0.6890 - f1-score: 0.8139For batch 7, tr_loss is    0.30.\n",
      "  9/232 [>.............................] - ETA: 4:24 - loss: 0.2915 - iou_score: 0.7008 - f1-score: 0.8217For batch 8, tr_loss is    0.29.\n",
      " 10/232 [>.............................] - ETA: 4:17 - loss: 0.2912 - iou_score: 0.7010 - f1-score: 0.8220For batch 9, tr_loss is    0.29.\n",
      " 11/232 [>.............................] - ETA: 4:11 - loss: 0.2876 - iou_score: 0.7033 - f1-score: 0.8238For batch 10, tr_loss is    0.29.\n",
      " 12/232 [>.............................] - ETA: 3:57 - loss: 0.2825 - iou_score: 0.7108 - f1-score: 0.8288For batch 11, tr_loss is    0.28.\n",
      " 13/232 [>.............................] - ETA: 3:55 - loss: 0.2811 - iou_score: 0.7119 - f1-score: 0.8296For batch 12, tr_loss is    0.28.\n",
      " 14/232 [>.............................] - ETA: 3:44 - loss: 0.2761 - iou_score: 0.7168 - f1-score: 0.8330For batch 13, tr_loss is    0.28.\n",
      " 15/232 [>.............................] - ETA: 3:40 - loss: 0.2755 - iou_score: 0.7182 - f1-score: 0.8341For batch 14, tr_loss is    0.28.\n",
      " 16/232 [=>............................] - ETA: 3:34 - loss: 0.2749 - iou_score: 0.7179 - f1-score: 0.8339For batch 15, tr_loss is    0.27.\n",
      " 17/232 [=>............................] - ETA: 3:34 - loss: 0.2741 - iou_score: 0.7195 - f1-score: 0.8351For batch 16, tr_loss is    0.27.\n",
      " 18/232 [=>............................] - ETA: 3:27 - loss: 0.2757 - iou_score: 0.7181 - f1-score: 0.8342For batch 17, tr_loss is    0.28.\n",
      " 19/232 [=>............................] - ETA: 3:28 - loss: 0.2794 - iou_score: 0.7140 - f1-score: 0.8314For batch 18, tr_loss is    0.28.\n",
      " 20/232 [=>............................] - ETA: 3:21 - loss: 0.2770 - iou_score: 0.7154 - f1-score: 0.8324For batch 19, tr_loss is    0.28.\n",
      " 21/232 [=>............................] - ETA: 3:19 - loss: 0.2820 - iou_score: 0.7118 - f1-score: 0.8298For batch 20, tr_loss is    0.28.\n",
      " 22/232 [=>............................] - ETA: 3:17 - loss: 0.2859 - iou_score: 0.7083 - f1-score: 0.8271For batch 21, tr_loss is    0.29.\n",
      " 23/232 [=>............................] - ETA: 3:14 - loss: 0.2855 - iou_score: 0.7087 - f1-score: 0.8274For batch 22, tr_loss is    0.29.\n",
      " 24/232 [==>...........................] - ETA: 3:14 - loss: 0.2857 - iou_score: 0.7079 - f1-score: 0.8269For batch 23, tr_loss is    0.29.\n",
      " 25/232 [==>...........................] - ETA: 3:14 - loss: 0.2878 - iou_score: 0.7039 - f1-score: 0.8240For batch 24, tr_loss is    0.29.\n",
      " 26/232 [==>...........................] - ETA: 3:13 - loss: 0.2884 - iou_score: 0.7032 - f1-score: 0.8236For batch 25, tr_loss is    0.29.\n",
      " 27/232 [==>...........................] - ETA: 3:08 - loss: 0.2866 - iou_score: 0.7058 - f1-score: 0.8253For batch 26, tr_loss is    0.29.\n",
      " 28/232 [==>...........................] - ETA: 3:09 - loss: 0.2870 - iou_score: 0.7054 - f1-score: 0.8251For batch 27, tr_loss is    0.29.\n",
      " 29/232 [==>...........................] - ETA: 3:09 - loss: 0.2870 - iou_score: 0.7040 - f1-score: 0.8241For batch 28, tr_loss is    0.29.\n",
      " 30/232 [==>...........................] - ETA: 3:05 - loss: 0.2859 - iou_score: 0.7060 - f1-score: 0.8255For batch 29, tr_loss is    0.29.\n",
      " 31/232 [===>..........................] - ETA: 3:05 - loss: 0.2851 - iou_score: 0.7068 - f1-score: 0.8261For batch 30, tr_loss is    0.29.\n",
      " 32/232 [===>..........................] - ETA: 3:01 - loss: 0.2850 - iou_score: 0.7067 - f1-score: 0.8261For batch 31, tr_loss is    0.29.\n",
      " 33/232 [===>..........................] - ETA: 3:00 - loss: 0.2872 - iou_score: 0.7044 - f1-score: 0.8245For batch 32, tr_loss is    0.29.\n",
      " 34/232 [===>..........................] - ETA: 2:58 - loss: 0.2870 - iou_score: 0.7046 - f1-score: 0.8247For batch 33, tr_loss is    0.29.\n",
      " 35/232 [===>..........................] - ETA: 2:58 - loss: 0.2881 - iou_score: 0.7030 - f1-score: 0.8236For batch 34, tr_loss is    0.29.\n",
      " 36/232 [===>..........................] - ETA: 2:55 - loss: 0.2882 - iou_score: 0.7034 - f1-score: 0.8239For batch 35, tr_loss is    0.29.\n",
      " 37/232 [===>..........................] - ETA: 2:55 - loss: 0.2884 - iou_score: 0.7027 - f1-score: 0.8234For batch 36, tr_loss is    0.29.\n",
      " 38/232 [===>..........................] - ETA: 2:55 - loss: 0.2897 - iou_score: 0.7020 - f1-score: 0.8230For batch 37, tr_loss is    0.29.\n",
      " 39/232 [====>.........................] - ETA: 2:54 - loss: 0.2942 - iou_score: 0.6979 - f1-score: 0.8199For batch 38, tr_loss is    0.29.\n",
      " 40/232 [====>.........................] - ETA: 2:54 - loss: 0.2953 - iou_score: 0.6970 - f1-score: 0.8192For batch 39, tr_loss is    0.30.\n",
      " 41/232 [====>.........................] - ETA: 2:54 - loss: 0.2965 - iou_score: 0.6958 - f1-score: 0.8184For batch 40, tr_loss is    0.30.\n",
      " 42/232 [====>.........................] - ETA: 2:51 - loss: 0.2972 - iou_score: 0.6941 - f1-score: 0.8172For batch 41, tr_loss is    0.30.\n",
      " 43/232 [====>.........................] - ETA: 2:51 - loss: 0.2962 - iou_score: 0.6955 - f1-score: 0.8182For batch 42, tr_loss is    0.30.\n",
      " 44/232 [====>.........................] - ETA: 2:51 - loss: 0.2985 - iou_score: 0.6933 - f1-score: 0.8165For batch 43, tr_loss is    0.30.\n",
      " 45/232 [====>.........................] - ETA: 2:50 - loss: 0.2992 - iou_score: 0.6929 - f1-score: 0.8162For batch 44, tr_loss is    0.30.\n",
      " 46/232 [====>.........................] - ETA: 2:50 - loss: 0.2996 - iou_score: 0.6928 - f1-score: 0.8162For batch 45, tr_loss is    0.30.\n",
      " 47/232 [=====>........................] - ETA: 2:49 - loss: 0.2998 - iou_score: 0.6930 - f1-score: 0.8163For batch 46, tr_loss is    0.30.\n",
      " 48/232 [=====>........................] - ETA: 2:46 - loss: 0.2988 - iou_score: 0.6945 - f1-score: 0.8174For batch 47, tr_loss is    0.30.\n",
      " 49/232 [=====>........................] - ETA: 2:45 - loss: 0.2995 - iou_score: 0.6940 - f1-score: 0.8171For batch 48, tr_loss is    0.30.\n",
      " 50/232 [=====>........................] - ETA: 2:43 - loss: 0.2991 - iou_score: 0.6943 - f1-score: 0.8173For batch 49, tr_loss is    0.30.\n",
      " 51/232 [=====>........................] - ETA: 2:43 - loss: 0.3014 - iou_score: 0.6915 - f1-score: 0.8152For batch 50, tr_loss is    0.30.\n",
      " 52/232 [=====>........................] - ETA: 2:41 - loss: 0.3044 - iou_score: 0.6891 - f1-score: 0.8135For batch 51, tr_loss is    0.30.\n",
      " 53/232 [=====>........................] - ETA: 2:41 - loss: 0.3034 - iou_score: 0.6903 - f1-score: 0.8143For batch 52, tr_loss is    0.30.\n",
      " 54/232 [=====>........................] - ETA: 2:39 - loss: 0.3035 - iou_score: 0.6896 - f1-score: 0.8138For batch 53, tr_loss is    0.30.\n",
      " 55/232 [======>.......................] - ETA: 2:38 - loss: 0.3029 - iou_score: 0.6902 - f1-score: 0.8142For batch 54, tr_loss is    0.30.\n",
      " 56/232 [======>.......................] - ETA: 2:38 - loss: 0.3029 - iou_score: 0.6901 - f1-score: 0.8142For batch 55, tr_loss is    0.30.\n",
      " 57/232 [======>.......................] - ETA: 2:37 - loss: 0.3033 - iou_score: 0.6894 - f1-score: 0.8137For batch 56, tr_loss is    0.30.\n",
      " 58/232 [======>.......................] - ETA: 2:35 - loss: 0.3024 - iou_score: 0.6905 - f1-score: 0.8145For batch 57, tr_loss is    0.30.\n",
      " 59/232 [======>.......................] - ETA: 2:35 - loss: 0.3021 - iou_score: 0.6908 - f1-score: 0.8147For batch 58, tr_loss is    0.30.\n",
      " 60/232 [======>.......................] - ETA: 2:34 - loss: 0.3034 - iou_score: 0.6895 - f1-score: 0.8138For batch 59, tr_loss is    0.30.\n",
      " 61/232 [======>.......................] - ETA: 2:34 - loss: 0.3050 - iou_score: 0.6881 - f1-score: 0.8126For batch 60, tr_loss is    0.30.\n",
      " 62/232 [=======>......................] - ETA: 2:34 - loss: 0.3056 - iou_score: 0.6873 - f1-score: 0.8120For batch 61, tr_loss is    0.31.\n",
      " 63/232 [=======>......................] - ETA: 2:33 - loss: 0.3049 - iou_score: 0.6880 - f1-score: 0.8126For batch 62, tr_loss is    0.30.\n",
      " 64/232 [=======>......................] - ETA: 2:31 - loss: 0.3051 - iou_score: 0.6877 - f1-score: 0.8124For batch 63, tr_loss is    0.31.\n",
      " 65/232 [=======>......................] - ETA: 2:30 - loss: 0.3053 - iou_score: 0.6874 - f1-score: 0.8122For batch 64, tr_loss is    0.31.\n",
      " 66/232 [=======>......................] - ETA: 2:28 - loss: 0.3052 - iou_score: 0.6873 - f1-score: 0.8122For batch 65, tr_loss is    0.31.\n",
      " 67/232 [=======>......................] - ETA: 2:28 - loss: 0.3043 - iou_score: 0.6883 - f1-score: 0.8128For batch 66, tr_loss is    0.30.\n",
      " 68/232 [=======>......................] - ETA: 2:27 - loss: 0.3037 - iou_score: 0.6890 - f1-score: 0.8134For batch 67, tr_loss is    0.30.\n",
      " 69/232 [=======>......................] - ETA: 2:27 - loss: 0.3031 - iou_score: 0.6895 - f1-score: 0.8137For batch 68, tr_loss is    0.30.\n",
      " 70/232 [========>.....................] - ETA: 2:26 - loss: 0.3026 - iou_score: 0.6899 - f1-score: 0.8140For batch 69, tr_loss is    0.30.\n",
      " 71/232 [========>.....................] - ETA: 2:25 - loss: 0.3015 - iou_score: 0.6913 - f1-score: 0.8149For batch 70, tr_loss is    0.30.\n",
      " 72/232 [========>.....................] - ETA: 2:25 - loss: 0.3006 - iou_score: 0.6921 - f1-score: 0.8155For batch 71, tr_loss is    0.30.\n",
      " 73/232 [========>.....................] - ETA: 2:24 - loss: 0.3006 - iou_score: 0.6918 - f1-score: 0.8153For batch 72, tr_loss is    0.30.\n",
      " 74/232 [========>.....................] - ETA: 2:23 - loss: 0.2996 - iou_score: 0.6927 - f1-score: 0.8160For batch 73, tr_loss is    0.30.\n",
      " 75/232 [========>.....................] - ETA: 2:22 - loss: 0.2996 - iou_score: 0.6927 - f1-score: 0.8160For batch 74, tr_loss is    0.30.\n",
      " 76/232 [========>.....................] - ETA: 2:21 - loss: 0.2991 - iou_score: 0.6929 - f1-score: 0.8162For batch 75, tr_loss is    0.30.\n",
      " 77/232 [========>.....................] - ETA: 2:20 - loss: 0.2982 - iou_score: 0.6937 - f1-score: 0.8167For batch 76, tr_loss is    0.30.\n",
      " 78/232 [=========>....................] - ETA: 2:19 - loss: 0.2983 - iou_score: 0.6933 - f1-score: 0.8165For batch 77, tr_loss is    0.30.\n",
      " 79/232 [=========>....................] - ETA: 2:19 - loss: 0.2978 - iou_score: 0.6938 - f1-score: 0.8169For batch 78, tr_loss is    0.30.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80/232 [=========>....................] - ETA: 2:17 - loss: 0.2977 - iou_score: 0.6938 - f1-score: 0.8168For batch 79, tr_loss is    0.30.\n",
      " 81/232 [=========>....................] - ETA: 2:17 - loss: 0.2981 - iou_score: 0.6932 - f1-score: 0.8164For batch 80, tr_loss is    0.30.\n",
      " 82/232 [=========>....................] - ETA: 2:15 - loss: 0.2981 - iou_score: 0.6931 - f1-score: 0.8164For batch 81, tr_loss is    0.30.\n",
      " 83/232 [=========>....................] - ETA: 2:14 - loss: 0.2994 - iou_score: 0.6915 - f1-score: 0.8152For batch 82, tr_loss is    0.30.\n",
      " 84/232 [=========>....................] - ETA: 2:13 - loss: 0.2997 - iou_score: 0.6912 - f1-score: 0.8150For batch 83, tr_loss is    0.30.\n",
      " 85/232 [=========>....................] - ETA: 2:12 - loss: 0.3003 - iou_score: 0.6908 - f1-score: 0.8147For batch 84, tr_loss is    0.30.\n",
      " 86/232 [==========>...................] - ETA: 2:11 - loss: 0.3006 - iou_score: 0.6902 - f1-score: 0.8143For batch 85, tr_loss is    0.30.\n",
      " 87/232 [==========>...................] - ETA: 2:10 - loss: 0.3004 - iou_score: 0.6905 - f1-score: 0.8145For batch 86, tr_loss is    0.30.\n",
      " 88/232 [==========>...................] - ETA: 2:08 - loss: 0.3012 - iou_score: 0.6894 - f1-score: 0.8137For batch 87, tr_loss is    0.30.\n",
      " 89/232 [==========>...................] - ETA: 2:07 - loss: 0.3009 - iou_score: 0.6899 - f1-score: 0.8141For batch 88, tr_loss is    0.30.\n",
      " 90/232 [==========>...................] - ETA: 2:06 - loss: 0.3003 - iou_score: 0.6906 - f1-score: 0.8146For batch 89, tr_loss is    0.30.\n",
      " 91/232 [==========>...................] - ETA: 2:05 - loss: 0.3002 - iou_score: 0.6908 - f1-score: 0.8147For batch 90, tr_loss is    0.30.\n",
      " 92/232 [==========>...................] - ETA: 2:05 - loss: 0.3000 - iou_score: 0.6907 - f1-score: 0.8147For batch 91, tr_loss is    0.30.\n",
      " 93/232 [===========>..................] - ETA: 2:04 - loss: 0.3009 - iou_score: 0.6896 - f1-score: 0.8138For batch 92, tr_loss is    0.30.\n",
      " 94/232 [===========>..................] - ETA: 2:03 - loss: 0.3003 - iou_score: 0.6904 - f1-score: 0.8144For batch 93, tr_loss is    0.30.\n",
      " 95/232 [===========>..................] - ETA: 2:02 - loss: 0.3005 - iou_score: 0.6900 - f1-score: 0.8141For batch 94, tr_loss is    0.30.\n",
      " 96/232 [===========>..................] - ETA: 2:01 - loss: 0.3002 - iou_score: 0.6903 - f1-score: 0.8143For batch 95, tr_loss is    0.30.\n",
      " 97/232 [===========>..................] - ETA: 1:59 - loss: 0.3004 - iou_score: 0.6900 - f1-score: 0.8141For batch 96, tr_loss is    0.30.\n",
      " 98/232 [===========>..................] - ETA: 1:59 - loss: 0.3003 - iou_score: 0.6900 - f1-score: 0.8141For batch 97, tr_loss is    0.30.\n",
      " 99/232 [===========>..................] - ETA: 1:58 - loss: 0.2996 - iou_score: 0.6909 - f1-score: 0.8148For batch 98, tr_loss is    0.30.\n",
      "100/232 [===========>..................] - ETA: 1:57 - loss: 0.2989 - iou_score: 0.6917 - f1-score: 0.8153For batch 99, tr_loss is    0.30.\n",
      "101/232 [============>.................] - ETA: 1:56 - loss: 0.2985 - iou_score: 0.6924 - f1-score: 0.8158For batch 100, tr_loss is    0.30.\n",
      "102/232 [============>.................] - ETA: 1:55 - loss: 0.2984 - iou_score: 0.6923 - f1-score: 0.8158For batch 101, tr_loss is    0.30.\n",
      "103/232 [============>.................] - ETA: 1:55 - loss: 0.2986 - iou_score: 0.6923 - f1-score: 0.8157For batch 102, tr_loss is    0.30.\n",
      "104/232 [============>.................] - ETA: 1:54 - loss: 0.2985 - iou_score: 0.6923 - f1-score: 0.8158For batch 103, tr_loss is    0.30.\n",
      "105/232 [============>.................] - ETA: 1:53 - loss: 0.2977 - iou_score: 0.6932 - f1-score: 0.8164For batch 104, tr_loss is    0.30.\n",
      "106/232 [============>.................] - ETA: 1:52 - loss: 0.2970 - iou_score: 0.6942 - f1-score: 0.8170For batch 105, tr_loss is    0.30.\n",
      "107/232 [============>.................] - ETA: 1:51 - loss: 0.2973 - iou_score: 0.6939 - f1-score: 0.8168For batch 106, tr_loss is    0.30.\n",
      "108/232 [============>.................] - ETA: 1:50 - loss: 0.2978 - iou_score: 0.6931 - f1-score: 0.8163For batch 107, tr_loss is    0.30.\n",
      "109/232 [=============>................] - ETA: 1:49 - loss: 0.2971 - iou_score: 0.6938 - f1-score: 0.8167For batch 108, tr_loss is    0.30.\n",
      "110/232 [=============>................] - ETA: 1:48 - loss: 0.2963 - iou_score: 0.6947 - f1-score: 0.8174For batch 109, tr_loss is    0.30.\n",
      "111/232 [=============>................] - ETA: 1:47 - loss: 0.2963 - iou_score: 0.6943 - f1-score: 0.8171For batch 110, tr_loss is    0.30.\n",
      "112/232 [=============>................] - ETA: 1:46 - loss: 0.2970 - iou_score: 0.6936 - f1-score: 0.8166For batch 111, tr_loss is    0.30.\n",
      "113/232 [=============>................] - ETA: 1:45 - loss: 0.2975 - iou_score: 0.6933 - f1-score: 0.8164For batch 112, tr_loss is    0.30.\n",
      "114/232 [=============>................] - ETA: 1:44 - loss: 0.2968 - iou_score: 0.6942 - f1-score: 0.8170For batch 113, tr_loss is    0.30.\n",
      "115/232 [=============>................] - ETA: 1:43 - loss: 0.2964 - iou_score: 0.6946 - f1-score: 0.8173For batch 114, tr_loss is    0.30.\n",
      "116/232 [==============>...............] - ETA: 1:42 - loss: 0.2959 - iou_score: 0.6949 - f1-score: 0.8175For batch 115, tr_loss is    0.30.\n",
      "117/232 [==============>...............] - ETA: 1:42 - loss: 0.2957 - iou_score: 0.6951 - f1-score: 0.8177For batch 116, tr_loss is    0.30.\n",
      "118/232 [==============>...............] - ETA: 1:40 - loss: 0.2953 - iou_score: 0.6957 - f1-score: 0.8181For batch 117, tr_loss is    0.30.\n",
      "119/232 [==============>...............] - ETA: 1:40 - loss: 0.2948 - iou_score: 0.6963 - f1-score: 0.8185For batch 118, tr_loss is    0.29.\n",
      "120/232 [==============>...............] - ETA: 1:39 - loss: 0.2952 - iou_score: 0.6959 - f1-score: 0.8183For batch 119, tr_loss is    0.30.\n",
      "121/232 [==============>...............] - ETA: 1:38 - loss: 0.2944 - iou_score: 0.6967 - f1-score: 0.8188For batch 120, tr_loss is    0.29.\n",
      "122/232 [==============>...............] - ETA: 1:37 - loss: 0.2948 - iou_score: 0.6963 - f1-score: 0.8185For batch 121, tr_loss is    0.29.\n",
      "123/232 [==============>...............] - ETA: 1:36 - loss: 0.2944 - iou_score: 0.6966 - f1-score: 0.8187For batch 122, tr_loss is    0.29.\n",
      "124/232 [===============>..............] - ETA: 1:35 - loss: 0.2945 - iou_score: 0.6966 - f1-score: 0.8187For batch 123, tr_loss is    0.29.\n",
      "125/232 [===============>..............] - ETA: 1:34 - loss: 0.2948 - iou_score: 0.6961 - f1-score: 0.8184For batch 124, tr_loss is    0.29.\n",
      "126/232 [===============>..............] - ETA: 1:33 - loss: 0.2950 - iou_score: 0.6963 - f1-score: 0.8186For batch 125, tr_loss is    0.30.\n",
      "127/232 [===============>..............] - ETA: 1:33 - loss: 0.2948 - iou_score: 0.6963 - f1-score: 0.8185For batch 126, tr_loss is    0.29.\n",
      "128/232 [===============>..............] - ETA: 1:32 - loss: 0.2953 - iou_score: 0.6956 - f1-score: 0.8181For batch 127, tr_loss is    0.30.\n",
      "129/232 [===============>..............] - ETA: 1:31 - loss: 0.2954 - iou_score: 0.6952 - f1-score: 0.8178For batch 128, tr_loss is    0.30.\n",
      "130/232 [===============>..............] - ETA: 1:30 - loss: 0.2955 - iou_score: 0.6958 - f1-score: 0.8182For batch 129, tr_loss is    0.30.\n",
      "131/232 [===============>..............] - ETA: 1:29 - loss: 0.2962 - iou_score: 0.6952 - f1-score: 0.8177For batch 130, tr_loss is    0.30.\n",
      "132/232 [================>.............] - ETA: 1:28 - loss: 0.2963 - iou_score: 0.6951 - f1-score: 0.8177For batch 131, tr_loss is    0.30.\n",
      "133/232 [================>.............] - ETA: 1:27 - loss: 0.2959 - iou_score: 0.6955 - f1-score: 0.8180For batch 132, tr_loss is    0.30.\n",
      "134/232 [================>.............] - ETA: 1:26 - loss: 0.2963 - iou_score: 0.6947 - f1-score: 0.8174For batch 133, tr_loss is    0.30.\n",
      "135/232 [================>.............] - ETA: 1:25 - loss: 0.2959 - iou_score: 0.6952 - f1-score: 0.8177For batch 134, tr_loss is    0.30.\n",
      "136/232 [================>.............] - ETA: 1:24 - loss: 0.2963 - iou_score: 0.6947 - f1-score: 0.8174For batch 135, tr_loss is    0.30.\n",
      "137/232 [================>.............] - ETA: 1:24 - loss: 0.2964 - iou_score: 0.6945 - f1-score: 0.8173For batch 136, tr_loss is    0.30.\n",
      "138/232 [================>.............] - ETA: 1:23 - loss: 0.2964 - iou_score: 0.6943 - f1-score: 0.8172For batch 137, tr_loss is    0.30.\n",
      "139/232 [================>.............] - ETA: 1:22 - loss: 0.2962 - iou_score: 0.6946 - f1-score: 0.8174For batch 138, tr_loss is    0.30.\n",
      "140/232 [=================>............] - ETA: 1:21 - loss: 0.2960 - iou_score: 0.6950 - f1-score: 0.8176For batch 139, tr_loss is    0.30.\n",
      "141/232 [=================>............] - ETA: 1:20 - loss: 0.2968 - iou_score: 0.6941 - f1-score: 0.8170For batch 140, tr_loss is    0.30.\n",
      "142/232 [=================>............] - ETA: 1:19 - loss: 0.2966 - iou_score: 0.6941 - f1-score: 0.8170For batch 141, tr_loss is    0.30.\n",
      "143/232 [=================>............] - ETA: 1:18 - loss: 0.2964 - iou_score: 0.6942 - f1-score: 0.8171For batch 142, tr_loss is    0.30.\n",
      "144/232 [=================>............] - ETA: 1:17 - loss: 0.2963 - iou_score: 0.6942 - f1-score: 0.8171For batch 143, tr_loss is    0.30.\n",
      "145/232 [=================>............] - ETA: 1:16 - loss: 0.2961 - iou_score: 0.6944 - f1-score: 0.8172For batch 144, tr_loss is    0.30.\n",
      "146/232 [=================>............] - ETA: 1:15 - loss: 0.2963 - iou_score: 0.6941 - f1-score: 0.8170For batch 145, tr_loss is    0.30.\n",
      "147/232 [==================>...........] - ETA: 1:14 - loss: 0.2959 - iou_score: 0.6945 - f1-score: 0.8174For batch 146, tr_loss is    0.30.\n",
      "148/232 [==================>...........] - ETA: 1:13 - loss: 0.2963 - iou_score: 0.6941 - f1-score: 0.8170For batch 147, tr_loss is    0.30.\n",
      "149/232 [==================>...........] - ETA: 1:12 - loss: 0.2960 - iou_score: 0.6945 - f1-score: 0.8173For batch 148, tr_loss is    0.30.\n",
      "150/232 [==================>...........] - ETA: 1:11 - loss: 0.2967 - iou_score: 0.6936 - f1-score: 0.8167For batch 149, tr_loss is    0.30.\n",
      "151/232 [==================>...........] - ETA: 1:10 - loss: 0.2969 - iou_score: 0.6933 - f1-score: 0.8164For batch 150, tr_loss is    0.30.\n",
      "152/232 [==================>...........] - ETA: 1:09 - loss: 0.2966 - iou_score: 0.6937 - f1-score: 0.8167For batch 151, tr_loss is    0.30.\n",
      "153/232 [==================>...........] - ETA: 1:09 - loss: 0.2965 - iou_score: 0.6937 - f1-score: 0.8167For batch 152, tr_loss is    0.30.\n",
      "154/232 [==================>...........] - ETA: 1:08 - loss: 0.2963 - iou_score: 0.6939 - f1-score: 0.8169For batch 153, tr_loss is    0.30.\n",
      "155/232 [===================>..........] - ETA: 1:07 - loss: 0.2960 - iou_score: 0.6941 - f1-score: 0.8170For batch 154, tr_loss is    0.30.\n",
      "156/232 [===================>..........] - ETA: 1:06 - loss: 0.2962 - iou_score: 0.6939 - f1-score: 0.8169For batch 155, tr_loss is    0.30.\n",
      "157/232 [===================>..........] - ETA: 1:05 - loss: 0.2969 - iou_score: 0.6935 - f1-score: 0.8166For batch 156, tr_loss is    0.30.\n",
      "158/232 [===================>..........] - ETA: 1:05 - loss: 0.2965 - iou_score: 0.6938 - f1-score: 0.8168For batch 157, tr_loss is    0.30.\n",
      "159/232 [===================>..........] - ETA: 1:04 - loss: 0.2966 - iou_score: 0.6939 - f1-score: 0.8169For batch 158, tr_loss is    0.30.\n",
      "160/232 [===================>..........] - ETA: 1:03 - loss: 0.2966 - iou_score: 0.6936 - f1-score: 0.8167For batch 159, tr_loss is    0.30.\n",
      "161/232 [===================>..........] - ETA: 1:02 - loss: 0.2962 - iou_score: 0.6940 - f1-score: 0.8170For batch 160, tr_loss is    0.30.\n",
      "162/232 [===================>..........] - ETA: 1:01 - loss: 0.2963 - iou_score: 0.6940 - f1-score: 0.8169For batch 161, tr_loss is    0.30.\n",
      "163/232 [====================>.........] - ETA: 1:00 - loss: 0.2959 - iou_score: 0.6944 - f1-score: 0.8172For batch 162, tr_loss is    0.30.\n",
      "164/232 [====================>.........] - ETA: 59s - loss: 0.2959 - iou_score: 0.6944 - f1-score: 0.8172 For batch 163, tr_loss is    0.30.\n",
      "165/232 [====================>.........] - ETA: 58s - loss: 0.2960 - iou_score: 0.6941 - f1-score: 0.8170For batch 164, tr_loss is    0.30.\n",
      "166/232 [====================>.........] - ETA: 58s - loss: 0.2961 - iou_score: 0.6940 - f1-score: 0.8170For batch 165, tr_loss is    0.30.\n",
      "167/232 [====================>.........] - ETA: 57s - loss: 0.2959 - iou_score: 0.6942 - f1-score: 0.8171For batch 166, tr_loss is    0.30.\n",
      "168/232 [====================>.........] - ETA: 56s - loss: 0.2962 - iou_score: 0.6939 - f1-score: 0.8169For batch 167, tr_loss is    0.30.\n",
      "169/232 [====================>.........] - ETA: 55s - loss: 0.2966 - iou_score: 0.6934 - f1-score: 0.8165For batch 168, tr_loss is    0.30.\n",
      "170/232 [====================>.........] - ETA: 54s - loss: 0.2965 - iou_score: 0.6935 - f1-score: 0.8166For batch 169, tr_loss is    0.30.\n",
      "171/232 [=====================>........] - ETA: 53s - loss: 0.2969 - iou_score: 0.6931 - f1-score: 0.8163For batch 170, tr_loss is    0.30.\n",
      "172/232 [=====================>........] - ETA: 52s - loss: 0.2970 - iou_score: 0.6928 - f1-score: 0.8161For batch 171, tr_loss is    0.30.\n",
      "173/232 [=====================>........] - ETA: 52s - loss: 0.2968 - iou_score: 0.6928 - f1-score: 0.8161For batch 172, tr_loss is    0.30.\n",
      "174/232 [=====================>........] - ETA: 51s - loss: 0.2965 - iou_score: 0.6931 - f1-score: 0.8163For batch 173, tr_loss is    0.30.\n",
      "175/232 [=====================>........] - ETA: 50s - loss: 0.2966 - iou_score: 0.6930 - f1-score: 0.8162For batch 174, tr_loss is    0.30.\n",
      "176/232 [=====================>........] - ETA: 49s - loss: 0.2967 - iou_score: 0.6928 - f1-score: 0.8161For batch 175, tr_loss is    0.30.\n",
      "177/232 [=====================>........] - ETA: 48s - loss: 0.2966 - iou_score: 0.6931 - f1-score: 0.8164For batch 176, tr_loss is    0.30.\n",
      "178/232 [======================>.......] - ETA: 47s - loss: 0.2965 - iou_score: 0.6932 - f1-score: 0.8164For batch 177, tr_loss is    0.30.\n",
      "179/232 [======================>.......] - ETA: 46s - loss: 0.2964 - iou_score: 0.6934 - f1-score: 0.8166For batch 178, tr_loss is    0.30.\n",
      "180/232 [======================>.......] - ETA: 45s - loss: 0.2965 - iou_score: 0.6933 - f1-score: 0.8165For batch 179, tr_loss is    0.30.\n",
      "181/232 [======================>.......] - ETA: 44s - loss: 0.2966 - iou_score: 0.6931 - f1-score: 0.8164For batch 180, tr_loss is    0.30.\n",
      "182/232 [======================>.......] - ETA: 44s - loss: 0.2966 - iou_score: 0.6931 - f1-score: 0.8164For batch 181, tr_loss is    0.30.\n",
      "183/232 [======================>.......] - ETA: 43s - loss: 0.2965 - iou_score: 0.6932 - f1-score: 0.8164For batch 182, tr_loss is    0.30.\n",
      "184/232 [======================>.......] - ETA: 42s - loss: 0.2961 - iou_score: 0.6936 - f1-score: 0.8167For batch 183, tr_loss is    0.30.\n",
      "185/232 [======================>.......] - ETA: 41s - loss: 0.2963 - iou_score: 0.6936 - f1-score: 0.8167For batch 184, tr_loss is    0.30.\n",
      "186/232 [=======================>......] - ETA: 40s - loss: 0.2964 - iou_score: 0.6935 - f1-score: 0.8167For batch 185, tr_loss is    0.30.\n",
      "187/232 [=======================>......] - ETA: 39s - loss: 0.2959 - iou_score: 0.6940 - f1-score: 0.8170For batch 186, tr_loss is    0.30.\n",
      "188/232 [=======================>......] - ETA: 38s - loss: 0.2960 - iou_score: 0.6939 - f1-score: 0.8169For batch 187, tr_loss is    0.30.\n",
      "189/232 [=======================>......] - ETA: 37s - loss: 0.2959 - iou_score: 0.6940 - f1-score: 0.8170For batch 188, tr_loss is    0.30.\n",
      "190/232 [=======================>......] - ETA: 36s - loss: 0.2958 - iou_score: 0.6941 - f1-score: 0.8170For batch 189, tr_loss is    0.30.\n",
      "191/232 [=======================>......] - ETA: 36s - loss: 0.2960 - iou_score: 0.6940 - f1-score: 0.8170For batch 190, tr_loss is    0.30.\n",
      "192/232 [=======================>......] - ETA: 35s - loss: 0.2962 - iou_score: 0.6938 - f1-score: 0.8169For batch 191, tr_loss is    0.30.\n",
      "193/232 [=======================>......] - ETA: 34s - loss: 0.2967 - iou_score: 0.6931 - f1-score: 0.8164For batch 192, tr_loss is    0.30.\n",
      "194/232 [========================>.....] - ETA: 33s - loss: 0.2967 - iou_score: 0.6929 - f1-score: 0.8162For batch 193, tr_loss is    0.30.\n",
      "195/232 [========================>.....] - ETA: 32s - loss: 0.2967 - iou_score: 0.6928 - f1-score: 0.8162For batch 194, tr_loss is    0.30.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/232 [========================>.....] - ETA: 31s - loss: 0.2966 - iou_score: 0.6929 - f1-score: 0.8162For batch 195, tr_loss is    0.30.\n",
      "197/232 [========================>.....] - ETA: 30s - loss: 0.2965 - iou_score: 0.6929 - f1-score: 0.8162For batch 196, tr_loss is    0.30.\n",
      "198/232 [========================>.....] - ETA: 29s - loss: 0.2964 - iou_score: 0.6933 - f1-score: 0.8165For batch 197, tr_loss is    0.30.\n",
      "199/232 [========================>.....] - ETA: 28s - loss: 0.2962 - iou_score: 0.6934 - f1-score: 0.8165For batch 198, tr_loss is    0.30.\n",
      "200/232 [========================>.....] - ETA: 28s - loss: 0.2958 - iou_score: 0.6938 - f1-score: 0.8169For batch 199, tr_loss is    0.30.\n",
      "201/232 [========================>.....] - ETA: 27s - loss: 0.2959 - iou_score: 0.6937 - f1-score: 0.8168For batch 200, tr_loss is    0.30.\n",
      "202/232 [=========================>....] - ETA: 26s - loss: 0.2958 - iou_score: 0.6937 - f1-score: 0.8168For batch 201, tr_loss is    0.30.\n",
      "203/232 [=========================>....] - ETA: 25s - loss: 0.2956 - iou_score: 0.6939 - f1-score: 0.8169For batch 202, tr_loss is    0.30.\n",
      "204/232 [=========================>....] - ETA: 24s - loss: 0.2952 - iou_score: 0.6943 - f1-score: 0.8172For batch 203, tr_loss is    0.30.\n",
      "205/232 [=========================>....] - ETA: 23s - loss: 0.2952 - iou_score: 0.6941 - f1-score: 0.8171For batch 204, tr_loss is    0.30.\n",
      "206/232 [=========================>....] - ETA: 22s - loss: 0.2954 - iou_score: 0.6941 - f1-score: 0.8170For batch 205, tr_loss is    0.30.\n",
      "207/232 [=========================>....] - ETA: 21s - loss: 0.2952 - iou_score: 0.6943 - f1-score: 0.8172For batch 206, tr_loss is    0.30.\n",
      "208/232 [=========================>....] - ETA: 21s - loss: 0.2951 - iou_score: 0.6944 - f1-score: 0.8172For batch 207, tr_loss is    0.30.\n",
      "209/232 [==========================>...] - ETA: 20s - loss: 0.2953 - iou_score: 0.6941 - f1-score: 0.8171For batch 208, tr_loss is    0.30.\n",
      "210/232 [==========================>...] - ETA: 19s - loss: 0.2955 - iou_score: 0.6939 - f1-score: 0.8169For batch 209, tr_loss is    0.30.\n",
      "211/232 [==========================>...] - ETA: 18s - loss: 0.2953 - iou_score: 0.6941 - f1-score: 0.8171For batch 210, tr_loss is    0.30.\n",
      "212/232 [==========================>...] - ETA: 17s - loss: 0.2950 - iou_score: 0.6945 - f1-score: 0.8173For batch 211, tr_loss is    0.30.\n",
      "213/232 [==========================>...] - ETA: 16s - loss: 0.2954 - iou_score: 0.6943 - f1-score: 0.8172For batch 212, tr_loss is    0.30.\n",
      "214/232 [==========================>...] - ETA: 15s - loss: 0.2952 - iou_score: 0.6945 - f1-score: 0.8174For batch 213, tr_loss is    0.30.\n",
      "215/232 [==========================>...] - ETA: 14s - loss: 0.2947 - iou_score: 0.6950 - f1-score: 0.8177For batch 214, tr_loss is    0.29.\n",
      "216/232 [==========================>...] - ETA: 14s - loss: 0.2946 - iou_score: 0.6952 - f1-score: 0.8178For batch 215, tr_loss is    0.29.\n",
      "217/232 [===========================>..] - ETA: 13s - loss: 0.2947 - iou_score: 0.6950 - f1-score: 0.8177For batch 216, tr_loss is    0.29.\n",
      "218/232 [===========================>..] - ETA: 12s - loss: 0.2947 - iou_score: 0.6949 - f1-score: 0.8176For batch 217, tr_loss is    0.29.\n",
      "219/232 [===========================>..] - ETA: 11s - loss: 0.2953 - iou_score: 0.6944 - f1-score: 0.8172For batch 218, tr_loss is    0.30.\n",
      "220/232 [===========================>..] - ETA: 10s - loss: 0.2953 - iou_score: 0.6943 - f1-score: 0.8172For batch 219, tr_loss is    0.30.\n",
      "221/232 [===========================>..] - ETA: 9s - loss: 0.2955 - iou_score: 0.6940 - f1-score: 0.8170 For batch 220, tr_loss is    0.30.\n",
      "222/232 [===========================>..] - ETA: 8s - loss: 0.2953 - iou_score: 0.6943 - f1-score: 0.8172For batch 221, tr_loss is    0.30.\n",
      "223/232 [===========================>..] - ETA: 7s - loss: 0.2953 - iou_score: 0.6941 - f1-score: 0.8171For batch 222, tr_loss is    0.30.\n",
      "224/232 [===========================>..] - ETA: 7s - loss: 0.2951 - iou_score: 0.6945 - f1-score: 0.8173For batch 223, tr_loss is    0.30.\n",
      "225/232 [============================>.] - ETA: 6s - loss: 0.2949 - iou_score: 0.6948 - f1-score: 0.8175For batch 224, tr_loss is    0.29.\n",
      "226/232 [============================>.] - ETA: 5s - loss: 0.2949 - iou_score: 0.6947 - f1-score: 0.8175For batch 225, tr_loss is    0.29.\n",
      "227/232 [============================>.] - ETA: 4s - loss: 0.2948 - iou_score: 0.6949 - f1-score: 0.8176For batch 226, tr_loss is    0.29.\n",
      "228/232 [============================>.] - ETA: 3s - loss: 0.2949 - iou_score: 0.6948 - f1-score: 0.8176For batch 227, tr_loss is    0.29.\n",
      "229/232 [============================>.] - ETA: 2s - loss: 0.2946 - iou_score: 0.6949 - f1-score: 0.8177For batch 228, tr_loss is    0.29.\n",
      "230/232 [============================>.] - ETA: 1s - loss: 0.2950 - iou_score: 0.6946 - f1-score: 0.8174For batch 229, tr_loss is    0.30.\n",
      "231/232 [============================>.] - ETA: 0s - loss: 0.2951 - iou_score: 0.6944 - f1-score: 0.8173For batch 230, tr_loss is    0.30.\n",
      "232/232 [==============================] - ETA: 0s - loss: 0.2948 - iou_score: 0.6948 - f1-score: 0.8176For batch 231, tr_loss is    0.29.\n",
      "For batch 0, vl_loss is    0.41.\n",
      "For batch 1, vl_loss is    0.38.\n",
      "For batch 2, vl_loss is    0.41.\n",
      "For batch 3, vl_loss is    0.41.\n",
      "For batch 4, vl_loss is    0.45.\n",
      "For batch 5, vl_loss is    0.43.\n",
      "For batch 6, vl_loss is    0.44.\n",
      "For batch 7, vl_loss is    0.43.\n",
      "For batch 8, vl_loss is    0.42.\n",
      "For batch 9, vl_loss is    0.41.\n",
      "For batch 10, vl_loss is    0.41.\n",
      "For batch 11, vl_loss is    0.41.\n",
      "For batch 12, vl_loss is    0.42.\n",
      "For batch 13, vl_loss is    0.42.\n",
      "For batch 14, vl_loss is    0.42.\n",
      "For batch 15, vl_loss is    0.41.\n",
      "For batch 16, vl_loss is    0.40.\n",
      "For batch 17, vl_loss is    0.41.\n",
      "For batch 18, vl_loss is    0.41.\n",
      "For batch 19, vl_loss is    0.40.\n",
      "For batch 20, vl_loss is    0.40.\n",
      "For batch 21, vl_loss is    0.40.\n",
      "For batch 22, vl_loss is    0.40.\n",
      "For batch 23, vl_loss is    0.40.\n",
      "For batch 24, vl_loss is    0.40.\n",
      "For batch 25, vl_loss is    0.40.\n",
      "For batch 26, vl_loss is    0.40.\n",
      "For batch 27, vl_loss is    0.40.\n",
      "For batch 28, vl_loss is    0.40.\n",
      "For batch 29, vl_loss is    0.40.\n",
      "For batch 30, vl_loss is    0.40.\n",
      "For batch 31, vl_loss is    0.40.\n",
      "For batch 32, vl_loss is    0.40.\n",
      "For batch 33, vl_loss is    0.40.\n",
      "For batch 34, vl_loss is    0.40.\n",
      "For batch 35, vl_loss is    0.40.\n",
      "For batch 36, vl_loss is    0.40.\n",
      "For batch 37, vl_loss is    0.40.\n",
      "For batch 38, vl_loss is    0.40.\n",
      "For batch 39, vl_loss is    0.40.\n",
      "For batch 40, vl_loss is    0.40.\n",
      "For batch 41, vl_loss is    0.40.\n",
      "For batch 42, vl_loss is    0.41.\n",
      "For batch 43, vl_loss is    0.41.\n",
      "For batch 44, vl_loss is    0.41.\n",
      "For batch 45, vl_loss is    0.41.\n",
      "For batch 46, vl_loss is    0.41.\n",
      "For batch 47, vl_loss is    0.41.\n",
      "For batch 48, vl_loss is    0.41.\n",
      "For batch 49, vl_loss is    0.40.\n",
      "For batch 50, vl_loss is    0.41.\n",
      "For batch 51, vl_loss is    0.41.\n",
      "For batch 52, vl_loss is    0.41.\n",
      "For batch 53, vl_loss is    0.41.\n",
      "For batch 54, vl_loss is    0.41.\n",
      "For batch 55, vl_loss is    0.41.\n",
      "For batch 56, vl_loss is    0.41.\n",
      "For batch 57, vl_loss is    0.41.\n",
      "For batch 58, vl_loss is    0.41.\n",
      "For batch 59, vl_loss is    0.41.\n",
      "For batch 60, vl_loss is    0.41.\n",
      "For batch 61, vl_loss is    0.40.\n",
      "For batch 62, vl_loss is    0.40.\n",
      "For batch 63, vl_loss is    0.40.\n",
      "For batch 64, vl_loss is    0.40.\n",
      "For batch 65, vl_loss is    0.40.\n",
      "For batch 66, vl_loss is    0.40.\n",
      "For batch 67, vl_loss is    0.40.\n",
      "232/232 [==============================] - 207s 884ms/step - loss: 0.2948 - iou_score: 0.6948 - f1-score: 0.8176 - val_loss: 0.4010 - val_iou_score: 0.6470 - val_f1-score: 0.7834\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.40504 to 0.40105, saving model to ./model/tumor_100_unet_efficientnetb0_imagenet_09291.hdf5\n",
      "The average loss for epoch 3 is    0.29 \n",
      "Epoch 5/200\n",
      "  1/232 [..............................] - ETA: 7:32 - loss: 0.2352 - iou_score: 0.7686 - f1-score: 0.8676For batch 0, tr_loss is    0.24.\n",
      "  2/232 [..............................] - ETA: 4:47 - loss: 0.2502 - iou_score: 0.7499 - f1-score: 0.8561For batch 1, tr_loss is    0.25.\n",
      "  3/232 [..............................] - ETA: 4:46 - loss: 0.2681 - iou_score: 0.7203 - f1-score: 0.8360For batch 2, tr_loss is    0.27.\n",
      "  4/232 [..............................] - ETA: 5:09 - loss: 0.2656 - iou_score: 0.7258 - f1-score: 0.8399For batch 3, tr_loss is    0.27.\n",
      "  5/232 [..............................] - ETA: 5:33 - loss: 0.2736 - iou_score: 0.7172 - f1-score: 0.8339For batch 4, tr_loss is    0.27.\n",
      "  6/232 [..............................] - ETA: 5:41 - loss: 0.2797 - iou_score: 0.7120 - f1-score: 0.8297For batch 5, tr_loss is    0.28.\n",
      "  7/232 [..............................] - ETA: 5:22 - loss: 0.2878 - iou_score: 0.7021 - f1-score: 0.8229For batch 6, tr_loss is    0.29.\n",
      "  8/232 [>.............................] - ETA: 5:07 - loss: 0.2957 - iou_score: 0.6911 - f1-score: 0.8152For batch 7, tr_loss is    0.30.\n",
      "  9/232 [>.............................] - ETA: 4:57 - loss: 0.2867 - iou_score: 0.7025 - f1-score: 0.8229For batch 8, tr_loss is    0.29.\n",
      " 10/232 [>.............................] - ETA: 4:40 - loss: 0.2862 - iou_score: 0.7012 - f1-score: 0.8221For batch 9, tr_loss is    0.29.\n",
      " 11/232 [>.............................] - ETA: 4:34 - loss: 0.2831 - iou_score: 0.7033 - f1-score: 0.8238For batch 10, tr_loss is    0.28.\n",
      " 12/232 [>.............................] - ETA: 4:27 - loss: 0.2799 - iou_score: 0.7104 - f1-score: 0.8286For batch 11, tr_loss is    0.28.\n",
      " 13/232 [>.............................] - ETA: 4:18 - loss: 0.2783 - iou_score: 0.7131 - f1-score: 0.8303For batch 12, tr_loss is    0.28.\n",
      " 14/232 [>.............................] - ETA: 4:14 - loss: 0.2739 - iou_score: 0.7172 - f1-score: 0.8332For batch 13, tr_loss is    0.27.\n",
      " 15/232 [>.............................] - ETA: 4:11 - loss: 0.2709 - iou_score: 0.7200 - f1-score: 0.8352For batch 14, tr_loss is    0.27.\n",
      " 16/232 [=>............................] - ETA: 4:07 - loss: 0.2680 - iou_score: 0.7218 - f1-score: 0.8364For batch 15, tr_loss is    0.27.\n",
      " 17/232 [=>............................] - ETA: 3:57 - loss: 0.2655 - iou_score: 0.7250 - f1-score: 0.8386For batch 16, tr_loss is    0.27.\n",
      " 18/232 [=>............................] - ETA: 3:55 - loss: 0.2659 - iou_score: 0.7244 - f1-score: 0.8383For batch 17, tr_loss is    0.27.\n",
      " 19/232 [=>............................] - ETA: 3:46 - loss: 0.2683 - iou_score: 0.7210 - f1-score: 0.8360For batch 18, tr_loss is    0.27.\n",
      " 20/232 [=>............................] - ETA: 3:42 - loss: 0.2661 - iou_score: 0.7223 - f1-score: 0.8370For batch 19, tr_loss is    0.27.\n",
      " 21/232 [=>............................] - ETA: 3:41 - loss: 0.2714 - iou_score: 0.7193 - f1-score: 0.8348For batch 20, tr_loss is    0.27.\n",
      " 22/232 [=>............................] - ETA: 3:40 - loss: 0.2745 - iou_score: 0.7157 - f1-score: 0.8320For batch 21, tr_loss is    0.27.\n",
      " 23/232 [=>............................] - ETA: 3:37 - loss: 0.2745 - iou_score: 0.7160 - f1-score: 0.8323For batch 22, tr_loss is    0.27.\n",
      " 24/232 [==>...........................] - ETA: 3:35 - loss: 0.2738 - iou_score: 0.7163 - f1-score: 0.8326For batch 23, tr_loss is    0.27.\n",
      " 25/232 [==>...........................] - ETA: 3:29 - loss: 0.2761 - iou_score: 0.7119 - f1-score: 0.8295For batch 24, tr_loss is    0.28.\n",
      " 26/232 [==>...........................] - ETA: 3:26 - loss: 0.2776 - iou_score: 0.7112 - f1-score: 0.8290For batch 25, tr_loss is    0.28.\n",
      " 27/232 [==>...........................] - ETA: 3:27 - loss: 0.2753 - iou_score: 0.7143 - f1-score: 0.8311For batch 26, tr_loss is    0.28.\n",
      " 28/232 [==>...........................] - ETA: 3:24 - loss: 0.2759 - iou_score: 0.7140 - f1-score: 0.8309For batch 27, tr_loss is    0.28.\n",
      " 29/232 [==>...........................] - ETA: 3:23 - loss: 0.2762 - iou_score: 0.7120 - f1-score: 0.8294For batch 28, tr_loss is    0.28.\n",
      " 30/232 [==>...........................] - ETA: 3:20 - loss: 0.2749 - iou_score: 0.7137 - f1-score: 0.8307For batch 29, tr_loss is    0.27.\n",
      " 31/232 [===>..........................] - ETA: 3:15 - loss: 0.2746 - iou_score: 0.7145 - f1-score: 0.8313For batch 30, tr_loss is    0.27.\n",
      " 32/232 [===>..........................] - ETA: 3:15 - loss: 0.2746 - iou_score: 0.7144 - f1-score: 0.8312For batch 31, tr_loss is    0.27.\n",
      " 33/232 [===>..........................] - ETA: 3:14 - loss: 0.2775 - iou_score: 0.7117 - f1-score: 0.8293For batch 32, tr_loss is    0.28.\n",
      " 34/232 [===>..........................] - ETA: 3:14 - loss: 0.2777 - iou_score: 0.7114 - f1-score: 0.8292For batch 33, tr_loss is    0.28.\n",
      " 35/232 [===>..........................] - ETA: 3:13 - loss: 0.2791 - iou_score: 0.7094 - f1-score: 0.8279For batch 34, tr_loss is    0.28.\n",
      " 36/232 [===>..........................] - ETA: 3:10 - loss: 0.2795 - iou_score: 0.7096 - f1-score: 0.8281For batch 35, tr_loss is    0.28.\n",
      " 37/232 [===>..........................] - ETA: 3:10 - loss: 0.2798 - iou_score: 0.7092 - f1-score: 0.8278For batch 36, tr_loss is    0.28.\n",
      " 38/232 [===>..........................] - ETA: 3:08 - loss: 0.2814 - iou_score: 0.7078 - f1-score: 0.8269For batch 37, tr_loss is    0.28.\n",
      " 39/232 [====>.........................] - ETA: 3:08 - loss: 0.2852 - iou_score: 0.7045 - f1-score: 0.8244For batch 38, tr_loss is    0.29.\n",
      " 40/232 [====>.........................] - ETA: 3:07 - loss: 0.2864 - iou_score: 0.7040 - f1-score: 0.8241For batch 39, tr_loss is    0.29.\n",
      " 41/232 [====>.........................] - ETA: 3:06 - loss: 0.2875 - iou_score: 0.7029 - f1-score: 0.8234For batch 40, tr_loss is    0.29.\n",
      " 42/232 [====>.........................] - ETA: 3:03 - loss: 0.2879 - iou_score: 0.7018 - f1-score: 0.8226For batch 41, tr_loss is    0.29.\n",
      " 43/232 [====>.........................] - ETA: 3:02 - loss: 0.2872 - iou_score: 0.7026 - f1-score: 0.8232For batch 42, tr_loss is    0.29.\n",
      " 44/232 [====>.........................] - ETA: 2:59 - loss: 0.2899 - iou_score: 0.7001 - f1-score: 0.8212For batch 43, tr_loss is    0.29.\n",
      " 45/232 [====>.........................] - ETA: 2:57 - loss: 0.2904 - iou_score: 0.6996 - f1-score: 0.8208For batch 44, tr_loss is    0.29.\n",
      " 46/232 [====>.........................] - ETA: 2:57 - loss: 0.2906 - iou_score: 0.6999 - f1-score: 0.8211For batch 45, tr_loss is    0.29.\n",
      " 47/232 [=====>........................] - ETA: 2:56 - loss: 0.2901 - iou_score: 0.7006 - f1-score: 0.8217For batch 46, tr_loss is    0.29.\n",
      " 48/232 [=====>........................] - ETA: 2:53 - loss: 0.2890 - iou_score: 0.7024 - f1-score: 0.8229For batch 47, tr_loss is    0.29.\n",
      " 49/232 [=====>........................] - ETA: 2:53 - loss: 0.2899 - iou_score: 0.7020 - f1-score: 0.8226For batch 48, tr_loss is    0.29.\n",
      " 50/232 [=====>........................] - ETA: 2:53 - loss: 0.2895 - iou_score: 0.7027 - f1-score: 0.8231For batch 49, tr_loss is    0.29.\n",
      " 51/232 [=====>........................] - ETA: 2:52 - loss: 0.2912 - iou_score: 0.7008 - f1-score: 0.8218For batch 50, tr_loss is    0.29.\n",
      " 52/232 [=====>........................] - ETA: 2:52 - loss: 0.2937 - iou_score: 0.6987 - f1-score: 0.8202For batch 51, tr_loss is    0.29.\n",
      " 53/232 [=====>........................] - ETA: 2:51 - loss: 0.2926 - iou_score: 0.6998 - f1-score: 0.8210For batch 52, tr_loss is    0.29.\n",
      " 54/232 [=====>........................] - ETA: 2:50 - loss: 0.2927 - iou_score: 0.6990 - f1-score: 0.8205For batch 53, tr_loss is    0.29.\n",
      " 55/232 [======>.......................] - ETA: 2:47 - loss: 0.2920 - iou_score: 0.6995 - f1-score: 0.8209For batch 54, tr_loss is    0.29.\n",
      " 56/232 [======>.......................] - ETA: 2:46 - loss: 0.2923 - iou_score: 0.6992 - f1-score: 0.8207For batch 55, tr_loss is    0.29.\n",
      " 57/232 [======>.......................] - ETA: 2:45 - loss: 0.2929 - iou_score: 0.6982 - f1-score: 0.8199For batch 56, tr_loss is    0.29.\n",
      " 58/232 [======>.......................] - ETA: 2:44 - loss: 0.2921 - iou_score: 0.6994 - f1-score: 0.8208For batch 57, tr_loss is    0.29.\n",
      " 59/232 [======>.......................] - ETA: 2:42 - loss: 0.2914 - iou_score: 0.7000 - f1-score: 0.8213For batch 58, tr_loss is    0.29.\n",
      " 60/232 [======>.......................] - ETA: 2:40 - loss: 0.2932 - iou_score: 0.6984 - f1-score: 0.8201For batch 59, tr_loss is    0.29.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 61/232 [======>.......................] - ETA: 2:40 - loss: 0.2948 - iou_score: 0.6970 - f1-score: 0.8190For batch 60, tr_loss is    0.29.\n",
      " 62/232 [=======>......................] - ETA: 2:40 - loss: 0.2957 - iou_score: 0.6964 - f1-score: 0.8186For batch 61, tr_loss is    0.30.\n",
      " 63/232 [=======>......................] - ETA: 2:38 - loss: 0.2949 - iou_score: 0.6975 - f1-score: 0.8193For batch 62, tr_loss is    0.29.\n",
      " 64/232 [=======>......................] - ETA: 2:37 - loss: 0.2948 - iou_score: 0.6973 - f1-score: 0.8192For batch 63, tr_loss is    0.29.\n",
      " 65/232 [=======>......................] - ETA: 2:36 - loss: 0.2948 - iou_score: 0.6976 - f1-score: 0.8194For batch 64, tr_loss is    0.29.\n",
      " 66/232 [=======>......................] - ETA: 2:34 - loss: 0.2946 - iou_score: 0.6974 - f1-score: 0.8193For batch 65, tr_loss is    0.29.\n",
      " 67/232 [=======>......................] - ETA: 2:33 - loss: 0.2936 - iou_score: 0.6983 - f1-score: 0.8200For batch 66, tr_loss is    0.29.\n",
      " 68/232 [=======>......................] - ETA: 2:31 - loss: 0.2933 - iou_score: 0.6987 - f1-score: 0.8202For batch 67, tr_loss is    0.29.\n",
      " 69/232 [=======>......................] - ETA: 2:30 - loss: 0.2930 - iou_score: 0.6990 - f1-score: 0.8205For batch 68, tr_loss is    0.29.\n",
      " 70/232 [========>.....................] - ETA: 2:28 - loss: 0.2923 - iou_score: 0.6995 - f1-score: 0.8208For batch 69, tr_loss is    0.29.\n",
      " 71/232 [========>.....................] - ETA: 2:28 - loss: 0.2913 - iou_score: 0.7007 - f1-score: 0.8217For batch 70, tr_loss is    0.29.\n",
      " 72/232 [========>.....................] - ETA: 2:27 - loss: 0.2904 - iou_score: 0.7016 - f1-score: 0.8222For batch 71, tr_loss is    0.29.\n",
      " 73/232 [========>.....................] - ETA: 2:26 - loss: 0.2907 - iou_score: 0.7010 - f1-score: 0.8218For batch 72, tr_loss is    0.29.\n",
      " 74/232 [========>.....................] - ETA: 2:24 - loss: 0.2895 - iou_score: 0.7021 - f1-score: 0.8226For batch 73, tr_loss is    0.29.\n",
      " 75/232 [========>.....................] - ETA: 2:23 - loss: 0.2896 - iou_score: 0.7021 - f1-score: 0.8226For batch 74, tr_loss is    0.29.\n",
      " 76/232 [========>.....................] - ETA: 2:22 - loss: 0.2891 - iou_score: 0.7025 - f1-score: 0.8229For batch 75, tr_loss is    0.29.\n",
      " 77/232 [========>.....................] - ETA: 2:21 - loss: 0.2881 - iou_score: 0.7033 - f1-score: 0.8235For batch 76, tr_loss is    0.29.\n",
      " 78/232 [=========>....................] - ETA: 2:20 - loss: 0.2884 - iou_score: 0.7028 - f1-score: 0.8232For batch 77, tr_loss is    0.29.\n",
      " 79/232 [=========>....................] - ETA: 2:19 - loss: 0.2881 - iou_score: 0.7030 - f1-score: 0.8233For batch 78, tr_loss is    0.29.\n",
      " 80/232 [=========>....................] - ETA: 2:17 - loss: 0.2879 - iou_score: 0.7030 - f1-score: 0.8233For batch 79, tr_loss is    0.29.\n",
      " 81/232 [=========>....................] - ETA: 2:16 - loss: 0.2882 - iou_score: 0.7025 - f1-score: 0.8230For batch 80, tr_loss is    0.29.\n",
      " 82/232 [=========>....................] - ETA: 2:16 - loss: 0.2883 - iou_score: 0.7022 - f1-score: 0.8228For batch 81, tr_loss is    0.29.\n",
      " 83/232 [=========>....................] - ETA: 2:15 - loss: 0.2892 - iou_score: 0.7008 - f1-score: 0.8218For batch 82, tr_loss is    0.29.\n",
      " 84/232 [=========>....................] - ETA: 2:13 - loss: 0.2895 - iou_score: 0.7003 - f1-score: 0.8214For batch 83, tr_loss is    0.29.\n",
      " 85/232 [=========>....................] - ETA: 2:12 - loss: 0.2896 - iou_score: 0.7000 - f1-score: 0.8212For batch 84, tr_loss is    0.29.\n",
      " 86/232 [==========>...................] - ETA: 2:11 - loss: 0.2901 - iou_score: 0.6992 - f1-score: 0.8207For batch 85, tr_loss is    0.29.\n",
      " 87/232 [==========>...................] - ETA: 2:11 - loss: 0.2898 - iou_score: 0.6996 - f1-score: 0.8210For batch 86, tr_loss is    0.29.\n",
      " 88/232 [==========>...................] - ETA: 2:09 - loss: 0.2907 - iou_score: 0.6986 - f1-score: 0.8202For batch 87, tr_loss is    0.29.\n",
      " 89/232 [==========>...................] - ETA: 2:09 - loss: 0.2904 - iou_score: 0.6991 - f1-score: 0.8206For batch 88, tr_loss is    0.29.\n",
      " 90/232 [==========>...................] - ETA: 2:08 - loss: 0.2900 - iou_score: 0.6996 - f1-score: 0.8210For batch 89, tr_loss is    0.29.\n",
      " 91/232 [==========>...................] - ETA: 2:07 - loss: 0.2899 - iou_score: 0.7000 - f1-score: 0.8213For batch 90, tr_loss is    0.29.\n",
      " 92/232 [==========>...................] - ETA: 2:06 - loss: 0.2897 - iou_score: 0.7001 - f1-score: 0.8213For batch 91, tr_loss is    0.29.\n",
      " 93/232 [===========>..................] - ETA: 2:06 - loss: 0.2910 - iou_score: 0.6986 - f1-score: 0.8202For batch 92, tr_loss is    0.29.\n",
      " 94/232 [===========>..................] - ETA: 2:05 - loss: 0.2903 - iou_score: 0.6995 - f1-score: 0.8207For batch 93, tr_loss is    0.29.\n",
      " 95/232 [===========>..................] - ETA: 2:04 - loss: 0.2905 - iou_score: 0.6992 - f1-score: 0.8205For batch 94, tr_loss is    0.29.\n",
      " 96/232 [===========>..................] - ETA: 2:03 - loss: 0.2902 - iou_score: 0.6995 - f1-score: 0.8208For batch 95, tr_loss is    0.29.\n",
      " 97/232 [===========>..................] - ETA: 2:02 - loss: 0.2906 - iou_score: 0.6989 - f1-score: 0.8203For batch 96, tr_loss is    0.29.\n",
      " 98/232 [===========>..................] - ETA: 2:01 - loss: 0.2905 - iou_score: 0.6988 - f1-score: 0.8203For batch 97, tr_loss is    0.29.\n",
      " 99/232 [===========>..................] - ETA: 2:00 - loss: 0.2896 - iou_score: 0.6999 - f1-score: 0.8210For batch 98, tr_loss is    0.29.\n",
      "100/232 [===========>..................] - ETA: 2:00 - loss: 0.2890 - iou_score: 0.7006 - f1-score: 0.8215For batch 99, tr_loss is    0.29.\n",
      "101/232 [============>.................] - ETA: 1:59 - loss: 0.2886 - iou_score: 0.7013 - f1-score: 0.8220For batch 100, tr_loss is    0.29.\n",
      "102/232 [============>.................] - ETA: 1:57 - loss: 0.2885 - iou_score: 0.7013 - f1-score: 0.8220For batch 101, tr_loss is    0.29.\n",
      "103/232 [============>.................] - ETA: 1:57 - loss: 0.2888 - iou_score: 0.7012 - f1-score: 0.8220For batch 102, tr_loss is    0.29.\n",
      "104/232 [============>.................] - ETA: 1:56 - loss: 0.2885 - iou_score: 0.7016 - f1-score: 0.8222For batch 103, tr_loss is    0.29.\n",
      "105/232 [============>.................] - ETA: 1:54 - loss: 0.2878 - iou_score: 0.7024 - f1-score: 0.8228For batch 104, tr_loss is    0.29.\n",
      "106/232 [============>.................] - ETA: 1:54 - loss: 0.2870 - iou_score: 0.7033 - f1-score: 0.8234For batch 105, tr_loss is    0.29.\n",
      "107/232 [============>.................] - ETA: 1:53 - loss: 0.2873 - iou_score: 0.7031 - f1-score: 0.8233For batch 106, tr_loss is    0.29.\n",
      "108/232 [============>.................] - ETA: 1:52 - loss: 0.2880 - iou_score: 0.7022 - f1-score: 0.8226For batch 107, tr_loss is    0.29.\n",
      "109/232 [=============>................] - ETA: 1:51 - loss: 0.2873 - iou_score: 0.7027 - f1-score: 0.8230For batch 108, tr_loss is    0.29.\n",
      "110/232 [=============>................] - ETA: 1:50 - loss: 0.2866 - iou_score: 0.7036 - f1-score: 0.8235For batch 109, tr_loss is    0.29.\n",
      "111/232 [=============>................] - ETA: 1:50 - loss: 0.2865 - iou_score: 0.7034 - f1-score: 0.8235For batch 110, tr_loss is    0.29.\n",
      "112/232 [=============>................] - ETA: 1:49 - loss: 0.2868 - iou_score: 0.7030 - f1-score: 0.8232For batch 111, tr_loss is    0.29.\n",
      "113/232 [=============>................] - ETA: 1:47 - loss: 0.2874 - iou_score: 0.7027 - f1-score: 0.8230For batch 112, tr_loss is    0.29.\n",
      "114/232 [=============>................] - ETA: 1:46 - loss: 0.2868 - iou_score: 0.7033 - f1-score: 0.8234For batch 113, tr_loss is    0.29.\n",
      "115/232 [=============>................] - ETA: 1:46 - loss: 0.2867 - iou_score: 0.7033 - f1-score: 0.8234For batch 114, tr_loss is    0.29.\n",
      "116/232 [==============>...............] - ETA: 1:45 - loss: 0.2865 - iou_score: 0.7034 - f1-score: 0.8235For batch 115, tr_loss is    0.29.\n",
      "117/232 [==============>...............] - ETA: 1:44 - loss: 0.2864 - iou_score: 0.7035 - f1-score: 0.8235For batch 116, tr_loss is    0.29.\n",
      "118/232 [==============>...............] - ETA: 1:43 - loss: 0.2858 - iou_score: 0.7042 - f1-score: 0.8240For batch 117, tr_loss is    0.29.\n",
      "119/232 [==============>...............] - ETA: 1:42 - loss: 0.2853 - iou_score: 0.7049 - f1-score: 0.8245For batch 118, tr_loss is    0.29.\n",
      "120/232 [==============>...............] - ETA: 1:41 - loss: 0.2857 - iou_score: 0.7044 - f1-score: 0.8242For batch 119, tr_loss is    0.29.\n",
      "121/232 [==============>...............] - ETA: 1:40 - loss: 0.2850 - iou_score: 0.7051 - f1-score: 0.8247For batch 120, tr_loss is    0.29.\n",
      "122/232 [==============>...............] - ETA: 1:39 - loss: 0.2854 - iou_score: 0.7046 - f1-score: 0.8243For batch 121, tr_loss is    0.29.\n",
      "123/232 [==============>...............] - ETA: 1:38 - loss: 0.2850 - iou_score: 0.7049 - f1-score: 0.8245For batch 122, tr_loss is    0.29.\n",
      "124/232 [===============>..............] - ETA: 1:37 - loss: 0.2851 - iou_score: 0.7049 - f1-score: 0.8245For batch 123, tr_loss is    0.29.\n",
      "125/232 [===============>..............] - ETA: 1:36 - loss: 0.2854 - iou_score: 0.7045 - f1-score: 0.8242For batch 124, tr_loss is    0.29.\n",
      "126/232 [===============>..............] - ETA: 1:35 - loss: 0.2854 - iou_score: 0.7046 - f1-score: 0.8243For batch 125, tr_loss is    0.29.\n",
      "127/232 [===============>..............] - ETA: 1:34 - loss: 0.2852 - iou_score: 0.7046 - f1-score: 0.8244For batch 126, tr_loss is    0.29.\n",
      "128/232 [===============>..............] - ETA: 1:33 - loss: 0.2855 - iou_score: 0.7038 - f1-score: 0.8238For batch 127, tr_loss is    0.29.\n",
      "129/232 [===============>..............] - ETA: 1:32 - loss: 0.2857 - iou_score: 0.7034 - f1-score: 0.8235For batch 128, tr_loss is    0.29.\n",
      "130/232 [===============>..............] - ETA: 1:31 - loss: 0.2856 - iou_score: 0.7040 - f1-score: 0.8239For batch 129, tr_loss is    0.29.\n",
      "131/232 [===============>..............] - ETA: 1:30 - loss: 0.2864 - iou_score: 0.7032 - f1-score: 0.8233For batch 130, tr_loss is    0.29.\n",
      "132/232 [================>.............] - ETA: 1:29 - loss: 0.2869 - iou_score: 0.7030 - f1-score: 0.8232For batch 131, tr_loss is    0.29.\n",
      "133/232 [================>.............] - ETA: 1:29 - loss: 0.2865 - iou_score: 0.7033 - f1-score: 0.8234For batch 132, tr_loss is    0.29.\n",
      "134/232 [================>.............] - ETA: 1:28 - loss: 0.2872 - iou_score: 0.7023 - f1-score: 0.8227For batch 133, tr_loss is    0.29.\n",
      "135/232 [================>.............] - ETA: 1:27 - loss: 0.2868 - iou_score: 0.7026 - f1-score: 0.8229For batch 134, tr_loss is    0.29.\n",
      "136/232 [================>.............] - ETA: 1:26 - loss: 0.2873 - iou_score: 0.7020 - f1-score: 0.8225For batch 135, tr_loss is    0.29.\n",
      "137/232 [================>.............] - ETA: 1:25 - loss: 0.2874 - iou_score: 0.7018 - f1-score: 0.8223For batch 136, tr_loss is    0.29.\n",
      "138/232 [================>.............] - ETA: 1:24 - loss: 0.2874 - iou_score: 0.7017 - f1-score: 0.8223For batch 137, tr_loss is    0.29.\n",
      "139/232 [================>.............] - ETA: 1:23 - loss: 0.2873 - iou_score: 0.7018 - f1-score: 0.8223For batch 138, tr_loss is    0.29.\n",
      "140/232 [=================>............] - ETA: 1:22 - loss: 0.2872 - iou_score: 0.7020 - f1-score: 0.8225For batch 139, tr_loss is    0.29.\n",
      "141/232 [=================>............] - ETA: 1:22 - loss: 0.2877 - iou_score: 0.7012 - f1-score: 0.8219For batch 140, tr_loss is    0.29.\n",
      "142/232 [=================>............] - ETA: 1:21 - loss: 0.2876 - iou_score: 0.7011 - f1-score: 0.8219For batch 141, tr_loss is    0.29.\n",
      "143/232 [=================>............] - ETA: 1:20 - loss: 0.2873 - iou_score: 0.7014 - f1-score: 0.8221For batch 142, tr_loss is    0.29.\n",
      "144/232 [=================>............] - ETA: 1:19 - loss: 0.2871 - iou_score: 0.7015 - f1-score: 0.8222For batch 143, tr_loss is    0.29.\n",
      "145/232 [=================>............] - ETA: 1:18 - loss: 0.2869 - iou_score: 0.7017 - f1-score: 0.8223For batch 144, tr_loss is    0.29.\n",
      "146/232 [=================>............] - ETA: 1:17 - loss: 0.2870 - iou_score: 0.7014 - f1-score: 0.8221For batch 145, tr_loss is    0.29.\n",
      "147/232 [==================>...........] - ETA: 1:17 - loss: 0.2867 - iou_score: 0.7018 - f1-score: 0.8224For batch 146, tr_loss is    0.29.\n",
      "148/232 [==================>...........] - ETA: 1:16 - loss: 0.2870 - iou_score: 0.7014 - f1-score: 0.8221For batch 147, tr_loss is    0.29.\n",
      "149/232 [==================>...........] - ETA: 1:15 - loss: 0.2867 - iou_score: 0.7018 - f1-score: 0.8224For batch 148, tr_loss is    0.29.\n",
      "150/232 [==================>...........] - ETA: 1:14 - loss: 0.2873 - iou_score: 0.7010 - f1-score: 0.8218For batch 149, tr_loss is    0.29.\n",
      "151/232 [==================>...........] - ETA: 1:13 - loss: 0.2875 - iou_score: 0.7007 - f1-score: 0.8216For batch 150, tr_loss is    0.29.\n",
      "152/232 [==================>...........] - ETA: 1:12 - loss: 0.2871 - iou_score: 0.7011 - f1-score: 0.8219For batch 151, tr_loss is    0.29.\n",
      "153/232 [==================>...........] - ETA: 1:11 - loss: 0.2869 - iou_score: 0.7012 - f1-score: 0.8219For batch 152, tr_loss is    0.29.\n",
      "154/232 [==================>...........] - ETA: 1:10 - loss: 0.2865 - iou_score: 0.7015 - f1-score: 0.8222For batch 153, tr_loss is    0.29.\n",
      "155/232 [===================>..........] - ETA: 1:09 - loss: 0.2866 - iou_score: 0.7014 - f1-score: 0.8221For batch 154, tr_loss is    0.29.\n",
      "156/232 [===================>..........] - ETA: 1:08 - loss: 0.2866 - iou_score: 0.7014 - f1-score: 0.8221For batch 155, tr_loss is    0.29.\n",
      "157/232 [===================>..........] - ETA: 1:07 - loss: 0.2869 - iou_score: 0.7011 - f1-score: 0.8219For batch 156, tr_loss is    0.29.\n",
      "158/232 [===================>..........] - ETA: 1:06 - loss: 0.2867 - iou_score: 0.7013 - f1-score: 0.8220For batch 157, tr_loss is    0.29.\n",
      "159/232 [===================>..........] - ETA: 1:05 - loss: 0.2865 - iou_score: 0.7015 - f1-score: 0.8222For batch 158, tr_loss is    0.29.\n",
      "160/232 [===================>..........] - ETA: 1:04 - loss: 0.2863 - iou_score: 0.7013 - f1-score: 0.8221For batch 159, tr_loss is    0.29.\n",
      "161/232 [===================>..........] - ETA: 1:04 - loss: 0.2862 - iou_score: 0.7016 - f1-score: 0.8223For batch 160, tr_loss is    0.29.\n",
      "162/232 [===================>..........] - ETA: 1:03 - loss: 0.2863 - iou_score: 0.7015 - f1-score: 0.8222For batch 161, tr_loss is    0.29.\n",
      "163/232 [====================>.........] - ETA: 1:02 - loss: 0.2860 - iou_score: 0.7018 - f1-score: 0.8224For batch 162, tr_loss is    0.29.\n",
      "164/232 [====================>.........] - ETA: 1:01 - loss: 0.2861 - iou_score: 0.7017 - f1-score: 0.8224For batch 163, tr_loss is    0.29.\n",
      "165/232 [====================>.........] - ETA: 1:00 - loss: 0.2863 - iou_score: 0.7014 - f1-score: 0.8222For batch 164, tr_loss is    0.29.\n",
      "166/232 [====================>.........] - ETA: 59s - loss: 0.2860 - iou_score: 0.7014 - f1-score: 0.8222 For batch 165, tr_loss is    0.29.\n",
      "167/232 [====================>.........] - ETA: 58s - loss: 0.2859 - iou_score: 0.7015 - f1-score: 0.8222For batch 166, tr_loss is    0.29.\n",
      "168/232 [====================>.........] - ETA: 57s - loss: 0.2862 - iou_score: 0.7012 - f1-score: 0.8221For batch 167, tr_loss is    0.29.\n",
      "169/232 [====================>.........] - ETA: 56s - loss: 0.2867 - iou_score: 0.7007 - f1-score: 0.8217For batch 168, tr_loss is    0.29.\n",
      "170/232 [====================>.........] - ETA: 55s - loss: 0.2870 - iou_score: 0.7005 - f1-score: 0.8216For batch 169, tr_loss is    0.29.\n",
      "171/232 [=====================>........] - ETA: 54s - loss: 0.2874 - iou_score: 0.7000 - f1-score: 0.8212For batch 170, tr_loss is    0.29.\n",
      "172/232 [=====================>........] - ETA: 54s - loss: 0.2877 - iou_score: 0.6997 - f1-score: 0.8210For batch 171, tr_loss is    0.29.\n",
      "173/232 [=====================>........] - ETA: 53s - loss: 0.2874 - iou_score: 0.6999 - f1-score: 0.8212For batch 172, tr_loss is    0.29.\n",
      "174/232 [=====================>........] - ETA: 52s - loss: 0.2872 - iou_score: 0.7002 - f1-score: 0.8213For batch 173, tr_loss is    0.29.\n",
      "175/232 [=====================>........] - ETA: 51s - loss: 0.2873 - iou_score: 0.7000 - f1-score: 0.8212For batch 174, tr_loss is    0.29.\n",
      "176/232 [=====================>........] - ETA: 50s - loss: 0.2875 - iou_score: 0.6997 - f1-score: 0.8210For batch 175, tr_loss is    0.29.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/232 [=====================>........] - ETA: 49s - loss: 0.2872 - iou_score: 0.7003 - f1-score: 0.8214For batch 176, tr_loss is    0.29.\n",
      "178/232 [======================>.......] - ETA: 48s - loss: 0.2872 - iou_score: 0.7004 - f1-score: 0.8215For batch 177, tr_loss is    0.29.\n",
      "179/232 [======================>.......] - ETA: 47s - loss: 0.2870 - iou_score: 0.7007 - f1-score: 0.8217For batch 178, tr_loss is    0.29.\n",
      "180/232 [======================>.......] - ETA: 46s - loss: 0.2870 - iou_score: 0.7006 - f1-score: 0.8216For batch 179, tr_loss is    0.29.\n",
      "181/232 [======================>.......] - ETA: 45s - loss: 0.2871 - iou_score: 0.7005 - f1-score: 0.8216For batch 180, tr_loss is    0.29.\n",
      "182/232 [======================>.......] - ETA: 45s - loss: 0.2870 - iou_score: 0.7006 - f1-score: 0.8216For batch 181, tr_loss is    0.29.\n",
      "183/232 [======================>.......] - ETA: 44s - loss: 0.2870 - iou_score: 0.7006 - f1-score: 0.8216For batch 182, tr_loss is    0.29.\n",
      "184/232 [======================>.......] - ETA: 43s - loss: 0.2867 - iou_score: 0.7010 - f1-score: 0.8219For batch 183, tr_loss is    0.29.\n",
      "185/232 [======================>.......] - ETA: 42s - loss: 0.2867 - iou_score: 0.7010 - f1-score: 0.8220For batch 184, tr_loss is    0.29.\n",
      "186/232 [=======================>......] - ETA: 41s - loss: 0.2867 - iou_score: 0.7010 - f1-score: 0.8219For batch 185, tr_loss is    0.29.\n",
      "187/232 [=======================>......] - ETA: 40s - loss: 0.2862 - iou_score: 0.7015 - f1-score: 0.8223For batch 186, tr_loss is    0.29.\n",
      "188/232 [=======================>......] - ETA: 39s - loss: 0.2864 - iou_score: 0.7014 - f1-score: 0.8222For batch 187, tr_loss is    0.29.\n",
      "189/232 [=======================>......] - ETA: 38s - loss: 0.2863 - iou_score: 0.7016 - f1-score: 0.8223For batch 188, tr_loss is    0.29.\n",
      "190/232 [=======================>......] - ETA: 38s - loss: 0.2861 - iou_score: 0.7017 - f1-score: 0.8224For batch 189, tr_loss is    0.29.\n",
      "191/232 [=======================>......] - ETA: 37s - loss: 0.2861 - iou_score: 0.7017 - f1-score: 0.8224For batch 190, tr_loss is    0.29.\n",
      "192/232 [=======================>......] - ETA: 36s - loss: 0.2862 - iou_score: 0.7015 - f1-score: 0.8223For batch 191, tr_loss is    0.29.\n",
      "193/232 [=======================>......] - ETA: 35s - loss: 0.2866 - iou_score: 0.7010 - f1-score: 0.8219For batch 192, tr_loss is    0.29.\n",
      "194/232 [========================>.....] - ETA: 34s - loss: 0.2866 - iou_score: 0.7008 - f1-score: 0.8218For batch 193, tr_loss is    0.29.\n",
      "195/232 [========================>.....] - ETA: 33s - loss: 0.2866 - iou_score: 0.7007 - f1-score: 0.8217For batch 194, tr_loss is    0.29.\n",
      "196/232 [========================>.....] - ETA: 32s - loss: 0.2865 - iou_score: 0.7006 - f1-score: 0.8216For batch 195, tr_loss is    0.29.\n",
      "197/232 [========================>.....] - ETA: 31s - loss: 0.2865 - iou_score: 0.7006 - f1-score: 0.8216For batch 196, tr_loss is    0.29.\n",
      "198/232 [========================>.....] - ETA: 30s - loss: 0.2864 - iou_score: 0.7008 - f1-score: 0.8218For batch 197, tr_loss is    0.29.\n",
      "199/232 [========================>.....] - ETA: 29s - loss: 0.2862 - iou_score: 0.7010 - f1-score: 0.8219For batch 198, tr_loss is    0.29.\n",
      "200/232 [========================>.....] - ETA: 28s - loss: 0.2858 - iou_score: 0.7015 - f1-score: 0.8223For batch 199, tr_loss is    0.29.\n",
      "201/232 [========================>.....] - ETA: 27s - loss: 0.2859 - iou_score: 0.7013 - f1-score: 0.8221For batch 200, tr_loss is    0.29.\n",
      "202/232 [=========================>....] - ETA: 27s - loss: 0.2859 - iou_score: 0.7012 - f1-score: 0.8221For batch 201, tr_loss is    0.29.\n",
      "203/232 [=========================>....] - ETA: 26s - loss: 0.2857 - iou_score: 0.7013 - f1-score: 0.8222For batch 202, tr_loss is    0.29.\n",
      "204/232 [=========================>....] - ETA: 25s - loss: 0.2853 - iou_score: 0.7018 - f1-score: 0.8225For batch 203, tr_loss is    0.29.\n",
      "205/232 [=========================>....] - ETA: 24s - loss: 0.2854 - iou_score: 0.7016 - f1-score: 0.8224For batch 204, tr_loss is    0.29.\n",
      "206/232 [=========================>....] - ETA: 23s - loss: 0.2856 - iou_score: 0.7015 - f1-score: 0.8223For batch 205, tr_loss is    0.29.\n",
      "207/232 [=========================>....] - ETA: 22s - loss: 0.2856 - iou_score: 0.7016 - f1-score: 0.8224For batch 206, tr_loss is    0.29.\n",
      "208/232 [=========================>....] - ETA: 21s - loss: 0.2854 - iou_score: 0.7017 - f1-score: 0.8224For batch 207, tr_loss is    0.29.\n",
      "209/232 [==========================>...] - ETA: 20s - loss: 0.2858 - iou_score: 0.7014 - f1-score: 0.8222For batch 208, tr_loss is    0.29.\n",
      "210/232 [==========================>...] - ETA: 19s - loss: 0.2861 - iou_score: 0.7012 - f1-score: 0.8220For batch 209, tr_loss is    0.29.\n",
      "211/232 [==========================>...] - ETA: 18s - loss: 0.2860 - iou_score: 0.7013 - f1-score: 0.8222For batch 210, tr_loss is    0.29.\n",
      "212/232 [==========================>...] - ETA: 17s - loss: 0.2857 - iou_score: 0.7016 - f1-score: 0.8224For batch 211, tr_loss is    0.29.\n",
      "213/232 [==========================>...] - ETA: 17s - loss: 0.2858 - iou_score: 0.7016 - f1-score: 0.8224For batch 212, tr_loss is    0.29.\n",
      "214/232 [==========================>...] - ETA: 16s - loss: 0.2857 - iou_score: 0.7018 - f1-score: 0.8225For batch 213, tr_loss is    0.29.\n",
      "215/232 [==========================>...] - ETA: 15s - loss: 0.2853 - iou_score: 0.7023 - f1-score: 0.8228For batch 214, tr_loss is    0.29.\n",
      "216/232 [==========================>...] - ETA: 14s - loss: 0.2851 - iou_score: 0.7025 - f1-score: 0.8230For batch 215, tr_loss is    0.29.\n",
      "217/232 [===========================>..] - ETA: 13s - loss: 0.2852 - iou_score: 0.7023 - f1-score: 0.8228For batch 216, tr_loss is    0.29.\n",
      "218/232 [===========================>..] - ETA: 12s - loss: 0.2852 - iou_score: 0.7022 - f1-score: 0.8228For batch 217, tr_loss is    0.29.\n",
      "219/232 [===========================>..] - ETA: 11s - loss: 0.2858 - iou_score: 0.7015 - f1-score: 0.8223For batch 218, tr_loss is    0.29.\n",
      "220/232 [===========================>..] - ETA: 10s - loss: 0.2859 - iou_score: 0.7014 - f1-score: 0.8222For batch 219, tr_loss is    0.29.\n",
      "221/232 [===========================>..] - ETA: 9s - loss: 0.2860 - iou_score: 0.7012 - f1-score: 0.8220 For batch 220, tr_loss is    0.29.\n",
      "222/232 [===========================>..] - ETA: 8s - loss: 0.2858 - iou_score: 0.7014 - f1-score: 0.8222For batch 221, tr_loss is    0.29.\n",
      "223/232 [===========================>..] - ETA: 8s - loss: 0.2859 - iou_score: 0.7012 - f1-score: 0.8221For batch 222, tr_loss is    0.29.\n",
      "224/232 [===========================>..] - ETA: 7s - loss: 0.2857 - iou_score: 0.7015 - f1-score: 0.8223For batch 223, tr_loss is    0.29.\n",
      "225/232 [============================>.] - ETA: 6s - loss: 0.2854 - iou_score: 0.7018 - f1-score: 0.8225For batch 224, tr_loss is    0.29.\n",
      "226/232 [============================>.] - ETA: 5s - loss: 0.2854 - iou_score: 0.7018 - f1-score: 0.8225For batch 225, tr_loss is    0.29.\n",
      "227/232 [============================>.] - ETA: 4s - loss: 0.2852 - iou_score: 0.7020 - f1-score: 0.8226For batch 226, tr_loss is    0.29.\n",
      "228/232 [============================>.] - ETA: 3s - loss: 0.2854 - iou_score: 0.7018 - f1-score: 0.8225For batch 227, tr_loss is    0.29.\n",
      "229/232 [============================>.] - ETA: 2s - loss: 0.2853 - iou_score: 0.7018 - f1-score: 0.8225For batch 228, tr_loss is    0.29.\n",
      "230/232 [============================>.] - ETA: 1s - loss: 0.2857 - iou_score: 0.7015 - f1-score: 0.8223For batch 229, tr_loss is    0.29.\n",
      "231/232 [============================>.] - ETA: 0s - loss: 0.2859 - iou_score: 0.7012 - f1-score: 0.8221For batch 230, tr_loss is    0.29.\n",
      "232/232 [==============================] - ETA: 0s - loss: 0.2856 - iou_score: 0.7016 - f1-score: 0.8224For batch 231, tr_loss is    0.29.\n",
      "For batch 0, vl_loss is    0.48.\n",
      "For batch 1, vl_loss is    0.42.\n",
      "For batch 2, vl_loss is    0.43.\n",
      "For batch 3, vl_loss is    0.45.\n",
      "For batch 4, vl_loss is    0.48.\n",
      "For batch 5, vl_loss is    0.46.\n",
      "For batch 6, vl_loss is    0.46.\n",
      "For batch 7, vl_loss is    0.45.\n",
      "For batch 8, vl_loss is    0.45.\n",
      "For batch 9, vl_loss is    0.44.\n",
      "For batch 10, vl_loss is    0.43.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 11, vl_loss is    0.44.\n",
      "For batch 12, vl_loss is    0.45.\n",
      "For batch 13, vl_loss is    0.46.\n",
      "For batch 14, vl_loss is    0.45.\n",
      "For batch 15, vl_loss is    0.45.\n",
      "For batch 16, vl_loss is    0.44.\n",
      "For batch 17, vl_loss is    0.44.\n",
      "For batch 18, vl_loss is    0.44.\n",
      "For batch 19, vl_loss is    0.44.\n",
      "For batch 20, vl_loss is    0.43.\n",
      "For batch 21, vl_loss is    0.43.\n",
      "For batch 22, vl_loss is    0.43.\n",
      "For batch 23, vl_loss is    0.43.\n",
      "For batch 24, vl_loss is    0.43.\n",
      "For batch 25, vl_loss is    0.42.\n",
      "For batch 26, vl_loss is    0.42.\n",
      "For batch 27, vl_loss is    0.43.\n",
      "For batch 28, vl_loss is    0.43.\n",
      "For batch 29, vl_loss is    0.43.\n",
      "For batch 30, vl_loss is    0.43.\n",
      "For batch 31, vl_loss is    0.43.\n",
      "For batch 32, vl_loss is    0.43.\n",
      "For batch 33, vl_loss is    0.43.\n",
      "For batch 34, vl_loss is    0.43.\n",
      "For batch 35, vl_loss is    0.43.\n",
      "For batch 36, vl_loss is    0.43.\n",
      "For batch 37, vl_loss is    0.43.\n",
      "For batch 38, vl_loss is    0.43.\n",
      "For batch 39, vl_loss is    0.43.\n",
      "For batch 40, vl_loss is    0.43.\n",
      "For batch 41, vl_loss is    0.44.\n",
      "For batch 42, vl_loss is    0.44.\n",
      "For batch 43, vl_loss is    0.44.\n",
      "For batch 44, vl_loss is    0.44.\n",
      "For batch 45, vl_loss is    0.44.\n",
      "For batch 46, vl_loss is    0.44.\n",
      "For batch 47, vl_loss is    0.44.\n",
      "For batch 48, vl_loss is    0.44.\n",
      "For batch 49, vl_loss is    0.44.\n",
      "For batch 50, vl_loss is    0.44.\n",
      "For batch 51, vl_loss is    0.44.\n",
      "For batch 52, vl_loss is    0.44.\n",
      "For batch 53, vl_loss is    0.44.\n",
      "For batch 54, vl_loss is    0.44.\n",
      "For batch 55, vl_loss is    0.44.\n",
      "For batch 56, vl_loss is    0.44.\n",
      "For batch 57, vl_loss is    0.44.\n",
      "For batch 58, vl_loss is    0.44.\n",
      "For batch 59, vl_loss is    0.44.\n",
      "For batch 60, vl_loss is    0.44.\n",
      "For batch 61, vl_loss is    0.44.\n",
      "For batch 62, vl_loss is    0.44.\n",
      "For batch 63, vl_loss is    0.43.\n",
      "For batch 64, vl_loss is    0.43.\n",
      "For batch 65, vl_loss is    0.43.\n",
      "For batch 66, vl_loss is    0.43.\n",
      "For batch 67, vl_loss is    0.43.\n",
      "232/232 [==============================] - 210s 901ms/step - loss: 0.2856 - iou_score: 0.7016 - f1-score: 0.8224 - val_loss: 0.4322 - val_iou_score: 0.6431 - val_f1-score: 0.7805\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.40105\n",
      "The average loss for epoch 4 is    0.29 \n",
      "Epoch 6/200\n",
      "  1/232 [..............................] - ETA: 9:22 - loss: 0.2429 - iou_score: 0.7458 - f1-score: 0.8529For batch 0, tr_loss is    0.24.\n",
      "  2/232 [..............................] - ETA: 4:59 - loss: 0.2425 - iou_score: 0.7480 - f1-score: 0.8551For batch 1, tr_loss is    0.24.\n",
      "  3/232 [..............................] - ETA: 4:24 - loss: 0.2565 - iou_score: 0.7228 - f1-score: 0.8380For batch 2, tr_loss is    0.26.\n",
      "  4/232 [..............................] - ETA: 4:46 - loss: 0.2549 - iou_score: 0.7275 - f1-score: 0.8410For batch 3, tr_loss is    0.25.\n",
      "  5/232 [..............................] - ETA: 4:37 - loss: 0.2624 - iou_score: 0.7214 - f1-score: 0.8368For batch 4, tr_loss is    0.26.\n",
      "  6/232 [..............................] - ETA: 4:31 - loss: 0.2653 - iou_score: 0.7194 - f1-score: 0.8351For batch 5, tr_loss is    0.27.\n",
      "  7/232 [..............................] - ETA: 4:42 - loss: 0.2835 - iou_score: 0.7062 - f1-score: 0.8259For batch 6, tr_loss is    0.28.\n",
      "  8/232 [>.............................] - ETA: 4:49 - loss: 0.2864 - iou_score: 0.6997 - f1-score: 0.8215For batch 7, tr_loss is    0.29.\n",
      "  9/232 [>.............................] - ETA: 4:26 - loss: 0.2785 - iou_score: 0.7087 - f1-score: 0.8275For batch 8, tr_loss is    0.28.\n",
      " 10/232 [>.............................] - ETA: 4:15 - loss: 0.2792 - iou_score: 0.7064 - f1-score: 0.8259For batch 9, tr_loss is    0.28.\n",
      " 11/232 [>.............................] - ETA: 4:04 - loss: 0.2761 - iou_score: 0.7093 - f1-score: 0.8281For batch 10, tr_loss is    0.28.\n",
      " 12/232 [>.............................] - ETA: 3:53 - loss: 0.2710 - iou_score: 0.7165 - f1-score: 0.8329For batch 11, tr_loss is    0.27.\n",
      " 13/232 [>.............................] - ETA: 3:47 - loss: 0.2691 - iou_score: 0.7182 - f1-score: 0.8340For batch 12, tr_loss is    0.27.\n",
      " 14/232 [>.............................] - ETA: 3:49 - loss: 0.2657 - iou_score: 0.7218 - f1-score: 0.8365For batch 13, tr_loss is    0.27.\n",
      " 15/232 [>.............................] - ETA: 3:43 - loss: 0.2642 - iou_score: 0.7234 - f1-score: 0.8377For batch 14, tr_loss is    0.26.\n",
      " 16/232 [=>............................] - ETA: 3:36 - loss: 0.2623 - iou_score: 0.7244 - f1-score: 0.8384For batch 15, tr_loss is    0.26.\n",
      " 17/232 [=>............................] - ETA: 3:32 - loss: 0.2610 - iou_score: 0.7263 - f1-score: 0.8398For batch 16, tr_loss is    0.26.\n",
      " 18/232 [=>............................] - ETA: 3:26 - loss: 0.2620 - iou_score: 0.7260 - f1-score: 0.8397For batch 17, tr_loss is    0.26.\n",
      " 19/232 [=>............................] - ETA: 3:26 - loss: 0.2640 - iou_score: 0.7225 - f1-score: 0.8373For batch 18, tr_loss is    0.26.\n",
      " 20/232 [=>............................] - ETA: 3:25 - loss: 0.2611 - iou_score: 0.7250 - f1-score: 0.8390For batch 19, tr_loss is    0.26.\n",
      " 21/232 [=>............................] - ETA: 3:19 - loss: 0.2658 - iou_score: 0.7211 - f1-score: 0.8362For batch 20, tr_loss is    0.27.\n",
      " 22/232 [=>............................] - ETA: 3:18 - loss: 0.2687 - iou_score: 0.7182 - f1-score: 0.8340For batch 21, tr_loss is    0.27.\n",
      " 23/232 [=>............................] - ETA: 3:16 - loss: 0.2688 - iou_score: 0.7174 - f1-score: 0.8335For batch 22, tr_loss is    0.27.\n",
      " 24/232 [==>...........................] - ETA: 3:16 - loss: 0.2681 - iou_score: 0.7174 - f1-score: 0.8336For batch 23, tr_loss is    0.27.\n",
      " 25/232 [==>...........................] - ETA: 3:15 - loss: 0.2710 - iou_score: 0.7130 - f1-score: 0.8304For batch 24, tr_loss is    0.27.\n",
      " 26/232 [==>...........................] - ETA: 3:12 - loss: 0.2724 - iou_score: 0.7125 - f1-score: 0.8301For batch 25, tr_loss is    0.27.\n",
      " 27/232 [==>...........................] - ETA: 3:09 - loss: 0.2707 - iou_score: 0.7153 - f1-score: 0.8320For batch 26, tr_loss is    0.27.\n",
      " 28/232 [==>...........................] - ETA: 3:06 - loss: 0.2708 - iou_score: 0.7151 - f1-score: 0.8319For batch 27, tr_loss is    0.27.\n",
      " 29/232 [==>...........................] - ETA: 3:07 - loss: 0.2710 - iou_score: 0.7132 - f1-score: 0.8305For batch 28, tr_loss is    0.27.\n",
      " 30/232 [==>...........................] - ETA: 3:04 - loss: 0.2698 - iou_score: 0.7147 - f1-score: 0.8316For batch 29, tr_loss is    0.27.\n",
      " 31/232 [===>..........................] - ETA: 3:00 - loss: 0.2696 - iou_score: 0.7151 - f1-score: 0.8319For batch 30, tr_loss is    0.27.\n",
      " 32/232 [===>..........................] - ETA: 3:01 - loss: 0.2694 - iou_score: 0.7153 - f1-score: 0.8321For batch 31, tr_loss is    0.27.\n",
      " 33/232 [===>..........................] - ETA: 2:59 - loss: 0.2719 - iou_score: 0.7127 - f1-score: 0.8303For batch 32, tr_loss is    0.27.\n",
      " 34/232 [===>..........................] - ETA: 2:59 - loss: 0.2718 - iou_score: 0.7126 - f1-score: 0.8302For batch 33, tr_loss is    0.27.\n",
      " 35/232 [===>..........................] - ETA: 2:59 - loss: 0.2729 - iou_score: 0.7109 - f1-score: 0.8291For batch 34, tr_loss is    0.27.\n",
      " 36/232 [===>..........................] - ETA: 2:58 - loss: 0.2733 - iou_score: 0.7111 - f1-score: 0.8292For batch 35, tr_loss is    0.27.\n",
      " 37/232 [===>..........................] - ETA: 2:56 - loss: 0.2733 - iou_score: 0.7106 - f1-score: 0.8290For batch 36, tr_loss is    0.27.\n",
      " 38/232 [===>..........................] - ETA: 2:56 - loss: 0.2752 - iou_score: 0.7096 - f1-score: 0.8283For batch 37, tr_loss is    0.28.\n",
      " 39/232 [====>.........................] - ETA: 2:56 - loss: 0.2793 - iou_score: 0.7062 - f1-score: 0.8259For batch 38, tr_loss is    0.28.\n",
      " 40/232 [====>.........................] - ETA: 2:53 - loss: 0.2813 - iou_score: 0.7051 - f1-score: 0.8250For batch 39, tr_loss is    0.28.\n",
      " 41/232 [====>.........................] - ETA: 2:50 - loss: 0.2829 - iou_score: 0.7036 - f1-score: 0.8239For batch 40, tr_loss is    0.28.\n",
      " 42/232 [====>.........................] - ETA: 2:50 - loss: 0.2831 - iou_score: 0.7026 - f1-score: 0.8233For batch 41, tr_loss is    0.28.\n",
      " 43/232 [====>.........................] - ETA: 2:50 - loss: 0.2822 - iou_score: 0.7035 - f1-score: 0.8239For batch 42, tr_loss is    0.28.\n",
      " 44/232 [====>.........................] - ETA: 2:47 - loss: 0.2855 - iou_score: 0.7009 - f1-score: 0.8219For batch 43, tr_loss is    0.29.\n",
      " 45/232 [====>.........................] - ETA: 2:48 - loss: 0.2867 - iou_score: 0.7001 - f1-score: 0.8213For batch 44, tr_loss is    0.29.\n",
      " 46/232 [====>.........................] - ETA: 2:45 - loss: 0.2866 - iou_score: 0.7005 - f1-score: 0.8217For batch 45, tr_loss is    0.29.\n",
      " 47/232 [=====>........................] - ETA: 2:44 - loss: 0.2863 - iou_score: 0.7012 - f1-score: 0.8222For batch 46, tr_loss is    0.29.\n",
      " 48/232 [=====>........................] - ETA: 2:42 - loss: 0.2854 - iou_score: 0.7026 - f1-score: 0.8231For batch 47, tr_loss is    0.29.\n",
      " 49/232 [=====>........................] - ETA: 2:42 - loss: 0.2858 - iou_score: 0.7025 - f1-score: 0.8231For batch 48, tr_loss is    0.29.\n",
      " 50/232 [=====>........................] - ETA: 2:42 - loss: 0.2857 - iou_score: 0.7027 - f1-score: 0.8232For batch 49, tr_loss is    0.29.\n",
      " 51/232 [=====>........................] - ETA: 2:41 - loss: 0.2872 - iou_score: 0.7008 - f1-score: 0.8219For batch 50, tr_loss is    0.29.\n",
      " 52/232 [=====>........................] - ETA: 2:41 - loss: 0.2896 - iou_score: 0.6988 - f1-score: 0.8205For batch 51, tr_loss is    0.29.\n",
      " 53/232 [=====>........................] - ETA: 2:40 - loss: 0.2886 - iou_score: 0.7000 - f1-score: 0.8213For batch 52, tr_loss is    0.29.\n",
      " 54/232 [=====>........................] - ETA: 2:38 - loss: 0.2891 - iou_score: 0.6993 - f1-score: 0.8209For batch 53, tr_loss is    0.29.\n",
      " 55/232 [======>.......................] - ETA: 2:37 - loss: 0.2887 - iou_score: 0.6996 - f1-score: 0.8211For batch 54, tr_loss is    0.29.\n",
      " 56/232 [======>.......................] - ETA: 2:37 - loss: 0.2884 - iou_score: 0.6999 - f1-score: 0.8213For batch 55, tr_loss is    0.29.\n",
      " 57/232 [======>.......................] - ETA: 2:36 - loss: 0.2892 - iou_score: 0.6987 - f1-score: 0.8205For batch 56, tr_loss is    0.29.\n",
      " 58/232 [======>.......................] - ETA: 2:34 - loss: 0.2883 - iou_score: 0.7000 - f1-score: 0.8214For batch 57, tr_loss is    0.29.\n",
      " 59/232 [======>.......................] - ETA: 2:33 - loss: 0.2878 - iou_score: 0.7005 - f1-score: 0.8218For batch 58, tr_loss is    0.29.\n",
      " 60/232 [======>.......................] - ETA: 2:31 - loss: 0.2893 - iou_score: 0.6992 - f1-score: 0.8208For batch 59, tr_loss is    0.29.\n",
      " 61/232 [======>.......................] - ETA: 2:30 - loss: 0.2910 - iou_score: 0.6974 - f1-score: 0.8194For batch 60, tr_loss is    0.29.\n",
      " 62/232 [=======>......................] - ETA: 2:30 - loss: 0.2917 - iou_score: 0.6966 - f1-score: 0.8188For batch 61, tr_loss is    0.29.\n",
      " 63/232 [=======>......................] - ETA: 2:28 - loss: 0.2917 - iou_score: 0.6973 - f1-score: 0.8193For batch 62, tr_loss is    0.29.\n",
      " 64/232 [=======>......................] - ETA: 2:28 - loss: 0.2918 - iou_score: 0.6969 - f1-score: 0.8191For batch 63, tr_loss is    0.29.\n",
      " 65/232 [=======>......................] - ETA: 2:27 - loss: 0.2920 - iou_score: 0.6968 - f1-score: 0.8190For batch 64, tr_loss is    0.29.\n",
      " 66/232 [=======>......................] - ETA: 2:25 - loss: 0.2922 - iou_score: 0.6964 - f1-score: 0.8188For batch 65, tr_loss is    0.29.\n",
      " 67/232 [=======>......................] - ETA: 2:25 - loss: 0.2913 - iou_score: 0.6971 - f1-score: 0.8193For batch 66, tr_loss is    0.29.\n",
      " 68/232 [=======>......................] - ETA: 2:23 - loss: 0.2909 - iou_score: 0.6977 - f1-score: 0.8197For batch 67, tr_loss is    0.29.\n",
      " 69/232 [=======>......................] - ETA: 2:22 - loss: 0.2905 - iou_score: 0.6983 - f1-score: 0.8201For batch 68, tr_loss is    0.29.\n",
      " 70/232 [========>.....................] - ETA: 2:20 - loss: 0.2899 - iou_score: 0.6988 - f1-score: 0.8205For batch 69, tr_loss is    0.29.\n",
      " 71/232 [========>.....................] - ETA: 2:19 - loss: 0.2891 - iou_score: 0.6998 - f1-score: 0.8212For batch 70, tr_loss is    0.29.\n",
      " 72/232 [========>.....................] - ETA: 2:18 - loss: 0.2884 - iou_score: 0.7005 - f1-score: 0.8216For batch 71, tr_loss is    0.29.\n",
      " 73/232 [========>.....................] - ETA: 2:18 - loss: 0.2885 - iou_score: 0.7000 - f1-score: 0.8213For batch 72, tr_loss is    0.29.\n",
      " 74/232 [========>.....................] - ETA: 2:17 - loss: 0.2877 - iou_score: 0.7008 - f1-score: 0.8219For batch 73, tr_loss is    0.29.\n",
      " 75/232 [========>.....................] - ETA: 2:15 - loss: 0.2879 - iou_score: 0.7006 - f1-score: 0.8217For batch 74, tr_loss is    0.29.\n",
      " 76/232 [========>.....................] - ETA: 2:14 - loss: 0.2871 - iou_score: 0.7012 - f1-score: 0.8221For batch 75, tr_loss is    0.29.\n",
      " 77/232 [========>.....................] - ETA: 2:14 - loss: 0.2862 - iou_score: 0.7021 - f1-score: 0.8228For batch 76, tr_loss is    0.29.\n",
      " 78/232 [=========>....................] - ETA: 2:12 - loss: 0.2860 - iou_score: 0.7019 - f1-score: 0.8227For batch 77, tr_loss is    0.29.\n",
      " 79/232 [=========>....................] - ETA: 2:11 - loss: 0.2857 - iou_score: 0.7022 - f1-score: 0.8229For batch 78, tr_loss is    0.29.\n",
      " 80/232 [=========>....................] - ETA: 2:11 - loss: 0.2855 - iou_score: 0.7022 - f1-score: 0.8229For batch 79, tr_loss is    0.29.\n",
      " 81/232 [=========>....................] - ETA: 2:10 - loss: 0.2858 - iou_score: 0.7019 - f1-score: 0.8227For batch 80, tr_loss is    0.29.\n",
      " 82/232 [=========>....................] - ETA: 2:08 - loss: 0.2858 - iou_score: 0.7016 - f1-score: 0.8225For batch 81, tr_loss is    0.29.\n",
      " 83/232 [=========>....................] - ETA: 2:08 - loss: 0.2865 - iou_score: 0.7005 - f1-score: 0.8217For batch 82, tr_loss is    0.29.\n",
      " 84/232 [=========>....................] - ETA: 2:07 - loss: 0.2868 - iou_score: 0.7001 - f1-score: 0.8215For batch 83, tr_loss is    0.29.\n",
      " 85/232 [=========>....................] - ETA: 2:07 - loss: 0.2868 - iou_score: 0.7001 - f1-score: 0.8215For batch 84, tr_loss is    0.29.\n",
      " 86/232 [==========>...................] - ETA: 2:06 - loss: 0.2875 - iou_score: 0.6995 - f1-score: 0.8211For batch 85, tr_loss is    0.29.\n",
      " 87/232 [==========>...................] - ETA: 2:05 - loss: 0.2871 - iou_score: 0.6998 - f1-score: 0.8213For batch 86, tr_loss is    0.29.\n",
      " 88/232 [==========>...................] - ETA: 2:05 - loss: 0.2879 - iou_score: 0.6989 - f1-score: 0.8207For batch 87, tr_loss is    0.29.\n",
      " 89/232 [==========>...................] - ETA: 2:03 - loss: 0.2875 - iou_score: 0.6995 - f1-score: 0.8211For batch 88, tr_loss is    0.29.\n",
      " 90/232 [==========>...................] - ETA: 2:03 - loss: 0.2870 - iou_score: 0.7000 - f1-score: 0.8215For batch 89, tr_loss is    0.29.\n",
      " 91/232 [==========>...................] - ETA: 2:02 - loss: 0.2867 - iou_score: 0.7003 - f1-score: 0.8217For batch 90, tr_loss is    0.29.\n",
      " 92/232 [==========>...................] - ETA: 2:02 - loss: 0.2866 - iou_score: 0.7006 - f1-score: 0.8219For batch 91, tr_loss is    0.29.\n",
      " 93/232 [===========>..................] - ETA: 2:01 - loss: 0.2876 - iou_score: 0.6993 - f1-score: 0.8209For batch 92, tr_loss is    0.29.\n",
      " 94/232 [===========>..................] - ETA: 2:00 - loss: 0.2870 - iou_score: 0.7002 - f1-score: 0.8215For batch 93, tr_loss is    0.29.\n",
      " 95/232 [===========>..................] - ETA: 2:00 - loss: 0.2872 - iou_score: 0.7000 - f1-score: 0.8213For batch 94, tr_loss is    0.29.\n",
      " 96/232 [===========>..................] - ETA: 1:59 - loss: 0.2867 - iou_score: 0.7003 - f1-score: 0.8216For batch 95, tr_loss is    0.29.\n",
      " 97/232 [===========>..................] - ETA: 1:58 - loss: 0.2869 - iou_score: 0.7001 - f1-score: 0.8215For batch 96, tr_loss is    0.29.\n",
      " 98/232 [===========>..................] - ETA: 1:57 - loss: 0.2865 - iou_score: 0.7004 - f1-score: 0.8217For batch 97, tr_loss is    0.29.\n",
      " 99/232 [===========>..................] - ETA: 1:57 - loss: 0.2857 - iou_score: 0.7015 - f1-score: 0.8224For batch 98, tr_loss is    0.29.\n",
      "100/232 [===========>..................] - ETA: 1:56 - loss: 0.2850 - iou_score: 0.7023 - f1-score: 0.8230For batch 99, tr_loss is    0.29.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/232 [============>.................] - ETA: 1:55 - loss: 0.2846 - iou_score: 0.7030 - f1-score: 0.8234For batch 100, tr_loss is    0.28.\n",
      "102/232 [============>.................] - ETA: 1:54 - loss: 0.2845 - iou_score: 0.7031 - f1-score: 0.8235For batch 101, tr_loss is    0.28.\n",
      "103/232 [============>.................] - ETA: 1:54 - loss: 0.2846 - iou_score: 0.7031 - f1-score: 0.8235For batch 102, tr_loss is    0.28.\n",
      "104/232 [============>.................] - ETA: 1:52 - loss: 0.2846 - iou_score: 0.7031 - f1-score: 0.8235For batch 103, tr_loss is    0.28.\n",
      "105/232 [============>.................] - ETA: 1:52 - loss: 0.2840 - iou_score: 0.7037 - f1-score: 0.8239For batch 104, tr_loss is    0.28.\n",
      "106/232 [============>.................] - ETA: 1:50 - loss: 0.2833 - iou_score: 0.7045 - f1-score: 0.8245For batch 105, tr_loss is    0.28.\n",
      "107/232 [============>.................] - ETA: 1:49 - loss: 0.2837 - iou_score: 0.7043 - f1-score: 0.8243For batch 106, tr_loss is    0.28.\n",
      "108/232 [============>.................] - ETA: 1:48 - loss: 0.2842 - iou_score: 0.7034 - f1-score: 0.8237For batch 107, tr_loss is    0.28.\n",
      "109/232 [=============>................] - ETA: 1:47 - loss: 0.2837 - iou_score: 0.7040 - f1-score: 0.8241For batch 108, tr_loss is    0.28.\n",
      "110/232 [=============>................] - ETA: 1:46 - loss: 0.2829 - iou_score: 0.7050 - f1-score: 0.8248For batch 109, tr_loss is    0.28.\n",
      "111/232 [=============>................] - ETA: 1:46 - loss: 0.2828 - iou_score: 0.7048 - f1-score: 0.8246For batch 110, tr_loss is    0.28.\n",
      "112/232 [=============>................] - ETA: 1:44 - loss: 0.2831 - iou_score: 0.7044 - f1-score: 0.8244For batch 111, tr_loss is    0.28.\n",
      "113/232 [=============>................] - ETA: 1:44 - loss: 0.2834 - iou_score: 0.7043 - f1-score: 0.8243For batch 112, tr_loss is    0.28.\n",
      "114/232 [=============>................] - ETA: 1:43 - loss: 0.2828 - iou_score: 0.7050 - f1-score: 0.8248For batch 113, tr_loss is    0.28.\n",
      "115/232 [=============>................] - ETA: 1:42 - loss: 0.2826 - iou_score: 0.7052 - f1-score: 0.8249For batch 114, tr_loss is    0.28.\n",
      "116/232 [==============>...............] - ETA: 1:41 - loss: 0.2822 - iou_score: 0.7056 - f1-score: 0.8252For batch 115, tr_loss is    0.28.\n",
      "117/232 [==============>...............] - ETA: 1:40 - loss: 0.2822 - iou_score: 0.7055 - f1-score: 0.8252For batch 116, tr_loss is    0.28.\n",
      "118/232 [==============>...............] - ETA: 1:39 - loss: 0.2817 - iou_score: 0.7062 - f1-score: 0.8256For batch 117, tr_loss is    0.28.\n",
      "119/232 [==============>...............] - ETA: 1:38 - loss: 0.2814 - iou_score: 0.7065 - f1-score: 0.8258For batch 118, tr_loss is    0.28.\n",
      "120/232 [==============>...............] - ETA: 1:38 - loss: 0.2820 - iou_score: 0.7060 - f1-score: 0.8255For batch 119, tr_loss is    0.28.\n",
      "121/232 [==============>...............] - ETA: 1:37 - loss: 0.2812 - iou_score: 0.7068 - f1-score: 0.8261For batch 120, tr_loss is    0.28.\n",
      "122/232 [==============>...............] - ETA: 1:36 - loss: 0.2818 - iou_score: 0.7062 - f1-score: 0.8256For batch 121, tr_loss is    0.28.\n",
      "123/232 [==============>...............] - ETA: 1:35 - loss: 0.2813 - iou_score: 0.7064 - f1-score: 0.8258For batch 122, tr_loss is    0.28.\n",
      "124/232 [===============>..............] - ETA: 1:34 - loss: 0.2815 - iou_score: 0.7063 - f1-score: 0.8257For batch 123, tr_loss is    0.28.\n",
      "125/232 [===============>..............] - ETA: 1:33 - loss: 0.2818 - iou_score: 0.7059 - f1-score: 0.8254For batch 124, tr_loss is    0.28.\n",
      "126/232 [===============>..............] - ETA: 1:32 - loss: 0.2818 - iou_score: 0.7061 - f1-score: 0.8256For batch 125, tr_loss is    0.28.\n",
      "127/232 [===============>..............] - ETA: 1:31 - loss: 0.2815 - iou_score: 0.7063 - f1-score: 0.8257For batch 126, tr_loss is    0.28.\n",
      "128/232 [===============>..............] - ETA: 1:30 - loss: 0.2817 - iou_score: 0.7058 - f1-score: 0.8254For batch 127, tr_loss is    0.28.\n",
      "129/232 [===============>..............] - ETA: 1:30 - loss: 0.2817 - iou_score: 0.7057 - f1-score: 0.8253For batch 128, tr_loss is    0.28.\n",
      "130/232 [===============>..............] - ETA: 1:29 - loss: 0.2816 - iou_score: 0.7063 - f1-score: 0.8257For batch 129, tr_loss is    0.28.\n",
      "131/232 [===============>..............] - ETA: 1:28 - loss: 0.2823 - iou_score: 0.7056 - f1-score: 0.8252For batch 130, tr_loss is    0.28.\n",
      "132/232 [================>.............] - ETA: 1:27 - loss: 0.2826 - iou_score: 0.7054 - f1-score: 0.8251For batch 131, tr_loss is    0.28.\n",
      "133/232 [================>.............] - ETA: 1:26 - loss: 0.2822 - iou_score: 0.7057 - f1-score: 0.8253For batch 132, tr_loss is    0.28.\n",
      "134/232 [================>.............] - ETA: 1:25 - loss: 0.2826 - iou_score: 0.7050 - f1-score: 0.8248For batch 133, tr_loss is    0.28.\n",
      "135/232 [================>.............] - ETA: 1:24 - loss: 0.2822 - iou_score: 0.7054 - f1-score: 0.8251For batch 134, tr_loss is    0.28.\n",
      "136/232 [================>.............] - ETA: 1:23 - loss: 0.2824 - iou_score: 0.7050 - f1-score: 0.8248For batch 135, tr_loss is    0.28.\n",
      "137/232 [================>.............] - ETA: 1:22 - loss: 0.2826 - iou_score: 0.7047 - f1-score: 0.8246For batch 136, tr_loss is    0.28.\n",
      "138/232 [================>.............] - ETA: 1:22 - loss: 0.2825 - iou_score: 0.7046 - f1-score: 0.8245For batch 137, tr_loss is    0.28.\n",
      "139/232 [================>.............] - ETA: 1:21 - loss: 0.2823 - iou_score: 0.7048 - f1-score: 0.8247For batch 138, tr_loss is    0.28.\n",
      "140/232 [=================>............] - ETA: 1:20 - loss: 0.2823 - iou_score: 0.7049 - f1-score: 0.8247For batch 139, tr_loss is    0.28.\n",
      "141/232 [=================>............] - ETA: 1:19 - loss: 0.2829 - iou_score: 0.7041 - f1-score: 0.8242For batch 140, tr_loss is    0.28.\n",
      "142/232 [=================>............] - ETA: 1:18 - loss: 0.2828 - iou_score: 0.7042 - f1-score: 0.8242For batch 141, tr_loss is    0.28.\n",
      "143/232 [=================>............] - ETA: 1:17 - loss: 0.2824 - iou_score: 0.7046 - f1-score: 0.8246For batch 142, tr_loss is    0.28.\n",
      "144/232 [=================>............] - ETA: 1:16 - loss: 0.2823 - iou_score: 0.7046 - f1-score: 0.8245For batch 143, tr_loss is    0.28.\n",
      "145/232 [=================>............] - ETA: 1:15 - loss: 0.2822 - iou_score: 0.7046 - f1-score: 0.8246For batch 144, tr_loss is    0.28.\n",
      "146/232 [=================>............] - ETA: 1:14 - loss: 0.2824 - iou_score: 0.7043 - f1-score: 0.8243For batch 145, tr_loss is    0.28.\n",
      "147/232 [==================>...........] - ETA: 1:13 - loss: 0.2820 - iou_score: 0.7047 - f1-score: 0.8246For batch 146, tr_loss is    0.28.\n",
      "148/232 [==================>...........] - ETA: 1:12 - loss: 0.2825 - iou_score: 0.7041 - f1-score: 0.8242For batch 147, tr_loss is    0.28.\n",
      "149/232 [==================>...........] - ETA: 1:11 - loss: 0.2821 - iou_score: 0.7046 - f1-score: 0.8245For batch 148, tr_loss is    0.28.\n",
      "150/232 [==================>...........] - ETA: 1:10 - loss: 0.2828 - iou_score: 0.7038 - f1-score: 0.8240For batch 149, tr_loss is    0.28.\n",
      "151/232 [==================>...........] - ETA: 1:10 - loss: 0.2830 - iou_score: 0.7034 - f1-score: 0.8237For batch 150, tr_loss is    0.28.\n",
      "152/232 [==================>...........] - ETA: 1:09 - loss: 0.2826 - iou_score: 0.7038 - f1-score: 0.8240For batch 151, tr_loss is    0.28.\n",
      "153/232 [==================>...........] - ETA: 1:08 - loss: 0.2825 - iou_score: 0.7038 - f1-score: 0.8239For batch 152, tr_loss is    0.28.\n",
      "154/232 [==================>...........] - ETA: 1:07 - loss: 0.2821 - iou_score: 0.7042 - f1-score: 0.8242For batch 153, tr_loss is    0.28.\n",
      "155/232 [===================>..........] - ETA: 1:06 - loss: 0.2819 - iou_score: 0.7043 - f1-score: 0.8243For batch 154, tr_loss is    0.28.\n",
      "156/232 [===================>..........] - ETA: 1:05 - loss: 0.2819 - iou_score: 0.7043 - f1-score: 0.8243For batch 155, tr_loss is    0.28.\n",
      "157/232 [===================>..........] - ETA: 1:04 - loss: 0.2825 - iou_score: 0.7039 - f1-score: 0.8240For batch 156, tr_loss is    0.28.\n",
      "158/232 [===================>..........] - ETA: 1:03 - loss: 0.2822 - iou_score: 0.7043 - f1-score: 0.8243For batch 157, tr_loss is    0.28.\n",
      "159/232 [===================>..........] - ETA: 1:03 - loss: 0.2821 - iou_score: 0.7045 - f1-score: 0.8244For batch 158, tr_loss is    0.28.\n",
      "160/232 [===================>..........] - ETA: 1:02 - loss: 0.2820 - iou_score: 0.7043 - f1-score: 0.8243For batch 159, tr_loss is    0.28.\n",
      "161/232 [===================>..........] - ETA: 1:01 - loss: 0.2816 - iou_score: 0.7046 - f1-score: 0.8246For batch 160, tr_loss is    0.28.\n",
      "162/232 [===================>..........] - ETA: 1:00 - loss: 0.2817 - iou_score: 0.7044 - f1-score: 0.8244For batch 161, tr_loss is    0.28.\n",
      "163/232 [====================>.........] - ETA: 59s - loss: 0.2813 - iou_score: 0.7049 - f1-score: 0.8248 For batch 162, tr_loss is    0.28.\n",
      "164/232 [====================>.........] - ETA: 58s - loss: 0.2815 - iou_score: 0.7048 - f1-score: 0.8247For batch 163, tr_loss is    0.28.\n",
      "165/232 [====================>.........] - ETA: 57s - loss: 0.2816 - iou_score: 0.7046 - f1-score: 0.8245For batch 164, tr_loss is    0.28.\n",
      "166/232 [====================>.........] - ETA: 57s - loss: 0.2814 - iou_score: 0.7046 - f1-score: 0.8245For batch 165, tr_loss is    0.28.\n",
      "167/232 [====================>.........] - ETA: 56s - loss: 0.2813 - iou_score: 0.7047 - f1-score: 0.8246For batch 166, tr_loss is    0.28.\n",
      "168/232 [====================>.........] - ETA: 55s - loss: 0.2815 - iou_score: 0.7044 - f1-score: 0.8244For batch 167, tr_loss is    0.28.\n",
      "169/232 [====================>.........] - ETA: 54s - loss: 0.2820 - iou_score: 0.7038 - f1-score: 0.8240For batch 168, tr_loss is    0.28.\n",
      "170/232 [====================>.........] - ETA: 53s - loss: 0.2820 - iou_score: 0.7038 - f1-score: 0.8240For batch 169, tr_loss is    0.28.\n",
      "171/232 [=====================>........] - ETA: 52s - loss: 0.2825 - iou_score: 0.7034 - f1-score: 0.8237For batch 170, tr_loss is    0.28.\n",
      "172/232 [=====================>........] - ETA: 51s - loss: 0.2826 - iou_score: 0.7031 - f1-score: 0.8235For batch 171, tr_loss is    0.28.\n",
      "173/232 [=====================>........] - ETA: 50s - loss: 0.2823 - iou_score: 0.7034 - f1-score: 0.8237For batch 172, tr_loss is    0.28.\n",
      "174/232 [=====================>........] - ETA: 49s - loss: 0.2821 - iou_score: 0.7036 - f1-score: 0.8238For batch 173, tr_loss is    0.28.\n",
      "175/232 [=====================>........] - ETA: 49s - loss: 0.2822 - iou_score: 0.7034 - f1-score: 0.8237For batch 174, tr_loss is    0.28.\n",
      "176/232 [=====================>........] - ETA: 48s - loss: 0.2824 - iou_score: 0.7031 - f1-score: 0.8235For batch 175, tr_loss is    0.28.\n",
      "177/232 [=====================>........] - ETA: 47s - loss: 0.2822 - iou_score: 0.7035 - f1-score: 0.8237For batch 176, tr_loss is    0.28.\n",
      "178/232 [======================>.......] - ETA: 46s - loss: 0.2821 - iou_score: 0.7036 - f1-score: 0.8239For batch 177, tr_loss is    0.28.\n",
      "179/232 [======================>.......] - ETA: 45s - loss: 0.2820 - iou_score: 0.7038 - f1-score: 0.8240For batch 178, tr_loss is    0.28.\n",
      "180/232 [======================>.......] - ETA: 44s - loss: 0.2820 - iou_score: 0.7037 - f1-score: 0.8239For batch 179, tr_loss is    0.28.\n",
      "181/232 [======================>.......] - ETA: 44s - loss: 0.2820 - iou_score: 0.7036 - f1-score: 0.8239For batch 180, tr_loss is    0.28.\n",
      "182/232 [======================>.......] - ETA: 43s - loss: 0.2820 - iou_score: 0.7036 - f1-score: 0.8238For batch 181, tr_loss is    0.28.\n",
      "183/232 [======================>.......] - ETA: 42s - loss: 0.2820 - iou_score: 0.7037 - f1-score: 0.8239For batch 182, tr_loss is    0.28.\n",
      "184/232 [======================>.......] - ETA: 41s - loss: 0.2816 - iou_score: 0.7041 - f1-score: 0.8242For batch 183, tr_loss is    0.28.\n",
      "185/232 [======================>.......] - ETA: 40s - loss: 0.2817 - iou_score: 0.7041 - f1-score: 0.8242For batch 184, tr_loss is    0.28.\n",
      "186/232 [=======================>......] - ETA: 39s - loss: 0.2817 - iou_score: 0.7041 - f1-score: 0.8242For batch 185, tr_loss is    0.28.\n",
      "187/232 [=======================>......] - ETA: 38s - loss: 0.2812 - iou_score: 0.7046 - f1-score: 0.8245For batch 186, tr_loss is    0.28.\n",
      "188/232 [=======================>......] - ETA: 38s - loss: 0.2813 - iou_score: 0.7045 - f1-score: 0.8244For batch 187, tr_loss is    0.28.\n",
      "189/232 [=======================>......] - ETA: 37s - loss: 0.2812 - iou_score: 0.7045 - f1-score: 0.8245For batch 188, tr_loss is    0.28.\n",
      "190/232 [=======================>......] - ETA: 36s - loss: 0.2810 - iou_score: 0.7047 - f1-score: 0.8246For batch 189, tr_loss is    0.28.\n",
      "191/232 [=======================>......] - ETA: 35s - loss: 0.2810 - iou_score: 0.7047 - f1-score: 0.8246For batch 190, tr_loss is    0.28.\n",
      "192/232 [=======================>......] - ETA: 34s - loss: 0.2812 - iou_score: 0.7043 - f1-score: 0.8244For batch 191, tr_loss is    0.28.\n",
      "193/232 [=======================>......] - ETA: 33s - loss: 0.2819 - iou_score: 0.7037 - f1-score: 0.8239For batch 192, tr_loss is    0.28.\n",
      "194/232 [========================>.....] - ETA: 32s - loss: 0.2820 - iou_score: 0.7035 - f1-score: 0.8237For batch 193, tr_loss is    0.28.\n",
      "195/232 [========================>.....] - ETA: 31s - loss: 0.2820 - iou_score: 0.7033 - f1-score: 0.8236For batch 194, tr_loss is    0.28.\n",
      "196/232 [========================>.....] - ETA: 31s - loss: 0.2819 - iou_score: 0.7033 - f1-score: 0.8236For batch 195, tr_loss is    0.28.\n",
      "197/232 [========================>.....] - ETA: 30s - loss: 0.2819 - iou_score: 0.7033 - f1-score: 0.8236For batch 196, tr_loss is    0.28.\n",
      "198/232 [========================>.....] - ETA: 29s - loss: 0.2819 - iou_score: 0.7036 - f1-score: 0.8238For batch 197, tr_loss is    0.28.\n",
      "199/232 [========================>.....] - ETA: 28s - loss: 0.2816 - iou_score: 0.7038 - f1-score: 0.8239For batch 198, tr_loss is    0.28.\n",
      "200/232 [========================>.....] - ETA: 27s - loss: 0.2813 - iou_score: 0.7043 - f1-score: 0.8243For batch 199, tr_loss is    0.28.\n",
      "201/232 [========================>.....] - ETA: 26s - loss: 0.2814 - iou_score: 0.7041 - f1-score: 0.8242For batch 200, tr_loss is    0.28.\n",
      "202/232 [=========================>....] - ETA: 26s - loss: 0.2813 - iou_score: 0.7041 - f1-score: 0.8242For batch 201, tr_loss is    0.28.\n",
      "203/232 [=========================>....] - ETA: 25s - loss: 0.2810 - iou_score: 0.7044 - f1-score: 0.8244For batch 202, tr_loss is    0.28.\n",
      "204/232 [=========================>....] - ETA: 24s - loss: 0.2806 - iou_score: 0.7048 - f1-score: 0.8246For batch 203, tr_loss is    0.28.\n",
      "205/232 [=========================>....] - ETA: 23s - loss: 0.2806 - iou_score: 0.7046 - f1-score: 0.8245For batch 204, tr_loss is    0.28.\n",
      "206/232 [=========================>....] - ETA: 22s - loss: 0.2808 - iou_score: 0.7044 - f1-score: 0.8244For batch 205, tr_loss is    0.28.\n",
      "207/232 [=========================>....] - ETA: 21s - loss: 0.2806 - iou_score: 0.7047 - f1-score: 0.8246For batch 206, tr_loss is    0.28.\n",
      "208/232 [=========================>....] - ETA: 20s - loss: 0.2805 - iou_score: 0.7048 - f1-score: 0.8246For batch 207, tr_loss is    0.28.\n",
      "209/232 [==========================>...] - ETA: 19s - loss: 0.2806 - iou_score: 0.7046 - f1-score: 0.8245For batch 208, tr_loss is    0.28.\n",
      "210/232 [==========================>...] - ETA: 19s - loss: 0.2809 - iou_score: 0.7043 - f1-score: 0.8244For batch 209, tr_loss is    0.28.\n",
      "211/232 [==========================>...] - ETA: 18s - loss: 0.2807 - iou_score: 0.7046 - f1-score: 0.8245For batch 210, tr_loss is    0.28.\n",
      "212/232 [==========================>...] - ETA: 17s - loss: 0.2805 - iou_score: 0.7049 - f1-score: 0.8248For batch 211, tr_loss is    0.28.\n",
      "213/232 [==========================>...] - ETA: 16s - loss: 0.2806 - iou_score: 0.7049 - f1-score: 0.8247For batch 212, tr_loss is    0.28.\n",
      "214/232 [==========================>...] - ETA: 15s - loss: 0.2805 - iou_score: 0.7049 - f1-score: 0.8248For batch 213, tr_loss is    0.28.\n",
      "215/232 [==========================>...] - ETA: 14s - loss: 0.2802 - iou_score: 0.7054 - f1-score: 0.8251For batch 214, tr_loss is    0.28.\n",
      "216/232 [==========================>...] - ETA: 13s - loss: 0.2800 - iou_score: 0.7056 - f1-score: 0.8252For batch 215, tr_loss is    0.28.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217/232 [===========================>..] - ETA: 13s - loss: 0.2799 - iou_score: 0.7056 - f1-score: 0.8252For batch 216, tr_loss is    0.28.\n",
      "218/232 [===========================>..] - ETA: 12s - loss: 0.2801 - iou_score: 0.7054 - f1-score: 0.8251For batch 217, tr_loss is    0.28.\n",
      "219/232 [===========================>..] - ETA: 11s - loss: 0.2807 - iou_score: 0.7047 - f1-score: 0.8246For batch 218, tr_loss is    0.28.\n",
      "220/232 [===========================>..] - ETA: 10s - loss: 0.2807 - iou_score: 0.7047 - f1-score: 0.8246For batch 219, tr_loss is    0.28.\n",
      "221/232 [===========================>..] - ETA: 9s - loss: 0.2809 - iou_score: 0.7044 - f1-score: 0.8244 For batch 220, tr_loss is    0.28.\n",
      "222/232 [===========================>..] - ETA: 8s - loss: 0.2807 - iou_score: 0.7047 - f1-score: 0.8246For batch 221, tr_loss is    0.28.\n",
      "223/232 [===========================>..] - ETA: 7s - loss: 0.2807 - iou_score: 0.7046 - f1-score: 0.8245For batch 222, tr_loss is    0.28.\n",
      "224/232 [===========================>..] - ETA: 6s - loss: 0.2805 - iou_score: 0.7049 - f1-score: 0.8247For batch 223, tr_loss is    0.28.\n",
      "225/232 [============================>.] - ETA: 6s - loss: 0.2803 - iou_score: 0.7052 - f1-score: 0.8249For batch 224, tr_loss is    0.28.\n",
      "226/232 [============================>.] - ETA: 5s - loss: 0.2802 - iou_score: 0.7052 - f1-score: 0.8249For batch 225, tr_loss is    0.28.\n",
      "227/232 [============================>.] - ETA: 4s - loss: 0.2801 - iou_score: 0.7053 - f1-score: 0.8250For batch 226, tr_loss is    0.28.\n",
      "228/232 [============================>.] - ETA: 3s - loss: 0.2802 - iou_score: 0.7052 - f1-score: 0.8250For batch 227, tr_loss is    0.28.\n",
      "229/232 [============================>.] - ETA: 2s - loss: 0.2799 - iou_score: 0.7054 - f1-score: 0.8251For batch 228, tr_loss is    0.28.\n",
      "230/232 [============================>.] - ETA: 1s - loss: 0.2802 - iou_score: 0.7051 - f1-score: 0.8249For batch 229, tr_loss is    0.28.\n",
      "231/232 [============================>.] - ETA: 0s - loss: 0.2805 - iou_score: 0.7048 - f1-score: 0.8247For batch 230, tr_loss is    0.28.\n",
      "232/232 [==============================] - ETA: 0s - loss: 0.2802 - iou_score: 0.7052 - f1-score: 0.8249For batch 231, tr_loss is    0.28.\n",
      "For batch 0, vl_loss is    0.41.\n",
      "For batch 1, vl_loss is    0.36.\n",
      "For batch 2, vl_loss is    0.41.\n",
      "For batch 3, vl_loss is    0.41.\n",
      "For batch 4, vl_loss is    0.44.\n",
      "For batch 5, vl_loss is    0.42.\n",
      "For batch 6, vl_loss is    0.43.\n",
      "For batch 7, vl_loss is    0.42.\n",
      "For batch 8, vl_loss is    0.42.\n",
      "For batch 9, vl_loss is    0.41.\n",
      "For batch 10, vl_loss is    0.41.\n",
      "For batch 11, vl_loss is    0.42.\n",
      "For batch 12, vl_loss is    0.42.\n",
      "For batch 13, vl_loss is    0.43.\n",
      "For batch 14, vl_loss is    0.42.\n",
      "For batch 15, vl_loss is    0.42.\n",
      "For batch 16, vl_loss is    0.41.\n",
      "For batch 17, vl_loss is    0.42.\n",
      "For batch 18, vl_loss is    0.42.\n",
      "For batch 19, vl_loss is    0.42.\n",
      "For batch 20, vl_loss is    0.41.\n",
      "For batch 21, vl_loss is    0.41.\n",
      "For batch 22, vl_loss is    0.41.\n",
      "For batch 23, vl_loss is    0.41.\n",
      "For batch 24, vl_loss is    0.41.\n",
      "For batch 25, vl_loss is    0.41.\n",
      "For batch 26, vl_loss is    0.41.\n",
      "For batch 27, vl_loss is    0.41.\n",
      "For batch 28, vl_loss is    0.41.\n",
      "For batch 29, vl_loss is    0.41.\n",
      "For batch 30, vl_loss is    0.41.\n",
      "For batch 31, vl_loss is    0.41.\n",
      "For batch 32, vl_loss is    0.41.\n",
      "For batch 33, vl_loss is    0.41.\n",
      "For batch 34, vl_loss is    0.41.\n",
      "For batch 35, vl_loss is    0.41.\n",
      "For batch 36, vl_loss is    0.41.\n",
      "For batch 37, vl_loss is    0.41.\n",
      "For batch 38, vl_loss is    0.40.\n",
      "For batch 39, vl_loss is    0.41.\n",
      "For batch 40, vl_loss is    0.41.\n",
      "For batch 41, vl_loss is    0.41.\n",
      "For batch 42, vl_loss is    0.42.\n",
      "For batch 43, vl_loss is    0.42.\n",
      "For batch 44, vl_loss is    0.42.\n",
      "For batch 45, vl_loss is    0.42.\n",
      "For batch 46, vl_loss is    0.42.\n",
      "For batch 47, vl_loss is    0.41.\n",
      "For batch 48, vl_loss is    0.42.\n",
      "For batch 49, vl_loss is    0.41.\n",
      "For batch 50, vl_loss is    0.41.\n",
      "For batch 51, vl_loss is    0.41.\n",
      "For batch 52, vl_loss is    0.42.\n",
      "For batch 53, vl_loss is    0.42.\n",
      "For batch 54, vl_loss is    0.42.\n",
      "For batch 55, vl_loss is    0.42.\n",
      "For batch 56, vl_loss is    0.42.\n",
      "For batch 57, vl_loss is    0.42.\n",
      "For batch 58, vl_loss is    0.42.\n",
      "For batch 59, vl_loss is    0.42.\n",
      "For batch 60, vl_loss is    0.42.\n",
      "For batch 61, vl_loss is    0.41.\n",
      "For batch 62, vl_loss is    0.41.\n",
      "For batch 63, vl_loss is    0.41.\n",
      "For batch 64, vl_loss is    0.41.\n",
      "For batch 65, vl_loss is    0.41.\n",
      "For batch 66, vl_loss is    0.41.\n",
      "For batch 67, vl_loss is    0.41.\n",
      "232/232 [==============================] - 205s 878ms/step - loss: 0.2802 - iou_score: 0.7052 - f1-score: 0.8249 - val_loss: 0.4136 - val_iou_score: 0.6366 - val_f1-score: 0.7756\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.40105\n",
      "The average loss for epoch 5 is    0.28 \n",
      "Epoch 7/200\n",
      "  1/232 [..............................] - ETA: 11:21 - loss: 0.2294 - iou_score: 0.7754 - f1-score: 0.8720For batch 0, tr_loss is    0.23.\n",
      "  2/232 [..............................] - ETA: 4:24 - loss: 0.2286 - iou_score: 0.7687 - f1-score: 0.8684 For batch 1, tr_loss is    0.23.\n",
      "  3/232 [..............................] - ETA: 5:34 - loss: 0.2479 - iou_score: 0.7317 - f1-score: 0.8433For batch 2, tr_loss is    0.25.\n",
      "  4/232 [..............................] - ETA: 4:41 - loss: 0.2480 - iou_score: 0.7380 - f1-score: 0.8477For batch 3, tr_loss is    0.25.\n",
      "  5/232 [..............................] - ETA: 5:00 - loss: 0.2567 - iou_score: 0.7291 - f1-score: 0.8415For batch 4, tr_loss is    0.26.\n",
      "  6/232 [..............................] - ETA: 5:03 - loss: 0.2621 - iou_score: 0.7213 - f1-score: 0.8359For batch 5, tr_loss is    0.26.\n",
      "  7/232 [..............................] - ETA: 4:57 - loss: 0.2763 - iou_score: 0.7060 - f1-score: 0.8251For batch 6, tr_loss is    0.28.\n",
      "  8/232 [>.............................] - ETA: 4:47 - loss: 0.2824 - iou_score: 0.6958 - f1-score: 0.8181For batch 7, tr_loss is    0.28.\n",
      "  9/232 [>.............................] - ETA: 4:37 - loss: 0.2749 - iou_score: 0.7059 - f1-score: 0.8250For batch 8, tr_loss is    0.27.\n",
      " 10/232 [>.............................] - ETA: 4:28 - loss: 0.2740 - iou_score: 0.7065 - f1-score: 0.8256For batch 9, tr_loss is    0.27.\n",
      " 11/232 [>.............................] - ETA: 4:11 - loss: 0.2723 - iou_score: 0.7075 - f1-score: 0.8265For batch 10, tr_loss is    0.27.\n",
      " 12/232 [>.............................] - ETA: 4:07 - loss: 0.2691 - iou_score: 0.7140 - f1-score: 0.8309For batch 11, tr_loss is    0.27.\n",
      " 13/232 [>.............................] - ETA: 3:55 - loss: 0.2682 - iou_score: 0.7175 - f1-score: 0.8331For batch 12, tr_loss is    0.27.\n",
      " 14/232 [>.............................] - ETA: 3:54 - loss: 0.2643 - iou_score: 0.7217 - f1-score: 0.8361For batch 13, tr_loss is    0.26.\n",
      " 15/232 [>.............................] - ETA: 3:44 - loss: 0.2599 - iou_score: 0.7267 - f1-score: 0.8394For batch 14, tr_loss is    0.26.\n",
      " 16/232 [=>............................] - ETA: 3:45 - loss: 0.2588 - iou_score: 0.7263 - f1-score: 0.8392For batch 15, tr_loss is    0.26.\n",
      " 17/232 [=>............................] - ETA: 3:43 - loss: 0.2572 - iou_score: 0.7290 - f1-score: 0.8411For batch 16, tr_loss is    0.26.\n",
      " 18/232 [=>............................] - ETA: 3:35 - loss: 0.2588 - iou_score: 0.7285 - f1-score: 0.8409For batch 17, tr_loss is    0.26.\n",
      " 19/232 [=>............................] - ETA: 3:31 - loss: 0.2614 - iou_score: 0.7251 - f1-score: 0.8386For batch 18, tr_loss is    0.26.\n",
      " 20/232 [=>............................] - ETA: 3:31 - loss: 0.2588 - iou_score: 0.7270 - f1-score: 0.8399For batch 19, tr_loss is    0.26.\n",
      " 21/232 [=>............................] - ETA: 3:30 - loss: 0.2647 - iou_score: 0.7239 - f1-score: 0.8376For batch 20, tr_loss is    0.26.\n",
      " 22/232 [=>............................] - ETA: 3:30 - loss: 0.2670 - iou_score: 0.7211 - f1-score: 0.8356For batch 21, tr_loss is    0.27.\n",
      " 23/232 [=>............................] - ETA: 3:29 - loss: 0.2671 - iou_score: 0.7208 - f1-score: 0.8355For batch 22, tr_loss is    0.27.\n",
      " 24/232 [==>...........................] - ETA: 3:24 - loss: 0.2672 - iou_score: 0.7204 - f1-score: 0.8353For batch 23, tr_loss is    0.27.\n",
      " 25/232 [==>...........................] - ETA: 3:20 - loss: 0.2707 - iou_score: 0.7154 - f1-score: 0.8317For batch 24, tr_loss is    0.27.\n",
      " 26/232 [==>...........................] - ETA: 3:17 - loss: 0.2713 - iou_score: 0.7152 - f1-score: 0.8316For batch 25, tr_loss is    0.27.\n",
      " 27/232 [==>...........................] - ETA: 3:16 - loss: 0.2690 - iou_score: 0.7182 - f1-score: 0.8336For batch 26, tr_loss is    0.27.\n",
      " 28/232 [==>...........................] - ETA: 3:16 - loss: 0.2691 - iou_score: 0.7182 - f1-score: 0.8336For batch 27, tr_loss is    0.27.\n",
      " 29/232 [==>...........................] - ETA: 3:11 - loss: 0.2686 - iou_score: 0.7172 - f1-score: 0.8329For batch 28, tr_loss is    0.27.\n",
      " 30/232 [==>...........................] - ETA: 3:08 - loss: 0.2682 - iou_score: 0.7187 - f1-score: 0.8340For batch 29, tr_loss is    0.27.\n",
      " 31/232 [===>..........................] - ETA: 3:08 - loss: 0.2670 - iou_score: 0.7204 - f1-score: 0.8351For batch 30, tr_loss is    0.27.\n",
      " 32/232 [===>..........................] - ETA: 3:08 - loss: 0.2671 - iou_score: 0.7202 - f1-score: 0.8351For batch 31, tr_loss is    0.27.\n",
      " 33/232 [===>..........................] - ETA: 3:07 - loss: 0.2691 - iou_score: 0.7177 - f1-score: 0.8334For batch 32, tr_loss is    0.27.\n",
      " 34/232 [===>..........................] - ETA: 3:07 - loss: 0.2698 - iou_score: 0.7174 - f1-score: 0.8332For batch 33, tr_loss is    0.27.\n",
      " 35/232 [===>..........................] - ETA: 3:05 - loss: 0.2709 - iou_score: 0.7162 - f1-score: 0.8324For batch 34, tr_loss is    0.27.\n",
      " 36/232 [===>..........................] - ETA: 3:02 - loss: 0.2711 - iou_score: 0.7161 - f1-score: 0.8324For batch 35, tr_loss is    0.27.\n",
      " 37/232 [===>..........................] - ETA: 3:02 - loss: 0.2707 - iou_score: 0.7158 - f1-score: 0.8323For batch 36, tr_loss is    0.27.\n",
      " 38/232 [===>..........................] - ETA: 3:01 - loss: 0.2722 - iou_score: 0.7146 - f1-score: 0.8314For batch 37, tr_loss is    0.27.\n",
      " 39/232 [====>.........................] - ETA: 2:58 - loss: 0.2759 - iou_score: 0.7109 - f1-score: 0.8288For batch 38, tr_loss is    0.28.\n",
      " 40/232 [====>.........................] - ETA: 2:56 - loss: 0.2770 - iou_score: 0.7104 - f1-score: 0.8284For batch 39, tr_loss is    0.28.\n",
      " 41/232 [====>.........................] - ETA: 2:54 - loss: 0.2784 - iou_score: 0.7089 - f1-score: 0.8274For batch 40, tr_loss is    0.28.\n",
      " 42/232 [====>.........................] - ETA: 2:54 - loss: 0.2789 - iou_score: 0.7074 - f1-score: 0.8263For batch 41, tr_loss is    0.28.\n",
      " 43/232 [====>.........................] - ETA: 2:51 - loss: 0.2783 - iou_score: 0.7083 - f1-score: 0.8269For batch 42, tr_loss is    0.28.\n",
      " 44/232 [====>.........................] - ETA: 2:49 - loss: 0.2803 - iou_score: 0.7061 - f1-score: 0.8253For batch 43, tr_loss is    0.28.\n",
      " 45/232 [====>.........................] - ETA: 2:49 - loss: 0.2814 - iou_score: 0.7055 - f1-score: 0.8249For batch 44, tr_loss is    0.28.\n",
      " 46/232 [====>.........................] - ETA: 2:46 - loss: 0.2811 - iou_score: 0.7062 - f1-score: 0.8254For batch 45, tr_loss is    0.28.\n",
      " 47/232 [=====>........................] - ETA: 2:47 - loss: 0.2807 - iou_score: 0.7070 - f1-score: 0.8260For batch 46, tr_loss is    0.28.\n",
      " 48/232 [=====>........................] - ETA: 2:46 - loss: 0.2797 - iou_score: 0.7084 - f1-score: 0.8270For batch 47, tr_loss is    0.28.\n",
      " 49/232 [=====>........................] - ETA: 2:46 - loss: 0.2803 - iou_score: 0.7079 - f1-score: 0.8266For batch 48, tr_loss is    0.28.\n",
      " 50/232 [=====>........................] - ETA: 2:45 - loss: 0.2796 - iou_score: 0.7089 - f1-score: 0.8273For batch 49, tr_loss is    0.28.\n",
      " 51/232 [=====>........................] - ETA: 2:44 - loss: 0.2809 - iou_score: 0.7077 - f1-score: 0.8264For batch 50, tr_loss is    0.28.\n",
      " 52/232 [=====>........................] - ETA: 2:44 - loss: 0.2834 - iou_score: 0.7058 - f1-score: 0.8251For batch 51, tr_loss is    0.28.\n",
      " 53/232 [=====>........................] - ETA: 2:43 - loss: 0.2821 - iou_score: 0.7073 - f1-score: 0.8261For batch 52, tr_loss is    0.28.\n",
      " 54/232 [=====>........................] - ETA: 2:43 - loss: 0.2823 - iou_score: 0.7066 - f1-score: 0.8256For batch 53, tr_loss is    0.28.\n",
      " 55/232 [======>.......................] - ETA: 2:41 - loss: 0.2819 - iou_score: 0.7069 - f1-score: 0.8259For batch 54, tr_loss is    0.28.\n",
      " 56/232 [======>.......................] - ETA: 2:40 - loss: 0.2819 - iou_score: 0.7064 - f1-score: 0.8256For batch 55, tr_loss is    0.28.\n",
      " 57/232 [======>.......................] - ETA: 2:40 - loss: 0.2822 - iou_score: 0.7056 - f1-score: 0.8250For batch 56, tr_loss is    0.28.\n",
      " 58/232 [======>.......................] - ETA: 2:39 - loss: 0.2816 - iou_score: 0.7065 - f1-score: 0.8257For batch 57, tr_loss is    0.28.\n",
      " 59/232 [======>.......................] - ETA: 2:38 - loss: 0.2812 - iou_score: 0.7072 - f1-score: 0.8262For batch 58, tr_loss is    0.28.\n",
      " 60/232 [======>.......................] - ETA: 2:37 - loss: 0.2825 - iou_score: 0.7056 - f1-score: 0.8250For batch 59, tr_loss is    0.28.\n",
      " 61/232 [======>.......................] - ETA: 2:36 - loss: 0.2844 - iou_score: 0.7040 - f1-score: 0.8237For batch 60, tr_loss is    0.28.\n",
      " 62/232 [=======>......................] - ETA: 2:34 - loss: 0.2852 - iou_score: 0.7032 - f1-score: 0.8232For batch 61, tr_loss is    0.29.\n",
      " 63/232 [=======>......................] - ETA: 2:33 - loss: 0.2847 - iou_score: 0.7039 - f1-score: 0.8237For batch 62, tr_loss is    0.28.\n",
      " 64/232 [=======>......................] - ETA: 2:31 - loss: 0.2848 - iou_score: 0.7033 - f1-score: 0.8233For batch 63, tr_loss is    0.28.\n",
      " 65/232 [=======>......................] - ETA: 2:30 - loss: 0.2848 - iou_score: 0.7035 - f1-score: 0.8234For batch 64, tr_loss is    0.28.\n",
      " 66/232 [=======>......................] - ETA: 2:29 - loss: 0.2854 - iou_score: 0.7028 - f1-score: 0.8230For batch 65, tr_loss is    0.29.\n",
      " 67/232 [=======>......................] - ETA: 2:28 - loss: 0.2846 - iou_score: 0.7036 - f1-score: 0.8236For batch 66, tr_loss is    0.28.\n",
      " 68/232 [=======>......................] - ETA: 2:26 - loss: 0.2843 - iou_score: 0.7041 - f1-score: 0.8239For batch 67, tr_loss is    0.28.\n",
      " 69/232 [=======>......................] - ETA: 2:25 - loss: 0.2841 - iou_score: 0.7044 - f1-score: 0.8242For batch 68, tr_loss is    0.28.\n",
      " 70/232 [========>.....................] - ETA: 2:25 - loss: 0.2835 - iou_score: 0.7049 - f1-score: 0.8245For batch 69, tr_loss is    0.28.\n",
      " 71/232 [========>.....................] - ETA: 2:24 - loss: 0.2827 - iou_score: 0.7060 - f1-score: 0.8252For batch 70, tr_loss is    0.28.\n",
      " 72/232 [========>.....................] - ETA: 2:24 - loss: 0.2819 - iou_score: 0.7067 - f1-score: 0.8257For batch 71, tr_loss is    0.28.\n",
      " 73/232 [========>.....................] - ETA: 2:22 - loss: 0.2819 - iou_score: 0.7064 - f1-score: 0.8256For batch 72, tr_loss is    0.28.\n",
      " 74/232 [========>.....................] - ETA: 2:21 - loss: 0.2810 - iou_score: 0.7074 - f1-score: 0.8262For batch 73, tr_loss is    0.28.\n",
      " 75/232 [========>.....................] - ETA: 2:20 - loss: 0.2811 - iou_score: 0.7073 - f1-score: 0.8262For batch 74, tr_loss is    0.28.\n",
      " 76/232 [========>.....................] - ETA: 2:20 - loss: 0.2806 - iou_score: 0.7075 - f1-score: 0.8264For batch 75, tr_loss is    0.28.\n",
      " 77/232 [========>.....................] - ETA: 2:18 - loss: 0.2798 - iou_score: 0.7083 - f1-score: 0.8269For batch 76, tr_loss is    0.28.\n",
      " 78/232 [=========>....................] - ETA: 2:18 - loss: 0.2800 - iou_score: 0.7081 - f1-score: 0.8268For batch 77, tr_loss is    0.28.\n",
      " 79/232 [=========>....................] - ETA: 2:17 - loss: 0.2793 - iou_score: 0.7088 - f1-score: 0.8273For batch 78, tr_loss is    0.28.\n",
      " 80/232 [=========>....................] - ETA: 2:16 - loss: 0.2791 - iou_score: 0.7088 - f1-score: 0.8273For batch 79, tr_loss is    0.28.\n",
      " 81/232 [=========>....................] - ETA: 2:16 - loss: 0.2793 - iou_score: 0.7085 - f1-score: 0.8271For batch 80, tr_loss is    0.28.\n",
      " 82/232 [=========>....................] - ETA: 2:15 - loss: 0.2797 - iou_score: 0.7081 - f1-score: 0.8268For batch 81, tr_loss is    0.28.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 83/232 [=========>....................] - ETA: 2:13 - loss: 0.2805 - iou_score: 0.7069 - f1-score: 0.8260For batch 82, tr_loss is    0.28.\n",
      " 84/232 [=========>....................] - ETA: 2:11 - loss: 0.2808 - iou_score: 0.7065 - f1-score: 0.8257For batch 83, tr_loss is    0.28.\n",
      " 85/232 [=========>....................] - ETA: 2:10 - loss: 0.2810 - iou_score: 0.7062 - f1-score: 0.8255For batch 84, tr_loss is    0.28.\n",
      " 86/232 [==========>...................] - ETA: 2:09 - loss: 0.2812 - iou_score: 0.7057 - f1-score: 0.8252For batch 85, tr_loss is    0.28.\n",
      " 87/232 [==========>...................] - ETA: 2:08 - loss: 0.2808 - iou_score: 0.7060 - f1-score: 0.8254For batch 86, tr_loss is    0.28.\n",
      " 88/232 [==========>...................] - ETA: 2:08 - loss: 0.2816 - iou_score: 0.7051 - f1-score: 0.8248For batch 87, tr_loss is    0.28.\n",
      " 89/232 [==========>...................] - ETA: 2:07 - loss: 0.2812 - iou_score: 0.7054 - f1-score: 0.8250For batch 88, tr_loss is    0.28.\n",
      " 90/232 [==========>...................] - ETA: 2:06 - loss: 0.2808 - iou_score: 0.7056 - f1-score: 0.8252For batch 89, tr_loss is    0.28.\n",
      " 91/232 [==========>...................] - ETA: 2:05 - loss: 0.2807 - iou_score: 0.7056 - f1-score: 0.8252For batch 90, tr_loss is    0.28.\n",
      " 92/232 [==========>...................] - ETA: 2:04 - loss: 0.2806 - iou_score: 0.7058 - f1-score: 0.8254For batch 91, tr_loss is    0.28.\n",
      " 93/232 [===========>..................] - ETA: 2:03 - loss: 0.2815 - iou_score: 0.7046 - f1-score: 0.8245For batch 92, tr_loss is    0.28.\n",
      " 94/232 [===========>..................] - ETA: 2:03 - loss: 0.2812 - iou_score: 0.7054 - f1-score: 0.8250For batch 93, tr_loss is    0.28.\n",
      " 95/232 [===========>..................] - ETA: 2:02 - loss: 0.2815 - iou_score: 0.7049 - f1-score: 0.8246For batch 94, tr_loss is    0.28.\n",
      " 96/232 [===========>..................] - ETA: 2:01 - loss: 0.2811 - iou_score: 0.7052 - f1-score: 0.8248For batch 95, tr_loss is    0.28.\n",
      " 97/232 [===========>..................] - ETA: 2:01 - loss: 0.2817 - iou_score: 0.7045 - f1-score: 0.8243For batch 96, tr_loss is    0.28.\n",
      " 98/232 [===========>..................] - ETA: 2:00 - loss: 0.2814 - iou_score: 0.7046 - f1-score: 0.8244For batch 97, tr_loss is    0.28.\n",
      " 99/232 [===========>..................] - ETA: 1:58 - loss: 0.2805 - iou_score: 0.7058 - f1-score: 0.8252For batch 98, tr_loss is    0.28.\n",
      "100/232 [===========>..................] - ETA: 1:58 - loss: 0.2799 - iou_score: 0.7064 - f1-score: 0.8257For batch 99, tr_loss is    0.28.\n",
      "101/232 [============>.................] - ETA: 1:57 - loss: 0.2795 - iou_score: 0.7070 - f1-score: 0.8261For batch 100, tr_loss is    0.28.\n",
      "102/232 [============>.................] - ETA: 1:56 - loss: 0.2795 - iou_score: 0.7071 - f1-score: 0.8261For batch 101, tr_loss is    0.28.\n",
      "103/232 [============>.................] - ETA: 1:56 - loss: 0.2796 - iou_score: 0.7072 - f1-score: 0.8262For batch 102, tr_loss is    0.28.\n",
      "104/232 [============>.................] - ETA: 1:54 - loss: 0.2792 - iou_score: 0.7076 - f1-score: 0.8265For batch 103, tr_loss is    0.28.\n",
      "105/232 [============>.................] - ETA: 1:53 - loss: 0.2784 - iou_score: 0.7085 - f1-score: 0.8271For batch 104, tr_loss is    0.28.\n",
      "106/232 [============>.................] - ETA: 1:53 - loss: 0.2777 - iou_score: 0.7094 - f1-score: 0.8277For batch 105, tr_loss is    0.28.\n",
      "107/232 [============>.................] - ETA: 1:52 - loss: 0.2780 - iou_score: 0.7091 - f1-score: 0.8275For batch 106, tr_loss is    0.28.\n",
      "108/232 [============>.................] - ETA: 1:51 - loss: 0.2785 - iou_score: 0.7083 - f1-score: 0.8270For batch 107, tr_loss is    0.28.\n",
      "109/232 [=============>................] - ETA: 1:50 - loss: 0.2780 - iou_score: 0.7089 - f1-score: 0.8274For batch 108, tr_loss is    0.28.\n",
      "110/232 [=============>................] - ETA: 1:49 - loss: 0.2773 - iou_score: 0.7098 - f1-score: 0.8280For batch 109, tr_loss is    0.28.\n",
      "111/232 [=============>................] - ETA: 1:48 - loss: 0.2774 - iou_score: 0.7095 - f1-score: 0.8278For batch 110, tr_loss is    0.28.\n",
      "112/232 [=============>................] - ETA: 1:47 - loss: 0.2776 - iou_score: 0.7093 - f1-score: 0.8276For batch 111, tr_loss is    0.28.\n",
      "113/232 [=============>................] - ETA: 1:46 - loss: 0.2782 - iou_score: 0.7087 - f1-score: 0.8272For batch 112, tr_loss is    0.28.\n",
      "114/232 [=============>................] - ETA: 1:45 - loss: 0.2776 - iou_score: 0.7095 - f1-score: 0.8278For batch 113, tr_loss is    0.28.\n",
      "115/232 [=============>................] - ETA: 1:44 - loss: 0.2772 - iou_score: 0.7098 - f1-score: 0.8280For batch 114, tr_loss is    0.28.\n",
      "116/232 [==============>...............] - ETA: 1:43 - loss: 0.2768 - iou_score: 0.7101 - f1-score: 0.8282For batch 115, tr_loss is    0.28.\n",
      "117/232 [==============>...............] - ETA: 1:42 - loss: 0.2766 - iou_score: 0.7102 - f1-score: 0.8283For batch 116, tr_loss is    0.28.\n",
      "118/232 [==============>...............] - ETA: 1:41 - loss: 0.2761 - iou_score: 0.7110 - f1-score: 0.8288For batch 117, tr_loss is    0.28.\n",
      "119/232 [==============>...............] - ETA: 1:40 - loss: 0.2756 - iou_score: 0.7116 - f1-score: 0.8292For batch 118, tr_loss is    0.28.\n",
      "120/232 [==============>...............] - ETA: 1:39 - loss: 0.2759 - iou_score: 0.7113 - f1-score: 0.8290For batch 119, tr_loss is    0.28.\n",
      "121/232 [==============>...............] - ETA: 1:38 - loss: 0.2752 - iou_score: 0.7121 - f1-score: 0.8295For batch 120, tr_loss is    0.28.\n",
      "122/232 [==============>...............] - ETA: 1:37 - loss: 0.2755 - iou_score: 0.7115 - f1-score: 0.8291For batch 121, tr_loss is    0.28.\n",
      "123/232 [==============>...............] - ETA: 1:36 - loss: 0.2750 - iou_score: 0.7119 - f1-score: 0.8294For batch 122, tr_loss is    0.28.\n",
      "124/232 [===============>..............] - ETA: 1:36 - loss: 0.2750 - iou_score: 0.7119 - f1-score: 0.8294For batch 123, tr_loss is    0.28.\n",
      "125/232 [===============>..............] - ETA: 1:35 - loss: 0.2752 - iou_score: 0.7115 - f1-score: 0.8291For batch 124, tr_loss is    0.28.\n",
      "126/232 [===============>..............] - ETA: 1:34 - loss: 0.2754 - iou_score: 0.7116 - f1-score: 0.8292For batch 125, tr_loss is    0.28.\n",
      "127/232 [===============>..............] - ETA: 1:33 - loss: 0.2752 - iou_score: 0.7116 - f1-score: 0.8292For batch 126, tr_loss is    0.28.\n",
      "128/232 [===============>..............] - ETA: 1:33 - loss: 0.2757 - iou_score: 0.7112 - f1-score: 0.8289For batch 127, tr_loss is    0.28.\n",
      "129/232 [===============>..............] - ETA: 1:32 - loss: 0.2758 - iou_score: 0.7109 - f1-score: 0.8288For batch 128, tr_loss is    0.28.\n",
      "130/232 [===============>..............] - ETA: 1:31 - loss: 0.2759 - iou_score: 0.7113 - f1-score: 0.8290For batch 129, tr_loss is    0.28.\n",
      "131/232 [===============>..............] - ETA: 1:30 - loss: 0.2765 - iou_score: 0.7106 - f1-score: 0.8285For batch 130, tr_loss is    0.28.\n",
      "132/232 [================>.............] - ETA: 1:29 - loss: 0.2768 - iou_score: 0.7104 - f1-score: 0.8284For batch 131, tr_loss is    0.28.\n",
      "133/232 [================>.............] - ETA: 1:28 - loss: 0.2765 - iou_score: 0.7107 - f1-score: 0.8286For batch 132, tr_loss is    0.28.\n",
      "134/232 [================>.............] - ETA: 1:27 - loss: 0.2770 - iou_score: 0.7097 - f1-score: 0.8279For batch 133, tr_loss is    0.28.\n",
      "135/232 [================>.............] - ETA: 1:27 - loss: 0.2766 - iou_score: 0.7101 - f1-score: 0.8281For batch 134, tr_loss is    0.28.\n",
      "136/232 [================>.............] - ETA: 1:25 - loss: 0.2769 - iou_score: 0.7096 - f1-score: 0.8278For batch 135, tr_loss is    0.28.\n",
      "137/232 [================>.............] - ETA: 1:24 - loss: 0.2771 - iou_score: 0.7094 - f1-score: 0.8277For batch 136, tr_loss is    0.28.\n",
      "138/232 [================>.............] - ETA: 1:23 - loss: 0.2773 - iou_score: 0.7091 - f1-score: 0.8275For batch 137, tr_loss is    0.28.\n",
      "139/232 [================>.............] - ETA: 1:23 - loss: 0.2772 - iou_score: 0.7093 - f1-score: 0.8277For batch 138, tr_loss is    0.28.\n",
      "140/232 [=================>............] - ETA: 1:22 - loss: 0.2771 - iou_score: 0.7095 - f1-score: 0.8278For batch 139, tr_loss is    0.28.\n",
      "141/232 [=================>............] - ETA: 1:21 - loss: 0.2777 - iou_score: 0.7086 - f1-score: 0.8272For batch 140, tr_loss is    0.28.\n",
      "142/232 [=================>............] - ETA: 1:20 - loss: 0.2777 - iou_score: 0.7085 - f1-score: 0.8271For batch 141, tr_loss is    0.28.\n",
      "143/232 [=================>............] - ETA: 1:19 - loss: 0.2774 - iou_score: 0.7088 - f1-score: 0.8273For batch 142, tr_loss is    0.28.\n",
      "144/232 [=================>............] - ETA: 1:18 - loss: 0.2773 - iou_score: 0.7088 - f1-score: 0.8273For batch 143, tr_loss is    0.28.\n",
      "145/232 [=================>............] - ETA: 1:18 - loss: 0.2772 - iou_score: 0.7088 - f1-score: 0.8274For batch 144, tr_loss is    0.28.\n",
      "146/232 [=================>............] - ETA: 1:17 - loss: 0.2774 - iou_score: 0.7085 - f1-score: 0.8271For batch 145, tr_loss is    0.28.\n",
      "147/232 [==================>...........] - ETA: 1:16 - loss: 0.2770 - iou_score: 0.7090 - f1-score: 0.8275For batch 146, tr_loss is    0.28.\n",
      "148/232 [==================>...........] - ETA: 1:15 - loss: 0.2775 - iou_score: 0.7085 - f1-score: 0.8271For batch 147, tr_loss is    0.28.\n",
      "149/232 [==================>...........] - ETA: 1:14 - loss: 0.2771 - iou_score: 0.7090 - f1-score: 0.8274For batch 148, tr_loss is    0.28.\n",
      "150/232 [==================>...........] - ETA: 1:13 - loss: 0.2778 - iou_score: 0.7082 - f1-score: 0.8269For batch 149, tr_loss is    0.28.\n",
      "151/232 [==================>...........] - ETA: 1:12 - loss: 0.2780 - iou_score: 0.7079 - f1-score: 0.8267For batch 150, tr_loss is    0.28.\n",
      "152/232 [==================>...........] - ETA: 1:11 - loss: 0.2777 - iou_score: 0.7083 - f1-score: 0.8269For batch 151, tr_loss is    0.28.\n",
      "153/232 [==================>...........] - ETA: 1:10 - loss: 0.2776 - iou_score: 0.7082 - f1-score: 0.8269For batch 152, tr_loss is    0.28.\n",
      "154/232 [==================>...........] - ETA: 1:09 - loss: 0.2772 - iou_score: 0.7086 - f1-score: 0.8271For batch 153, tr_loss is    0.28.\n",
      "155/232 [===================>..........] - ETA: 1:08 - loss: 0.2771 - iou_score: 0.7086 - f1-score: 0.8272For batch 154, tr_loss is    0.28.\n",
      "156/232 [===================>..........] - ETA: 1:08 - loss: 0.2773 - iou_score: 0.7084 - f1-score: 0.8270For batch 155, tr_loss is    0.28.\n",
      "157/232 [===================>..........] - ETA: 1:07 - loss: 0.2777 - iou_score: 0.7082 - f1-score: 0.8269For batch 156, tr_loss is    0.28.\n",
      "158/232 [===================>..........] - ETA: 1:06 - loss: 0.2773 - iou_score: 0.7086 - f1-score: 0.8272For batch 157, tr_loss is    0.28.\n",
      "159/232 [===================>..........] - ETA: 1:05 - loss: 0.2772 - iou_score: 0.7089 - f1-score: 0.8274For batch 158, tr_loss is    0.28.\n",
      "160/232 [===================>..........] - ETA: 1:04 - loss: 0.2770 - iou_score: 0.7088 - f1-score: 0.8273For batch 159, tr_loss is    0.28.\n",
      "161/232 [===================>..........] - ETA: 1:03 - loss: 0.2768 - iou_score: 0.7091 - f1-score: 0.8275For batch 160, tr_loss is    0.28.\n",
      "162/232 [===================>..........] - ETA: 1:02 - loss: 0.2769 - iou_score: 0.7090 - f1-score: 0.8275For batch 161, tr_loss is    0.28.\n",
      "163/232 [====================>.........] - ETA: 1:01 - loss: 0.2766 - iou_score: 0.7093 - f1-score: 0.8277For batch 162, tr_loss is    0.28.\n",
      "164/232 [====================>.........] - ETA: 1:00 - loss: 0.2766 - iou_score: 0.7092 - f1-score: 0.8276For batch 163, tr_loss is    0.28.\n",
      "165/232 [====================>.........] - ETA: 59s - loss: 0.2767 - iou_score: 0.7090 - f1-score: 0.8275 For batch 164, tr_loss is    0.28.\n",
      "166/232 [====================>.........] - ETA: 58s - loss: 0.2764 - iou_score: 0.7091 - f1-score: 0.8276For batch 165, tr_loss is    0.28.\n",
      "167/232 [====================>.........] - ETA: 57s - loss: 0.2761 - iou_score: 0.7094 - f1-score: 0.8277For batch 166, tr_loss is    0.28.\n",
      "168/232 [====================>.........] - ETA: 56s - loss: 0.2763 - iou_score: 0.7093 - f1-score: 0.8277For batch 167, tr_loss is    0.28.\n",
      "169/232 [====================>.........] - ETA: 55s - loss: 0.2768 - iou_score: 0.7087 - f1-score: 0.8273For batch 168, tr_loss is    0.28.\n",
      "170/232 [====================>.........] - ETA: 54s - loss: 0.2767 - iou_score: 0.7089 - f1-score: 0.8274For batch 169, tr_loss is    0.28.\n",
      "171/232 [=====================>........] - ETA: 54s - loss: 0.2772 - iou_score: 0.7083 - f1-score: 0.8270For batch 170, tr_loss is    0.28.\n",
      "172/232 [=====================>........] - ETA: 53s - loss: 0.2773 - iou_score: 0.7081 - f1-score: 0.8268For batch 171, tr_loss is    0.28.\n",
      "173/232 [=====================>........] - ETA: 52s - loss: 0.2770 - iou_score: 0.7083 - f1-score: 0.8270For batch 172, tr_loss is    0.28.\n",
      "174/232 [=====================>........] - ETA: 51s - loss: 0.2768 - iou_score: 0.7085 - f1-score: 0.8271For batch 173, tr_loss is    0.28.\n",
      "175/232 [=====================>........] - ETA: 50s - loss: 0.2768 - iou_score: 0.7084 - f1-score: 0.8271For batch 174, tr_loss is    0.28.\n",
      "176/232 [=====================>........] - ETA: 49s - loss: 0.2770 - iou_score: 0.7081 - f1-score: 0.8269For batch 175, tr_loss is    0.28.\n",
      "177/232 [=====================>........] - ETA: 48s - loss: 0.2766 - iou_score: 0.7086 - f1-score: 0.8272For batch 176, tr_loss is    0.28.\n",
      "178/232 [======================>.......] - ETA: 47s - loss: 0.2766 - iou_score: 0.7086 - f1-score: 0.8272For batch 177, tr_loss is    0.28.\n",
      "179/232 [======================>.......] - ETA: 46s - loss: 0.2764 - iou_score: 0.7089 - f1-score: 0.8274For batch 178, tr_loss is    0.28.\n",
      "180/232 [======================>.......] - ETA: 46s - loss: 0.2765 - iou_score: 0.7088 - f1-score: 0.8273For batch 179, tr_loss is    0.28.\n",
      "181/232 [======================>.......] - ETA: 45s - loss: 0.2767 - iou_score: 0.7086 - f1-score: 0.8272For batch 180, tr_loss is    0.28.\n",
      "182/232 [======================>.......] - ETA: 44s - loss: 0.2767 - iou_score: 0.7086 - f1-score: 0.8272For batch 181, tr_loss is    0.28.\n",
      "183/232 [======================>.......] - ETA: 43s - loss: 0.2767 - iou_score: 0.7085 - f1-score: 0.8272For batch 182, tr_loss is    0.28.\n",
      "184/232 [======================>.......] - ETA: 42s - loss: 0.2763 - iou_score: 0.7090 - f1-score: 0.8275For batch 183, tr_loss is    0.28.\n",
      "185/232 [======================>.......] - ETA: 41s - loss: 0.2764 - iou_score: 0.7089 - f1-score: 0.8275For batch 184, tr_loss is    0.28.\n",
      "186/232 [=======================>......] - ETA: 40s - loss: 0.2765 - iou_score: 0.7088 - f1-score: 0.8274For batch 185, tr_loss is    0.28.\n",
      "187/232 [=======================>......] - ETA: 39s - loss: 0.2760 - iou_score: 0.7093 - f1-score: 0.8277For batch 186, tr_loss is    0.28.\n",
      "188/232 [=======================>......] - ETA: 38s - loss: 0.2763 - iou_score: 0.7091 - f1-score: 0.8276For batch 187, tr_loss is    0.28.\n",
      "189/232 [=======================>......] - ETA: 37s - loss: 0.2762 - iou_score: 0.7093 - f1-score: 0.8277For batch 188, tr_loss is    0.28.\n",
      "190/232 [=======================>......] - ETA: 37s - loss: 0.2761 - iou_score: 0.7094 - f1-score: 0.8278For batch 189, tr_loss is    0.28.\n",
      "191/232 [=======================>......] - ETA: 36s - loss: 0.2762 - iou_score: 0.7094 - f1-score: 0.8278For batch 190, tr_loss is    0.28.\n",
      "192/232 [=======================>......] - ETA: 35s - loss: 0.2763 - iou_score: 0.7091 - f1-score: 0.8276For batch 191, tr_loss is    0.28.\n",
      "193/232 [=======================>......] - ETA: 34s - loss: 0.2766 - iou_score: 0.7086 - f1-score: 0.8272For batch 192, tr_loss is    0.28.\n",
      "194/232 [========================>.....] - ETA: 33s - loss: 0.2767 - iou_score: 0.7085 - f1-score: 0.8271For batch 193, tr_loss is    0.28.\n",
      "195/232 [========================>.....] - ETA: 32s - loss: 0.2767 - iou_score: 0.7083 - f1-score: 0.8270For batch 194, tr_loss is    0.28.\n",
      "196/232 [========================>.....] - ETA: 31s - loss: 0.2767 - iou_score: 0.7083 - f1-score: 0.8270For batch 195, tr_loss is    0.28.\n",
      "197/232 [========================>.....] - ETA: 31s - loss: 0.2765 - iou_score: 0.7084 - f1-score: 0.8271For batch 196, tr_loss is    0.28.\n",
      "198/232 [========================>.....] - ETA: 30s - loss: 0.2762 - iou_score: 0.7089 - f1-score: 0.8274For batch 197, tr_loss is    0.28.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/232 [========================>.....] - ETA: 29s - loss: 0.2760 - iou_score: 0.7090 - f1-score: 0.8275For batch 198, tr_loss is    0.28.\n",
      "200/232 [========================>.....] - ETA: 28s - loss: 0.2757 - iou_score: 0.7095 - f1-score: 0.8278For batch 199, tr_loss is    0.28.\n",
      "201/232 [========================>.....] - ETA: 27s - loss: 0.2758 - iou_score: 0.7092 - f1-score: 0.8277For batch 200, tr_loss is    0.28.\n",
      "202/232 [=========================>....] - ETA: 26s - loss: 0.2757 - iou_score: 0.7094 - f1-score: 0.8277For batch 201, tr_loss is    0.28.\n",
      "203/232 [=========================>....] - ETA: 25s - loss: 0.2753 - iou_score: 0.7096 - f1-score: 0.8279For batch 202, tr_loss is    0.28.\n",
      "204/232 [=========================>....] - ETA: 24s - loss: 0.2749 - iou_score: 0.7101 - f1-score: 0.8282For batch 203, tr_loss is    0.27.\n",
      "205/232 [=========================>....] - ETA: 23s - loss: 0.2749 - iou_score: 0.7101 - f1-score: 0.8282For batch 204, tr_loss is    0.27.\n",
      "206/232 [=========================>....] - ETA: 22s - loss: 0.2752 - iou_score: 0.7099 - f1-score: 0.8281For batch 205, tr_loss is    0.28.\n",
      "207/232 [=========================>....] - ETA: 22s - loss: 0.2751 - iou_score: 0.7100 - f1-score: 0.8282For batch 206, tr_loss is    0.28.\n",
      "208/232 [=========================>....] - ETA: 21s - loss: 0.2750 - iou_score: 0.7101 - f1-score: 0.8282For batch 207, tr_loss is    0.27.\n",
      "209/232 [==========================>...] - ETA: 20s - loss: 0.2752 - iou_score: 0.7099 - f1-score: 0.8281For batch 208, tr_loss is    0.28.\n",
      "210/232 [==========================>...] - ETA: 19s - loss: 0.2755 - iou_score: 0.7095 - f1-score: 0.8278For batch 209, tr_loss is    0.28.\n",
      "211/232 [==========================>...] - ETA: 18s - loss: 0.2753 - iou_score: 0.7097 - f1-score: 0.8280For batch 210, tr_loss is    0.28.\n",
      "212/232 [==========================>...] - ETA: 17s - loss: 0.2750 - iou_score: 0.7102 - f1-score: 0.8283For batch 211, tr_loss is    0.27.\n",
      "213/232 [==========================>...] - ETA: 16s - loss: 0.2751 - iou_score: 0.7101 - f1-score: 0.8283For batch 212, tr_loss is    0.28.\n",
      "214/232 [==========================>...] - ETA: 15s - loss: 0.2750 - iou_score: 0.7103 - f1-score: 0.8284For batch 213, tr_loss is    0.27.\n",
      "215/232 [==========================>...] - ETA: 14s - loss: 0.2747 - iou_score: 0.7106 - f1-score: 0.8286For batch 214, tr_loss is    0.27.\n",
      "216/232 [==========================>...] - ETA: 14s - loss: 0.2744 - iou_score: 0.7109 - f1-score: 0.8288For batch 215, tr_loss is    0.27.\n",
      "217/232 [===========================>..] - ETA: 13s - loss: 0.2744 - iou_score: 0.7109 - f1-score: 0.8288For batch 216, tr_loss is    0.27.\n",
      "218/232 [===========================>..] - ETA: 12s - loss: 0.2745 - iou_score: 0.7108 - f1-score: 0.8287For batch 217, tr_loss is    0.27.\n",
      "219/232 [===========================>..] - ETA: 11s - loss: 0.2750 - iou_score: 0.7101 - f1-score: 0.8283For batch 218, tr_loss is    0.28.\n",
      "220/232 [===========================>..] - ETA: 10s - loss: 0.2750 - iou_score: 0.7101 - f1-score: 0.8282For batch 219, tr_loss is    0.27.\n",
      "221/232 [===========================>..] - ETA: 9s - loss: 0.2750 - iou_score: 0.7099 - f1-score: 0.8281 For batch 220, tr_loss is    0.28.\n",
      "222/232 [===========================>..] - ETA: 8s - loss: 0.2749 - iou_score: 0.7102 - f1-score: 0.8283For batch 221, tr_loss is    0.27.\n",
      "223/232 [===========================>..] - ETA: 7s - loss: 0.2749 - iou_score: 0.7101 - f1-score: 0.8282For batch 222, tr_loss is    0.27.\n",
      "224/232 [===========================>..] - ETA: 7s - loss: 0.2747 - iou_score: 0.7103 - f1-score: 0.8284For batch 223, tr_loss is    0.27.\n",
      "225/232 [============================>.] - ETA: 6s - loss: 0.2745 - iou_score: 0.7106 - f1-score: 0.8286For batch 224, tr_loss is    0.27.\n",
      "226/232 [============================>.] - ETA: 5s - loss: 0.2744 - iou_score: 0.7105 - f1-score: 0.8286For batch 225, tr_loss is    0.27.\n",
      "227/232 [============================>.] - ETA: 4s - loss: 0.2742 - iou_score: 0.7108 - f1-score: 0.8287For batch 226, tr_loss is    0.27.\n",
      "228/232 [============================>.] - ETA: 3s - loss: 0.2744 - iou_score: 0.7106 - f1-score: 0.8286For batch 227, tr_loss is    0.27.\n",
      "229/232 [============================>.] - ETA: 2s - loss: 0.2742 - iou_score: 0.7107 - f1-score: 0.8287For batch 228, tr_loss is    0.27.\n",
      "230/232 [============================>.] - ETA: 1s - loss: 0.2745 - iou_score: 0.7104 - f1-score: 0.8284For batch 229, tr_loss is    0.27.\n",
      "231/232 [============================>.] - ETA: 0s - loss: 0.2749 - iou_score: 0.7100 - f1-score: 0.8282For batch 230, tr_loss is    0.27.\n",
      "232/232 [==============================] - ETA: 0s - loss: 0.2746 - iou_score: 0.7103 - f1-score: 0.8284For batch 231, tr_loss is    0.27.\n",
      "For batch 0, vl_loss is    0.49.\n",
      "For batch 1, vl_loss is    0.45.\n",
      "For batch 2, vl_loss is    0.48.\n",
      "For batch 3, vl_loss is    0.50.\n",
      "For batch 4, vl_loss is    0.53.\n",
      "For batch 5, vl_loss is    0.50.\n",
      "For batch 6, vl_loss is    0.51.\n",
      "For batch 7, vl_loss is    0.50.\n",
      "For batch 8, vl_loss is    0.49.\n",
      "For batch 9, vl_loss is    0.47.\n",
      "For batch 10, vl_loss is    0.46.\n",
      "For batch 11, vl_loss is    0.47.\n",
      "For batch 12, vl_loss is    0.48.\n",
      "For batch 13, vl_loss is    0.49.\n",
      "For batch 14, vl_loss is    0.48.\n",
      "For batch 15, vl_loss is    0.48.\n",
      "For batch 16, vl_loss is    0.47.\n",
      "For batch 17, vl_loss is    0.47.\n",
      "For batch 18, vl_loss is    0.47.\n",
      "For batch 19, vl_loss is    0.46.\n",
      "For batch 20, vl_loss is    0.46.\n",
      "For batch 21, vl_loss is    0.46.\n",
      "For batch 22, vl_loss is    0.46.\n",
      "For batch 23, vl_loss is    0.46.\n",
      "For batch 24, vl_loss is    0.45.\n",
      "For batch 25, vl_loss is    0.45.\n",
      "For batch 26, vl_loss is    0.45.\n",
      "For batch 27, vl_loss is    0.46.\n",
      "For batch 28, vl_loss is    0.46.\n",
      "For batch 29, vl_loss is    0.46.\n",
      "For batch 30, vl_loss is    0.46.\n",
      "For batch 31, vl_loss is    0.46.\n",
      "For batch 32, vl_loss is    0.46.\n",
      "For batch 33, vl_loss is    0.46.\n",
      "For batch 34, vl_loss is    0.46.\n",
      "For batch 35, vl_loss is    0.46.\n",
      "For batch 36, vl_loss is    0.46.\n",
      "For batch 37, vl_loss is    0.46.\n",
      "For batch 38, vl_loss is    0.46.\n",
      "For batch 39, vl_loss is    0.46.\n",
      "For batch 40, vl_loss is    0.46.\n",
      "For batch 41, vl_loss is    0.47.\n",
      "For batch 42, vl_loss is    0.47.\n",
      "For batch 43, vl_loss is    0.47.\n",
      "For batch 44, vl_loss is    0.47.\n",
      "For batch 45, vl_loss is    0.48.\n",
      "For batch 46, vl_loss is    0.47.\n",
      "For batch 47, vl_loss is    0.47.\n",
      "For batch 48, vl_loss is    0.47.\n",
      "For batch 49, vl_loss is    0.47.\n",
      "For batch 50, vl_loss is    0.47.\n",
      "For batch 51, vl_loss is    0.47.\n",
      "For batch 52, vl_loss is    0.47.\n",
      "For batch 53, vl_loss is    0.48.\n",
      "For batch 54, vl_loss is    0.48.\n",
      "For batch 55, vl_loss is    0.48.\n",
      "For batch 56, vl_loss is    0.47.\n",
      "For batch 57, vl_loss is    0.48.\n",
      "For batch 58, vl_loss is    0.48.\n",
      "For batch 59, vl_loss is    0.48.\n",
      "For batch 60, vl_loss is    0.47.\n",
      "For batch 61, vl_loss is    0.47.\n",
      "For batch 62, vl_loss is    0.47.\n",
      "For batch 63, vl_loss is    0.47.\n",
      "For batch 64, vl_loss is    0.47.\n",
      "For batch 65, vl_loss is    0.47.\n",
      "For batch 66, vl_loss is    0.47.\n",
      "For batch 67, vl_loss is    0.47.\n",
      "232/232 [==============================] - 207s 884ms/step - loss: 0.2746 - iou_score: 0.7103 - f1-score: 0.8284 - val_loss: 0.4662 - val_iou_score: 0.6479 - val_f1-score: 0.7840\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.40105\n",
      "The average loss for epoch 6 is    0.27 \n",
      "Epoch 8/200\n",
      "  1/232 [..............................] - ETA: 9:41 - loss: 0.2175 - iou_score: 0.7839 - f1-score: 0.8771For batch 0, tr_loss is    0.22.\n",
      "  2/232 [..............................] - ETA: 5:49 - loss: 0.2205 - iou_score: 0.7775 - f1-score: 0.8739For batch 1, tr_loss is    0.22.\n",
      "  3/232 [..............................] - ETA: 5:39 - loss: 0.2401 - iou_score: 0.7460 - f1-score: 0.8530For batch 2, tr_loss is    0.24.\n",
      "  4/232 [..............................] - ETA: 5:46 - loss: 0.2368 - iou_score: 0.7549 - f1-score: 0.8591For batch 3, tr_loss is    0.24.\n",
      "  5/232 [..............................] - ETA: 5:26 - loss: 0.2476 - iou_score: 0.7420 - f1-score: 0.8503For batch 4, tr_loss is    0.25.\n",
      "  6/232 [..............................] - ETA: 5:11 - loss: 0.2575 - iou_score: 0.7310 - f1-score: 0.8423For batch 5, tr_loss is    0.26.\n",
      "  7/232 [..............................] - ETA: 4:55 - loss: 0.2695 - iou_score: 0.7185 - f1-score: 0.8338For batch 6, tr_loss is    0.27.\n",
      "  8/232 [>.............................] - ETA: 4:57 - loss: 0.2743 - iou_score: 0.7104 - f1-score: 0.8283For batch 7, tr_loss is    0.27.\n",
      "  9/232 [>.............................] - ETA: 4:52 - loss: 0.2667 - iou_score: 0.7203 - f1-score: 0.8350For batch 8, tr_loss is    0.27.\n",
      " 10/232 [>.............................] - ETA: 4:45 - loss: 0.2673 - iou_score: 0.7183 - f1-score: 0.8337For batch 9, tr_loss is    0.27.\n",
      " 11/232 [>.............................] - ETA: 4:36 - loss: 0.2655 - iou_score: 0.7188 - f1-score: 0.8342For batch 10, tr_loss is    0.27.\n",
      " 12/232 [>.............................] - ETA: 4:30 - loss: 0.2623 - iou_score: 0.7253 - f1-score: 0.8386For batch 11, tr_loss is    0.26.\n",
      " 13/232 [>.............................] - ETA: 4:18 - loss: 0.2609 - iou_score: 0.7277 - f1-score: 0.8401For batch 12, tr_loss is    0.26.\n",
      " 14/232 [>.............................] - ETA: 4:13 - loss: 0.2576 - iou_score: 0.7312 - f1-score: 0.8425For batch 13, tr_loss is    0.26.\n",
      " 15/232 [>.............................] - ETA: 4:10 - loss: 0.2534 - iou_score: 0.7358 - f1-score: 0.8456For batch 14, tr_loss is    0.25.\n",
      " 16/232 [=>............................] - ETA: 4:06 - loss: 0.2524 - iou_score: 0.7356 - f1-score: 0.8455For batch 15, tr_loss is    0.25.\n",
      " 17/232 [=>............................] - ETA: 3:55 - loss: 0.2495 - iou_score: 0.7385 - f1-score: 0.8475For batch 16, tr_loss is    0.25.\n",
      " 18/232 [=>............................] - ETA: 3:54 - loss: 0.2507 - iou_score: 0.7370 - f1-score: 0.8466For batch 17, tr_loss is    0.25.\n",
      " 19/232 [=>............................] - ETA: 3:52 - loss: 0.2529 - iou_score: 0.7332 - f1-score: 0.8440For batch 18, tr_loss is    0.25.\n",
      " 20/232 [=>............................] - ETA: 3:49 - loss: 0.2503 - iou_score: 0.7355 - f1-score: 0.8457For batch 19, tr_loss is    0.25.\n",
      " 21/232 [=>............................] - ETA: 3:43 - loss: 0.2552 - iou_score: 0.7324 - f1-score: 0.8435For batch 20, tr_loss is    0.26.\n",
      " 22/232 [=>............................] - ETA: 3:42 - loss: 0.2571 - iou_score: 0.7298 - f1-score: 0.8416For batch 21, tr_loss is    0.26.\n",
      " 23/232 [=>............................] - ETA: 3:40 - loss: 0.2567 - iou_score: 0.7296 - f1-score: 0.8414For batch 22, tr_loss is    0.26.\n",
      " 24/232 [==>...........................] - ETA: 3:39 - loss: 0.2560 - iou_score: 0.7298 - f1-score: 0.8416For batch 23, tr_loss is    0.26.\n",
      " 25/232 [==>...........................] - ETA: 3:38 - loss: 0.2595 - iou_score: 0.7255 - f1-score: 0.8386For batch 24, tr_loss is    0.26.\n",
      " 26/232 [==>...........................] - ETA: 3:36 - loss: 0.2600 - iou_score: 0.7250 - f1-score: 0.8383For batch 25, tr_loss is    0.26.\n",
      " 27/232 [==>...........................] - ETA: 3:31 - loss: 0.2588 - iou_score: 0.7267 - f1-score: 0.8395For batch 26, tr_loss is    0.26.\n",
      " 28/232 [==>...........................] - ETA: 3:30 - loss: 0.2588 - iou_score: 0.7263 - f1-score: 0.8393For batch 27, tr_loss is    0.26.\n",
      " 29/232 [==>...........................] - ETA: 3:29 - loss: 0.2580 - iou_score: 0.7261 - f1-score: 0.8391For batch 28, tr_loss is    0.26.\n",
      " 30/232 [==>...........................] - ETA: 3:28 - loss: 0.2585 - iou_score: 0.7274 - f1-score: 0.8400For batch 29, tr_loss is    0.26.\n",
      " 31/232 [===>..........................] - ETA: 3:26 - loss: 0.2587 - iou_score: 0.7281 - f1-score: 0.8405For batch 30, tr_loss is    0.26.\n",
      " 32/232 [===>..........................] - ETA: 3:25 - loss: 0.2578 - iou_score: 0.7293 - f1-score: 0.8414For batch 31, tr_loss is    0.26.\n",
      " 33/232 [===>..........................] - ETA: 3:23 - loss: 0.2604 - iou_score: 0.7262 - f1-score: 0.8392For batch 32, tr_loss is    0.26.\n",
      " 34/232 [===>..........................] - ETA: 3:22 - loss: 0.2606 - iou_score: 0.7258 - f1-score: 0.8390For batch 33, tr_loss is    0.26.\n",
      " 35/232 [===>..........................] - ETA: 3:18 - loss: 0.2621 - iou_score: 0.7239 - f1-score: 0.8377For batch 34, tr_loss is    0.26.\n",
      " 36/232 [===>..........................] - ETA: 3:18 - loss: 0.2622 - iou_score: 0.7241 - f1-score: 0.8379For batch 35, tr_loss is    0.26.\n",
      " 37/232 [===>..........................] - ETA: 3:17 - loss: 0.2628 - iou_score: 0.7231 - f1-score: 0.8373For batch 36, tr_loss is    0.26.\n",
      " 38/232 [===>..........................] - ETA: 3:14 - loss: 0.2636 - iou_score: 0.7223 - f1-score: 0.8368For batch 37, tr_loss is    0.26.\n",
      " 39/232 [====>.........................] - ETA: 3:11 - loss: 0.2681 - iou_score: 0.7183 - f1-score: 0.8338For batch 38, tr_loss is    0.27.\n",
      " 40/232 [====>.........................] - ETA: 3:08 - loss: 0.2692 - iou_score: 0.7174 - f1-score: 0.8332For batch 39, tr_loss is    0.27.\n",
      " 41/232 [====>.........................] - ETA: 3:08 - loss: 0.2706 - iou_score: 0.7158 - f1-score: 0.8321For batch 40, tr_loss is    0.27.\n",
      " 42/232 [====>.........................] - ETA: 3:05 - loss: 0.2709 - iou_score: 0.7147 - f1-score: 0.8314For batch 41, tr_loss is    0.27.\n",
      " 43/232 [====>.........................] - ETA: 3:04 - loss: 0.2704 - iou_score: 0.7154 - f1-score: 0.8319For batch 42, tr_loss is    0.27.\n",
      " 44/232 [====>.........................] - ETA: 3:03 - loss: 0.2727 - iou_score: 0.7132 - f1-score: 0.8302For batch 43, tr_loss is    0.27.\n",
      " 45/232 [====>.........................] - ETA: 3:03 - loss: 0.2738 - iou_score: 0.7125 - f1-score: 0.8297For batch 44, tr_loss is    0.27.\n",
      " 46/232 [====>.........................] - ETA: 3:02 - loss: 0.2737 - iou_score: 0.7130 - f1-score: 0.8302For batch 45, tr_loss is    0.27.\n",
      " 47/232 [=====>........................] - ETA: 3:01 - loss: 0.2737 - iou_score: 0.7132 - f1-score: 0.8303For batch 46, tr_loss is    0.27.\n",
      " 48/232 [=====>........................] - ETA: 3:00 - loss: 0.2728 - iou_score: 0.7147 - f1-score: 0.8314For batch 47, tr_loss is    0.27.\n",
      " 49/232 [=====>........................] - ETA: 2:58 - loss: 0.2735 - iou_score: 0.7144 - f1-score: 0.8312For batch 48, tr_loss is    0.27.\n",
      " 50/232 [=====>........................] - ETA: 2:57 - loss: 0.2732 - iou_score: 0.7149 - f1-score: 0.8315For batch 49, tr_loss is    0.27.\n",
      " 51/232 [=====>........................] - ETA: 2:55 - loss: 0.2745 - iou_score: 0.7135 - f1-score: 0.8305For batch 50, tr_loss is    0.27.\n",
      " 52/232 [=====>........................] - ETA: 2:53 - loss: 0.2764 - iou_score: 0.7115 - f1-score: 0.8292For batch 51, tr_loss is    0.28.\n",
      " 53/232 [=====>........................] - ETA: 2:52 - loss: 0.2758 - iou_score: 0.7121 - f1-score: 0.8296For batch 52, tr_loss is    0.28.\n",
      " 54/232 [=====>........................] - ETA: 2:51 - loss: 0.2762 - iou_score: 0.7111 - f1-score: 0.8289For batch 53, tr_loss is    0.28.\n",
      " 55/232 [======>.......................] - ETA: 2:48 - loss: 0.2759 - iou_score: 0.7113 - f1-score: 0.8291For batch 54, tr_loss is    0.28.\n",
      " 56/232 [======>.......................] - ETA: 2:48 - loss: 0.2758 - iou_score: 0.7112 - f1-score: 0.8290For batch 55, tr_loss is    0.28.\n",
      " 57/232 [======>.......................] - ETA: 2:46 - loss: 0.2764 - iou_score: 0.7106 - f1-score: 0.8286For batch 56, tr_loss is    0.28.\n",
      " 58/232 [======>.......................] - ETA: 2:44 - loss: 0.2755 - iou_score: 0.7117 - f1-score: 0.8294For batch 57, tr_loss is    0.28.\n",
      " 59/232 [======>.......................] - ETA: 2:44 - loss: 0.2754 - iou_score: 0.7118 - f1-score: 0.8295For batch 58, tr_loss is    0.28.\n",
      " 60/232 [======>.......................] - ETA: 2:42 - loss: 0.2768 - iou_score: 0.7104 - f1-score: 0.8284For batch 59, tr_loss is    0.28.\n",
      " 61/232 [======>.......................] - ETA: 2:42 - loss: 0.2789 - iou_score: 0.7089 - f1-score: 0.8273For batch 60, tr_loss is    0.28.\n",
      " 62/232 [=======>......................] - ETA: 2:41 - loss: 0.2798 - iou_score: 0.7081 - f1-score: 0.8267For batch 61, tr_loss is    0.28.\n",
      " 63/232 [=======>......................] - ETA: 2:40 - loss: 0.2788 - iou_score: 0.7092 - f1-score: 0.8275For batch 62, tr_loss is    0.28.\n",
      " 64/232 [=======>......................] - ETA: 2:39 - loss: 0.2790 - iou_score: 0.7090 - f1-score: 0.8273For batch 63, tr_loss is    0.28.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 65/232 [=======>......................] - ETA: 2:39 - loss: 0.2788 - iou_score: 0.7092 - f1-score: 0.8275For batch 64, tr_loss is    0.28.\n",
      " 66/232 [=======>......................] - ETA: 2:38 - loss: 0.2789 - iou_score: 0.7087 - f1-score: 0.8272For batch 65, tr_loss is    0.28.\n",
      " 67/232 [=======>......................] - ETA: 2:37 - loss: 0.2779 - iou_score: 0.7099 - f1-score: 0.8280For batch 66, tr_loss is    0.28.\n",
      " 68/232 [=======>......................] - ETA: 2:36 - loss: 0.2776 - iou_score: 0.7103 - f1-score: 0.8283For batch 67, tr_loss is    0.28.\n",
      " 69/232 [=======>......................] - ETA: 2:35 - loss: 0.2772 - iou_score: 0.7107 - f1-score: 0.8285For batch 68, tr_loss is    0.28.\n",
      " 70/232 [========>.....................] - ETA: 2:35 - loss: 0.2769 - iou_score: 0.7107 - f1-score: 0.8286For batch 69, tr_loss is    0.28.\n",
      " 71/232 [========>.....................] - ETA: 2:33 - loss: 0.2761 - iou_score: 0.7120 - f1-score: 0.8294For batch 70, tr_loss is    0.28.\n",
      " 72/232 [========>.....................] - ETA: 2:32 - loss: 0.2753 - iou_score: 0.7125 - f1-score: 0.8298For batch 71, tr_loss is    0.28.\n",
      " 73/232 [========>.....................] - ETA: 2:31 - loss: 0.2752 - iou_score: 0.7122 - f1-score: 0.8296For batch 72, tr_loss is    0.28.\n",
      " 74/232 [========>.....................] - ETA: 2:29 - loss: 0.2746 - iou_score: 0.7131 - f1-score: 0.8302For batch 73, tr_loss is    0.27.\n",
      " 75/232 [========>.....................] - ETA: 2:28 - loss: 0.2748 - iou_score: 0.7129 - f1-score: 0.8301For batch 74, tr_loss is    0.27.\n",
      " 76/232 [========>.....................] - ETA: 2:27 - loss: 0.2743 - iou_score: 0.7133 - f1-score: 0.8304For batch 75, tr_loss is    0.27.\n",
      " 77/232 [========>.....................] - ETA: 2:26 - loss: 0.2734 - iou_score: 0.7140 - f1-score: 0.8309For batch 76, tr_loss is    0.27.\n",
      " 78/232 [=========>....................] - ETA: 2:25 - loss: 0.2735 - iou_score: 0.7137 - f1-score: 0.8307For batch 77, tr_loss is    0.27.\n",
      " 79/232 [=========>....................] - ETA: 2:24 - loss: 0.2730 - iou_score: 0.7141 - f1-score: 0.8310For batch 78, tr_loss is    0.27.\n",
      " 80/232 [=========>....................] - ETA: 2:23 - loss: 0.2729 - iou_score: 0.7142 - f1-score: 0.8311For batch 79, tr_loss is    0.27.\n",
      " 81/232 [=========>....................] - ETA: 2:23 - loss: 0.2730 - iou_score: 0.7138 - f1-score: 0.8308For batch 80, tr_loss is    0.27.\n",
      " 82/232 [=========>....................] - ETA: 2:22 - loss: 0.2731 - iou_score: 0.7134 - f1-score: 0.8305For batch 81, tr_loss is    0.27.\n",
      " 83/232 [=========>....................] - ETA: 2:21 - loss: 0.2738 - iou_score: 0.7122 - f1-score: 0.8297For batch 82, tr_loss is    0.27.\n",
      " 84/232 [=========>....................] - ETA: 2:20 - loss: 0.2741 - iou_score: 0.7118 - f1-score: 0.8294For batch 83, tr_loss is    0.27.\n",
      " 85/232 [=========>....................] - ETA: 2:19 - loss: 0.2743 - iou_score: 0.7112 - f1-score: 0.8291For batch 84, tr_loss is    0.27.\n",
      " 86/232 [==========>...................] - ETA: 2:18 - loss: 0.2746 - iou_score: 0.7106 - f1-score: 0.8286For batch 85, tr_loss is    0.27.\n",
      " 87/232 [==========>...................] - ETA: 2:16 - loss: 0.2745 - iou_score: 0.7108 - f1-score: 0.8288For batch 86, tr_loss is    0.27.\n",
      " 88/232 [==========>...................] - ETA: 2:15 - loss: 0.2752 - iou_score: 0.7101 - f1-score: 0.8284For batch 87, tr_loss is    0.28.\n",
      " 89/232 [==========>...................] - ETA: 2:14 - loss: 0.2747 - iou_score: 0.7107 - f1-score: 0.8288For batch 88, tr_loss is    0.27.\n",
      " 90/232 [==========>...................] - ETA: 2:14 - loss: 0.2744 - iou_score: 0.7113 - f1-score: 0.8292For batch 89, tr_loss is    0.27.\n",
      " 91/232 [==========>...................] - ETA: 2:12 - loss: 0.2741 - iou_score: 0.7115 - f1-score: 0.8293For batch 90, tr_loss is    0.27.\n",
      " 92/232 [==========>...................] - ETA: 2:11 - loss: 0.2740 - iou_score: 0.7118 - f1-score: 0.8295For batch 91, tr_loss is    0.27.\n",
      " 93/232 [===========>..................] - ETA: 2:11 - loss: 0.2756 - iou_score: 0.7104 - f1-score: 0.8285For batch 92, tr_loss is    0.28.\n",
      " 94/232 [===========>..................] - ETA: 2:10 - loss: 0.2751 - iou_score: 0.7108 - f1-score: 0.8288For batch 93, tr_loss is    0.28.\n",
      " 95/232 [===========>..................] - ETA: 2:09 - loss: 0.2752 - iou_score: 0.7106 - f1-score: 0.8286For batch 94, tr_loss is    0.28.\n",
      " 96/232 [===========>..................] - ETA: 2:07 - loss: 0.2750 - iou_score: 0.7108 - f1-score: 0.8288For batch 95, tr_loss is    0.27.\n",
      " 97/232 [===========>..................] - ETA: 2:07 - loss: 0.2751 - iou_score: 0.7105 - f1-score: 0.8286For batch 96, tr_loss is    0.28.\n",
      " 98/232 [===========>..................] - ETA: 2:05 - loss: 0.2749 - iou_score: 0.7105 - f1-score: 0.8286For batch 97, tr_loss is    0.27.\n",
      " 99/232 [===========>..................] - ETA: 2:04 - loss: 0.2739 - iou_score: 0.7116 - f1-score: 0.8293For batch 98, tr_loss is    0.27.\n",
      "100/232 [===========>..................] - ETA: 2:03 - loss: 0.2733 - iou_score: 0.7122 - f1-score: 0.8298For batch 99, tr_loss is    0.27.\n",
      "101/232 [============>.................] - ETA: 2:02 - loss: 0.2728 - iou_score: 0.7129 - f1-score: 0.8302For batch 100, tr_loss is    0.27.\n",
      "102/232 [============>.................] - ETA: 2:01 - loss: 0.2727 - iou_score: 0.7130 - f1-score: 0.8303For batch 101, tr_loss is    0.27.\n",
      "103/232 [============>.................] - ETA: 2:00 - loss: 0.2729 - iou_score: 0.7132 - f1-score: 0.8304For batch 102, tr_loss is    0.27.\n",
      "104/232 [============>.................] - ETA: 1:59 - loss: 0.2727 - iou_score: 0.7133 - f1-score: 0.8305For batch 103, tr_loss is    0.27.\n",
      "105/232 [============>.................] - ETA: 1:58 - loss: 0.2719 - iou_score: 0.7143 - f1-score: 0.8311For batch 104, tr_loss is    0.27.\n",
      "106/232 [============>.................] - ETA: 1:57 - loss: 0.2711 - iou_score: 0.7152 - f1-score: 0.8318For batch 105, tr_loss is    0.27.\n",
      "107/232 [============>.................] - ETA: 1:56 - loss: 0.2716 - iou_score: 0.7149 - f1-score: 0.8315For batch 106, tr_loss is    0.27.\n",
      "108/232 [============>.................] - ETA: 1:55 - loss: 0.2722 - iou_score: 0.7140 - f1-score: 0.8309For batch 107, tr_loss is    0.27.\n",
      "109/232 [=============>................] - ETA: 1:54 - loss: 0.2716 - iou_score: 0.7145 - f1-score: 0.8312For batch 108, tr_loss is    0.27.\n",
      "110/232 [=============>................] - ETA: 1:53 - loss: 0.2707 - iou_score: 0.7156 - f1-score: 0.8320For batch 109, tr_loss is    0.27.\n",
      "111/232 [=============>................] - ETA: 1:52 - loss: 0.2709 - iou_score: 0.7152 - f1-score: 0.8317For batch 110, tr_loss is    0.27.\n",
      "112/232 [=============>................] - ETA: 1:51 - loss: 0.2710 - iou_score: 0.7151 - f1-score: 0.8317For batch 111, tr_loss is    0.27.\n",
      "113/232 [=============>................] - ETA: 1:50 - loss: 0.2714 - iou_score: 0.7148 - f1-score: 0.8315For batch 112, tr_loss is    0.27.\n",
      "114/232 [=============>................] - ETA: 1:49 - loss: 0.2707 - iou_score: 0.7155 - f1-score: 0.8320For batch 113, tr_loss is    0.27.\n",
      "115/232 [=============>................] - ETA: 1:48 - loss: 0.2704 - iou_score: 0.7158 - f1-score: 0.8321For batch 114, tr_loss is    0.27.\n",
      "116/232 [==============>...............] - ETA: 1:47 - loss: 0.2701 - iou_score: 0.7161 - f1-score: 0.8324For batch 115, tr_loss is    0.27.\n",
      "117/232 [==============>...............] - ETA: 1:46 - loss: 0.2699 - iou_score: 0.7161 - f1-score: 0.8324For batch 116, tr_loss is    0.27.\n",
      "118/232 [==============>...............] - ETA: 1:46 - loss: 0.2696 - iou_score: 0.7168 - f1-score: 0.8328For batch 117, tr_loss is    0.27.\n",
      "119/232 [==============>...............] - ETA: 1:44 - loss: 0.2692 - iou_score: 0.7172 - f1-score: 0.8331For batch 118, tr_loss is    0.27.\n",
      "120/232 [==============>...............] - ETA: 1:43 - loss: 0.2697 - iou_score: 0.7167 - f1-score: 0.8328For batch 119, tr_loss is    0.27.\n",
      "121/232 [==============>...............] - ETA: 1:42 - loss: 0.2691 - iou_score: 0.7174 - f1-score: 0.8332For batch 120, tr_loss is    0.27.\n",
      "122/232 [==============>...............] - ETA: 1:41 - loss: 0.2697 - iou_score: 0.7167 - f1-score: 0.8327For batch 121, tr_loss is    0.27.\n",
      "123/232 [==============>...............] - ETA: 1:40 - loss: 0.2692 - iou_score: 0.7170 - f1-score: 0.8329For batch 122, tr_loss is    0.27.\n",
      "124/232 [===============>..............] - ETA: 1:39 - loss: 0.2693 - iou_score: 0.7169 - f1-score: 0.8329For batch 123, tr_loss is    0.27.\n",
      "125/232 [===============>..............] - ETA: 1:39 - loss: 0.2695 - iou_score: 0.7163 - f1-score: 0.8325For batch 124, tr_loss is    0.27.\n",
      "126/232 [===============>..............] - ETA: 1:38 - loss: 0.2694 - iou_score: 0.7165 - f1-score: 0.8326For batch 125, tr_loss is    0.27.\n",
      "127/232 [===============>..............] - ETA: 1:37 - loss: 0.2690 - iou_score: 0.7167 - f1-score: 0.8328For batch 126, tr_loss is    0.27.\n",
      "128/232 [===============>..............] - ETA: 1:36 - loss: 0.2694 - iou_score: 0.7163 - f1-score: 0.8325For batch 127, tr_loss is    0.27.\n",
      "129/232 [===============>..............] - ETA: 1:35 - loss: 0.2694 - iou_score: 0.7163 - f1-score: 0.8325For batch 128, tr_loss is    0.27.\n",
      "130/232 [===============>..............] - ETA: 1:34 - loss: 0.2693 - iou_score: 0.7166 - f1-score: 0.8328For batch 129, tr_loss is    0.27.\n",
      "131/232 [===============>..............] - ETA: 1:32 - loss: 0.2703 - iou_score: 0.7158 - f1-score: 0.8322For batch 130, tr_loss is    0.27.\n",
      "132/232 [================>.............] - ETA: 1:31 - loss: 0.2708 - iou_score: 0.7155 - f1-score: 0.8319For batch 131, tr_loss is    0.27.\n",
      "133/232 [================>.............] - ETA: 1:30 - loss: 0.2704 - iou_score: 0.7157 - f1-score: 0.8321For batch 132, tr_loss is    0.27.\n",
      "134/232 [================>.............] - ETA: 1:29 - loss: 0.2710 - iou_score: 0.7148 - f1-score: 0.8315For batch 133, tr_loss is    0.27.\n",
      "135/232 [================>.............] - ETA: 1:28 - loss: 0.2707 - iou_score: 0.7151 - f1-score: 0.8317For batch 134, tr_loss is    0.27.\n",
      "136/232 [================>.............] - ETA: 1:27 - loss: 0.2711 - iou_score: 0.7145 - f1-score: 0.8312For batch 135, tr_loss is    0.27.\n",
      "137/232 [================>.............] - ETA: 1:26 - loss: 0.2712 - iou_score: 0.7143 - f1-score: 0.8311For batch 136, tr_loss is    0.27.\n",
      "138/232 [================>.............] - ETA: 1:25 - loss: 0.2713 - iou_score: 0.7141 - f1-score: 0.8310For batch 137, tr_loss is    0.27.\n",
      "139/232 [================>.............] - ETA: 1:24 - loss: 0.2713 - iou_score: 0.7140 - f1-score: 0.8309For batch 138, tr_loss is    0.27.\n",
      "140/232 [=================>............] - ETA: 1:23 - loss: 0.2712 - iou_score: 0.7141 - f1-score: 0.8310For batch 139, tr_loss is    0.27.\n",
      "141/232 [=================>............] - ETA: 1:23 - loss: 0.2718 - iou_score: 0.7133 - f1-score: 0.8304For batch 140, tr_loss is    0.27.\n",
      "142/232 [=================>............] - ETA: 1:22 - loss: 0.2718 - iou_score: 0.7132 - f1-score: 0.8304For batch 141, tr_loss is    0.27.\n",
      "143/232 [=================>............] - ETA: 1:21 - loss: 0.2716 - iou_score: 0.7134 - f1-score: 0.8305For batch 142, tr_loss is    0.27.\n",
      "144/232 [=================>............] - ETA: 1:20 - loss: 0.2715 - iou_score: 0.7135 - f1-score: 0.8306For batch 143, tr_loss is    0.27.\n",
      "145/232 [=================>............] - ETA: 1:19 - loss: 0.2714 - iou_score: 0.7135 - f1-score: 0.8306For batch 144, tr_loss is    0.27.\n",
      "146/232 [=================>............] - ETA: 1:18 - loss: 0.2716 - iou_score: 0.7133 - f1-score: 0.8305For batch 145, tr_loss is    0.27.\n",
      "147/232 [==================>...........] - ETA: 1:17 - loss: 0.2713 - iou_score: 0.7137 - f1-score: 0.8308For batch 146, tr_loss is    0.27.\n",
      "148/232 [==================>...........] - ETA: 1:16 - loss: 0.2717 - iou_score: 0.7132 - f1-score: 0.8304For batch 147, tr_loss is    0.27.\n",
      "149/232 [==================>...........] - ETA: 1:15 - loss: 0.2714 - iou_score: 0.7136 - f1-score: 0.8307For batch 148, tr_loss is    0.27.\n",
      "150/232 [==================>...........] - ETA: 1:15 - loss: 0.2720 - iou_score: 0.7128 - f1-score: 0.8301For batch 149, tr_loss is    0.27.\n",
      "151/232 [==================>...........] - ETA: 1:14 - loss: 0.2722 - iou_score: 0.7124 - f1-score: 0.8298For batch 150, tr_loss is    0.27.\n",
      "152/232 [==================>...........] - ETA: 1:13 - loss: 0.2718 - iou_score: 0.7128 - f1-score: 0.8301For batch 151, tr_loss is    0.27.\n",
      "153/232 [==================>...........] - ETA: 1:12 - loss: 0.2719 - iou_score: 0.7127 - f1-score: 0.8300For batch 152, tr_loss is    0.27.\n",
      "154/232 [==================>...........] - ETA: 1:11 - loss: 0.2716 - iou_score: 0.7129 - f1-score: 0.8302For batch 153, tr_loss is    0.27.\n",
      "155/232 [===================>..........] - ETA: 1:10 - loss: 0.2714 - iou_score: 0.7131 - f1-score: 0.8303For batch 154, tr_loss is    0.27.\n",
      "156/232 [===================>..........] - ETA: 1:09 - loss: 0.2714 - iou_score: 0.7130 - f1-score: 0.8302For batch 155, tr_loss is    0.27.\n",
      "157/232 [===================>..........] - ETA: 1:08 - loss: 0.2717 - iou_score: 0.7127 - f1-score: 0.8301For batch 156, tr_loss is    0.27.\n",
      "158/232 [===================>..........] - ETA: 1:07 - loss: 0.2713 - iou_score: 0.7131 - f1-score: 0.8303For batch 157, tr_loss is    0.27.\n",
      "159/232 [===================>..........] - ETA: 1:06 - loss: 0.2710 - iou_score: 0.7134 - f1-score: 0.8305For batch 158, tr_loss is    0.27.\n",
      "160/232 [===================>..........] - ETA: 1:05 - loss: 0.2709 - iou_score: 0.7133 - f1-score: 0.8305For batch 159, tr_loss is    0.27.\n",
      "161/232 [===================>..........] - ETA: 1:04 - loss: 0.2706 - iou_score: 0.7137 - f1-score: 0.8307For batch 160, tr_loss is    0.27.\n",
      "162/232 [===================>..........] - ETA: 1:03 - loss: 0.2706 - iou_score: 0.7136 - f1-score: 0.8307For batch 161, tr_loss is    0.27.\n",
      "163/232 [====================>.........] - ETA: 1:03 - loss: 0.2702 - iou_score: 0.7141 - f1-score: 0.8310For batch 162, tr_loss is    0.27.\n",
      "164/232 [====================>.........] - ETA: 1:02 - loss: 0.2703 - iou_score: 0.7139 - f1-score: 0.8309For batch 163, tr_loss is    0.27.\n",
      "165/232 [====================>.........] - ETA: 1:01 - loss: 0.2704 - iou_score: 0.7138 - f1-score: 0.8308For batch 164, tr_loss is    0.27.\n",
      "166/232 [====================>.........] - ETA: 1:00 - loss: 0.2701 - iou_score: 0.7140 - f1-score: 0.8309For batch 165, tr_loss is    0.27.\n",
      "167/232 [====================>.........] - ETA: 59s - loss: 0.2698 - iou_score: 0.7142 - f1-score: 0.8311 For batch 166, tr_loss is    0.27.\n",
      "168/232 [====================>.........] - ETA: 58s - loss: 0.2702 - iou_score: 0.7140 - f1-score: 0.8310For batch 167, tr_loss is    0.27.\n",
      "169/232 [====================>.........] - ETA: 57s - loss: 0.2707 - iou_score: 0.7135 - f1-score: 0.8306For batch 168, tr_loss is    0.27.\n",
      "170/232 [====================>.........] - ETA: 56s - loss: 0.2708 - iou_score: 0.7134 - f1-score: 0.8305For batch 169, tr_loss is    0.27.\n",
      "171/232 [=====================>........] - ETA: 55s - loss: 0.2713 - iou_score: 0.7128 - f1-score: 0.8302For batch 170, tr_loss is    0.27.\n",
      "172/232 [=====================>........] - ETA: 54s - loss: 0.2715 - iou_score: 0.7126 - f1-score: 0.8300For batch 171, tr_loss is    0.27.\n",
      "173/232 [=====================>........] - ETA: 53s - loss: 0.2712 - iou_score: 0.7129 - f1-score: 0.8302For batch 172, tr_loss is    0.27.\n",
      "174/232 [=====================>........] - ETA: 52s - loss: 0.2709 - iou_score: 0.7131 - f1-score: 0.8304For batch 173, tr_loss is    0.27.\n",
      "175/232 [=====================>........] - ETA: 51s - loss: 0.2709 - iou_score: 0.7130 - f1-score: 0.8303For batch 174, tr_loss is    0.27.\n",
      "176/232 [=====================>........] - ETA: 51s - loss: 0.2711 - iou_score: 0.7127 - f1-score: 0.8301For batch 175, tr_loss is    0.27.\n",
      "177/232 [=====================>........] - ETA: 50s - loss: 0.2708 - iou_score: 0.7132 - f1-score: 0.8305For batch 176, tr_loss is    0.27.\n",
      "178/232 [======================>.......] - ETA: 49s - loss: 0.2708 - iou_score: 0.7133 - f1-score: 0.8305For batch 177, tr_loss is    0.27.\n",
      "179/232 [======================>.......] - ETA: 48s - loss: 0.2707 - iou_score: 0.7134 - f1-score: 0.8306For batch 178, tr_loss is    0.27.\n",
      "180/232 [======================>.......] - ETA: 47s - loss: 0.2707 - iou_score: 0.7132 - f1-score: 0.8305For batch 179, tr_loss is    0.27.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181/232 [======================>.......] - ETA: 46s - loss: 0.2708 - iou_score: 0.7131 - f1-score: 0.8304For batch 180, tr_loss is    0.27.\n",
      "182/232 [======================>.......] - ETA: 45s - loss: 0.2707 - iou_score: 0.7131 - f1-score: 0.8304For batch 181, tr_loss is    0.27.\n",
      "183/232 [======================>.......] - ETA: 44s - loss: 0.2706 - iou_score: 0.7131 - f1-score: 0.8304For batch 182, tr_loss is    0.27.\n",
      "184/232 [======================>.......] - ETA: 43s - loss: 0.2703 - iou_score: 0.7136 - f1-score: 0.8308For batch 183, tr_loss is    0.27.\n",
      "185/232 [======================>.......] - ETA: 42s - loss: 0.2704 - iou_score: 0.7136 - f1-score: 0.8307For batch 184, tr_loss is    0.27.\n",
      "186/232 [=======================>......] - ETA: 41s - loss: 0.2703 - iou_score: 0.7136 - f1-score: 0.8307For batch 185, tr_loss is    0.27.\n",
      "187/232 [=======================>......] - ETA: 40s - loss: 0.2698 - iou_score: 0.7142 - f1-score: 0.8311For batch 186, tr_loss is    0.27.\n",
      "188/232 [=======================>......] - ETA: 39s - loss: 0.2699 - iou_score: 0.7141 - f1-score: 0.8311For batch 187, tr_loss is    0.27.\n",
      "189/232 [=======================>......] - ETA: 38s - loss: 0.2698 - iou_score: 0.7143 - f1-score: 0.8312For batch 188, tr_loss is    0.27.\n",
      "190/232 [=======================>......] - ETA: 37s - loss: 0.2696 - iou_score: 0.7144 - f1-score: 0.8313For batch 189, tr_loss is    0.27.\n",
      "191/232 [=======================>......] - ETA: 37s - loss: 0.2697 - iou_score: 0.7144 - f1-score: 0.8313For batch 190, tr_loss is    0.27.\n",
      "192/232 [=======================>......] - ETA: 36s - loss: 0.2699 - iou_score: 0.7141 - f1-score: 0.8311For batch 191, tr_loss is    0.27.\n",
      "193/232 [=======================>......] - ETA: 35s - loss: 0.2702 - iou_score: 0.7137 - f1-score: 0.8308For batch 192, tr_loss is    0.27.\n",
      "194/232 [========================>.....] - ETA: 34s - loss: 0.2702 - iou_score: 0.7135 - f1-score: 0.8307For batch 193, tr_loss is    0.27.\n",
      "195/232 [========================>.....] - ETA: 33s - loss: 0.2701 - iou_score: 0.7135 - f1-score: 0.8307For batch 194, tr_loss is    0.27.\n",
      "196/232 [========================>.....] - ETA: 32s - loss: 0.2699 - iou_score: 0.7136 - f1-score: 0.8308For batch 195, tr_loss is    0.27.\n",
      "197/232 [========================>.....] - ETA: 31s - loss: 0.2701 - iou_score: 0.7135 - f1-score: 0.8307For batch 196, tr_loss is    0.27.\n",
      "198/232 [========================>.....] - ETA: 30s - loss: 0.2698 - iou_score: 0.7139 - f1-score: 0.8310For batch 197, tr_loss is    0.27.\n",
      "199/232 [========================>.....] - ETA: 29s - loss: 0.2696 - iou_score: 0.7140 - f1-score: 0.8310For batch 198, tr_loss is    0.27.\n",
      "200/232 [========================>.....] - ETA: 28s - loss: 0.2693 - iou_score: 0.7144 - f1-score: 0.8313For batch 199, tr_loss is    0.27.\n",
      "201/232 [========================>.....] - ETA: 28s - loss: 0.2695 - iou_score: 0.7140 - f1-score: 0.8310For batch 200, tr_loss is    0.27.\n",
      "202/232 [=========================>....] - ETA: 27s - loss: 0.2695 - iou_score: 0.7139 - f1-score: 0.8309For batch 201, tr_loss is    0.27.\n",
      "203/232 [=========================>....] - ETA: 26s - loss: 0.2694 - iou_score: 0.7139 - f1-score: 0.8310For batch 202, tr_loss is    0.27.\n",
      "204/232 [=========================>....] - ETA: 25s - loss: 0.2690 - iou_score: 0.7144 - f1-score: 0.8313For batch 203, tr_loss is    0.27.\n",
      "205/232 [=========================>....] - ETA: 24s - loss: 0.2689 - iou_score: 0.7143 - f1-score: 0.8312For batch 204, tr_loss is    0.27.\n",
      "206/232 [=========================>....] - ETA: 23s - loss: 0.2691 - iou_score: 0.7142 - f1-score: 0.8311For batch 205, tr_loss is    0.27.\n",
      "207/232 [=========================>....] - ETA: 22s - loss: 0.2691 - iou_score: 0.7143 - f1-score: 0.8312For batch 206, tr_loss is    0.27.\n",
      "208/232 [=========================>....] - ETA: 21s - loss: 0.2689 - iou_score: 0.7144 - f1-score: 0.8313For batch 207, tr_loss is    0.27.\n",
      "209/232 [==========================>...] - ETA: 20s - loss: 0.2691 - iou_score: 0.7142 - f1-score: 0.8312For batch 208, tr_loss is    0.27.\n",
      "210/232 [==========================>...] - ETA: 19s - loss: 0.2694 - iou_score: 0.7139 - f1-score: 0.8309For batch 209, tr_loss is    0.27.\n",
      "211/232 [==========================>...] - ETA: 19s - loss: 0.2693 - iou_score: 0.7140 - f1-score: 0.8310For batch 210, tr_loss is    0.27.\n",
      "212/232 [==========================>...] - ETA: 18s - loss: 0.2690 - iou_score: 0.7144 - f1-score: 0.8313For batch 211, tr_loss is    0.27.\n",
      "213/232 [==========================>...] - ETA: 17s - loss: 0.2692 - iou_score: 0.7142 - f1-score: 0.8312For batch 212, tr_loss is    0.27.\n",
      "214/232 [==========================>...] - ETA: 16s - loss: 0.2692 - iou_score: 0.7143 - f1-score: 0.8312For batch 213, tr_loss is    0.27.\n",
      "215/232 [==========================>...] - ETA: 15s - loss: 0.2689 - iou_score: 0.7147 - f1-score: 0.8315For batch 214, tr_loss is    0.27.\n",
      "216/232 [==========================>...] - ETA: 14s - loss: 0.2687 - iou_score: 0.7148 - f1-score: 0.8316For batch 215, tr_loss is    0.27.\n",
      "217/232 [===========================>..] - ETA: 13s - loss: 0.2687 - iou_score: 0.7147 - f1-score: 0.8315For batch 216, tr_loss is    0.27.\n",
      "218/232 [===========================>..] - ETA: 12s - loss: 0.2687 - iou_score: 0.7146 - f1-score: 0.8314For batch 217, tr_loss is    0.27.\n",
      "219/232 [===========================>..] - ETA: 11s - loss: 0.2693 - iou_score: 0.7139 - f1-score: 0.8309For batch 218, tr_loss is    0.27.\n",
      "220/232 [===========================>..] - ETA: 10s - loss: 0.2693 - iou_score: 0.7138 - f1-score: 0.8309For batch 219, tr_loss is    0.27.\n",
      "221/232 [===========================>..] - ETA: 9s - loss: 0.2695 - iou_score: 0.7135 - f1-score: 0.8306 For batch 220, tr_loss is    0.27.\n",
      "222/232 [===========================>..] - ETA: 9s - loss: 0.2694 - iou_score: 0.7136 - f1-score: 0.8307For batch 221, tr_loss is    0.27.\n",
      "223/232 [===========================>..] - ETA: 8s - loss: 0.2695 - iou_score: 0.7134 - f1-score: 0.8306For batch 222, tr_loss is    0.27.\n",
      "224/232 [===========================>..] - ETA: 7s - loss: 0.2693 - iou_score: 0.7137 - f1-score: 0.8308For batch 223, tr_loss is    0.27.\n",
      "225/232 [============================>.] - ETA: 6s - loss: 0.2691 - iou_score: 0.7140 - f1-score: 0.8310For batch 224, tr_loss is    0.27.\n",
      "226/232 [============================>.] - ETA: 5s - loss: 0.2692 - iou_score: 0.7139 - f1-score: 0.8309For batch 225, tr_loss is    0.27.\n",
      "227/232 [============================>.] - ETA: 4s - loss: 0.2692 - iou_score: 0.7140 - f1-score: 0.8310For batch 226, tr_loss is    0.27.\n",
      "228/232 [============================>.] - ETA: 3s - loss: 0.2692 - iou_score: 0.7138 - f1-score: 0.8309For batch 227, tr_loss is    0.27.\n",
      "229/232 [============================>.] - ETA: 2s - loss: 0.2690 - iou_score: 0.7141 - f1-score: 0.8310For batch 228, tr_loss is    0.27.\n",
      "230/232 [============================>.] - ETA: 1s - loss: 0.2693 - iou_score: 0.7137 - f1-score: 0.8308For batch 229, tr_loss is    0.27.\n",
      "231/232 [============================>.] - ETA: 0s - loss: 0.2696 - iou_score: 0.7134 - f1-score: 0.8306For batch 230, tr_loss is    0.27.\n",
      "232/232 [==============================] - ETA: 0s - loss: 0.2693 - iou_score: 0.7138 - f1-score: 0.8308For batch 231, tr_loss is    0.27.\n",
      "For batch 0, vl_loss is    0.47.\n",
      "For batch 1, vl_loss is    0.49.\n",
      "For batch 2, vl_loss is    0.52.\n",
      "For batch 3, vl_loss is    0.55.\n",
      "For batch 4, vl_loss is    0.58.\n",
      "For batch 5, vl_loss is    0.55.\n",
      "For batch 6, vl_loss is    0.56.\n",
      "For batch 7, vl_loss is    0.55.\n",
      "For batch 8, vl_loss is    0.53.\n",
      "For batch 9, vl_loss is    0.51.\n",
      "For batch 10, vl_loss is    0.51.\n",
      "For batch 11, vl_loss is    0.52.\n",
      "For batch 12, vl_loss is    0.53.\n",
      "For batch 13, vl_loss is    0.54.\n",
      "For batch 14, vl_loss is    0.53.\n",
      "For batch 15, vl_loss is    0.53.\n",
      "For batch 16, vl_loss is    0.52.\n",
      "For batch 17, vl_loss is    0.52.\n",
      "For batch 18, vl_loss is    0.52.\n",
      "For batch 19, vl_loss is    0.51.\n",
      "For batch 20, vl_loss is    0.50.\n",
      "For batch 21, vl_loss is    0.50.\n",
      "For batch 22, vl_loss is    0.50.\n",
      "For batch 23, vl_loss is    0.50.\n",
      "For batch 24, vl_loss is    0.50.\n",
      "For batch 25, vl_loss is    0.50.\n",
      "For batch 26, vl_loss is    0.50.\n",
      "For batch 27, vl_loss is    0.50.\n",
      "For batch 28, vl_loss is    0.51.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 29, vl_loss is    0.51.\n",
      "For batch 30, vl_loss is    0.51.\n",
      "For batch 31, vl_loss is    0.51.\n",
      "For batch 32, vl_loss is    0.51.\n",
      "For batch 33, vl_loss is    0.51.\n",
      "For batch 34, vl_loss is    0.50.\n",
      "For batch 35, vl_loss is    0.51.\n",
      "For batch 36, vl_loss is    0.50.\n",
      "For batch 37, vl_loss is    0.51.\n",
      "For batch 38, vl_loss is    0.51.\n",
      "For batch 39, vl_loss is    0.51.\n",
      "For batch 40, vl_loss is    0.51.\n",
      "For batch 41, vl_loss is    0.52.\n",
      "For batch 42, vl_loss is    0.52.\n",
      "For batch 43, vl_loss is    0.53.\n",
      "For batch 44, vl_loss is    0.52.\n",
      "For batch 45, vl_loss is    0.53.\n",
      "For batch 46, vl_loss is    0.52.\n",
      "For batch 47, vl_loss is    0.52.\n",
      "For batch 48, vl_loss is    0.53.\n",
      "For batch 49, vl_loss is    0.52.\n",
      "For batch 50, vl_loss is    0.52.\n",
      "For batch 51, vl_loss is    0.52.\n",
      "For batch 52, vl_loss is    0.53.\n",
      "For batch 53, vl_loss is    0.53.\n",
      "For batch 54, vl_loss is    0.53.\n",
      "For batch 55, vl_loss is    0.53.\n",
      "For batch 56, vl_loss is    0.53.\n",
      "For batch 57, vl_loss is    0.53.\n",
      "For batch 58, vl_loss is    0.53.\n",
      "For batch 59, vl_loss is    0.53.\n",
      "For batch 60, vl_loss is    0.53.\n",
      "For batch 61, vl_loss is    0.52.\n",
      "For batch 62, vl_loss is    0.52.\n",
      "For batch 63, vl_loss is    0.52.\n",
      "For batch 64, vl_loss is    0.52.\n",
      "For batch 65, vl_loss is    0.52.\n",
      "For batch 66, vl_loss is    0.52.\n",
      "For batch 67, vl_loss is    0.52.\n",
      "232/232 [==============================] - 212s 907ms/step - loss: 0.2693 - iou_score: 0.7138 - f1-score: 0.8308 - val_loss: 0.5165 - val_iou_score: 0.6391 - val_f1-score: 0.7773\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.40105\n",
      "The average loss for epoch 7 is    0.27 \n",
      "Epoch 9/200\n",
      "  1/232 [..............................] - ETA: 9:55 - loss: 0.2091 - iou_score: 0.7841 - f1-score: 0.8775For batch 0, tr_loss is    0.21.\n",
      "  2/232 [..............................] - ETA: 4:41 - loss: 0.2277 - iou_score: 0.7620 - f1-score: 0.8640For batch 1, tr_loss is    0.23.\n",
      "  3/232 [..............................] - ETA: 4:36 - loss: 0.2467 - iou_score: 0.7410 - f1-score: 0.8502For batch 2, tr_loss is    0.25.\n",
      "  4/232 [..............................] - ETA: 4:41 - loss: 0.2458 - iou_score: 0.7470 - f1-score: 0.8542For batch 3, tr_loss is    0.25.\n",
      "  5/232 [..............................] - ETA: 4:45 - loss: 0.2522 - iou_score: 0.7398 - f1-score: 0.8492For batch 4, tr_loss is    0.25.\n",
      "  6/232 [..............................] - ETA: 4:50 - loss: 0.2588 - iou_score: 0.7304 - f1-score: 0.8423For batch 5, tr_loss is    0.26.\n",
      "  7/232 [..............................] - ETA: 5:00 - loss: 0.2671 - iou_score: 0.7196 - f1-score: 0.8350For batch 6, tr_loss is    0.27.\n",
      "  8/232 [>.............................] - ETA: 4:53 - loss: 0.2706 - iou_score: 0.7126 - f1-score: 0.8303For batch 7, tr_loss is    0.27.\n",
      "  9/232 [>.............................] - ETA: 4:44 - loss: 0.2627 - iou_score: 0.7212 - f1-score: 0.8360For batch 8, tr_loss is    0.26.\n",
      " 10/232 [>.............................] - ETA: 4:25 - loss: 0.2625 - iou_score: 0.7208 - f1-score: 0.8358For batch 9, tr_loss is    0.26.\n",
      " 11/232 [>.............................] - ETA: 4:15 - loss: 0.2598 - iou_score: 0.7232 - f1-score: 0.8375For batch 10, tr_loss is    0.26.\n",
      " 12/232 [>.............................] - ETA: 4:02 - loss: 0.2561 - iou_score: 0.7289 - f1-score: 0.8413For batch 11, tr_loss is    0.26.\n",
      " 13/232 [>.............................] - ETA: 4:03 - loss: 0.2544 - iou_score: 0.7301 - f1-score: 0.8422For batch 12, tr_loss is    0.25.\n",
      " 14/232 [>.............................] - ETA: 4:00 - loss: 0.2515 - iou_score: 0.7325 - f1-score: 0.8439For batch 13, tr_loss is    0.25.\n",
      " 15/232 [>.............................] - ETA: 3:58 - loss: 0.2497 - iou_score: 0.7337 - f1-score: 0.8448For batch 14, tr_loss is    0.25.\n",
      " 16/232 [=>............................] - ETA: 3:55 - loss: 0.2472 - iou_score: 0.7356 - f1-score: 0.8460For batch 15, tr_loss is    0.25.\n",
      " 17/232 [=>............................] - ETA: 3:46 - loss: 0.2452 - iou_score: 0.7372 - f1-score: 0.8472For batch 16, tr_loss is    0.25.\n",
      " 18/232 [=>............................] - ETA: 3:40 - loss: 0.2458 - iou_score: 0.7365 - f1-score: 0.8468For batch 17, tr_loss is    0.25.\n",
      " 19/232 [=>............................] - ETA: 3:38 - loss: 0.2475 - iou_score: 0.7336 - f1-score: 0.8449For batch 18, tr_loss is    0.25.\n",
      " 20/232 [=>............................] - ETA: 3:32 - loss: 0.2455 - iou_score: 0.7349 - f1-score: 0.8458For batch 19, tr_loss is    0.25.\n",
      " 21/232 [=>............................] - ETA: 3:29 - loss: 0.2496 - iou_score: 0.7329 - f1-score: 0.8443For batch 20, tr_loss is    0.25.\n",
      " 22/232 [=>............................] - ETA: 3:24 - loss: 0.2535 - iou_score: 0.7291 - f1-score: 0.8415For batch 21, tr_loss is    0.25.\n",
      " 23/232 [=>............................] - ETA: 3:24 - loss: 0.2536 - iou_score: 0.7283 - f1-score: 0.8410For batch 22, tr_loss is    0.25.\n",
      " 24/232 [==>...........................] - ETA: 3:18 - loss: 0.2522 - iou_score: 0.7291 - f1-score: 0.8417For batch 23, tr_loss is    0.25.\n",
      " 25/232 [==>...........................] - ETA: 3:15 - loss: 0.2562 - iou_score: 0.7251 - f1-score: 0.8389For batch 24, tr_loss is    0.26.\n",
      " 26/232 [==>...........................] - ETA: 3:15 - loss: 0.2564 - iou_score: 0.7248 - f1-score: 0.8387For batch 25, tr_loss is    0.26.\n",
      " 27/232 [==>...........................] - ETA: 3:14 - loss: 0.2545 - iou_score: 0.7272 - f1-score: 0.8403For batch 26, tr_loss is    0.25.\n",
      " 28/232 [==>...........................] - ETA: 3:14 - loss: 0.2549 - iou_score: 0.7272 - f1-score: 0.8403For batch 27, tr_loss is    0.25.\n",
      " 29/232 [==>...........................] - ETA: 3:13 - loss: 0.2549 - iou_score: 0.7258 - f1-score: 0.8392For batch 28, tr_loss is    0.25.\n",
      " 30/232 [==>...........................] - ETA: 3:12 - loss: 0.2536 - iou_score: 0.7272 - f1-score: 0.8402For batch 29, tr_loss is    0.25.\n",
      " 31/232 [===>..........................] - ETA: 3:12 - loss: 0.2532 - iou_score: 0.7275 - f1-score: 0.8405For batch 30, tr_loss is    0.25.\n",
      " 32/232 [===>..........................] - ETA: 3:11 - loss: 0.2528 - iou_score: 0.7281 - f1-score: 0.8409For batch 31, tr_loss is    0.25.\n",
      " 33/232 [===>..........................] - ETA: 3:10 - loss: 0.2558 - iou_score: 0.7256 - f1-score: 0.8392For batch 32, tr_loss is    0.26.\n",
      " 34/232 [===>..........................] - ETA: 3:09 - loss: 0.2559 - iou_score: 0.7254 - f1-score: 0.8391For batch 33, tr_loss is    0.26.\n",
      " 35/232 [===>..........................] - ETA: 3:06 - loss: 0.2573 - iou_score: 0.7236 - f1-score: 0.8379For batch 34, tr_loss is    0.26.\n",
      " 36/232 [===>..........................] - ETA: 3:03 - loss: 0.2579 - iou_score: 0.7242 - f1-score: 0.8383For batch 35, tr_loss is    0.26.\n",
      " 37/232 [===>..........................] - ETA: 3:05 - loss: 0.2580 - iou_score: 0.7236 - f1-score: 0.8380For batch 36, tr_loss is    0.26.\n",
      " 38/232 [===>..........................] - ETA: 3:03 - loss: 0.2591 - iou_score: 0.7222 - f1-score: 0.8371For batch 37, tr_loss is    0.26.\n",
      " 39/232 [====>.........................] - ETA: 3:00 - loss: 0.2640 - iou_score: 0.7181 - f1-score: 0.8340For batch 38, tr_loss is    0.26.\n",
      " 40/232 [====>.........................] - ETA: 2:58 - loss: 0.2660 - iou_score: 0.7169 - f1-score: 0.8331For batch 39, tr_loss is    0.27.\n",
      " 41/232 [====>.........................] - ETA: 2:56 - loss: 0.2669 - iou_score: 0.7155 - f1-score: 0.8322For batch 40, tr_loss is    0.27.\n",
      " 42/232 [====>.........................] - ETA: 2:56 - loss: 0.2670 - iou_score: 0.7149 - f1-score: 0.8318For batch 41, tr_loss is    0.27.\n",
      " 43/232 [====>.........................] - ETA: 2:55 - loss: 0.2663 - iou_score: 0.7159 - f1-score: 0.8325For batch 42, tr_loss is    0.27.\n",
      " 44/232 [====>.........................] - ETA: 2:55 - loss: 0.2687 - iou_score: 0.7136 - f1-score: 0.8307For batch 43, tr_loss is    0.27.\n",
      " 45/232 [====>.........................] - ETA: 2:54 - loss: 0.2698 - iou_score: 0.7126 - f1-score: 0.8300For batch 44, tr_loss is    0.27.\n",
      " 46/232 [====>.........................] - ETA: 2:53 - loss: 0.2698 - iou_score: 0.7129 - f1-score: 0.8303For batch 45, tr_loss is    0.27.\n",
      " 47/232 [=====>........................] - ETA: 2:52 - loss: 0.2693 - iou_score: 0.7136 - f1-score: 0.8308For batch 46, tr_loss is    0.27.\n",
      " 48/232 [=====>........................] - ETA: 2:51 - loss: 0.2683 - iou_score: 0.7148 - f1-score: 0.8316For batch 47, tr_loss is    0.27.\n",
      " 49/232 [=====>........................] - ETA: 2:48 - loss: 0.2687 - iou_score: 0.7147 - f1-score: 0.8316For batch 48, tr_loss is    0.27.\n",
      " 50/232 [=====>........................] - ETA: 2:48 - loss: 0.2686 - iou_score: 0.7150 - f1-score: 0.8318For batch 49, tr_loss is    0.27.\n",
      " 51/232 [=====>........................] - ETA: 2:47 - loss: 0.2699 - iou_score: 0.7138 - f1-score: 0.8309For batch 50, tr_loss is    0.27.\n",
      " 52/232 [=====>........................] - ETA: 2:47 - loss: 0.2716 - iou_score: 0.7122 - f1-score: 0.8298For batch 51, tr_loss is    0.27.\n",
      " 53/232 [=====>........................] - ETA: 2:46 - loss: 0.2705 - iou_score: 0.7136 - f1-score: 0.8307For batch 52, tr_loss is    0.27.\n",
      " 54/232 [=====>........................] - ETA: 2:46 - loss: 0.2706 - iou_score: 0.7132 - f1-score: 0.8305For batch 53, tr_loss is    0.27.\n",
      " 55/232 [======>.......................] - ETA: 2:44 - loss: 0.2703 - iou_score: 0.7132 - f1-score: 0.8306For batch 54, tr_loss is    0.27.\n",
      " 56/232 [======>.......................] - ETA: 2:42 - loss: 0.2701 - iou_score: 0.7134 - f1-score: 0.8307For batch 55, tr_loss is    0.27.\n",
      " 57/232 [======>.......................] - ETA: 2:42 - loss: 0.2706 - iou_score: 0.7127 - f1-score: 0.8302For batch 56, tr_loss is    0.27.\n",
      " 58/232 [======>.......................] - ETA: 2:41 - loss: 0.2698 - iou_score: 0.7139 - f1-score: 0.8311For batch 57, tr_loss is    0.27.\n",
      " 59/232 [======>.......................] - ETA: 2:41 - loss: 0.2695 - iou_score: 0.7142 - f1-score: 0.8313For batch 58, tr_loss is    0.27.\n",
      " 60/232 [======>.......................] - ETA: 2:40 - loss: 0.2712 - iou_score: 0.7126 - f1-score: 0.8301For batch 59, tr_loss is    0.27.\n",
      " 61/232 [======>.......................] - ETA: 2:39 - loss: 0.2728 - iou_score: 0.7110 - f1-score: 0.8289For batch 60, tr_loss is    0.27.\n",
      " 62/232 [=======>......................] - ETA: 2:39 - loss: 0.2735 - iou_score: 0.7103 - f1-score: 0.8283For batch 61, tr_loss is    0.27.\n",
      " 63/232 [=======>......................] - ETA: 2:37 - loss: 0.2727 - iou_score: 0.7114 - f1-score: 0.8291For batch 62, tr_loss is    0.27.\n",
      " 64/232 [=======>......................] - ETA: 2:37 - loss: 0.2727 - iou_score: 0.7114 - f1-score: 0.8291For batch 63, tr_loss is    0.27.\n",
      " 65/232 [=======>......................] - ETA: 2:35 - loss: 0.2726 - iou_score: 0.7116 - f1-score: 0.8293For batch 64, tr_loss is    0.27.\n",
      " 66/232 [=======>......................] - ETA: 2:34 - loss: 0.2726 - iou_score: 0.7114 - f1-score: 0.8291For batch 65, tr_loss is    0.27.\n",
      " 67/232 [=======>......................] - ETA: 2:34 - loss: 0.2719 - iou_score: 0.7122 - f1-score: 0.8297For batch 66, tr_loss is    0.27.\n",
      " 68/232 [=======>......................] - ETA: 2:32 - loss: 0.2717 - iou_score: 0.7126 - f1-score: 0.8300For batch 67, tr_loss is    0.27.\n",
      " 69/232 [=======>......................] - ETA: 2:30 - loss: 0.2716 - iou_score: 0.7127 - f1-score: 0.8301For batch 68, tr_loss is    0.27.\n",
      " 70/232 [========>.....................] - ETA: 2:29 - loss: 0.2713 - iou_score: 0.7128 - f1-score: 0.8302For batch 69, tr_loss is    0.27.\n",
      " 71/232 [========>.....................] - ETA: 2:28 - loss: 0.2705 - iou_score: 0.7139 - f1-score: 0.8309For batch 70, tr_loss is    0.27.\n",
      " 72/232 [========>.....................] - ETA: 2:28 - loss: 0.2699 - iou_score: 0.7143 - f1-score: 0.8312For batch 71, tr_loss is    0.27.\n",
      " 73/232 [========>.....................] - ETA: 2:27 - loss: 0.2701 - iou_score: 0.7139 - f1-score: 0.8309For batch 72, tr_loss is    0.27.\n",
      " 74/232 [========>.....................] - ETA: 2:26 - loss: 0.2692 - iou_score: 0.7148 - f1-score: 0.8316For batch 73, tr_loss is    0.27.\n",
      " 75/232 [========>.....................] - ETA: 2:24 - loss: 0.2693 - iou_score: 0.7147 - f1-score: 0.8315For batch 74, tr_loss is    0.27.\n",
      " 76/232 [========>.....................] - ETA: 2:23 - loss: 0.2687 - iou_score: 0.7152 - f1-score: 0.8318For batch 75, tr_loss is    0.27.\n",
      " 77/232 [========>.....................] - ETA: 2:23 - loss: 0.2677 - iou_score: 0.7161 - f1-score: 0.8325For batch 76, tr_loss is    0.27.\n",
      " 78/232 [=========>....................] - ETA: 2:22 - loss: 0.2683 - iou_score: 0.7155 - f1-score: 0.8320For batch 77, tr_loss is    0.27.\n",
      " 79/232 [=========>....................] - ETA: 2:21 - loss: 0.2677 - iou_score: 0.7160 - f1-score: 0.8324For batch 78, tr_loss is    0.27.\n",
      " 80/232 [=========>....................] - ETA: 2:20 - loss: 0.2675 - iou_score: 0.7161 - f1-score: 0.8325For batch 79, tr_loss is    0.27.\n",
      " 81/232 [=========>....................] - ETA: 2:18 - loss: 0.2677 - iou_score: 0.7157 - f1-score: 0.8322For batch 80, tr_loss is    0.27.\n",
      " 82/232 [=========>....................] - ETA: 2:18 - loss: 0.2678 - iou_score: 0.7155 - f1-score: 0.8321For batch 81, tr_loss is    0.27.\n",
      " 83/232 [=========>....................] - ETA: 2:17 - loss: 0.2683 - iou_score: 0.7147 - f1-score: 0.8315For batch 82, tr_loss is    0.27.\n",
      " 84/232 [=========>....................] - ETA: 2:16 - loss: 0.2690 - iou_score: 0.7141 - f1-score: 0.8311For batch 83, tr_loss is    0.27.\n",
      " 85/232 [=========>....................] - ETA: 2:15 - loss: 0.2693 - iou_score: 0.7138 - f1-score: 0.8310For batch 84, tr_loss is    0.27.\n",
      " 86/232 [==========>...................] - ETA: 2:14 - loss: 0.2696 - iou_score: 0.7133 - f1-score: 0.8306For batch 85, tr_loss is    0.27.\n",
      " 87/232 [==========>...................] - ETA: 2:13 - loss: 0.2695 - iou_score: 0.7135 - f1-score: 0.8308For batch 86, tr_loss is    0.27.\n",
      " 88/232 [==========>...................] - ETA: 2:13 - loss: 0.2699 - iou_score: 0.7130 - f1-score: 0.8304For batch 87, tr_loss is    0.27.\n",
      " 89/232 [==========>...................] - ETA: 2:12 - loss: 0.2695 - iou_score: 0.7133 - f1-score: 0.8307For batch 88, tr_loss is    0.27.\n",
      " 90/232 [==========>...................] - ETA: 2:11 - loss: 0.2691 - iou_score: 0.7139 - f1-score: 0.8311For batch 89, tr_loss is    0.27.\n",
      " 91/232 [==========>...................] - ETA: 2:10 - loss: 0.2689 - iou_score: 0.7139 - f1-score: 0.8310For batch 90, tr_loss is    0.27.\n",
      " 92/232 [==========>...................] - ETA: 2:08 - loss: 0.2689 - iou_score: 0.7140 - f1-score: 0.8312For batch 91, tr_loss is    0.27.\n",
      " 93/232 [===========>..................] - ETA: 2:08 - loss: 0.2697 - iou_score: 0.7128 - f1-score: 0.8302For batch 92, tr_loss is    0.27.\n",
      " 94/232 [===========>..................] - ETA: 2:07 - loss: 0.2691 - iou_score: 0.7134 - f1-score: 0.8307For batch 93, tr_loss is    0.27.\n",
      " 95/232 [===========>..................] - ETA: 2:06 - loss: 0.2693 - iou_score: 0.7130 - f1-score: 0.8304For batch 94, tr_loss is    0.27.\n",
      " 96/232 [===========>..................] - ETA: 2:05 - loss: 0.2691 - iou_score: 0.7131 - f1-score: 0.8305For batch 95, tr_loss is    0.27.\n",
      " 97/232 [===========>..................] - ETA: 2:04 - loss: 0.2694 - iou_score: 0.7128 - f1-score: 0.8303For batch 96, tr_loss is    0.27.\n",
      " 98/232 [===========>..................] - ETA: 2:03 - loss: 0.2693 - iou_score: 0.7127 - f1-score: 0.8302For batch 97, tr_loss is    0.27.\n",
      " 99/232 [===========>..................] - ETA: 2:02 - loss: 0.2685 - iou_score: 0.7137 - f1-score: 0.8309For batch 98, tr_loss is    0.27.\n",
      "100/232 [===========>..................] - ETA: 2:01 - loss: 0.2680 - iou_score: 0.7144 - f1-score: 0.8313For batch 99, tr_loss is    0.27.\n",
      "101/232 [============>.................] - ETA: 1:59 - loss: 0.2674 - iou_score: 0.7151 - f1-score: 0.8318For batch 100, tr_loss is    0.27.\n",
      "102/232 [============>.................] - ETA: 1:59 - loss: 0.2674 - iou_score: 0.7151 - f1-score: 0.8318For batch 101, tr_loss is    0.27.\n",
      "103/232 [============>.................] - ETA: 1:57 - loss: 0.2674 - iou_score: 0.7153 - f1-score: 0.8319For batch 102, tr_loss is    0.27.\n",
      "104/232 [============>.................] - ETA: 1:56 - loss: 0.2672 - iou_score: 0.7155 - f1-score: 0.8321For batch 103, tr_loss is    0.27.\n",
      "105/232 [============>.................] - ETA: 1:55 - loss: 0.2665 - iou_score: 0.7162 - f1-score: 0.8326For batch 104, tr_loss is    0.27.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/232 [============>.................] - ETA: 1:54 - loss: 0.2659 - iou_score: 0.7171 - f1-score: 0.8331For batch 105, tr_loss is    0.27.\n",
      "107/232 [============>.................] - ETA: 1:53 - loss: 0.2664 - iou_score: 0.7168 - f1-score: 0.8330For batch 106, tr_loss is    0.27.\n",
      "108/232 [============>.................] - ETA: 1:53 - loss: 0.2669 - iou_score: 0.7161 - f1-score: 0.8325For batch 107, tr_loss is    0.27.\n",
      "109/232 [=============>................] - ETA: 1:52 - loss: 0.2665 - iou_score: 0.7165 - f1-score: 0.8328For batch 108, tr_loss is    0.27.\n",
      "110/232 [=============>................] - ETA: 1:51 - loss: 0.2658 - iou_score: 0.7175 - f1-score: 0.8334For batch 109, tr_loss is    0.27.\n",
      "111/232 [=============>................] - ETA: 1:50 - loss: 0.2661 - iou_score: 0.7171 - f1-score: 0.8331For batch 110, tr_loss is    0.27.\n",
      "112/232 [=============>................] - ETA: 1:49 - loss: 0.2663 - iou_score: 0.7167 - f1-score: 0.8329For batch 111, tr_loss is    0.27.\n",
      "113/232 [=============>................] - ETA: 1:48 - loss: 0.2669 - iou_score: 0.7165 - f1-score: 0.8327For batch 112, tr_loss is    0.27.\n",
      "114/232 [=============>................] - ETA: 1:47 - loss: 0.2662 - iou_score: 0.7173 - f1-score: 0.8333For batch 113, tr_loss is    0.27.\n",
      "115/232 [=============>................] - ETA: 1:46 - loss: 0.2659 - iou_score: 0.7176 - f1-score: 0.8335For batch 114, tr_loss is    0.27.\n",
      "116/232 [==============>...............] - ETA: 1:45 - loss: 0.2656 - iou_score: 0.7181 - f1-score: 0.8338For batch 115, tr_loss is    0.27.\n",
      "117/232 [==============>...............] - ETA: 1:44 - loss: 0.2655 - iou_score: 0.7182 - f1-score: 0.8339For batch 116, tr_loss is    0.27.\n",
      "118/232 [==============>...............] - ETA: 1:43 - loss: 0.2651 - iou_score: 0.7188 - f1-score: 0.8343For batch 117, tr_loss is    0.27.\n",
      "119/232 [==============>...............] - ETA: 1:42 - loss: 0.2647 - iou_score: 0.7191 - f1-score: 0.8345For batch 118, tr_loss is    0.26.\n",
      "120/232 [==============>...............] - ETA: 1:41 - loss: 0.2650 - iou_score: 0.7187 - f1-score: 0.8343For batch 119, tr_loss is    0.27.\n",
      "121/232 [==============>...............] - ETA: 1:41 - loss: 0.2644 - iou_score: 0.7195 - f1-score: 0.8348For batch 120, tr_loss is    0.26.\n",
      "122/232 [==============>...............] - ETA: 1:40 - loss: 0.2648 - iou_score: 0.7189 - f1-score: 0.8344For batch 121, tr_loss is    0.26.\n",
      "123/232 [==============>...............] - ETA: 1:39 - loss: 0.2644 - iou_score: 0.7191 - f1-score: 0.8345For batch 122, tr_loss is    0.26.\n",
      "124/232 [===============>..............] - ETA: 1:38 - loss: 0.2645 - iou_score: 0.7191 - f1-score: 0.8345For batch 123, tr_loss is    0.26.\n",
      "125/232 [===============>..............] - ETA: 1:37 - loss: 0.2649 - iou_score: 0.7185 - f1-score: 0.8342For batch 124, tr_loss is    0.26.\n",
      "126/232 [===============>..............] - ETA: 1:36 - loss: 0.2648 - iou_score: 0.7188 - f1-score: 0.8343For batch 125, tr_loss is    0.26.\n",
      "127/232 [===============>..............] - ETA: 1:35 - loss: 0.2646 - iou_score: 0.7188 - f1-score: 0.8343For batch 126, tr_loss is    0.26.\n",
      "128/232 [===============>..............] - ETA: 1:34 - loss: 0.2650 - iou_score: 0.7181 - f1-score: 0.8339For batch 127, tr_loss is    0.26.\n",
      "129/232 [===============>..............] - ETA: 1:33 - loss: 0.2649 - iou_score: 0.7180 - f1-score: 0.8338For batch 128, tr_loss is    0.26.\n",
      "130/232 [===============>..............] - ETA: 1:32 - loss: 0.2646 - iou_score: 0.7185 - f1-score: 0.8341For batch 129, tr_loss is    0.26.\n",
      "131/232 [===============>..............] - ETA: 1:31 - loss: 0.2650 - iou_score: 0.7180 - f1-score: 0.8338For batch 130, tr_loss is    0.27.\n",
      "132/232 [================>.............] - ETA: 1:30 - loss: 0.2654 - iou_score: 0.7177 - f1-score: 0.8336For batch 131, tr_loss is    0.27.\n",
      "133/232 [================>.............] - ETA: 1:29 - loss: 0.2650 - iou_score: 0.7180 - f1-score: 0.8338For batch 132, tr_loss is    0.27.\n",
      "134/232 [================>.............] - ETA: 1:28 - loss: 0.2653 - iou_score: 0.7175 - f1-score: 0.8334For batch 133, tr_loss is    0.27.\n",
      "135/232 [================>.............] - ETA: 1:27 - loss: 0.2651 - iou_score: 0.7178 - f1-score: 0.8337For batch 134, tr_loss is    0.27.\n",
      "136/232 [================>.............] - ETA: 1:26 - loss: 0.2653 - iou_score: 0.7174 - f1-score: 0.8334For batch 135, tr_loss is    0.27.\n",
      "137/232 [================>.............] - ETA: 1:25 - loss: 0.2654 - iou_score: 0.7173 - f1-score: 0.8333For batch 136, tr_loss is    0.27.\n",
      "138/232 [================>.............] - ETA: 1:24 - loss: 0.2656 - iou_score: 0.7170 - f1-score: 0.8332For batch 137, tr_loss is    0.27.\n",
      "139/232 [================>.............] - ETA: 1:23 - loss: 0.2654 - iou_score: 0.7172 - f1-score: 0.8333For batch 138, tr_loss is    0.27.\n",
      "140/232 [=================>............] - ETA: 1:22 - loss: 0.2652 - iou_score: 0.7175 - f1-score: 0.8335For batch 139, tr_loss is    0.27.\n",
      "141/232 [=================>............] - ETA: 1:22 - loss: 0.2657 - iou_score: 0.7167 - f1-score: 0.8329For batch 140, tr_loss is    0.27.\n",
      "142/232 [=================>............] - ETA: 1:21 - loss: 0.2656 - iou_score: 0.7166 - f1-score: 0.8329For batch 141, tr_loss is    0.27.\n",
      "143/232 [=================>............] - ETA: 1:20 - loss: 0.2654 - iou_score: 0.7169 - f1-score: 0.8330For batch 142, tr_loss is    0.27.\n",
      "144/232 [=================>............] - ETA: 1:19 - loss: 0.2654 - iou_score: 0.7167 - f1-score: 0.8330For batch 143, tr_loss is    0.27.\n",
      "145/232 [=================>............] - ETA: 1:18 - loss: 0.2652 - iou_score: 0.7169 - f1-score: 0.8331For batch 144, tr_loss is    0.27.\n",
      "146/232 [=================>............] - ETA: 1:17 - loss: 0.2653 - iou_score: 0.7167 - f1-score: 0.8330For batch 145, tr_loss is    0.27.\n",
      "147/232 [==================>...........] - ETA: 1:16 - loss: 0.2650 - iou_score: 0.7171 - f1-score: 0.8332For batch 146, tr_loss is    0.26.\n",
      "148/232 [==================>...........] - ETA: 1:15 - loss: 0.2655 - iou_score: 0.7165 - f1-score: 0.8328For batch 147, tr_loss is    0.27.\n",
      "149/232 [==================>...........] - ETA: 1:14 - loss: 0.2652 - iou_score: 0.7169 - f1-score: 0.8331For batch 148, tr_loss is    0.27.\n",
      "150/232 [==================>...........] - ETA: 1:14 - loss: 0.2659 - iou_score: 0.7161 - f1-score: 0.8325For batch 149, tr_loss is    0.27.\n",
      "151/232 [==================>...........] - ETA: 1:13 - loss: 0.2661 - iou_score: 0.7157 - f1-score: 0.8322For batch 150, tr_loss is    0.27.\n",
      "152/232 [==================>...........] - ETA: 1:12 - loss: 0.2659 - iou_score: 0.7161 - f1-score: 0.8325For batch 151, tr_loss is    0.27.\n",
      "153/232 [==================>...........] - ETA: 1:11 - loss: 0.2660 - iou_score: 0.7160 - f1-score: 0.8324For batch 152, tr_loss is    0.27.\n",
      "154/232 [==================>...........] - ETA: 1:10 - loss: 0.2656 - iou_score: 0.7163 - f1-score: 0.8326For batch 153, tr_loss is    0.27.\n",
      "155/232 [===================>..........] - ETA: 1:09 - loss: 0.2655 - iou_score: 0.7164 - f1-score: 0.8327For batch 154, tr_loss is    0.27.\n",
      "156/232 [===================>..........] - ETA: 1:08 - loss: 0.2656 - iou_score: 0.7162 - f1-score: 0.8326For batch 155, tr_loss is    0.27.\n",
      "157/232 [===================>..........] - ETA: 1:07 - loss: 0.2665 - iou_score: 0.7157 - f1-score: 0.8322For batch 156, tr_loss is    0.27.\n",
      "158/232 [===================>..........] - ETA: 1:06 - loss: 0.2662 - iou_score: 0.7161 - f1-score: 0.8325For batch 157, tr_loss is    0.27.\n",
      "159/232 [===================>..........] - ETA: 1:06 - loss: 0.2660 - iou_score: 0.7165 - f1-score: 0.8327For batch 158, tr_loss is    0.27.\n",
      "160/232 [===================>..........] - ETA: 1:05 - loss: 0.2658 - iou_score: 0.7164 - f1-score: 0.8327For batch 159, tr_loss is    0.27.\n",
      "161/232 [===================>..........] - ETA: 1:04 - loss: 0.2657 - iou_score: 0.7168 - f1-score: 0.8329For batch 160, tr_loss is    0.27.\n",
      "162/232 [===================>..........] - ETA: 1:03 - loss: 0.2656 - iou_score: 0.7167 - f1-score: 0.8329For batch 161, tr_loss is    0.27.\n",
      "163/232 [====================>.........] - ETA: 1:02 - loss: 0.2653 - iou_score: 0.7172 - f1-score: 0.8332For batch 162, tr_loss is    0.27.\n",
      "164/232 [====================>.........] - ETA: 1:01 - loss: 0.2654 - iou_score: 0.7169 - f1-score: 0.8330For batch 163, tr_loss is    0.27.\n",
      "165/232 [====================>.........] - ETA: 1:00 - loss: 0.2655 - iou_score: 0.7168 - f1-score: 0.8330For batch 164, tr_loss is    0.27.\n",
      "166/232 [====================>.........] - ETA: 59s - loss: 0.2654 - iou_score: 0.7169 - f1-score: 0.8330 For batch 165, tr_loss is    0.27.\n",
      "167/232 [====================>.........] - ETA: 58s - loss: 0.2651 - iou_score: 0.7172 - f1-score: 0.8333For batch 166, tr_loss is    0.27.\n",
      "168/232 [====================>.........] - ETA: 57s - loss: 0.2654 - iou_score: 0.7169 - f1-score: 0.8331For batch 167, tr_loss is    0.27.\n",
      "169/232 [====================>.........] - ETA: 56s - loss: 0.2659 - iou_score: 0.7164 - f1-score: 0.8327For batch 168, tr_loss is    0.27.\n",
      "170/232 [====================>.........] - ETA: 56s - loss: 0.2657 - iou_score: 0.7166 - f1-score: 0.8328For batch 169, tr_loss is    0.27.\n",
      "171/232 [=====================>........] - ETA: 55s - loss: 0.2661 - iou_score: 0.7160 - f1-score: 0.8324For batch 170, tr_loss is    0.27.\n",
      "172/232 [=====================>........] - ETA: 54s - loss: 0.2664 - iou_score: 0.7158 - f1-score: 0.8323For batch 171, tr_loss is    0.27.\n",
      "173/232 [=====================>........] - ETA: 53s - loss: 0.2661 - iou_score: 0.7160 - f1-score: 0.8324For batch 172, tr_loss is    0.27.\n",
      "174/232 [=====================>........] - ETA: 52s - loss: 0.2658 - iou_score: 0.7162 - f1-score: 0.8326For batch 173, tr_loss is    0.27.\n",
      "175/232 [=====================>........] - ETA: 51s - loss: 0.2659 - iou_score: 0.7161 - f1-score: 0.8325For batch 174, tr_loss is    0.27.\n",
      "176/232 [=====================>........] - ETA: 50s - loss: 0.2660 - iou_score: 0.7159 - f1-score: 0.8324For batch 175, tr_loss is    0.27.\n",
      "177/232 [=====================>........] - ETA: 49s - loss: 0.2658 - iou_score: 0.7163 - f1-score: 0.8327For batch 176, tr_loss is    0.27.\n",
      "178/232 [======================>.......] - ETA: 48s - loss: 0.2658 - iou_score: 0.7164 - f1-score: 0.8327For batch 177, tr_loss is    0.27.\n",
      "179/232 [======================>.......] - ETA: 47s - loss: 0.2656 - iou_score: 0.7165 - f1-score: 0.8328For batch 178, tr_loss is    0.27.\n",
      "180/232 [======================>.......] - ETA: 46s - loss: 0.2657 - iou_score: 0.7164 - f1-score: 0.8327For batch 179, tr_loss is    0.27.\n",
      "181/232 [======================>.......] - ETA: 46s - loss: 0.2657 - iou_score: 0.7163 - f1-score: 0.8326For batch 180, tr_loss is    0.27.\n",
      "182/232 [======================>.......] - ETA: 45s - loss: 0.2658 - iou_score: 0.7162 - f1-score: 0.8326For batch 181, tr_loss is    0.27.\n",
      "183/232 [======================>.......] - ETA: 44s - loss: 0.2658 - iou_score: 0.7162 - f1-score: 0.8326For batch 182, tr_loss is    0.27.\n",
      "184/232 [======================>.......] - ETA: 43s - loss: 0.2655 - iou_score: 0.7167 - f1-score: 0.8329For batch 183, tr_loss is    0.27.\n",
      "185/232 [======================>.......] - ETA: 42s - loss: 0.2655 - iou_score: 0.7168 - f1-score: 0.8330For batch 184, tr_loss is    0.27.\n",
      "186/232 [=======================>......] - ETA: 41s - loss: 0.2655 - iou_score: 0.7167 - f1-score: 0.8330For batch 185, tr_loss is    0.27.\n",
      "187/232 [=======================>......] - ETA: 40s - loss: 0.2650 - iou_score: 0.7173 - f1-score: 0.8333For batch 186, tr_loss is    0.27.\n",
      "188/232 [=======================>......] - ETA: 39s - loss: 0.2651 - iou_score: 0.7172 - f1-score: 0.8333For batch 187, tr_loss is    0.27.\n",
      "189/232 [=======================>......] - ETA: 38s - loss: 0.2649 - iou_score: 0.7174 - f1-score: 0.8334For batch 188, tr_loss is    0.26.\n",
      "190/232 [=======================>......] - ETA: 37s - loss: 0.2648 - iou_score: 0.7175 - f1-score: 0.8335For batch 189, tr_loss is    0.26.\n",
      "191/232 [=======================>......] - ETA: 36s - loss: 0.2646 - iou_score: 0.7176 - f1-score: 0.8336For batch 190, tr_loss is    0.26.\n",
      "192/232 [=======================>......] - ETA: 35s - loss: 0.2648 - iou_score: 0.7173 - f1-score: 0.8334For batch 191, tr_loss is    0.26.\n",
      "193/232 [=======================>......] - ETA: 35s - loss: 0.2652 - iou_score: 0.7168 - f1-score: 0.8330For batch 192, tr_loss is    0.27.\n",
      "194/232 [========================>.....] - ETA: 34s - loss: 0.2652 - iou_score: 0.7167 - f1-score: 0.8329For batch 193, tr_loss is    0.27.\n",
      "195/232 [========================>.....] - ETA: 33s - loss: 0.2653 - iou_score: 0.7166 - f1-score: 0.8329For batch 194, tr_loss is    0.27.\n",
      "196/232 [========================>.....] - ETA: 32s - loss: 0.2651 - iou_score: 0.7167 - f1-score: 0.8329For batch 195, tr_loss is    0.27.\n",
      "197/232 [========================>.....] - ETA: 31s - loss: 0.2650 - iou_score: 0.7167 - f1-score: 0.8330For batch 196, tr_loss is    0.27.\n",
      "198/232 [========================>.....] - ETA: 30s - loss: 0.2649 - iou_score: 0.7171 - f1-score: 0.8332For batch 197, tr_loss is    0.26.\n",
      "199/232 [========================>.....] - ETA: 29s - loss: 0.2647 - iou_score: 0.7173 - f1-score: 0.8333For batch 198, tr_loss is    0.26.\n",
      "200/232 [========================>.....] - ETA: 28s - loss: 0.2643 - iou_score: 0.7177 - f1-score: 0.8337For batch 199, tr_loss is    0.26.\n",
      "201/232 [========================>.....] - ETA: 27s - loss: 0.2645 - iou_score: 0.7175 - f1-score: 0.8335For batch 200, tr_loss is    0.26.\n",
      "202/232 [=========================>....] - ETA: 26s - loss: 0.2645 - iou_score: 0.7174 - f1-score: 0.8334For batch 201, tr_loss is    0.26.\n",
      "203/232 [=========================>....] - ETA: 25s - loss: 0.2643 - iou_score: 0.7175 - f1-score: 0.8335For batch 202, tr_loss is    0.26.\n",
      "204/232 [=========================>....] - ETA: 24s - loss: 0.2639 - iou_score: 0.7180 - f1-score: 0.8338For batch 203, tr_loss is    0.26.\n",
      "205/232 [=========================>....] - ETA: 24s - loss: 0.2638 - iou_score: 0.7180 - f1-score: 0.8338For batch 204, tr_loss is    0.26.\n",
      "206/232 [=========================>....] - ETA: 23s - loss: 0.2640 - iou_score: 0.7179 - f1-score: 0.8338For batch 205, tr_loss is    0.26.\n",
      "207/232 [=========================>....] - ETA: 22s - loss: 0.2641 - iou_score: 0.7178 - f1-score: 0.8337For batch 206, tr_loss is    0.26.\n",
      "208/232 [=========================>....] - ETA: 21s - loss: 0.2639 - iou_score: 0.7179 - f1-score: 0.8338For batch 207, tr_loss is    0.26.\n",
      "209/232 [==========================>...] - ETA: 20s - loss: 0.2640 - iou_score: 0.7178 - f1-score: 0.8337For batch 208, tr_loss is    0.26.\n",
      "210/232 [==========================>...] - ETA: 19s - loss: 0.2643 - iou_score: 0.7174 - f1-score: 0.8335For batch 209, tr_loss is    0.26.\n",
      "211/232 [==========================>...] - ETA: 18s - loss: 0.2642 - iou_score: 0.7176 - f1-score: 0.8336For batch 210, tr_loss is    0.26.\n",
      "212/232 [==========================>...] - ETA: 17s - loss: 0.2638 - iou_score: 0.7180 - f1-score: 0.8339For batch 211, tr_loss is    0.26.\n",
      "213/232 [==========================>...] - ETA: 16s - loss: 0.2639 - iou_score: 0.7179 - f1-score: 0.8338For batch 212, tr_loss is    0.26.\n",
      "214/232 [==========================>...] - ETA: 16s - loss: 0.2636 - iou_score: 0.7181 - f1-score: 0.8340For batch 213, tr_loss is    0.26.\n",
      "215/232 [==========================>...] - ETA: 15s - loss: 0.2633 - iou_score: 0.7186 - f1-score: 0.8343For batch 214, tr_loss is    0.26.\n",
      "216/232 [==========================>...] - ETA: 14s - loss: 0.2632 - iou_score: 0.7188 - f1-score: 0.8344For batch 215, tr_loss is    0.26.\n",
      "217/232 [===========================>..] - ETA: 13s - loss: 0.2632 - iou_score: 0.7187 - f1-score: 0.8343For batch 216, tr_loss is    0.26.\n",
      "218/232 [===========================>..] - ETA: 12s - loss: 0.2633 - iou_score: 0.7186 - f1-score: 0.8343For batch 217, tr_loss is    0.26.\n",
      "219/232 [===========================>..] - ETA: 11s - loss: 0.2639 - iou_score: 0.7180 - f1-score: 0.8338For batch 218, tr_loss is    0.26.\n",
      "220/232 [===========================>..] - ETA: 10s - loss: 0.2639 - iou_score: 0.7180 - f1-score: 0.8338For batch 219, tr_loss is    0.26.\n",
      "221/232 [===========================>..] - ETA: 9s - loss: 0.2640 - iou_score: 0.7177 - f1-score: 0.8337 For batch 220, tr_loss is    0.26.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222/232 [===========================>..] - ETA: 8s - loss: 0.2639 - iou_score: 0.7180 - f1-score: 0.8338For batch 221, tr_loss is    0.26.\n",
      "223/232 [===========================>..] - ETA: 8s - loss: 0.2639 - iou_score: 0.7179 - f1-score: 0.8337For batch 222, tr_loss is    0.26.\n",
      "224/232 [===========================>..] - ETA: 7s - loss: 0.2636 - iou_score: 0.7182 - f1-score: 0.8340For batch 223, tr_loss is    0.26.\n",
      "225/232 [============================>.] - ETA: 6s - loss: 0.2635 - iou_score: 0.7184 - f1-score: 0.8341For batch 224, tr_loss is    0.26.\n",
      "226/232 [============================>.] - ETA: 5s - loss: 0.2635 - iou_score: 0.7184 - f1-score: 0.8341For batch 225, tr_loss is    0.26.\n",
      "227/232 [============================>.] - ETA: 4s - loss: 0.2634 - iou_score: 0.7185 - f1-score: 0.8342For batch 226, tr_loss is    0.26.\n",
      "228/232 [============================>.] - ETA: 3s - loss: 0.2634 - iou_score: 0.7185 - f1-score: 0.8342For batch 227, tr_loss is    0.26.\n",
      "229/232 [============================>.] - ETA: 2s - loss: 0.2633 - iou_score: 0.7186 - f1-score: 0.8342For batch 228, tr_loss is    0.26.\n",
      "230/232 [============================>.] - ETA: 1s - loss: 0.2636 - iou_score: 0.7183 - f1-score: 0.8341For batch 229, tr_loss is    0.26.\n",
      "231/232 [============================>.] - ETA: 0s - loss: 0.2637 - iou_score: 0.7181 - f1-score: 0.8339For batch 230, tr_loss is    0.26.\n",
      "232/232 [==============================] - ETA: 0s - loss: 0.2634 - iou_score: 0.7185 - f1-score: 0.8342For batch 231, tr_loss is    0.26.\n",
      "For batch 0, vl_loss is    0.36.\n",
      "For batch 1, vl_loss is    0.32.\n",
      "For batch 2, vl_loss is    0.35.\n",
      "For batch 3, vl_loss is    0.35.\n",
      "For batch 4, vl_loss is    0.37.\n",
      "For batch 5, vl_loss is    0.36.\n",
      "For batch 6, vl_loss is    0.38.\n",
      "For batch 7, vl_loss is    0.37.\n",
      "For batch 8, vl_loss is    0.37.\n",
      "For batch 9, vl_loss is    0.36.\n",
      "For batch 10, vl_loss is    0.36.\n",
      "For batch 11, vl_loss is    0.37.\n",
      "For batch 12, vl_loss is    0.37.\n",
      "For batch 13, vl_loss is    0.37.\n",
      "For batch 14, vl_loss is    0.37.\n",
      "For batch 15, vl_loss is    0.36.\n",
      "For batch 16, vl_loss is    0.36.\n",
      "For batch 17, vl_loss is    0.36.\n",
      "For batch 18, vl_loss is    0.36.\n",
      "For batch 19, vl_loss is    0.36.\n",
      "For batch 20, vl_loss is    0.36.\n",
      "For batch 21, vl_loss is    0.36.\n",
      "For batch 22, vl_loss is    0.36.\n",
      "For batch 23, vl_loss is    0.36.\n",
      "For batch 24, vl_loss is    0.36.\n",
      "For batch 25, vl_loss is    0.35.\n",
      "For batch 26, vl_loss is    0.35.\n",
      "For batch 27, vl_loss is    0.36.\n",
      "For batch 28, vl_loss is    0.36.\n",
      "For batch 29, vl_loss is    0.36.\n",
      "For batch 30, vl_loss is    0.36.\n",
      "For batch 31, vl_loss is    0.36.\n",
      "For batch 32, vl_loss is    0.36.\n",
      "For batch 33, vl_loss is    0.36.\n",
      "For batch 34, vl_loss is    0.36.\n",
      "For batch 35, vl_loss is    0.36.\n",
      "For batch 36, vl_loss is    0.36.\n",
      "For batch 37, vl_loss is    0.36.\n",
      "For batch 38, vl_loss is    0.36.\n",
      "For batch 39, vl_loss is    0.36.\n",
      "For batch 40, vl_loss is    0.36.\n",
      "For batch 41, vl_loss is    0.36.\n",
      "For batch 42, vl_loss is    0.36.\n",
      "For batch 43, vl_loss is    0.37.\n",
      "For batch 44, vl_loss is    0.36.\n",
      "For batch 45, vl_loss is    0.37.\n",
      "For batch 46, vl_loss is    0.36.\n",
      "For batch 47, vl_loss is    0.36.\n",
      "For batch 48, vl_loss is    0.37.\n",
      "For batch 49, vl_loss is    0.36.\n",
      "For batch 50, vl_loss is    0.37.\n",
      "For batch 51, vl_loss is    0.37.\n",
      "For batch 52, vl_loss is    0.37.\n",
      "For batch 53, vl_loss is    0.37.\n",
      "For batch 54, vl_loss is    0.37.\n",
      "For batch 55, vl_loss is    0.37.\n",
      "For batch 56, vl_loss is    0.37.\n",
      "For batch 57, vl_loss is    0.37.\n",
      "For batch 58, vl_loss is    0.37.\n",
      "For batch 59, vl_loss is    0.36.\n",
      "For batch 60, vl_loss is    0.36.\n",
      "For batch 61, vl_loss is    0.36.\n",
      "For batch 62, vl_loss is    0.36.\n",
      "For batch 63, vl_loss is    0.36.\n",
      "For batch 64, vl_loss is    0.36.\n",
      "For batch 65, vl_loss is    0.36.\n",
      "For batch 66, vl_loss is    0.36.\n",
      "For batch 67, vl_loss is    0.36.\n",
      "232/232 [==============================] - 210s 898ms/step - loss: 0.2634 - iou_score: 0.7185 - f1-score: 0.8342 - val_loss: 0.3610 - val_iou_score: 0.6467 - val_f1-score: 0.7833\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.40105 to 0.36098, saving model to ./model/tumor_100_unet_efficientnetb0_imagenet_09291.hdf5\n",
      "The average loss for epoch 8 is    0.26 \n",
      "Epoch 10/200\n",
      "  1/232 [..............................] - ETA: 9:38 - loss: 0.2149 - iou_score: 0.7771 - f1-score: 0.8727For batch 0, tr_loss is    0.21.\n",
      "  2/232 [..............................] - ETA: 3:36 - loss: 0.2199 - iou_score: 0.7764 - f1-score: 0.8731For batch 1, tr_loss is    0.22.\n",
      "  3/232 [..............................] - ETA: 3:45 - loss: 0.2346 - iou_score: 0.7481 - f1-score: 0.8546For batch 2, tr_loss is    0.23.\n",
      "  4/232 [..............................] - ETA: 4:09 - loss: 0.2328 - iou_score: 0.7563 - f1-score: 0.8601For batch 3, tr_loss is    0.23.\n",
      "  5/232 [..............................] - ETA: 4:31 - loss: 0.2463 - iou_score: 0.7422 - f1-score: 0.8504For batch 4, tr_loss is    0.25.\n",
      "  6/232 [..............................] - ETA: 4:33 - loss: 0.2540 - iou_score: 0.7336 - f1-score: 0.8441For batch 5, tr_loss is    0.25.\n",
      "  7/232 [..............................] - ETA: 4:42 - loss: 0.2622 - iou_score: 0.7230 - f1-score: 0.8370For batch 6, tr_loss is    0.26.\n",
      "  8/232 [>.............................] - ETA: 4:50 - loss: 0.2655 - iou_score: 0.7176 - f1-score: 0.8336For batch 7, tr_loss is    0.27.\n",
      "  9/232 [>.............................] - ETA: 4:51 - loss: 0.2580 - iou_score: 0.7270 - f1-score: 0.8398For batch 8, tr_loss is    0.26.\n",
      " 10/232 [>.............................] - ETA: 4:44 - loss: 0.2565 - iou_score: 0.7269 - f1-score: 0.8399For batch 9, tr_loss is    0.26.\n",
      " 11/232 [>.............................] - ETA: 4:26 - loss: 0.2540 - iou_score: 0.7283 - f1-score: 0.8410For batch 10, tr_loss is    0.25.\n",
      " 12/232 [>.............................] - ETA: 4:22 - loss: 0.2516 - iou_score: 0.7337 - f1-score: 0.8446For batch 11, tr_loss is    0.25.\n",
      " 13/232 [>.............................] - ETA: 4:09 - loss: 0.2505 - iou_score: 0.7357 - f1-score: 0.8458For batch 12, tr_loss is    0.25.\n",
      " 14/232 [>.............................] - ETA: 4:01 - loss: 0.2474 - iou_score: 0.7388 - f1-score: 0.8479For batch 13, tr_loss is    0.25.\n",
      " 15/232 [>.............................] - ETA: 3:55 - loss: 0.2438 - iou_score: 0.7430 - f1-score: 0.8507For batch 14, tr_loss is    0.24.\n",
      " 16/232 [=>............................] - ETA: 3:49 - loss: 0.2420 - iou_score: 0.7436 - f1-score: 0.8512For batch 15, tr_loss is    0.24.\n",
      " 17/232 [=>............................] - ETA: 3:42 - loss: 0.2407 - iou_score: 0.7464 - f1-score: 0.8531For batch 16, tr_loss is    0.24.\n",
      " 18/232 [=>............................] - ETA: 3:38 - loss: 0.2422 - iou_score: 0.7449 - f1-score: 0.8522For batch 17, tr_loss is    0.24.\n",
      " 19/232 [=>............................] - ETA: 3:37 - loss: 0.2444 - iou_score: 0.7411 - f1-score: 0.8496For batch 18, tr_loss is    0.24.\n",
      " 20/232 [=>............................] - ETA: 3:36 - loss: 0.2421 - iou_score: 0.7432 - f1-score: 0.8511For batch 19, tr_loss is    0.24.\n",
      " 21/232 [=>............................] - ETA: 3:32 - loss: 0.2463 - iou_score: 0.7402 - f1-score: 0.8489For batch 20, tr_loss is    0.25.\n",
      " 22/232 [=>............................] - ETA: 3:31 - loss: 0.2482 - iou_score: 0.7371 - f1-score: 0.8468For batch 21, tr_loss is    0.25.\n",
      " 23/232 [=>............................] - ETA: 3:30 - loss: 0.2493 - iou_score: 0.7360 - f1-score: 0.8460For batch 22, tr_loss is    0.25.\n",
      " 24/232 [==>...........................] - ETA: 3:29 - loss: 0.2489 - iou_score: 0.7360 - f1-score: 0.8462For batch 23, tr_loss is    0.25.\n",
      " 25/232 [==>...........................] - ETA: 3:28 - loss: 0.2532 - iou_score: 0.7310 - f1-score: 0.8426For batch 24, tr_loss is    0.25.\n",
      " 26/232 [==>...........................] - ETA: 3:24 - loss: 0.2536 - iou_score: 0.7305 - f1-score: 0.8423For batch 25, tr_loss is    0.25.\n",
      " 27/232 [==>...........................] - ETA: 3:24 - loss: 0.2520 - iou_score: 0.7326 - f1-score: 0.8437For batch 26, tr_loss is    0.25.\n",
      " 28/232 [==>...........................] - ETA: 3:23 - loss: 0.2520 - iou_score: 0.7319 - f1-score: 0.8432For batch 27, tr_loss is    0.25.\n",
      " 29/232 [==>...........................] - ETA: 3:22 - loss: 0.2514 - iou_score: 0.7312 - f1-score: 0.8427For batch 28, tr_loss is    0.25.\n",
      " 30/232 [==>...........................] - ETA: 3:19 - loss: 0.2501 - iou_score: 0.7324 - f1-score: 0.8436For batch 29, tr_loss is    0.25.\n",
      " 31/232 [===>..........................] - ETA: 3:19 - loss: 0.2504 - iou_score: 0.7325 - f1-score: 0.8438For batch 30, tr_loss is    0.25.\n",
      " 32/232 [===>..........................] - ETA: 3:14 - loss: 0.2500 - iou_score: 0.7333 - f1-score: 0.8443For batch 31, tr_loss is    0.25.\n",
      " 33/232 [===>..........................] - ETA: 3:14 - loss: 0.2530 - iou_score: 0.7309 - f1-score: 0.8427For batch 32, tr_loss is    0.25.\n",
      " 34/232 [===>..........................] - ETA: 3:13 - loss: 0.2533 - iou_score: 0.7305 - f1-score: 0.8425For batch 33, tr_loss is    0.25.\n",
      " 35/232 [===>..........................] - ETA: 3:11 - loss: 0.2560 - iou_score: 0.7280 - f1-score: 0.8407For batch 34, tr_loss is    0.26.\n",
      " 36/232 [===>..........................] - ETA: 3:07 - loss: 0.2570 - iou_score: 0.7271 - f1-score: 0.8401For batch 35, tr_loss is    0.26.\n",
      " 37/232 [===>..........................] - ETA: 3:06 - loss: 0.2571 - iou_score: 0.7265 - f1-score: 0.8398For batch 36, tr_loss is    0.26.\n",
      " 38/232 [===>..........................] - ETA: 3:05 - loss: 0.2584 - iou_score: 0.7252 - f1-score: 0.8389For batch 37, tr_loss is    0.26.\n",
      " 39/232 [====>.........................] - ETA: 3:02 - loss: 0.2618 - iou_score: 0.7219 - f1-score: 0.8365For batch 38, tr_loss is    0.26.\n",
      " 40/232 [====>.........................] - ETA: 3:01 - loss: 0.2639 - iou_score: 0.7205 - f1-score: 0.8355For batch 39, tr_loss is    0.26.\n",
      " 41/232 [====>.........................] - ETA: 2:58 - loss: 0.2648 - iou_score: 0.7191 - f1-score: 0.8346For batch 40, tr_loss is    0.26.\n",
      " 42/232 [====>.........................] - ETA: 2:58 - loss: 0.2650 - iou_score: 0.7182 - f1-score: 0.8340For batch 41, tr_loss is    0.26.\n",
      " 43/232 [====>.........................] - ETA: 2:55 - loss: 0.2641 - iou_score: 0.7191 - f1-score: 0.8347For batch 42, tr_loss is    0.26.\n",
      " 44/232 [====>.........................] - ETA: 2:53 - loss: 0.2668 - iou_score: 0.7167 - f1-score: 0.8328For batch 43, tr_loss is    0.27.\n",
      " 45/232 [====>.........................] - ETA: 2:52 - loss: 0.2677 - iou_score: 0.7164 - f1-score: 0.8326For batch 44, tr_loss is    0.27.\n",
      " 46/232 [====>.........................] - ETA: 2:50 - loss: 0.2678 - iou_score: 0.7164 - f1-score: 0.8327For batch 45, tr_loss is    0.27.\n",
      " 47/232 [=====>........................] - ETA: 2:50 - loss: 0.2674 - iou_score: 0.7167 - f1-score: 0.8329For batch 46, tr_loss is    0.27.\n",
      " 48/232 [=====>........................] - ETA: 2:47 - loss: 0.2663 - iou_score: 0.7180 - f1-score: 0.8338For batch 47, tr_loss is    0.27.\n",
      " 49/232 [=====>........................] - ETA: 2:47 - loss: 0.2669 - iou_score: 0.7179 - f1-score: 0.8337For batch 48, tr_loss is    0.27.\n",
      " 50/232 [=====>........................] - ETA: 2:46 - loss: 0.2665 - iou_score: 0.7183 - f1-score: 0.8340For batch 49, tr_loss is    0.27.\n",
      " 51/232 [=====>........................] - ETA: 2:46 - loss: 0.2671 - iou_score: 0.7173 - f1-score: 0.8333For batch 50, tr_loss is    0.27.\n",
      " 52/232 [=====>........................] - ETA: 2:45 - loss: 0.2693 - iou_score: 0.7153 - f1-score: 0.8319For batch 51, tr_loss is    0.27.\n",
      " 53/232 [=====>........................] - ETA: 2:45 - loss: 0.2681 - iou_score: 0.7167 - f1-score: 0.8328For batch 52, tr_loss is    0.27.\n",
      " 54/232 [=====>........................] - ETA: 2:42 - loss: 0.2685 - iou_score: 0.7162 - f1-score: 0.8325For batch 53, tr_loss is    0.27.\n",
      " 55/232 [======>.......................] - ETA: 2:41 - loss: 0.2683 - iou_score: 0.7164 - f1-score: 0.8327For batch 54, tr_loss is    0.27.\n",
      " 56/232 [======>.......................] - ETA: 2:39 - loss: 0.2682 - iou_score: 0.7164 - f1-score: 0.8327For batch 55, tr_loss is    0.27.\n",
      " 57/232 [======>.......................] - ETA: 2:38 - loss: 0.2695 - iou_score: 0.7148 - f1-score: 0.8315For batch 56, tr_loss is    0.27.\n",
      " 58/232 [======>.......................] - ETA: 2:38 - loss: 0.2687 - iou_score: 0.7161 - f1-score: 0.8324For batch 57, tr_loss is    0.27.\n",
      " 59/232 [======>.......................] - ETA: 2:36 - loss: 0.2679 - iou_score: 0.7167 - f1-score: 0.8328For batch 58, tr_loss is    0.27.\n",
      " 60/232 [======>.......................] - ETA: 2:34 - loss: 0.2699 - iou_score: 0.7151 - f1-score: 0.8316For batch 59, tr_loss is    0.27.\n",
      " 61/232 [======>.......................] - ETA: 2:32 - loss: 0.2722 - iou_score: 0.7133 - f1-score: 0.8303For batch 60, tr_loss is    0.27.\n",
      " 62/232 [=======>......................] - ETA: 2:31 - loss: 0.2728 - iou_score: 0.7124 - f1-score: 0.8297For batch 61, tr_loss is    0.27.\n",
      " 63/232 [=======>......................] - ETA: 2:31 - loss: 0.2721 - iou_score: 0.7133 - f1-score: 0.8303For batch 62, tr_loss is    0.27.\n",
      " 64/232 [=======>......................] - ETA: 2:29 - loss: 0.2720 - iou_score: 0.7133 - f1-score: 0.8303For batch 63, tr_loss is    0.27.\n",
      " 65/232 [=======>......................] - ETA: 2:28 - loss: 0.2720 - iou_score: 0.7135 - f1-score: 0.8305For batch 64, tr_loss is    0.27.\n",
      " 66/232 [=======>......................] - ETA: 2:26 - loss: 0.2720 - iou_score: 0.7130 - f1-score: 0.8302For batch 65, tr_loss is    0.27.\n",
      " 67/232 [=======>......................] - ETA: 2:25 - loss: 0.2711 - iou_score: 0.7141 - f1-score: 0.8309For batch 66, tr_loss is    0.27.\n",
      " 68/232 [=======>......................] - ETA: 2:25 - loss: 0.2707 - iou_score: 0.7148 - f1-score: 0.8314For batch 67, tr_loss is    0.27.\n",
      " 69/232 [=======>......................] - ETA: 2:24 - loss: 0.2708 - iou_score: 0.7150 - f1-score: 0.8316For batch 68, tr_loss is    0.27.\n",
      " 70/232 [========>.....................] - ETA: 2:23 - loss: 0.2703 - iou_score: 0.7154 - f1-score: 0.8318For batch 69, tr_loss is    0.27.\n",
      " 71/232 [========>.....................] - ETA: 2:22 - loss: 0.2696 - iou_score: 0.7165 - f1-score: 0.8326For batch 70, tr_loss is    0.27.\n",
      " 72/232 [========>.....................] - ETA: 2:20 - loss: 0.2689 - iou_score: 0.7173 - f1-score: 0.8331For batch 71, tr_loss is    0.27.\n",
      " 73/232 [========>.....................] - ETA: 2:20 - loss: 0.2687 - iou_score: 0.7171 - f1-score: 0.8330For batch 72, tr_loss is    0.27.\n",
      " 74/232 [========>.....................] - ETA: 2:19 - loss: 0.2680 - iou_score: 0.7179 - f1-score: 0.8336For batch 73, tr_loss is    0.27.\n",
      " 75/232 [========>.....................] - ETA: 2:19 - loss: 0.2682 - iou_score: 0.7178 - f1-score: 0.8335For batch 74, tr_loss is    0.27.\n",
      " 76/232 [========>.....................] - ETA: 2:18 - loss: 0.2675 - iou_score: 0.7182 - f1-score: 0.8338For batch 75, tr_loss is    0.27.\n",
      " 77/232 [========>.....................] - ETA: 2:17 - loss: 0.2667 - iou_score: 0.7189 - f1-score: 0.8343For batch 76, tr_loss is    0.27.\n",
      " 78/232 [=========>....................] - ETA: 2:16 - loss: 0.2670 - iou_score: 0.7184 - f1-score: 0.8339For batch 77, tr_loss is    0.27.\n",
      " 79/232 [=========>....................] - ETA: 2:14 - loss: 0.2663 - iou_score: 0.7190 - f1-score: 0.8344For batch 78, tr_loss is    0.27.\n",
      " 80/232 [=========>....................] - ETA: 2:13 - loss: 0.2663 - iou_score: 0.7190 - f1-score: 0.8343For batch 79, tr_loss is    0.27.\n",
      " 81/232 [=========>....................] - ETA: 2:12 - loss: 0.2666 - iou_score: 0.7186 - f1-score: 0.8340For batch 80, tr_loss is    0.27.\n",
      " 82/232 [=========>....................] - ETA: 2:11 - loss: 0.2665 - iou_score: 0.7185 - f1-score: 0.8340For batch 81, tr_loss is    0.27.\n",
      " 83/232 [=========>....................] - ETA: 2:11 - loss: 0.2671 - iou_score: 0.7177 - f1-score: 0.8335For batch 82, tr_loss is    0.27.\n",
      " 84/232 [=========>....................] - ETA: 2:09 - loss: 0.2677 - iou_score: 0.7170 - f1-score: 0.8330For batch 83, tr_loss is    0.27.\n",
      " 85/232 [=========>....................] - ETA: 2:08 - loss: 0.2678 - iou_score: 0.7168 - f1-score: 0.8329For batch 84, tr_loss is    0.27.\n",
      " 86/232 [==========>...................] - ETA: 2:08 - loss: 0.2681 - iou_score: 0.7162 - f1-score: 0.8325For batch 85, tr_loss is    0.27.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 87/232 [==========>...................] - ETA: 2:07 - loss: 0.2677 - iou_score: 0.7166 - f1-score: 0.8328For batch 86, tr_loss is    0.27.\n",
      " 88/232 [==========>...................] - ETA: 2:06 - loss: 0.2681 - iou_score: 0.7159 - f1-score: 0.8323For batch 87, tr_loss is    0.27.\n",
      " 89/232 [==========>...................] - ETA: 2:05 - loss: 0.2677 - iou_score: 0.7164 - f1-score: 0.8327For batch 88, tr_loss is    0.27.\n",
      " 90/232 [==========>...................] - ETA: 2:04 - loss: 0.2672 - iou_score: 0.7171 - f1-score: 0.8331For batch 89, tr_loss is    0.27.\n",
      " 91/232 [==========>...................] - ETA: 2:04 - loss: 0.2670 - iou_score: 0.7173 - f1-score: 0.8333For batch 90, tr_loss is    0.27.\n",
      " 92/232 [==========>...................] - ETA: 2:03 - loss: 0.2668 - iou_score: 0.7176 - f1-score: 0.8335For batch 91, tr_loss is    0.27.\n",
      " 93/232 [===========>..................] - ETA: 2:02 - loss: 0.2680 - iou_score: 0.7163 - f1-score: 0.8325For batch 92, tr_loss is    0.27.\n",
      " 94/232 [===========>..................] - ETA: 2:01 - loss: 0.2674 - iou_score: 0.7171 - f1-score: 0.8331For batch 93, tr_loss is    0.27.\n",
      " 95/232 [===========>..................] - ETA: 2:00 - loss: 0.2677 - iou_score: 0.7167 - f1-score: 0.8328For batch 94, tr_loss is    0.27.\n",
      " 96/232 [===========>..................] - ETA: 1:59 - loss: 0.2676 - iou_score: 0.7168 - f1-score: 0.8328For batch 95, tr_loss is    0.27.\n",
      " 97/232 [===========>..................] - ETA: 1:57 - loss: 0.2681 - iou_score: 0.7160 - f1-score: 0.8323For batch 96, tr_loss is    0.27.\n",
      " 98/232 [===========>..................] - ETA: 1:57 - loss: 0.2679 - iou_score: 0.7160 - f1-score: 0.8323For batch 97, tr_loss is    0.27.\n",
      " 99/232 [===========>..................] - ETA: 1:56 - loss: 0.2672 - iou_score: 0.7169 - f1-score: 0.8329For batch 98, tr_loss is    0.27.\n",
      "100/232 [===========>..................] - ETA: 1:55 - loss: 0.2665 - iou_score: 0.7178 - f1-score: 0.8335For batch 99, tr_loss is    0.27.\n",
      "101/232 [============>.................] - ETA: 1:55 - loss: 0.2660 - iou_score: 0.7185 - f1-score: 0.8340For batch 100, tr_loss is    0.27.\n",
      "102/232 [============>.................] - ETA: 1:54 - loss: 0.2659 - iou_score: 0.7186 - f1-score: 0.8341For batch 101, tr_loss is    0.27.\n",
      "103/232 [============>.................] - ETA: 1:53 - loss: 0.2661 - iou_score: 0.7186 - f1-score: 0.8340For batch 102, tr_loss is    0.27.\n",
      "104/232 [============>.................] - ETA: 1:51 - loss: 0.2659 - iou_score: 0.7187 - f1-score: 0.8342For batch 103, tr_loss is    0.27.\n",
      "105/232 [============>.................] - ETA: 1:51 - loss: 0.2652 - iou_score: 0.7195 - f1-score: 0.8347For batch 104, tr_loss is    0.27.\n",
      "106/232 [============>.................] - ETA: 1:50 - loss: 0.2644 - iou_score: 0.7203 - f1-score: 0.8353For batch 105, tr_loss is    0.26.\n",
      "107/232 [============>.................] - ETA: 1:49 - loss: 0.2648 - iou_score: 0.7202 - f1-score: 0.8351For batch 106, tr_loss is    0.26.\n",
      "108/232 [============>.................] - ETA: 1:48 - loss: 0.2654 - iou_score: 0.7193 - f1-score: 0.8345For batch 107, tr_loss is    0.27.\n",
      "109/232 [=============>................] - ETA: 1:48 - loss: 0.2650 - iou_score: 0.7196 - f1-score: 0.8347For batch 108, tr_loss is    0.27.\n",
      "110/232 [=============>................] - ETA: 1:46 - loss: 0.2641 - iou_score: 0.7208 - f1-score: 0.8355For batch 109, tr_loss is    0.26.\n",
      "111/232 [=============>................] - ETA: 1:45 - loss: 0.2642 - iou_score: 0.7205 - f1-score: 0.8353For batch 110, tr_loss is    0.26.\n",
      "112/232 [=============>................] - ETA: 1:44 - loss: 0.2643 - iou_score: 0.7205 - f1-score: 0.8353For batch 111, tr_loss is    0.26.\n",
      "113/232 [=============>................] - ETA: 1:44 - loss: 0.2647 - iou_score: 0.7200 - f1-score: 0.8350For batch 112, tr_loss is    0.26.\n",
      "114/232 [=============>................] - ETA: 1:43 - loss: 0.2641 - iou_score: 0.7206 - f1-score: 0.8354For batch 113, tr_loss is    0.26.\n",
      "115/232 [=============>................] - ETA: 1:42 - loss: 0.2638 - iou_score: 0.7209 - f1-score: 0.8356For batch 114, tr_loss is    0.26.\n",
      "116/232 [==============>...............] - ETA: 1:41 - loss: 0.2636 - iou_score: 0.7210 - f1-score: 0.8357For batch 115, tr_loss is    0.26.\n",
      "117/232 [==============>...............] - ETA: 1:41 - loss: 0.2635 - iou_score: 0.7209 - f1-score: 0.8356For batch 116, tr_loss is    0.26.\n",
      "118/232 [==============>...............] - ETA: 1:39 - loss: 0.2631 - iou_score: 0.7215 - f1-score: 0.8361For batch 117, tr_loss is    0.26.\n",
      "119/232 [==============>...............] - ETA: 1:38 - loss: 0.2627 - iou_score: 0.7219 - f1-score: 0.8363For batch 118, tr_loss is    0.26.\n",
      "120/232 [==============>...............] - ETA: 1:38 - loss: 0.2632 - iou_score: 0.7214 - f1-score: 0.8360For batch 119, tr_loss is    0.26.\n",
      "121/232 [==============>...............] - ETA: 1:37 - loss: 0.2627 - iou_score: 0.7220 - f1-score: 0.8364For batch 120, tr_loss is    0.26.\n",
      "122/232 [==============>...............] - ETA: 1:36 - loss: 0.2632 - iou_score: 0.7214 - f1-score: 0.8359For batch 121, tr_loss is    0.26.\n",
      "123/232 [==============>...............] - ETA: 1:35 - loss: 0.2629 - iou_score: 0.7215 - f1-score: 0.8361For batch 122, tr_loss is    0.26.\n",
      "124/232 [===============>..............] - ETA: 1:34 - loss: 0.2631 - iou_score: 0.7214 - f1-score: 0.8359For batch 123, tr_loss is    0.26.\n",
      "125/232 [===============>..............] - ETA: 1:33 - loss: 0.2635 - iou_score: 0.7208 - f1-score: 0.8356For batch 124, tr_loss is    0.26.\n",
      "126/232 [===============>..............] - ETA: 1:32 - loss: 0.2633 - iou_score: 0.7211 - f1-score: 0.8358For batch 125, tr_loss is    0.26.\n",
      "127/232 [===============>..............] - ETA: 1:32 - loss: 0.2630 - iou_score: 0.7211 - f1-score: 0.8358For batch 126, tr_loss is    0.26.\n",
      "128/232 [===============>..............] - ETA: 1:31 - loss: 0.2636 - iou_score: 0.7206 - f1-score: 0.8354For batch 127, tr_loss is    0.26.\n",
      "129/232 [===============>..............] - ETA: 1:30 - loss: 0.2637 - iou_score: 0.7204 - f1-score: 0.8353For batch 128, tr_loss is    0.26.\n",
      "130/232 [===============>..............] - ETA: 1:29 - loss: 0.2636 - iou_score: 0.7206 - f1-score: 0.8355For batch 129, tr_loss is    0.26.\n",
      "131/232 [===============>..............] - ETA: 1:28 - loss: 0.2642 - iou_score: 0.7199 - f1-score: 0.8350For batch 130, tr_loss is    0.26.\n",
      "132/232 [================>.............] - ETA: 1:27 - loss: 0.2645 - iou_score: 0.7197 - f1-score: 0.8349For batch 131, tr_loss is    0.26.\n",
      "133/232 [================>.............] - ETA: 1:26 - loss: 0.2641 - iou_score: 0.7200 - f1-score: 0.8351For batch 132, tr_loss is    0.26.\n",
      "134/232 [================>.............] - ETA: 1:25 - loss: 0.2645 - iou_score: 0.7193 - f1-score: 0.8346For batch 133, tr_loss is    0.26.\n",
      "135/232 [================>.............] - ETA: 1:24 - loss: 0.2640 - iou_score: 0.7197 - f1-score: 0.8349For batch 134, tr_loss is    0.26.\n",
      "136/232 [================>.............] - ETA: 1:23 - loss: 0.2643 - iou_score: 0.7192 - f1-score: 0.8345For batch 135, tr_loss is    0.26.\n",
      "137/232 [================>.............] - ETA: 1:22 - loss: 0.2645 - iou_score: 0.7189 - f1-score: 0.8343For batch 136, tr_loss is    0.26.\n",
      "138/232 [================>.............] - ETA: 1:21 - loss: 0.2645 - iou_score: 0.7187 - f1-score: 0.8342For batch 137, tr_loss is    0.26.\n",
      "139/232 [================>.............] - ETA: 1:21 - loss: 0.2644 - iou_score: 0.7188 - f1-score: 0.8343For batch 138, tr_loss is    0.26.\n",
      "140/232 [=================>............] - ETA: 1:20 - loss: 0.2642 - iou_score: 0.7190 - f1-score: 0.8344For batch 139, tr_loss is    0.26.\n",
      "141/232 [=================>............] - ETA: 1:19 - loss: 0.2649 - iou_score: 0.7181 - f1-score: 0.8337For batch 140, tr_loss is    0.26.\n",
      "142/232 [=================>............] - ETA: 1:18 - loss: 0.2649 - iou_score: 0.7179 - f1-score: 0.8336For batch 141, tr_loss is    0.26.\n",
      "143/232 [=================>............] - ETA: 1:17 - loss: 0.2646 - iou_score: 0.7182 - f1-score: 0.8338For batch 142, tr_loss is    0.26.\n",
      "144/232 [=================>............] - ETA: 1:16 - loss: 0.2645 - iou_score: 0.7181 - f1-score: 0.8338For batch 143, tr_loss is    0.26.\n",
      "145/232 [=================>............] - ETA: 1:16 - loss: 0.2644 - iou_score: 0.7181 - f1-score: 0.8338For batch 144, tr_loss is    0.26.\n",
      "146/232 [=================>............] - ETA: 1:15 - loss: 0.2645 - iou_score: 0.7178 - f1-score: 0.8336For batch 145, tr_loss is    0.26.\n",
      "147/232 [==================>...........] - ETA: 1:14 - loss: 0.2643 - iou_score: 0.7182 - f1-score: 0.8339For batch 146, tr_loss is    0.26.\n",
      "148/232 [==================>...........] - ETA: 1:13 - loss: 0.2647 - iou_score: 0.7176 - f1-score: 0.8335For batch 147, tr_loss is    0.26.\n",
      "149/232 [==================>...........] - ETA: 1:12 - loss: 0.2645 - iou_score: 0.7178 - f1-score: 0.8336For batch 148, tr_loss is    0.26.\n",
      "150/232 [==================>...........] - ETA: 1:11 - loss: 0.2653 - iou_score: 0.7171 - f1-score: 0.8331For batch 149, tr_loss is    0.27.\n",
      "151/232 [==================>...........] - ETA: 1:10 - loss: 0.2656 - iou_score: 0.7167 - f1-score: 0.8328For batch 150, tr_loss is    0.27.\n",
      "152/232 [==================>...........] - ETA: 1:09 - loss: 0.2653 - iou_score: 0.7171 - f1-score: 0.8331For batch 151, tr_loss is    0.27.\n",
      "153/232 [==================>...........] - ETA: 1:08 - loss: 0.2652 - iou_score: 0.7171 - f1-score: 0.8330For batch 152, tr_loss is    0.27.\n",
      "154/232 [==================>...........] - ETA: 1:07 - loss: 0.2649 - iou_score: 0.7173 - f1-score: 0.8332For batch 153, tr_loss is    0.26.\n",
      "155/232 [===================>..........] - ETA: 1:07 - loss: 0.2649 - iou_score: 0.7173 - f1-score: 0.8333For batch 154, tr_loss is    0.26.\n",
      "156/232 [===================>..........] - ETA: 1:06 - loss: 0.2648 - iou_score: 0.7173 - f1-score: 0.8333For batch 155, tr_loss is    0.26.\n",
      "157/232 [===================>..........] - ETA: 1:05 - loss: 0.2651 - iou_score: 0.7171 - f1-score: 0.8331For batch 156, tr_loss is    0.27.\n",
      "158/232 [===================>..........] - ETA: 1:04 - loss: 0.2648 - iou_score: 0.7174 - f1-score: 0.8333For batch 157, tr_loss is    0.26.\n",
      "159/232 [===================>..........] - ETA: 1:03 - loss: 0.2646 - iou_score: 0.7179 - f1-score: 0.8337For batch 158, tr_loss is    0.26.\n",
      "160/232 [===================>..........] - ETA: 1:02 - loss: 0.2645 - iou_score: 0.7178 - f1-score: 0.8336For batch 159, tr_loss is    0.26.\n",
      "161/232 [===================>..........] - ETA: 1:02 - loss: 0.2641 - iou_score: 0.7182 - f1-score: 0.8339For batch 160, tr_loss is    0.26.\n",
      "162/232 [===================>..........] - ETA: 1:01 - loss: 0.2640 - iou_score: 0.7182 - f1-score: 0.8339For batch 161, tr_loss is    0.26.\n",
      "163/232 [====================>.........] - ETA: 1:00 - loss: 0.2636 - iou_score: 0.7187 - f1-score: 0.8342For batch 162, tr_loss is    0.26.\n",
      "164/232 [====================>.........] - ETA: 59s - loss: 0.2636 - iou_score: 0.7186 - f1-score: 0.8342 For batch 163, tr_loss is    0.26.\n",
      "165/232 [====================>.........] - ETA: 58s - loss: 0.2637 - iou_score: 0.7184 - f1-score: 0.8340For batch 164, tr_loss is    0.26.\n",
      "166/232 [====================>.........] - ETA: 57s - loss: 0.2634 - iou_score: 0.7186 - f1-score: 0.8341For batch 165, tr_loss is    0.26.\n",
      "167/232 [====================>.........] - ETA: 57s - loss: 0.2632 - iou_score: 0.7188 - f1-score: 0.8343For batch 166, tr_loss is    0.26.\n",
      "168/232 [====================>.........] - ETA: 56s - loss: 0.2636 - iou_score: 0.7185 - f1-score: 0.8341For batch 167, tr_loss is    0.26.\n",
      "169/232 [====================>.........] - ETA: 55s - loss: 0.2642 - iou_score: 0.7180 - f1-score: 0.8337For batch 168, tr_loss is    0.26.\n",
      "170/232 [====================>.........] - ETA: 54s - loss: 0.2642 - iou_score: 0.7179 - f1-score: 0.8337For batch 169, tr_loss is    0.26.\n",
      "171/232 [=====================>........] - ETA: 53s - loss: 0.2646 - iou_score: 0.7173 - f1-score: 0.8333For batch 170, tr_loss is    0.26.\n",
      "172/232 [=====================>........] - ETA: 52s - loss: 0.2647 - iou_score: 0.7172 - f1-score: 0.8332For batch 171, tr_loss is    0.26.\n",
      "173/232 [=====================>........] - ETA: 51s - loss: 0.2644 - iou_score: 0.7174 - f1-score: 0.8333For batch 172, tr_loss is    0.26.\n",
      "174/232 [=====================>........] - ETA: 50s - loss: 0.2643 - iou_score: 0.7176 - f1-score: 0.8335For batch 173, tr_loss is    0.26.\n",
      "175/232 [=====================>........] - ETA: 49s - loss: 0.2643 - iou_score: 0.7175 - f1-score: 0.8334For batch 174, tr_loss is    0.26.\n",
      "176/232 [=====================>........] - ETA: 48s - loss: 0.2645 - iou_score: 0.7172 - f1-score: 0.8332For batch 175, tr_loss is    0.26.\n",
      "177/232 [=====================>........] - ETA: 47s - loss: 0.2642 - iou_score: 0.7178 - f1-score: 0.8336For batch 176, tr_loss is    0.26.\n",
      "178/232 [======================>.......] - ETA: 46s - loss: 0.2640 - iou_score: 0.7181 - f1-score: 0.8338For batch 177, tr_loss is    0.26.\n",
      "179/232 [======================>.......] - ETA: 46s - loss: 0.2640 - iou_score: 0.7181 - f1-score: 0.8338For batch 178, tr_loss is    0.26.\n",
      "180/232 [======================>.......] - ETA: 45s - loss: 0.2640 - iou_score: 0.7179 - f1-score: 0.8337For batch 179, tr_loss is    0.26.\n",
      "181/232 [======================>.......] - ETA: 44s - loss: 0.2641 - iou_score: 0.7178 - f1-score: 0.8337For batch 180, tr_loss is    0.26.\n",
      "182/232 [======================>.......] - ETA: 43s - loss: 0.2641 - iou_score: 0.7178 - f1-score: 0.8337For batch 181, tr_loss is    0.26.\n",
      "183/232 [======================>.......] - ETA: 42s - loss: 0.2640 - iou_score: 0.7179 - f1-score: 0.8337For batch 182, tr_loss is    0.26.\n",
      "184/232 [======================>.......] - ETA: 41s - loss: 0.2636 - iou_score: 0.7184 - f1-score: 0.8341For batch 183, tr_loss is    0.26.\n",
      "185/232 [======================>.......] - ETA: 40s - loss: 0.2637 - iou_score: 0.7184 - f1-score: 0.8340For batch 184, tr_loss is    0.26.\n",
      "186/232 [=======================>......] - ETA: 39s - loss: 0.2638 - iou_score: 0.7183 - f1-score: 0.8340For batch 185, tr_loss is    0.26.\n",
      "187/232 [=======================>......] - ETA: 38s - loss: 0.2634 - iou_score: 0.7188 - f1-score: 0.8343For batch 186, tr_loss is    0.26.\n",
      "188/232 [=======================>......] - ETA: 38s - loss: 0.2633 - iou_score: 0.7188 - f1-score: 0.8343For batch 187, tr_loss is    0.26.\n",
      "189/232 [=======================>......] - ETA: 37s - loss: 0.2632 - iou_score: 0.7190 - f1-score: 0.8344For batch 188, tr_loss is    0.26.\n",
      "190/232 [=======================>......] - ETA: 36s - loss: 0.2631 - iou_score: 0.7191 - f1-score: 0.8345For batch 189, tr_loss is    0.26.\n",
      "191/232 [=======================>......] - ETA: 35s - loss: 0.2631 - iou_score: 0.7190 - f1-score: 0.8345For batch 190, tr_loss is    0.26.\n",
      "192/232 [=======================>......] - ETA: 34s - loss: 0.2633 - iou_score: 0.7187 - f1-score: 0.8343For batch 191, tr_loss is    0.26.\n",
      "193/232 [=======================>......] - ETA: 33s - loss: 0.2636 - iou_score: 0.7183 - f1-score: 0.8340For batch 192, tr_loss is    0.26.\n",
      "194/232 [========================>.....] - ETA: 32s - loss: 0.2635 - iou_score: 0.7183 - f1-score: 0.8340For batch 193, tr_loss is    0.26.\n",
      "195/232 [========================>.....] - ETA: 31s - loss: 0.2634 - iou_score: 0.7183 - f1-score: 0.8340For batch 194, tr_loss is    0.26.\n",
      "196/232 [========================>.....] - ETA: 31s - loss: 0.2633 - iou_score: 0.7183 - f1-score: 0.8340For batch 195, tr_loss is    0.26.\n",
      "197/232 [========================>.....] - ETA: 30s - loss: 0.2633 - iou_score: 0.7183 - f1-score: 0.8340For batch 196, tr_loss is    0.26.\n",
      "198/232 [========================>.....] - ETA: 29s - loss: 0.2630 - iou_score: 0.7187 - f1-score: 0.8343For batch 197, tr_loss is    0.26.\n",
      "199/232 [========================>.....] - ETA: 28s - loss: 0.2629 - iou_score: 0.7188 - f1-score: 0.8343For batch 198, tr_loss is    0.26.\n",
      "200/232 [========================>.....] - ETA: 27s - loss: 0.2625 - iou_score: 0.7192 - f1-score: 0.8346For batch 199, tr_loss is    0.26.\n",
      "201/232 [========================>.....] - ETA: 26s - loss: 0.2627 - iou_score: 0.7190 - f1-score: 0.8345For batch 200, tr_loss is    0.26.\n",
      "202/232 [=========================>....] - ETA: 25s - loss: 0.2626 - iou_score: 0.7190 - f1-score: 0.8345For batch 201, tr_loss is    0.26.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/232 [=========================>....] - ETA: 25s - loss: 0.2624 - iou_score: 0.7192 - f1-score: 0.8346For batch 202, tr_loss is    0.26.\n",
      "204/232 [=========================>....] - ETA: 24s - loss: 0.2620 - iou_score: 0.7196 - f1-score: 0.8349For batch 203, tr_loss is    0.26.\n",
      "205/232 [=========================>....] - ETA: 23s - loss: 0.2620 - iou_score: 0.7195 - f1-score: 0.8348For batch 204, tr_loss is    0.26.\n",
      "206/232 [=========================>....] - ETA: 22s - loss: 0.2620 - iou_score: 0.7195 - f1-score: 0.8348For batch 205, tr_loss is    0.26.\n",
      "207/232 [=========================>....] - ETA: 21s - loss: 0.2620 - iou_score: 0.7196 - f1-score: 0.8349For batch 206, tr_loss is    0.26.\n",
      "208/232 [=========================>....] - ETA: 20s - loss: 0.2619 - iou_score: 0.7196 - f1-score: 0.8349For batch 207, tr_loss is    0.26.\n",
      "209/232 [==========================>...] - ETA: 19s - loss: 0.2620 - iou_score: 0.7195 - f1-score: 0.8348For batch 208, tr_loss is    0.26.\n",
      "210/232 [==========================>...] - ETA: 18s - loss: 0.2623 - iou_score: 0.7191 - f1-score: 0.8346For batch 209, tr_loss is    0.26.\n",
      "211/232 [==========================>...] - ETA: 18s - loss: 0.2622 - iou_score: 0.7193 - f1-score: 0.8347For batch 210, tr_loss is    0.26.\n",
      "212/232 [==========================>...] - ETA: 17s - loss: 0.2619 - iou_score: 0.7196 - f1-score: 0.8349For batch 211, tr_loss is    0.26.\n",
      "213/232 [==========================>...] - ETA: 16s - loss: 0.2621 - iou_score: 0.7195 - f1-score: 0.8348For batch 212, tr_loss is    0.26.\n",
      "214/232 [==========================>...] - ETA: 15s - loss: 0.2619 - iou_score: 0.7196 - f1-score: 0.8349For batch 213, tr_loss is    0.26.\n",
      "215/232 [==========================>...] - ETA: 14s - loss: 0.2616 - iou_score: 0.7201 - f1-score: 0.8352For batch 214, tr_loss is    0.26.\n",
      "216/232 [==========================>...] - ETA: 13s - loss: 0.2613 - iou_score: 0.7203 - f1-score: 0.8354For batch 215, tr_loss is    0.26.\n",
      "217/232 [===========================>..] - ETA: 12s - loss: 0.2613 - iou_score: 0.7202 - f1-score: 0.8353For batch 216, tr_loss is    0.26.\n",
      "218/232 [===========================>..] - ETA: 11s - loss: 0.2613 - iou_score: 0.7202 - f1-score: 0.8353For batch 217, tr_loss is    0.26.\n",
      "219/232 [===========================>..] - ETA: 11s - loss: 0.2618 - iou_score: 0.7196 - f1-score: 0.8349For batch 218, tr_loss is    0.26.\n",
      "220/232 [===========================>..] - ETA: 10s - loss: 0.2618 - iou_score: 0.7195 - f1-score: 0.8348For batch 219, tr_loss is    0.26.\n",
      "221/232 [===========================>..] - ETA: 9s - loss: 0.2619 - iou_score: 0.7193 - f1-score: 0.8347 For batch 220, tr_loss is    0.26.\n",
      "222/232 [===========================>..] - ETA: 8s - loss: 0.2617 - iou_score: 0.7195 - f1-score: 0.8348For batch 221, tr_loss is    0.26.\n",
      "223/232 [===========================>..] - ETA: 7s - loss: 0.2617 - iou_score: 0.7193 - f1-score: 0.8347For batch 222, tr_loss is    0.26.\n",
      "224/232 [===========================>..] - ETA: 6s - loss: 0.2615 - iou_score: 0.7196 - f1-score: 0.8349For batch 223, tr_loss is    0.26.\n",
      "225/232 [============================>.] - ETA: 5s - loss: 0.2613 - iou_score: 0.7199 - f1-score: 0.8351For batch 224, tr_loss is    0.26.\n",
      "226/232 [============================>.] - ETA: 5s - loss: 0.2612 - iou_score: 0.7198 - f1-score: 0.8351For batch 225, tr_loss is    0.26.\n",
      "227/232 [============================>.] - ETA: 4s - loss: 0.2611 - iou_score: 0.7200 - f1-score: 0.8352For batch 226, tr_loss is    0.26.\n",
      "228/232 [============================>.] - ETA: 3s - loss: 0.2613 - iou_score: 0.7198 - f1-score: 0.8351For batch 227, tr_loss is    0.26.\n",
      "229/232 [============================>.] - ETA: 2s - loss: 0.2611 - iou_score: 0.7200 - f1-score: 0.8352For batch 228, tr_loss is    0.26.\n",
      "230/232 [============================>.] - ETA: 1s - loss: 0.2615 - iou_score: 0.7196 - f1-score: 0.8349For batch 229, tr_loss is    0.26.\n",
      "231/232 [============================>.] - ETA: 0s - loss: 0.2616 - iou_score: 0.7195 - f1-score: 0.8348For batch 230, tr_loss is    0.26.\n",
      "232/232 [==============================] - ETA: 0s - loss: 0.2614 - iou_score: 0.7198 - f1-score: 0.8350For batch 231, tr_loss is    0.26.\n",
      "For batch 0, vl_loss is    0.41.\n",
      "For batch 1, vl_loss is    0.36.\n",
      "For batch 2, vl_loss is    0.38.\n",
      "For batch 3, vl_loss is    0.38.\n",
      "For batch 4, vl_loss is    0.40.\n",
      "For batch 5, vl_loss is    0.39.\n",
      "For batch 6, vl_loss is    0.40.\n",
      "For batch 7, vl_loss is    0.40.\n",
      "For batch 8, vl_loss is    0.39.\n",
      "For batch 9, vl_loss is    0.38.\n",
      "For batch 10, vl_loss is    0.38.\n",
      "For batch 11, vl_loss is    0.39.\n",
      "For batch 12, vl_loss is    0.39.\n",
      "For batch 13, vl_loss is    0.39.\n",
      "For batch 14, vl_loss is    0.39.\n",
      "For batch 15, vl_loss is    0.38.\n",
      "For batch 16, vl_loss is    0.38.\n",
      "For batch 17, vl_loss is    0.39.\n",
      "For batch 18, vl_loss is    0.39.\n",
      "For batch 19, vl_loss is    0.39.\n",
      "For batch 20, vl_loss is    0.38.\n",
      "For batch 21, vl_loss is    0.39.\n",
      "For batch 22, vl_loss is    0.38.\n",
      "For batch 23, vl_loss is    0.38.\n",
      "For batch 24, vl_loss is    0.38.\n",
      "For batch 25, vl_loss is    0.38.\n",
      "For batch 26, vl_loss is    0.38.\n",
      "For batch 27, vl_loss is    0.38.\n",
      "For batch 28, vl_loss is    0.39.\n",
      "For batch 29, vl_loss is    0.39.\n",
      "For batch 30, vl_loss is    0.39.\n",
      "For batch 31, vl_loss is    0.39.\n",
      "For batch 32, vl_loss is    0.39.\n",
      "For batch 33, vl_loss is    0.39.\n",
      "For batch 34, vl_loss is    0.39.\n",
      "For batch 35, vl_loss is    0.39.\n",
      "For batch 36, vl_loss is    0.39.\n",
      "For batch 37, vl_loss is    0.39.\n",
      "For batch 38, vl_loss is    0.38.\n",
      "For batch 39, vl_loss is    0.38.\n",
      "For batch 40, vl_loss is    0.39.\n",
      "For batch 41, vl_loss is    0.39.\n",
      "For batch 42, vl_loss is    0.39.\n",
      "For batch 43, vl_loss is    0.39.\n",
      "For batch 44, vl_loss is    0.39.\n",
      "For batch 45, vl_loss is    0.39.\n",
      "For batch 46, vl_loss is    0.39.\n",
      "For batch 47, vl_loss is    0.39.\n",
      "For batch 48, vl_loss is    0.39.\n",
      "For batch 49, vl_loss is    0.39.\n",
      "For batch 50, vl_loss is    0.39.\n",
      "For batch 51, vl_loss is    0.39.\n",
      "For batch 52, vl_loss is    0.39.\n",
      "For batch 53, vl_loss is    0.39.\n",
      "For batch 54, vl_loss is    0.39.\n",
      "For batch 55, vl_loss is    0.39.\n",
      "For batch 56, vl_loss is    0.39.\n",
      "For batch 57, vl_loss is    0.39.\n",
      "For batch 58, vl_loss is    0.39.\n",
      "For batch 59, vl_loss is    0.39.\n",
      "For batch 60, vl_loss is    0.39.\n",
      "For batch 61, vl_loss is    0.39.\n",
      "For batch 62, vl_loss is    0.39.\n",
      "For batch 63, vl_loss is    0.39.\n",
      "For batch 64, vl_loss is    0.39.\n",
      "For batch 65, vl_loss is    0.39.\n",
      "For batch 66, vl_loss is    0.38.\n",
      "For batch 67, vl_loss is    0.38.\n",
      "232/232 [==============================] - 202s 866ms/step - loss: 0.2614 - iou_score: 0.7198 - f1-score: 0.8350 - val_loss: 0.3848 - val_iou_score: 0.6266 - val_f1-score: 0.7680\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.36098\n",
      "The average loss for epoch 9 is    0.26 \n",
      "Epoch 11/200\n",
      "  1/232 [..............................] - ETA: 11:18 - loss: 0.2121 - iou_score: 0.7791 - f1-score: 0.8740For batch 0, tr_loss is    0.21.\n",
      "  2/232 [..............................] - ETA: 4:06 - loss: 0.2082 - iou_score: 0.7747 - f1-score: 0.8722 For batch 1, tr_loss is    0.21.\n",
      "  3/232 [..............................] - ETA: 4:57 - loss: 0.2311 - iou_score: 0.7443 - f1-score: 0.8520For batch 2, tr_loss is    0.23.\n",
      "  4/232 [..............................] - ETA: 4:55 - loss: 0.2352 - iou_score: 0.7458 - f1-score: 0.8533For batch 3, tr_loss is    0.24.\n",
      "  5/232 [..............................] - ETA: 4:31 - loss: 0.2440 - iou_score: 0.7355 - f1-score: 0.8461For batch 4, tr_loss is    0.24.\n",
      "  6/232 [..............................] - ETA: 4:40 - loss: 0.2533 - iou_score: 0.7275 - f1-score: 0.8401For batch 5, tr_loss is    0.25.\n",
      "  7/232 [..............................] - ETA: 4:34 - loss: 0.2639 - iou_score: 0.7177 - f1-score: 0.8336For batch 6, tr_loss is    0.26.\n",
      "  8/232 [>.............................] - ETA: 4:29 - loss: 0.2681 - iou_score: 0.7111 - f1-score: 0.8292For batch 7, tr_loss is    0.27.\n",
      "  9/232 [>.............................] - ETA: 4:42 - loss: 0.2601 - iou_score: 0.7216 - f1-score: 0.8362For batch 8, tr_loss is    0.26.\n",
      " 10/232 [>.............................] - ETA: 4:39 - loss: 0.2592 - iou_score: 0.7214 - f1-score: 0.8361For batch 9, tr_loss is    0.26.\n",
      " 11/232 [>.............................] - ETA: 4:29 - loss: 0.2574 - iou_score: 0.7221 - f1-score: 0.8368For batch 10, tr_loss is    0.26.\n",
      " 12/232 [>.............................] - ETA: 4:23 - loss: 0.2524 - iou_score: 0.7300 - f1-score: 0.8420For batch 11, tr_loss is    0.25.\n",
      " 13/232 [>.............................] - ETA: 4:14 - loss: 0.2518 - iou_score: 0.7316 - f1-score: 0.8429For batch 12, tr_loss is    0.25.\n",
      " 14/232 [>.............................] - ETA: 4:11 - loss: 0.2491 - iou_score: 0.7344 - f1-score: 0.8449For batch 13, tr_loss is    0.25.\n",
      " 15/232 [>.............................] - ETA: 4:07 - loss: 0.2461 - iou_score: 0.7379 - f1-score: 0.8473For batch 14, tr_loss is    0.25.\n",
      " 16/232 [=>............................] - ETA: 3:57 - loss: 0.2447 - iou_score: 0.7388 - f1-score: 0.8480For batch 15, tr_loss is    0.24.\n",
      " 17/232 [=>............................] - ETA: 3:50 - loss: 0.2420 - iou_score: 0.7424 - f1-score: 0.8504For batch 16, tr_loss is    0.24.\n",
      " 18/232 [=>............................] - ETA: 3:51 - loss: 0.2435 - iou_score: 0.7406 - f1-score: 0.8493For batch 17, tr_loss is    0.24.\n",
      " 19/232 [=>............................] - ETA: 3:49 - loss: 0.2455 - iou_score: 0.7380 - f1-score: 0.8476For batch 18, tr_loss is    0.25.\n",
      " 20/232 [=>............................] - ETA: 3:47 - loss: 0.2432 - iou_score: 0.7408 - f1-score: 0.8495For batch 19, tr_loss is    0.24.\n",
      " 21/232 [=>............................] - ETA: 3:40 - loss: 0.2474 - iou_score: 0.7381 - f1-score: 0.8475For batch 20, tr_loss is    0.25.\n",
      " 22/232 [=>............................] - ETA: 3:39 - loss: 0.2490 - iou_score: 0.7352 - f1-score: 0.8455For batch 21, tr_loss is    0.25.\n",
      " 23/232 [=>............................] - ETA: 3:34 - loss: 0.2499 - iou_score: 0.7336 - f1-score: 0.8445For batch 22, tr_loss is    0.25.\n",
      " 24/232 [==>...........................] - ETA: 3:33 - loss: 0.2495 - iou_score: 0.7337 - f1-score: 0.8446For batch 23, tr_loss is    0.25.\n",
      " 25/232 [==>...........................] - ETA: 3:32 - loss: 0.2530 - iou_score: 0.7301 - f1-score: 0.8421For batch 24, tr_loss is    0.25.\n",
      " 26/232 [==>...........................] - ETA: 3:31 - loss: 0.2535 - iou_score: 0.7293 - f1-score: 0.8415For batch 25, tr_loss is    0.25.\n",
      " 27/232 [==>...........................] - ETA: 3:26 - loss: 0.2513 - iou_score: 0.7319 - f1-score: 0.8432For batch 26, tr_loss is    0.25.\n",
      " 28/232 [==>...........................] - ETA: 3:27 - loss: 0.2513 - iou_score: 0.7314 - f1-score: 0.8429For batch 27, tr_loss is    0.25.\n",
      " 29/232 [==>...........................] - ETA: 3:26 - loss: 0.2507 - iou_score: 0.7302 - f1-score: 0.8422For batch 28, tr_loss is    0.25.\n",
      " 30/232 [==>...........................] - ETA: 3:25 - loss: 0.2495 - iou_score: 0.7319 - f1-score: 0.8432For batch 29, tr_loss is    0.25.\n",
      " 31/232 [===>..........................] - ETA: 3:22 - loss: 0.2487 - iou_score: 0.7328 - f1-score: 0.8439For batch 30, tr_loss is    0.25.\n",
      " 32/232 [===>..........................] - ETA: 3:19 - loss: 0.2483 - iou_score: 0.7333 - f1-score: 0.8443For batch 31, tr_loss is    0.25.\n",
      " 33/232 [===>..........................] - ETA: 3:18 - loss: 0.2503 - iou_score: 0.7306 - f1-score: 0.8425For batch 32, tr_loss is    0.25.\n",
      " 34/232 [===>..........................] - ETA: 3:17 - loss: 0.2500 - iou_score: 0.7311 - f1-score: 0.8429For batch 33, tr_loss is    0.25.\n",
      " 35/232 [===>..........................] - ETA: 3:13 - loss: 0.2515 - iou_score: 0.7292 - f1-score: 0.8416For batch 34, tr_loss is    0.25.\n",
      " 36/232 [===>..........................] - ETA: 3:10 - loss: 0.2513 - iou_score: 0.7293 - f1-score: 0.8417For batch 35, tr_loss is    0.25.\n",
      " 37/232 [===>..........................] - ETA: 3:10 - loss: 0.2514 - iou_score: 0.7285 - f1-score: 0.8412For batch 36, tr_loss is    0.25.\n",
      " 38/232 [===>..........................] - ETA: 3:09 - loss: 0.2538 - iou_score: 0.7264 - f1-score: 0.8398For batch 37, tr_loss is    0.25.\n",
      " 39/232 [====>.........................] - ETA: 3:07 - loss: 0.2576 - iou_score: 0.7234 - f1-score: 0.8376For batch 38, tr_loss is    0.26.\n",
      " 40/232 [====>.........................] - ETA: 3:07 - loss: 0.2583 - iou_score: 0.7226 - f1-score: 0.8371For batch 39, tr_loss is    0.26.\n",
      " 41/232 [====>.........................] - ETA: 3:06 - loss: 0.2593 - iou_score: 0.7212 - f1-score: 0.8361For batch 40, tr_loss is    0.26.\n",
      " 42/232 [====>.........................] - ETA: 3:05 - loss: 0.2599 - iou_score: 0.7199 - f1-score: 0.8353For batch 41, tr_loss is    0.26.\n",
      " 43/232 [====>.........................] - ETA: 3:03 - loss: 0.2594 - iou_score: 0.7207 - f1-score: 0.8358For batch 42, tr_loss is    0.26.\n",
      " 44/232 [====>.........................] - ETA: 3:02 - loss: 0.2619 - iou_score: 0.7181 - f1-score: 0.8338For batch 43, tr_loss is    0.26.\n",
      " 45/232 [====>.........................] - ETA: 3:01 - loss: 0.2633 - iou_score: 0.7171 - f1-score: 0.8332For batch 44, tr_loss is    0.26.\n",
      " 46/232 [====>.........................] - ETA: 2:58 - loss: 0.2633 - iou_score: 0.7174 - f1-score: 0.8334For batch 45, tr_loss is    0.26.\n",
      " 47/232 [=====>........................] - ETA: 2:59 - loss: 0.2632 - iou_score: 0.7178 - f1-score: 0.8337For batch 46, tr_loss is    0.26.\n",
      " 48/232 [=====>........................] - ETA: 2:56 - loss: 0.2626 - iou_score: 0.7183 - f1-score: 0.8340For batch 47, tr_loss is    0.26.\n",
      " 49/232 [=====>........................] - ETA: 2:56 - loss: 0.2630 - iou_score: 0.7181 - f1-score: 0.8339For batch 48, tr_loss is    0.26.\n",
      " 50/232 [=====>........................] - ETA: 2:53 - loss: 0.2627 - iou_score: 0.7185 - f1-score: 0.8342For batch 49, tr_loss is    0.26.\n",
      " 51/232 [=====>........................] - ETA: 2:53 - loss: 0.2639 - iou_score: 0.7176 - f1-score: 0.8336For batch 50, tr_loss is    0.26.\n",
      " 52/232 [=====>........................] - ETA: 2:51 - loss: 0.2669 - iou_score: 0.7152 - f1-score: 0.8318For batch 51, tr_loss is    0.27.\n",
      " 53/232 [=====>........................] - ETA: 2:48 - loss: 0.2661 - iou_score: 0.7163 - f1-score: 0.8326For batch 52, tr_loss is    0.27.\n",
      " 54/232 [=====>........................] - ETA: 2:48 - loss: 0.2662 - iou_score: 0.7159 - f1-score: 0.8323For batch 53, tr_loss is    0.27.\n",
      " 55/232 [======>.......................] - ETA: 2:47 - loss: 0.2660 - iou_score: 0.7162 - f1-score: 0.8326For batch 54, tr_loss is    0.27.\n",
      " 56/232 [======>.......................] - ETA: 2:46 - loss: 0.2655 - iou_score: 0.7167 - f1-score: 0.8330For batch 55, tr_loss is    0.27.\n",
      " 57/232 [======>.......................] - ETA: 2:43 - loss: 0.2656 - iou_score: 0.7164 - f1-score: 0.8328For batch 56, tr_loss is    0.27.\n",
      " 58/232 [======>.......................] - ETA: 2:43 - loss: 0.2649 - iou_score: 0.7174 - f1-score: 0.8334For batch 57, tr_loss is    0.26.\n",
      " 59/232 [======>.......................] - ETA: 2:42 - loss: 0.2646 - iou_score: 0.7177 - f1-score: 0.8336For batch 58, tr_loss is    0.26.\n",
      " 60/232 [======>.......................] - ETA: 2:40 - loss: 0.2660 - iou_score: 0.7162 - f1-score: 0.8326For batch 59, tr_loss is    0.27.\n",
      " 61/232 [======>.......................] - ETA: 2:39 - loss: 0.2679 - iou_score: 0.7145 - f1-score: 0.8313For batch 60, tr_loss is    0.27.\n",
      " 62/232 [=======>......................] - ETA: 2:38 - loss: 0.2686 - iou_score: 0.7137 - f1-score: 0.8307For batch 61, tr_loss is    0.27.\n",
      " 63/232 [=======>......................] - ETA: 2:38 - loss: 0.2678 - iou_score: 0.7146 - f1-score: 0.8313For batch 62, tr_loss is    0.27.\n",
      " 64/232 [=======>......................] - ETA: 2:37 - loss: 0.2677 - iou_score: 0.7146 - f1-score: 0.8313For batch 63, tr_loss is    0.27.\n",
      " 65/232 [=======>......................] - ETA: 2:35 - loss: 0.2677 - iou_score: 0.7147 - f1-score: 0.8314For batch 64, tr_loss is    0.27.\n",
      " 66/232 [=======>......................] - ETA: 2:34 - loss: 0.2678 - iou_score: 0.7144 - f1-score: 0.8312For batch 65, tr_loss is    0.27.\n",
      " 67/232 [=======>......................] - ETA: 2:34 - loss: 0.2671 - iou_score: 0.7153 - f1-score: 0.8319For batch 66, tr_loss is    0.27.\n",
      " 68/232 [=======>......................] - ETA: 2:32 - loss: 0.2668 - iou_score: 0.7158 - f1-score: 0.8322For batch 67, tr_loss is    0.27.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 69/232 [=======>......................] - ETA: 2:30 - loss: 0.2669 - iou_score: 0.7157 - f1-score: 0.8322For batch 68, tr_loss is    0.27.\n",
      " 70/232 [========>.....................] - ETA: 2:30 - loss: 0.2664 - iou_score: 0.7161 - f1-score: 0.8324For batch 69, tr_loss is    0.27.\n",
      " 71/232 [========>.....................] - ETA: 2:29 - loss: 0.2656 - iou_score: 0.7171 - f1-score: 0.8331For batch 70, tr_loss is    0.27.\n",
      " 72/232 [========>.....................] - ETA: 2:28 - loss: 0.2649 - iou_score: 0.7177 - f1-score: 0.8335For batch 71, tr_loss is    0.26.\n",
      " 73/232 [========>.....................] - ETA: 2:26 - loss: 0.2651 - iou_score: 0.7171 - f1-score: 0.8332For batch 72, tr_loss is    0.27.\n",
      " 74/232 [========>.....................] - ETA: 2:26 - loss: 0.2643 - iou_score: 0.7182 - f1-score: 0.8338For batch 73, tr_loss is    0.26.\n",
      " 75/232 [========>.....................] - ETA: 2:25 - loss: 0.2646 - iou_score: 0.7182 - f1-score: 0.8339For batch 74, tr_loss is    0.26.\n",
      " 76/232 [========>.....................] - ETA: 2:24 - loss: 0.2639 - iou_score: 0.7185 - f1-score: 0.8341For batch 75, tr_loss is    0.26.\n",
      " 77/232 [========>.....................] - ETA: 2:23 - loss: 0.2629 - iou_score: 0.7196 - f1-score: 0.8348For batch 76, tr_loss is    0.26.\n",
      " 78/232 [=========>....................] - ETA: 2:22 - loss: 0.2628 - iou_score: 0.7195 - f1-score: 0.8348For batch 77, tr_loss is    0.26.\n",
      " 79/232 [=========>....................] - ETA: 2:20 - loss: 0.2622 - iou_score: 0.7203 - f1-score: 0.8353For batch 78, tr_loss is    0.26.\n",
      " 80/232 [=========>....................] - ETA: 2:19 - loss: 0.2620 - iou_score: 0.7204 - f1-score: 0.8354For batch 79, tr_loss is    0.26.\n",
      " 81/232 [=========>....................] - ETA: 2:18 - loss: 0.2623 - iou_score: 0.7201 - f1-score: 0.8352For batch 80, tr_loss is    0.26.\n",
      " 82/232 [=========>....................] - ETA: 2:16 - loss: 0.2625 - iou_score: 0.7198 - f1-score: 0.8350For batch 81, tr_loss is    0.26.\n",
      " 83/232 [=========>....................] - ETA: 2:16 - loss: 0.2630 - iou_score: 0.7190 - f1-score: 0.8344For batch 82, tr_loss is    0.26.\n",
      " 84/232 [=========>....................] - ETA: 2:14 - loss: 0.2633 - iou_score: 0.7185 - f1-score: 0.8341For batch 83, tr_loss is    0.26.\n",
      " 85/232 [=========>....................] - ETA: 2:13 - loss: 0.2637 - iou_score: 0.7183 - f1-score: 0.8340For batch 84, tr_loss is    0.26.\n",
      " 86/232 [==========>...................] - ETA: 2:13 - loss: 0.2642 - iou_score: 0.7175 - f1-score: 0.8335For batch 85, tr_loss is    0.26.\n",
      " 87/232 [==========>...................] - ETA: 2:12 - loss: 0.2640 - iou_score: 0.7177 - f1-score: 0.8337For batch 86, tr_loss is    0.26.\n",
      " 88/232 [==========>...................] - ETA: 2:10 - loss: 0.2645 - iou_score: 0.7170 - f1-score: 0.8332For batch 87, tr_loss is    0.26.\n",
      " 89/232 [==========>...................] - ETA: 2:10 - loss: 0.2640 - iou_score: 0.7178 - f1-score: 0.8337For batch 88, tr_loss is    0.26.\n",
      " 90/232 [==========>...................] - ETA: 2:09 - loss: 0.2635 - iou_score: 0.7182 - f1-score: 0.8340For batch 89, tr_loss is    0.26.\n",
      " 91/232 [==========>...................] - ETA: 2:08 - loss: 0.2638 - iou_score: 0.7185 - f1-score: 0.8342For batch 90, tr_loss is    0.26.\n",
      " 92/232 [==========>...................] - ETA: 2:07 - loss: 0.2637 - iou_score: 0.7187 - f1-score: 0.8343For batch 91, tr_loss is    0.26.\n",
      " 93/232 [===========>..................] - ETA: 2:06 - loss: 0.2642 - iou_score: 0.7176 - f1-score: 0.8335For batch 92, tr_loss is    0.26.\n",
      " 94/232 [===========>..................] - ETA: 2:06 - loss: 0.2636 - iou_score: 0.7184 - f1-score: 0.8341For batch 93, tr_loss is    0.26.\n",
      " 95/232 [===========>..................] - ETA: 2:04 - loss: 0.2639 - iou_score: 0.7181 - f1-score: 0.8338For batch 94, tr_loss is    0.26.\n",
      " 96/232 [===========>..................] - ETA: 2:03 - loss: 0.2638 - iou_score: 0.7182 - f1-score: 0.8339For batch 95, tr_loss is    0.26.\n",
      " 97/232 [===========>..................] - ETA: 2:02 - loss: 0.2641 - iou_score: 0.7178 - f1-score: 0.8337For batch 96, tr_loss is    0.26.\n",
      " 98/232 [===========>..................] - ETA: 2:01 - loss: 0.2640 - iou_score: 0.7177 - f1-score: 0.8336For batch 97, tr_loss is    0.26.\n",
      " 99/232 [===========>..................] - ETA: 2:00 - loss: 0.2631 - iou_score: 0.7188 - f1-score: 0.8344For batch 98, tr_loss is    0.26.\n",
      "100/232 [===========>..................] - ETA: 1:59 - loss: 0.2626 - iou_score: 0.7195 - f1-score: 0.8348For batch 99, tr_loss is    0.26.\n",
      "101/232 [============>.................] - ETA: 1:59 - loss: 0.2619 - iou_score: 0.7204 - f1-score: 0.8354For batch 100, tr_loss is    0.26.\n",
      "102/232 [============>.................] - ETA: 1:58 - loss: 0.2620 - iou_score: 0.7205 - f1-score: 0.8355For batch 101, tr_loss is    0.26.\n",
      "103/232 [============>.................] - ETA: 1:56 - loss: 0.2621 - iou_score: 0.7205 - f1-score: 0.8355For batch 102, tr_loss is    0.26.\n",
      "104/232 [============>.................] - ETA: 1:55 - loss: 0.2618 - iou_score: 0.7208 - f1-score: 0.8357For batch 103, tr_loss is    0.26.\n",
      "105/232 [============>.................] - ETA: 1:55 - loss: 0.2611 - iou_score: 0.7216 - f1-score: 0.8362For batch 104, tr_loss is    0.26.\n",
      "106/232 [============>.................] - ETA: 1:54 - loss: 0.2603 - iou_score: 0.7225 - f1-score: 0.8368For batch 105, tr_loss is    0.26.\n",
      "107/232 [============>.................] - ETA: 1:53 - loss: 0.2607 - iou_score: 0.7223 - f1-score: 0.8367For batch 106, tr_loss is    0.26.\n",
      "108/232 [============>.................] - ETA: 1:52 - loss: 0.2613 - iou_score: 0.7215 - f1-score: 0.8361For batch 107, tr_loss is    0.26.\n",
      "109/232 [=============>................] - ETA: 1:51 - loss: 0.2607 - iou_score: 0.7220 - f1-score: 0.8365For batch 108, tr_loss is    0.26.\n",
      "110/232 [=============>................] - ETA: 1:50 - loss: 0.2600 - iou_score: 0.7229 - f1-score: 0.8371For batch 109, tr_loss is    0.26.\n",
      "111/232 [=============>................] - ETA: 1:49 - loss: 0.2601 - iou_score: 0.7227 - f1-score: 0.8370For batch 110, tr_loss is    0.26.\n",
      "112/232 [=============>................] - ETA: 1:49 - loss: 0.2604 - iou_score: 0.7224 - f1-score: 0.8368For batch 111, tr_loss is    0.26.\n",
      "113/232 [=============>................] - ETA: 1:48 - loss: 0.2608 - iou_score: 0.7221 - f1-score: 0.8365For batch 112, tr_loss is    0.26.\n",
      "114/232 [=============>................] - ETA: 1:47 - loss: 0.2603 - iou_score: 0.7227 - f1-score: 0.8369For batch 113, tr_loss is    0.26.\n",
      "115/232 [=============>................] - ETA: 1:46 - loss: 0.2599 - iou_score: 0.7231 - f1-score: 0.8372For batch 114, tr_loss is    0.26.\n",
      "116/232 [==============>...............] - ETA: 1:45 - loss: 0.2596 - iou_score: 0.7234 - f1-score: 0.8374For batch 115, tr_loss is    0.26.\n",
      "117/232 [==============>...............] - ETA: 1:44 - loss: 0.2593 - iou_score: 0.7235 - f1-score: 0.8375For batch 116, tr_loss is    0.26.\n",
      "118/232 [==============>...............] - ETA: 1:43 - loss: 0.2588 - iou_score: 0.7243 - f1-score: 0.8380For batch 117, tr_loss is    0.26.\n",
      "119/232 [==============>...............] - ETA: 1:43 - loss: 0.2586 - iou_score: 0.7245 - f1-score: 0.8382For batch 118, tr_loss is    0.26.\n",
      "120/232 [==============>...............] - ETA: 1:42 - loss: 0.2590 - iou_score: 0.7241 - f1-score: 0.8379For batch 119, tr_loss is    0.26.\n",
      "121/232 [==============>...............] - ETA: 1:41 - loss: 0.2584 - iou_score: 0.7247 - f1-score: 0.8383For batch 120, tr_loss is    0.26.\n",
      "122/232 [==============>...............] - ETA: 1:40 - loss: 0.2589 - iou_score: 0.7241 - f1-score: 0.8379For batch 121, tr_loss is    0.26.\n",
      "123/232 [==============>...............] - ETA: 1:39 - loss: 0.2585 - iou_score: 0.7244 - f1-score: 0.8381For batch 122, tr_loss is    0.26.\n",
      "124/232 [===============>..............] - ETA: 1:38 - loss: 0.2587 - iou_score: 0.7242 - f1-score: 0.8380For batch 123, tr_loss is    0.26.\n",
      "125/232 [===============>..............] - ETA: 1:38 - loss: 0.2588 - iou_score: 0.7239 - f1-score: 0.8378For batch 124, tr_loss is    0.26.\n",
      "126/232 [===============>..............] - ETA: 1:36 - loss: 0.2586 - iou_score: 0.7241 - f1-score: 0.8379For batch 125, tr_loss is    0.26.\n",
      "127/232 [===============>..............] - ETA: 1:35 - loss: 0.2584 - iou_score: 0.7243 - f1-score: 0.8381For batch 126, tr_loss is    0.26.\n",
      "128/232 [===============>..............] - ETA: 1:35 - loss: 0.2585 - iou_score: 0.7240 - f1-score: 0.8379For batch 127, tr_loss is    0.26.\n",
      "129/232 [===============>..............] - ETA: 1:34 - loss: 0.2585 - iou_score: 0.7239 - f1-score: 0.8378For batch 128, tr_loss is    0.26.\n",
      "130/232 [===============>..............] - ETA: 1:33 - loss: 0.2584 - iou_score: 0.7242 - f1-score: 0.8380For batch 129, tr_loss is    0.26.\n",
      "131/232 [===============>..............] - ETA: 1:32 - loss: 0.2592 - iou_score: 0.7236 - f1-score: 0.8376For batch 130, tr_loss is    0.26.\n",
      "132/232 [================>.............] - ETA: 1:31 - loss: 0.2596 - iou_score: 0.7233 - f1-score: 0.8374For batch 131, tr_loss is    0.26.\n",
      "133/232 [================>.............] - ETA: 1:30 - loss: 0.2592 - iou_score: 0.7236 - f1-score: 0.8376For batch 132, tr_loss is    0.26.\n",
      "134/232 [================>.............] - ETA: 1:29 - loss: 0.2597 - iou_score: 0.7228 - f1-score: 0.8370For batch 133, tr_loss is    0.26.\n",
      "135/232 [================>.............] - ETA: 1:28 - loss: 0.2593 - iou_score: 0.7231 - f1-score: 0.8372For batch 134, tr_loss is    0.26.\n",
      "136/232 [================>.............] - ETA: 1:27 - loss: 0.2595 - iou_score: 0.7226 - f1-score: 0.8369For batch 135, tr_loss is    0.26.\n",
      "137/232 [================>.............] - ETA: 1:26 - loss: 0.2598 - iou_score: 0.7223 - f1-score: 0.8367For batch 136, tr_loss is    0.26.\n",
      "138/232 [================>.............] - ETA: 1:25 - loss: 0.2600 - iou_score: 0.7220 - f1-score: 0.8365For batch 137, tr_loss is    0.26.\n",
      "139/232 [================>.............] - ETA: 1:24 - loss: 0.2598 - iou_score: 0.7220 - f1-score: 0.8365For batch 138, tr_loss is    0.26.\n",
      "140/232 [=================>............] - ETA: 1:23 - loss: 0.2598 - iou_score: 0.7221 - f1-score: 0.8367For batch 139, tr_loss is    0.26.\n",
      "141/232 [=================>............] - ETA: 1:22 - loss: 0.2605 - iou_score: 0.7211 - f1-score: 0.8359For batch 140, tr_loss is    0.26.\n",
      "142/232 [=================>............] - ETA: 1:21 - loss: 0.2603 - iou_score: 0.7212 - f1-score: 0.8359For batch 141, tr_loss is    0.26.\n",
      "143/232 [=================>............] - ETA: 1:20 - loss: 0.2600 - iou_score: 0.7216 - f1-score: 0.8362For batch 142, tr_loss is    0.26.\n",
      "144/232 [=================>............] - ETA: 1:19 - loss: 0.2599 - iou_score: 0.7215 - f1-score: 0.8362For batch 143, tr_loss is    0.26.\n",
      "145/232 [=================>............] - ETA: 1:18 - loss: 0.2599 - iou_score: 0.7215 - f1-score: 0.8362For batch 144, tr_loss is    0.26.\n",
      "146/232 [=================>............] - ETA: 1:17 - loss: 0.2600 - iou_score: 0.7212 - f1-score: 0.8360For batch 145, tr_loss is    0.26.\n",
      "147/232 [==================>...........] - ETA: 1:16 - loss: 0.2597 - iou_score: 0.7216 - f1-score: 0.8363For batch 146, tr_loss is    0.26.\n",
      "148/232 [==================>...........] - ETA: 1:15 - loss: 0.2602 - iou_score: 0.7211 - f1-score: 0.8359For batch 147, tr_loss is    0.26.\n",
      "149/232 [==================>...........] - ETA: 1:14 - loss: 0.2602 - iou_score: 0.7213 - f1-score: 0.8360For batch 148, tr_loss is    0.26.\n",
      "150/232 [==================>...........] - ETA: 1:13 - loss: 0.2608 - iou_score: 0.7205 - f1-score: 0.8355For batch 149, tr_loss is    0.26.\n",
      "151/232 [==================>...........] - ETA: 1:13 - loss: 0.2609 - iou_score: 0.7202 - f1-score: 0.8352For batch 150, tr_loss is    0.26.\n",
      "152/232 [==================>...........] - ETA: 1:12 - loss: 0.2604 - iou_score: 0.7207 - f1-score: 0.8356For batch 151, tr_loss is    0.26.\n",
      "153/232 [==================>...........] - ETA: 1:11 - loss: 0.2604 - iou_score: 0.7206 - f1-score: 0.8355For batch 152, tr_loss is    0.26.\n",
      "154/232 [==================>...........] - ETA: 1:10 - loss: 0.2601 - iou_score: 0.7209 - f1-score: 0.8357For batch 153, tr_loss is    0.26.\n",
      "155/232 [===================>..........] - ETA: 1:09 - loss: 0.2600 - iou_score: 0.7209 - f1-score: 0.8357For batch 154, tr_loss is    0.26.\n",
      "156/232 [===================>..........] - ETA: 1:08 - loss: 0.2600 - iou_score: 0.7207 - f1-score: 0.8356For batch 155, tr_loss is    0.26.\n",
      "157/232 [===================>..........] - ETA: 1:07 - loss: 0.2606 - iou_score: 0.7204 - f1-score: 0.8354For batch 156, tr_loss is    0.26.\n",
      "158/232 [===================>..........] - ETA: 1:06 - loss: 0.2603 - iou_score: 0.7207 - f1-score: 0.8356For batch 157, tr_loss is    0.26.\n",
      "159/232 [===================>..........] - ETA: 1:06 - loss: 0.2599 - iou_score: 0.7213 - f1-score: 0.8360For batch 158, tr_loss is    0.26.\n",
      "160/232 [===================>..........] - ETA: 1:04 - loss: 0.2598 - iou_score: 0.7212 - f1-score: 0.8360For batch 159, tr_loss is    0.26.\n",
      "161/232 [===================>..........] - ETA: 1:04 - loss: 0.2595 - iou_score: 0.7215 - f1-score: 0.8361For batch 160, tr_loss is    0.26.\n",
      "162/232 [===================>..........] - ETA: 1:02 - loss: 0.2593 - iou_score: 0.7216 - f1-score: 0.8362For batch 161, tr_loss is    0.26.\n",
      "163/232 [====================>.........] - ETA: 1:01 - loss: 0.2589 - iou_score: 0.7221 - f1-score: 0.8366For batch 162, tr_loss is    0.26.\n",
      "164/232 [====================>.........] - ETA: 1:01 - loss: 0.2591 - iou_score: 0.7220 - f1-score: 0.8365For batch 163, tr_loss is    0.26.\n",
      "165/232 [====================>.........] - ETA: 1:00 - loss: 0.2592 - iou_score: 0.7218 - f1-score: 0.8364For batch 164, tr_loss is    0.26.\n",
      "166/232 [====================>.........] - ETA: 59s - loss: 0.2590 - iou_score: 0.7220 - f1-score: 0.8365 For batch 165, tr_loss is    0.26.\n",
      "167/232 [====================>.........] - ETA: 58s - loss: 0.2588 - iou_score: 0.7222 - f1-score: 0.8367For batch 166, tr_loss is    0.26.\n",
      "168/232 [====================>.........] - ETA: 57s - loss: 0.2592 - iou_score: 0.7219 - f1-score: 0.8365For batch 167, tr_loss is    0.26.\n",
      "169/232 [====================>.........] - ETA: 56s - loss: 0.2596 - iou_score: 0.7215 - f1-score: 0.8362For batch 168, tr_loss is    0.26.\n",
      "170/232 [====================>.........] - ETA: 55s - loss: 0.2596 - iou_score: 0.7216 - f1-score: 0.8363For batch 169, tr_loss is    0.26.\n",
      "171/232 [=====================>........] - ETA: 54s - loss: 0.2601 - iou_score: 0.7210 - f1-score: 0.8359For batch 170, tr_loss is    0.26.\n",
      "172/232 [=====================>........] - ETA: 53s - loss: 0.2604 - iou_score: 0.7207 - f1-score: 0.8356For batch 171, tr_loss is    0.26.\n",
      "173/232 [=====================>........] - ETA: 52s - loss: 0.2601 - iou_score: 0.7209 - f1-score: 0.8358For batch 172, tr_loss is    0.26.\n",
      "174/232 [=====================>........] - ETA: 51s - loss: 0.2598 - iou_score: 0.7211 - f1-score: 0.8359For batch 173, tr_loss is    0.26.\n",
      "175/232 [=====================>........] - ETA: 51s - loss: 0.2601 - iou_score: 0.7208 - f1-score: 0.8357For batch 174, tr_loss is    0.26.\n",
      "176/232 [=====================>........] - ETA: 49s - loss: 0.2602 - iou_score: 0.7206 - f1-score: 0.8356For batch 175, tr_loss is    0.26.\n",
      "177/232 [=====================>........] - ETA: 49s - loss: 0.2600 - iou_score: 0.7211 - f1-score: 0.8359For batch 176, tr_loss is    0.26.\n",
      "178/232 [======================>.......] - ETA: 48s - loss: 0.2600 - iou_score: 0.7211 - f1-score: 0.8359For batch 177, tr_loss is    0.26.\n",
      "179/232 [======================>.......] - ETA: 47s - loss: 0.2599 - iou_score: 0.7213 - f1-score: 0.8360For batch 178, tr_loss is    0.26.\n",
      "180/232 [======================>.......] - ETA: 46s - loss: 0.2599 - iou_score: 0.7211 - f1-score: 0.8360For batch 179, tr_loss is    0.26.\n",
      "181/232 [======================>.......] - ETA: 45s - loss: 0.2599 - iou_score: 0.7211 - f1-score: 0.8360For batch 180, tr_loss is    0.26.\n",
      "182/232 [======================>.......] - ETA: 44s - loss: 0.2600 - iou_score: 0.7211 - f1-score: 0.8360For batch 181, tr_loss is    0.26.\n",
      "183/232 [======================>.......] - ETA: 43s - loss: 0.2599 - iou_score: 0.7212 - f1-score: 0.8360For batch 182, tr_loss is    0.26.\n",
      "184/232 [======================>.......] - ETA: 42s - loss: 0.2596 - iou_score: 0.7216 - f1-score: 0.8363For batch 183, tr_loss is    0.26.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/232 [======================>.......] - ETA: 42s - loss: 0.2597 - iou_score: 0.7216 - f1-score: 0.8363For batch 184, tr_loss is    0.26.\n",
      "186/232 [=======================>......] - ETA: 41s - loss: 0.2598 - iou_score: 0.7215 - f1-score: 0.8362For batch 185, tr_loss is    0.26.\n",
      "187/232 [=======================>......] - ETA: 40s - loss: 0.2593 - iou_score: 0.7220 - f1-score: 0.8365For batch 186, tr_loss is    0.26.\n",
      "188/232 [=======================>......] - ETA: 39s - loss: 0.2593 - iou_score: 0.7219 - f1-score: 0.8365For batch 187, tr_loss is    0.26.\n",
      "189/232 [=======================>......] - ETA: 38s - loss: 0.2591 - iou_score: 0.7222 - f1-score: 0.8367For batch 188, tr_loss is    0.26.\n",
      "190/232 [=======================>......] - ETA: 37s - loss: 0.2590 - iou_score: 0.7223 - f1-score: 0.8367For batch 189, tr_loss is    0.26.\n",
      "191/232 [=======================>......] - ETA: 36s - loss: 0.2591 - iou_score: 0.7223 - f1-score: 0.8368For batch 190, tr_loss is    0.26.\n",
      "192/232 [=======================>......] - ETA: 35s - loss: 0.2594 - iou_score: 0.7221 - f1-score: 0.8366For batch 191, tr_loss is    0.26.\n",
      "193/232 [=======================>......] - ETA: 34s - loss: 0.2596 - iou_score: 0.7217 - f1-score: 0.8364For batch 192, tr_loss is    0.26.\n",
      "194/232 [========================>.....] - ETA: 33s - loss: 0.2595 - iou_score: 0.7217 - f1-score: 0.8364For batch 193, tr_loss is    0.26.\n",
      "195/232 [========================>.....] - ETA: 32s - loss: 0.2595 - iou_score: 0.7216 - f1-score: 0.8363For batch 194, tr_loss is    0.26.\n",
      "196/232 [========================>.....] - ETA: 32s - loss: 0.2594 - iou_score: 0.7217 - f1-score: 0.8364For batch 195, tr_loss is    0.26.\n",
      "197/232 [========================>.....] - ETA: 31s - loss: 0.2594 - iou_score: 0.7217 - f1-score: 0.8363For batch 196, tr_loss is    0.26.\n",
      "198/232 [========================>.....] - ETA: 30s - loss: 0.2590 - iou_score: 0.7222 - f1-score: 0.8367For batch 197, tr_loss is    0.26.\n",
      "199/232 [========================>.....] - ETA: 29s - loss: 0.2589 - iou_score: 0.7222 - f1-score: 0.8367For batch 198, tr_loss is    0.26.\n",
      "200/232 [========================>.....] - ETA: 28s - loss: 0.2585 - iou_score: 0.7227 - f1-score: 0.8371For batch 199, tr_loss is    0.26.\n",
      "201/232 [========================>.....] - ETA: 27s - loss: 0.2586 - iou_score: 0.7226 - f1-score: 0.8369For batch 200, tr_loss is    0.26.\n",
      "202/232 [=========================>....] - ETA: 26s - loss: 0.2585 - iou_score: 0.7226 - f1-score: 0.8370For batch 201, tr_loss is    0.26.\n",
      "203/232 [=========================>....] - ETA: 25s - loss: 0.2581 - iou_score: 0.7229 - f1-score: 0.8372For batch 202, tr_loss is    0.26.\n",
      "204/232 [=========================>....] - ETA: 24s - loss: 0.2578 - iou_score: 0.7233 - f1-score: 0.8375For batch 203, tr_loss is    0.26.\n",
      "205/232 [=========================>....] - ETA: 23s - loss: 0.2576 - iou_score: 0.7233 - f1-score: 0.8375For batch 204, tr_loss is    0.26.\n",
      "206/232 [=========================>....] - ETA: 22s - loss: 0.2580 - iou_score: 0.7231 - f1-score: 0.8373For batch 205, tr_loss is    0.26.\n",
      "207/232 [=========================>....] - ETA: 22s - loss: 0.2579 - iou_score: 0.7232 - f1-score: 0.8374For batch 206, tr_loss is    0.26.\n",
      "208/232 [=========================>....] - ETA: 21s - loss: 0.2577 - iou_score: 0.7234 - f1-score: 0.8375For batch 207, tr_loss is    0.26.\n",
      "209/232 [==========================>...] - ETA: 20s - loss: 0.2579 - iou_score: 0.7232 - f1-score: 0.8374For batch 208, tr_loss is    0.26.\n",
      "210/232 [==========================>...] - ETA: 19s - loss: 0.2582 - iou_score: 0.7228 - f1-score: 0.8372For batch 209, tr_loss is    0.26.\n",
      "211/232 [==========================>...] - ETA: 18s - loss: 0.2581 - iou_score: 0.7230 - f1-score: 0.8373For batch 210, tr_loss is    0.26.\n",
      "212/232 [==========================>...] - ETA: 17s - loss: 0.2578 - iou_score: 0.7233 - f1-score: 0.8375For batch 211, tr_loss is    0.26.\n",
      "213/232 [==========================>...] - ETA: 16s - loss: 0.2579 - iou_score: 0.7232 - f1-score: 0.8374For batch 212, tr_loss is    0.26.\n",
      "214/232 [==========================>...] - ETA: 15s - loss: 0.2577 - iou_score: 0.7234 - f1-score: 0.8376For batch 213, tr_loss is    0.26.\n",
      "215/232 [==========================>...] - ETA: 15s - loss: 0.2574 - iou_score: 0.7237 - f1-score: 0.8378For batch 214, tr_loss is    0.26.\n",
      "216/232 [==========================>...] - ETA: 14s - loss: 0.2572 - iou_score: 0.7239 - f1-score: 0.8379For batch 215, tr_loss is    0.26.\n",
      "217/232 [===========================>..] - ETA: 13s - loss: 0.2572 - iou_score: 0.7239 - f1-score: 0.8379For batch 216, tr_loss is    0.26.\n",
      "218/232 [===========================>..] - ETA: 12s - loss: 0.2573 - iou_score: 0.7238 - f1-score: 0.8378For batch 217, tr_loss is    0.26.\n",
      "219/232 [===========================>..] - ETA: 11s - loss: 0.2577 - iou_score: 0.7232 - f1-score: 0.8373For batch 218, tr_loss is    0.26.\n",
      "220/232 [===========================>..] - ETA: 10s - loss: 0.2578 - iou_score: 0.7231 - f1-score: 0.8373For batch 219, tr_loss is    0.26.\n",
      "221/232 [===========================>..] - ETA: 9s - loss: 0.2579 - iou_score: 0.7229 - f1-score: 0.8372 For batch 220, tr_loss is    0.26.\n",
      "222/232 [===========================>..] - ETA: 8s - loss: 0.2577 - iou_score: 0.7232 - f1-score: 0.8373For batch 221, tr_loss is    0.26.\n",
      "223/232 [===========================>..] - ETA: 7s - loss: 0.2577 - iou_score: 0.7230 - f1-score: 0.8372For batch 222, tr_loss is    0.26.\n",
      "224/232 [===========================>..] - ETA: 7s - loss: 0.2575 - iou_score: 0.7233 - f1-score: 0.8374For batch 223, tr_loss is    0.26.\n",
      "225/232 [============================>.] - ETA: 6s - loss: 0.2573 - iou_score: 0.7235 - f1-score: 0.8376For batch 224, tr_loss is    0.26.\n",
      "226/232 [============================>.] - ETA: 5s - loss: 0.2574 - iou_score: 0.7234 - f1-score: 0.8375For batch 225, tr_loss is    0.26.\n",
      "227/232 [============================>.] - ETA: 4s - loss: 0.2575 - iou_score: 0.7235 - f1-score: 0.8376For batch 226, tr_loss is    0.26.\n",
      "228/232 [============================>.] - ETA: 3s - loss: 0.2577 - iou_score: 0.7233 - f1-score: 0.8375For batch 227, tr_loss is    0.26.\n",
      "229/232 [============================>.] - ETA: 2s - loss: 0.2576 - iou_score: 0.7234 - f1-score: 0.8375For batch 228, tr_loss is    0.26.\n",
      "230/232 [============================>.] - ETA: 1s - loss: 0.2580 - iou_score: 0.7231 - f1-score: 0.8373For batch 229, tr_loss is    0.26.\n",
      "231/232 [============================>.] - ETA: 0s - loss: 0.2581 - iou_score: 0.7230 - f1-score: 0.8372For batch 230, tr_loss is    0.26.\n",
      "232/232 [==============================] - ETA: 0s - loss: 0.2578 - iou_score: 0.7233 - f1-score: 0.8374For batch 231, tr_loss is    0.26.\n",
      "For batch 0, vl_loss is    0.39.\n",
      "For batch 1, vl_loss is    0.36.\n",
      "For batch 2, vl_loss is    0.39.\n",
      "For batch 3, vl_loss is    0.39.\n",
      "For batch 4, vl_loss is    0.42.\n",
      "For batch 5, vl_loss is    0.41.\n",
      "For batch 6, vl_loss is    0.42.\n",
      "For batch 7, vl_loss is    0.42.\n",
      "For batch 8, vl_loss is    0.41.\n",
      "For batch 9, vl_loss is    0.39.\n",
      "For batch 10, vl_loss is    0.40.\n",
      "For batch 11, vl_loss is    0.40.\n",
      "For batch 12, vl_loss is    0.41.\n",
      "For batch 13, vl_loss is    0.41.\n",
      "For batch 14, vl_loss is    0.40.\n",
      "For batch 15, vl_loss is    0.40.\n",
      "For batch 16, vl_loss is    0.39.\n",
      "For batch 17, vl_loss is    0.40.\n",
      "For batch 18, vl_loss is    0.40.\n",
      "For batch 19, vl_loss is    0.40.\n",
      "For batch 20, vl_loss is    0.39.\n",
      "For batch 21, vl_loss is    0.39.\n",
      "For batch 22, vl_loss is    0.39.\n",
      "For batch 23, vl_loss is    0.39.\n",
      "For batch 24, vl_loss is    0.39.\n",
      "For batch 25, vl_loss is    0.39.\n",
      "For batch 26, vl_loss is    0.39.\n",
      "For batch 27, vl_loss is    0.39.\n",
      "For batch 28, vl_loss is    0.39.\n",
      "For batch 29, vl_loss is    0.40.\n",
      "For batch 30, vl_loss is    0.40.\n",
      "For batch 31, vl_loss is    0.40.\n",
      "For batch 32, vl_loss is    0.40.\n",
      "For batch 33, vl_loss is    0.40.\n",
      "For batch 34, vl_loss is    0.40.\n",
      "For batch 35, vl_loss is    0.40.\n",
      "For batch 36, vl_loss is    0.39.\n",
      "For batch 37, vl_loss is    0.40.\n",
      "For batch 38, vl_loss is    0.39.\n",
      "For batch 39, vl_loss is    0.39.\n",
      "For batch 40, vl_loss is    0.40.\n",
      "For batch 41, vl_loss is    0.40.\n",
      "For batch 42, vl_loss is    0.40.\n",
      "For batch 43, vl_loss is    0.40.\n",
      "For batch 44, vl_loss is    0.40.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 45, vl_loss is    0.40.\n",
      "For batch 46, vl_loss is    0.40.\n",
      "For batch 47, vl_loss is    0.40.\n",
      "For batch 48, vl_loss is    0.40.\n",
      "For batch 49, vl_loss is    0.40.\n",
      "For batch 50, vl_loss is    0.40.\n",
      "For batch 51, vl_loss is    0.40.\n",
      "For batch 52, vl_loss is    0.41.\n",
      "For batch 53, vl_loss is    0.41.\n",
      "For batch 54, vl_loss is    0.41.\n",
      "For batch 55, vl_loss is    0.41.\n",
      "For batch 56, vl_loss is    0.41.\n",
      "For batch 57, vl_loss is    0.41.\n",
      "For batch 58, vl_loss is    0.41.\n",
      "For batch 59, vl_loss is    0.41.\n",
      "For batch 60, vl_loss is    0.40.\n",
      "For batch 61, vl_loss is    0.40.\n",
      "For batch 62, vl_loss is    0.40.\n",
      "For batch 63, vl_loss is    0.40.\n",
      "For batch 64, vl_loss is    0.40.\n",
      "For batch 65, vl_loss is    0.40.\n",
      "For batch 66, vl_loss is    0.40.\n",
      "For batch 67, vl_loss is    0.40.\n",
      "232/232 [==============================] - 207s 886ms/step - loss: 0.2578 - iou_score: 0.7233 - f1-score: 0.8374 - val_loss: 0.4018 - val_iou_score: 0.6361 - val_f1-score: 0.7753\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.36098\n",
      "The average loss for epoch 10 is    0.26 \n",
      "Epoch 12/200\n",
      "  1/232 [..............................] - ETA: 12:20 - loss: 0.2116 - iou_score: 0.7734 - f1-score: 0.8697For batch 0, tr_loss is    0.21.\n",
      "  2/232 [..............................] - ETA: 5:15 - loss: 0.2091 - iou_score: 0.7722 - f1-score: 0.8701 For batch 1, tr_loss is    0.21.\n",
      "  3/232 [..............................] - ETA: 5:44 - loss: 0.2310 - iou_score: 0.7445 - f1-score: 0.8520For batch 2, tr_loss is    0.23.\n",
      "  4/232 [..............................] - ETA: 5:15 - loss: 0.2346 - iou_score: 0.7463 - f1-score: 0.8534For batch 3, tr_loss is    0.23.\n",
      "  5/232 [..............................] - ETA: 5:08 - loss: 0.2448 - iou_score: 0.7366 - f1-score: 0.8466For batch 4, tr_loss is    0.24.\n",
      "  6/232 [..............................] - ETA: 4:55 - loss: 0.2601 - iou_score: 0.7265 - f1-score: 0.8395For batch 5, tr_loss is    0.26.\n",
      "  7/232 [..............................] - ETA: 5:00 - loss: 0.2662 - iou_score: 0.7165 - f1-score: 0.8327For batch 6, tr_loss is    0.27.\n",
      "  8/232 [>.............................] - ETA: 4:49 - loss: 0.2697 - iou_score: 0.7099 - f1-score: 0.8284For batch 7, tr_loss is    0.27.\n",
      "  9/232 [>.............................] - ETA: 4:47 - loss: 0.2604 - iou_score: 0.7221 - f1-score: 0.8364For batch 8, tr_loss is    0.26.\n",
      " 10/232 [>.............................] - ETA: 4:41 - loss: 0.2604 - iou_score: 0.7210 - f1-score: 0.8358For batch 9, tr_loss is    0.26.\n",
      " 11/232 [>.............................] - ETA: 4:29 - loss: 0.2586 - iou_score: 0.7216 - f1-score: 0.8364For batch 10, tr_loss is    0.26.\n",
      " 12/232 [>.............................] - ETA: 4:23 - loss: 0.2530 - iou_score: 0.7292 - f1-score: 0.8414For batch 11, tr_loss is    0.25.\n",
      " 13/232 [>.............................] - ETA: 4:19 - loss: 0.2506 - iou_score: 0.7323 - f1-score: 0.8434For batch 12, tr_loss is    0.25.\n",
      " 14/232 [>.............................] - ETA: 4:15 - loss: 0.2469 - iou_score: 0.7363 - f1-score: 0.8462For batch 13, tr_loss is    0.25.\n",
      " 15/232 [>.............................] - ETA: 4:03 - loss: 0.2434 - iou_score: 0.7401 - f1-score: 0.8487For batch 14, tr_loss is    0.24.\n",
      " 16/232 [=>............................] - ETA: 4:01 - loss: 0.2406 - iou_score: 0.7427 - f1-score: 0.8505For batch 15, tr_loss is    0.24.\n",
      " 17/232 [=>............................] - ETA: 3:59 - loss: 0.2383 - iou_score: 0.7458 - f1-score: 0.8526For batch 16, tr_loss is    0.24.\n",
      " 18/232 [=>............................] - ETA: 3:52 - loss: 0.2397 - iou_score: 0.7441 - f1-score: 0.8516For batch 17, tr_loss is    0.24.\n",
      " 19/232 [=>............................] - ETA: 3:46 - loss: 0.2417 - iou_score: 0.7406 - f1-score: 0.8493For batch 18, tr_loss is    0.24.\n",
      " 20/232 [=>............................] - ETA: 3:45 - loss: 0.2392 - iou_score: 0.7430 - f1-score: 0.8508For batch 19, tr_loss is    0.24.\n",
      " 21/232 [=>............................] - ETA: 3:37 - loss: 0.2439 - iou_score: 0.7395 - f1-score: 0.8484For batch 20, tr_loss is    0.24.\n",
      " 22/232 [=>............................] - ETA: 3:37 - loss: 0.2457 - iou_score: 0.7364 - f1-score: 0.8462For batch 21, tr_loss is    0.25.\n",
      " 23/232 [=>............................] - ETA: 3:31 - loss: 0.2458 - iou_score: 0.7357 - f1-score: 0.8458For batch 22, tr_loss is    0.25.\n",
      " 24/232 [==>...........................] - ETA: 3:30 - loss: 0.2443 - iou_score: 0.7369 - f1-score: 0.8467For batch 23, tr_loss is    0.24.\n",
      " 25/232 [==>...........................] - ETA: 3:29 - loss: 0.2480 - iou_score: 0.7325 - f1-score: 0.8436For batch 24, tr_loss is    0.25.\n",
      " 26/232 [==>...........................] - ETA: 3:27 - loss: 0.2482 - iou_score: 0.7321 - f1-score: 0.8433For batch 25, tr_loss is    0.25.\n",
      " 27/232 [==>...........................] - ETA: 3:26 - loss: 0.2460 - iou_score: 0.7350 - f1-score: 0.8452For batch 26, tr_loss is    0.25.\n",
      " 28/232 [==>...........................] - ETA: 3:21 - loss: 0.2466 - iou_score: 0.7351 - f1-score: 0.8453For batch 27, tr_loss is    0.25.\n",
      " 29/232 [==>...........................] - ETA: 3:18 - loss: 0.2460 - iou_score: 0.7351 - f1-score: 0.8453For batch 28, tr_loss is    0.25.\n",
      " 30/232 [==>...........................] - ETA: 3:15 - loss: 0.2443 - iou_score: 0.7375 - f1-score: 0.8469For batch 29, tr_loss is    0.24.\n",
      " 31/232 [===>..........................] - ETA: 3:14 - loss: 0.2438 - iou_score: 0.7383 - f1-score: 0.8475For batch 30, tr_loss is    0.24.\n",
      " 32/232 [===>..........................] - ETA: 3:14 - loss: 0.2433 - iou_score: 0.7388 - f1-score: 0.8479For batch 31, tr_loss is    0.24.\n",
      " 33/232 [===>..........................] - ETA: 3:13 - loss: 0.2452 - iou_score: 0.7362 - f1-score: 0.8461For batch 32, tr_loss is    0.25.\n",
      " 34/232 [===>..........................] - ETA: 3:13 - loss: 0.2451 - iou_score: 0.7359 - f1-score: 0.8460For batch 33, tr_loss is    0.25.\n",
      " 35/232 [===>..........................] - ETA: 3:12 - loss: 0.2476 - iou_score: 0.7337 - f1-score: 0.8445For batch 34, tr_loss is    0.25.\n",
      " 36/232 [===>..........................] - ETA: 3:11 - loss: 0.2475 - iou_score: 0.7343 - f1-score: 0.8449For batch 35, tr_loss is    0.25.\n",
      " 37/232 [===>..........................] - ETA: 3:10 - loss: 0.2476 - iou_score: 0.7340 - f1-score: 0.8448For batch 36, tr_loss is    0.25.\n",
      " 38/232 [===>..........................] - ETA: 3:08 - loss: 0.2484 - iou_score: 0.7327 - f1-score: 0.8439For batch 37, tr_loss is    0.25.\n",
      " 39/232 [====>.........................] - ETA: 3:08 - loss: 0.2525 - iou_score: 0.7286 - f1-score: 0.8410For batch 38, tr_loss is    0.25.\n",
      " 40/232 [====>.........................] - ETA: 3:04 - loss: 0.2542 - iou_score: 0.7278 - f1-score: 0.8405For batch 39, tr_loss is    0.25.\n",
      " 41/232 [====>.........................] - ETA: 3:03 - loss: 0.2556 - iou_score: 0.7260 - f1-score: 0.8392For batch 40, tr_loss is    0.26.\n",
      " 42/232 [====>.........................] - ETA: 3:03 - loss: 0.2562 - iou_score: 0.7250 - f1-score: 0.8386For batch 41, tr_loss is    0.26.\n",
      " 43/232 [====>.........................] - ETA: 3:02 - loss: 0.2554 - iou_score: 0.7258 - f1-score: 0.8392For batch 42, tr_loss is    0.26.\n",
      " 44/232 [====>.........................] - ETA: 3:01 - loss: 0.2581 - iou_score: 0.7233 - f1-score: 0.8373For batch 43, tr_loss is    0.26.\n",
      " 45/232 [====>.........................] - ETA: 2:58 - loss: 0.2588 - iou_score: 0.7232 - f1-score: 0.8372For batch 44, tr_loss is    0.26.\n",
      " 46/232 [====>.........................] - ETA: 2:58 - loss: 0.2591 - iou_score: 0.7230 - f1-score: 0.8372For batch 45, tr_loss is    0.26.\n",
      " 47/232 [=====>........................] - ETA: 2:56 - loss: 0.2589 - iou_score: 0.7234 - f1-score: 0.8374For batch 46, tr_loss is    0.26.\n",
      " 48/232 [=====>........................] - ETA: 2:54 - loss: 0.2579 - iou_score: 0.7249 - f1-score: 0.8384For batch 47, tr_loss is    0.26.\n",
      " 49/232 [=====>........................] - ETA: 2:53 - loss: 0.2583 - iou_score: 0.7248 - f1-score: 0.8383For batch 48, tr_loss is    0.26.\n",
      " 50/232 [=====>........................] - ETA: 2:52 - loss: 0.2581 - iou_score: 0.7249 - f1-score: 0.8384For batch 49, tr_loss is    0.26.\n",
      " 51/232 [=====>........................] - ETA: 2:50 - loss: 0.2592 - iou_score: 0.7235 - f1-score: 0.8375For batch 50, tr_loss is    0.26.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 52/232 [=====>........................] - ETA: 2:50 - loss: 0.2615 - iou_score: 0.7213 - f1-score: 0.8359For batch 51, tr_loss is    0.26.\n",
      " 53/232 [=====>........................] - ETA: 2:47 - loss: 0.2608 - iou_score: 0.7225 - f1-score: 0.8367For batch 52, tr_loss is    0.26.\n",
      " 54/232 [=====>........................] - ETA: 2:46 - loss: 0.2610 - iou_score: 0.7220 - f1-score: 0.8364For batch 53, tr_loss is    0.26.\n",
      " 55/232 [======>.......................] - ETA: 2:45 - loss: 0.2606 - iou_score: 0.7224 - f1-score: 0.8367For batch 54, tr_loss is    0.26.\n",
      " 56/232 [======>.......................] - ETA: 2:44 - loss: 0.2606 - iou_score: 0.7220 - f1-score: 0.8365For batch 55, tr_loss is    0.26.\n",
      " 57/232 [======>.......................] - ETA: 2:44 - loss: 0.2609 - iou_score: 0.7214 - f1-score: 0.8361For batch 56, tr_loss is    0.26.\n",
      " 58/232 [======>.......................] - ETA: 2:41 - loss: 0.2602 - iou_score: 0.7226 - f1-score: 0.8369For batch 57, tr_loss is    0.26.\n",
      " 59/232 [======>.......................] - ETA: 2:40 - loss: 0.2596 - iou_score: 0.7230 - f1-score: 0.8372For batch 58, tr_loss is    0.26.\n",
      " 60/232 [======>.......................] - ETA: 2:38 - loss: 0.2612 - iou_score: 0.7211 - f1-score: 0.8358For batch 59, tr_loss is    0.26.\n",
      " 61/232 [======>.......................] - ETA: 2:38 - loss: 0.2632 - iou_score: 0.7194 - f1-score: 0.8345For batch 60, tr_loss is    0.26.\n",
      " 62/232 [=======>......................] - ETA: 2:37 - loss: 0.2639 - iou_score: 0.7185 - f1-score: 0.8338For batch 61, tr_loss is    0.26.\n",
      " 63/232 [=======>......................] - ETA: 2:35 - loss: 0.2633 - iou_score: 0.7191 - f1-score: 0.8343For batch 62, tr_loss is    0.26.\n",
      " 64/232 [=======>......................] - ETA: 2:34 - loss: 0.2634 - iou_score: 0.7191 - f1-score: 0.8343For batch 63, tr_loss is    0.26.\n",
      " 65/232 [=======>......................] - ETA: 2:33 - loss: 0.2633 - iou_score: 0.7190 - f1-score: 0.8343For batch 64, tr_loss is    0.26.\n",
      " 66/232 [=======>......................] - ETA: 2:32 - loss: 0.2640 - iou_score: 0.7183 - f1-score: 0.8338For batch 65, tr_loss is    0.26.\n",
      " 67/232 [=======>......................] - ETA: 2:32 - loss: 0.2633 - iou_score: 0.7192 - f1-score: 0.8345For batch 66, tr_loss is    0.26.\n",
      " 68/232 [=======>......................] - ETA: 2:31 - loss: 0.2628 - iou_score: 0.7199 - f1-score: 0.8349For batch 67, tr_loss is    0.26.\n",
      " 69/232 [=======>......................] - ETA: 2:30 - loss: 0.2627 - iou_score: 0.7202 - f1-score: 0.8352For batch 68, tr_loss is    0.26.\n",
      " 70/232 [========>.....................] - ETA: 2:28 - loss: 0.2622 - iou_score: 0.7205 - f1-score: 0.8353For batch 69, tr_loss is    0.26.\n",
      " 71/232 [========>.....................] - ETA: 2:27 - loss: 0.2613 - iou_score: 0.7219 - f1-score: 0.8363For batch 70, tr_loss is    0.26.\n",
      " 72/232 [========>.....................] - ETA: 2:26 - loss: 0.2605 - iou_score: 0.7227 - f1-score: 0.8368For batch 71, tr_loss is    0.26.\n",
      " 73/232 [========>.....................] - ETA: 2:24 - loss: 0.2606 - iou_score: 0.7222 - f1-score: 0.8365For batch 72, tr_loss is    0.26.\n",
      " 74/232 [========>.....................] - ETA: 2:23 - loss: 0.2599 - iou_score: 0.7231 - f1-score: 0.8371For batch 73, tr_loss is    0.26.\n",
      " 75/232 [========>.....................] - ETA: 2:22 - loss: 0.2601 - iou_score: 0.7227 - f1-score: 0.8369For batch 74, tr_loss is    0.26.\n",
      " 76/232 [========>.....................] - ETA: 2:20 - loss: 0.2596 - iou_score: 0.7230 - f1-score: 0.8370For batch 75, tr_loss is    0.26.\n",
      " 77/232 [========>.....................] - ETA: 2:20 - loss: 0.2588 - iou_score: 0.7237 - f1-score: 0.8376For batch 76, tr_loss is    0.26.\n",
      " 78/232 [=========>....................] - ETA: 2:20 - loss: 0.2592 - iou_score: 0.7233 - f1-score: 0.8373For batch 77, tr_loss is    0.26.\n",
      " 79/232 [=========>....................] - ETA: 2:19 - loss: 0.2588 - iou_score: 0.7239 - f1-score: 0.8377For batch 78, tr_loss is    0.26.\n",
      " 80/232 [=========>....................] - ETA: 2:18 - loss: 0.2588 - iou_score: 0.7239 - f1-score: 0.8377For batch 79, tr_loss is    0.26.\n",
      " 81/232 [=========>....................] - ETA: 2:18 - loss: 0.2587 - iou_score: 0.7238 - f1-score: 0.8376For batch 80, tr_loss is    0.26.\n",
      " 82/232 [=========>....................] - ETA: 2:16 - loss: 0.2586 - iou_score: 0.7236 - f1-score: 0.8376For batch 81, tr_loss is    0.26.\n",
      " 83/232 [=========>....................] - ETA: 2:16 - loss: 0.2594 - iou_score: 0.7227 - f1-score: 0.8369For batch 82, tr_loss is    0.26.\n",
      " 84/232 [=========>....................] - ETA: 2:14 - loss: 0.2598 - iou_score: 0.7222 - f1-score: 0.8366For batch 83, tr_loss is    0.26.\n",
      " 85/232 [=========>....................] - ETA: 2:13 - loss: 0.2601 - iou_score: 0.7221 - f1-score: 0.8366For batch 84, tr_loss is    0.26.\n",
      " 86/232 [==========>...................] - ETA: 2:12 - loss: 0.2607 - iou_score: 0.7213 - f1-score: 0.8360For batch 85, tr_loss is    0.26.\n",
      " 87/232 [==========>...................] - ETA: 2:11 - loss: 0.2605 - iou_score: 0.7215 - f1-score: 0.8362For batch 86, tr_loss is    0.26.\n",
      " 88/232 [==========>...................] - ETA: 2:10 - loss: 0.2609 - iou_score: 0.7209 - f1-score: 0.8358For batch 87, tr_loss is    0.26.\n",
      " 89/232 [==========>...................] - ETA: 2:09 - loss: 0.2605 - iou_score: 0.7212 - f1-score: 0.8360For batch 88, tr_loss is    0.26.\n",
      " 90/232 [==========>...................] - ETA: 2:08 - loss: 0.2601 - iou_score: 0.7218 - f1-score: 0.8364For batch 89, tr_loss is    0.26.\n",
      " 91/232 [==========>...................] - ETA: 2:07 - loss: 0.2599 - iou_score: 0.7222 - f1-score: 0.8367For batch 90, tr_loss is    0.26.\n",
      " 92/232 [==========>...................] - ETA: 2:07 - loss: 0.2596 - iou_score: 0.7224 - f1-score: 0.8368For batch 91, tr_loss is    0.26.\n",
      " 93/232 [===========>..................] - ETA: 2:06 - loss: 0.2605 - iou_score: 0.7212 - f1-score: 0.8360For batch 92, tr_loss is    0.26.\n",
      " 94/232 [===========>..................] - ETA: 2:04 - loss: 0.2600 - iou_score: 0.7219 - f1-score: 0.8364For batch 93, tr_loss is    0.26.\n",
      " 95/232 [===========>..................] - ETA: 2:03 - loss: 0.2604 - iou_score: 0.7215 - f1-score: 0.8362For batch 94, tr_loss is    0.26.\n",
      " 96/232 [===========>..................] - ETA: 2:02 - loss: 0.2604 - iou_score: 0.7216 - f1-score: 0.8362For batch 95, tr_loss is    0.26.\n",
      " 97/232 [===========>..................] - ETA: 2:01 - loss: 0.2607 - iou_score: 0.7213 - f1-score: 0.8361For batch 96, tr_loss is    0.26.\n",
      " 98/232 [===========>..................] - ETA: 2:00 - loss: 0.2603 - iou_score: 0.7213 - f1-score: 0.8361For batch 97, tr_loss is    0.26.\n",
      " 99/232 [===========>..................] - ETA: 1:59 - loss: 0.2594 - iou_score: 0.7226 - f1-score: 0.8369For batch 98, tr_loss is    0.26.\n",
      "100/232 [===========>..................] - ETA: 1:58 - loss: 0.2590 - iou_score: 0.7232 - f1-score: 0.8373For batch 99, tr_loss is    0.26.\n",
      "101/232 [============>.................] - ETA: 1:58 - loss: 0.2584 - iou_score: 0.7240 - f1-score: 0.8378For batch 100, tr_loss is    0.26.\n",
      "102/232 [============>.................] - ETA: 1:57 - loss: 0.2584 - iou_score: 0.7240 - f1-score: 0.8378For batch 101, tr_loss is    0.26.\n",
      "103/232 [============>.................] - ETA: 1:55 - loss: 0.2584 - iou_score: 0.7240 - f1-score: 0.8378For batch 102, tr_loss is    0.26.\n",
      "104/232 [============>.................] - ETA: 1:55 - loss: 0.2582 - iou_score: 0.7242 - f1-score: 0.8380For batch 103, tr_loss is    0.26.\n",
      "105/232 [============>.................] - ETA: 1:54 - loss: 0.2576 - iou_score: 0.7249 - f1-score: 0.8384For batch 104, tr_loss is    0.26.\n",
      "106/232 [============>.................] - ETA: 1:52 - loss: 0.2568 - iou_score: 0.7258 - f1-score: 0.8391For batch 105, tr_loss is    0.26.\n",
      "107/232 [============>.................] - ETA: 1:51 - loss: 0.2574 - iou_score: 0.7255 - f1-score: 0.8388For batch 106, tr_loss is    0.26.\n",
      "108/232 [============>.................] - ETA: 1:50 - loss: 0.2580 - iou_score: 0.7245 - f1-score: 0.8382For batch 107, tr_loss is    0.26.\n",
      "109/232 [=============>................] - ETA: 1:49 - loss: 0.2574 - iou_score: 0.7251 - f1-score: 0.8385For batch 108, tr_loss is    0.26.\n",
      "110/232 [=============>................] - ETA: 1:48 - loss: 0.2566 - iou_score: 0.7262 - f1-score: 0.8393For batch 109, tr_loss is    0.26.\n",
      "111/232 [=============>................] - ETA: 1:47 - loss: 0.2566 - iou_score: 0.7260 - f1-score: 0.8391For batch 110, tr_loss is    0.26.\n",
      "112/232 [=============>................] - ETA: 1:47 - loss: 0.2568 - iou_score: 0.7257 - f1-score: 0.8389For batch 111, tr_loss is    0.26.\n",
      "113/232 [=============>................] - ETA: 1:46 - loss: 0.2577 - iou_score: 0.7253 - f1-score: 0.8386For batch 112, tr_loss is    0.26.\n",
      "114/232 [=============>................] - ETA: 1:45 - loss: 0.2571 - iou_score: 0.7259 - f1-score: 0.8391For batch 113, tr_loss is    0.26.\n",
      "115/232 [=============>................] - ETA: 1:44 - loss: 0.2567 - iou_score: 0.7264 - f1-score: 0.8394For batch 114, tr_loss is    0.26.\n",
      "116/232 [==============>...............] - ETA: 1:43 - loss: 0.2564 - iou_score: 0.7267 - f1-score: 0.8396For batch 115, tr_loss is    0.26.\n",
      "117/232 [==============>...............] - ETA: 1:42 - loss: 0.2562 - iou_score: 0.7268 - f1-score: 0.8396For batch 116, tr_loss is    0.26.\n",
      "118/232 [==============>...............] - ETA: 1:41 - loss: 0.2557 - iou_score: 0.7274 - f1-score: 0.8401For batch 117, tr_loss is    0.26.\n",
      "119/232 [==============>...............] - ETA: 1:40 - loss: 0.2554 - iou_score: 0.7279 - f1-score: 0.8404For batch 118, tr_loss is    0.26.\n",
      "120/232 [==============>...............] - ETA: 1:39 - loss: 0.2557 - iou_score: 0.7275 - f1-score: 0.8402For batch 119, tr_loss is    0.26.\n",
      "121/232 [==============>...............] - ETA: 1:39 - loss: 0.2552 - iou_score: 0.7280 - f1-score: 0.8405For batch 120, tr_loss is    0.26.\n",
      "122/232 [==============>...............] - ETA: 1:38 - loss: 0.2558 - iou_score: 0.7276 - f1-score: 0.8402For batch 121, tr_loss is    0.26.\n",
      "123/232 [==============>...............] - ETA: 1:37 - loss: 0.2553 - iou_score: 0.7279 - f1-score: 0.8404For batch 122, tr_loss is    0.26.\n",
      "124/232 [===============>..............] - ETA: 1:36 - loss: 0.2554 - iou_score: 0.7277 - f1-score: 0.8403For batch 123, tr_loss is    0.26.\n",
      "125/232 [===============>..............] - ETA: 1:35 - loss: 0.2556 - iou_score: 0.7274 - f1-score: 0.8401For batch 124, tr_loss is    0.26.\n",
      "126/232 [===============>..............] - ETA: 1:34 - loss: 0.2553 - iou_score: 0.7278 - f1-score: 0.8404For batch 125, tr_loss is    0.26.\n",
      "127/232 [===============>..............] - ETA: 1:33 - loss: 0.2551 - iou_score: 0.7279 - f1-score: 0.8404For batch 126, tr_loss is    0.26.\n",
      "128/232 [===============>..............] - ETA: 1:32 - loss: 0.2557 - iou_score: 0.7273 - f1-score: 0.8400For batch 127, tr_loss is    0.26.\n",
      "129/232 [===============>..............] - ETA: 1:32 - loss: 0.2557 - iou_score: 0.7273 - f1-score: 0.8400For batch 128, tr_loss is    0.26.\n",
      "130/232 [===============>..............] - ETA: 1:31 - loss: 0.2556 - iou_score: 0.7276 - f1-score: 0.8402For batch 129, tr_loss is    0.26.\n",
      "131/232 [===============>..............] - ETA: 1:30 - loss: 0.2561 - iou_score: 0.7269 - f1-score: 0.8398For batch 130, tr_loss is    0.26.\n",
      "132/232 [================>.............] - ETA: 1:29 - loss: 0.2565 - iou_score: 0.7267 - f1-score: 0.8396For batch 131, tr_loss is    0.26.\n",
      "133/232 [================>.............] - ETA: 1:28 - loss: 0.2561 - iou_score: 0.7270 - f1-score: 0.8398For batch 132, tr_loss is    0.26.\n",
      "134/232 [================>.............] - ETA: 1:27 - loss: 0.2564 - iou_score: 0.7263 - f1-score: 0.8394For batch 133, tr_loss is    0.26.\n",
      "135/232 [================>.............] - ETA: 1:27 - loss: 0.2562 - iou_score: 0.7266 - f1-score: 0.8396For batch 134, tr_loss is    0.26.\n",
      "136/232 [================>.............] - ETA: 1:26 - loss: 0.2565 - iou_score: 0.7261 - f1-score: 0.8392For batch 135, tr_loss is    0.26.\n",
      "137/232 [================>.............] - ETA: 1:24 - loss: 0.2567 - iou_score: 0.7257 - f1-score: 0.8390For batch 136, tr_loss is    0.26.\n",
      "138/232 [================>.............] - ETA: 1:24 - loss: 0.2570 - iou_score: 0.7254 - f1-score: 0.8388For batch 137, tr_loss is    0.26.\n",
      "139/232 [================>.............] - ETA: 1:23 - loss: 0.2569 - iou_score: 0.7255 - f1-score: 0.8388For batch 138, tr_loss is    0.26.\n",
      "140/232 [=================>............] - ETA: 1:22 - loss: 0.2568 - iou_score: 0.7257 - f1-score: 0.8390For batch 139, tr_loss is    0.26.\n",
      "141/232 [=================>............] - ETA: 1:21 - loss: 0.2573 - iou_score: 0.7250 - f1-score: 0.8385For batch 140, tr_loss is    0.26.\n",
      "142/232 [=================>............] - ETA: 1:20 - loss: 0.2572 - iou_score: 0.7250 - f1-score: 0.8385For batch 141, tr_loss is    0.26.\n",
      "143/232 [=================>............] - ETA: 1:20 - loss: 0.2570 - iou_score: 0.7251 - f1-score: 0.8386For batch 142, tr_loss is    0.26.\n",
      "144/232 [=================>............] - ETA: 1:18 - loss: 0.2568 - iou_score: 0.7252 - f1-score: 0.8386For batch 143, tr_loss is    0.26.\n",
      "145/232 [=================>............] - ETA: 1:18 - loss: 0.2568 - iou_score: 0.7252 - f1-score: 0.8386For batch 144, tr_loss is    0.26.\n",
      "146/232 [=================>............] - ETA: 1:17 - loss: 0.2571 - iou_score: 0.7247 - f1-score: 0.8383For batch 145, tr_loss is    0.26.\n",
      "147/232 [==================>...........] - ETA: 1:16 - loss: 0.2568 - iou_score: 0.7252 - f1-score: 0.8387For batch 146, tr_loss is    0.26.\n",
      "148/232 [==================>...........] - ETA: 1:15 - loss: 0.2572 - iou_score: 0.7246 - f1-score: 0.8382For batch 147, tr_loss is    0.26.\n",
      "149/232 [==================>...........] - ETA: 1:14 - loss: 0.2571 - iou_score: 0.7247 - f1-score: 0.8383For batch 148, tr_loss is    0.26.\n",
      "150/232 [==================>...........] - ETA: 1:13 - loss: 0.2579 - iou_score: 0.7239 - f1-score: 0.8377For batch 149, tr_loss is    0.26.\n",
      "151/232 [==================>...........] - ETA: 1:13 - loss: 0.2581 - iou_score: 0.7235 - f1-score: 0.8374For batch 150, tr_loss is    0.26.\n",
      "152/232 [==================>...........] - ETA: 1:12 - loss: 0.2578 - iou_score: 0.7239 - f1-score: 0.8377For batch 151, tr_loss is    0.26.\n",
      "153/232 [==================>...........] - ETA: 1:11 - loss: 0.2578 - iou_score: 0.7237 - f1-score: 0.8376For batch 152, tr_loss is    0.26.\n",
      "154/232 [==================>...........] - ETA: 1:10 - loss: 0.2575 - iou_score: 0.7239 - f1-score: 0.8377For batch 153, tr_loss is    0.26.\n",
      "155/232 [===================>..........] - ETA: 1:09 - loss: 0.2575 - iou_score: 0.7237 - f1-score: 0.8376For batch 154, tr_loss is    0.26.\n",
      "156/232 [===================>..........] - ETA: 1:08 - loss: 0.2574 - iou_score: 0.7237 - f1-score: 0.8376For batch 155, tr_loss is    0.26.\n",
      "157/232 [===================>..........] - ETA: 1:07 - loss: 0.2577 - iou_score: 0.7234 - f1-score: 0.8374For batch 156, tr_loss is    0.26.\n",
      "158/232 [===================>..........] - ETA: 1:06 - loss: 0.2575 - iou_score: 0.7238 - f1-score: 0.8377For batch 157, tr_loss is    0.26.\n",
      "159/232 [===================>..........] - ETA: 1:05 - loss: 0.2571 - iou_score: 0.7243 - f1-score: 0.8380For batch 158, tr_loss is    0.26.\n",
      "160/232 [===================>..........] - ETA: 1:04 - loss: 0.2570 - iou_score: 0.7242 - f1-score: 0.8380For batch 159, tr_loss is    0.26.\n",
      "161/232 [===================>..........] - ETA: 1:03 - loss: 0.2567 - iou_score: 0.7246 - f1-score: 0.8382For batch 160, tr_loss is    0.26.\n",
      "162/232 [===================>..........] - ETA: 1:02 - loss: 0.2566 - iou_score: 0.7246 - f1-score: 0.8382For batch 161, tr_loss is    0.26.\n",
      "163/232 [====================>.........] - ETA: 1:01 - loss: 0.2563 - iou_score: 0.7251 - f1-score: 0.8386For batch 162, tr_loss is    0.26.\n",
      "164/232 [====================>.........] - ETA: 1:00 - loss: 0.2563 - iou_score: 0.7249 - f1-score: 0.8385For batch 163, tr_loss is    0.26.\n",
      "165/232 [====================>.........] - ETA: 59s - loss: 0.2564 - iou_score: 0.7247 - f1-score: 0.8383 For batch 164, tr_loss is    0.26.\n",
      "166/232 [====================>.........] - ETA: 58s - loss: 0.2561 - iou_score: 0.7249 - f1-score: 0.8384For batch 165, tr_loss is    0.26.\n",
      "167/232 [====================>.........] - ETA: 57s - loss: 0.2559 - iou_score: 0.7251 - f1-score: 0.8386For batch 166, tr_loss is    0.26.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168/232 [====================>.........] - ETA: 56s - loss: 0.2561 - iou_score: 0.7249 - f1-score: 0.8384For batch 167, tr_loss is    0.26.\n",
      "169/232 [====================>.........] - ETA: 55s - loss: 0.2567 - iou_score: 0.7242 - f1-score: 0.8380For batch 168, tr_loss is    0.26.\n",
      "170/232 [====================>.........] - ETA: 55s - loss: 0.2567 - iou_score: 0.7243 - f1-score: 0.8380For batch 169, tr_loss is    0.26.\n",
      "171/232 [=====================>........] - ETA: 54s - loss: 0.2571 - iou_score: 0.7238 - f1-score: 0.8377For batch 170, tr_loss is    0.26.\n",
      "172/232 [=====================>........] - ETA: 53s - loss: 0.2573 - iou_score: 0.7235 - f1-score: 0.8375For batch 171, tr_loss is    0.26.\n",
      "173/232 [=====================>........] - ETA: 52s - loss: 0.2570 - iou_score: 0.7236 - f1-score: 0.8376For batch 172, tr_loss is    0.26.\n",
      "174/232 [=====================>........] - ETA: 51s - loss: 0.2567 - iou_score: 0.7240 - f1-score: 0.8378For batch 173, tr_loss is    0.26.\n",
      "175/232 [=====================>........] - ETA: 50s - loss: 0.2569 - iou_score: 0.7238 - f1-score: 0.8377For batch 174, tr_loss is    0.26.\n",
      "176/232 [=====================>........] - ETA: 49s - loss: 0.2571 - iou_score: 0.7235 - f1-score: 0.8375For batch 175, tr_loss is    0.26.\n",
      "177/232 [=====================>........] - ETA: 48s - loss: 0.2568 - iou_score: 0.7239 - f1-score: 0.8377For batch 176, tr_loss is    0.26.\n",
      "178/232 [======================>.......] - ETA: 48s - loss: 0.2568 - iou_score: 0.7239 - f1-score: 0.8378For batch 177, tr_loss is    0.26.\n",
      "179/232 [======================>.......] - ETA: 47s - loss: 0.2568 - iou_score: 0.7239 - f1-score: 0.8378For batch 178, tr_loss is    0.26.\n",
      "180/232 [======================>.......] - ETA: 46s - loss: 0.2567 - iou_score: 0.7239 - f1-score: 0.8378For batch 179, tr_loss is    0.26.\n",
      "181/232 [======================>.......] - ETA: 45s - loss: 0.2569 - iou_score: 0.7237 - f1-score: 0.8376For batch 180, tr_loss is    0.26.\n",
      "182/232 [======================>.......] - ETA: 44s - loss: 0.2570 - iou_score: 0.7237 - f1-score: 0.8376For batch 181, tr_loss is    0.26.\n",
      "183/232 [======================>.......] - ETA: 43s - loss: 0.2570 - iou_score: 0.7236 - f1-score: 0.8376For batch 182, tr_loss is    0.26.\n",
      "184/232 [======================>.......] - ETA: 42s - loss: 0.2568 - iou_score: 0.7240 - f1-score: 0.8378For batch 183, tr_loss is    0.26.\n",
      "185/232 [======================>.......] - ETA: 41s - loss: 0.2567 - iou_score: 0.7239 - f1-score: 0.8378For batch 184, tr_loss is    0.26.\n",
      "186/232 [=======================>......] - ETA: 40s - loss: 0.2568 - iou_score: 0.7238 - f1-score: 0.8377For batch 185, tr_loss is    0.26.\n",
      "187/232 [=======================>......] - ETA: 39s - loss: 0.2564 - iou_score: 0.7243 - f1-score: 0.8381For batch 186, tr_loss is    0.26.\n",
      "188/232 [=======================>......] - ETA: 39s - loss: 0.2564 - iou_score: 0.7242 - f1-score: 0.8380For batch 187, tr_loss is    0.26.\n",
      "189/232 [=======================>......] - ETA: 38s - loss: 0.2563 - iou_score: 0.7244 - f1-score: 0.8381For batch 188, tr_loss is    0.26.\n",
      "190/232 [=======================>......] - ETA: 37s - loss: 0.2562 - iou_score: 0.7245 - f1-score: 0.8382For batch 189, tr_loss is    0.26.\n",
      "191/232 [=======================>......] - ETA: 36s - loss: 0.2563 - iou_score: 0.7246 - f1-score: 0.8383For batch 190, tr_loss is    0.26.\n",
      "192/232 [=======================>......] - ETA: 35s - loss: 0.2565 - iou_score: 0.7243 - f1-score: 0.8381For batch 191, tr_loss is    0.26.\n",
      "193/232 [=======================>......] - ETA: 34s - loss: 0.2568 - iou_score: 0.7239 - f1-score: 0.8378For batch 192, tr_loss is    0.26.\n",
      "194/232 [========================>.....] - ETA: 33s - loss: 0.2568 - iou_score: 0.7239 - f1-score: 0.8378For batch 193, tr_loss is    0.26.\n",
      "195/232 [========================>.....] - ETA: 32s - loss: 0.2567 - iou_score: 0.7238 - f1-score: 0.8378For batch 194, tr_loss is    0.26.\n",
      "196/232 [========================>.....] - ETA: 31s - loss: 0.2566 - iou_score: 0.7239 - f1-score: 0.8378For batch 195, tr_loss is    0.26.\n",
      "197/232 [========================>.....] - ETA: 31s - loss: 0.2565 - iou_score: 0.7240 - f1-score: 0.8379For batch 196, tr_loss is    0.26.\n",
      "198/232 [========================>.....] - ETA: 30s - loss: 0.2563 - iou_score: 0.7245 - f1-score: 0.8382For batch 197, tr_loss is    0.26.\n",
      "199/232 [========================>.....] - ETA: 29s - loss: 0.2561 - iou_score: 0.7247 - f1-score: 0.8383For batch 198, tr_loss is    0.26.\n",
      "200/232 [========================>.....] - ETA: 28s - loss: 0.2557 - iou_score: 0.7251 - f1-score: 0.8386For batch 199, tr_loss is    0.26.\n",
      "201/232 [========================>.....] - ETA: 27s - loss: 0.2557 - iou_score: 0.7250 - f1-score: 0.8386For batch 200, tr_loss is    0.26.\n",
      "202/232 [=========================>....] - ETA: 26s - loss: 0.2557 - iou_score: 0.7250 - f1-score: 0.8386For batch 201, tr_loss is    0.26.\n",
      "203/232 [=========================>....] - ETA: 25s - loss: 0.2554 - iou_score: 0.7252 - f1-score: 0.8387For batch 202, tr_loss is    0.26.\n",
      "204/232 [=========================>....] - ETA: 24s - loss: 0.2551 - iou_score: 0.7256 - f1-score: 0.8389For batch 203, tr_loss is    0.26.\n",
      "205/232 [=========================>....] - ETA: 23s - loss: 0.2550 - iou_score: 0.7255 - f1-score: 0.8389For batch 204, tr_loss is    0.26.\n",
      "206/232 [=========================>....] - ETA: 23s - loss: 0.2552 - iou_score: 0.7255 - f1-score: 0.8389For batch 205, tr_loss is    0.26.\n",
      "207/232 [=========================>....] - ETA: 22s - loss: 0.2552 - iou_score: 0.7256 - f1-score: 0.8389For batch 206, tr_loss is    0.26.\n",
      "208/232 [=========================>....] - ETA: 21s - loss: 0.2550 - iou_score: 0.7256 - f1-score: 0.8390For batch 207, tr_loss is    0.25.\n",
      "209/232 [==========================>...] - ETA: 20s - loss: 0.2551 - iou_score: 0.7255 - f1-score: 0.8389For batch 208, tr_loss is    0.26.\n",
      "210/232 [==========================>...] - ETA: 19s - loss: 0.2554 - iou_score: 0.7251 - f1-score: 0.8386For batch 209, tr_loss is    0.26.\n",
      "211/232 [==========================>...] - ETA: 18s - loss: 0.2552 - iou_score: 0.7253 - f1-score: 0.8388For batch 210, tr_loss is    0.26.\n",
      "212/232 [==========================>...] - ETA: 17s - loss: 0.2549 - iou_score: 0.7256 - f1-score: 0.8390For batch 211, tr_loss is    0.25.\n",
      "213/232 [==========================>...] - ETA: 16s - loss: 0.2550 - iou_score: 0.7255 - f1-score: 0.8389For batch 212, tr_loss is    0.25.\n",
      "214/232 [==========================>...] - ETA: 15s - loss: 0.2548 - iou_score: 0.7257 - f1-score: 0.8391For batch 213, tr_loss is    0.25.\n",
      "215/232 [==========================>...] - ETA: 15s - loss: 0.2545 - iou_score: 0.7261 - f1-score: 0.8394For batch 214, tr_loss is    0.25.\n",
      "216/232 [==========================>...] - ETA: 14s - loss: 0.2543 - iou_score: 0.7263 - f1-score: 0.8395For batch 215, tr_loss is    0.25.\n",
      "217/232 [===========================>..] - ETA: 13s - loss: 0.2543 - iou_score: 0.7262 - f1-score: 0.8394For batch 216, tr_loss is    0.25.\n",
      "218/232 [===========================>..] - ETA: 12s - loss: 0.2543 - iou_score: 0.7261 - f1-score: 0.8393For batch 217, tr_loss is    0.25.\n",
      "219/232 [===========================>..] - ETA: 11s - loss: 0.2548 - iou_score: 0.7256 - f1-score: 0.8389For batch 218, tr_loss is    0.25.\n",
      "220/232 [===========================>..] - ETA: 10s - loss: 0.2548 - iou_score: 0.7255 - f1-score: 0.8389For batch 219, tr_loss is    0.25.\n",
      "221/232 [===========================>..] - ETA: 9s - loss: 0.2548 - iou_score: 0.7253 - f1-score: 0.8388 For batch 220, tr_loss is    0.25.\n",
      "222/232 [===========================>..] - ETA: 8s - loss: 0.2546 - iou_score: 0.7256 - f1-score: 0.8390For batch 221, tr_loss is    0.25.\n",
      "223/232 [===========================>..] - ETA: 7s - loss: 0.2546 - iou_score: 0.7254 - f1-score: 0.8388For batch 222, tr_loss is    0.25.\n",
      "224/232 [===========================>..] - ETA: 7s - loss: 0.2544 - iou_score: 0.7257 - f1-score: 0.8390For batch 223, tr_loss is    0.25.\n",
      "225/232 [============================>.] - ETA: 6s - loss: 0.2541 - iou_score: 0.7260 - f1-score: 0.8393For batch 224, tr_loss is    0.25.\n",
      "226/232 [============================>.] - ETA: 5s - loss: 0.2541 - iou_score: 0.7259 - f1-score: 0.8392For batch 225, tr_loss is    0.25.\n",
      "227/232 [============================>.] - ETA: 4s - loss: 0.2539 - iou_score: 0.7261 - f1-score: 0.8393For batch 226, tr_loss is    0.25.\n",
      "228/232 [============================>.] - ETA: 3s - loss: 0.2542 - iou_score: 0.7259 - f1-score: 0.8392For batch 227, tr_loss is    0.25.\n",
      "229/232 [============================>.] - ETA: 2s - loss: 0.2539 - iou_score: 0.7262 - f1-score: 0.8394For batch 228, tr_loss is    0.25.\n",
      "230/232 [============================>.] - ETA: 1s - loss: 0.2543 - iou_score: 0.7258 - f1-score: 0.8391For batch 229, tr_loss is    0.25.\n",
      "231/232 [============================>.] - ETA: 0s - loss: 0.2547 - iou_score: 0.7255 - f1-score: 0.8389For batch 230, tr_loss is    0.25.\n",
      "232/232 [==============================] - ETA: 0s - loss: 0.2544 - iou_score: 0.7258 - f1-score: 0.8391For batch 231, tr_loss is    0.25.\n",
      "For batch 0, vl_loss is    0.48.\n",
      "For batch 1, vl_loss is    0.47.\n",
      "For batch 2, vl_loss is    0.48.\n",
      "For batch 3, vl_loss is    0.50.\n",
      "For batch 4, vl_loss is    0.54.\n",
      "For batch 5, vl_loss is    0.51.\n",
      "For batch 6, vl_loss is    0.51.\n",
      "For batch 7, vl_loss is    0.51.\n",
      "For batch 8, vl_loss is    0.50.\n",
      "For batch 9, vl_loss is    0.48.\n",
      "For batch 10, vl_loss is    0.47.\n",
      "For batch 11, vl_loss is    0.48.\n",
      "For batch 12, vl_loss is    0.49.\n",
      "For batch 13, vl_loss is    0.50.\n",
      "For batch 14, vl_loss is    0.49.\n",
      "For batch 15, vl_loss is    0.48.\n",
      "For batch 16, vl_loss is    0.48.\n",
      "For batch 17, vl_loss is    0.48.\n",
      "For batch 18, vl_loss is    0.48.\n",
      "For batch 19, vl_loss is    0.48.\n",
      "For batch 20, vl_loss is    0.47.\n",
      "For batch 21, vl_loss is    0.47.\n",
      "For batch 22, vl_loss is    0.47.\n",
      "For batch 23, vl_loss is    0.47.\n",
      "For batch 24, vl_loss is    0.47.\n",
      "For batch 25, vl_loss is    0.46.\n",
      "For batch 26, vl_loss is    0.46.\n",
      "For batch 27, vl_loss is    0.47.\n",
      "For batch 28, vl_loss is    0.47.\n",
      "For batch 29, vl_loss is    0.47.\n",
      "For batch 30, vl_loss is    0.47.\n",
      "For batch 31, vl_loss is    0.47.\n",
      "For batch 32, vl_loss is    0.47.\n",
      "For batch 33, vl_loss is    0.47.\n",
      "For batch 34, vl_loss is    0.47.\n",
      "For batch 35, vl_loss is    0.47.\n",
      "For batch 36, vl_loss is    0.47.\n",
      "For batch 37, vl_loss is    0.47.\n",
      "For batch 38, vl_loss is    0.47.\n",
      "For batch 39, vl_loss is    0.47.\n",
      "For batch 40, vl_loss is    0.47.\n",
      "For batch 41, vl_loss is    0.47.\n",
      "For batch 42, vl_loss is    0.48.\n",
      "For batch 43, vl_loss is    0.48.\n",
      "For batch 44, vl_loss is    0.48.\n",
      "For batch 45, vl_loss is    0.48.\n",
      "For batch 46, vl_loss is    0.48.\n",
      "For batch 47, vl_loss is    0.48.\n",
      "For batch 48, vl_loss is    0.48.\n",
      "For batch 49, vl_loss is    0.48.\n",
      "For batch 50, vl_loss is    0.48.\n",
      "For batch 51, vl_loss is    0.48.\n",
      "For batch 52, vl_loss is    0.48.\n",
      "For batch 53, vl_loss is    0.49.\n",
      "For batch 54, vl_loss is    0.49.\n",
      "For batch 55, vl_loss is    0.49.\n",
      "For batch 56, vl_loss is    0.48.\n",
      "For batch 57, vl_loss is    0.49.\n",
      "For batch 58, vl_loss is    0.48.\n",
      "For batch 59, vl_loss is    0.48.\n",
      "For batch 60, vl_loss is    0.48.\n",
      "For batch 61, vl_loss is    0.48.\n",
      "For batch 62, vl_loss is    0.48.\n",
      "For batch 63, vl_loss is    0.48.\n",
      "For batch 64, vl_loss is    0.48.\n",
      "For batch 65, vl_loss is    0.47.\n",
      "For batch 66, vl_loss is    0.47.\n",
      "For batch 67, vl_loss is    0.47.\n",
      "232/232 [==============================] - 209s 892ms/step - loss: 0.2544 - iou_score: 0.7258 - f1-score: 0.8391 - val_loss: 0.4732 - val_iou_score: 0.6393 - val_f1-score: 0.7778\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.36098\n",
      "The average loss for epoch 11 is    0.25 \n",
      "Epoch 13/200\n",
      "  1/232 [..............................] - ETA: 12:30 - loss: 0.2201 - iou_score: 0.7741 - f1-score: 0.8706For batch 0, tr_loss is    0.22.\n",
      "  2/232 [..............................] - ETA: 5:03 - loss: 0.2206 - iou_score: 0.7778 - f1-score: 0.8740 For batch 1, tr_loss is    0.22.\n",
      "  3/232 [..............................] - ETA: 5:08 - loss: 0.2397 - iou_score: 0.7449 - f1-score: 0.8522For batch 2, tr_loss is    0.24.\n",
      "  4/232 [..............................] - ETA: 5:17 - loss: 0.2398 - iou_score: 0.7505 - f1-score: 0.8562For batch 3, tr_loss is    0.24.\n",
      "  5/232 [..............................] - ETA: 4:49 - loss: 0.2459 - iou_score: 0.7411 - f1-score: 0.8500For batch 4, tr_loss is    0.25.\n",
      "  6/232 [..............................] - ETA: 5:02 - loss: 0.2496 - iou_score: 0.7363 - f1-score: 0.8463For batch 5, tr_loss is    0.25.\n",
      "  7/232 [..............................] - ETA: 4:56 - loss: 0.2591 - iou_score: 0.7251 - f1-score: 0.8389For batch 6, tr_loss is    0.26.\n",
      "  8/232 [>.............................] - ETA: 4:39 - loss: 0.2616 - iou_score: 0.7188 - f1-score: 0.8347For batch 7, tr_loss is    0.26.\n",
      "  9/232 [>.............................] - ETA: 4:29 - loss: 0.2525 - iou_score: 0.7301 - f1-score: 0.8421For batch 8, tr_loss is    0.25.\n",
      " 10/232 [>.............................] - ETA: 4:10 - loss: 0.2527 - iou_score: 0.7281 - f1-score: 0.8408For batch 9, tr_loss is    0.25.\n",
      " 11/232 [>.............................] - ETA: 4:10 - loss: 0.2502 - iou_score: 0.7296 - f1-score: 0.8419For batch 10, tr_loss is    0.25.\n",
      " 12/232 [>.............................] - ETA: 4:07 - loss: 0.2475 - iou_score: 0.7357 - f1-score: 0.8460For batch 11, tr_loss is    0.25.\n",
      " 13/232 [>.............................] - ETA: 4:05 - loss: 0.2449 - iou_score: 0.7383 - f1-score: 0.8475For batch 12, tr_loss is    0.24.\n",
      " 14/232 [>.............................] - ETA: 3:58 - loss: 0.2422 - iou_score: 0.7411 - f1-score: 0.8494For batch 13, tr_loss is    0.24.\n",
      " 15/232 [>.............................] - ETA: 3:51 - loss: 0.2386 - iou_score: 0.7451 - f1-score: 0.8521For batch 14, tr_loss is    0.24.\n",
      " 16/232 [=>............................] - ETA: 3:49 - loss: 0.2360 - iou_score: 0.7473 - f1-score: 0.8536For batch 15, tr_loss is    0.24.\n",
      " 17/232 [=>............................] - ETA: 3:48 - loss: 0.2337 - iou_score: 0.7498 - f1-score: 0.8553For batch 16, tr_loss is    0.23.\n",
      " 18/232 [=>............................] - ETA: 3:47 - loss: 0.2340 - iou_score: 0.7498 - f1-score: 0.8554For batch 17, tr_loss is    0.23.\n",
      " 19/232 [=>............................] - ETA: 3:39 - loss: 0.2360 - iou_score: 0.7464 - f1-score: 0.8532For batch 18, tr_loss is    0.24.\n",
      " 20/232 [=>............................] - ETA: 3:35 - loss: 0.2338 - iou_score: 0.7482 - f1-score: 0.8544For batch 19, tr_loss is    0.23.\n",
      " 21/232 [=>............................] - ETA: 3:34 - loss: 0.2404 - iou_score: 0.7435 - f1-score: 0.8511For batch 20, tr_loss is    0.24.\n",
      " 22/232 [=>............................] - ETA: 3:33 - loss: 0.2417 - iou_score: 0.7408 - f1-score: 0.8492For batch 21, tr_loss is    0.24.\n",
      " 23/232 [=>............................] - ETA: 3:32 - loss: 0.2431 - iou_score: 0.7392 - f1-score: 0.8481For batch 22, tr_loss is    0.24.\n",
      " 24/232 [==>...........................] - ETA: 3:25 - loss: 0.2421 - iou_score: 0.7404 - f1-score: 0.8490For batch 23, tr_loss is    0.24.\n",
      " 25/232 [==>...........................] - ETA: 3:22 - loss: 0.2461 - iou_score: 0.7363 - f1-score: 0.8462For batch 24, tr_loss is    0.25.\n",
      " 26/232 [==>...........................] - ETA: 3:21 - loss: 0.2465 - iou_score: 0.7353 - f1-score: 0.8455For batch 25, tr_loss is    0.25.\n",
      " 27/232 [==>...........................] - ETA: 3:16 - loss: 0.2448 - iou_score: 0.7369 - f1-score: 0.8466For batch 26, tr_loss is    0.24.\n",
      " 28/232 [==>...........................] - ETA: 3:14 - loss: 0.2449 - iou_score: 0.7372 - f1-score: 0.8468For batch 27, tr_loss is    0.24.\n",
      " 29/232 [==>...........................] - ETA: 3:13 - loss: 0.2443 - iou_score: 0.7375 - f1-score: 0.8470For batch 28, tr_loss is    0.24.\n",
      " 30/232 [==>...........................] - ETA: 3:13 - loss: 0.2437 - iou_score: 0.7382 - f1-score: 0.8475For batch 29, tr_loss is    0.24.\n",
      " 31/232 [===>..........................] - ETA: 3:09 - loss: 0.2433 - iou_score: 0.7389 - f1-score: 0.8480For batch 30, tr_loss is    0.24.\n",
      " 32/232 [===>..........................] - ETA: 3:09 - loss: 0.2430 - iou_score: 0.7394 - f1-score: 0.8485For batch 31, tr_loss is    0.24.\n",
      " 33/232 [===>..........................] - ETA: 3:08 - loss: 0.2459 - iou_score: 0.7366 - f1-score: 0.8465For batch 32, tr_loss is    0.25.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 34/232 [===>..........................] - ETA: 3:07 - loss: 0.2455 - iou_score: 0.7371 - f1-score: 0.8469For batch 33, tr_loss is    0.25.\n",
      " 35/232 [===>..........................] - ETA: 3:07 - loss: 0.2473 - iou_score: 0.7351 - f1-score: 0.8456For batch 34, tr_loss is    0.25.\n",
      " 36/232 [===>..........................] - ETA: 3:03 - loss: 0.2482 - iou_score: 0.7352 - f1-score: 0.8456For batch 35, tr_loss is    0.25.\n",
      " 37/232 [===>..........................] - ETA: 3:02 - loss: 0.2488 - iou_score: 0.7341 - f1-score: 0.8449For batch 36, tr_loss is    0.25.\n",
      " 38/232 [===>..........................] - ETA: 3:02 - loss: 0.2503 - iou_score: 0.7326 - f1-score: 0.8440For batch 37, tr_loss is    0.25.\n",
      " 39/232 [====>.........................] - ETA: 3:01 - loss: 0.2541 - iou_score: 0.7279 - f1-score: 0.8405For batch 38, tr_loss is    0.25.\n",
      " 40/232 [====>.........................] - ETA: 3:01 - loss: 0.2550 - iou_score: 0.7272 - f1-score: 0.8400For batch 39, tr_loss is    0.25.\n",
      " 41/232 [====>.........................] - ETA: 2:59 - loss: 0.2565 - iou_score: 0.7256 - f1-score: 0.8390For batch 40, tr_loss is    0.26.\n",
      " 42/232 [====>.........................] - ETA: 2:58 - loss: 0.2565 - iou_score: 0.7249 - f1-score: 0.8386For batch 41, tr_loss is    0.26.\n",
      " 43/232 [====>.........................] - ETA: 2:58 - loss: 0.2556 - iou_score: 0.7258 - f1-score: 0.8392For batch 42, tr_loss is    0.26.\n",
      " 44/232 [====>.........................] - ETA: 2:57 - loss: 0.2573 - iou_score: 0.7236 - f1-score: 0.8375For batch 43, tr_loss is    0.26.\n",
      " 45/232 [====>.........................] - ETA: 2:56 - loss: 0.2587 - iou_score: 0.7236 - f1-score: 0.8375For batch 44, tr_loss is    0.26.\n",
      " 46/232 [====>.........................] - ETA: 2:56 - loss: 0.2586 - iou_score: 0.7237 - f1-score: 0.8376For batch 45, tr_loss is    0.26.\n",
      " 47/232 [=====>........................] - ETA: 2:55 - loss: 0.2583 - iou_score: 0.7239 - f1-score: 0.8378For batch 46, tr_loss is    0.26.\n",
      " 48/232 [=====>........................] - ETA: 2:55 - loss: 0.2573 - iou_score: 0.7252 - f1-score: 0.8387For batch 47, tr_loss is    0.26.\n",
      " 49/232 [=====>........................] - ETA: 2:54 - loss: 0.2575 - iou_score: 0.7251 - f1-score: 0.8386For batch 48, tr_loss is    0.26.\n",
      " 50/232 [=====>........................] - ETA: 2:53 - loss: 0.2573 - iou_score: 0.7253 - f1-score: 0.8388For batch 49, tr_loss is    0.26.\n",
      " 51/232 [=====>........................] - ETA: 2:52 - loss: 0.2584 - iou_score: 0.7244 - f1-score: 0.8382For batch 50, tr_loss is    0.26.\n",
      " 52/232 [=====>........................] - ETA: 2:51 - loss: 0.2606 - iou_score: 0.7223 - f1-score: 0.8367For batch 51, tr_loss is    0.26.\n",
      " 53/232 [=====>........................] - ETA: 2:50 - loss: 0.2596 - iou_score: 0.7237 - f1-score: 0.8376For batch 52, tr_loss is    0.26.\n",
      " 54/232 [=====>........................] - ETA: 2:48 - loss: 0.2599 - iou_score: 0.7234 - f1-score: 0.8374For batch 53, tr_loss is    0.26.\n",
      " 55/232 [======>.......................] - ETA: 2:48 - loss: 0.2598 - iou_score: 0.7234 - f1-score: 0.8375For batch 54, tr_loss is    0.26.\n",
      " 56/232 [======>.......................] - ETA: 2:47 - loss: 0.2593 - iou_score: 0.7237 - f1-score: 0.8377For batch 55, tr_loss is    0.26.\n",
      " 57/232 [======>.......................] - ETA: 2:46 - loss: 0.2599 - iou_score: 0.7232 - f1-score: 0.8373For batch 56, tr_loss is    0.26.\n",
      " 58/232 [======>.......................] - ETA: 2:44 - loss: 0.2595 - iou_score: 0.7240 - f1-score: 0.8379For batch 57, tr_loss is    0.26.\n",
      " 59/232 [======>.......................] - ETA: 2:43 - loss: 0.2588 - iou_score: 0.7246 - f1-score: 0.8383For batch 58, tr_loss is    0.26.\n",
      " 60/232 [======>.......................] - ETA: 2:42 - loss: 0.2609 - iou_score: 0.7226 - f1-score: 0.8368For batch 59, tr_loss is    0.26.\n",
      " 61/232 [======>.......................] - ETA: 2:42 - loss: 0.2630 - iou_score: 0.7207 - f1-score: 0.8354For batch 60, tr_loss is    0.26.\n",
      " 62/232 [=======>......................] - ETA: 2:40 - loss: 0.2639 - iou_score: 0.7195 - f1-score: 0.8345For batch 61, tr_loss is    0.26.\n",
      " 63/232 [=======>......................] - ETA: 2:39 - loss: 0.2635 - iou_score: 0.7198 - f1-score: 0.8348For batch 62, tr_loss is    0.26.\n",
      " 64/232 [=======>......................] - ETA: 2:37 - loss: 0.2634 - iou_score: 0.7200 - f1-score: 0.8349For batch 63, tr_loss is    0.26.\n",
      " 65/232 [=======>......................] - ETA: 2:35 - loss: 0.2634 - iou_score: 0.7199 - f1-score: 0.8349For batch 64, tr_loss is    0.26.\n",
      " 66/232 [=======>......................] - ETA: 2:35 - loss: 0.2637 - iou_score: 0.7192 - f1-score: 0.8344For batch 65, tr_loss is    0.26.\n",
      " 67/232 [=======>......................] - ETA: 2:34 - loss: 0.2629 - iou_score: 0.7200 - f1-score: 0.8350For batch 66, tr_loss is    0.26.\n",
      " 68/232 [=======>......................] - ETA: 2:32 - loss: 0.2627 - iou_score: 0.7205 - f1-score: 0.8353For batch 67, tr_loss is    0.26.\n",
      " 69/232 [=======>......................] - ETA: 2:32 - loss: 0.2632 - iou_score: 0.7203 - f1-score: 0.8352For batch 68, tr_loss is    0.26.\n",
      " 70/232 [========>.....................] - ETA: 2:30 - loss: 0.2629 - iou_score: 0.7206 - f1-score: 0.8354For batch 69, tr_loss is    0.26.\n",
      " 71/232 [========>.....................] - ETA: 2:28 - loss: 0.2621 - iou_score: 0.7218 - f1-score: 0.8362For batch 70, tr_loss is    0.26.\n",
      " 72/232 [========>.....................] - ETA: 2:27 - loss: 0.2614 - iou_score: 0.7224 - f1-score: 0.8366For batch 71, tr_loss is    0.26.\n",
      " 73/232 [========>.....................] - ETA: 2:27 - loss: 0.2613 - iou_score: 0.7221 - f1-score: 0.8365For batch 72, tr_loss is    0.26.\n",
      " 74/232 [========>.....................] - ETA: 2:25 - loss: 0.2606 - iou_score: 0.7230 - f1-score: 0.8370For batch 73, tr_loss is    0.26.\n",
      " 75/232 [========>.....................] - ETA: 2:24 - loss: 0.2604 - iou_score: 0.7231 - f1-score: 0.8371For batch 74, tr_loss is    0.26.\n",
      " 76/232 [========>.....................] - ETA: 2:22 - loss: 0.2598 - iou_score: 0.7235 - f1-score: 0.8374For batch 75, tr_loss is    0.26.\n",
      " 77/232 [========>.....................] - ETA: 2:21 - loss: 0.2590 - iou_score: 0.7241 - f1-score: 0.8379For batch 76, tr_loss is    0.26.\n",
      " 78/232 [=========>....................] - ETA: 2:20 - loss: 0.2590 - iou_score: 0.7239 - f1-score: 0.8377For batch 77, tr_loss is    0.26.\n",
      " 79/232 [=========>....................] - ETA: 2:19 - loss: 0.2583 - iou_score: 0.7246 - f1-score: 0.8382For batch 78, tr_loss is    0.26.\n",
      " 80/232 [=========>....................] - ETA: 2:18 - loss: 0.2590 - iou_score: 0.7244 - f1-score: 0.8381For batch 79, tr_loss is    0.26.\n",
      " 81/232 [=========>....................] - ETA: 2:17 - loss: 0.2592 - iou_score: 0.7240 - f1-score: 0.8378For batch 80, tr_loss is    0.26.\n",
      " 82/232 [=========>....................] - ETA: 2:16 - loss: 0.2592 - iou_score: 0.7238 - f1-score: 0.8377For batch 81, tr_loss is    0.26.\n",
      " 83/232 [=========>....................] - ETA: 2:15 - loss: 0.2598 - iou_score: 0.7230 - f1-score: 0.8372For batch 82, tr_loss is    0.26.\n",
      " 84/232 [=========>....................] - ETA: 2:14 - loss: 0.2602 - iou_score: 0.7226 - f1-score: 0.8369For batch 83, tr_loss is    0.26.\n",
      " 85/232 [=========>....................] - ETA: 2:13 - loss: 0.2602 - iou_score: 0.7226 - f1-score: 0.8369For batch 84, tr_loss is    0.26.\n",
      " 86/232 [==========>...................] - ETA: 2:11 - loss: 0.2607 - iou_score: 0.7218 - f1-score: 0.8364For batch 85, tr_loss is    0.26.\n",
      " 87/232 [==========>...................] - ETA: 2:10 - loss: 0.2604 - iou_score: 0.7220 - f1-score: 0.8365For batch 86, tr_loss is    0.26.\n",
      " 88/232 [==========>...................] - ETA: 2:10 - loss: 0.2605 - iou_score: 0.7219 - f1-score: 0.8365For batch 87, tr_loss is    0.26.\n",
      " 89/232 [==========>...................] - ETA: 2:08 - loss: 0.2601 - iou_score: 0.7222 - f1-score: 0.8367For batch 88, tr_loss is    0.26.\n",
      " 90/232 [==========>...................] - ETA: 2:08 - loss: 0.2596 - iou_score: 0.7227 - f1-score: 0.8371For batch 89, tr_loss is    0.26.\n",
      " 91/232 [==========>...................] - ETA: 2:06 - loss: 0.2595 - iou_score: 0.7228 - f1-score: 0.8371For batch 90, tr_loss is    0.26.\n",
      " 92/232 [==========>...................] - ETA: 2:06 - loss: 0.2595 - iou_score: 0.7230 - f1-score: 0.8372For batch 91, tr_loss is    0.26.\n",
      " 93/232 [===========>..................] - ETA: 2:04 - loss: 0.2604 - iou_score: 0.7218 - f1-score: 0.8364For batch 92, tr_loss is    0.26.\n",
      " 94/232 [===========>..................] - ETA: 2:04 - loss: 0.2596 - iou_score: 0.7227 - f1-score: 0.8370For batch 93, tr_loss is    0.26.\n",
      " 95/232 [===========>..................] - ETA: 2:03 - loss: 0.2601 - iou_score: 0.7223 - f1-score: 0.8367For batch 94, tr_loss is    0.26.\n",
      " 96/232 [===========>..................] - ETA: 2:02 - loss: 0.2598 - iou_score: 0.7224 - f1-score: 0.8368For batch 95, tr_loss is    0.26.\n",
      " 97/232 [===========>..................] - ETA: 2:01 - loss: 0.2600 - iou_score: 0.7222 - f1-score: 0.8367For batch 96, tr_loss is    0.26.\n",
      " 98/232 [===========>..................] - ETA: 2:00 - loss: 0.2597 - iou_score: 0.7222 - f1-score: 0.8367For batch 97, tr_loss is    0.26.\n",
      " 99/232 [===========>..................] - ETA: 1:59 - loss: 0.2588 - iou_score: 0.7234 - f1-score: 0.8375For batch 98, tr_loss is    0.26.\n",
      "100/232 [===========>..................] - ETA: 1:58 - loss: 0.2582 - iou_score: 0.7241 - f1-score: 0.8379For batch 99, tr_loss is    0.26.\n",
      "101/232 [============>.................] - ETA: 1:57 - loss: 0.2576 - iou_score: 0.7248 - f1-score: 0.8384For batch 100, tr_loss is    0.26.\n",
      "102/232 [============>.................] - ETA: 1:56 - loss: 0.2576 - iou_score: 0.7249 - f1-score: 0.8385For batch 101, tr_loss is    0.26.\n",
      "103/232 [============>.................] - ETA: 1:54 - loss: 0.2576 - iou_score: 0.7250 - f1-score: 0.8385For batch 102, tr_loss is    0.26.\n",
      "104/232 [============>.................] - ETA: 1:53 - loss: 0.2575 - iou_score: 0.7251 - f1-score: 0.8386For batch 103, tr_loss is    0.26.\n",
      "105/232 [============>.................] - ETA: 1:52 - loss: 0.2568 - iou_score: 0.7259 - f1-score: 0.8392For batch 104, tr_loss is    0.26.\n",
      "106/232 [============>.................] - ETA: 1:51 - loss: 0.2561 - iou_score: 0.7267 - f1-score: 0.8397For batch 105, tr_loss is    0.26.\n",
      "107/232 [============>.................] - ETA: 1:50 - loss: 0.2564 - iou_score: 0.7265 - f1-score: 0.8395For batch 106, tr_loss is    0.26.\n",
      "108/232 [============>.................] - ETA: 1:49 - loss: 0.2568 - iou_score: 0.7258 - f1-score: 0.8391For batch 107, tr_loss is    0.26.\n",
      "109/232 [=============>................] - ETA: 1:48 - loss: 0.2563 - iou_score: 0.7262 - f1-score: 0.8393For batch 108, tr_loss is    0.26.\n",
      "110/232 [=============>................] - ETA: 1:46 - loss: 0.2556 - iou_score: 0.7272 - f1-score: 0.8400For batch 109, tr_loss is    0.26.\n",
      "111/232 [=============>................] - ETA: 1:45 - loss: 0.2555 - iou_score: 0.7270 - f1-score: 0.8398For batch 110, tr_loss is    0.26.\n",
      "112/232 [=============>................] - ETA: 1:45 - loss: 0.2556 - iou_score: 0.7268 - f1-score: 0.8398For batch 111, tr_loss is    0.26.\n",
      "113/232 [=============>................] - ETA: 1:44 - loss: 0.2562 - iou_score: 0.7265 - f1-score: 0.8395For batch 112, tr_loss is    0.26.\n",
      "114/232 [=============>................] - ETA: 1:43 - loss: 0.2556 - iou_score: 0.7272 - f1-score: 0.8400For batch 113, tr_loss is    0.26.\n",
      "115/232 [=============>................] - ETA: 1:42 - loss: 0.2553 - iou_score: 0.7272 - f1-score: 0.8401For batch 114, tr_loss is    0.26.\n",
      "116/232 [==============>...............] - ETA: 1:41 - loss: 0.2549 - iou_score: 0.7277 - f1-score: 0.8404For batch 115, tr_loss is    0.25.\n",
      "117/232 [==============>...............] - ETA: 1:40 - loss: 0.2548 - iou_score: 0.7277 - f1-score: 0.8404For batch 116, tr_loss is    0.25.\n",
      "118/232 [==============>...............] - ETA: 1:39 - loss: 0.2544 - iou_score: 0.7284 - f1-score: 0.8409For batch 117, tr_loss is    0.25.\n",
      "119/232 [==============>...............] - ETA: 1:39 - loss: 0.2541 - iou_score: 0.7289 - f1-score: 0.8412For batch 118, tr_loss is    0.25.\n",
      "120/232 [==============>...............] - ETA: 1:38 - loss: 0.2548 - iou_score: 0.7283 - f1-score: 0.8408For batch 119, tr_loss is    0.25.\n",
      "121/232 [==============>...............] - ETA: 1:37 - loss: 0.2542 - iou_score: 0.7290 - f1-score: 0.8412For batch 120, tr_loss is    0.25.\n",
      "122/232 [==============>...............] - ETA: 1:36 - loss: 0.2547 - iou_score: 0.7283 - f1-score: 0.8407For batch 121, tr_loss is    0.25.\n",
      "123/232 [==============>...............] - ETA: 1:35 - loss: 0.2542 - iou_score: 0.7286 - f1-score: 0.8410For batch 122, tr_loss is    0.25.\n",
      "124/232 [===============>..............] - ETA: 1:34 - loss: 0.2543 - iou_score: 0.7285 - f1-score: 0.8409For batch 123, tr_loss is    0.25.\n",
      "125/232 [===============>..............] - ETA: 1:34 - loss: 0.2545 - iou_score: 0.7281 - f1-score: 0.8406For batch 124, tr_loss is    0.25.\n",
      "126/232 [===============>..............] - ETA: 1:33 - loss: 0.2544 - iou_score: 0.7284 - f1-score: 0.8409For batch 125, tr_loss is    0.25.\n",
      "127/232 [===============>..............] - ETA: 1:32 - loss: 0.2541 - iou_score: 0.7285 - f1-score: 0.8409For batch 126, tr_loss is    0.25.\n",
      "128/232 [===============>..............] - ETA: 1:31 - loss: 0.2543 - iou_score: 0.7281 - f1-score: 0.8407For batch 127, tr_loss is    0.25.\n",
      "129/232 [===============>..............] - ETA: 1:30 - loss: 0.2543 - iou_score: 0.7282 - f1-score: 0.8408For batch 128, tr_loss is    0.25.\n",
      "130/232 [===============>..............] - ETA: 1:29 - loss: 0.2542 - iou_score: 0.7284 - f1-score: 0.8409For batch 129, tr_loss is    0.25.\n",
      "131/232 [===============>..............] - ETA: 1:28 - loss: 0.2551 - iou_score: 0.7276 - f1-score: 0.8403For batch 130, tr_loss is    0.26.\n",
      "132/232 [================>.............] - ETA: 1:27 - loss: 0.2555 - iou_score: 0.7271 - f1-score: 0.8400For batch 131, tr_loss is    0.26.\n",
      "133/232 [================>.............] - ETA: 1:26 - loss: 0.2551 - iou_score: 0.7274 - f1-score: 0.8402For batch 132, tr_loss is    0.26.\n",
      "134/232 [================>.............] - ETA: 1:26 - loss: 0.2554 - iou_score: 0.7267 - f1-score: 0.8397For batch 133, tr_loss is    0.26.\n",
      "135/232 [================>.............] - ETA: 1:25 - loss: 0.2550 - iou_score: 0.7270 - f1-score: 0.8399For batch 134, tr_loss is    0.25.\n",
      "136/232 [================>.............] - ETA: 1:24 - loss: 0.2554 - iou_score: 0.7264 - f1-score: 0.8395For batch 135, tr_loss is    0.26.\n",
      "137/232 [================>.............] - ETA: 1:23 - loss: 0.2556 - iou_score: 0.7261 - f1-score: 0.8393For batch 136, tr_loss is    0.26.\n",
      "138/232 [================>.............] - ETA: 1:22 - loss: 0.2559 - iou_score: 0.7257 - f1-score: 0.8391For batch 137, tr_loss is    0.26.\n",
      "139/232 [================>.............] - ETA: 1:22 - loss: 0.2558 - iou_score: 0.7257 - f1-score: 0.8390For batch 138, tr_loss is    0.26.\n",
      "140/232 [=================>............] - ETA: 1:21 - loss: 0.2556 - iou_score: 0.7259 - f1-score: 0.8392For batch 139, tr_loss is    0.26.\n",
      "141/232 [=================>............] - ETA: 1:20 - loss: 0.2563 - iou_score: 0.7250 - f1-score: 0.8385For batch 140, tr_loss is    0.26.\n",
      "142/232 [=================>............] - ETA: 1:19 - loss: 0.2562 - iou_score: 0.7250 - f1-score: 0.8386For batch 141, tr_loss is    0.26.\n",
      "143/232 [=================>............] - ETA: 1:18 - loss: 0.2560 - iou_score: 0.7252 - f1-score: 0.8387For batch 142, tr_loss is    0.26.\n",
      "144/232 [=================>............] - ETA: 1:17 - loss: 0.2560 - iou_score: 0.7252 - f1-score: 0.8387For batch 143, tr_loss is    0.26.\n",
      "145/232 [=================>............] - ETA: 1:16 - loss: 0.2563 - iou_score: 0.7251 - f1-score: 0.8387For batch 144, tr_loss is    0.26.\n",
      "146/232 [=================>............] - ETA: 1:15 - loss: 0.2565 - iou_score: 0.7247 - f1-score: 0.8384For batch 145, tr_loss is    0.26.\n",
      "147/232 [==================>...........] - ETA: 1:14 - loss: 0.2563 - iou_score: 0.7251 - f1-score: 0.8386For batch 146, tr_loss is    0.26.\n",
      "148/232 [==================>...........] - ETA: 1:13 - loss: 0.2565 - iou_score: 0.7248 - f1-score: 0.8384For batch 147, tr_loss is    0.26.\n",
      "149/232 [==================>...........] - ETA: 1:12 - loss: 0.2565 - iou_score: 0.7247 - f1-score: 0.8384For batch 148, tr_loss is    0.26.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/232 [==================>...........] - ETA: 1:11 - loss: 0.2570 - iou_score: 0.7239 - f1-score: 0.8378For batch 149, tr_loss is    0.26.\n",
      "151/232 [==================>...........] - ETA: 1:11 - loss: 0.2571 - iou_score: 0.7236 - f1-score: 0.8376For batch 150, tr_loss is    0.26.\n",
      "152/232 [==================>...........] - ETA: 1:10 - loss: 0.2569 - iou_score: 0.7240 - f1-score: 0.8379For batch 151, tr_loss is    0.26.\n",
      "153/232 [==================>...........] - ETA: 1:09 - loss: 0.2570 - iou_score: 0.7238 - f1-score: 0.8377For batch 152, tr_loss is    0.26.\n",
      "154/232 [==================>...........] - ETA: 1:08 - loss: 0.2567 - iou_score: 0.7241 - f1-score: 0.8379For batch 153, tr_loss is    0.26.\n",
      "155/232 [===================>..........] - ETA: 1:07 - loss: 0.2566 - iou_score: 0.7240 - f1-score: 0.8379For batch 154, tr_loss is    0.26.\n",
      "156/232 [===================>..........] - ETA: 1:06 - loss: 0.2566 - iou_score: 0.7238 - f1-score: 0.8377For batch 155, tr_loss is    0.26.\n",
      "157/232 [===================>..........] - ETA: 1:05 - loss: 0.2572 - iou_score: 0.7234 - f1-score: 0.8374For batch 156, tr_loss is    0.26.\n",
      "158/232 [===================>..........] - ETA: 1:04 - loss: 0.2569 - iou_score: 0.7237 - f1-score: 0.8377For batch 157, tr_loss is    0.26.\n",
      "159/232 [===================>..........] - ETA: 1:03 - loss: 0.2565 - iou_score: 0.7241 - f1-score: 0.8380For batch 158, tr_loss is    0.26.\n",
      "160/232 [===================>..........] - ETA: 1:02 - loss: 0.2565 - iou_score: 0.7240 - f1-score: 0.8379For batch 159, tr_loss is    0.26.\n",
      "161/232 [===================>..........] - ETA: 1:01 - loss: 0.2561 - iou_score: 0.7244 - f1-score: 0.8382For batch 160, tr_loss is    0.26.\n",
      "162/232 [===================>..........] - ETA: 1:01 - loss: 0.2560 - iou_score: 0.7244 - f1-score: 0.8382For batch 161, tr_loss is    0.26.\n",
      "163/232 [====================>.........] - ETA: 1:00 - loss: 0.2557 - iou_score: 0.7247 - f1-score: 0.8384For batch 162, tr_loss is    0.26.\n",
      "164/232 [====================>.........] - ETA: 59s - loss: 0.2558 - iou_score: 0.7246 - f1-score: 0.8383 For batch 163, tr_loss is    0.26.\n",
      "165/232 [====================>.........] - ETA: 58s - loss: 0.2559 - iou_score: 0.7244 - f1-score: 0.8381For batch 164, tr_loss is    0.26.\n",
      "166/232 [====================>.........] - ETA: 57s - loss: 0.2556 - iou_score: 0.7246 - f1-score: 0.8383For batch 165, tr_loss is    0.26.\n",
      "167/232 [====================>.........] - ETA: 56s - loss: 0.2551 - iou_score: 0.7250 - f1-score: 0.8386For batch 166, tr_loss is    0.26.\n",
      "168/232 [====================>.........] - ETA: 55s - loss: 0.2556 - iou_score: 0.7247 - f1-score: 0.8384For batch 167, tr_loss is    0.26.\n",
      "169/232 [====================>.........] - ETA: 54s - loss: 0.2560 - iou_score: 0.7243 - f1-score: 0.8381For batch 168, tr_loss is    0.26.\n",
      "170/232 [====================>.........] - ETA: 54s - loss: 0.2560 - iou_score: 0.7243 - f1-score: 0.8381For batch 169, tr_loss is    0.26.\n",
      "171/232 [=====================>........] - ETA: 53s - loss: 0.2565 - iou_score: 0.7238 - f1-score: 0.8378For batch 170, tr_loss is    0.26.\n",
      "172/232 [=====================>........] - ETA: 52s - loss: 0.2566 - iou_score: 0.7236 - f1-score: 0.8376For batch 171, tr_loss is    0.26.\n",
      "173/232 [=====================>........] - ETA: 51s - loss: 0.2563 - iou_score: 0.7238 - f1-score: 0.8377For batch 172, tr_loss is    0.26.\n",
      "174/232 [=====================>........] - ETA: 50s - loss: 0.2561 - iou_score: 0.7241 - f1-score: 0.8379For batch 173, tr_loss is    0.26.\n",
      "175/232 [=====================>........] - ETA: 49s - loss: 0.2562 - iou_score: 0.7239 - f1-score: 0.8379For batch 174, tr_loss is    0.26.\n",
      "176/232 [=====================>........] - ETA: 48s - loss: 0.2562 - iou_score: 0.7238 - f1-score: 0.8378For batch 175, tr_loss is    0.26.\n",
      "177/232 [=====================>........] - ETA: 47s - loss: 0.2559 - iou_score: 0.7242 - f1-score: 0.8381For batch 176, tr_loss is    0.26.\n",
      "178/232 [======================>.......] - ETA: 46s - loss: 0.2559 - iou_score: 0.7244 - f1-score: 0.8382For batch 177, tr_loss is    0.26.\n",
      "179/232 [======================>.......] - ETA: 46s - loss: 0.2558 - iou_score: 0.7245 - f1-score: 0.8382For batch 178, tr_loss is    0.26.\n",
      "180/232 [======================>.......] - ETA: 45s - loss: 0.2558 - iou_score: 0.7243 - f1-score: 0.8382For batch 179, tr_loss is    0.26.\n",
      "181/232 [======================>.......] - ETA: 44s - loss: 0.2557 - iou_score: 0.7243 - f1-score: 0.8382For batch 180, tr_loss is    0.26.\n",
      "182/232 [======================>.......] - ETA: 43s - loss: 0.2557 - iou_score: 0.7243 - f1-score: 0.8382For batch 181, tr_loss is    0.26.\n",
      "183/232 [======================>.......] - ETA: 42s - loss: 0.2557 - iou_score: 0.7244 - f1-score: 0.8382For batch 182, tr_loss is    0.26.\n",
      "184/232 [======================>.......] - ETA: 41s - loss: 0.2553 - iou_score: 0.7249 - f1-score: 0.8386For batch 183, tr_loss is    0.26.\n",
      "185/232 [======================>.......] - ETA: 41s - loss: 0.2553 - iou_score: 0.7248 - f1-score: 0.8385For batch 184, tr_loss is    0.26.\n",
      "186/232 [=======================>......] - ETA: 40s - loss: 0.2554 - iou_score: 0.7248 - f1-score: 0.8385For batch 185, tr_loss is    0.26.\n",
      "187/232 [=======================>......] - ETA: 39s - loss: 0.2550 - iou_score: 0.7252 - f1-score: 0.8388For batch 186, tr_loss is    0.26.\n",
      "188/232 [=======================>......] - ETA: 38s - loss: 0.2551 - iou_score: 0.7251 - f1-score: 0.8387For batch 187, tr_loss is    0.26.\n",
      "189/232 [=======================>......] - ETA: 37s - loss: 0.2549 - iou_score: 0.7254 - f1-score: 0.8389For batch 188, tr_loss is    0.25.\n",
      "190/232 [=======================>......] - ETA: 36s - loss: 0.2547 - iou_score: 0.7255 - f1-score: 0.8390For batch 189, tr_loss is    0.25.\n",
      "191/232 [=======================>......] - ETA: 35s - loss: 0.2547 - iou_score: 0.7256 - f1-score: 0.8390For batch 190, tr_loss is    0.25.\n",
      "192/232 [=======================>......] - ETA: 34s - loss: 0.2550 - iou_score: 0.7252 - f1-score: 0.8388For batch 191, tr_loss is    0.26.\n",
      "193/232 [=======================>......] - ETA: 34s - loss: 0.2553 - iou_score: 0.7248 - f1-score: 0.8385For batch 192, tr_loss is    0.26.\n",
      "194/232 [========================>.....] - ETA: 33s - loss: 0.2552 - iou_score: 0.7248 - f1-score: 0.8385For batch 193, tr_loss is    0.26.\n",
      "195/232 [========================>.....] - ETA: 32s - loss: 0.2553 - iou_score: 0.7245 - f1-score: 0.8383For batch 194, tr_loss is    0.26.\n",
      "196/232 [========================>.....] - ETA: 31s - loss: 0.2552 - iou_score: 0.7246 - f1-score: 0.8383For batch 195, tr_loss is    0.26.\n",
      "197/232 [========================>.....] - ETA: 30s - loss: 0.2552 - iou_score: 0.7245 - f1-score: 0.8383For batch 196, tr_loss is    0.26.\n",
      "198/232 [========================>.....] - ETA: 29s - loss: 0.2550 - iou_score: 0.7251 - f1-score: 0.8386For batch 197, tr_loss is    0.25.\n",
      "199/232 [========================>.....] - ETA: 28s - loss: 0.2548 - iou_score: 0.7252 - f1-score: 0.8387For batch 198, tr_loss is    0.25.\n",
      "200/232 [========================>.....] - ETA: 28s - loss: 0.2544 - iou_score: 0.7257 - f1-score: 0.8391For batch 199, tr_loss is    0.25.\n",
      "201/232 [========================>.....] - ETA: 27s - loss: 0.2546 - iou_score: 0.7254 - f1-score: 0.8389For batch 200, tr_loss is    0.25.\n",
      "202/232 [=========================>....] - ETA: 26s - loss: 0.2545 - iou_score: 0.7255 - f1-score: 0.8390For batch 201, tr_loss is    0.25.\n",
      "203/232 [=========================>....] - ETA: 25s - loss: 0.2541 - iou_score: 0.7258 - f1-score: 0.8392For batch 202, tr_loss is    0.25.\n",
      "204/232 [=========================>....] - ETA: 24s - loss: 0.2538 - iou_score: 0.7262 - f1-score: 0.8394For batch 203, tr_loss is    0.25.\n",
      "205/232 [=========================>....] - ETA: 23s - loss: 0.2539 - iou_score: 0.7261 - f1-score: 0.8393For batch 204, tr_loss is    0.25.\n",
      "206/232 [=========================>....] - ETA: 22s - loss: 0.2540 - iou_score: 0.7260 - f1-score: 0.8393For batch 205, tr_loss is    0.25.\n",
      "207/232 [=========================>....] - ETA: 21s - loss: 0.2539 - iou_score: 0.7262 - f1-score: 0.8394For batch 206, tr_loss is    0.25.\n",
      "208/232 [=========================>....] - ETA: 21s - loss: 0.2539 - iou_score: 0.7263 - f1-score: 0.8395For batch 207, tr_loss is    0.25.\n",
      "209/232 [==========================>...] - ETA: 20s - loss: 0.2539 - iou_score: 0.7262 - f1-score: 0.8394For batch 208, tr_loss is    0.25.\n",
      "210/232 [==========================>...] - ETA: 19s - loss: 0.2543 - iou_score: 0.7258 - f1-score: 0.8392For batch 209, tr_loss is    0.25.\n",
      "211/232 [==========================>...] - ETA: 18s - loss: 0.2540 - iou_score: 0.7261 - f1-score: 0.8394For batch 210, tr_loss is    0.25.\n",
      "212/232 [==========================>...] - ETA: 17s - loss: 0.2538 - iou_score: 0.7263 - f1-score: 0.8395For batch 211, tr_loss is    0.25.\n",
      "213/232 [==========================>...] - ETA: 16s - loss: 0.2540 - iou_score: 0.7261 - f1-score: 0.8393For batch 212, tr_loss is    0.25.\n",
      "214/232 [==========================>...] - ETA: 15s - loss: 0.2538 - iou_score: 0.7263 - f1-score: 0.8395For batch 213, tr_loss is    0.25.\n",
      "215/232 [==========================>...] - ETA: 14s - loss: 0.2535 - iou_score: 0.7266 - f1-score: 0.8397For batch 214, tr_loss is    0.25.\n",
      "216/232 [==========================>...] - ETA: 14s - loss: 0.2533 - iou_score: 0.7269 - f1-score: 0.8399For batch 215, tr_loss is    0.25.\n",
      "217/232 [===========================>..] - ETA: 13s - loss: 0.2533 - iou_score: 0.7268 - f1-score: 0.8399For batch 216, tr_loss is    0.25.\n",
      "218/232 [===========================>..] - ETA: 12s - loss: 0.2533 - iou_score: 0.7268 - f1-score: 0.8398For batch 217, tr_loss is    0.25.\n",
      "219/232 [===========================>..] - ETA: 11s - loss: 0.2538 - iou_score: 0.7261 - f1-score: 0.8393For batch 218, tr_loss is    0.25.\n",
      "220/232 [===========================>..] - ETA: 10s - loss: 0.2538 - iou_score: 0.7261 - f1-score: 0.8393For batch 219, tr_loss is    0.25.\n",
      "221/232 [===========================>..] - ETA: 9s - loss: 0.2539 - iou_score: 0.7258 - f1-score: 0.8391 For batch 220, tr_loss is    0.25.\n",
      "222/232 [===========================>..] - ETA: 8s - loss: 0.2537 - iou_score: 0.7260 - f1-score: 0.8393For batch 221, tr_loss is    0.25.\n",
      "223/232 [===========================>..] - ETA: 7s - loss: 0.2537 - iou_score: 0.7259 - f1-score: 0.8392For batch 222, tr_loss is    0.25.\n",
      "224/232 [===========================>..] - ETA: 7s - loss: 0.2536 - iou_score: 0.7262 - f1-score: 0.8394For batch 223, tr_loss is    0.25.\n",
      "225/232 [============================>.] - ETA: 6s - loss: 0.2533 - iou_score: 0.7265 - f1-score: 0.8396For batch 224, tr_loss is    0.25.\n",
      "226/232 [============================>.] - ETA: 5s - loss: 0.2533 - iou_score: 0.7265 - f1-score: 0.8396For batch 225, tr_loss is    0.25.\n",
      "227/232 [============================>.] - ETA: 4s - loss: 0.2532 - iou_score: 0.7266 - f1-score: 0.8397For batch 226, tr_loss is    0.25.\n",
      "228/232 [============================>.] - ETA: 3s - loss: 0.2532 - iou_score: 0.7266 - f1-score: 0.8397For batch 227, tr_loss is    0.25.\n",
      "229/232 [============================>.] - ETA: 2s - loss: 0.2530 - iou_score: 0.7267 - f1-score: 0.8398For batch 228, tr_loss is    0.25.\n",
      "230/232 [============================>.] - ETA: 1s - loss: 0.2534 - iou_score: 0.7263 - f1-score: 0.8395For batch 229, tr_loss is    0.25.\n",
      "231/232 [============================>.] - ETA: 0s - loss: 0.2536 - iou_score: 0.7262 - f1-score: 0.8394For batch 230, tr_loss is    0.25.\n",
      "232/232 [==============================] - ETA: 0s - loss: 0.2534 - iou_score: 0.7264 - f1-score: 0.8396For batch 231, tr_loss is    0.25.\n",
      "For batch 0, vl_loss is    0.43.\n",
      "For batch 1, vl_loss is    0.40.\n",
      "For batch 2, vl_loss is    0.43.\n",
      "For batch 3, vl_loss is    0.42.\n",
      "For batch 4, vl_loss is    0.45.\n",
      "For batch 5, vl_loss is    0.44.\n",
      "For batch 6, vl_loss is    0.45.\n",
      "For batch 7, vl_loss is    0.44.\n",
      "For batch 8, vl_loss is    0.44.\n",
      "For batch 9, vl_loss is    0.43.\n",
      "For batch 10, vl_loss is    0.43.\n",
      "For batch 11, vl_loss is    0.43.\n",
      "For batch 12, vl_loss is    0.44.\n",
      "For batch 13, vl_loss is    0.44.\n",
      "For batch 14, vl_loss is    0.43.\n",
      "For batch 15, vl_loss is    0.43.\n",
      "For batch 16, vl_loss is    0.43.\n",
      "For batch 17, vl_loss is    0.43.\n",
      "For batch 18, vl_loss is    0.43.\n",
      "For batch 19, vl_loss is    0.43.\n",
      "For batch 20, vl_loss is    0.43.\n",
      "For batch 21, vl_loss is    0.43.\n",
      "For batch 22, vl_loss is    0.43.\n",
      "For batch 23, vl_loss is    0.43.\n",
      "For batch 24, vl_loss is    0.43.\n",
      "For batch 25, vl_loss is    0.43.\n",
      "For batch 26, vl_loss is    0.42.\n",
      "For batch 27, vl_loss is    0.43.\n",
      "For batch 28, vl_loss is    0.43.\n",
      "For batch 29, vl_loss is    0.43.\n",
      "For batch 30, vl_loss is    0.43.\n",
      "For batch 31, vl_loss is    0.43.\n",
      "For batch 32, vl_loss is    0.43.\n",
      "For batch 33, vl_loss is    0.43.\n",
      "For batch 34, vl_loss is    0.43.\n",
      "For batch 35, vl_loss is    0.43.\n",
      "For batch 36, vl_loss is    0.43.\n",
      "For batch 37, vl_loss is    0.43.\n",
      "For batch 38, vl_loss is    0.43.\n",
      "For batch 39, vl_loss is    0.43.\n",
      "For batch 40, vl_loss is    0.43.\n",
      "For batch 41, vl_loss is    0.43.\n",
      "For batch 42, vl_loss is    0.43.\n",
      "For batch 43, vl_loss is    0.43.\n",
      "For batch 44, vl_loss is    0.43.\n",
      "For batch 45, vl_loss is    0.43.\n",
      "For batch 46, vl_loss is    0.43.\n",
      "For batch 47, vl_loss is    0.43.\n",
      "For batch 48, vl_loss is    0.43.\n",
      "For batch 49, vl_loss is    0.43.\n",
      "For batch 50, vl_loss is    0.43.\n",
      "For batch 51, vl_loss is    0.43.\n",
      "For batch 52, vl_loss is    0.43.\n",
      "For batch 53, vl_loss is    0.43.\n",
      "For batch 54, vl_loss is    0.44.\n",
      "For batch 55, vl_loss is    0.43.\n",
      "For batch 56, vl_loss is    0.43.\n",
      "For batch 57, vl_loss is    0.43.\n",
      "For batch 58, vl_loss is    0.43.\n",
      "For batch 59, vl_loss is    0.43.\n",
      "For batch 60, vl_loss is    0.43.\n",
      "For batch 61, vl_loss is    0.43.\n",
      "For batch 62, vl_loss is    0.43.\n",
      "For batch 63, vl_loss is    0.43.\n",
      "For batch 64, vl_loss is    0.43.\n",
      "For batch 65, vl_loss is    0.43.\n",
      "For batch 66, vl_loss is    0.43.\n",
      "For batch 67, vl_loss is    0.43.\n",
      "232/232 [==============================] - 207s 883ms/step - loss: 0.2534 - iou_score: 0.7264 - f1-score: 0.8396 - val_loss: 0.4288 - val_iou_score: 0.5617 - val_f1-score: 0.7162\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.36098\n",
      "The average loss for epoch 12 is    0.25 \n",
      "Epoch 14/200\n",
      "  1/232 [..............................] - ETA: 9:31 - loss: 0.2134 - iou_score: 0.7889 - f1-score: 0.8806For batch 0, tr_loss is    0.21.\n",
      "  2/232 [..............................] - ETA: 3:24 - loss: 0.2137 - iou_score: 0.7813 - f1-score: 0.8765For batch 1, tr_loss is    0.21.\n",
      "  3/232 [..............................] - ETA: 4:42 - loss: 0.2267 - iou_score: 0.7569 - f1-score: 0.8606For batch 2, tr_loss is    0.23.\n",
      "  4/232 [..............................] - ETA: 4:56 - loss: 0.2264 - iou_score: 0.7651 - f1-score: 0.8660For batch 3, tr_loss is    0.23.\n",
      "  5/232 [..............................] - ETA: 5:00 - loss: 0.2393 - iou_score: 0.7535 - f1-score: 0.8580For batch 4, tr_loss is    0.24.\n",
      "  6/232 [..............................] - ETA: 4:45 - loss: 0.2465 - iou_score: 0.7433 - f1-score: 0.8508For batch 5, tr_loss is    0.25.\n",
      "  7/232 [..............................] - ETA: 4:25 - loss: 0.2534 - iou_score: 0.7330 - f1-score: 0.8440For batch 6, tr_loss is    0.25.\n",
      "  8/232 [>.............................] - ETA: 4:26 - loss: 0.2571 - iou_score: 0.7255 - f1-score: 0.8390For batch 7, tr_loss is    0.26.\n",
      "  9/232 [>.............................] - ETA: 4:26 - loss: 0.2503 - iou_score: 0.7331 - f1-score: 0.8440For batch 8, tr_loss is    0.25.\n",
      " 10/232 [>.............................] - ETA: 4:38 - loss: 0.2512 - iou_score: 0.7308 - f1-score: 0.8425For batch 9, tr_loss is    0.25.\n",
      " 11/232 [>.............................] - ETA: 4:35 - loss: 0.2490 - iou_score: 0.7318 - f1-score: 0.8433For batch 10, tr_loss is    0.25.\n",
      " 12/232 [>.............................] - ETA: 4:33 - loss: 0.2454 - iou_score: 0.7379 - f1-score: 0.8474For batch 11, tr_loss is    0.25.\n",
      " 13/232 [>.............................] - ETA: 4:28 - loss: 0.2426 - iou_score: 0.7403 - f1-score: 0.8488For batch 12, tr_loss is    0.24.\n",
      " 14/232 [>.............................] - ETA: 4:23 - loss: 0.2393 - iou_score: 0.7435 - f1-score: 0.8511For batch 13, tr_loss is    0.24.\n",
      " 15/232 [>.............................] - ETA: 4:19 - loss: 0.2357 - iou_score: 0.7485 - f1-score: 0.8543For batch 14, tr_loss is    0.24.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16/232 [=>............................] - ETA: 4:11 - loss: 0.2343 - iou_score: 0.7492 - f1-score: 0.8549For batch 15, tr_loss is    0.23.\n",
      " 17/232 [=>............................] - ETA: 4:09 - loss: 0.2325 - iou_score: 0.7509 - f1-score: 0.8561For batch 16, tr_loss is    0.23.\n",
      " 18/232 [=>............................] - ETA: 4:06 - loss: 0.2334 - iou_score: 0.7499 - f1-score: 0.8555For batch 17, tr_loss is    0.23.\n",
      " 19/232 [=>............................] - ETA: 3:56 - loss: 0.2350 - iou_score: 0.7469 - f1-score: 0.8536For batch 18, tr_loss is    0.24.\n",
      " 20/232 [=>............................] - ETA: 3:57 - loss: 0.2330 - iou_score: 0.7486 - f1-score: 0.8547For batch 19, tr_loss is    0.23.\n",
      " 21/232 [=>............................] - ETA: 3:48 - loss: 0.2374 - iou_score: 0.7460 - f1-score: 0.8529For batch 20, tr_loss is    0.24.\n",
      " 22/232 [=>............................] - ETA: 3:43 - loss: 0.2403 - iou_score: 0.7430 - f1-score: 0.8507For batch 21, tr_loss is    0.24.\n",
      " 23/232 [=>............................] - ETA: 3:39 - loss: 0.2406 - iou_score: 0.7420 - f1-score: 0.8500For batch 22, tr_loss is    0.24.\n",
      " 24/232 [==>...........................] - ETA: 3:37 - loss: 0.2398 - iou_score: 0.7424 - f1-score: 0.8504For batch 23, tr_loss is    0.24.\n",
      " 25/232 [==>...........................] - ETA: 3:35 - loss: 0.2463 - iou_score: 0.7363 - f1-score: 0.8461For batch 24, tr_loss is    0.25.\n",
      " 26/232 [==>...........................] - ETA: 3:34 - loss: 0.2466 - iou_score: 0.7360 - f1-score: 0.8459For batch 25, tr_loss is    0.25.\n",
      " 27/232 [==>...........................] - ETA: 3:28 - loss: 0.2448 - iou_score: 0.7380 - f1-score: 0.8473For batch 26, tr_loss is    0.24.\n",
      " 28/232 [==>...........................] - ETA: 3:27 - loss: 0.2455 - iou_score: 0.7372 - f1-score: 0.8467For batch 27, tr_loss is    0.25.\n",
      " 29/232 [==>...........................] - ETA: 3:24 - loss: 0.2437 - iou_score: 0.7380 - f1-score: 0.8472For batch 28, tr_loss is    0.24.\n",
      " 30/232 [==>...........................] - ETA: 3:23 - loss: 0.2423 - iou_score: 0.7393 - f1-score: 0.8481For batch 29, tr_loss is    0.24.\n",
      " 31/232 [===>..........................] - ETA: 3:18 - loss: 0.2417 - iou_score: 0.7400 - f1-score: 0.8486For batch 30, tr_loss is    0.24.\n",
      " 32/232 [===>..........................] - ETA: 3:19 - loss: 0.2409 - iou_score: 0.7406 - f1-score: 0.8491For batch 31, tr_loss is    0.24.\n",
      " 33/232 [===>..........................] - ETA: 3:15 - loss: 0.2429 - iou_score: 0.7378 - f1-score: 0.8472For batch 32, tr_loss is    0.24.\n",
      " 34/232 [===>..........................] - ETA: 3:13 - loss: 0.2426 - iou_score: 0.7376 - f1-score: 0.8471For batch 33, tr_loss is    0.24.\n",
      " 35/232 [===>..........................] - ETA: 3:10 - loss: 0.2440 - iou_score: 0.7350 - f1-score: 0.8454For batch 34, tr_loss is    0.24.\n",
      " 36/232 [===>..........................] - ETA: 3:10 - loss: 0.2458 - iou_score: 0.7341 - f1-score: 0.8448For batch 35, tr_loss is    0.25.\n",
      " 37/232 [===>..........................] - ETA: 3:06 - loss: 0.2462 - iou_score: 0.7338 - f1-score: 0.8447For batch 36, tr_loss is    0.25.\n",
      " 38/232 [===>..........................] - ETA: 3:04 - loss: 0.2478 - iou_score: 0.7330 - f1-score: 0.8441For batch 37, tr_loss is    0.25.\n",
      " 39/232 [====>.........................] - ETA: 3:03 - loss: 0.2507 - iou_score: 0.7299 - f1-score: 0.8419For batch 38, tr_loss is    0.25.\n",
      " 40/232 [====>.........................] - ETA: 3:03 - loss: 0.2509 - iou_score: 0.7297 - f1-score: 0.8419For batch 39, tr_loss is    0.25.\n",
      " 41/232 [====>.........................] - ETA: 3:02 - loss: 0.2526 - iou_score: 0.7285 - f1-score: 0.8410For batch 40, tr_loss is    0.25.\n",
      " 42/232 [====>.........................] - ETA: 3:01 - loss: 0.2529 - iou_score: 0.7275 - f1-score: 0.8404For batch 41, tr_loss is    0.25.\n",
      " 43/232 [====>.........................] - ETA: 3:01 - loss: 0.2519 - iou_score: 0.7284 - f1-score: 0.8410For batch 42, tr_loss is    0.25.\n",
      " 44/232 [====>.........................] - ETA: 2:59 - loss: 0.2533 - iou_score: 0.7267 - f1-score: 0.8397For batch 43, tr_loss is    0.25.\n",
      " 45/232 [====>.........................] - ETA: 2:57 - loss: 0.2533 - iou_score: 0.7268 - f1-score: 0.8398For batch 44, tr_loss is    0.25.\n",
      " 46/232 [====>.........................] - ETA: 2:54 - loss: 0.2531 - iou_score: 0.7270 - f1-score: 0.8400For batch 45, tr_loss is    0.25.\n",
      " 47/232 [=====>........................] - ETA: 2:54 - loss: 0.2529 - iou_score: 0.7273 - f1-score: 0.8402For batch 46, tr_loss is    0.25.\n",
      " 48/232 [=====>........................] - ETA: 2:53 - loss: 0.2517 - iou_score: 0.7286 - f1-score: 0.8411For batch 47, tr_loss is    0.25.\n",
      " 49/232 [=====>........................] - ETA: 2:51 - loss: 0.2522 - iou_score: 0.7281 - f1-score: 0.8408For batch 48, tr_loss is    0.25.\n",
      " 50/232 [=====>........................] - ETA: 2:50 - loss: 0.2514 - iou_score: 0.7290 - f1-score: 0.8414For batch 49, tr_loss is    0.25.\n",
      " 51/232 [=====>........................] - ETA: 2:48 - loss: 0.2520 - iou_score: 0.7281 - f1-score: 0.8408For batch 50, tr_loss is    0.25.\n",
      " 52/232 [=====>........................] - ETA: 2:46 - loss: 0.2543 - iou_score: 0.7263 - f1-score: 0.8395For batch 51, tr_loss is    0.25.\n",
      " 53/232 [=====>........................] - ETA: 2:45 - loss: 0.2535 - iou_score: 0.7274 - f1-score: 0.8402For batch 52, tr_loss is    0.25.\n",
      " 54/232 [=====>........................] - ETA: 2:44 - loss: 0.2538 - iou_score: 0.7268 - f1-score: 0.8398For batch 53, tr_loss is    0.25.\n",
      " 55/232 [======>.......................] - ETA: 2:43 - loss: 0.2534 - iou_score: 0.7272 - f1-score: 0.8401For batch 54, tr_loss is    0.25.\n",
      " 56/232 [======>.......................] - ETA: 2:40 - loss: 0.2529 - iou_score: 0.7274 - f1-score: 0.8403For batch 55, tr_loss is    0.25.\n",
      " 57/232 [======>.......................] - ETA: 2:40 - loss: 0.2532 - iou_score: 0.7269 - f1-score: 0.8399For batch 56, tr_loss is    0.25.\n",
      " 58/232 [======>.......................] - ETA: 2:39 - loss: 0.2527 - iou_score: 0.7277 - f1-score: 0.8405For batch 57, tr_loss is    0.25.\n",
      " 59/232 [======>.......................] - ETA: 2:38 - loss: 0.2520 - iou_score: 0.7281 - f1-score: 0.8408For batch 58, tr_loss is    0.25.\n",
      " 60/232 [======>.......................] - ETA: 2:36 - loss: 0.2538 - iou_score: 0.7264 - f1-score: 0.8395For batch 59, tr_loss is    0.25.\n",
      " 61/232 [======>.......................] - ETA: 2:36 - loss: 0.2559 - iou_score: 0.7246 - f1-score: 0.8382For batch 60, tr_loss is    0.26.\n",
      " 62/232 [=======>......................] - ETA: 2:35 - loss: 0.2562 - iou_score: 0.7238 - f1-score: 0.8376For batch 61, tr_loss is    0.26.\n",
      " 63/232 [=======>......................] - ETA: 2:34 - loss: 0.2557 - iou_score: 0.7247 - f1-score: 0.8382For batch 62, tr_loss is    0.26.\n",
      " 64/232 [=======>......................] - ETA: 2:33 - loss: 0.2559 - iou_score: 0.7244 - f1-score: 0.8381For batch 63, tr_loss is    0.26.\n",
      " 65/232 [=======>......................] - ETA: 2:32 - loss: 0.2558 - iou_score: 0.7245 - f1-score: 0.8381For batch 64, tr_loss is    0.26.\n",
      " 66/232 [=======>......................] - ETA: 2:30 - loss: 0.2559 - iou_score: 0.7240 - f1-score: 0.8379For batch 65, tr_loss is    0.26.\n",
      " 67/232 [=======>......................] - ETA: 2:30 - loss: 0.2553 - iou_score: 0.7251 - f1-score: 0.8386For batch 66, tr_loss is    0.26.\n",
      " 68/232 [=======>......................] - ETA: 2:28 - loss: 0.2551 - iou_score: 0.7254 - f1-score: 0.8388For batch 67, tr_loss is    0.26.\n",
      " 69/232 [=======>......................] - ETA: 2:27 - loss: 0.2552 - iou_score: 0.7255 - f1-score: 0.8389For batch 68, tr_loss is    0.26.\n",
      " 70/232 [========>.....................] - ETA: 2:26 - loss: 0.2547 - iou_score: 0.7259 - f1-score: 0.8391For batch 69, tr_loss is    0.25.\n",
      " 71/232 [========>.....................] - ETA: 2:25 - loss: 0.2539 - iou_score: 0.7271 - f1-score: 0.8399For batch 70, tr_loss is    0.25.\n",
      " 72/232 [========>.....................] - ETA: 2:23 - loss: 0.2533 - iou_score: 0.7275 - f1-score: 0.8402For batch 71, tr_loss is    0.25.\n",
      " 73/232 [========>.....................] - ETA: 2:23 - loss: 0.2537 - iou_score: 0.7268 - f1-score: 0.8397For batch 72, tr_loss is    0.25.\n",
      " 74/232 [========>.....................] - ETA: 2:22 - loss: 0.2530 - iou_score: 0.7277 - f1-score: 0.8403For batch 73, tr_loss is    0.25.\n",
      " 75/232 [========>.....................] - ETA: 2:21 - loss: 0.2533 - iou_score: 0.7273 - f1-score: 0.8401For batch 74, tr_loss is    0.25.\n",
      " 76/232 [========>.....................] - ETA: 2:20 - loss: 0.2540 - iou_score: 0.7268 - f1-score: 0.8397For batch 75, tr_loss is    0.25.\n",
      " 77/232 [========>.....................] - ETA: 2:19 - loss: 0.2530 - iou_score: 0.7277 - f1-score: 0.8403For batch 76, tr_loss is    0.25.\n",
      " 78/232 [=========>....................] - ETA: 2:17 - loss: 0.2534 - iou_score: 0.7271 - f1-score: 0.8400For batch 77, tr_loss is    0.25.\n",
      " 79/232 [=========>....................] - ETA: 2:17 - loss: 0.2527 - iou_score: 0.7278 - f1-score: 0.8404For batch 78, tr_loss is    0.25.\n",
      " 80/232 [=========>....................] - ETA: 2:16 - loss: 0.2525 - iou_score: 0.7279 - f1-score: 0.8405For batch 79, tr_loss is    0.25.\n",
      " 81/232 [=========>....................] - ETA: 2:15 - loss: 0.2526 - iou_score: 0.7275 - f1-score: 0.8403For batch 80, tr_loss is    0.25.\n",
      " 82/232 [=========>....................] - ETA: 2:13 - loss: 0.2525 - iou_score: 0.7275 - f1-score: 0.8402For batch 81, tr_loss is    0.25.\n",
      " 83/232 [=========>....................] - ETA: 2:13 - loss: 0.2531 - iou_score: 0.7268 - f1-score: 0.8398For batch 82, tr_loss is    0.25.\n",
      " 84/232 [=========>....................] - ETA: 2:12 - loss: 0.2533 - iou_score: 0.7267 - f1-score: 0.8397For batch 83, tr_loss is    0.25.\n",
      " 85/232 [=========>....................] - ETA: 2:11 - loss: 0.2533 - iou_score: 0.7265 - f1-score: 0.8397For batch 84, tr_loss is    0.25.\n",
      " 86/232 [==========>...................] - ETA: 2:10 - loss: 0.2533 - iou_score: 0.7263 - f1-score: 0.8395For batch 85, tr_loss is    0.25.\n",
      " 87/232 [==========>...................] - ETA: 2:10 - loss: 0.2530 - iou_score: 0.7266 - f1-score: 0.8397For batch 86, tr_loss is    0.25.\n",
      " 88/232 [==========>...................] - ETA: 2:09 - loss: 0.2533 - iou_score: 0.7261 - f1-score: 0.8394For batch 87, tr_loss is    0.25.\n",
      " 89/232 [==========>...................] - ETA: 2:08 - loss: 0.2532 - iou_score: 0.7260 - f1-score: 0.8394For batch 88, tr_loss is    0.25.\n",
      " 90/232 [==========>...................] - ETA: 2:07 - loss: 0.2526 - iou_score: 0.7267 - f1-score: 0.8399For batch 89, tr_loss is    0.25.\n",
      " 91/232 [==========>...................] - ETA: 2:07 - loss: 0.2524 - iou_score: 0.7270 - f1-score: 0.8400For batch 90, tr_loss is    0.25.\n",
      " 92/232 [==========>...................] - ETA: 2:05 - loss: 0.2525 - iou_score: 0.7270 - f1-score: 0.8400For batch 91, tr_loss is    0.25.\n",
      " 93/232 [===========>..................] - ETA: 2:04 - loss: 0.2535 - iou_score: 0.7258 - f1-score: 0.8392For batch 92, tr_loss is    0.25.\n",
      " 94/232 [===========>..................] - ETA: 2:03 - loss: 0.2529 - iou_score: 0.7263 - f1-score: 0.8395For batch 93, tr_loss is    0.25.\n",
      " 95/232 [===========>..................] - ETA: 2:03 - loss: 0.2534 - iou_score: 0.7258 - f1-score: 0.8392For batch 94, tr_loss is    0.25.\n",
      " 96/232 [===========>..................] - ETA: 2:01 - loss: 0.2533 - iou_score: 0.7259 - f1-score: 0.8392For batch 95, tr_loss is    0.25.\n",
      " 97/232 [===========>..................] - ETA: 2:01 - loss: 0.2533 - iou_score: 0.7257 - f1-score: 0.8391For batch 96, tr_loss is    0.25.\n",
      " 98/232 [===========>..................] - ETA: 2:00 - loss: 0.2532 - iou_score: 0.7255 - f1-score: 0.8390For batch 97, tr_loss is    0.25.\n",
      " 99/232 [===========>..................] - ETA: 1:58 - loss: 0.2526 - iou_score: 0.7264 - f1-score: 0.8396For batch 98, tr_loss is    0.25.\n",
      "100/232 [===========>..................] - ETA: 1:57 - loss: 0.2521 - iou_score: 0.7269 - f1-score: 0.8400For batch 99, tr_loss is    0.25.\n",
      "101/232 [============>.................] - ETA: 1:56 - loss: 0.2515 - iou_score: 0.7278 - f1-score: 0.8406For batch 100, tr_loss is    0.25.\n",
      "102/232 [============>.................] - ETA: 1:56 - loss: 0.2516 - iou_score: 0.7279 - f1-score: 0.8406For batch 101, tr_loss is    0.25.\n",
      "103/232 [============>.................] - ETA: 1:55 - loss: 0.2516 - iou_score: 0.7279 - f1-score: 0.8406For batch 102, tr_loss is    0.25.\n",
      "104/232 [============>.................] - ETA: 1:54 - loss: 0.2513 - iou_score: 0.7281 - f1-score: 0.8408For batch 103, tr_loss is    0.25.\n",
      "105/232 [============>.................] - ETA: 1:53 - loss: 0.2508 - iou_score: 0.7288 - f1-score: 0.8412For batch 104, tr_loss is    0.25.\n",
      "106/232 [============>.................] - ETA: 1:53 - loss: 0.2500 - iou_score: 0.7297 - f1-score: 0.8418For batch 105, tr_loss is    0.25.\n",
      "107/232 [============>.................] - ETA: 1:52 - loss: 0.2504 - iou_score: 0.7295 - f1-score: 0.8417For batch 106, tr_loss is    0.25.\n",
      "108/232 [============>.................] - ETA: 1:51 - loss: 0.2508 - iou_score: 0.7288 - f1-score: 0.8412For batch 107, tr_loss is    0.25.\n",
      "109/232 [=============>................] - ETA: 1:50 - loss: 0.2502 - iou_score: 0.7294 - f1-score: 0.8416For batch 108, tr_loss is    0.25.\n",
      "110/232 [=============>................] - ETA: 1:49 - loss: 0.2494 - iou_score: 0.7304 - f1-score: 0.8423For batch 109, tr_loss is    0.25.\n",
      "111/232 [=============>................] - ETA: 1:48 - loss: 0.2495 - iou_score: 0.7301 - f1-score: 0.8421For batch 110, tr_loss is    0.25.\n",
      "112/232 [=============>................] - ETA: 1:47 - loss: 0.2499 - iou_score: 0.7298 - f1-score: 0.8418For batch 111, tr_loss is    0.25.\n",
      "113/232 [=============>................] - ETA: 1:46 - loss: 0.2505 - iou_score: 0.7291 - f1-score: 0.8414For batch 112, tr_loss is    0.25.\n",
      "114/232 [=============>................] - ETA: 1:45 - loss: 0.2500 - iou_score: 0.7297 - f1-score: 0.8418For batch 113, tr_loss is    0.25.\n",
      "115/232 [=============>................] - ETA: 1:45 - loss: 0.2497 - iou_score: 0.7300 - f1-score: 0.8420For batch 114, tr_loss is    0.25.\n",
      "116/232 [==============>...............] - ETA: 1:43 - loss: 0.2494 - iou_score: 0.7302 - f1-score: 0.8421For batch 115, tr_loss is    0.25.\n",
      "117/232 [==============>...............] - ETA: 1:43 - loss: 0.2493 - iou_score: 0.7303 - f1-score: 0.8422For batch 116, tr_loss is    0.25.\n",
      "118/232 [==============>...............] - ETA: 1:42 - loss: 0.2488 - iou_score: 0.7310 - f1-score: 0.8427For batch 117, tr_loss is    0.25.\n",
      "119/232 [==============>...............] - ETA: 1:41 - loss: 0.2484 - iou_score: 0.7317 - f1-score: 0.8432For batch 118, tr_loss is    0.25.\n",
      "120/232 [==============>...............] - ETA: 1:40 - loss: 0.2487 - iou_score: 0.7313 - f1-score: 0.8429For batch 119, tr_loss is    0.25.\n",
      "121/232 [==============>...............] - ETA: 1:39 - loss: 0.2482 - iou_score: 0.7318 - f1-score: 0.8432For batch 120, tr_loss is    0.25.\n",
      "122/232 [==============>...............] - ETA: 1:38 - loss: 0.2487 - iou_score: 0.7312 - f1-score: 0.8427For batch 121, tr_loss is    0.25.\n",
      "123/232 [==============>...............] - ETA: 1:37 - loss: 0.2482 - iou_score: 0.7315 - f1-score: 0.8430For batch 122, tr_loss is    0.25.\n",
      "124/232 [===============>..............] - ETA: 1:36 - loss: 0.2483 - iou_score: 0.7315 - f1-score: 0.8430For batch 123, tr_loss is    0.25.\n",
      "125/232 [===============>..............] - ETA: 1:36 - loss: 0.2486 - iou_score: 0.7313 - f1-score: 0.8429For batch 124, tr_loss is    0.25.\n",
      "126/232 [===============>..............] - ETA: 1:35 - loss: 0.2483 - iou_score: 0.7316 - f1-score: 0.8431For batch 125, tr_loss is    0.25.\n",
      "127/232 [===============>..............] - ETA: 1:34 - loss: 0.2481 - iou_score: 0.7317 - f1-score: 0.8431For batch 126, tr_loss is    0.25.\n",
      "128/232 [===============>..............] - ETA: 1:33 - loss: 0.2481 - iou_score: 0.7315 - f1-score: 0.8431For batch 127, tr_loss is    0.25.\n",
      "129/232 [===============>..............] - ETA: 1:32 - loss: 0.2480 - iou_score: 0.7314 - f1-score: 0.8430For batch 128, tr_loss is    0.25.\n",
      "130/232 [===============>..............] - ETA: 1:30 - loss: 0.2478 - iou_score: 0.7318 - f1-score: 0.8433For batch 129, tr_loss is    0.25.\n",
      "131/232 [===============>..............] - ETA: 1:30 - loss: 0.2484 - iou_score: 0.7311 - f1-score: 0.8428For batch 130, tr_loss is    0.25.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/232 [================>.............] - ETA: 1:29 - loss: 0.2487 - iou_score: 0.7309 - f1-score: 0.8426For batch 131, tr_loss is    0.25.\n",
      "133/232 [================>.............] - ETA: 1:28 - loss: 0.2485 - iou_score: 0.7310 - f1-score: 0.8427For batch 132, tr_loss is    0.25.\n",
      "134/232 [================>.............] - ETA: 1:27 - loss: 0.2490 - iou_score: 0.7303 - f1-score: 0.8422For batch 133, tr_loss is    0.25.\n",
      "135/232 [================>.............] - ETA: 1:26 - loss: 0.2485 - iou_score: 0.7307 - f1-score: 0.8425For batch 134, tr_loss is    0.25.\n",
      "136/232 [================>.............] - ETA: 1:25 - loss: 0.2487 - iou_score: 0.7303 - f1-score: 0.8422For batch 135, tr_loss is    0.25.\n",
      "137/232 [================>.............] - ETA: 1:24 - loss: 0.2489 - iou_score: 0.7301 - f1-score: 0.8421For batch 136, tr_loss is    0.25.\n",
      "138/232 [================>.............] - ETA: 1:23 - loss: 0.2490 - iou_score: 0.7299 - f1-score: 0.8420For batch 137, tr_loss is    0.25.\n",
      "139/232 [================>.............] - ETA: 1:22 - loss: 0.2489 - iou_score: 0.7299 - f1-score: 0.8420For batch 138, tr_loss is    0.25.\n",
      "140/232 [=================>............] - ETA: 1:21 - loss: 0.2488 - iou_score: 0.7301 - f1-score: 0.8421For batch 139, tr_loss is    0.25.\n",
      "141/232 [=================>............] - ETA: 1:20 - loss: 0.2494 - iou_score: 0.7292 - f1-score: 0.8414For batch 140, tr_loss is    0.25.\n",
      "142/232 [=================>............] - ETA: 1:19 - loss: 0.2494 - iou_score: 0.7292 - f1-score: 0.8414For batch 141, tr_loss is    0.25.\n",
      "143/232 [=================>............] - ETA: 1:19 - loss: 0.2492 - iou_score: 0.7295 - f1-score: 0.8416For batch 142, tr_loss is    0.25.\n",
      "144/232 [=================>............] - ETA: 1:18 - loss: 0.2491 - iou_score: 0.7294 - f1-score: 0.8416For batch 143, tr_loss is    0.25.\n",
      "145/232 [=================>............] - ETA: 1:17 - loss: 0.2491 - iou_score: 0.7294 - f1-score: 0.8416For batch 144, tr_loss is    0.25.\n",
      "146/232 [=================>............] - ETA: 1:16 - loss: 0.2493 - iou_score: 0.7290 - f1-score: 0.8414For batch 145, tr_loss is    0.25.\n",
      "147/232 [==================>...........] - ETA: 1:15 - loss: 0.2491 - iou_score: 0.7293 - f1-score: 0.8416For batch 146, tr_loss is    0.25.\n",
      "148/232 [==================>...........] - ETA: 1:14 - loss: 0.2495 - iou_score: 0.7289 - f1-score: 0.8413For batch 147, tr_loss is    0.25.\n",
      "149/232 [==================>...........] - ETA: 1:13 - loss: 0.2493 - iou_score: 0.7291 - f1-score: 0.8414For batch 148, tr_loss is    0.25.\n",
      "150/232 [==================>...........] - ETA: 1:12 - loss: 0.2498 - iou_score: 0.7283 - f1-score: 0.8409For batch 149, tr_loss is    0.25.\n",
      "151/232 [==================>...........] - ETA: 1:11 - loss: 0.2500 - iou_score: 0.7280 - f1-score: 0.8406For batch 150, tr_loss is    0.25.\n",
      "152/232 [==================>...........] - ETA: 1:10 - loss: 0.2498 - iou_score: 0.7283 - f1-score: 0.8408For batch 151, tr_loss is    0.25.\n",
      "153/232 [==================>...........] - ETA: 1:10 - loss: 0.2500 - iou_score: 0.7281 - f1-score: 0.8407For batch 152, tr_loss is    0.25.\n",
      "154/232 [==================>...........] - ETA: 1:09 - loss: 0.2497 - iou_score: 0.7284 - f1-score: 0.8409For batch 153, tr_loss is    0.25.\n",
      "155/232 [===================>..........] - ETA: 1:08 - loss: 0.2498 - iou_score: 0.7283 - f1-score: 0.8408For batch 154, tr_loss is    0.25.\n",
      "156/232 [===================>..........] - ETA: 1:07 - loss: 0.2498 - iou_score: 0.7280 - f1-score: 0.8407For batch 155, tr_loss is    0.25.\n",
      "157/232 [===================>..........] - ETA: 1:06 - loss: 0.2504 - iou_score: 0.7277 - f1-score: 0.8404For batch 156, tr_loss is    0.25.\n",
      "158/232 [===================>..........] - ETA: 1:05 - loss: 0.2501 - iou_score: 0.7281 - f1-score: 0.8407For batch 157, tr_loss is    0.25.\n",
      "159/232 [===================>..........] - ETA: 1:05 - loss: 0.2498 - iou_score: 0.7284 - f1-score: 0.8409For batch 158, tr_loss is    0.25.\n",
      "160/232 [===================>..........] - ETA: 1:04 - loss: 0.2497 - iou_score: 0.7283 - f1-score: 0.8409For batch 159, tr_loss is    0.25.\n",
      "161/232 [===================>..........] - ETA: 1:03 - loss: 0.2494 - iou_score: 0.7288 - f1-score: 0.8412For batch 160, tr_loss is    0.25.\n",
      "162/232 [===================>..........] - ETA: 1:02 - loss: 0.2493 - iou_score: 0.7288 - f1-score: 0.8412For batch 161, tr_loss is    0.25.\n",
      "163/232 [====================>.........] - ETA: 1:01 - loss: 0.2492 - iou_score: 0.7290 - f1-score: 0.8414For batch 162, tr_loss is    0.25.\n",
      "164/232 [====================>.........] - ETA: 1:00 - loss: 0.2491 - iou_score: 0.7290 - f1-score: 0.8413For batch 163, tr_loss is    0.25.\n",
      "165/232 [====================>.........] - ETA: 59s - loss: 0.2492 - iou_score: 0.7288 - f1-score: 0.8412 For batch 164, tr_loss is    0.25.\n",
      "166/232 [====================>.........] - ETA: 58s - loss: 0.2489 - iou_score: 0.7290 - f1-score: 0.8414For batch 165, tr_loss is    0.25.\n",
      "167/232 [====================>.........] - ETA: 57s - loss: 0.2486 - iou_score: 0.7293 - f1-score: 0.8415For batch 166, tr_loss is    0.25.\n",
      "168/232 [====================>.........] - ETA: 56s - loss: 0.2490 - iou_score: 0.7290 - f1-score: 0.8413For batch 167, tr_loss is    0.25.\n",
      "169/232 [====================>.........] - ETA: 55s - loss: 0.2493 - iou_score: 0.7285 - f1-score: 0.8410For batch 168, tr_loss is    0.25.\n",
      "170/232 [====================>.........] - ETA: 55s - loss: 0.2493 - iou_score: 0.7285 - f1-score: 0.8410For batch 169, tr_loss is    0.25.\n",
      "171/232 [=====================>........] - ETA: 54s - loss: 0.2496 - iou_score: 0.7281 - f1-score: 0.8407For batch 170, tr_loss is    0.25.\n",
      "172/232 [=====================>........] - ETA: 53s - loss: 0.2499 - iou_score: 0.7278 - f1-score: 0.8405For batch 171, tr_loss is    0.25.\n",
      "173/232 [=====================>........] - ETA: 52s - loss: 0.2496 - iou_score: 0.7281 - f1-score: 0.8407For batch 172, tr_loss is    0.25.\n",
      "174/232 [=====================>........] - ETA: 51s - loss: 0.2493 - iou_score: 0.7284 - f1-score: 0.8409For batch 173, tr_loss is    0.25.\n",
      "175/232 [=====================>........] - ETA: 50s - loss: 0.2496 - iou_score: 0.7280 - f1-score: 0.8407For batch 174, tr_loss is    0.25.\n",
      "176/232 [=====================>........] - ETA: 49s - loss: 0.2497 - iou_score: 0.7277 - f1-score: 0.8405For batch 175, tr_loss is    0.25.\n",
      "177/232 [=====================>........] - ETA: 48s - loss: 0.2494 - iou_score: 0.7283 - f1-score: 0.8409For batch 176, tr_loss is    0.25.\n",
      "178/232 [======================>.......] - ETA: 47s - loss: 0.2494 - iou_score: 0.7285 - f1-score: 0.8410For batch 177, tr_loss is    0.25.\n",
      "179/232 [======================>.......] - ETA: 46s - loss: 0.2493 - iou_score: 0.7286 - f1-score: 0.8411For batch 178, tr_loss is    0.25.\n",
      "180/232 [======================>.......] - ETA: 46s - loss: 0.2494 - iou_score: 0.7284 - f1-score: 0.8410For batch 179, tr_loss is    0.25.\n",
      "181/232 [======================>.......] - ETA: 45s - loss: 0.2494 - iou_score: 0.7284 - f1-score: 0.8410For batch 180, tr_loss is    0.25.\n",
      "182/232 [======================>.......] - ETA: 44s - loss: 0.2493 - iou_score: 0.7285 - f1-score: 0.8410For batch 181, tr_loss is    0.25.\n",
      "183/232 [======================>.......] - ETA: 43s - loss: 0.2493 - iou_score: 0.7285 - f1-score: 0.8410For batch 182, tr_loss is    0.25.\n",
      "184/232 [======================>.......] - ETA: 42s - loss: 0.2489 - iou_score: 0.7290 - f1-score: 0.8414For batch 183, tr_loss is    0.25.\n",
      "185/232 [======================>.......] - ETA: 41s - loss: 0.2489 - iou_score: 0.7291 - f1-score: 0.8414For batch 184, tr_loss is    0.25.\n",
      "186/232 [=======================>......] - ETA: 40s - loss: 0.2489 - iou_score: 0.7290 - f1-score: 0.8414For batch 185, tr_loss is    0.25.\n",
      "187/232 [=======================>......] - ETA: 39s - loss: 0.2485 - iou_score: 0.7296 - f1-score: 0.8417For batch 186, tr_loss is    0.25.\n",
      "188/232 [=======================>......] - ETA: 38s - loss: 0.2484 - iou_score: 0.7295 - f1-score: 0.8417For batch 187, tr_loss is    0.25.\n",
      "189/232 [=======================>......] - ETA: 38s - loss: 0.2482 - iou_score: 0.7297 - f1-score: 0.8418For batch 188, tr_loss is    0.25.\n",
      "190/232 [=======================>......] - ETA: 37s - loss: 0.2481 - iou_score: 0.7297 - f1-score: 0.8419For batch 189, tr_loss is    0.25.\n",
      "191/232 [=======================>......] - ETA: 36s - loss: 0.2482 - iou_score: 0.7298 - f1-score: 0.8419For batch 190, tr_loss is    0.25.\n",
      "192/232 [=======================>......] - ETA: 35s - loss: 0.2484 - iou_score: 0.7294 - f1-score: 0.8417For batch 191, tr_loss is    0.25.\n",
      "193/232 [=======================>......] - ETA: 34s - loss: 0.2485 - iou_score: 0.7292 - f1-score: 0.8415For batch 192, tr_loss is    0.25.\n",
      "194/232 [========================>.....] - ETA: 33s - loss: 0.2483 - iou_score: 0.7293 - f1-score: 0.8416For batch 193, tr_loss is    0.25.\n",
      "195/232 [========================>.....] - ETA: 32s - loss: 0.2483 - iou_score: 0.7293 - f1-score: 0.8416For batch 194, tr_loss is    0.25.\n",
      "196/232 [========================>.....] - ETA: 31s - loss: 0.2480 - iou_score: 0.7294 - f1-score: 0.8417For batch 195, tr_loss is    0.25.\n",
      "197/232 [========================>.....] - ETA: 30s - loss: 0.2480 - iou_score: 0.7294 - f1-score: 0.8417For batch 196, tr_loss is    0.25.\n",
      "198/232 [========================>.....] - ETA: 30s - loss: 0.2477 - iou_score: 0.7299 - f1-score: 0.8420For batch 197, tr_loss is    0.25.\n",
      "199/232 [========================>.....] - ETA: 29s - loss: 0.2475 - iou_score: 0.7301 - f1-score: 0.8421For batch 198, tr_loss is    0.25.\n",
      "200/232 [========================>.....] - ETA: 28s - loss: 0.2472 - iou_score: 0.7305 - f1-score: 0.8424For batch 199, tr_loss is    0.25.\n",
      "201/232 [========================>.....] - ETA: 27s - loss: 0.2473 - iou_score: 0.7303 - f1-score: 0.8423For batch 200, tr_loss is    0.25.\n",
      "202/232 [=========================>....] - ETA: 26s - loss: 0.2472 - iou_score: 0.7303 - f1-score: 0.8423For batch 201, tr_loss is    0.25.\n",
      "203/232 [=========================>....] - ETA: 25s - loss: 0.2470 - iou_score: 0.7305 - f1-score: 0.8424For batch 202, tr_loss is    0.25.\n",
      "204/232 [=========================>....] - ETA: 24s - loss: 0.2467 - iou_score: 0.7309 - f1-score: 0.8427For batch 203, tr_loss is    0.25.\n",
      "205/232 [=========================>....] - ETA: 23s - loss: 0.2467 - iou_score: 0.7308 - f1-score: 0.8426For batch 204, tr_loss is    0.25.\n",
      "206/232 [=========================>....] - ETA: 22s - loss: 0.2470 - iou_score: 0.7307 - f1-score: 0.8425For batch 205, tr_loss is    0.25.\n",
      "207/232 [=========================>....] - ETA: 21s - loss: 0.2470 - iou_score: 0.7308 - f1-score: 0.8426For batch 206, tr_loss is    0.25.\n",
      "208/232 [=========================>....] - ETA: 21s - loss: 0.2469 - iou_score: 0.7309 - f1-score: 0.8426For batch 207, tr_loss is    0.25.\n",
      "209/232 [==========================>...] - ETA: 20s - loss: 0.2471 - iou_score: 0.7306 - f1-score: 0.8425For batch 208, tr_loss is    0.25.\n",
      "210/232 [==========================>...] - ETA: 19s - loss: 0.2475 - iou_score: 0.7304 - f1-score: 0.8423For batch 209, tr_loss is    0.25.\n",
      "211/232 [==========================>...] - ETA: 18s - loss: 0.2474 - iou_score: 0.7306 - f1-score: 0.8425For batch 210, tr_loss is    0.25.\n",
      "212/232 [==========================>...] - ETA: 17s - loss: 0.2472 - iou_score: 0.7308 - f1-score: 0.8426For batch 211, tr_loss is    0.25.\n",
      "213/232 [==========================>...] - ETA: 16s - loss: 0.2474 - iou_score: 0.7307 - f1-score: 0.8426For batch 212, tr_loss is    0.25.\n",
      "214/232 [==========================>...] - ETA: 15s - loss: 0.2472 - iou_score: 0.7309 - f1-score: 0.8427For batch 213, tr_loss is    0.25.\n",
      "215/232 [==========================>...] - ETA: 14s - loss: 0.2469 - iou_score: 0.7312 - f1-score: 0.8429For batch 214, tr_loss is    0.25.\n",
      "216/232 [==========================>...] - ETA: 14s - loss: 0.2467 - iou_score: 0.7314 - f1-score: 0.8430For batch 215, tr_loss is    0.25.\n",
      "217/232 [===========================>..] - ETA: 13s - loss: 0.2468 - iou_score: 0.7313 - f1-score: 0.8430For batch 216, tr_loss is    0.25.\n",
      "218/232 [===========================>..] - ETA: 12s - loss: 0.2468 - iou_score: 0.7312 - f1-score: 0.8429For batch 217, tr_loss is    0.25.\n",
      "219/232 [===========================>..] - ETA: 11s - loss: 0.2473 - iou_score: 0.7306 - f1-score: 0.8425For batch 218, tr_loss is    0.25.\n",
      "220/232 [===========================>..] - ETA: 10s - loss: 0.2473 - iou_score: 0.7305 - f1-score: 0.8424For batch 219, tr_loss is    0.25.\n",
      "221/232 [===========================>..] - ETA: 9s - loss: 0.2475 - iou_score: 0.7302 - f1-score: 0.8422 For batch 220, tr_loss is    0.25.\n",
      "222/232 [===========================>..] - ETA: 8s - loss: 0.2473 - iou_score: 0.7305 - f1-score: 0.8424For batch 221, tr_loss is    0.25.\n",
      "223/232 [===========================>..] - ETA: 7s - loss: 0.2473 - iou_score: 0.7303 - f1-score: 0.8423For batch 222, tr_loss is    0.25.\n",
      "224/232 [===========================>..] - ETA: 7s - loss: 0.2473 - iou_score: 0.7305 - f1-score: 0.8424For batch 223, tr_loss is    0.25.\n",
      "225/232 [============================>.] - ETA: 6s - loss: 0.2471 - iou_score: 0.7307 - f1-score: 0.8426For batch 224, tr_loss is    0.25.\n",
      "226/232 [============================>.] - ETA: 5s - loss: 0.2471 - iou_score: 0.7306 - f1-score: 0.8425For batch 225, tr_loss is    0.25.\n",
      "227/232 [============================>.] - ETA: 4s - loss: 0.2471 - iou_score: 0.7308 - f1-score: 0.8426For batch 226, tr_loss is    0.25.\n",
      "228/232 [============================>.] - ETA: 3s - loss: 0.2474 - iou_score: 0.7306 - f1-score: 0.8424For batch 227, tr_loss is    0.25.\n",
      "229/232 [============================>.] - ETA: 2s - loss: 0.2472 - iou_score: 0.7307 - f1-score: 0.8426For batch 228, tr_loss is    0.25.\n",
      "230/232 [============================>.] - ETA: 1s - loss: 0.2475 - iou_score: 0.7305 - f1-score: 0.8424For batch 229, tr_loss is    0.25.\n",
      "231/232 [============================>.] - ETA: 0s - loss: 0.2478 - iou_score: 0.7301 - f1-score: 0.8421For batch 230, tr_loss is    0.25.\n",
      "232/232 [==============================] - ETA: 0s - loss: 0.2475 - iou_score: 0.7304 - f1-score: 0.8423For batch 231, tr_loss is    0.25.\n",
      "For batch 0, vl_loss is    0.38.\n",
      "For batch 1, vl_loss is    0.36.\n",
      "For batch 2, vl_loss is    0.37.\n",
      "For batch 3, vl_loss is    0.38.\n",
      "For batch 4, vl_loss is    0.40.\n",
      "For batch 5, vl_loss is    0.38.\n",
      "For batch 6, vl_loss is    0.39.\n",
      "For batch 7, vl_loss is    0.39.\n",
      "For batch 8, vl_loss is    0.39.\n",
      "For batch 9, vl_loss is    0.37.\n",
      "For batch 10, vl_loss is    0.38.\n",
      "For batch 11, vl_loss is    0.38.\n",
      "For batch 12, vl_loss is    0.39.\n",
      "For batch 13, vl_loss is    0.40.\n",
      "For batch 14, vl_loss is    0.39.\n",
      "For batch 15, vl_loss is    0.39.\n",
      "For batch 16, vl_loss is    0.39.\n",
      "For batch 17, vl_loss is    0.39.\n",
      "For batch 18, vl_loss is    0.39.\n",
      "For batch 19, vl_loss is    0.38.\n",
      "For batch 20, vl_loss is    0.38.\n",
      "For batch 21, vl_loss is    0.38.\n",
      "For batch 22, vl_loss is    0.38.\n",
      "For batch 23, vl_loss is    0.38.\n",
      "For batch 24, vl_loss is    0.38.\n",
      "For batch 25, vl_loss is    0.38.\n",
      "For batch 26, vl_loss is    0.38.\n",
      "For batch 27, vl_loss is    0.38.\n",
      "For batch 28, vl_loss is    0.38.\n",
      "For batch 29, vl_loss is    0.39.\n",
      "For batch 30, vl_loss is    0.38.\n",
      "For batch 31, vl_loss is    0.38.\n",
      "For batch 32, vl_loss is    0.39.\n",
      "For batch 33, vl_loss is    0.39.\n",
      "For batch 34, vl_loss is    0.39.\n",
      "For batch 35, vl_loss is    0.39.\n",
      "For batch 36, vl_loss is    0.38.\n",
      "For batch 37, vl_loss is    0.38.\n",
      "For batch 38, vl_loss is    0.38.\n",
      "For batch 39, vl_loss is    0.38.\n",
      "For batch 40, vl_loss is    0.39.\n",
      "For batch 41, vl_loss is    0.39.\n",
      "For batch 42, vl_loss is    0.39.\n",
      "For batch 43, vl_loss is    0.39.\n",
      "For batch 44, vl_loss is    0.39.\n",
      "For batch 45, vl_loss is    0.39.\n",
      "For batch 46, vl_loss is    0.39.\n",
      "For batch 47, vl_loss is    0.39.\n",
      "For batch 48, vl_loss is    0.39.\n",
      "For batch 49, vl_loss is    0.39.\n",
      "For batch 50, vl_loss is    0.39.\n",
      "For batch 51, vl_loss is    0.39.\n",
      "For batch 52, vl_loss is    0.39.\n",
      "For batch 53, vl_loss is    0.39.\n",
      "For batch 54, vl_loss is    0.39.\n",
      "For batch 55, vl_loss is    0.39.\n",
      "For batch 56, vl_loss is    0.39.\n",
      "For batch 57, vl_loss is    0.39.\n",
      "For batch 58, vl_loss is    0.39.\n",
      "For batch 59, vl_loss is    0.39.\n",
      "For batch 60, vl_loss is    0.39.\n",
      "For batch 61, vl_loss is    0.39.\n",
      "For batch 62, vl_loss is    0.39.\n",
      "For batch 63, vl_loss is    0.39.\n",
      "For batch 64, vl_loss is    0.39.\n",
      "For batch 65, vl_loss is    0.39.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 66, vl_loss is    0.39.\n",
      "For batch 67, vl_loss is    0.39.\n",
      "232/232 [==============================] - 207s 885ms/step - loss: 0.2475 - iou_score: 0.7304 - f1-score: 0.8423 - val_loss: 0.3871 - val_iou_score: 0.6228 - val_f1-score: 0.7653\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.36098\n",
      "The average loss for epoch 13 is    0.25 \n",
      "Epoch 15/200\n",
      "  1/232 [..............................] - ETA: 7:08 - loss: 0.1937 - iou_score: 0.7961 - f1-score: 0.8844For batch 0, tr_loss is    0.19.\n",
      "  2/232 [..............................] - ETA: 4:09 - loss: 0.1923 - iou_score: 0.7952 - f1-score: 0.8849For batch 1, tr_loss is    0.19.\n",
      "  3/232 [..............................] - ETA: 3:32 - loss: 0.2153 - iou_score: 0.7646 - f1-score: 0.8652For batch 2, tr_loss is    0.22.\n",
      "  4/232 [..............................] - ETA: 3:43 - loss: 0.2147 - iou_score: 0.7695 - f1-score: 0.8686For batch 3, tr_loss is    0.21.\n",
      "  5/232 [..............................] - ETA: 3:45 - loss: 0.2295 - iou_score: 0.7568 - f1-score: 0.8598For batch 4, tr_loss is    0.23.\n",
      "  6/232 [..............................] - ETA: 3:48 - loss: 0.2374 - iou_score: 0.7495 - f1-score: 0.8546For batch 5, tr_loss is    0.24.\n",
      "  7/232 [..............................] - ETA: 3:37 - loss: 0.2509 - iou_score: 0.7348 - f1-score: 0.8446For batch 6, tr_loss is    0.25.\n",
      "  8/232 [>.............................] - ETA: 3:44 - loss: 0.2548 - iou_score: 0.7278 - f1-score: 0.8402For batch 7, tr_loss is    0.25.\n",
      "  9/232 [>.............................] - ETA: 3:43 - loss: 0.2471 - iou_score: 0.7372 - f1-score: 0.8463For batch 8, tr_loss is    0.25.\n",
      " 10/232 [>.............................] - ETA: 3:50 - loss: 0.2460 - iou_score: 0.7361 - f1-score: 0.8457For batch 9, tr_loss is    0.25.\n",
      " 11/232 [>.............................] - ETA: 3:52 - loss: 0.2439 - iou_score: 0.7370 - f1-score: 0.8466For batch 10, tr_loss is    0.24.\n",
      " 12/232 [>.............................] - ETA: 3:58 - loss: 0.2406 - iou_score: 0.7423 - f1-score: 0.8501For batch 11, tr_loss is    0.24.\n",
      " 13/232 [>.............................] - ETA: 4:02 - loss: 0.2378 - iou_score: 0.7443 - f1-score: 0.8513For batch 12, tr_loss is    0.24.\n",
      " 14/232 [>.............................] - ETA: 3:56 - loss: 0.2343 - iou_score: 0.7475 - f1-score: 0.8535For batch 13, tr_loss is    0.23.\n",
      " 15/232 [>.............................] - ETA: 3:53 - loss: 0.2306 - iou_score: 0.7516 - f1-score: 0.8562For batch 14, tr_loss is    0.23.\n",
      " 16/232 [=>............................] - ETA: 3:51 - loss: 0.2284 - iou_score: 0.7534 - f1-score: 0.8575For batch 15, tr_loss is    0.23.\n",
      " 17/232 [=>............................] - ETA: 3:42 - loss: 0.2256 - iou_score: 0.7564 - f1-score: 0.8595For batch 16, tr_loss is    0.23.\n",
      " 18/232 [=>............................] - ETA: 3:41 - loss: 0.2276 - iou_score: 0.7553 - f1-score: 0.8589For batch 17, tr_loss is    0.23.\n",
      " 19/232 [=>............................] - ETA: 3:40 - loss: 0.2299 - iou_score: 0.7519 - f1-score: 0.8566For batch 18, tr_loss is    0.23.\n",
      " 20/232 [=>............................] - ETA: 3:32 - loss: 0.2273 - iou_score: 0.7552 - f1-score: 0.8588For batch 19, tr_loss is    0.23.\n",
      " 21/232 [=>............................] - ETA: 3:28 - loss: 0.2304 - iou_score: 0.7531 - f1-score: 0.8573For batch 20, tr_loss is    0.23.\n",
      " 22/232 [=>............................] - ETA: 3:28 - loss: 0.2314 - iou_score: 0.7507 - f1-score: 0.8556For batch 21, tr_loss is    0.23.\n",
      " 23/232 [=>............................] - ETA: 3:22 - loss: 0.2319 - iou_score: 0.7497 - f1-score: 0.8550For batch 22, tr_loss is    0.23.\n",
      " 24/232 [==>...........................] - ETA: 3:19 - loss: 0.2309 - iou_score: 0.7505 - f1-score: 0.8555For batch 23, tr_loss is    0.23.\n",
      " 25/232 [==>...........................] - ETA: 3:17 - loss: 0.2347 - iou_score: 0.7459 - f1-score: 0.8524For batch 24, tr_loss is    0.23.\n",
      " 26/232 [==>...........................] - ETA: 3:13 - loss: 0.2349 - iou_score: 0.7451 - f1-score: 0.8519For batch 25, tr_loss is    0.23.\n",
      " 27/232 [==>...........................] - ETA: 3:11 - loss: 0.2328 - iou_score: 0.7474 - f1-score: 0.8535For batch 26, tr_loss is    0.23.\n",
      " 28/232 [==>...........................] - ETA: 3:11 - loss: 0.2335 - iou_score: 0.7468 - f1-score: 0.8530For batch 27, tr_loss is    0.23.\n",
      " 29/232 [==>...........................] - ETA: 3:08 - loss: 0.2318 - iou_score: 0.7482 - f1-score: 0.8539For batch 28, tr_loss is    0.23.\n",
      " 30/232 [==>...........................] - ETA: 3:04 - loss: 0.2306 - iou_score: 0.7491 - f1-score: 0.8546For batch 29, tr_loss is    0.23.\n",
      " 31/232 [===>..........................] - ETA: 3:04 - loss: 0.2304 - iou_score: 0.7495 - f1-score: 0.8549For batch 30, tr_loss is    0.23.\n",
      " 32/232 [===>..........................] - ETA: 3:01 - loss: 0.2303 - iou_score: 0.7494 - f1-score: 0.8549For batch 31, tr_loss is    0.23.\n",
      " 33/232 [===>..........................] - ETA: 2:58 - loss: 0.2322 - iou_score: 0.7467 - f1-score: 0.8530For batch 32, tr_loss is    0.23.\n",
      " 34/232 [===>..........................] - ETA: 2:57 - loss: 0.2324 - iou_score: 0.7461 - f1-score: 0.8527For batch 33, tr_loss is    0.23.\n",
      " 35/232 [===>..........................] - ETA: 2:54 - loss: 0.2337 - iou_score: 0.7443 - f1-score: 0.8515For batch 34, tr_loss is    0.23.\n",
      " 36/232 [===>..........................] - ETA: 2:52 - loss: 0.2334 - iou_score: 0.7447 - f1-score: 0.8518For batch 35, tr_loss is    0.23.\n",
      " 37/232 [===>..........................] - ETA: 2:53 - loss: 0.2334 - iou_score: 0.7443 - f1-score: 0.8516For batch 36, tr_loss is    0.23.\n",
      " 38/232 [===>..........................] - ETA: 2:53 - loss: 0.2342 - iou_score: 0.7434 - f1-score: 0.8510For batch 37, tr_loss is    0.23.\n",
      " 39/232 [====>.........................] - ETA: 2:53 - loss: 0.2385 - iou_score: 0.7393 - f1-score: 0.8481For batch 38, tr_loss is    0.24.\n",
      " 40/232 [====>.........................] - ETA: 2:53 - loss: 0.2380 - iou_score: 0.7399 - f1-score: 0.8485For batch 39, tr_loss is    0.24.\n",
      " 41/232 [====>.........................] - ETA: 2:52 - loss: 0.2397 - iou_score: 0.7379 - f1-score: 0.8471For batch 40, tr_loss is    0.24.\n",
      " 42/232 [====>.........................] - ETA: 2:52 - loss: 0.2400 - iou_score: 0.7370 - f1-score: 0.8466For batch 41, tr_loss is    0.24.\n",
      " 43/232 [====>.........................] - ETA: 2:49 - loss: 0.2397 - iou_score: 0.7374 - f1-score: 0.8469For batch 42, tr_loss is    0.24.\n",
      " 44/232 [====>.........................] - ETA: 2:48 - loss: 0.2419 - iou_score: 0.7355 - f1-score: 0.8455For batch 43, tr_loss is    0.24.\n",
      " 45/232 [====>.........................] - ETA: 2:46 - loss: 0.2428 - iou_score: 0.7347 - f1-score: 0.8450For batch 44, tr_loss is    0.24.\n",
      " 46/232 [====>.........................] - ETA: 2:46 - loss: 0.2428 - iou_score: 0.7350 - f1-score: 0.8453For batch 45, tr_loss is    0.24.\n",
      " 47/232 [=====>........................] - ETA: 2:44 - loss: 0.2422 - iou_score: 0.7355 - f1-score: 0.8456For batch 46, tr_loss is    0.24.\n",
      " 48/232 [=====>........................] - ETA: 2:44 - loss: 0.2412 - iou_score: 0.7367 - f1-score: 0.8464For batch 47, tr_loss is    0.24.\n",
      " 49/232 [=====>........................] - ETA: 2:43 - loss: 0.2427 - iou_score: 0.7359 - f1-score: 0.8459For batch 48, tr_loss is    0.24.\n",
      " 50/232 [=====>........................] - ETA: 2:42 - loss: 0.2424 - iou_score: 0.7360 - f1-score: 0.8460For batch 49, tr_loss is    0.24.\n",
      " 51/232 [=====>........................] - ETA: 2:41 - loss: 0.2429 - iou_score: 0.7350 - f1-score: 0.8453For batch 50, tr_loss is    0.24.\n",
      " 52/232 [=====>........................] - ETA: 2:41 - loss: 0.2456 - iou_score: 0.7328 - f1-score: 0.8438For batch 51, tr_loss is    0.25.\n",
      " 53/232 [=====>........................] - ETA: 2:40 - loss: 0.2445 - iou_score: 0.7343 - f1-score: 0.8447For batch 52, tr_loss is    0.24.\n",
      " 54/232 [=====>........................] - ETA: 2:40 - loss: 0.2446 - iou_score: 0.7342 - f1-score: 0.8447For batch 53, tr_loss is    0.24.\n",
      " 55/232 [======>.......................] - ETA: 2:37 - loss: 0.2437 - iou_score: 0.7351 - f1-score: 0.8453For batch 54, tr_loss is    0.24.\n",
      " 56/232 [======>.......................] - ETA: 2:37 - loss: 0.2430 - iou_score: 0.7357 - f1-score: 0.8457For batch 55, tr_loss is    0.24.\n",
      " 57/232 [======>.......................] - ETA: 2:36 - loss: 0.2436 - iou_score: 0.7351 - f1-score: 0.8454For batch 56, tr_loss is    0.24.\n",
      " 58/232 [======>.......................] - ETA: 2:35 - loss: 0.2428 - iou_score: 0.7363 - f1-score: 0.8461For batch 57, tr_loss is    0.24.\n",
      " 59/232 [======>.......................] - ETA: 2:34 - loss: 0.2420 - iou_score: 0.7369 - f1-score: 0.8465For batch 58, tr_loss is    0.24.\n",
      " 60/232 [======>.......................] - ETA: 2:34 - loss: 0.2430 - iou_score: 0.7355 - f1-score: 0.8456For batch 59, tr_loss is    0.24.\n",
      " 61/232 [======>.......................] - ETA: 2:33 - loss: 0.2447 - iou_score: 0.7340 - f1-score: 0.8444For batch 60, tr_loss is    0.24.\n",
      " 62/232 [=======>......................] - ETA: 2:31 - loss: 0.2451 - iou_score: 0.7334 - f1-score: 0.8440For batch 61, tr_loss is    0.25.\n",
      " 63/232 [=======>......................] - ETA: 2:30 - loss: 0.2448 - iou_score: 0.7338 - f1-score: 0.8443For batch 62, tr_loss is    0.24.\n",
      " 64/232 [=======>......................] - ETA: 2:30 - loss: 0.2450 - iou_score: 0.7335 - f1-score: 0.8442For batch 63, tr_loss is    0.24.\n",
      " 65/232 [=======>......................] - ETA: 2:29 - loss: 0.2448 - iou_score: 0.7337 - f1-score: 0.8443For batch 64, tr_loss is    0.24.\n",
      " 66/232 [=======>......................] - ETA: 2:27 - loss: 0.2448 - iou_score: 0.7336 - f1-score: 0.8442For batch 65, tr_loss is    0.24.\n",
      " 67/232 [=======>......................] - ETA: 2:27 - loss: 0.2442 - iou_score: 0.7341 - f1-score: 0.8446For batch 66, tr_loss is    0.24.\n",
      " 68/232 [=======>......................] - ETA: 2:26 - loss: 0.2438 - iou_score: 0.7346 - f1-score: 0.8450For batch 67, tr_loss is    0.24.\n",
      " 69/232 [=======>......................] - ETA: 2:25 - loss: 0.2438 - iou_score: 0.7347 - f1-score: 0.8451For batch 68, tr_loss is    0.24.\n",
      " 70/232 [========>.....................] - ETA: 2:23 - loss: 0.2436 - iou_score: 0.7347 - f1-score: 0.8451For batch 69, tr_loss is    0.24.\n",
      " 71/232 [========>.....................] - ETA: 2:23 - loss: 0.2426 - iou_score: 0.7361 - f1-score: 0.8460For batch 70, tr_loss is    0.24.\n",
      " 72/232 [========>.....................] - ETA: 2:21 - loss: 0.2419 - iou_score: 0.7367 - f1-score: 0.8464For batch 71, tr_loss is    0.24.\n",
      " 73/232 [========>.....................] - ETA: 2:20 - loss: 0.2424 - iou_score: 0.7362 - f1-score: 0.8460For batch 72, tr_loss is    0.24.\n",
      " 74/232 [========>.....................] - ETA: 2:19 - loss: 0.2418 - iou_score: 0.7368 - f1-score: 0.8465For batch 73, tr_loss is    0.24.\n",
      " 75/232 [========>.....................] - ETA: 2:18 - loss: 0.2420 - iou_score: 0.7363 - f1-score: 0.8461For batch 74, tr_loss is    0.24.\n",
      " 76/232 [========>.....................] - ETA: 2:18 - loss: 0.2417 - iou_score: 0.7366 - f1-score: 0.8464For batch 75, tr_loss is    0.24.\n",
      " 77/232 [========>.....................] - ETA: 2:17 - loss: 0.2411 - iou_score: 0.7372 - f1-score: 0.8468For batch 76, tr_loss is    0.24.\n",
      " 78/232 [=========>....................] - ETA: 2:17 - loss: 0.2410 - iou_score: 0.7372 - f1-score: 0.8468For batch 77, tr_loss is    0.24.\n",
      " 79/232 [=========>....................] - ETA: 2:15 - loss: 0.2405 - iou_score: 0.7379 - f1-score: 0.8473For batch 78, tr_loss is    0.24.\n",
      " 80/232 [=========>....................] - ETA: 2:15 - loss: 0.2408 - iou_score: 0.7374 - f1-score: 0.8470For batch 79, tr_loss is    0.24.\n",
      " 81/232 [=========>....................] - ETA: 2:14 - loss: 0.2408 - iou_score: 0.7372 - f1-score: 0.8468For batch 80, tr_loss is    0.24.\n",
      " 82/232 [=========>....................] - ETA: 2:12 - loss: 0.2407 - iou_score: 0.7371 - f1-score: 0.8468For batch 81, tr_loss is    0.24.\n",
      " 83/232 [=========>....................] - ETA: 2:12 - loss: 0.2414 - iou_score: 0.7361 - f1-score: 0.8461For batch 82, tr_loss is    0.24.\n",
      " 84/232 [=========>....................] - ETA: 2:12 - loss: 0.2419 - iou_score: 0.7358 - f1-score: 0.8459For batch 83, tr_loss is    0.24.\n",
      " 85/232 [=========>....................] - ETA: 2:10 - loss: 0.2421 - iou_score: 0.7355 - f1-score: 0.8457For batch 84, tr_loss is    0.24.\n",
      " 86/232 [==========>...................] - ETA: 2:09 - loss: 0.2424 - iou_score: 0.7352 - f1-score: 0.8455For batch 85, tr_loss is    0.24.\n",
      " 87/232 [==========>...................] - ETA: 2:08 - loss: 0.2424 - iou_score: 0.7351 - f1-score: 0.8455For batch 86, tr_loss is    0.24.\n",
      " 88/232 [==========>...................] - ETA: 2:07 - loss: 0.2430 - iou_score: 0.7342 - f1-score: 0.8449For batch 87, tr_loss is    0.24.\n",
      " 89/232 [==========>...................] - ETA: 2:06 - loss: 0.2426 - iou_score: 0.7346 - f1-score: 0.8452For batch 88, tr_loss is    0.24.\n",
      " 90/232 [==========>...................] - ETA: 2:04 - loss: 0.2423 - iou_score: 0.7350 - f1-score: 0.8454For batch 89, tr_loss is    0.24.\n",
      " 91/232 [==========>...................] - ETA: 2:04 - loss: 0.2424 - iou_score: 0.7348 - f1-score: 0.8453For batch 90, tr_loss is    0.24.\n",
      " 92/232 [==========>...................] - ETA: 2:03 - loss: 0.2426 - iou_score: 0.7350 - f1-score: 0.8454For batch 91, tr_loss is    0.24.\n",
      " 93/232 [===========>..................] - ETA: 2:02 - loss: 0.2433 - iou_score: 0.7339 - f1-score: 0.8447For batch 92, tr_loss is    0.24.\n",
      " 94/232 [===========>..................] - ETA: 2:01 - loss: 0.2428 - iou_score: 0.7345 - f1-score: 0.8451For batch 93, tr_loss is    0.24.\n",
      " 95/232 [===========>..................] - ETA: 1:59 - loss: 0.2431 - iou_score: 0.7341 - f1-score: 0.8448For batch 94, tr_loss is    0.24.\n",
      " 96/232 [===========>..................] - ETA: 1:59 - loss: 0.2428 - iou_score: 0.7342 - f1-score: 0.8449For batch 95, tr_loss is    0.24.\n",
      " 97/232 [===========>..................] - ETA: 1:57 - loss: 0.2432 - iou_score: 0.7339 - f1-score: 0.8447For batch 96, tr_loss is    0.24.\n",
      " 98/232 [===========>..................] - ETA: 1:57 - loss: 0.2431 - iou_score: 0.7338 - f1-score: 0.8447For batch 97, tr_loss is    0.24.\n",
      " 99/232 [===========>..................] - ETA: 1:55 - loss: 0.2424 - iou_score: 0.7348 - f1-score: 0.8453For batch 98, tr_loss is    0.24.\n",
      "100/232 [===========>..................] - ETA: 1:54 - loss: 0.2420 - iou_score: 0.7355 - f1-score: 0.8458For batch 99, tr_loss is    0.24.\n",
      "101/232 [============>.................] - ETA: 1:53 - loss: 0.2417 - iou_score: 0.7361 - f1-score: 0.8462For batch 100, tr_loss is    0.24.\n",
      "102/232 [============>.................] - ETA: 1:53 - loss: 0.2417 - iou_score: 0.7362 - f1-score: 0.8463For batch 101, tr_loss is    0.24.\n",
      "103/232 [============>.................] - ETA: 1:51 - loss: 0.2418 - iou_score: 0.7361 - f1-score: 0.8462For batch 102, tr_loss is    0.24.\n",
      "104/232 [============>.................] - ETA: 1:50 - loss: 0.2415 - iou_score: 0.7365 - f1-score: 0.8465For batch 103, tr_loss is    0.24.\n",
      "105/232 [============>.................] - ETA: 1:50 - loss: 0.2408 - iou_score: 0.7373 - f1-score: 0.8470For batch 104, tr_loss is    0.24.\n",
      "106/232 [============>.................] - ETA: 1:49 - loss: 0.2401 - iou_score: 0.7382 - f1-score: 0.8476For batch 105, tr_loss is    0.24.\n",
      "107/232 [============>.................] - ETA: 1:48 - loss: 0.2406 - iou_score: 0.7379 - f1-score: 0.8474For batch 106, tr_loss is    0.24.\n",
      "108/232 [============>.................] - ETA: 1:47 - loss: 0.2411 - iou_score: 0.7371 - f1-score: 0.8468For batch 107, tr_loss is    0.24.\n",
      "109/232 [=============>................] - ETA: 1:46 - loss: 0.2407 - iou_score: 0.7375 - f1-score: 0.8471For batch 108, tr_loss is    0.24.\n",
      "110/232 [=============>................] - ETA: 1:45 - loss: 0.2399 - iou_score: 0.7387 - f1-score: 0.8478For batch 109, tr_loss is    0.24.\n",
      "111/232 [=============>................] - ETA: 1:44 - loss: 0.2401 - iou_score: 0.7383 - f1-score: 0.8476For batch 110, tr_loss is    0.24.\n",
      "112/232 [=============>................] - ETA: 1:44 - loss: 0.2402 - iou_score: 0.7383 - f1-score: 0.8476For batch 111, tr_loss is    0.24.\n",
      "113/232 [=============>................] - ETA: 1:42 - loss: 0.2407 - iou_score: 0.7378 - f1-score: 0.8473For batch 112, tr_loss is    0.24.\n",
      "114/232 [=============>................] - ETA: 1:42 - loss: 0.2400 - iou_score: 0.7386 - f1-score: 0.8478For batch 113, tr_loss is    0.24.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/232 [=============>................] - ETA: 1:41 - loss: 0.2398 - iou_score: 0.7388 - f1-score: 0.8479For batch 114, tr_loss is    0.24.\n",
      "116/232 [==============>...............] - ETA: 1:40 - loss: 0.2394 - iou_score: 0.7391 - f1-score: 0.8481For batch 115, tr_loss is    0.24.\n",
      "117/232 [==============>...............] - ETA: 1:39 - loss: 0.2393 - iou_score: 0.7392 - f1-score: 0.8482For batch 116, tr_loss is    0.24.\n",
      "118/232 [==============>...............] - ETA: 1:38 - loss: 0.2391 - iou_score: 0.7397 - f1-score: 0.8485For batch 117, tr_loss is    0.24.\n",
      "119/232 [==============>...............] - ETA: 1:37 - loss: 0.2388 - iou_score: 0.7400 - f1-score: 0.8487For batch 118, tr_loss is    0.24.\n",
      "120/232 [==============>...............] - ETA: 1:36 - loss: 0.2395 - iou_score: 0.7395 - f1-score: 0.8484For batch 119, tr_loss is    0.24.\n",
      "121/232 [==============>...............] - ETA: 1:35 - loss: 0.2390 - iou_score: 0.7399 - f1-score: 0.8486For batch 120, tr_loss is    0.24.\n",
      "122/232 [==============>...............] - ETA: 1:34 - loss: 0.2394 - iou_score: 0.7394 - f1-score: 0.8483For batch 121, tr_loss is    0.24.\n",
      "123/232 [==============>...............] - ETA: 1:33 - loss: 0.2390 - iou_score: 0.7397 - f1-score: 0.8485For batch 122, tr_loss is    0.24.\n",
      "124/232 [===============>..............] - ETA: 1:32 - loss: 0.2390 - iou_score: 0.7397 - f1-score: 0.8486For batch 123, tr_loss is    0.24.\n",
      "125/232 [===============>..............] - ETA: 1:31 - loss: 0.2393 - iou_score: 0.7392 - f1-score: 0.8482For batch 124, tr_loss is    0.24.\n",
      "126/232 [===============>..............] - ETA: 1:31 - loss: 0.2391 - iou_score: 0.7396 - f1-score: 0.8484For batch 125, tr_loss is    0.24.\n",
      "127/232 [===============>..............] - ETA: 1:30 - loss: 0.2389 - iou_score: 0.7396 - f1-score: 0.8485For batch 126, tr_loss is    0.24.\n",
      "128/232 [===============>..............] - ETA: 1:29 - loss: 0.2391 - iou_score: 0.7391 - f1-score: 0.8482For batch 127, tr_loss is    0.24.\n",
      "129/232 [===============>..............] - ETA: 1:28 - loss: 0.2390 - iou_score: 0.7391 - f1-score: 0.8482For batch 128, tr_loss is    0.24.\n",
      "130/232 [===============>..............] - ETA: 1:28 - loss: 0.2387 - iou_score: 0.7394 - f1-score: 0.8484For batch 129, tr_loss is    0.24.\n",
      "131/232 [===============>..............] - ETA: 1:27 - loss: 0.2393 - iou_score: 0.7387 - f1-score: 0.8479For batch 130, tr_loss is    0.24.\n",
      "132/232 [================>.............] - ETA: 1:26 - loss: 0.2402 - iou_score: 0.7382 - f1-score: 0.8475For batch 131, tr_loss is    0.24.\n",
      "133/232 [================>.............] - ETA: 1:25 - loss: 0.2399 - iou_score: 0.7384 - f1-score: 0.8477For batch 132, tr_loss is    0.24.\n",
      "134/232 [================>.............] - ETA: 1:24 - loss: 0.2402 - iou_score: 0.7379 - f1-score: 0.8473For batch 133, tr_loss is    0.24.\n",
      "135/232 [================>.............] - ETA: 1:24 - loss: 0.2399 - iou_score: 0.7381 - f1-score: 0.8475For batch 134, tr_loss is    0.24.\n",
      "136/232 [================>.............] - ETA: 1:23 - loss: 0.2402 - iou_score: 0.7376 - f1-score: 0.8472For batch 135, tr_loss is    0.24.\n",
      "137/232 [================>.............] - ETA: 1:22 - loss: 0.2403 - iou_score: 0.7374 - f1-score: 0.8470For batch 136, tr_loss is    0.24.\n",
      "138/232 [================>.............] - ETA: 1:21 - loss: 0.2405 - iou_score: 0.7372 - f1-score: 0.8469For batch 137, tr_loss is    0.24.\n",
      "139/232 [================>.............] - ETA: 1:20 - loss: 0.2404 - iou_score: 0.7372 - f1-score: 0.8469For batch 138, tr_loss is    0.24.\n",
      "140/232 [=================>............] - ETA: 1:19 - loss: 0.2403 - iou_score: 0.7375 - f1-score: 0.8471For batch 139, tr_loss is    0.24.\n",
      "141/232 [=================>............] - ETA: 1:18 - loss: 0.2409 - iou_score: 0.7367 - f1-score: 0.8465For batch 140, tr_loss is    0.24.\n",
      "142/232 [=================>............] - ETA: 1:17 - loss: 0.2407 - iou_score: 0.7367 - f1-score: 0.8465For batch 141, tr_loss is    0.24.\n",
      "143/232 [=================>............] - ETA: 1:16 - loss: 0.2406 - iou_score: 0.7367 - f1-score: 0.8465For batch 142, tr_loss is    0.24.\n",
      "144/232 [=================>............] - ETA: 1:15 - loss: 0.2406 - iou_score: 0.7366 - f1-score: 0.8465For batch 143, tr_loss is    0.24.\n",
      "145/232 [=================>............] - ETA: 1:14 - loss: 0.2406 - iou_score: 0.7366 - f1-score: 0.8465For batch 144, tr_loss is    0.24.\n",
      "146/232 [=================>............] - ETA: 1:14 - loss: 0.2408 - iou_score: 0.7362 - f1-score: 0.8462For batch 145, tr_loss is    0.24.\n",
      "147/232 [==================>...........] - ETA: 1:13 - loss: 0.2405 - iou_score: 0.7366 - f1-score: 0.8465For batch 146, tr_loss is    0.24.\n",
      "148/232 [==================>...........] - ETA: 1:12 - loss: 0.2409 - iou_score: 0.7360 - f1-score: 0.8461For batch 147, tr_loss is    0.24.\n",
      "149/232 [==================>...........] - ETA: 1:11 - loss: 0.2409 - iou_score: 0.7360 - f1-score: 0.8461For batch 148, tr_loss is    0.24.\n",
      "150/232 [==================>...........] - ETA: 1:10 - loss: 0.2415 - iou_score: 0.7353 - f1-score: 0.8456For batch 149, tr_loss is    0.24.\n",
      "151/232 [==================>...........] - ETA: 1:09 - loss: 0.2416 - iou_score: 0.7351 - f1-score: 0.8455For batch 150, tr_loss is    0.24.\n",
      "152/232 [==================>...........] - ETA: 1:08 - loss: 0.2412 - iou_score: 0.7355 - f1-score: 0.8457For batch 151, tr_loss is    0.24.\n",
      "153/232 [==================>...........] - ETA: 1:07 - loss: 0.2411 - iou_score: 0.7355 - f1-score: 0.8457For batch 152, tr_loss is    0.24.\n",
      "154/232 [==================>...........] - ETA: 1:06 - loss: 0.2407 - iou_score: 0.7358 - f1-score: 0.8460For batch 153, tr_loss is    0.24.\n",
      "155/232 [===================>..........] - ETA: 1:06 - loss: 0.2406 - iou_score: 0.7360 - f1-score: 0.8461For batch 154, tr_loss is    0.24.\n",
      "156/232 [===================>..........] - ETA: 1:05 - loss: 0.2406 - iou_score: 0.7360 - f1-score: 0.8461For batch 155, tr_loss is    0.24.\n",
      "157/232 [===================>..........] - ETA: 1:04 - loss: 0.2409 - iou_score: 0.7357 - f1-score: 0.8459For batch 156, tr_loss is    0.24.\n",
      "158/232 [===================>..........] - ETA: 1:03 - loss: 0.2405 - iou_score: 0.7361 - f1-score: 0.8461For batch 157, tr_loss is    0.24.\n",
      "159/232 [===================>..........] - ETA: 1:02 - loss: 0.2401 - iou_score: 0.7366 - f1-score: 0.8465For batch 158, tr_loss is    0.24.\n",
      "160/232 [===================>..........] - ETA: 1:01 - loss: 0.2399 - iou_score: 0.7367 - f1-score: 0.8466For batch 159, tr_loss is    0.24.\n",
      "161/232 [===================>..........] - ETA: 1:01 - loss: 0.2395 - iou_score: 0.7371 - f1-score: 0.8469For batch 160, tr_loss is    0.24.\n",
      "162/232 [===================>..........] - ETA: 1:00 - loss: 0.2395 - iou_score: 0.7372 - f1-score: 0.8469For batch 161, tr_loss is    0.24.\n",
      "163/232 [====================>.........] - ETA: 59s - loss: 0.2393 - iou_score: 0.7375 - f1-score: 0.8471 For batch 162, tr_loss is    0.24.\n",
      "164/232 [====================>.........] - ETA: 58s - loss: 0.2394 - iou_score: 0.7373 - f1-score: 0.8470For batch 163, tr_loss is    0.24.\n",
      "165/232 [====================>.........] - ETA: 57s - loss: 0.2394 - iou_score: 0.7372 - f1-score: 0.8469For batch 164, tr_loss is    0.24.\n",
      "166/232 [====================>.........] - ETA: 56s - loss: 0.2391 - iou_score: 0.7375 - f1-score: 0.8471For batch 165, tr_loss is    0.24.\n",
      "167/232 [====================>.........] - ETA: 55s - loss: 0.2390 - iou_score: 0.7377 - f1-score: 0.8472For batch 166, tr_loss is    0.24.\n",
      "168/232 [====================>.........] - ETA: 55s - loss: 0.2393 - iou_score: 0.7373 - f1-score: 0.8470For batch 167, tr_loss is    0.24.\n",
      "169/232 [====================>.........] - ETA: 54s - loss: 0.2397 - iou_score: 0.7367 - f1-score: 0.8465For batch 168, tr_loss is    0.24.\n",
      "170/232 [====================>.........] - ETA: 53s - loss: 0.2398 - iou_score: 0.7366 - f1-score: 0.8465For batch 169, tr_loss is    0.24.\n",
      "171/232 [=====================>........] - ETA: 52s - loss: 0.2401 - iou_score: 0.7362 - f1-score: 0.8462For batch 170, tr_loss is    0.24.\n",
      "172/232 [=====================>........] - ETA: 51s - loss: 0.2403 - iou_score: 0.7360 - f1-score: 0.8461For batch 171, tr_loss is    0.24.\n",
      "173/232 [=====================>........] - ETA: 50s - loss: 0.2400 - iou_score: 0.7363 - f1-score: 0.8463For batch 172, tr_loss is    0.24.\n",
      "174/232 [=====================>........] - ETA: 49s - loss: 0.2397 - iou_score: 0.7367 - f1-score: 0.8465For batch 173, tr_loss is    0.24.\n",
      "175/232 [=====================>........] - ETA: 48s - loss: 0.2398 - iou_score: 0.7365 - f1-score: 0.8464For batch 174, tr_loss is    0.24.\n",
      "176/232 [=====================>........] - ETA: 47s - loss: 0.2398 - iou_score: 0.7364 - f1-score: 0.8464For batch 175, tr_loss is    0.24.\n",
      "177/232 [=====================>........] - ETA: 47s - loss: 0.2395 - iou_score: 0.7369 - f1-score: 0.8467For batch 176, tr_loss is    0.24.\n",
      "178/232 [======================>.......] - ETA: 46s - loss: 0.2395 - iou_score: 0.7371 - f1-score: 0.8468For batch 177, tr_loss is    0.24.\n",
      "179/232 [======================>.......] - ETA: 45s - loss: 0.2393 - iou_score: 0.7372 - f1-score: 0.8469For batch 178, tr_loss is    0.24.\n",
      "180/232 [======================>.......] - ETA: 44s - loss: 0.2393 - iou_score: 0.7370 - f1-score: 0.8468For batch 179, tr_loss is    0.24.\n",
      "181/232 [======================>.......] - ETA: 43s - loss: 0.2394 - iou_score: 0.7369 - f1-score: 0.8467For batch 180, tr_loss is    0.24.\n",
      "182/232 [======================>.......] - ETA: 42s - loss: 0.2396 - iou_score: 0.7368 - f1-score: 0.8466For batch 181, tr_loss is    0.24.\n",
      "183/232 [======================>.......] - ETA: 41s - loss: 0.2395 - iou_score: 0.7368 - f1-score: 0.8467For batch 182, tr_loss is    0.24.\n",
      "184/232 [======================>.......] - ETA: 40s - loss: 0.2391 - iou_score: 0.7374 - f1-score: 0.8470For batch 183, tr_loss is    0.24.\n",
      "185/232 [======================>.......] - ETA: 40s - loss: 0.2391 - iou_score: 0.7374 - f1-score: 0.8471For batch 184, tr_loss is    0.24.\n",
      "186/232 [=======================>......] - ETA: 39s - loss: 0.2392 - iou_score: 0.7373 - f1-score: 0.8470For batch 185, tr_loss is    0.24.\n",
      "187/232 [=======================>......] - ETA: 38s - loss: 0.2388 - iou_score: 0.7378 - f1-score: 0.8473For batch 186, tr_loss is    0.24.\n",
      "188/232 [=======================>......] - ETA: 37s - loss: 0.2388 - iou_score: 0.7377 - f1-score: 0.8473For batch 187, tr_loss is    0.24.\n",
      "189/232 [=======================>......] - ETA: 36s - loss: 0.2386 - iou_score: 0.7379 - f1-score: 0.8474For batch 188, tr_loss is    0.24.\n",
      "190/232 [=======================>......] - ETA: 35s - loss: 0.2385 - iou_score: 0.7381 - f1-score: 0.8475For batch 189, tr_loss is    0.24.\n",
      "191/232 [=======================>......] - ETA: 34s - loss: 0.2385 - iou_score: 0.7381 - f1-score: 0.8475For batch 190, tr_loss is    0.24.\n",
      "192/232 [=======================>......] - ETA: 34s - loss: 0.2386 - iou_score: 0.7378 - f1-score: 0.8473For batch 191, tr_loss is    0.24.\n",
      "193/232 [=======================>......] - ETA: 33s - loss: 0.2388 - iou_score: 0.7375 - f1-score: 0.8471For batch 192, tr_loss is    0.24.\n",
      "194/232 [========================>.....] - ETA: 32s - loss: 0.2388 - iou_score: 0.7375 - f1-score: 0.8471For batch 193, tr_loss is    0.24.\n",
      "195/232 [========================>.....] - ETA: 31s - loss: 0.2387 - iou_score: 0.7374 - f1-score: 0.8471For batch 194, tr_loss is    0.24.\n",
      "196/232 [========================>.....] - ETA: 30s - loss: 0.2385 - iou_score: 0.7375 - f1-score: 0.8471For batch 195, tr_loss is    0.24.\n",
      "197/232 [========================>.....] - ETA: 29s - loss: 0.2385 - iou_score: 0.7376 - f1-score: 0.8472For batch 196, tr_loss is    0.24.\n",
      "198/232 [========================>.....] - ETA: 29s - loss: 0.2382 - iou_score: 0.7380 - f1-score: 0.8475For batch 197, tr_loss is    0.24.\n",
      "199/232 [========================>.....] - ETA: 28s - loss: 0.2381 - iou_score: 0.7381 - f1-score: 0.8475For batch 198, tr_loss is    0.24.\n",
      "200/232 [========================>.....] - ETA: 27s - loss: 0.2378 - iou_score: 0.7385 - f1-score: 0.8478For batch 199, tr_loss is    0.24.\n",
      "201/232 [========================>.....] - ETA: 26s - loss: 0.2378 - iou_score: 0.7383 - f1-score: 0.8477For batch 200, tr_loss is    0.24.\n",
      "202/232 [=========================>....] - ETA: 25s - loss: 0.2378 - iou_score: 0.7383 - f1-score: 0.8477For batch 201, tr_loss is    0.24.\n",
      "203/232 [=========================>....] - ETA: 24s - loss: 0.2375 - iou_score: 0.7386 - f1-score: 0.8479For batch 202, tr_loss is    0.24.\n",
      "204/232 [=========================>....] - ETA: 23s - loss: 0.2371 - iou_score: 0.7391 - f1-score: 0.8482For batch 203, tr_loss is    0.24.\n",
      "205/232 [=========================>....] - ETA: 23s - loss: 0.2370 - iou_score: 0.7391 - f1-score: 0.8482For batch 204, tr_loss is    0.24.\n",
      "206/232 [=========================>....] - ETA: 22s - loss: 0.2372 - iou_score: 0.7389 - f1-score: 0.8481For batch 205, tr_loss is    0.24.\n",
      "207/232 [=========================>....] - ETA: 21s - loss: 0.2373 - iou_score: 0.7390 - f1-score: 0.8481For batch 206, tr_loss is    0.24.\n",
      "208/232 [=========================>....] - ETA: 20s - loss: 0.2371 - iou_score: 0.7391 - f1-score: 0.8482For batch 207, tr_loss is    0.24.\n",
      "209/232 [==========================>...] - ETA: 19s - loss: 0.2372 - iou_score: 0.7390 - f1-score: 0.8481For batch 208, tr_loss is    0.24.\n",
      "210/232 [==========================>...] - ETA: 18s - loss: 0.2375 - iou_score: 0.7386 - f1-score: 0.8478For batch 209, tr_loss is    0.24.\n",
      "211/232 [==========================>...] - ETA: 17s - loss: 0.2374 - iou_score: 0.7388 - f1-score: 0.8480For batch 210, tr_loss is    0.24.\n",
      "212/232 [==========================>...] - ETA: 17s - loss: 0.2371 - iou_score: 0.7391 - f1-score: 0.8482For batch 211, tr_loss is    0.24.\n",
      "213/232 [==========================>...] - ETA: 16s - loss: 0.2371 - iou_score: 0.7390 - f1-score: 0.8481For batch 212, tr_loss is    0.24.\n",
      "214/232 [==========================>...] - ETA: 15s - loss: 0.2369 - iou_score: 0.7392 - f1-score: 0.8483For batch 213, tr_loss is    0.24.\n",
      "215/232 [==========================>...] - ETA: 14s - loss: 0.2368 - iou_score: 0.7395 - f1-score: 0.8484For batch 214, tr_loss is    0.24.\n",
      "216/232 [==========================>...] - ETA: 13s - loss: 0.2366 - iou_score: 0.7397 - f1-score: 0.8486For batch 215, tr_loss is    0.24.\n",
      "217/232 [===========================>..] - ETA: 12s - loss: 0.2366 - iou_score: 0.7396 - f1-score: 0.8485For batch 216, tr_loss is    0.24.\n",
      "218/232 [===========================>..] - ETA: 12s - loss: 0.2366 - iou_score: 0.7396 - f1-score: 0.8485For batch 217, tr_loss is    0.24.\n",
      "219/232 [===========================>..] - ETA: 11s - loss: 0.2370 - iou_score: 0.7390 - f1-score: 0.8481For batch 218, tr_loss is    0.24.\n",
      "220/232 [===========================>..] - ETA: 10s - loss: 0.2371 - iou_score: 0.7389 - f1-score: 0.8481For batch 219, tr_loss is    0.24.\n",
      "221/232 [===========================>..] - ETA: 9s - loss: 0.2372 - iou_score: 0.7386 - f1-score: 0.8478 For batch 220, tr_loss is    0.24.\n",
      "222/232 [===========================>..] - ETA: 8s - loss: 0.2370 - iou_score: 0.7388 - f1-score: 0.8480For batch 221, tr_loss is    0.24.\n",
      "223/232 [===========================>..] - ETA: 7s - loss: 0.2371 - iou_score: 0.7386 - f1-score: 0.8479For batch 222, tr_loss is    0.24.\n",
      "224/232 [===========================>..] - ETA: 6s - loss: 0.2369 - iou_score: 0.7388 - f1-score: 0.8480For batch 223, tr_loss is    0.24.\n",
      "225/232 [============================>.] - ETA: 5s - loss: 0.2368 - iou_score: 0.7390 - f1-score: 0.8481For batch 224, tr_loss is    0.24.\n",
      "226/232 [============================>.] - ETA: 5s - loss: 0.2368 - iou_score: 0.7389 - f1-score: 0.8480For batch 225, tr_loss is    0.24.\n",
      "227/232 [============================>.] - ETA: 4s - loss: 0.2368 - iou_score: 0.7390 - f1-score: 0.8481For batch 226, tr_loss is    0.24.\n",
      "228/232 [============================>.] - ETA: 3s - loss: 0.2368 - iou_score: 0.7390 - f1-score: 0.8481For batch 227, tr_loss is    0.24.\n",
      "229/232 [============================>.] - ETA: 2s - loss: 0.2366 - iou_score: 0.7391 - f1-score: 0.8482For batch 228, tr_loss is    0.24.\n",
      "230/232 [============================>.] - ETA: 1s - loss: 0.2370 - iou_score: 0.7387 - f1-score: 0.8480For batch 229, tr_loss is    0.24.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231/232 [============================>.] - ETA: 0s - loss: 0.2371 - iou_score: 0.7386 - f1-score: 0.8479For batch 230, tr_loss is    0.24.\n",
      "232/232 [==============================] - ETA: 0s - loss: 0.2369 - iou_score: 0.7389 - f1-score: 0.8481For batch 231, tr_loss is    0.24.\n",
      "For batch 0, vl_loss is    0.37.\n",
      "For batch 1, vl_loss is    0.35.\n",
      "For batch 2, vl_loss is    0.38.\n",
      "For batch 3, vl_loss is    0.39.\n",
      "For batch 4, vl_loss is    0.42.\n",
      "For batch 5, vl_loss is    0.41.\n",
      "For batch 6, vl_loss is    0.41.\n",
      "For batch 7, vl_loss is    0.41.\n",
      "For batch 8, vl_loss is    0.41.\n",
      "For batch 9, vl_loss is    0.40.\n",
      "For batch 10, vl_loss is    0.40.\n",
      "For batch 11, vl_loss is    0.40.\n",
      "For batch 12, vl_loss is    0.41.\n",
      "For batch 13, vl_loss is    0.41.\n",
      "For batch 14, vl_loss is    0.41.\n",
      "For batch 15, vl_loss is    0.40.\n",
      "For batch 16, vl_loss is    0.40.\n",
      "For batch 17, vl_loss is    0.40.\n",
      "For batch 18, vl_loss is    0.40.\n",
      "For batch 19, vl_loss is    0.40.\n",
      "For batch 20, vl_loss is    0.40.\n",
      "For batch 21, vl_loss is    0.40.\n",
      "For batch 22, vl_loss is    0.40.\n",
      "For batch 23, vl_loss is    0.39.\n",
      "For batch 24, vl_loss is    0.39.\n",
      "For batch 25, vl_loss is    0.39.\n",
      "For batch 26, vl_loss is    0.39.\n",
      "For batch 27, vl_loss is    0.39.\n",
      "For batch 28, vl_loss is    0.40.\n",
      "For batch 29, vl_loss is    0.40.\n",
      "For batch 30, vl_loss is    0.39.\n",
      "For batch 31, vl_loss is    0.39.\n",
      "For batch 32, vl_loss is    0.39.\n",
      "For batch 33, vl_loss is    0.39.\n",
      "For batch 34, vl_loss is    0.39.\n",
      "For batch 35, vl_loss is    0.39.\n",
      "For batch 36, vl_loss is    0.39.\n",
      "For batch 37, vl_loss is    0.39.\n",
      "For batch 38, vl_loss is    0.39.\n",
      "For batch 39, vl_loss is    0.39.\n",
      "For batch 40, vl_loss is    0.39.\n",
      "For batch 41, vl_loss is    0.40.\n",
      "For batch 42, vl_loss is    0.40.\n",
      "For batch 43, vl_loss is    0.40.\n",
      "For batch 44, vl_loss is    0.40.\n",
      "For batch 45, vl_loss is    0.40.\n",
      "For batch 46, vl_loss is    0.40.\n",
      "For batch 47, vl_loss is    0.40.\n",
      "For batch 48, vl_loss is    0.40.\n",
      "For batch 49, vl_loss is    0.40.\n",
      "For batch 50, vl_loss is    0.40.\n",
      "For batch 51, vl_loss is    0.40.\n",
      "For batch 52, vl_loss is    0.40.\n",
      "For batch 53, vl_loss is    0.40.\n",
      "For batch 54, vl_loss is    0.40.\n",
      "For batch 55, vl_loss is    0.40.\n",
      "For batch 56, vl_loss is    0.40.\n",
      "For batch 57, vl_loss is    0.40.\n",
      "For batch 58, vl_loss is    0.40.\n",
      "For batch 59, vl_loss is    0.40.\n",
      "For batch 60, vl_loss is    0.40.\n",
      "For batch 61, vl_loss is    0.40.\n",
      "For batch 62, vl_loss is    0.40.\n",
      "For batch 63, vl_loss is    0.40.\n",
      "For batch 64, vl_loss is    0.40.\n",
      "For batch 65, vl_loss is    0.40.\n",
      "For batch 66, vl_loss is    0.40.\n",
      "For batch 67, vl_loss is    0.40.\n",
      "232/232 [==============================] - 201s 863ms/step - loss: 0.2369 - iou_score: 0.7389 - f1-score: 0.8481 - val_loss: 0.3974 - val_iou_score: 0.6220 - val_f1-score: 0.7645\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.36098\n",
      "The average loss for epoch 14 is    0.24 \n",
      "Epoch 16/200\n",
      "  1/232 [..............................] - ETA: 11:42 - loss: 0.1932 - iou_score: 0.7897 - f1-score: 0.8823For batch 0, tr_loss is    0.19.\n",
      "  2/232 [..............................] - ETA: 3:42 - loss: 0.1907 - iou_score: 0.7849 - f1-score: 0.8793 For batch 1, tr_loss is    0.19.\n",
      "  3/232 [..............................] - ETA: 4:11 - loss: 0.2152 - iou_score: 0.7541 - f1-score: 0.8589For batch 2, tr_loss is    0.22.\n",
      "  4/232 [..............................] - ETA: 4:09 - loss: 0.2137 - iou_score: 0.7634 - f1-score: 0.8650For batch 3, tr_loss is    0.21.\n",
      "  5/232 [..............................] - ETA: 4:33 - loss: 0.2269 - iou_score: 0.7513 - f1-score: 0.8567For batch 4, tr_loss is    0.23.\n",
      "  6/232 [..............................] - ETA: 4:33 - loss: 0.2343 - iou_score: 0.7414 - f1-score: 0.8499For batch 5, tr_loss is    0.23.\n",
      "  7/232 [..............................] - ETA: 4:34 - loss: 0.2448 - iou_score: 0.7280 - f1-score: 0.8407For batch 6, tr_loss is    0.24.\n",
      "  8/232 [>.............................] - ETA: 4:42 - loss: 0.2519 - iou_score: 0.7203 - f1-score: 0.8356For batch 7, tr_loss is    0.25.\n",
      "  9/232 [>.............................] - ETA: 4:38 - loss: 0.2418 - iou_score: 0.7317 - f1-score: 0.8430For batch 8, tr_loss is    0.24.\n",
      " 10/232 [>.............................] - ETA: 4:17 - loss: 0.2395 - iou_score: 0.7329 - f1-score: 0.8439For batch 9, tr_loss is    0.24.\n",
      " 11/232 [>.............................] - ETA: 4:13 - loss: 0.2386 - iou_score: 0.7331 - f1-score: 0.8442For batch 10, tr_loss is    0.24.\n",
      " 12/232 [>.............................] - ETA: 4:09 - loss: 0.2327 - iou_score: 0.7402 - f1-score: 0.8489For batch 11, tr_loss is    0.23.\n",
      " 13/232 [>.............................] - ETA: 4:01 - loss: 0.2318 - iou_score: 0.7416 - f1-score: 0.8496For batch 12, tr_loss is    0.23.\n",
      " 14/232 [>.............................] - ETA: 3:54 - loss: 0.2288 - iou_score: 0.7451 - f1-score: 0.8521For batch 13, tr_loss is    0.23.\n",
      " 15/232 [>.............................] - ETA: 3:53 - loss: 0.2255 - iou_score: 0.7498 - f1-score: 0.8551For batch 14, tr_loss is    0.23.\n",
      " 16/232 [=>............................] - ETA: 3:51 - loss: 0.2241 - iou_score: 0.7507 - f1-score: 0.8558For batch 15, tr_loss is    0.22.\n",
      " 17/232 [=>............................] - ETA: 3:49 - loss: 0.2215 - iou_score: 0.7538 - f1-score: 0.8578For batch 16, tr_loss is    0.22.\n",
      " 18/232 [=>............................] - ETA: 3:47 - loss: 0.2227 - iou_score: 0.7524 - f1-score: 0.8570For batch 17, tr_loss is    0.22.\n",
      " 19/232 [=>............................] - ETA: 3:45 - loss: 0.2243 - iou_score: 0.7496 - f1-score: 0.8552For batch 18, tr_loss is    0.22.\n",
      " 20/232 [=>............................] - ETA: 3:38 - loss: 0.2236 - iou_score: 0.7509 - f1-score: 0.8561For batch 19, tr_loss is    0.22.\n",
      " 21/232 [=>............................] - ETA: 3:34 - loss: 0.2259 - iou_score: 0.7492 - f1-score: 0.8550For batch 20, tr_loss is    0.23.\n",
      " 22/232 [=>............................] - ETA: 3:29 - loss: 0.2277 - iou_score: 0.7465 - f1-score: 0.8530For batch 21, tr_loss is    0.23.\n",
      " 23/232 [=>............................] - ETA: 3:26 - loss: 0.2279 - iou_score: 0.7463 - f1-score: 0.8529For batch 22, tr_loss is    0.23.\n",
      " 24/232 [==>...........................] - ETA: 3:23 - loss: 0.2267 - iou_score: 0.7477 - f1-score: 0.8539For batch 23, tr_loss is    0.23.\n",
      " 25/232 [==>...........................] - ETA: 3:19 - loss: 0.2309 - iou_score: 0.7435 - f1-score: 0.8511For batch 24, tr_loss is    0.23.\n",
      " 26/232 [==>...........................] - ETA: 3:15 - loss: 0.2321 - iou_score: 0.7428 - f1-score: 0.8506For batch 25, tr_loss is    0.23.\n",
      " 27/232 [==>...........................] - ETA: 3:12 - loss: 0.2310 - iou_score: 0.7439 - f1-score: 0.8514For batch 26, tr_loss is    0.23.\n",
      " 28/232 [==>...........................] - ETA: 3:11 - loss: 0.2302 - iou_score: 0.7450 - f1-score: 0.8520For batch 27, tr_loss is    0.23.\n",
      " 29/232 [==>...........................] - ETA: 3:11 - loss: 0.2282 - iou_score: 0.7469 - f1-score: 0.8533For batch 28, tr_loss is    0.23.\n",
      " 30/232 [==>...........................] - ETA: 3:11 - loss: 0.2269 - iou_score: 0.7487 - f1-score: 0.8545For batch 29, tr_loss is    0.23.\n",
      " 31/232 [===>..........................] - ETA: 3:09 - loss: 0.2259 - iou_score: 0.7501 - f1-score: 0.8554For batch 30, tr_loss is    0.23.\n",
      " 32/232 [===>..........................] - ETA: 3:09 - loss: 0.2259 - iou_score: 0.7504 - f1-score: 0.8557For batch 31, tr_loss is    0.23.\n",
      " 33/232 [===>..........................] - ETA: 3:08 - loss: 0.2273 - iou_score: 0.7487 - f1-score: 0.8546For batch 32, tr_loss is    0.23.\n",
      " 34/232 [===>..........................] - ETA: 3:07 - loss: 0.2274 - iou_score: 0.7487 - f1-score: 0.8546For batch 33, tr_loss is    0.23.\n",
      " 35/232 [===>..........................] - ETA: 3:07 - loss: 0.2301 - iou_score: 0.7459 - f1-score: 0.8527For batch 34, tr_loss is    0.23.\n",
      " 36/232 [===>..........................] - ETA: 3:06 - loss: 0.2305 - iou_score: 0.7460 - f1-score: 0.8529For batch 35, tr_loss is    0.23.\n",
      " 37/232 [===>..........................] - ETA: 3:05 - loss: 0.2312 - iou_score: 0.7450 - f1-score: 0.8522For batch 36, tr_loss is    0.23.\n",
      " 38/232 [===>..........................] - ETA: 3:03 - loss: 0.2329 - iou_score: 0.7436 - f1-score: 0.8513For batch 37, tr_loss is    0.23.\n",
      " 39/232 [====>.........................] - ETA: 3:02 - loss: 0.2367 - iou_score: 0.7402 - f1-score: 0.8489For batch 38, tr_loss is    0.24.\n",
      " 40/232 [====>.........................] - ETA: 3:02 - loss: 0.2372 - iou_score: 0.7399 - f1-score: 0.8487For batch 39, tr_loss is    0.24.\n",
      " 41/232 [====>.........................] - ETA: 3:01 - loss: 0.2390 - iou_score: 0.7381 - f1-score: 0.8475For batch 40, tr_loss is    0.24.\n",
      " 42/232 [====>.........................] - ETA: 3:00 - loss: 0.2390 - iou_score: 0.7379 - f1-score: 0.8474For batch 41, tr_loss is    0.24.\n",
      " 43/232 [====>.........................] - ETA: 3:00 - loss: 0.2384 - iou_score: 0.7384 - f1-score: 0.8478For batch 42, tr_loss is    0.24.\n",
      " 44/232 [====>.........................] - ETA: 2:59 - loss: 0.2409 - iou_score: 0.7362 - f1-score: 0.8461For batch 43, tr_loss is    0.24.\n",
      " 45/232 [====>.........................] - ETA: 2:57 - loss: 0.2417 - iou_score: 0.7363 - f1-score: 0.8462For batch 44, tr_loss is    0.24.\n",
      " 46/232 [====>.........................] - ETA: 2:57 - loss: 0.2417 - iou_score: 0.7367 - f1-score: 0.8465For batch 45, tr_loss is    0.24.\n",
      " 47/232 [=====>........................] - ETA: 2:54 - loss: 0.2411 - iou_score: 0.7373 - f1-score: 0.8469For batch 46, tr_loss is    0.24.\n",
      " 48/232 [=====>........................] - ETA: 2:52 - loss: 0.2401 - iou_score: 0.7383 - f1-score: 0.8476For batch 47, tr_loss is    0.24.\n",
      " 49/232 [=====>........................] - ETA: 2:52 - loss: 0.2408 - iou_score: 0.7377 - f1-score: 0.8472For batch 48, tr_loss is    0.24.\n",
      " 50/232 [=====>........................] - ETA: 2:50 - loss: 0.2403 - iou_score: 0.7384 - f1-score: 0.8477For batch 49, tr_loss is    0.24.\n",
      " 51/232 [=====>........................] - ETA: 2:50 - loss: 0.2411 - iou_score: 0.7370 - f1-score: 0.8467For batch 50, tr_loss is    0.24.\n",
      " 52/232 [=====>........................] - ETA: 2:47 - loss: 0.2437 - iou_score: 0.7346 - f1-score: 0.8451For batch 51, tr_loss is    0.24.\n",
      " 53/232 [=====>........................] - ETA: 2:45 - loss: 0.2425 - iou_score: 0.7360 - f1-score: 0.8459For batch 52, tr_loss is    0.24.\n",
      " 54/232 [=====>........................] - ETA: 2:45 - loss: 0.2426 - iou_score: 0.7354 - f1-score: 0.8456For batch 53, tr_loss is    0.24.\n",
      " 55/232 [======>.......................] - ETA: 2:44 - loss: 0.2419 - iou_score: 0.7359 - f1-score: 0.8459For batch 54, tr_loss is    0.24.\n",
      " 56/232 [======>.......................] - ETA: 2:42 - loss: 0.2414 - iou_score: 0.7362 - f1-score: 0.8462For batch 55, tr_loss is    0.24.\n",
      " 57/232 [======>.......................] - ETA: 2:42 - loss: 0.2419 - iou_score: 0.7356 - f1-score: 0.8458For batch 56, tr_loss is    0.24.\n",
      " 58/232 [======>.......................] - ETA: 2:40 - loss: 0.2413 - iou_score: 0.7365 - f1-score: 0.8464For batch 57, tr_loss is    0.24.\n",
      " 59/232 [======>.......................] - ETA: 2:40 - loss: 0.2407 - iou_score: 0.7371 - f1-score: 0.8468For batch 58, tr_loss is    0.24.\n",
      " 60/232 [======>.......................] - ETA: 2:38 - loss: 0.2418 - iou_score: 0.7355 - f1-score: 0.8456For batch 59, tr_loss is    0.24.\n",
      " 61/232 [======>.......................] - ETA: 2:36 - loss: 0.2431 - iou_score: 0.7339 - f1-score: 0.8445For batch 60, tr_loss is    0.24.\n",
      " 62/232 [=======>......................] - ETA: 2:36 - loss: 0.2434 - iou_score: 0.7334 - f1-score: 0.8441For batch 61, tr_loss is    0.24.\n",
      " 63/232 [=======>......................] - ETA: 2:36 - loss: 0.2428 - iou_score: 0.7339 - f1-score: 0.8445For batch 62, tr_loss is    0.24.\n",
      " 64/232 [=======>......................] - ETA: 2:34 - loss: 0.2428 - iou_score: 0.7338 - f1-score: 0.8444For batch 63, tr_loss is    0.24.\n",
      " 65/232 [=======>......................] - ETA: 2:33 - loss: 0.2430 - iou_score: 0.7336 - f1-score: 0.8443For batch 64, tr_loss is    0.24.\n",
      " 66/232 [=======>......................] - ETA: 2:33 - loss: 0.2432 - iou_score: 0.7334 - f1-score: 0.8442For batch 65, tr_loss is    0.24.\n",
      " 67/232 [=======>......................] - ETA: 2:32 - loss: 0.2424 - iou_score: 0.7343 - f1-score: 0.8448For batch 66, tr_loss is    0.24.\n",
      " 68/232 [=======>......................] - ETA: 2:30 - loss: 0.2421 - iou_score: 0.7348 - f1-score: 0.8452For batch 67, tr_loss is    0.24.\n",
      " 69/232 [=======>......................] - ETA: 2:29 - loss: 0.2421 - iou_score: 0.7351 - f1-score: 0.8453For batch 68, tr_loss is    0.24.\n",
      " 70/232 [========>.....................] - ETA: 2:27 - loss: 0.2418 - iou_score: 0.7353 - f1-score: 0.8455For batch 69, tr_loss is    0.24.\n",
      " 71/232 [========>.....................] - ETA: 2:26 - loss: 0.2407 - iou_score: 0.7366 - f1-score: 0.8464For batch 70, tr_loss is    0.24.\n",
      " 72/232 [========>.....................] - ETA: 2:25 - loss: 0.2402 - iou_score: 0.7373 - f1-score: 0.8468For batch 71, tr_loss is    0.24.\n",
      " 73/232 [========>.....................] - ETA: 2:24 - loss: 0.2403 - iou_score: 0.7369 - f1-score: 0.8465For batch 72, tr_loss is    0.24.\n",
      " 74/232 [========>.....................] - ETA: 2:23 - loss: 0.2397 - iou_score: 0.7377 - f1-score: 0.8471For batch 73, tr_loss is    0.24.\n",
      " 75/232 [========>.....................] - ETA: 2:22 - loss: 0.2396 - iou_score: 0.7374 - f1-score: 0.8469For batch 74, tr_loss is    0.24.\n",
      " 76/232 [========>.....................] - ETA: 2:21 - loss: 0.2391 - iou_score: 0.7379 - f1-score: 0.8472For batch 75, tr_loss is    0.24.\n",
      " 77/232 [========>.....................] - ETA: 2:21 - loss: 0.2386 - iou_score: 0.7384 - f1-score: 0.8476For batch 76, tr_loss is    0.24.\n",
      " 78/232 [=========>....................] - ETA: 2:19 - loss: 0.2386 - iou_score: 0.7381 - f1-score: 0.8474For batch 77, tr_loss is    0.24.\n",
      " 79/232 [=========>....................] - ETA: 2:19 - loss: 0.2382 - iou_score: 0.7387 - f1-score: 0.8478For batch 78, tr_loss is    0.24.\n",
      " 80/232 [=========>....................] - ETA: 2:18 - loss: 0.2386 - iou_score: 0.7385 - f1-score: 0.8477For batch 79, tr_loss is    0.24.\n",
      " 81/232 [=========>....................] - ETA: 2:16 - loss: 0.2388 - iou_score: 0.7381 - f1-score: 0.8474For batch 80, tr_loss is    0.24.\n",
      " 82/232 [=========>....................] - ETA: 2:15 - loss: 0.2386 - iou_score: 0.7381 - f1-score: 0.8475For batch 81, tr_loss is    0.24.\n",
      " 83/232 [=========>....................] - ETA: 2:14 - loss: 0.2391 - iou_score: 0.7375 - f1-score: 0.8471For batch 82, tr_loss is    0.24.\n",
      " 84/232 [=========>....................] - ETA: 2:13 - loss: 0.2396 - iou_score: 0.7370 - f1-score: 0.8467For batch 83, tr_loss is    0.24.\n",
      " 85/232 [=========>....................] - ETA: 2:12 - loss: 0.2396 - iou_score: 0.7370 - f1-score: 0.8467For batch 84, tr_loss is    0.24.\n",
      " 86/232 [==========>...................] - ETA: 2:12 - loss: 0.2399 - iou_score: 0.7365 - f1-score: 0.8465For batch 85, tr_loss is    0.24.\n",
      " 87/232 [==========>...................] - ETA: 2:11 - loss: 0.2395 - iou_score: 0.7369 - f1-score: 0.8467For batch 86, tr_loss is    0.24.\n",
      " 88/232 [==========>...................] - ETA: 2:10 - loss: 0.2397 - iou_score: 0.7367 - f1-score: 0.8466For batch 87, tr_loss is    0.24.\n",
      " 89/232 [==========>...................] - ETA: 2:09 - loss: 0.2392 - iou_score: 0.7370 - f1-score: 0.8468For batch 88, tr_loss is    0.24.\n",
      " 90/232 [==========>...................] - ETA: 2:09 - loss: 0.2388 - iou_score: 0.7376 - f1-score: 0.8472For batch 89, tr_loss is    0.24.\n",
      " 91/232 [==========>...................] - ETA: 2:08 - loss: 0.2386 - iou_score: 0.7377 - f1-score: 0.8473For batch 90, tr_loss is    0.24.\n",
      " 92/232 [==========>...................] - ETA: 2:07 - loss: 0.2385 - iou_score: 0.7377 - f1-score: 0.8473For batch 91, tr_loss is    0.24.\n",
      " 93/232 [===========>..................] - ETA: 2:06 - loss: 0.2390 - iou_score: 0.7367 - f1-score: 0.8466For batch 92, tr_loss is    0.24.\n",
      " 94/232 [===========>..................] - ETA: 2:05 - loss: 0.2385 - iou_score: 0.7371 - f1-score: 0.8469For batch 93, tr_loss is    0.24.\n",
      " 95/232 [===========>..................] - ETA: 2:04 - loss: 0.2387 - iou_score: 0.7368 - f1-score: 0.8467For batch 94, tr_loss is    0.24.\n",
      " 96/232 [===========>..................] - ETA: 2:04 - loss: 0.2388 - iou_score: 0.7367 - f1-score: 0.8466For batch 95, tr_loss is    0.24.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 97/232 [===========>..................] - ETA: 2:03 - loss: 0.2394 - iou_score: 0.7362 - f1-score: 0.8463For batch 96, tr_loss is    0.24.\n",
      " 98/232 [===========>..................] - ETA: 2:02 - loss: 0.2393 - iou_score: 0.7360 - f1-score: 0.8462For batch 97, tr_loss is    0.24.\n",
      " 99/232 [===========>..................] - ETA: 2:01 - loss: 0.2385 - iou_score: 0.7372 - f1-score: 0.8469For batch 98, tr_loss is    0.24.\n",
      "100/232 [===========>..................] - ETA: 2:00 - loss: 0.2380 - iou_score: 0.7379 - f1-score: 0.8474For batch 99, tr_loss is    0.24.\n",
      "101/232 [============>.................] - ETA: 1:59 - loss: 0.2375 - iou_score: 0.7387 - f1-score: 0.8479For batch 100, tr_loss is    0.24.\n",
      "102/232 [============>.................] - ETA: 1:59 - loss: 0.2374 - iou_score: 0.7388 - f1-score: 0.8480For batch 101, tr_loss is    0.24.\n",
      "103/232 [============>.................] - ETA: 1:58 - loss: 0.2373 - iou_score: 0.7388 - f1-score: 0.8480For batch 102, tr_loss is    0.24.\n",
      "104/232 [============>.................] - ETA: 1:57 - loss: 0.2371 - iou_score: 0.7390 - f1-score: 0.8481For batch 103, tr_loss is    0.24.\n",
      "105/232 [============>.................] - ETA: 1:56 - loss: 0.2364 - iou_score: 0.7398 - f1-score: 0.8486For batch 104, tr_loss is    0.24.\n",
      "106/232 [============>.................] - ETA: 1:55 - loss: 0.2357 - iou_score: 0.7407 - f1-score: 0.8492For batch 105, tr_loss is    0.24.\n",
      "107/232 [============>.................] - ETA: 1:54 - loss: 0.2363 - iou_score: 0.7404 - f1-score: 0.8490For batch 106, tr_loss is    0.24.\n",
      "108/232 [============>.................] - ETA: 1:53 - loss: 0.2366 - iou_score: 0.7398 - f1-score: 0.8486For batch 107, tr_loss is    0.24.\n",
      "109/232 [=============>................] - ETA: 1:51 - loss: 0.2361 - iou_score: 0.7404 - f1-score: 0.8490For batch 108, tr_loss is    0.24.\n",
      "110/232 [=============>................] - ETA: 1:51 - loss: 0.2354 - iou_score: 0.7415 - f1-score: 0.8497For batch 109, tr_loss is    0.24.\n",
      "111/232 [=============>................] - ETA: 1:49 - loss: 0.2354 - iou_score: 0.7414 - f1-score: 0.8496For batch 110, tr_loss is    0.24.\n",
      "112/232 [=============>................] - ETA: 1:49 - loss: 0.2358 - iou_score: 0.7411 - f1-score: 0.8494For batch 111, tr_loss is    0.24.\n",
      "113/232 [=============>................] - ETA: 1:48 - loss: 0.2363 - iou_score: 0.7407 - f1-score: 0.8491For batch 112, tr_loss is    0.24.\n",
      "114/232 [=============>................] - ETA: 1:47 - loss: 0.2355 - iou_score: 0.7415 - f1-score: 0.8497For batch 113, tr_loss is    0.24.\n",
      "115/232 [=============>................] - ETA: 1:46 - loss: 0.2353 - iou_score: 0.7418 - f1-score: 0.8498For batch 114, tr_loss is    0.24.\n",
      "116/232 [==============>...............] - ETA: 1:45 - loss: 0.2348 - iou_score: 0.7422 - f1-score: 0.8501For batch 115, tr_loss is    0.23.\n",
      "117/232 [==============>...............] - ETA: 1:44 - loss: 0.2345 - iou_score: 0.7426 - f1-score: 0.8504For batch 116, tr_loss is    0.23.\n",
      "118/232 [==============>...............] - ETA: 1:43 - loss: 0.2341 - iou_score: 0.7432 - f1-score: 0.8508For batch 117, tr_loss is    0.23.\n",
      "119/232 [==============>...............] - ETA: 1:42 - loss: 0.2339 - iou_score: 0.7435 - f1-score: 0.8510For batch 118, tr_loss is    0.23.\n",
      "120/232 [==============>...............] - ETA: 1:41 - loss: 0.2342 - iou_score: 0.7431 - f1-score: 0.8507For batch 119, tr_loss is    0.23.\n",
      "121/232 [==============>...............] - ETA: 1:40 - loss: 0.2337 - iou_score: 0.7435 - f1-score: 0.8510For batch 120, tr_loss is    0.23.\n",
      "122/232 [==============>...............] - ETA: 1:39 - loss: 0.2342 - iou_score: 0.7429 - f1-score: 0.8505For batch 121, tr_loss is    0.23.\n",
      "123/232 [==============>...............] - ETA: 1:38 - loss: 0.2338 - iou_score: 0.7432 - f1-score: 0.8508For batch 122, tr_loss is    0.23.\n",
      "124/232 [===============>..............] - ETA: 1:37 - loss: 0.2341 - iou_score: 0.7431 - f1-score: 0.8507For batch 123, tr_loss is    0.23.\n",
      "125/232 [===============>..............] - ETA: 1:37 - loss: 0.2345 - iou_score: 0.7426 - f1-score: 0.8504For batch 124, tr_loss is    0.23.\n",
      "126/232 [===============>..............] - ETA: 1:36 - loss: 0.2345 - iou_score: 0.7428 - f1-score: 0.8505For batch 125, tr_loss is    0.23.\n",
      "127/232 [===============>..............] - ETA: 1:35 - loss: 0.2341 - iou_score: 0.7432 - f1-score: 0.8508For batch 126, tr_loss is    0.23.\n",
      "128/232 [===============>..............] - ETA: 1:34 - loss: 0.2340 - iou_score: 0.7431 - f1-score: 0.8508For batch 127, tr_loss is    0.23.\n",
      "129/232 [===============>..............] - ETA: 1:33 - loss: 0.2340 - iou_score: 0.7430 - f1-score: 0.8507For batch 128, tr_loss is    0.23.\n",
      "130/232 [===============>..............] - ETA: 1:32 - loss: 0.2338 - iou_score: 0.7434 - f1-score: 0.8510For batch 129, tr_loss is    0.23.\n",
      "131/232 [===============>..............] - ETA: 1:32 - loss: 0.2344 - iou_score: 0.7428 - f1-score: 0.8505For batch 130, tr_loss is    0.23.\n",
      "132/232 [================>.............] - ETA: 1:31 - loss: 0.2348 - iou_score: 0.7424 - f1-score: 0.8503For batch 131, tr_loss is    0.23.\n",
      "133/232 [================>.............] - ETA: 1:30 - loss: 0.2345 - iou_score: 0.7428 - f1-score: 0.8505For batch 132, tr_loss is    0.23.\n",
      "134/232 [================>.............] - ETA: 1:29 - loss: 0.2347 - iou_score: 0.7424 - f1-score: 0.8502For batch 133, tr_loss is    0.23.\n",
      "135/232 [================>.............] - ETA: 1:28 - loss: 0.2344 - iou_score: 0.7428 - f1-score: 0.8505For batch 134, tr_loss is    0.23.\n",
      "136/232 [================>.............] - ETA: 1:27 - loss: 0.2344 - iou_score: 0.7426 - f1-score: 0.8504For batch 135, tr_loss is    0.23.\n",
      "137/232 [================>.............] - ETA: 1:26 - loss: 0.2346 - iou_score: 0.7424 - f1-score: 0.8503For batch 136, tr_loss is    0.23.\n",
      "138/232 [================>.............] - ETA: 1:25 - loss: 0.2350 - iou_score: 0.7420 - f1-score: 0.8501For batch 137, tr_loss is    0.23.\n",
      "139/232 [================>.............] - ETA: 1:24 - loss: 0.2350 - iou_score: 0.7420 - f1-score: 0.8500For batch 138, tr_loss is    0.23.\n",
      "140/232 [=================>............] - ETA: 1:23 - loss: 0.2350 - iou_score: 0.7421 - f1-score: 0.8501For batch 139, tr_loss is    0.23.\n",
      "141/232 [=================>............] - ETA: 1:22 - loss: 0.2355 - iou_score: 0.7414 - f1-score: 0.8496For batch 140, tr_loss is    0.24.\n",
      "142/232 [=================>............] - ETA: 1:21 - loss: 0.2354 - iou_score: 0.7414 - f1-score: 0.8496For batch 141, tr_loss is    0.24.\n",
      "143/232 [=================>............] - ETA: 1:20 - loss: 0.2351 - iou_score: 0.7417 - f1-score: 0.8498For batch 142, tr_loss is    0.24.\n",
      "144/232 [=================>............] - ETA: 1:19 - loss: 0.2352 - iou_score: 0.7416 - f1-score: 0.8498For batch 143, tr_loss is    0.24.\n",
      "145/232 [=================>............] - ETA: 1:18 - loss: 0.2351 - iou_score: 0.7416 - f1-score: 0.8498For batch 144, tr_loss is    0.24.\n",
      "146/232 [=================>............] - ETA: 1:18 - loss: 0.2353 - iou_score: 0.7412 - f1-score: 0.8495For batch 145, tr_loss is    0.24.\n",
      "147/232 [==================>...........] - ETA: 1:17 - loss: 0.2350 - iou_score: 0.7417 - f1-score: 0.8499For batch 146, tr_loss is    0.24.\n",
      "148/232 [==================>...........] - ETA: 1:16 - loss: 0.2353 - iou_score: 0.7412 - f1-score: 0.8495For batch 147, tr_loss is    0.24.\n",
      "149/232 [==================>...........] - ETA: 1:15 - loss: 0.2352 - iou_score: 0.7415 - f1-score: 0.8497For batch 148, tr_loss is    0.24.\n",
      "150/232 [==================>...........] - ETA: 1:14 - loss: 0.2356 - iou_score: 0.7408 - f1-score: 0.8493For batch 149, tr_loss is    0.24.\n",
      "151/232 [==================>...........] - ETA: 1:13 - loss: 0.2357 - iou_score: 0.7407 - f1-score: 0.8491For batch 150, tr_loss is    0.24.\n",
      "152/232 [==================>...........] - ETA: 1:12 - loss: 0.2353 - iou_score: 0.7411 - f1-score: 0.8494For batch 151, tr_loss is    0.24.\n",
      "153/232 [==================>...........] - ETA: 1:11 - loss: 0.2352 - iou_score: 0.7411 - f1-score: 0.8494For batch 152, tr_loss is    0.24.\n",
      "154/232 [==================>...........] - ETA: 1:10 - loss: 0.2349 - iou_score: 0.7412 - f1-score: 0.8495For batch 153, tr_loss is    0.23.\n",
      "155/232 [===================>..........] - ETA: 1:09 - loss: 0.2349 - iou_score: 0.7413 - f1-score: 0.8496For batch 154, tr_loss is    0.23.\n",
      "156/232 [===================>..........] - ETA: 1:08 - loss: 0.2349 - iou_score: 0.7412 - f1-score: 0.8495For batch 155, tr_loss is    0.23.\n",
      "157/232 [===================>..........] - ETA: 1:07 - loss: 0.2352 - iou_score: 0.7408 - f1-score: 0.8493For batch 156, tr_loss is    0.24.\n",
      "158/232 [===================>..........] - ETA: 1:06 - loss: 0.2349 - iou_score: 0.7411 - f1-score: 0.8495For batch 157, tr_loss is    0.23.\n",
      "159/232 [===================>..........] - ETA: 1:05 - loss: 0.2346 - iou_score: 0.7415 - f1-score: 0.8497For batch 158, tr_loss is    0.23.\n",
      "160/232 [===================>..........] - ETA: 1:04 - loss: 0.2345 - iou_score: 0.7414 - f1-score: 0.8497For batch 159, tr_loss is    0.23.\n",
      "161/232 [===================>..........] - ETA: 1:03 - loss: 0.2342 - iou_score: 0.7418 - f1-score: 0.8499For batch 160, tr_loss is    0.23.\n",
      "162/232 [===================>..........] - ETA: 1:02 - loss: 0.2341 - iou_score: 0.7418 - f1-score: 0.8499For batch 161, tr_loss is    0.23.\n",
      "163/232 [====================>.........] - ETA: 1:01 - loss: 0.2338 - iou_score: 0.7423 - f1-score: 0.8502For batch 162, tr_loss is    0.23.\n",
      "164/232 [====================>.........] - ETA: 1:00 - loss: 0.2338 - iou_score: 0.7421 - f1-score: 0.8501For batch 163, tr_loss is    0.23.\n",
      "165/232 [====================>.........] - ETA: 1:00 - loss: 0.2339 - iou_score: 0.7421 - f1-score: 0.8501For batch 164, tr_loss is    0.23.\n",
      "166/232 [====================>.........] - ETA: 59s - loss: 0.2335 - iou_score: 0.7423 - f1-score: 0.8503 For batch 165, tr_loss is    0.23.\n",
      "167/232 [====================>.........] - ETA: 58s - loss: 0.2331 - iou_score: 0.7426 - f1-score: 0.8505For batch 166, tr_loss is    0.23.\n",
      "168/232 [====================>.........] - ETA: 57s - loss: 0.2334 - iou_score: 0.7424 - f1-score: 0.8503For batch 167, tr_loss is    0.23.\n",
      "169/232 [====================>.........] - ETA: 56s - loss: 0.2337 - iou_score: 0.7420 - f1-score: 0.8500For batch 168, tr_loss is    0.23.\n",
      "170/232 [====================>.........] - ETA: 55s - loss: 0.2337 - iou_score: 0.7420 - f1-score: 0.8501For batch 169, tr_loss is    0.23.\n",
      "171/232 [=====================>........] - ETA: 54s - loss: 0.2341 - iou_score: 0.7416 - f1-score: 0.8498For batch 170, tr_loss is    0.23.\n",
      "172/232 [=====================>........] - ETA: 53s - loss: 0.2342 - iou_score: 0.7414 - f1-score: 0.8497For batch 171, tr_loss is    0.23.\n",
      "173/232 [=====================>........] - ETA: 52s - loss: 0.2339 - iou_score: 0.7416 - f1-score: 0.8498For batch 172, tr_loss is    0.23.\n",
      "174/232 [=====================>........] - ETA: 52s - loss: 0.2338 - iou_score: 0.7418 - f1-score: 0.8499For batch 173, tr_loss is    0.23.\n",
      "175/232 [=====================>........] - ETA: 51s - loss: 0.2339 - iou_score: 0.7416 - f1-score: 0.8498For batch 174, tr_loss is    0.23.\n",
      "176/232 [=====================>........] - ETA: 50s - loss: 0.2341 - iou_score: 0.7413 - f1-score: 0.8496For batch 175, tr_loss is    0.23.\n",
      "177/232 [=====================>........] - ETA: 49s - loss: 0.2338 - iou_score: 0.7416 - f1-score: 0.8499For batch 176, tr_loss is    0.23.\n",
      "178/232 [======================>.......] - ETA: 48s - loss: 0.2337 - iou_score: 0.7419 - f1-score: 0.8500For batch 177, tr_loss is    0.23.\n",
      "179/232 [======================>.......] - ETA: 47s - loss: 0.2337 - iou_score: 0.7420 - f1-score: 0.8501For batch 178, tr_loss is    0.23.\n",
      "180/232 [======================>.......] - ETA: 46s - loss: 0.2338 - iou_score: 0.7418 - f1-score: 0.8499For batch 179, tr_loss is    0.23.\n",
      "181/232 [======================>.......] - ETA: 45s - loss: 0.2338 - iou_score: 0.7417 - f1-score: 0.8499For batch 180, tr_loss is    0.23.\n",
      "182/232 [======================>.......] - ETA: 44s - loss: 0.2339 - iou_score: 0.7416 - f1-score: 0.8499For batch 181, tr_loss is    0.23.\n",
      "183/232 [======================>.......] - ETA: 44s - loss: 0.2337 - iou_score: 0.7417 - f1-score: 0.8499For batch 182, tr_loss is    0.23.\n",
      "184/232 [======================>.......] - ETA: 43s - loss: 0.2333 - iou_score: 0.7422 - f1-score: 0.8503For batch 183, tr_loss is    0.23.\n",
      "185/232 [======================>.......] - ETA: 42s - loss: 0.2335 - iou_score: 0.7421 - f1-score: 0.8502For batch 184, tr_loss is    0.23.\n",
      "186/232 [=======================>......] - ETA: 41s - loss: 0.2336 - iou_score: 0.7419 - f1-score: 0.8501For batch 185, tr_loss is    0.23.\n",
      "187/232 [=======================>......] - ETA: 40s - loss: 0.2332 - iou_score: 0.7424 - f1-score: 0.8504For batch 186, tr_loss is    0.23.\n",
      "188/232 [=======================>......] - ETA: 39s - loss: 0.2332 - iou_score: 0.7423 - f1-score: 0.8503For batch 187, tr_loss is    0.23.\n",
      "189/232 [=======================>......] - ETA: 38s - loss: 0.2330 - iou_score: 0.7425 - f1-score: 0.8504For batch 188, tr_loss is    0.23.\n",
      "190/232 [=======================>......] - ETA: 37s - loss: 0.2329 - iou_score: 0.7427 - f1-score: 0.8505For batch 189, tr_loss is    0.23.\n",
      "191/232 [=======================>......] - ETA: 36s - loss: 0.2330 - iou_score: 0.7426 - f1-score: 0.8505For batch 190, tr_loss is    0.23.\n",
      "192/232 [=======================>......] - ETA: 35s - loss: 0.2331 - iou_score: 0.7424 - f1-score: 0.8503For batch 191, tr_loss is    0.23.\n",
      "193/232 [=======================>......] - ETA: 35s - loss: 0.2333 - iou_score: 0.7421 - f1-score: 0.8501For batch 192, tr_loss is    0.23.\n",
      "194/232 [========================>.....] - ETA: 34s - loss: 0.2332 - iou_score: 0.7420 - f1-score: 0.8501For batch 193, tr_loss is    0.23.\n",
      "195/232 [========================>.....] - ETA: 33s - loss: 0.2331 - iou_score: 0.7421 - f1-score: 0.8502For batch 194, tr_loss is    0.23.\n",
      "196/232 [========================>.....] - ETA: 32s - loss: 0.2329 - iou_score: 0.7422 - f1-score: 0.8502For batch 195, tr_loss is    0.23.\n",
      "197/232 [========================>.....] - ETA: 31s - loss: 0.2329 - iou_score: 0.7422 - f1-score: 0.8502For batch 196, tr_loss is    0.23.\n",
      "198/232 [========================>.....] - ETA: 30s - loss: 0.2327 - iou_score: 0.7425 - f1-score: 0.8505For batch 197, tr_loss is    0.23.\n",
      "199/232 [========================>.....] - ETA: 29s - loss: 0.2325 - iou_score: 0.7427 - f1-score: 0.8506For batch 198, tr_loss is    0.23.\n",
      "200/232 [========================>.....] - ETA: 28s - loss: 0.2322 - iou_score: 0.7431 - f1-score: 0.8508For batch 199, tr_loss is    0.23.\n",
      "201/232 [========================>.....] - ETA: 27s - loss: 0.2323 - iou_score: 0.7428 - f1-score: 0.8507For batch 200, tr_loss is    0.23.\n",
      "202/232 [=========================>....] - ETA: 26s - loss: 0.2322 - iou_score: 0.7429 - f1-score: 0.8507For batch 201, tr_loss is    0.23.\n",
      "203/232 [=========================>....] - ETA: 26s - loss: 0.2319 - iou_score: 0.7432 - f1-score: 0.8509For batch 202, tr_loss is    0.23.\n",
      "204/232 [=========================>....] - ETA: 25s - loss: 0.2316 - iou_score: 0.7436 - f1-score: 0.8512For batch 203, tr_loss is    0.23.\n",
      "205/232 [=========================>....] - ETA: 24s - loss: 0.2315 - iou_score: 0.7436 - f1-score: 0.8512For batch 204, tr_loss is    0.23.\n",
      "206/232 [=========================>....] - ETA: 23s - loss: 0.2317 - iou_score: 0.7434 - f1-score: 0.8511For batch 205, tr_loss is    0.23.\n",
      "207/232 [=========================>....] - ETA: 22s - loss: 0.2318 - iou_score: 0.7436 - f1-score: 0.8512For batch 206, tr_loss is    0.23.\n",
      "208/232 [=========================>....] - ETA: 21s - loss: 0.2317 - iou_score: 0.7436 - f1-score: 0.8512For batch 207, tr_loss is    0.23.\n",
      "209/232 [==========================>...] - ETA: 20s - loss: 0.2317 - iou_score: 0.7435 - f1-score: 0.8511For batch 208, tr_loss is    0.23.\n",
      "210/232 [==========================>...] - ETA: 19s - loss: 0.2320 - iou_score: 0.7432 - f1-score: 0.8509For batch 209, tr_loss is    0.23.\n",
      "211/232 [==========================>...] - ETA: 18s - loss: 0.2318 - iou_score: 0.7434 - f1-score: 0.8510For batch 210, tr_loss is    0.23.\n",
      "212/232 [==========================>...] - ETA: 17s - loss: 0.2316 - iou_score: 0.7436 - f1-score: 0.8512For batch 211, tr_loss is    0.23.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213/232 [==========================>...] - ETA: 16s - loss: 0.2316 - iou_score: 0.7436 - f1-score: 0.8512For batch 212, tr_loss is    0.23.\n",
      "214/232 [==========================>...] - ETA: 16s - loss: 0.2315 - iou_score: 0.7437 - f1-score: 0.8513For batch 213, tr_loss is    0.23.\n",
      "215/232 [==========================>...] - ETA: 15s - loss: 0.2313 - iou_score: 0.7439 - f1-score: 0.8514For batch 214, tr_loss is    0.23.\n",
      "216/232 [==========================>...] - ETA: 14s - loss: 0.2312 - iou_score: 0.7441 - f1-score: 0.8515For batch 215, tr_loss is    0.23.\n",
      "217/232 [===========================>..] - ETA: 13s - loss: 0.2312 - iou_score: 0.7440 - f1-score: 0.8515For batch 216, tr_loss is    0.23.\n",
      "218/232 [===========================>..] - ETA: 12s - loss: 0.2311 - iou_score: 0.7441 - f1-score: 0.8515For batch 217, tr_loss is    0.23.\n",
      "219/232 [===========================>..] - ETA: 11s - loss: 0.2315 - iou_score: 0.7436 - f1-score: 0.8512For batch 218, tr_loss is    0.23.\n",
      "220/232 [===========================>..] - ETA: 10s - loss: 0.2316 - iou_score: 0.7434 - f1-score: 0.8511For batch 219, tr_loss is    0.23.\n",
      "221/232 [===========================>..] - ETA: 9s - loss: 0.2318 - iou_score: 0.7432 - f1-score: 0.8509 For batch 220, tr_loss is    0.23.\n",
      "222/232 [===========================>..] - ETA: 8s - loss: 0.2317 - iou_score: 0.7433 - f1-score: 0.8510For batch 221, tr_loss is    0.23.\n",
      "223/232 [===========================>..] - ETA: 8s - loss: 0.2317 - iou_score: 0.7432 - f1-score: 0.8510For batch 222, tr_loss is    0.23.\n",
      "224/232 [===========================>..] - ETA: 7s - loss: 0.2316 - iou_score: 0.7434 - f1-score: 0.8511For batch 223, tr_loss is    0.23.\n",
      "225/232 [============================>.] - ETA: 6s - loss: 0.2314 - iou_score: 0.7437 - f1-score: 0.8512For batch 224, tr_loss is    0.23.\n",
      "226/232 [============================>.] - ETA: 5s - loss: 0.2315 - iou_score: 0.7435 - f1-score: 0.8511For batch 225, tr_loss is    0.23.\n",
      "227/232 [============================>.] - ETA: 4s - loss: 0.2314 - iou_score: 0.7436 - f1-score: 0.8512For batch 226, tr_loss is    0.23.\n",
      "228/232 [============================>.] - ETA: 3s - loss: 0.2314 - iou_score: 0.7436 - f1-score: 0.8512For batch 227, tr_loss is    0.23.\n",
      "229/232 [============================>.] - ETA: 2s - loss: 0.2313 - iou_score: 0.7436 - f1-score: 0.8512For batch 228, tr_loss is    0.23.\n",
      "230/232 [============================>.] - ETA: 1s - loss: 0.2317 - iou_score: 0.7433 - f1-score: 0.8510For batch 229, tr_loss is    0.23.\n",
      "231/232 [============================>.] - ETA: 0s - loss: 0.2319 - iou_score: 0.7431 - f1-score: 0.8509For batch 230, tr_loss is    0.23.\n",
      "232/232 [==============================] - ETA: 0s - loss: 0.2317 - iou_score: 0.7434 - f1-score: 0.8511For batch 231, tr_loss is    0.23.\n",
      "For batch 0, vl_loss is    0.38.\n",
      "For batch 1, vl_loss is    0.36.\n",
      "For batch 2, vl_loss is    0.38.\n",
      "For batch 3, vl_loss is    0.39.\n",
      "For batch 4, vl_loss is    0.44.\n",
      "For batch 5, vl_loss is    0.42.\n",
      "For batch 6, vl_loss is    0.43.\n",
      "For batch 7, vl_loss is    0.42.\n",
      "For batch 8, vl_loss is    0.41.\n",
      "For batch 9, vl_loss is    0.40.\n",
      "For batch 10, vl_loss is    0.41.\n",
      "For batch 11, vl_loss is    0.41.\n",
      "For batch 12, vl_loss is    0.42.\n",
      "For batch 13, vl_loss is    0.43.\n",
      "For batch 14, vl_loss is    0.42.\n",
      "For batch 15, vl_loss is    0.41.\n",
      "For batch 16, vl_loss is    0.41.\n",
      "For batch 17, vl_loss is    0.41.\n",
      "For batch 18, vl_loss is    0.41.\n",
      "For batch 19, vl_loss is    0.41.\n",
      "For batch 20, vl_loss is    0.40.\n",
      "For batch 21, vl_loss is    0.40.\n",
      "For batch 22, vl_loss is    0.40.\n",
      "For batch 23, vl_loss is    0.40.\n",
      "For batch 24, vl_loss is    0.40.\n",
      "For batch 25, vl_loss is    0.40.\n",
      "For batch 26, vl_loss is    0.40.\n",
      "For batch 27, vl_loss is    0.40.\n",
      "For batch 28, vl_loss is    0.40.\n",
      "For batch 29, vl_loss is    0.40.\n",
      "For batch 30, vl_loss is    0.40.\n",
      "For batch 31, vl_loss is    0.40.\n",
      "For batch 32, vl_loss is    0.40.\n",
      "For batch 33, vl_loss is    0.40.\n",
      "For batch 34, vl_loss is    0.40.\n",
      "For batch 35, vl_loss is    0.40.\n",
      "For batch 36, vl_loss is    0.40.\n",
      "For batch 37, vl_loss is    0.40.\n",
      "For batch 38, vl_loss is    0.40.\n",
      "For batch 39, vl_loss is    0.40.\n",
      "For batch 40, vl_loss is    0.40.\n",
      "For batch 41, vl_loss is    0.41.\n",
      "For batch 42, vl_loss is    0.41.\n",
      "For batch 43, vl_loss is    0.41.\n",
      "For batch 44, vl_loss is    0.41.\n",
      "For batch 45, vl_loss is    0.41.\n",
      "For batch 46, vl_loss is    0.41.\n",
      "For batch 47, vl_loss is    0.41.\n",
      "For batch 48, vl_loss is    0.41.\n",
      "For batch 49, vl_loss is    0.41.\n",
      "For batch 50, vl_loss is    0.41.\n",
      "For batch 51, vl_loss is    0.41.\n",
      "For batch 52, vl_loss is    0.41.\n",
      "For batch 53, vl_loss is    0.41.\n",
      "For batch 54, vl_loss is    0.42.\n",
      "For batch 55, vl_loss is    0.42.\n",
      "For batch 56, vl_loss is    0.41.\n",
      "For batch 57, vl_loss is    0.42.\n",
      "For batch 58, vl_loss is    0.41.\n",
      "For batch 59, vl_loss is    0.41.\n",
      "For batch 60, vl_loss is    0.41.\n",
      "For batch 61, vl_loss is    0.41.\n",
      "For batch 62, vl_loss is    0.41.\n",
      "For batch 63, vl_loss is    0.41.\n",
      "For batch 64, vl_loss is    0.41.\n",
      "For batch 65, vl_loss is    0.41.\n",
      "For batch 66, vl_loss is    0.41.\n",
      "For batch 67, vl_loss is    0.41.\n",
      "232/232 [==============================] - 210s 897ms/step - loss: 0.2317 - iou_score: 0.7434 - f1-score: 0.8511 - val_loss: 0.4088 - val_iou_score: 0.6136 - val_f1-score: 0.7580\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.36098\n",
      "The average loss for epoch 15 is    0.23 \n",
      "Epoch 17/200\n",
      "  1/232 [..............................] - ETA: 9:56 - loss: 0.1795 - iou_score: 0.7859 - f1-score: 0.8795For batch 0, tr_loss is    0.18.\n",
      "  2/232 [..............................] - ETA: 5:54 - loss: 0.1819 - iou_score: 0.7863 - f1-score: 0.8801For batch 1, tr_loss is    0.18.\n",
      "  3/232 [..............................] - ETA: 5:40 - loss: 0.2070 - iou_score: 0.7588 - f1-score: 0.8620For batch 2, tr_loss is    0.21.\n",
      "  4/232 [..............................] - ETA: 5:35 - loss: 0.2069 - iou_score: 0.7672 - f1-score: 0.8675For batch 3, tr_loss is    0.21.\n",
      "  5/232 [..............................] - ETA: 5:18 - loss: 0.2244 - iou_score: 0.7523 - f1-score: 0.8573For batch 4, tr_loss is    0.22.\n",
      "  6/232 [..............................] - ETA: 5:20 - loss: 0.2335 - iou_score: 0.7428 - f1-score: 0.8507For batch 5, tr_loss is    0.23.\n",
      "  7/232 [..............................] - ETA: 5:17 - loss: 0.2389 - iou_score: 0.7333 - f1-score: 0.8444For batch 6, tr_loss is    0.24.\n",
      "  8/232 [>.............................] - ETA: 5:05 - loss: 0.2423 - iou_score: 0.7280 - f1-score: 0.8410For batch 7, tr_loss is    0.24.\n",
      "  9/232 [>.............................] - ETA: 4:43 - loss: 0.2332 - iou_score: 0.7390 - f1-score: 0.8481For batch 8, tr_loss is    0.23.\n",
      " 10/232 [>.............................] - ETA: 4:28 - loss: 0.2336 - iou_score: 0.7369 - f1-score: 0.8466For batch 9, tr_loss is    0.23.\n",
      " 11/232 [>.............................] - ETA: 4:26 - loss: 0.2320 - iou_score: 0.7381 - f1-score: 0.8476For batch 10, tr_loss is    0.23.\n",
      " 12/232 [>.............................] - ETA: 4:21 - loss: 0.2284 - iou_score: 0.7435 - f1-score: 0.8512For batch 11, tr_loss is    0.23.\n",
      " 13/232 [>.............................] - ETA: 4:16 - loss: 0.2273 - iou_score: 0.7456 - f1-score: 0.8525For batch 12, tr_loss is    0.23.\n",
      " 14/232 [>.............................] - ETA: 4:13 - loss: 0.2253 - iou_score: 0.7477 - f1-score: 0.8540For batch 13, tr_loss is    0.23.\n",
      " 15/232 [>.............................] - ETA: 4:03 - loss: 0.2220 - iou_score: 0.7516 - f1-score: 0.8566For batch 14, tr_loss is    0.22.\n",
      " 16/232 [=>............................] - ETA: 3:53 - loss: 0.2200 - iou_score: 0.7523 - f1-score: 0.8570For batch 15, tr_loss is    0.22.\n",
      " 17/232 [=>............................] - ETA: 3:47 - loss: 0.2175 - iou_score: 0.7553 - f1-score: 0.8590For batch 16, tr_loss is    0.22.\n",
      " 18/232 [=>............................] - ETA: 3:45 - loss: 0.2186 - iou_score: 0.7535 - f1-score: 0.8579For batch 17, tr_loss is    0.22.\n",
      " 19/232 [=>............................] - ETA: 3:42 - loss: 0.2213 - iou_score: 0.7498 - f1-score: 0.8554For batch 18, tr_loss is    0.22.\n",
      " 20/232 [=>............................] - ETA: 3:41 - loss: 0.2192 - iou_score: 0.7526 - f1-score: 0.8573For batch 19, tr_loss is    0.22.\n",
      " 21/232 [=>............................] - ETA: 3:35 - loss: 0.2226 - iou_score: 0.7506 - f1-score: 0.8558For batch 20, tr_loss is    0.22.\n",
      " 22/232 [=>............................] - ETA: 3:29 - loss: 0.2243 - iou_score: 0.7481 - f1-score: 0.8541For batch 21, tr_loss is    0.22.\n",
      " 23/232 [=>............................] - ETA: 3:30 - loss: 0.2240 - iou_score: 0.7476 - f1-score: 0.8538For batch 22, tr_loss is    0.22.\n",
      " 24/232 [==>...........................] - ETA: 3:30 - loss: 0.2234 - iou_score: 0.7482 - f1-score: 0.8542For batch 23, tr_loss is    0.22.\n",
      " 25/232 [==>...........................] - ETA: 3:29 - loss: 0.2289 - iou_score: 0.7431 - f1-score: 0.8507For batch 24, tr_loss is    0.23.\n",
      " 26/232 [==>...........................] - ETA: 3:28 - loss: 0.2292 - iou_score: 0.7426 - f1-score: 0.8504For batch 25, tr_loss is    0.23.\n",
      " 27/232 [==>...........................] - ETA: 3:27 - loss: 0.2277 - iou_score: 0.7443 - f1-score: 0.8516For batch 26, tr_loss is    0.23.\n",
      " 28/232 [==>...........................] - ETA: 3:26 - loss: 0.2286 - iou_score: 0.7446 - f1-score: 0.8518For batch 27, tr_loss is    0.23.\n",
      " 29/232 [==>...........................] - ETA: 3:23 - loss: 0.2272 - iou_score: 0.7455 - f1-score: 0.8523For batch 28, tr_loss is    0.23.\n",
      " 30/232 [==>...........................] - ETA: 3:20 - loss: 0.2255 - iou_score: 0.7479 - f1-score: 0.8539For batch 29, tr_loss is    0.23.\n",
      " 31/232 [===>..........................] - ETA: 3:17 - loss: 0.2248 - iou_score: 0.7491 - f1-score: 0.8547For batch 30, tr_loss is    0.22.\n",
      " 32/232 [===>..........................] - ETA: 3:17 - loss: 0.2240 - iou_score: 0.7504 - f1-score: 0.8556For batch 31, tr_loss is    0.22.\n",
      " 33/232 [===>..........................] - ETA: 3:16 - loss: 0.2257 - iou_score: 0.7484 - f1-score: 0.8543For batch 32, tr_loss is    0.23.\n",
      " 34/232 [===>..........................] - ETA: 3:12 - loss: 0.2256 - iou_score: 0.7485 - f1-score: 0.8544For batch 33, tr_loss is    0.23.\n",
      " 35/232 [===>..........................] - ETA: 3:12 - loss: 0.2281 - iou_score: 0.7466 - f1-score: 0.8531For batch 34, tr_loss is    0.23.\n",
      " 36/232 [===>..........................] - ETA: 3:08 - loss: 0.2279 - iou_score: 0.7472 - f1-score: 0.8536For batch 35, tr_loss is    0.23.\n",
      " 37/232 [===>..........................] - ETA: 3:07 - loss: 0.2275 - iou_score: 0.7471 - f1-score: 0.8535For batch 36, tr_loss is    0.23.\n",
      " 38/232 [===>..........................] - ETA: 3:07 - loss: 0.2296 - iou_score: 0.7457 - f1-score: 0.8526For batch 37, tr_loss is    0.23.\n",
      " 39/232 [====>.........................] - ETA: 3:06 - loss: 0.2343 - iou_score: 0.7423 - f1-score: 0.8502For batch 38, tr_loss is    0.23.\n",
      " 40/232 [====>.........................] - ETA: 3:05 - loss: 0.2352 - iou_score: 0.7413 - f1-score: 0.8496For batch 39, tr_loss is    0.24.\n",
      " 41/232 [====>.........................] - ETA: 3:03 - loss: 0.2361 - iou_score: 0.7402 - f1-score: 0.8489For batch 40, tr_loss is    0.24.\n",
      " 42/232 [====>.........................] - ETA: 3:03 - loss: 0.2363 - iou_score: 0.7395 - f1-score: 0.8484For batch 41, tr_loss is    0.24.\n",
      " 43/232 [====>.........................] - ETA: 3:02 - loss: 0.2356 - iou_score: 0.7401 - f1-score: 0.8489For batch 42, tr_loss is    0.24.\n",
      " 44/232 [====>.........................] - ETA: 3:01 - loss: 0.2362 - iou_score: 0.7391 - f1-score: 0.8482For batch 43, tr_loss is    0.24.\n",
      " 45/232 [====>.........................] - ETA: 2:59 - loss: 0.2365 - iou_score: 0.7390 - f1-score: 0.8482For batch 44, tr_loss is    0.24.\n",
      " 46/232 [====>.........................] - ETA: 2:57 - loss: 0.2363 - iou_score: 0.7392 - f1-score: 0.8483For batch 45, tr_loss is    0.24.\n",
      " 47/232 [=====>........................] - ETA: 2:56 - loss: 0.2358 - iou_score: 0.7399 - f1-score: 0.8488For batch 46, tr_loss is    0.24.\n",
      " 48/232 [=====>........................] - ETA: 2:53 - loss: 0.2347 - iou_score: 0.7412 - f1-score: 0.8496For batch 47, tr_loss is    0.23.\n",
      " 49/232 [=====>........................] - ETA: 2:52 - loss: 0.2349 - iou_score: 0.7407 - f1-score: 0.8493For batch 48, tr_loss is    0.23.\n",
      " 50/232 [=====>........................] - ETA: 2:51 - loss: 0.2350 - iou_score: 0.7408 - f1-score: 0.8494For batch 49, tr_loss is    0.23.\n",
      " 51/232 [=====>........................] - ETA: 2:51 - loss: 0.2353 - iou_score: 0.7404 - f1-score: 0.8491For batch 50, tr_loss is    0.24.\n",
      " 52/232 [=====>........................] - ETA: 2:48 - loss: 0.2375 - iou_score: 0.7380 - f1-score: 0.8475For batch 51, tr_loss is    0.24.\n",
      " 53/232 [=====>........................] - ETA: 2:47 - loss: 0.2364 - iou_score: 0.7395 - f1-score: 0.8485For batch 52, tr_loss is    0.24.\n",
      " 54/232 [=====>........................] - ETA: 2:46 - loss: 0.2364 - iou_score: 0.7394 - f1-score: 0.8484For batch 53, tr_loss is    0.24.\n",
      " 55/232 [======>.......................] - ETA: 2:43 - loss: 0.2357 - iou_score: 0.7402 - f1-score: 0.8489For batch 54, tr_loss is    0.24.\n",
      " 56/232 [======>.......................] - ETA: 2:42 - loss: 0.2349 - iou_score: 0.7410 - f1-score: 0.8495For batch 55, tr_loss is    0.23.\n",
      " 57/232 [======>.......................] - ETA: 2:40 - loss: 0.2353 - iou_score: 0.7403 - f1-score: 0.8490For batch 56, tr_loss is    0.24.\n",
      " 58/232 [======>.......................] - ETA: 2:40 - loss: 0.2350 - iou_score: 0.7410 - f1-score: 0.8495For batch 57, tr_loss is    0.24.\n",
      " 59/232 [======>.......................] - ETA: 2:39 - loss: 0.2347 - iou_score: 0.7413 - f1-score: 0.8497For batch 58, tr_loss is    0.23.\n",
      " 60/232 [======>.......................] - ETA: 2:39 - loss: 0.2358 - iou_score: 0.7398 - f1-score: 0.8487For batch 59, tr_loss is    0.24.\n",
      " 61/232 [======>.......................] - ETA: 2:38 - loss: 0.2372 - iou_score: 0.7382 - f1-score: 0.8475For batch 60, tr_loss is    0.24.\n",
      " 62/232 [=======>......................] - ETA: 2:37 - loss: 0.2381 - iou_score: 0.7371 - f1-score: 0.8468For batch 61, tr_loss is    0.24.\n",
      " 63/232 [=======>......................] - ETA: 2:36 - loss: 0.2375 - iou_score: 0.7378 - f1-score: 0.8472For batch 62, tr_loss is    0.24.\n",
      " 64/232 [=======>......................] - ETA: 2:36 - loss: 0.2374 - iou_score: 0.7378 - f1-score: 0.8473For batch 63, tr_loss is    0.24.\n",
      " 65/232 [=======>......................] - ETA: 2:34 - loss: 0.2372 - iou_score: 0.7380 - f1-score: 0.8474For batch 64, tr_loss is    0.24.\n",
      " 66/232 [=======>......................] - ETA: 2:32 - loss: 0.2374 - iou_score: 0.7379 - f1-score: 0.8473For batch 65, tr_loss is    0.24.\n",
      " 67/232 [=======>......................] - ETA: 2:31 - loss: 0.2368 - iou_score: 0.7385 - f1-score: 0.8477For batch 66, tr_loss is    0.24.\n",
      " 68/232 [=======>......................] - ETA: 2:31 - loss: 0.2365 - iou_score: 0.7390 - f1-score: 0.8481For batch 67, tr_loss is    0.24.\n",
      " 69/232 [=======>......................] - ETA: 2:29 - loss: 0.2367 - iou_score: 0.7390 - f1-score: 0.8481For batch 68, tr_loss is    0.24.\n",
      " 70/232 [========>.....................] - ETA: 2:27 - loss: 0.2363 - iou_score: 0.7392 - f1-score: 0.8483For batch 69, tr_loss is    0.24.\n",
      " 71/232 [========>.....................] - ETA: 2:27 - loss: 0.2357 - iou_score: 0.7402 - f1-score: 0.8489For batch 70, tr_loss is    0.24.\n",
      " 72/232 [========>.....................] - ETA: 2:26 - loss: 0.2350 - iou_score: 0.7408 - f1-score: 0.8493For batch 71, tr_loss is    0.24.\n",
      " 73/232 [========>.....................] - ETA: 2:25 - loss: 0.2353 - iou_score: 0.7403 - f1-score: 0.8490For batch 72, tr_loss is    0.24.\n",
      " 74/232 [========>.....................] - ETA: 2:23 - loss: 0.2347 - iou_score: 0.7410 - f1-score: 0.8494For batch 73, tr_loss is    0.23.\n",
      " 75/232 [========>.....................] - ETA: 2:23 - loss: 0.2349 - iou_score: 0.7404 - f1-score: 0.8491For batch 74, tr_loss is    0.23.\n",
      " 76/232 [========>.....................] - ETA: 2:22 - loss: 0.2343 - iou_score: 0.7409 - f1-score: 0.8494For batch 75, tr_loss is    0.23.\n",
      " 77/232 [========>.....................] - ETA: 2:20 - loss: 0.2337 - iou_score: 0.7416 - f1-score: 0.8499For batch 76, tr_loss is    0.23.\n",
      " 78/232 [=========>....................] - ETA: 2:19 - loss: 0.2338 - iou_score: 0.7414 - f1-score: 0.8498For batch 77, tr_loss is    0.23.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 79/232 [=========>....................] - ETA: 2:19 - loss: 0.2332 - iou_score: 0.7421 - f1-score: 0.8502For batch 78, tr_loss is    0.23.\n",
      " 80/232 [=========>....................] - ETA: 2:18 - loss: 0.2335 - iou_score: 0.7420 - f1-score: 0.8502For batch 79, tr_loss is    0.23.\n",
      " 81/232 [=========>....................] - ETA: 2:16 - loss: 0.2335 - iou_score: 0.7420 - f1-score: 0.8501For batch 80, tr_loss is    0.23.\n",
      " 82/232 [=========>....................] - ETA: 2:16 - loss: 0.2334 - iou_score: 0.7420 - f1-score: 0.8502For batch 81, tr_loss is    0.23.\n",
      " 83/232 [=========>....................] - ETA: 2:15 - loss: 0.2342 - iou_score: 0.7411 - f1-score: 0.8496For batch 82, tr_loss is    0.23.\n",
      " 84/232 [=========>....................] - ETA: 2:14 - loss: 0.2346 - iou_score: 0.7404 - f1-score: 0.8491For batch 83, tr_loss is    0.23.\n",
      " 85/232 [=========>....................] - ETA: 2:13 - loss: 0.2347 - iou_score: 0.7405 - f1-score: 0.8492For batch 84, tr_loss is    0.23.\n",
      " 86/232 [==========>...................] - ETA: 2:12 - loss: 0.2348 - iou_score: 0.7402 - f1-score: 0.8490For batch 85, tr_loss is    0.23.\n",
      " 87/232 [==========>...................] - ETA: 2:11 - loss: 0.2344 - iou_score: 0.7406 - f1-score: 0.8493For batch 86, tr_loss is    0.23.\n",
      " 88/232 [==========>...................] - ETA: 2:10 - loss: 0.2349 - iou_score: 0.7399 - f1-score: 0.8489For batch 87, tr_loss is    0.23.\n",
      " 89/232 [==========>...................] - ETA: 2:10 - loss: 0.2345 - iou_score: 0.7403 - f1-score: 0.8491For batch 88, tr_loss is    0.23.\n",
      " 90/232 [==========>...................] - ETA: 2:08 - loss: 0.2340 - iou_score: 0.7408 - f1-score: 0.8495For batch 89, tr_loss is    0.23.\n",
      " 91/232 [==========>...................] - ETA: 2:07 - loss: 0.2338 - iou_score: 0.7409 - f1-score: 0.8496For batch 90, tr_loss is    0.23.\n",
      " 92/232 [==========>...................] - ETA: 2:06 - loss: 0.2336 - iou_score: 0.7410 - f1-score: 0.8496For batch 91, tr_loss is    0.23.\n",
      " 93/232 [===========>..................] - ETA: 2:05 - loss: 0.2340 - iou_score: 0.7404 - f1-score: 0.8492For batch 92, tr_loss is    0.23.\n",
      " 94/232 [===========>..................] - ETA: 2:04 - loss: 0.2336 - iou_score: 0.7408 - f1-score: 0.8495For batch 93, tr_loss is    0.23.\n",
      " 95/232 [===========>..................] - ETA: 2:02 - loss: 0.2341 - iou_score: 0.7403 - f1-score: 0.8491For batch 94, tr_loss is    0.23.\n",
      " 96/232 [===========>..................] - ETA: 2:02 - loss: 0.2342 - iou_score: 0.7403 - f1-score: 0.8491For batch 95, tr_loss is    0.23.\n",
      " 97/232 [===========>..................] - ETA: 2:01 - loss: 0.2346 - iou_score: 0.7398 - f1-score: 0.8488For batch 96, tr_loss is    0.23.\n",
      " 98/232 [===========>..................] - ETA: 2:00 - loss: 0.2344 - iou_score: 0.7400 - f1-score: 0.8490For batch 97, tr_loss is    0.23.\n",
      " 99/232 [===========>..................] - ETA: 2:00 - loss: 0.2337 - iou_score: 0.7410 - f1-score: 0.8496For batch 98, tr_loss is    0.23.\n",
      "100/232 [===========>..................] - ETA: 1:59 - loss: 0.2332 - iou_score: 0.7416 - f1-score: 0.8500For batch 99, tr_loss is    0.23.\n",
      "101/232 [============>.................] - ETA: 1:58 - loss: 0.2328 - iou_score: 0.7421 - f1-score: 0.8504For batch 100, tr_loss is    0.23.\n",
      "102/232 [============>.................] - ETA: 1:57 - loss: 0.2327 - iou_score: 0.7422 - f1-score: 0.8504For batch 101, tr_loss is    0.23.\n",
      "103/232 [============>.................] - ETA: 1:56 - loss: 0.2331 - iou_score: 0.7420 - f1-score: 0.8503For batch 102, tr_loss is    0.23.\n",
      "104/232 [============>.................] - ETA: 1:55 - loss: 0.2329 - iou_score: 0.7422 - f1-score: 0.8504For batch 103, tr_loss is    0.23.\n",
      "105/232 [============>.................] - ETA: 1:54 - loss: 0.2323 - iou_score: 0.7430 - f1-score: 0.8509For batch 104, tr_loss is    0.23.\n",
      "106/232 [============>.................] - ETA: 1:53 - loss: 0.2317 - iou_score: 0.7438 - f1-score: 0.8514For batch 105, tr_loss is    0.23.\n",
      "107/232 [============>.................] - ETA: 1:52 - loss: 0.2321 - iou_score: 0.7435 - f1-score: 0.8512For batch 106, tr_loss is    0.23.\n",
      "108/232 [============>.................] - ETA: 1:51 - loss: 0.2327 - iou_score: 0.7426 - f1-score: 0.8506For batch 107, tr_loss is    0.23.\n",
      "109/232 [=============>................] - ETA: 1:51 - loss: 0.2323 - iou_score: 0.7431 - f1-score: 0.8510For batch 108, tr_loss is    0.23.\n",
      "110/232 [=============>................] - ETA: 1:50 - loss: 0.2315 - iou_score: 0.7442 - f1-score: 0.8516For batch 109, tr_loss is    0.23.\n",
      "111/232 [=============>................] - ETA: 1:49 - loss: 0.2318 - iou_score: 0.7437 - f1-score: 0.8513For batch 110, tr_loss is    0.23.\n",
      "112/232 [=============>................] - ETA: 1:48 - loss: 0.2318 - iou_score: 0.7437 - f1-score: 0.8513For batch 111, tr_loss is    0.23.\n",
      "113/232 [=============>................] - ETA: 1:47 - loss: 0.2321 - iou_score: 0.7434 - f1-score: 0.8511For batch 112, tr_loss is    0.23.\n",
      "114/232 [=============>................] - ETA: 1:47 - loss: 0.2315 - iou_score: 0.7442 - f1-score: 0.8516For batch 113, tr_loss is    0.23.\n",
      "115/232 [=============>................] - ETA: 1:46 - loss: 0.2310 - iou_score: 0.7447 - f1-score: 0.8520For batch 114, tr_loss is    0.23.\n",
      "116/232 [==============>...............] - ETA: 1:45 - loss: 0.2309 - iou_score: 0.7448 - f1-score: 0.8521For batch 115, tr_loss is    0.23.\n",
      "117/232 [==============>...............] - ETA: 1:43 - loss: 0.2309 - iou_score: 0.7449 - f1-score: 0.8521For batch 116, tr_loss is    0.23.\n",
      "118/232 [==============>...............] - ETA: 1:42 - loss: 0.2305 - iou_score: 0.7455 - f1-score: 0.8525For batch 117, tr_loss is    0.23.\n",
      "119/232 [==============>...............] - ETA: 1:42 - loss: 0.2302 - iou_score: 0.7460 - f1-score: 0.8528For batch 118, tr_loss is    0.23.\n",
      "120/232 [==============>...............] - ETA: 1:41 - loss: 0.2309 - iou_score: 0.7455 - f1-score: 0.8525For batch 119, tr_loss is    0.23.\n",
      "121/232 [==============>...............] - ETA: 1:40 - loss: 0.2304 - iou_score: 0.7460 - f1-score: 0.8528For batch 120, tr_loss is    0.23.\n",
      "122/232 [==============>...............] - ETA: 1:39 - loss: 0.2310 - iou_score: 0.7452 - f1-score: 0.8523For batch 121, tr_loss is    0.23.\n",
      "123/232 [==============>...............] - ETA: 1:38 - loss: 0.2307 - iou_score: 0.7456 - f1-score: 0.8525For batch 122, tr_loss is    0.23.\n",
      "124/232 [===============>..............] - ETA: 1:37 - loss: 0.2307 - iou_score: 0.7455 - f1-score: 0.8525For batch 123, tr_loss is    0.23.\n",
      "125/232 [===============>..............] - ETA: 1:36 - loss: 0.2310 - iou_score: 0.7451 - f1-score: 0.8523For batch 124, tr_loss is    0.23.\n",
      "126/232 [===============>..............] - ETA: 1:36 - loss: 0.2309 - iou_score: 0.7454 - f1-score: 0.8524For batch 125, tr_loss is    0.23.\n",
      "127/232 [===============>..............] - ETA: 1:35 - loss: 0.2306 - iou_score: 0.7455 - f1-score: 0.8526For batch 126, tr_loss is    0.23.\n",
      "128/232 [===============>..............] - ETA: 1:34 - loss: 0.2308 - iou_score: 0.7452 - f1-score: 0.8523For batch 127, tr_loss is    0.23.\n",
      "129/232 [===============>..............] - ETA: 1:33 - loss: 0.2309 - iou_score: 0.7449 - f1-score: 0.8522For batch 128, tr_loss is    0.23.\n",
      "130/232 [===============>..............] - ETA: 1:32 - loss: 0.2307 - iou_score: 0.7455 - f1-score: 0.8525For batch 129, tr_loss is    0.23.\n",
      "131/232 [===============>..............] - ETA: 1:31 - loss: 0.2311 - iou_score: 0.7449 - f1-score: 0.8521For batch 130, tr_loss is    0.23.\n",
      "132/232 [================>.............] - ETA: 1:30 - loss: 0.2316 - iou_score: 0.7447 - f1-score: 0.8520For batch 131, tr_loss is    0.23.\n",
      "133/232 [================>.............] - ETA: 1:29 - loss: 0.2312 - iou_score: 0.7450 - f1-score: 0.8522For batch 132, tr_loss is    0.23.\n",
      "134/232 [================>.............] - ETA: 1:28 - loss: 0.2314 - iou_score: 0.7447 - f1-score: 0.8520For batch 133, tr_loss is    0.23.\n",
      "135/232 [================>.............] - ETA: 1:27 - loss: 0.2312 - iou_score: 0.7448 - f1-score: 0.8521For batch 134, tr_loss is    0.23.\n",
      "136/232 [================>.............] - ETA: 1:26 - loss: 0.2315 - iou_score: 0.7444 - f1-score: 0.8518For batch 135, tr_loss is    0.23.\n",
      "137/232 [================>.............] - ETA: 1:25 - loss: 0.2316 - iou_score: 0.7443 - f1-score: 0.8518For batch 136, tr_loss is    0.23.\n",
      "138/232 [================>.............] - ETA: 1:25 - loss: 0.2320 - iou_score: 0.7439 - f1-score: 0.8515For batch 137, tr_loss is    0.23.\n",
      "139/232 [================>.............] - ETA: 1:24 - loss: 0.2321 - iou_score: 0.7439 - f1-score: 0.8515For batch 138, tr_loss is    0.23.\n",
      "140/232 [=================>............] - ETA: 1:23 - loss: 0.2320 - iou_score: 0.7440 - f1-score: 0.8516For batch 139, tr_loss is    0.23.\n",
      "141/232 [=================>............] - ETA: 1:22 - loss: 0.2326 - iou_score: 0.7432 - f1-score: 0.8510For batch 140, tr_loss is    0.23.\n",
      "142/232 [=================>............] - ETA: 1:21 - loss: 0.2324 - iou_score: 0.7434 - f1-score: 0.8512For batch 141, tr_loss is    0.23.\n",
      "143/232 [=================>............] - ETA: 1:20 - loss: 0.2323 - iou_score: 0.7434 - f1-score: 0.8512For batch 142, tr_loss is    0.23.\n",
      "144/232 [=================>............] - ETA: 1:19 - loss: 0.2323 - iou_score: 0.7432 - f1-score: 0.8511For batch 143, tr_loss is    0.23.\n",
      "145/232 [=================>............] - ETA: 1:18 - loss: 0.2323 - iou_score: 0.7431 - f1-score: 0.8510For batch 144, tr_loss is    0.23.\n",
      "146/232 [=================>............] - ETA: 1:17 - loss: 0.2325 - iou_score: 0.7427 - f1-score: 0.8507For batch 145, tr_loss is    0.23.\n",
      "147/232 [==================>...........] - ETA: 1:17 - loss: 0.2322 - iou_score: 0.7432 - f1-score: 0.8510For batch 146, tr_loss is    0.23.\n",
      "148/232 [==================>...........] - ETA: 1:16 - loss: 0.2324 - iou_score: 0.7428 - f1-score: 0.8507For batch 147, tr_loss is    0.23.\n",
      "149/232 [==================>...........] - ETA: 1:15 - loss: 0.2322 - iou_score: 0.7431 - f1-score: 0.8510For batch 148, tr_loss is    0.23.\n",
      "150/232 [==================>...........] - ETA: 1:14 - loss: 0.2330 - iou_score: 0.7424 - f1-score: 0.8505For batch 149, tr_loss is    0.23.\n",
      "151/232 [==================>...........] - ETA: 1:13 - loss: 0.2333 - iou_score: 0.7420 - f1-score: 0.8502For batch 150, tr_loss is    0.23.\n",
      "152/232 [==================>...........] - ETA: 1:12 - loss: 0.2331 - iou_score: 0.7423 - f1-score: 0.8504For batch 151, tr_loss is    0.23.\n",
      "153/232 [==================>...........] - ETA: 1:11 - loss: 0.2330 - iou_score: 0.7424 - f1-score: 0.8504For batch 152, tr_loss is    0.23.\n",
      "154/232 [==================>...........] - ETA: 1:10 - loss: 0.2327 - iou_score: 0.7426 - f1-score: 0.8506For batch 153, tr_loss is    0.23.\n",
      "155/232 [===================>..........] - ETA: 1:09 - loss: 0.2327 - iou_score: 0.7426 - f1-score: 0.8506For batch 154, tr_loss is    0.23.\n",
      "156/232 [===================>..........] - ETA: 1:08 - loss: 0.2327 - iou_score: 0.7425 - f1-score: 0.8505For batch 155, tr_loss is    0.23.\n",
      "157/232 [===================>..........] - ETA: 1:07 - loss: 0.2330 - iou_score: 0.7422 - f1-score: 0.8503For batch 156, tr_loss is    0.23.\n",
      "158/232 [===================>..........] - ETA: 1:07 - loss: 0.2328 - iou_score: 0.7424 - f1-score: 0.8505For batch 157, tr_loss is    0.23.\n",
      "159/232 [===================>..........] - ETA: 1:06 - loss: 0.2324 - iou_score: 0.7429 - f1-score: 0.8508For batch 158, tr_loss is    0.23.\n",
      "160/232 [===================>..........] - ETA: 1:05 - loss: 0.2324 - iou_score: 0.7429 - f1-score: 0.8508For batch 159, tr_loss is    0.23.\n",
      "161/232 [===================>..........] - ETA: 1:04 - loss: 0.2320 - iou_score: 0.7434 - f1-score: 0.8512For batch 160, tr_loss is    0.23.\n",
      "162/232 [===================>..........] - ETA: 1:03 - loss: 0.2319 - iou_score: 0.7434 - f1-score: 0.8512For batch 161, tr_loss is    0.23.\n",
      "163/232 [====================>.........] - ETA: 1:02 - loss: 0.2316 - iou_score: 0.7439 - f1-score: 0.8514For batch 162, tr_loss is    0.23.\n",
      "164/232 [====================>.........] - ETA: 1:01 - loss: 0.2318 - iou_score: 0.7436 - f1-score: 0.8513For batch 163, tr_loss is    0.23.\n",
      "165/232 [====================>.........] - ETA: 1:00 - loss: 0.2320 - iou_score: 0.7435 - f1-score: 0.8512For batch 164, tr_loss is    0.23.\n",
      "166/232 [====================>.........] - ETA: 59s - loss: 0.2316 - iou_score: 0.7438 - f1-score: 0.8514 For batch 165, tr_loss is    0.23.\n",
      "167/232 [====================>.........] - ETA: 59s - loss: 0.2313 - iou_score: 0.7440 - f1-score: 0.8516For batch 166, tr_loss is    0.23.\n",
      "168/232 [====================>.........] - ETA: 58s - loss: 0.2315 - iou_score: 0.7438 - f1-score: 0.8514For batch 167, tr_loss is    0.23.\n",
      "169/232 [====================>.........] - ETA: 57s - loss: 0.2319 - iou_score: 0.7434 - f1-score: 0.8511For batch 168, tr_loss is    0.23.\n",
      "170/232 [====================>.........] - ETA: 56s - loss: 0.2318 - iou_score: 0.7435 - f1-score: 0.8512For batch 169, tr_loss is    0.23.\n",
      "171/232 [=====================>........] - ETA: 55s - loss: 0.2320 - iou_score: 0.7432 - f1-score: 0.8510For batch 170, tr_loss is    0.23.\n",
      "172/232 [=====================>........] - ETA: 54s - loss: 0.2323 - iou_score: 0.7429 - f1-score: 0.8508For batch 171, tr_loss is    0.23.\n",
      "173/232 [=====================>........] - ETA: 53s - loss: 0.2320 - iou_score: 0.7432 - f1-score: 0.8510For batch 172, tr_loss is    0.23.\n",
      "174/232 [=====================>........] - ETA: 52s - loss: 0.2318 - iou_score: 0.7434 - f1-score: 0.8511For batch 173, tr_loss is    0.23.\n",
      "175/232 [=====================>........] - ETA: 51s - loss: 0.2318 - iou_score: 0.7433 - f1-score: 0.8511For batch 174, tr_loss is    0.23.\n",
      "176/232 [=====================>........] - ETA: 50s - loss: 0.2320 - iou_score: 0.7430 - f1-score: 0.8509For batch 175, tr_loss is    0.23.\n",
      "177/232 [=====================>........] - ETA: 49s - loss: 0.2318 - iou_score: 0.7433 - f1-score: 0.8511For batch 176, tr_loss is    0.23.\n",
      "178/232 [======================>.......] - ETA: 49s - loss: 0.2318 - iou_score: 0.7433 - f1-score: 0.8511For batch 177, tr_loss is    0.23.\n",
      "179/232 [======================>.......] - ETA: 48s - loss: 0.2317 - iou_score: 0.7433 - f1-score: 0.8511For batch 178, tr_loss is    0.23.\n",
      "180/232 [======================>.......] - ETA: 47s - loss: 0.2318 - iou_score: 0.7431 - f1-score: 0.8510For batch 179, tr_loss is    0.23.\n",
      "181/232 [======================>.......] - ETA: 46s - loss: 0.2318 - iou_score: 0.7431 - f1-score: 0.8510For batch 180, tr_loss is    0.23.\n",
      "182/232 [======================>.......] - ETA: 45s - loss: 0.2318 - iou_score: 0.7431 - f1-score: 0.8510For batch 181, tr_loss is    0.23.\n",
      "183/232 [======================>.......] - ETA: 44s - loss: 0.2317 - iou_score: 0.7431 - f1-score: 0.8510For batch 182, tr_loss is    0.23.\n",
      "184/232 [======================>.......] - ETA: 43s - loss: 0.2315 - iou_score: 0.7435 - f1-score: 0.8512For batch 183, tr_loss is    0.23.\n",
      "185/232 [======================>.......] - ETA: 42s - loss: 0.2316 - iou_score: 0.7434 - f1-score: 0.8512For batch 184, tr_loss is    0.23.\n",
      "186/232 [=======================>......] - ETA: 41s - loss: 0.2316 - iou_score: 0.7433 - f1-score: 0.8511For batch 185, tr_loss is    0.23.\n",
      "187/232 [=======================>......] - ETA: 40s - loss: 0.2312 - iou_score: 0.7438 - f1-score: 0.8514For batch 186, tr_loss is    0.23.\n",
      "188/232 [=======================>......] - ETA: 39s - loss: 0.2312 - iou_score: 0.7437 - f1-score: 0.8513For batch 187, tr_loss is    0.23.\n",
      "189/232 [=======================>......] - ETA: 39s - loss: 0.2311 - iou_score: 0.7438 - f1-score: 0.8514For batch 188, tr_loss is    0.23.\n",
      "190/232 [=======================>......] - ETA: 38s - loss: 0.2311 - iou_score: 0.7439 - f1-score: 0.8515For batch 189, tr_loss is    0.23.\n",
      "191/232 [=======================>......] - ETA: 37s - loss: 0.2312 - iou_score: 0.7440 - f1-score: 0.8515For batch 190, tr_loss is    0.23.\n",
      "192/232 [=======================>......] - ETA: 36s - loss: 0.2316 - iou_score: 0.7435 - f1-score: 0.8512For batch 191, tr_loss is    0.23.\n",
      "193/232 [=======================>......] - ETA: 35s - loss: 0.2318 - iou_score: 0.7433 - f1-score: 0.8511For batch 192, tr_loss is    0.23.\n",
      "194/232 [========================>.....] - ETA: 34s - loss: 0.2318 - iou_score: 0.7431 - f1-score: 0.8510For batch 193, tr_loss is    0.23.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/232 [========================>.....] - ETA: 33s - loss: 0.2317 - iou_score: 0.7431 - f1-score: 0.8510For batch 194, tr_loss is    0.23.\n",
      "196/232 [========================>.....] - ETA: 32s - loss: 0.2316 - iou_score: 0.7433 - f1-score: 0.8511For batch 195, tr_loss is    0.23.\n",
      "197/232 [========================>.....] - ETA: 31s - loss: 0.2316 - iou_score: 0.7433 - f1-score: 0.8511For batch 196, tr_loss is    0.23.\n",
      "198/232 [========================>.....] - ETA: 30s - loss: 0.2313 - iou_score: 0.7437 - f1-score: 0.8514For batch 197, tr_loss is    0.23.\n",
      "199/232 [========================>.....] - ETA: 29s - loss: 0.2311 - iou_score: 0.7440 - f1-score: 0.8515For batch 198, tr_loss is    0.23.\n",
      "200/232 [========================>.....] - ETA: 28s - loss: 0.2308 - iou_score: 0.7444 - f1-score: 0.8518For batch 199, tr_loss is    0.23.\n",
      "201/232 [========================>.....] - ETA: 28s - loss: 0.2309 - iou_score: 0.7441 - f1-score: 0.8516For batch 200, tr_loss is    0.23.\n",
      "202/232 [=========================>....] - ETA: 27s - loss: 0.2308 - iou_score: 0.7442 - f1-score: 0.8517For batch 201, tr_loss is    0.23.\n",
      "203/232 [=========================>....] - ETA: 26s - loss: 0.2305 - iou_score: 0.7445 - f1-score: 0.8519For batch 202, tr_loss is    0.23.\n",
      "204/232 [=========================>....] - ETA: 25s - loss: 0.2302 - iou_score: 0.7449 - f1-score: 0.8521For batch 203, tr_loss is    0.23.\n",
      "205/232 [=========================>....] - ETA: 24s - loss: 0.2302 - iou_score: 0.7449 - f1-score: 0.8521For batch 204, tr_loss is    0.23.\n",
      "206/232 [=========================>....] - ETA: 23s - loss: 0.2302 - iou_score: 0.7447 - f1-score: 0.8520For batch 205, tr_loss is    0.23.\n",
      "207/232 [=========================>....] - ETA: 22s - loss: 0.2302 - iou_score: 0.7448 - f1-score: 0.8521For batch 206, tr_loss is    0.23.\n",
      "208/232 [=========================>....] - ETA: 21s - loss: 0.2302 - iou_score: 0.7447 - f1-score: 0.8520For batch 207, tr_loss is    0.23.\n",
      "209/232 [==========================>...] - ETA: 20s - loss: 0.2304 - iou_score: 0.7445 - f1-score: 0.8519For batch 208, tr_loss is    0.23.\n",
      "210/232 [==========================>...] - ETA: 19s - loss: 0.2307 - iou_score: 0.7441 - f1-score: 0.8516For batch 209, tr_loss is    0.23.\n",
      "211/232 [==========================>...] - ETA: 18s - loss: 0.2306 - iou_score: 0.7443 - f1-score: 0.8518For batch 210, tr_loss is    0.23.\n",
      "212/232 [==========================>...] - ETA: 18s - loss: 0.2303 - iou_score: 0.7446 - f1-score: 0.8519For batch 211, tr_loss is    0.23.\n",
      "213/232 [==========================>...] - ETA: 17s - loss: 0.2305 - iou_score: 0.7445 - f1-score: 0.8519For batch 212, tr_loss is    0.23.\n",
      "214/232 [==========================>...] - ETA: 16s - loss: 0.2303 - iou_score: 0.7447 - f1-score: 0.8520For batch 213, tr_loss is    0.23.\n",
      "215/232 [==========================>...] - ETA: 15s - loss: 0.2302 - iou_score: 0.7448 - f1-score: 0.8521For batch 214, tr_loss is    0.23.\n",
      "216/232 [==========================>...] - ETA: 14s - loss: 0.2300 - iou_score: 0.7450 - f1-score: 0.8522For batch 215, tr_loss is    0.23.\n",
      "217/232 [===========================>..] - ETA: 13s - loss: 0.2301 - iou_score: 0.7450 - f1-score: 0.8522For batch 216, tr_loss is    0.23.\n",
      "218/232 [===========================>..] - ETA: 12s - loss: 0.2301 - iou_score: 0.7449 - f1-score: 0.8521For batch 217, tr_loss is    0.23.\n",
      "219/232 [===========================>..] - ETA: 11s - loss: 0.2305 - iou_score: 0.7443 - f1-score: 0.8517For batch 218, tr_loss is    0.23.\n",
      "220/232 [===========================>..] - ETA: 10s - loss: 0.2306 - iou_score: 0.7442 - f1-score: 0.8517For batch 219, tr_loss is    0.23.\n",
      "221/232 [===========================>..] - ETA: 9s - loss: 0.2306 - iou_score: 0.7441 - f1-score: 0.8516 For batch 220, tr_loss is    0.23.\n",
      "222/232 [===========================>..] - ETA: 9s - loss: 0.2304 - iou_score: 0.7443 - f1-score: 0.8518For batch 221, tr_loss is    0.23.\n",
      "223/232 [===========================>..] - ETA: 8s - loss: 0.2305 - iou_score: 0.7442 - f1-score: 0.8517For batch 222, tr_loss is    0.23.\n",
      "224/232 [===========================>..] - ETA: 7s - loss: 0.2304 - iou_score: 0.7444 - f1-score: 0.8518For batch 223, tr_loss is    0.23.\n",
      "225/232 [============================>.] - ETA: 6s - loss: 0.2303 - iou_score: 0.7445 - f1-score: 0.8519For batch 224, tr_loss is    0.23.\n",
      "226/232 [============================>.] - ETA: 5s - loss: 0.2304 - iou_score: 0.7443 - f1-score: 0.8518For batch 225, tr_loss is    0.23.\n",
      "227/232 [============================>.] - ETA: 4s - loss: 0.2303 - iou_score: 0.7444 - f1-score: 0.8519For batch 226, tr_loss is    0.23.\n",
      "228/232 [============================>.] - ETA: 3s - loss: 0.2303 - iou_score: 0.7443 - f1-score: 0.8517For batch 227, tr_loss is    0.23.\n",
      "229/232 [============================>.] - ETA: 2s - loss: 0.2303 - iou_score: 0.7443 - f1-score: 0.8518For batch 228, tr_loss is    0.23.\n",
      "230/232 [============================>.] - ETA: 1s - loss: 0.2308 - iou_score: 0.7440 - f1-score: 0.8516For batch 229, tr_loss is    0.23.\n",
      "231/232 [============================>.] - ETA: 0s - loss: 0.2308 - iou_score: 0.7439 - f1-score: 0.8515For batch 230, tr_loss is    0.23.\n",
      "232/232 [==============================] - ETA: 0s - loss: 0.2306 - iou_score: 0.7442 - f1-score: 0.8517For batch 231, tr_loss is    0.23.\n",
      "For batch 0, vl_loss is    0.36.\n",
      "For batch 1, vl_loss is    0.36.\n",
      "For batch 2, vl_loss is    0.39.\n",
      "For batch 3, vl_loss is    0.38.\n",
      "For batch 4, vl_loss is    0.42.\n",
      "For batch 5, vl_loss is    0.40.\n",
      "For batch 6, vl_loss is    0.41.\n",
      "For batch 7, vl_loss is    0.41.\n",
      "For batch 8, vl_loss is    0.41.\n",
      "For batch 9, vl_loss is    0.39.\n",
      "For batch 10, vl_loss is    0.40.\n",
      "For batch 11, vl_loss is    0.40.\n",
      "For batch 12, vl_loss is    0.41.\n",
      "For batch 13, vl_loss is    0.41.\n",
      "For batch 14, vl_loss is    0.41.\n",
      "For batch 15, vl_loss is    0.40.\n",
      "For batch 16, vl_loss is    0.40.\n",
      "For batch 17, vl_loss is    0.41.\n",
      "For batch 18, vl_loss is    0.41.\n",
      "For batch 19, vl_loss is    0.41.\n",
      "For batch 20, vl_loss is    0.40.\n",
      "For batch 21, vl_loss is    0.40.\n",
      "For batch 22, vl_loss is    0.40.\n",
      "For batch 23, vl_loss is    0.40.\n",
      "For batch 24, vl_loss is    0.40.\n",
      "For batch 25, vl_loss is    0.40.\n",
      "For batch 26, vl_loss is    0.39.\n",
      "For batch 27, vl_loss is    0.40.\n",
      "For batch 28, vl_loss is    0.40.\n",
      "For batch 29, vl_loss is    0.40.\n",
      "For batch 30, vl_loss is    0.40.\n",
      "For batch 31, vl_loss is    0.40.\n",
      "For batch 32, vl_loss is    0.40.\n",
      "For batch 33, vl_loss is    0.40.\n",
      "For batch 34, vl_loss is    0.40.\n",
      "For batch 35, vl_loss is    0.40.\n",
      "For batch 36, vl_loss is    0.40.\n",
      "For batch 37, vl_loss is    0.40.\n",
      "For batch 38, vl_loss is    0.40.\n",
      "For batch 39, vl_loss is    0.40.\n",
      "For batch 40, vl_loss is    0.40.\n",
      "For batch 41, vl_loss is    0.41.\n",
      "For batch 42, vl_loss is    0.41.\n",
      "For batch 43, vl_loss is    0.41.\n",
      "For batch 44, vl_loss is    0.41.\n",
      "For batch 45, vl_loss is    0.41.\n",
      "For batch 46, vl_loss is    0.41.\n",
      "For batch 47, vl_loss is    0.41.\n",
      "For batch 48, vl_loss is    0.41.\n",
      "For batch 49, vl_loss is    0.41.\n",
      "For batch 50, vl_loss is    0.41.\n",
      "For batch 51, vl_loss is    0.41.\n",
      "For batch 52, vl_loss is    0.41.\n",
      "For batch 53, vl_loss is    0.41.\n",
      "For batch 54, vl_loss is    0.41.\n",
      "For batch 55, vl_loss is    0.41.\n",
      "For batch 56, vl_loss is    0.41.\n",
      "For batch 57, vl_loss is    0.41.\n",
      "For batch 58, vl_loss is    0.41.\n",
      "For batch 59, vl_loss is    0.41.\n",
      "For batch 60, vl_loss is    0.41.\n",
      "For batch 61, vl_loss is    0.41.\n",
      "For batch 62, vl_loss is    0.40.\n",
      "For batch 63, vl_loss is    0.40.\n",
      "For batch 64, vl_loss is    0.40.\n",
      "For batch 65, vl_loss is    0.40.\n",
      "For batch 66, vl_loss is    0.40.\n",
      "For batch 67, vl_loss is    0.40.\n",
      "232/232 [==============================] - 212s 906ms/step - loss: 0.2306 - iou_score: 0.7442 - f1-score: 0.8517 - val_loss: 0.4036 - val_iou_score: 0.6097 - val_f1-score: 0.7549\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.36098\n",
      "The average loss for epoch 16 is    0.23 \n",
      "Epoch 18/200\n",
      "  1/232 [..............................] - ETA: 10:05 - loss: 0.1872 - iou_score: 0.7875 - f1-score: 0.8794For batch 0, tr_loss is    0.19.\n",
      "  2/232 [..............................] - ETA: 4:03 - loss: 0.1872 - iou_score: 0.7915 - f1-score: 0.8827 For batch 1, tr_loss is    0.19.\n",
      "  3/232 [..............................] - ETA: 4:32 - loss: 0.2163 - iou_score: 0.7560 - f1-score: 0.8593For batch 2, tr_loss is    0.22.\n",
      "  4/232 [..............................] - ETA: 4:50 - loss: 0.2172 - iou_score: 0.7603 - f1-score: 0.8624For batch 3, tr_loss is    0.22.\n",
      "  5/232 [..............................] - ETA: 4:22 - loss: 0.2292 - iou_score: 0.7500 - f1-score: 0.8556For batch 4, tr_loss is    0.23.\n",
      "  6/232 [..............................] - ETA: 4:31 - loss: 0.2378 - iou_score: 0.7367 - f1-score: 0.8464For batch 5, tr_loss is    0.24.\n",
      "  7/232 [..............................] - ETA: 4:32 - loss: 0.2431 - iou_score: 0.7274 - f1-score: 0.8403For batch 6, tr_loss is    0.24.\n",
      "  8/232 [>.............................] - ETA: 4:27 - loss: 0.2486 - iou_score: 0.7203 - f1-score: 0.8357For batch 7, tr_loss is    0.25.\n",
      "  9/232 [>.............................] - ETA: 4:41 - loss: 0.2390 - iou_score: 0.7325 - f1-score: 0.8436For batch 8, tr_loss is    0.24.\n",
      " 10/232 [>.............................] - ETA: 4:34 - loss: 0.2394 - iou_score: 0.7305 - f1-score: 0.8423For batch 9, tr_loss is    0.24.\n",
      " 11/232 [>.............................] - ETA: 4:24 - loss: 0.2376 - iou_score: 0.7324 - f1-score: 0.8437For batch 10, tr_loss is    0.24.\n",
      " 12/232 [>.............................] - ETA: 4:19 - loss: 0.2337 - iou_score: 0.7390 - f1-score: 0.8481For batch 11, tr_loss is    0.23.\n",
      " 13/232 [>.............................] - ETA: 4:04 - loss: 0.2318 - iou_score: 0.7413 - f1-score: 0.8495For batch 12, tr_loss is    0.23.\n",
      " 14/232 [>.............................] - ETA: 3:58 - loss: 0.2287 - iou_score: 0.7450 - f1-score: 0.8521For batch 13, tr_loss is    0.23.\n",
      " 15/232 [>.............................] - ETA: 3:51 - loss: 0.2255 - iou_score: 0.7487 - f1-score: 0.8545For batch 14, tr_loss is    0.23.\n",
      " 16/232 [=>............................] - ETA: 3:49 - loss: 0.2233 - iou_score: 0.7508 - f1-score: 0.8560For batch 15, tr_loss is    0.22.\n",
      " 17/232 [=>............................] - ETA: 3:39 - loss: 0.2214 - iou_score: 0.7539 - f1-score: 0.8580For batch 16, tr_loss is    0.22.\n",
      " 18/232 [=>............................] - ETA: 3:39 - loss: 0.2220 - iou_score: 0.7530 - f1-score: 0.8575For batch 17, tr_loss is    0.22.\n",
      " 19/232 [=>............................] - ETA: 3:38 - loss: 0.2236 - iou_score: 0.7504 - f1-score: 0.8558For batch 18, tr_loss is    0.22.\n",
      " 20/232 [=>............................] - ETA: 3:34 - loss: 0.2217 - iou_score: 0.7530 - f1-score: 0.8576For batch 19, tr_loss is    0.22.\n",
      " 21/232 [=>............................] - ETA: 3:33 - loss: 0.2242 - iou_score: 0.7508 - f1-score: 0.8560For batch 20, tr_loss is    0.22.\n",
      " 22/232 [=>............................] - ETA: 3:27 - loss: 0.2256 - iou_score: 0.7479 - f1-score: 0.8540For batch 21, tr_loss is    0.23.\n",
      " 23/232 [=>............................] - ETA: 3:23 - loss: 0.2260 - iou_score: 0.7476 - f1-score: 0.8538For batch 22, tr_loss is    0.23.\n",
      " 24/232 [==>...........................] - ETA: 3:20 - loss: 0.2255 - iou_score: 0.7483 - f1-score: 0.8544For batch 23, tr_loss is    0.23.\n",
      " 25/232 [==>...........................] - ETA: 3:17 - loss: 0.2292 - iou_score: 0.7438 - f1-score: 0.8513For batch 24, tr_loss is    0.23.\n",
      " 26/232 [==>...........................] - ETA: 3:17 - loss: 0.2298 - iou_score: 0.7431 - f1-score: 0.8508For batch 25, tr_loss is    0.23.\n",
      " 27/232 [==>...........................] - ETA: 3:16 - loss: 0.2276 - iou_score: 0.7460 - f1-score: 0.8527For batch 26, tr_loss is    0.23.\n",
      " 28/232 [==>...........................] - ETA: 3:16 - loss: 0.2277 - iou_score: 0.7465 - f1-score: 0.8530For batch 27, tr_loss is    0.23.\n",
      " 29/232 [==>...........................] - ETA: 3:13 - loss: 0.2256 - iou_score: 0.7481 - f1-score: 0.8540For batch 28, tr_loss is    0.23.\n",
      " 30/232 [==>...........................] - ETA: 3:13 - loss: 0.2235 - iou_score: 0.7509 - f1-score: 0.8558For batch 29, tr_loss is    0.22.\n",
      " 31/232 [===>..........................] - ETA: 3:11 - loss: 0.2224 - iou_score: 0.7521 - f1-score: 0.8567For batch 30, tr_loss is    0.22.\n",
      " 32/232 [===>..........................] - ETA: 3:10 - loss: 0.2222 - iou_score: 0.7524 - f1-score: 0.8569For batch 31, tr_loss is    0.22.\n",
      " 33/232 [===>..........................] - ETA: 3:06 - loss: 0.2245 - iou_score: 0.7499 - f1-score: 0.8552For batch 32, tr_loss is    0.22.\n",
      " 34/232 [===>..........................] - ETA: 3:06 - loss: 0.2245 - iou_score: 0.7503 - f1-score: 0.8555For batch 33, tr_loss is    0.22.\n",
      " 35/232 [===>..........................] - ETA: 3:04 - loss: 0.2269 - iou_score: 0.7478 - f1-score: 0.8539For batch 34, tr_loss is    0.23.\n",
      " 36/232 [===>..........................] - ETA: 3:04 - loss: 0.2266 - iou_score: 0.7485 - f1-score: 0.8544For batch 35, tr_loss is    0.23.\n",
      " 37/232 [===>..........................] - ETA: 3:03 - loss: 0.2266 - iou_score: 0.7481 - f1-score: 0.8541For batch 36, tr_loss is    0.23.\n",
      " 38/232 [===>..........................] - ETA: 3:02 - loss: 0.2286 - iou_score: 0.7472 - f1-score: 0.8535For batch 37, tr_loss is    0.23.\n",
      " 39/232 [====>.........................] - ETA: 2:59 - loss: 0.2315 - iou_score: 0.7437 - f1-score: 0.8511For batch 38, tr_loss is    0.23.\n",
      " 40/232 [====>.........................] - ETA: 2:59 - loss: 0.2304 - iou_score: 0.7449 - f1-score: 0.8519For batch 39, tr_loss is    0.23.\n",
      " 41/232 [====>.........................] - ETA: 2:56 - loss: 0.2312 - iou_score: 0.7438 - f1-score: 0.8512For batch 40, tr_loss is    0.23.\n",
      " 42/232 [====>.........................] - ETA: 2:55 - loss: 0.2314 - iou_score: 0.7430 - f1-score: 0.8507For batch 41, tr_loss is    0.23.\n",
      " 43/232 [====>.........................] - ETA: 2:55 - loss: 0.2307 - iou_score: 0.7437 - f1-score: 0.8512For batch 42, tr_loss is    0.23.\n",
      " 44/232 [====>.........................] - ETA: 2:54 - loss: 0.2333 - iou_score: 0.7417 - f1-score: 0.8497For batch 43, tr_loss is    0.23.\n",
      " 45/232 [====>.........................] - ETA: 2:54 - loss: 0.2342 - iou_score: 0.7409 - f1-score: 0.8492For batch 44, tr_loss is    0.23.\n",
      " 46/232 [====>.........................] - ETA: 2:53 - loss: 0.2341 - iou_score: 0.7412 - f1-score: 0.8494For batch 45, tr_loss is    0.23.\n",
      " 47/232 [=====>........................] - ETA: 2:51 - loss: 0.2335 - iou_score: 0.7419 - f1-score: 0.8499For batch 46, tr_loss is    0.23.\n",
      " 48/232 [=====>........................] - ETA: 2:49 - loss: 0.2323 - iou_score: 0.7433 - f1-score: 0.8508For batch 47, tr_loss is    0.23.\n",
      " 49/232 [=====>........................] - ETA: 2:49 - loss: 0.2327 - iou_score: 0.7430 - f1-score: 0.8506For batch 48, tr_loss is    0.23.\n",
      " 50/232 [=====>........................] - ETA: 2:48 - loss: 0.2322 - iou_score: 0.7434 - f1-score: 0.8509For batch 49, tr_loss is    0.23.\n",
      " 51/232 [=====>........................] - ETA: 2:47 - loss: 0.2340 - iou_score: 0.7423 - f1-score: 0.8502For batch 50, tr_loss is    0.23.\n",
      " 52/232 [=====>........................] - ETA: 2:47 - loss: 0.2359 - iou_score: 0.7408 - f1-score: 0.8492For batch 51, tr_loss is    0.24.\n",
      " 53/232 [=====>........................] - ETA: 2:44 - loss: 0.2352 - iou_score: 0.7418 - f1-score: 0.8498For batch 52, tr_loss is    0.24.\n",
      " 54/232 [=====>........................] - ETA: 2:43 - loss: 0.2353 - iou_score: 0.7415 - f1-score: 0.8497For batch 53, tr_loss is    0.24.\n",
      " 55/232 [======>.......................] - ETA: 2:43 - loss: 0.2346 - iou_score: 0.7422 - f1-score: 0.8501For batch 54, tr_loss is    0.23.\n",
      " 56/232 [======>.......................] - ETA: 2:41 - loss: 0.2344 - iou_score: 0.7423 - f1-score: 0.8502For batch 55, tr_loss is    0.23.\n",
      " 57/232 [======>.......................] - ETA: 2:39 - loss: 0.2348 - iou_score: 0.7416 - f1-score: 0.8498For batch 56, tr_loss is    0.23.\n",
      " 58/232 [======>.......................] - ETA: 2:39 - loss: 0.2343 - iou_score: 0.7423 - f1-score: 0.8502For batch 57, tr_loss is    0.23.\n",
      " 59/232 [======>.......................] - ETA: 2:38 - loss: 0.2337 - iou_score: 0.7428 - f1-score: 0.8506For batch 58, tr_loss is    0.23.\n",
      " 60/232 [======>.......................] - ETA: 2:37 - loss: 0.2347 - iou_score: 0.7415 - f1-score: 0.8497For batch 59, tr_loss is    0.23.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 61/232 [======>.......................] - ETA: 2:36 - loss: 0.2365 - iou_score: 0.7400 - f1-score: 0.8486For batch 60, tr_loss is    0.24.\n",
      " 62/232 [=======>......................] - ETA: 2:36 - loss: 0.2371 - iou_score: 0.7390 - f1-score: 0.8479For batch 61, tr_loss is    0.24.\n",
      " 63/232 [=======>......................] - ETA: 2:35 - loss: 0.2365 - iou_score: 0.7396 - f1-score: 0.8483For batch 62, tr_loss is    0.24.\n",
      " 64/232 [=======>......................] - ETA: 2:34 - loss: 0.2365 - iou_score: 0.7396 - f1-score: 0.8483For batch 63, tr_loss is    0.24.\n",
      " 65/232 [=======>......................] - ETA: 2:33 - loss: 0.2368 - iou_score: 0.7396 - f1-score: 0.8483For batch 64, tr_loss is    0.24.\n",
      " 66/232 [=======>......................] - ETA: 2:32 - loss: 0.2365 - iou_score: 0.7398 - f1-score: 0.8485For batch 65, tr_loss is    0.24.\n",
      " 67/232 [=======>......................] - ETA: 2:32 - loss: 0.2360 - iou_score: 0.7404 - f1-score: 0.8489For batch 66, tr_loss is    0.24.\n",
      " 68/232 [=======>......................] - ETA: 2:31 - loss: 0.2357 - iou_score: 0.7409 - f1-score: 0.8492For batch 67, tr_loss is    0.24.\n",
      " 69/232 [=======>......................] - ETA: 2:29 - loss: 0.2358 - iou_score: 0.7410 - f1-score: 0.8493For batch 68, tr_loss is    0.24.\n",
      " 70/232 [========>.....................] - ETA: 2:29 - loss: 0.2356 - iou_score: 0.7412 - f1-score: 0.8495For batch 69, tr_loss is    0.24.\n",
      " 71/232 [========>.....................] - ETA: 2:28 - loss: 0.2348 - iou_score: 0.7423 - f1-score: 0.8502For batch 70, tr_loss is    0.23.\n",
      " 72/232 [========>.....................] - ETA: 2:26 - loss: 0.2342 - iou_score: 0.7429 - f1-score: 0.8506For batch 71, tr_loss is    0.23.\n",
      " 73/232 [========>.....................] - ETA: 2:25 - loss: 0.2343 - iou_score: 0.7424 - f1-score: 0.8503For batch 72, tr_loss is    0.23.\n",
      " 74/232 [========>.....................] - ETA: 2:23 - loss: 0.2337 - iou_score: 0.7431 - f1-score: 0.8508For batch 73, tr_loss is    0.23.\n",
      " 75/232 [========>.....................] - ETA: 2:22 - loss: 0.2336 - iou_score: 0.7432 - f1-score: 0.8508For batch 74, tr_loss is    0.23.\n",
      " 76/232 [========>.....................] - ETA: 2:21 - loss: 0.2331 - iou_score: 0.7436 - f1-score: 0.8511For batch 75, tr_loss is    0.23.\n",
      " 77/232 [========>.....................] - ETA: 2:19 - loss: 0.2326 - iou_score: 0.7442 - f1-score: 0.8515For batch 76, tr_loss is    0.23.\n",
      " 78/232 [=========>....................] - ETA: 2:18 - loss: 0.2328 - iou_score: 0.7439 - f1-score: 0.8513For batch 77, tr_loss is    0.23.\n",
      " 79/232 [=========>....................] - ETA: 2:18 - loss: 0.2323 - iou_score: 0.7446 - f1-score: 0.8518For batch 78, tr_loss is    0.23.\n",
      " 80/232 [=========>....................] - ETA: 2:17 - loss: 0.2321 - iou_score: 0.7447 - f1-score: 0.8518For batch 79, tr_loss is    0.23.\n",
      " 81/232 [=========>....................] - ETA: 2:16 - loss: 0.2323 - iou_score: 0.7445 - f1-score: 0.8517For batch 80, tr_loss is    0.23.\n",
      " 82/232 [=========>....................] - ETA: 2:16 - loss: 0.2322 - iou_score: 0.7444 - f1-score: 0.8517For batch 81, tr_loss is    0.23.\n",
      " 83/232 [=========>....................] - ETA: 2:15 - loss: 0.2327 - iou_score: 0.7436 - f1-score: 0.8512For batch 82, tr_loss is    0.23.\n",
      " 84/232 [=========>....................] - ETA: 2:13 - loss: 0.2332 - iou_score: 0.7432 - f1-score: 0.8509For batch 83, tr_loss is    0.23.\n",
      " 85/232 [=========>....................] - ETA: 2:12 - loss: 0.2335 - iou_score: 0.7430 - f1-score: 0.8508For batch 84, tr_loss is    0.23.\n",
      " 86/232 [==========>...................] - ETA: 2:12 - loss: 0.2341 - iou_score: 0.7422 - f1-score: 0.8503For batch 85, tr_loss is    0.23.\n",
      " 87/232 [==========>...................] - ETA: 2:11 - loss: 0.2337 - iou_score: 0.7428 - f1-score: 0.8506For batch 86, tr_loss is    0.23.\n",
      " 88/232 [==========>...................] - ETA: 2:09 - loss: 0.2339 - iou_score: 0.7423 - f1-score: 0.8504For batch 87, tr_loss is    0.23.\n",
      " 89/232 [==========>...................] - ETA: 2:08 - loss: 0.2334 - iou_score: 0.7429 - f1-score: 0.8507For batch 88, tr_loss is    0.23.\n",
      " 90/232 [==========>...................] - ETA: 2:08 - loss: 0.2329 - iou_score: 0.7433 - f1-score: 0.8511For batch 89, tr_loss is    0.23.\n",
      " 91/232 [==========>...................] - ETA: 2:07 - loss: 0.2327 - iou_score: 0.7435 - f1-score: 0.8511For batch 90, tr_loss is    0.23.\n",
      " 92/232 [==========>...................] - ETA: 2:06 - loss: 0.2327 - iou_score: 0.7435 - f1-score: 0.8511For batch 91, tr_loss is    0.23.\n",
      " 93/232 [===========>..................] - ETA: 2:05 - loss: 0.2331 - iou_score: 0.7428 - f1-score: 0.8506For batch 92, tr_loss is    0.23.\n",
      " 94/232 [===========>..................] - ETA: 2:04 - loss: 0.2327 - iou_score: 0.7431 - f1-score: 0.8509For batch 93, tr_loss is    0.23.\n",
      " 95/232 [===========>..................] - ETA: 2:02 - loss: 0.2332 - iou_score: 0.7425 - f1-score: 0.8505For batch 94, tr_loss is    0.23.\n",
      " 96/232 [===========>..................] - ETA: 2:02 - loss: 0.2331 - iou_score: 0.7427 - f1-score: 0.8506For batch 95, tr_loss is    0.23.\n",
      " 97/232 [===========>..................] - ETA: 2:01 - loss: 0.2334 - iou_score: 0.7424 - f1-score: 0.8505For batch 96, tr_loss is    0.23.\n",
      " 98/232 [===========>..................] - ETA: 2:00 - loss: 0.2333 - iou_score: 0.7425 - f1-score: 0.8505For batch 97, tr_loss is    0.23.\n",
      " 99/232 [===========>..................] - ETA: 1:59 - loss: 0.2326 - iou_score: 0.7434 - f1-score: 0.8511For batch 98, tr_loss is    0.23.\n",
      "100/232 [===========>..................] - ETA: 1:58 - loss: 0.2323 - iou_score: 0.7438 - f1-score: 0.8514For batch 99, tr_loss is    0.23.\n",
      "101/232 [============>.................] - ETA: 1:57 - loss: 0.2317 - iou_score: 0.7446 - f1-score: 0.8519For batch 100, tr_loss is    0.23.\n",
      "102/232 [============>.................] - ETA: 1:56 - loss: 0.2319 - iou_score: 0.7447 - f1-score: 0.8519For batch 101, tr_loss is    0.23.\n",
      "103/232 [============>.................] - ETA: 1:55 - loss: 0.2318 - iou_score: 0.7447 - f1-score: 0.8519For batch 102, tr_loss is    0.23.\n",
      "104/232 [============>.................] - ETA: 1:54 - loss: 0.2316 - iou_score: 0.7448 - f1-score: 0.8520For batch 103, tr_loss is    0.23.\n",
      "105/232 [============>.................] - ETA: 1:53 - loss: 0.2310 - iou_score: 0.7455 - f1-score: 0.8525For batch 104, tr_loss is    0.23.\n",
      "106/232 [============>.................] - ETA: 1:52 - loss: 0.2302 - iou_score: 0.7465 - f1-score: 0.8531For batch 105, tr_loss is    0.23.\n",
      "107/232 [============>.................] - ETA: 1:51 - loss: 0.2306 - iou_score: 0.7462 - f1-score: 0.8529For batch 106, tr_loss is    0.23.\n",
      "108/232 [============>.................] - ETA: 1:51 - loss: 0.2311 - iou_score: 0.7454 - f1-score: 0.8524For batch 107, tr_loss is    0.23.\n",
      "109/232 [=============>................] - ETA: 1:49 - loss: 0.2306 - iou_score: 0.7459 - f1-score: 0.8527For batch 108, tr_loss is    0.23.\n",
      "110/232 [=============>................] - ETA: 1:49 - loss: 0.2299 - iou_score: 0.7470 - f1-score: 0.8534For batch 109, tr_loss is    0.23.\n",
      "111/232 [=============>................] - ETA: 1:48 - loss: 0.2298 - iou_score: 0.7469 - f1-score: 0.8533For batch 110, tr_loss is    0.23.\n",
      "112/232 [=============>................] - ETA: 1:47 - loss: 0.2298 - iou_score: 0.7469 - f1-score: 0.8534For batch 111, tr_loss is    0.23.\n",
      "113/232 [=============>................] - ETA: 1:46 - loss: 0.2302 - iou_score: 0.7465 - f1-score: 0.8531For batch 112, tr_loss is    0.23.\n",
      "114/232 [=============>................] - ETA: 1:45 - loss: 0.2296 - iou_score: 0.7472 - f1-score: 0.8536For batch 113, tr_loss is    0.23.\n",
      "115/232 [=============>................] - ETA: 1:44 - loss: 0.2292 - iou_score: 0.7476 - f1-score: 0.8538For batch 114, tr_loss is    0.23.\n",
      "116/232 [==============>...............] - ETA: 1:43 - loss: 0.2288 - iou_score: 0.7481 - f1-score: 0.8541For batch 115, tr_loss is    0.23.\n",
      "117/232 [==============>...............] - ETA: 1:42 - loss: 0.2287 - iou_score: 0.7481 - f1-score: 0.8542For batch 116, tr_loss is    0.23.\n",
      "118/232 [==============>...............] - ETA: 1:41 - loss: 0.2283 - iou_score: 0.7488 - f1-score: 0.8546For batch 117, tr_loss is    0.23.\n",
      "119/232 [==============>...............] - ETA: 1:40 - loss: 0.2282 - iou_score: 0.7490 - f1-score: 0.8547For batch 118, tr_loss is    0.23.\n",
      "120/232 [==============>...............] - ETA: 1:40 - loss: 0.2285 - iou_score: 0.7487 - f1-score: 0.8545For batch 119, tr_loss is    0.23.\n",
      "121/232 [==============>...............] - ETA: 1:39 - loss: 0.2280 - iou_score: 0.7491 - f1-score: 0.8548For batch 120, tr_loss is    0.23.\n",
      "122/232 [==============>...............] - ETA: 1:38 - loss: 0.2284 - iou_score: 0.7485 - f1-score: 0.8544For batch 121, tr_loss is    0.23.\n",
      "123/232 [==============>...............] - ETA: 1:37 - loss: 0.2281 - iou_score: 0.7489 - f1-score: 0.8546For batch 122, tr_loss is    0.23.\n",
      "124/232 [===============>..............] - ETA: 1:36 - loss: 0.2282 - iou_score: 0.7487 - f1-score: 0.8545For batch 123, tr_loss is    0.23.\n",
      "125/232 [===============>..............] - ETA: 1:35 - loss: 0.2285 - iou_score: 0.7483 - f1-score: 0.8543For batch 124, tr_loss is    0.23.\n",
      "126/232 [===============>..............] - ETA: 1:34 - loss: 0.2283 - iou_score: 0.7485 - f1-score: 0.8544For batch 125, tr_loss is    0.23.\n",
      "127/232 [===============>..............] - ETA: 1:33 - loss: 0.2281 - iou_score: 0.7488 - f1-score: 0.8546For batch 126, tr_loss is    0.23.\n",
      "128/232 [===============>..............] - ETA: 1:32 - loss: 0.2280 - iou_score: 0.7486 - f1-score: 0.8545For batch 127, tr_loss is    0.23.\n",
      "129/232 [===============>..............] - ETA: 1:31 - loss: 0.2280 - iou_score: 0.7484 - f1-score: 0.8544For batch 128, tr_loss is    0.23.\n",
      "130/232 [===============>..............] - ETA: 1:30 - loss: 0.2277 - iou_score: 0.7489 - f1-score: 0.8547For batch 129, tr_loss is    0.23.\n",
      "131/232 [===============>..............] - ETA: 1:29 - loss: 0.2282 - iou_score: 0.7483 - f1-score: 0.8543For batch 130, tr_loss is    0.23.\n",
      "132/232 [================>.............] - ETA: 1:28 - loss: 0.2284 - iou_score: 0.7480 - f1-score: 0.8541For batch 131, tr_loss is    0.23.\n",
      "133/232 [================>.............] - ETA: 1:27 - loss: 0.2282 - iou_score: 0.7482 - f1-score: 0.8542For batch 132, tr_loss is    0.23.\n",
      "134/232 [================>.............] - ETA: 1:26 - loss: 0.2286 - iou_score: 0.7478 - f1-score: 0.8540For batch 133, tr_loss is    0.23.\n",
      "135/232 [================>.............] - ETA: 1:25 - loss: 0.2281 - iou_score: 0.7483 - f1-score: 0.8543For batch 134, tr_loss is    0.23.\n",
      "136/232 [================>.............] - ETA: 1:24 - loss: 0.2284 - iou_score: 0.7479 - f1-score: 0.8540For batch 135, tr_loss is    0.23.\n",
      "137/232 [================>.............] - ETA: 1:23 - loss: 0.2286 - iou_score: 0.7476 - f1-score: 0.8538For batch 136, tr_loss is    0.23.\n",
      "138/232 [================>.............] - ETA: 1:22 - loss: 0.2287 - iou_score: 0.7475 - f1-score: 0.8538For batch 137, tr_loss is    0.23.\n",
      "139/232 [================>.............] - ETA: 1:21 - loss: 0.2286 - iou_score: 0.7476 - f1-score: 0.8539For batch 138, tr_loss is    0.23.\n",
      "140/232 [=================>............] - ETA: 1:20 - loss: 0.2284 - iou_score: 0.7478 - f1-score: 0.8540For batch 139, tr_loss is    0.23.\n",
      "141/232 [=================>............] - ETA: 1:20 - loss: 0.2290 - iou_score: 0.7469 - f1-score: 0.8534For batch 140, tr_loss is    0.23.\n",
      "142/232 [=================>............] - ETA: 1:18 - loss: 0.2291 - iou_score: 0.7468 - f1-score: 0.8533For batch 141, tr_loss is    0.23.\n",
      "143/232 [=================>............] - ETA: 1:18 - loss: 0.2288 - iou_score: 0.7470 - f1-score: 0.8534For batch 142, tr_loss is    0.23.\n",
      "144/232 [=================>............] - ETA: 1:17 - loss: 0.2288 - iou_score: 0.7469 - f1-score: 0.8534For batch 143, tr_loss is    0.23.\n",
      "145/232 [=================>............] - ETA: 1:16 - loss: 0.2287 - iou_score: 0.7469 - f1-score: 0.8534For batch 144, tr_loss is    0.23.\n",
      "146/232 [=================>............] - ETA: 1:15 - loss: 0.2290 - iou_score: 0.7464 - f1-score: 0.8531For batch 145, tr_loss is    0.23.\n",
      "147/232 [==================>...........] - ETA: 1:14 - loss: 0.2287 - iou_score: 0.7468 - f1-score: 0.8533For batch 146, tr_loss is    0.23.\n",
      "148/232 [==================>...........] - ETA: 1:13 - loss: 0.2290 - iou_score: 0.7463 - f1-score: 0.8530For batch 147, tr_loss is    0.23.\n",
      "149/232 [==================>...........] - ETA: 1:13 - loss: 0.2290 - iou_score: 0.7463 - f1-score: 0.8530For batch 148, tr_loss is    0.23.\n",
      "150/232 [==================>...........] - ETA: 1:11 - loss: 0.2294 - iou_score: 0.7457 - f1-score: 0.8526For batch 149, tr_loss is    0.23.\n",
      "151/232 [==================>...........] - ETA: 1:11 - loss: 0.2296 - iou_score: 0.7454 - f1-score: 0.8524For batch 150, tr_loss is    0.23.\n",
      "152/232 [==================>...........] - ETA: 1:10 - loss: 0.2293 - iou_score: 0.7458 - f1-score: 0.8526For batch 151, tr_loss is    0.23.\n",
      "153/232 [==================>...........] - ETA: 1:09 - loss: 0.2292 - iou_score: 0.7458 - f1-score: 0.8526For batch 152, tr_loss is    0.23.\n",
      "154/232 [==================>...........] - ETA: 1:08 - loss: 0.2290 - iou_score: 0.7460 - f1-score: 0.8528For batch 153, tr_loss is    0.23.\n",
      "155/232 [===================>..........] - ETA: 1:07 - loss: 0.2290 - iou_score: 0.7461 - f1-score: 0.8528For batch 154, tr_loss is    0.23.\n",
      "156/232 [===================>..........] - ETA: 1:06 - loss: 0.2290 - iou_score: 0.7460 - f1-score: 0.8528For batch 155, tr_loss is    0.23.\n",
      "157/232 [===================>..........] - ETA: 1:06 - loss: 0.2292 - iou_score: 0.7458 - f1-score: 0.8526For batch 156, tr_loss is    0.23.\n",
      "158/232 [===================>..........] - ETA: 1:05 - loss: 0.2289 - iou_score: 0.7461 - f1-score: 0.8528For batch 157, tr_loss is    0.23.\n",
      "159/232 [===================>..........] - ETA: 1:04 - loss: 0.2287 - iou_score: 0.7464 - f1-score: 0.8531For batch 158, tr_loss is    0.23.\n",
      "160/232 [===================>..........] - ETA: 1:03 - loss: 0.2285 - iou_score: 0.7465 - f1-score: 0.8531For batch 159, tr_loss is    0.23.\n",
      "161/232 [===================>..........] - ETA: 1:02 - loss: 0.2281 - iou_score: 0.7470 - f1-score: 0.8534For batch 160, tr_loss is    0.23.\n",
      "162/232 [===================>..........] - ETA: 1:01 - loss: 0.2280 - iou_score: 0.7471 - f1-score: 0.8536For batch 161, tr_loss is    0.23.\n",
      "163/232 [====================>.........] - ETA: 1:00 - loss: 0.2277 - iou_score: 0.7475 - f1-score: 0.8538For batch 162, tr_loss is    0.23.\n",
      "164/232 [====================>.........] - ETA: 59s - loss: 0.2279 - iou_score: 0.7473 - f1-score: 0.8537 For batch 163, tr_loss is    0.23.\n",
      "165/232 [====================>.........] - ETA: 59s - loss: 0.2280 - iou_score: 0.7471 - f1-score: 0.8535For batch 164, tr_loss is    0.23.\n",
      "166/232 [====================>.........] - ETA: 58s - loss: 0.2277 - iou_score: 0.7473 - f1-score: 0.8537For batch 165, tr_loss is    0.23.\n",
      "167/232 [====================>.........] - ETA: 57s - loss: 0.2274 - iou_score: 0.7476 - f1-score: 0.8538For batch 166, tr_loss is    0.23.\n",
      "168/232 [====================>.........] - ETA: 56s - loss: 0.2277 - iou_score: 0.7474 - f1-score: 0.8538For batch 167, tr_loss is    0.23.\n",
      "169/232 [====================>.........] - ETA: 55s - loss: 0.2278 - iou_score: 0.7471 - f1-score: 0.8536For batch 168, tr_loss is    0.23.\n",
      "170/232 [====================>.........] - ETA: 54s - loss: 0.2278 - iou_score: 0.7471 - f1-score: 0.8536For batch 169, tr_loss is    0.23.\n",
      "171/232 [=====================>........] - ETA: 54s - loss: 0.2281 - iou_score: 0.7467 - f1-score: 0.8533For batch 170, tr_loss is    0.23.\n",
      "172/232 [=====================>........] - ETA: 53s - loss: 0.2282 - iou_score: 0.7466 - f1-score: 0.8532For batch 171, tr_loss is    0.23.\n",
      "173/232 [=====================>........] - ETA: 52s - loss: 0.2279 - iou_score: 0.7469 - f1-score: 0.8534For batch 172, tr_loss is    0.23.\n",
      "174/232 [=====================>........] - ETA: 51s - loss: 0.2277 - iou_score: 0.7471 - f1-score: 0.8536For batch 173, tr_loss is    0.23.\n",
      "175/232 [=====================>........] - ETA: 50s - loss: 0.2277 - iou_score: 0.7470 - f1-score: 0.8535For batch 174, tr_loss is    0.23.\n",
      "176/232 [=====================>........] - ETA: 49s - loss: 0.2279 - iou_score: 0.7467 - f1-score: 0.8533For batch 175, tr_loss is    0.23.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/232 [=====================>........] - ETA: 48s - loss: 0.2277 - iou_score: 0.7470 - f1-score: 0.8535For batch 176, tr_loss is    0.23.\n",
      "178/232 [======================>.......] - ETA: 47s - loss: 0.2276 - iou_score: 0.7472 - f1-score: 0.8536For batch 177, tr_loss is    0.23.\n",
      "179/232 [======================>.......] - ETA: 46s - loss: 0.2276 - iou_score: 0.7472 - f1-score: 0.8537For batch 178, tr_loss is    0.23.\n",
      "180/232 [======================>.......] - ETA: 46s - loss: 0.2276 - iou_score: 0.7471 - f1-score: 0.8536For batch 179, tr_loss is    0.23.\n",
      "181/232 [======================>.......] - ETA: 45s - loss: 0.2277 - iou_score: 0.7470 - f1-score: 0.8535For batch 180, tr_loss is    0.23.\n",
      "182/232 [======================>.......] - ETA: 44s - loss: 0.2278 - iou_score: 0.7468 - f1-score: 0.8534For batch 181, tr_loss is    0.23.\n",
      "183/232 [======================>.......] - ETA: 43s - loss: 0.2278 - iou_score: 0.7468 - f1-score: 0.8534For batch 182, tr_loss is    0.23.\n",
      "184/232 [======================>.......] - ETA: 42s - loss: 0.2274 - iou_score: 0.7473 - f1-score: 0.8537For batch 183, tr_loss is    0.23.\n",
      "185/232 [======================>.......] - ETA: 41s - loss: 0.2275 - iou_score: 0.7472 - f1-score: 0.8537For batch 184, tr_loss is    0.23.\n",
      "186/232 [=======================>......] - ETA: 40s - loss: 0.2275 - iou_score: 0.7472 - f1-score: 0.8537For batch 185, tr_loss is    0.23.\n",
      "187/232 [=======================>......] - ETA: 39s - loss: 0.2271 - iou_score: 0.7477 - f1-score: 0.8540For batch 186, tr_loss is    0.23.\n",
      "188/232 [=======================>......] - ETA: 39s - loss: 0.2271 - iou_score: 0.7476 - f1-score: 0.8539For batch 187, tr_loss is    0.23.\n",
      "189/232 [=======================>......] - ETA: 38s - loss: 0.2269 - iou_score: 0.7478 - f1-score: 0.8541For batch 188, tr_loss is    0.23.\n",
      "190/232 [=======================>......] - ETA: 37s - loss: 0.2268 - iou_score: 0.7479 - f1-score: 0.8541For batch 189, tr_loss is    0.23.\n",
      "191/232 [=======================>......] - ETA: 36s - loss: 0.2269 - iou_score: 0.7478 - f1-score: 0.8541For batch 190, tr_loss is    0.23.\n",
      "192/232 [=======================>......] - ETA: 35s - loss: 0.2271 - iou_score: 0.7476 - f1-score: 0.8539For batch 191, tr_loss is    0.23.\n",
      "193/232 [=======================>......] - ETA: 34s - loss: 0.2274 - iou_score: 0.7473 - f1-score: 0.8537For batch 192, tr_loss is    0.23.\n",
      "194/232 [========================>.....] - ETA: 33s - loss: 0.2274 - iou_score: 0.7473 - f1-score: 0.8537For batch 193, tr_loss is    0.23.\n",
      "195/232 [========================>.....] - ETA: 32s - loss: 0.2274 - iou_score: 0.7473 - f1-score: 0.8538For batch 194, tr_loss is    0.23.\n",
      "196/232 [========================>.....] - ETA: 31s - loss: 0.2272 - iou_score: 0.7475 - f1-score: 0.8539For batch 195, tr_loss is    0.23.\n",
      "197/232 [========================>.....] - ETA: 30s - loss: 0.2272 - iou_score: 0.7475 - f1-score: 0.8539For batch 196, tr_loss is    0.23.\n",
      "198/232 [========================>.....] - ETA: 29s - loss: 0.2269 - iou_score: 0.7480 - f1-score: 0.8542For batch 197, tr_loss is    0.23.\n",
      "199/232 [========================>.....] - ETA: 29s - loss: 0.2267 - iou_score: 0.7482 - f1-score: 0.8543For batch 198, tr_loss is    0.23.\n",
      "200/232 [========================>.....] - ETA: 28s - loss: 0.2264 - iou_score: 0.7485 - f1-score: 0.8545For batch 199, tr_loss is    0.23.\n",
      "201/232 [========================>.....] - ETA: 27s - loss: 0.2266 - iou_score: 0.7483 - f1-score: 0.8544For batch 200, tr_loss is    0.23.\n",
      "202/232 [=========================>....] - ETA: 26s - loss: 0.2264 - iou_score: 0.7484 - f1-score: 0.8545For batch 201, tr_loss is    0.23.\n",
      "203/232 [=========================>....] - ETA: 25s - loss: 0.2262 - iou_score: 0.7485 - f1-score: 0.8546For batch 202, tr_loss is    0.23.\n",
      "204/232 [=========================>....] - ETA: 24s - loss: 0.2259 - iou_score: 0.7489 - f1-score: 0.8548For batch 203, tr_loss is    0.23.\n",
      "205/232 [=========================>....] - ETA: 23s - loss: 0.2259 - iou_score: 0.7489 - f1-score: 0.8548For batch 204, tr_loss is    0.23.\n",
      "206/232 [=========================>....] - ETA: 23s - loss: 0.2261 - iou_score: 0.7486 - f1-score: 0.8546For batch 205, tr_loss is    0.23.\n",
      "207/232 [=========================>....] - ETA: 22s - loss: 0.2261 - iou_score: 0.7488 - f1-score: 0.8547For batch 206, tr_loss is    0.23.\n",
      "208/232 [=========================>....] - ETA: 21s - loss: 0.2260 - iou_score: 0.7489 - f1-score: 0.8548For batch 207, tr_loss is    0.23.\n",
      "209/232 [==========================>...] - ETA: 20s - loss: 0.2261 - iou_score: 0.7487 - f1-score: 0.8547For batch 208, tr_loss is    0.23.\n",
      "210/232 [==========================>...] - ETA: 19s - loss: 0.2264 - iou_score: 0.7484 - f1-score: 0.8545For batch 209, tr_loss is    0.23.\n",
      "211/232 [==========================>...] - ETA: 18s - loss: 0.2263 - iou_score: 0.7486 - f1-score: 0.8546For batch 210, tr_loss is    0.23.\n",
      "212/232 [==========================>...] - ETA: 17s - loss: 0.2260 - iou_score: 0.7488 - f1-score: 0.8547For batch 211, tr_loss is    0.23.\n",
      "213/232 [==========================>...] - ETA: 16s - loss: 0.2261 - iou_score: 0.7487 - f1-score: 0.8547For batch 212, tr_loss is    0.23.\n",
      "214/232 [==========================>...] - ETA: 15s - loss: 0.2260 - iou_score: 0.7488 - f1-score: 0.8548For batch 213, tr_loss is    0.23.\n",
      "215/232 [==========================>...] - ETA: 15s - loss: 0.2257 - iou_score: 0.7491 - f1-score: 0.8550For batch 214, tr_loss is    0.23.\n",
      "216/232 [==========================>...] - ETA: 14s - loss: 0.2256 - iou_score: 0.7493 - f1-score: 0.8551For batch 215, tr_loss is    0.23.\n",
      "217/232 [===========================>..] - ETA: 13s - loss: 0.2257 - iou_score: 0.7492 - f1-score: 0.8550For batch 216, tr_loss is    0.23.\n",
      "218/232 [===========================>..] - ETA: 12s - loss: 0.2257 - iou_score: 0.7492 - f1-score: 0.8550For batch 217, tr_loss is    0.23.\n",
      "219/232 [===========================>..] - ETA: 11s - loss: 0.2261 - iou_score: 0.7486 - f1-score: 0.8546For batch 218, tr_loss is    0.23.\n",
      "220/232 [===========================>..] - ETA: 10s - loss: 0.2262 - iou_score: 0.7485 - f1-score: 0.8545For batch 219, tr_loss is    0.23.\n",
      "221/232 [===========================>..] - ETA: 9s - loss: 0.2263 - iou_score: 0.7483 - f1-score: 0.8544 For batch 220, tr_loss is    0.23.\n",
      "222/232 [===========================>..] - ETA: 8s - loss: 0.2262 - iou_score: 0.7485 - f1-score: 0.8545For batch 221, tr_loss is    0.23.\n",
      "223/232 [===========================>..] - ETA: 7s - loss: 0.2263 - iou_score: 0.7483 - f1-score: 0.8544For batch 222, tr_loss is    0.23.\n",
      "224/232 [===========================>..] - ETA: 7s - loss: 0.2262 - iou_score: 0.7485 - f1-score: 0.8545For batch 223, tr_loss is    0.23.\n",
      "225/232 [============================>.] - ETA: 6s - loss: 0.2261 - iou_score: 0.7486 - f1-score: 0.8546For batch 224, tr_loss is    0.23.\n",
      "226/232 [============================>.] - ETA: 5s - loss: 0.2263 - iou_score: 0.7485 - f1-score: 0.8546For batch 225, tr_loss is    0.23.\n",
      "227/232 [============================>.] - ETA: 4s - loss: 0.2262 - iou_score: 0.7486 - f1-score: 0.8546For batch 226, tr_loss is    0.23.\n",
      "228/232 [============================>.] - ETA: 3s - loss: 0.2262 - iou_score: 0.7485 - f1-score: 0.8545For batch 227, tr_loss is    0.23.\n",
      "229/232 [============================>.] - ETA: 2s - loss: 0.2261 - iou_score: 0.7485 - f1-score: 0.8546For batch 228, tr_loss is    0.23.\n",
      "230/232 [============================>.] - ETA: 1s - loss: 0.2263 - iou_score: 0.7483 - f1-score: 0.8544For batch 229, tr_loss is    0.23.\n",
      "231/232 [============================>.] - ETA: 0s - loss: 0.2264 - iou_score: 0.7481 - f1-score: 0.8543For batch 230, tr_loss is    0.23.\n",
      "232/232 [==============================] - ETA: 0s - loss: 0.2262 - iou_score: 0.7483 - f1-score: 0.8545For batch 231, tr_loss is    0.23.\n",
      "For batch 0, vl_loss is    0.37.\n",
      "For batch 1, vl_loss is    0.34.\n",
      "For batch 2, vl_loss is    0.38.\n",
      "For batch 3, vl_loss is    0.38.\n",
      "For batch 4, vl_loss is    0.42.\n",
      "For batch 5, vl_loss is    0.40.\n",
      "For batch 6, vl_loss is    0.42.\n",
      "For batch 7, vl_loss is    0.42.\n",
      "For batch 8, vl_loss is    0.41.\n",
      "For batch 9, vl_loss is    0.40.\n",
      "For batch 10, vl_loss is    0.40.\n",
      "For batch 11, vl_loss is    0.41.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 12, vl_loss is    0.41.\n",
      "For batch 13, vl_loss is    0.42.\n",
      "For batch 14, vl_loss is    0.41.\n",
      "For batch 15, vl_loss is    0.40.\n",
      "For batch 16, vl_loss is    0.40.\n",
      "For batch 17, vl_loss is    0.40.\n",
      "For batch 18, vl_loss is    0.40.\n",
      "For batch 19, vl_loss is    0.40.\n",
      "For batch 20, vl_loss is    0.39.\n",
      "For batch 21, vl_loss is    0.40.\n",
      "For batch 22, vl_loss is    0.40.\n",
      "For batch 23, vl_loss is    0.40.\n",
      "For batch 24, vl_loss is    0.40.\n",
      "For batch 25, vl_loss is    0.39.\n",
      "For batch 26, vl_loss is    0.39.\n",
      "For batch 27, vl_loss is    0.40.\n",
      "For batch 28, vl_loss is    0.40.\n",
      "For batch 29, vl_loss is    0.40.\n",
      "For batch 30, vl_loss is    0.40.\n",
      "For batch 31, vl_loss is    0.40.\n",
      "For batch 32, vl_loss is    0.40.\n",
      "For batch 33, vl_loss is    0.40.\n",
      "For batch 34, vl_loss is    0.40.\n",
      "For batch 35, vl_loss is    0.40.\n",
      "For batch 36, vl_loss is    0.40.\n",
      "For batch 37, vl_loss is    0.40.\n",
      "For batch 38, vl_loss is    0.40.\n",
      "For batch 39, vl_loss is    0.40.\n",
      "For batch 40, vl_loss is    0.40.\n",
      "For batch 41, vl_loss is    0.41.\n",
      "For batch 42, vl_loss is    0.41.\n",
      "For batch 43, vl_loss is    0.41.\n",
      "For batch 44, vl_loss is    0.41.\n",
      "For batch 45, vl_loss is    0.41.\n",
      "For batch 46, vl_loss is    0.41.\n",
      "For batch 47, vl_loss is    0.41.\n",
      "For batch 48, vl_loss is    0.41.\n",
      "For batch 49, vl_loss is    0.41.\n",
      "For batch 50, vl_loss is    0.41.\n",
      "For batch 51, vl_loss is    0.41.\n",
      "For batch 52, vl_loss is    0.41.\n",
      "For batch 53, vl_loss is    0.41.\n",
      "For batch 54, vl_loss is    0.41.\n",
      "For batch 55, vl_loss is    0.41.\n",
      "For batch 56, vl_loss is    0.41.\n",
      "For batch 57, vl_loss is    0.41.\n",
      "For batch 58, vl_loss is    0.41.\n",
      "For batch 59, vl_loss is    0.41.\n",
      "For batch 60, vl_loss is    0.41.\n",
      "For batch 61, vl_loss is    0.41.\n",
      "For batch 62, vl_loss is    0.41.\n",
      "For batch 63, vl_loss is    0.41.\n",
      "For batch 64, vl_loss is    0.40.\n",
      "For batch 65, vl_loss is    0.40.\n",
      "For batch 66, vl_loss is    0.40.\n",
      "For batch 67, vl_loss is    0.40.\n",
      "232/232 [==============================] - 210s 896ms/step - loss: 0.2262 - iou_score: 0.7483 - f1-score: 0.8545 - val_loss: 0.4035 - val_iou_score: 0.6075 - val_f1-score: 0.7533\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.36098\n",
      "The average loss for epoch 17 is    0.23 \n",
      "Epoch 19/200\n",
      "  1/232 [..............................] - ETA: 10:02 - loss: 0.1883 - iou_score: 0.7927 - f1-score: 0.8826For batch 0, tr_loss is    0.19.\n",
      "  2/232 [..............................] - ETA: 5:16 - loss: 0.1886 - iou_score: 0.7918 - f1-score: 0.8830 For batch 1, tr_loss is    0.19.\n",
      "  3/232 [..............................] - ETA: 4:51 - loss: 0.2065 - iou_score: 0.7654 - f1-score: 0.8659For batch 2, tr_loss is    0.21.\n",
      "  4/232 [..............................] - ETA: 4:42 - loss: 0.2022 - iou_score: 0.7764 - f1-score: 0.8730For batch 3, tr_loss is    0.20.\n",
      "  5/232 [..............................] - ETA: 4:29 - loss: 0.2129 - iou_score: 0.7640 - f1-score: 0.8648For batch 4, tr_loss is    0.21.\n",
      "  6/232 [..............................] - ETA: 4:47 - loss: 0.2254 - iou_score: 0.7529 - f1-score: 0.8572For batch 5, tr_loss is    0.23.\n",
      "  7/232 [..............................] - ETA: 4:51 - loss: 0.2366 - iou_score: 0.7400 - f1-score: 0.8486For batch 6, tr_loss is    0.24.\n",
      "  8/232 [>.............................] - ETA: 4:45 - loss: 0.2390 - iou_score: 0.7352 - f1-score: 0.8456For batch 7, tr_loss is    0.24.\n",
      "  9/232 [>.............................] - ETA: 4:53 - loss: 0.2299 - iou_score: 0.7448 - f1-score: 0.8518For batch 8, tr_loss is    0.23.\n",
      " 10/232 [>.............................] - ETA: 4:45 - loss: 0.2292 - iou_score: 0.7442 - f1-score: 0.8514For batch 9, tr_loss is    0.23.\n",
      " 11/232 [>.............................] - ETA: 4:34 - loss: 0.2275 - iou_score: 0.7446 - f1-score: 0.8518For batch 10, tr_loss is    0.23.\n",
      " 12/232 [>.............................] - ETA: 4:28 - loss: 0.2224 - iou_score: 0.7507 - f1-score: 0.8558For batch 11, tr_loss is    0.22.\n",
      " 13/232 [>.............................] - ETA: 4:23 - loss: 0.2202 - iou_score: 0.7527 - f1-score: 0.8570For batch 12, tr_loss is    0.22.\n",
      " 14/232 [>.............................] - ETA: 4:19 - loss: 0.2169 - iou_score: 0.7570 - f1-score: 0.8599For batch 13, tr_loss is    0.22.\n",
      " 15/232 [>.............................] - ETA: 4:12 - loss: 0.2133 - iou_score: 0.7612 - f1-score: 0.8626For batch 14, tr_loss is    0.21.\n",
      " 16/232 [=>............................] - ETA: 4:08 - loss: 0.2112 - iou_score: 0.7627 - f1-score: 0.8637For batch 15, tr_loss is    0.21.\n",
      " 17/232 [=>............................] - ETA: 4:06 - loss: 0.2084 - iou_score: 0.7658 - f1-score: 0.8657For batch 16, tr_loss is    0.21.\n",
      " 18/232 [=>............................] - ETA: 4:03 - loss: 0.2102 - iou_score: 0.7642 - f1-score: 0.8648For batch 17, tr_loss is    0.21.\n",
      " 19/232 [=>............................] - ETA: 4:00 - loss: 0.2127 - iou_score: 0.7610 - f1-score: 0.8627For batch 18, tr_loss is    0.21.\n",
      " 20/232 [=>............................] - ETA: 3:54 - loss: 0.2112 - iou_score: 0.7630 - f1-score: 0.8640For batch 19, tr_loss is    0.21.\n",
      " 21/232 [=>............................] - ETA: 3:52 - loss: 0.2155 - iou_score: 0.7608 - f1-score: 0.8625For batch 20, tr_loss is    0.22.\n",
      " 22/232 [=>............................] - ETA: 3:45 - loss: 0.2170 - iou_score: 0.7591 - f1-score: 0.8614For batch 21, tr_loss is    0.22.\n",
      " 23/232 [=>............................] - ETA: 3:44 - loss: 0.2179 - iou_score: 0.7586 - f1-score: 0.8611For batch 22, tr_loss is    0.22.\n",
      " 24/232 [==>...........................] - ETA: 3:42 - loss: 0.2176 - iou_score: 0.7588 - f1-score: 0.8613For batch 23, tr_loss is    0.22.\n",
      " 25/232 [==>...........................] - ETA: 3:41 - loss: 0.2223 - iou_score: 0.7545 - f1-score: 0.8584For batch 24, tr_loss is    0.22.\n",
      " 26/232 [==>...........................] - ETA: 3:34 - loss: 0.2229 - iou_score: 0.7537 - f1-score: 0.8578For batch 25, tr_loss is    0.22.\n",
      " 27/232 [==>...........................] - ETA: 3:34 - loss: 0.2219 - iou_score: 0.7546 - f1-score: 0.8584For batch 26, tr_loss is    0.22.\n",
      " 28/232 [==>...........................] - ETA: 3:32 - loss: 0.2217 - iou_score: 0.7556 - f1-score: 0.8591For batch 27, tr_loss is    0.22.\n",
      " 29/232 [==>...........................] - ETA: 3:27 - loss: 0.2203 - iou_score: 0.7569 - f1-score: 0.8599For batch 28, tr_loss is    0.22.\n",
      " 30/232 [==>...........................] - ETA: 3:23 - loss: 0.2187 - iou_score: 0.7594 - f1-score: 0.8615For batch 29, tr_loss is    0.22.\n",
      " 31/232 [===>..........................] - ETA: 3:22 - loss: 0.2180 - iou_score: 0.7606 - f1-score: 0.8623For batch 30, tr_loss is    0.22.\n",
      " 32/232 [===>..........................] - ETA: 3:21 - loss: 0.2181 - iou_score: 0.7605 - f1-score: 0.8623For batch 31, tr_loss is    0.22.\n",
      " 33/232 [===>..........................] - ETA: 3:20 - loss: 0.2201 - iou_score: 0.7579 - f1-score: 0.8606For batch 32, tr_loss is    0.22.\n",
      " 34/232 [===>..........................] - ETA: 3:17 - loss: 0.2200 - iou_score: 0.7579 - f1-score: 0.8607For batch 33, tr_loss is    0.22.\n",
      " 35/232 [===>..........................] - ETA: 3:14 - loss: 0.2218 - iou_score: 0.7555 - f1-score: 0.8591For batch 34, tr_loss is    0.22.\n",
      " 36/232 [===>..........................] - ETA: 3:14 - loss: 0.2230 - iou_score: 0.7555 - f1-score: 0.8591For batch 35, tr_loss is    0.22.\n",
      " 37/232 [===>..........................] - ETA: 3:13 - loss: 0.2230 - iou_score: 0.7550 - f1-score: 0.8588For batch 36, tr_loss is    0.22.\n",
      " 38/232 [===>..........................] - ETA: 3:11 - loss: 0.2245 - iou_score: 0.7542 - f1-score: 0.8583For batch 37, tr_loss is    0.22.\n",
      " 39/232 [====>.........................] - ETA: 3:09 - loss: 0.2275 - iou_score: 0.7506 - f1-score: 0.8558For batch 38, tr_loss is    0.23.\n",
      " 40/232 [====>.........................] - ETA: 3:08 - loss: 0.2269 - iou_score: 0.7512 - f1-score: 0.8562For batch 39, tr_loss is    0.23.\n",
      " 41/232 [====>.........................] - ETA: 3:05 - loss: 0.2279 - iou_score: 0.7499 - f1-score: 0.8553For batch 40, tr_loss is    0.23.\n",
      " 42/232 [====>.........................] - ETA: 3:03 - loss: 0.2279 - iou_score: 0.7494 - f1-score: 0.8550For batch 41, tr_loss is    0.23.\n",
      " 43/232 [====>.........................] - ETA: 3:03 - loss: 0.2273 - iou_score: 0.7499 - f1-score: 0.8554For batch 42, tr_loss is    0.23.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 44/232 [====>.........................] - ETA: 3:02 - loss: 0.2302 - iou_score: 0.7471 - f1-score: 0.8534For batch 43, tr_loss is    0.23.\n",
      " 45/232 [====>.........................] - ETA: 3:00 - loss: 0.2306 - iou_score: 0.7464 - f1-score: 0.8529For batch 44, tr_loss is    0.23.\n",
      " 46/232 [====>.........................] - ETA: 3:00 - loss: 0.2308 - iou_score: 0.7457 - f1-score: 0.8525For batch 45, tr_loss is    0.23.\n",
      " 47/232 [=====>........................] - ETA: 2:59 - loss: 0.2304 - iou_score: 0.7462 - f1-score: 0.8528For batch 46, tr_loss is    0.23.\n",
      " 48/232 [=====>........................] - ETA: 2:56 - loss: 0.2294 - iou_score: 0.7474 - f1-score: 0.8536For batch 47, tr_loss is    0.23.\n",
      " 49/232 [=====>........................] - ETA: 2:54 - loss: 0.2301 - iou_score: 0.7468 - f1-score: 0.8532For batch 48, tr_loss is    0.23.\n",
      " 50/232 [=====>........................] - ETA: 2:52 - loss: 0.2296 - iou_score: 0.7473 - f1-score: 0.8536For batch 49, tr_loss is    0.23.\n",
      " 51/232 [=====>........................] - ETA: 2:51 - loss: 0.2302 - iou_score: 0.7464 - f1-score: 0.8530For batch 50, tr_loss is    0.23.\n",
      " 52/232 [=====>........................] - ETA: 2:51 - loss: 0.2325 - iou_score: 0.7447 - f1-score: 0.8518For batch 51, tr_loss is    0.23.\n",
      " 53/232 [=====>........................] - ETA: 2:50 - loss: 0.2315 - iou_score: 0.7461 - f1-score: 0.8527For batch 52, tr_loss is    0.23.\n",
      " 54/232 [=====>........................] - ETA: 2:49 - loss: 0.2316 - iou_score: 0.7457 - f1-score: 0.8525For batch 53, tr_loss is    0.23.\n",
      " 55/232 [======>.......................] - ETA: 2:49 - loss: 0.2312 - iou_score: 0.7459 - f1-score: 0.8527For batch 54, tr_loss is    0.23.\n",
      " 56/232 [======>.......................] - ETA: 2:46 - loss: 0.2309 - iou_score: 0.7461 - f1-score: 0.8528For batch 55, tr_loss is    0.23.\n",
      " 57/232 [======>.......................] - ETA: 2:44 - loss: 0.2312 - iou_score: 0.7455 - f1-score: 0.8524For batch 56, tr_loss is    0.23.\n",
      " 58/232 [======>.......................] - ETA: 2:43 - loss: 0.2308 - iou_score: 0.7462 - f1-score: 0.8529For batch 57, tr_loss is    0.23.\n",
      " 59/232 [======>.......................] - ETA: 2:41 - loss: 0.2302 - iou_score: 0.7468 - f1-score: 0.8533For batch 58, tr_loss is    0.23.\n",
      " 60/232 [======>.......................] - ETA: 2:40 - loss: 0.2314 - iou_score: 0.7453 - f1-score: 0.8523For batch 59, tr_loss is    0.23.\n",
      " 61/232 [======>.......................] - ETA: 2:40 - loss: 0.2337 - iou_score: 0.7434 - f1-score: 0.8508For batch 60, tr_loss is    0.23.\n",
      " 62/232 [=======>......................] - ETA: 2:39 - loss: 0.2340 - iou_score: 0.7428 - f1-score: 0.8504For batch 61, tr_loss is    0.23.\n",
      " 63/232 [=======>......................] - ETA: 2:38 - loss: 0.2336 - iou_score: 0.7433 - f1-score: 0.8508For batch 62, tr_loss is    0.23.\n",
      " 64/232 [=======>......................] - ETA: 2:38 - loss: 0.2337 - iou_score: 0.7430 - f1-score: 0.8506For batch 63, tr_loss is    0.23.\n",
      " 65/232 [=======>......................] - ETA: 2:36 - loss: 0.2338 - iou_score: 0.7429 - f1-score: 0.8506For batch 64, tr_loss is    0.23.\n",
      " 66/232 [=======>......................] - ETA: 2:34 - loss: 0.2343 - iou_score: 0.7425 - f1-score: 0.8503For batch 65, tr_loss is    0.23.\n",
      " 67/232 [=======>......................] - ETA: 2:34 - loss: 0.2335 - iou_score: 0.7433 - f1-score: 0.8509For batch 66, tr_loss is    0.23.\n",
      " 68/232 [=======>......................] - ETA: 2:33 - loss: 0.2333 - iou_score: 0.7436 - f1-score: 0.8510For batch 67, tr_loss is    0.23.\n",
      " 69/232 [=======>......................] - ETA: 2:31 - loss: 0.2335 - iou_score: 0.7434 - f1-score: 0.8510For batch 68, tr_loss is    0.23.\n",
      " 70/232 [========>.....................] - ETA: 2:29 - loss: 0.2333 - iou_score: 0.7436 - f1-score: 0.8511For batch 69, tr_loss is    0.23.\n",
      " 71/232 [========>.....................] - ETA: 2:29 - loss: 0.2324 - iou_score: 0.7448 - f1-score: 0.8519For batch 70, tr_loss is    0.23.\n",
      " 72/232 [========>.....................] - ETA: 2:28 - loss: 0.2321 - iou_score: 0.7451 - f1-score: 0.8520For batch 71, tr_loss is    0.23.\n",
      " 73/232 [========>.....................] - ETA: 2:26 - loss: 0.2320 - iou_score: 0.7448 - f1-score: 0.8519For batch 72, tr_loss is    0.23.\n",
      " 74/232 [========>.....................] - ETA: 2:26 - loss: 0.2316 - iou_score: 0.7452 - f1-score: 0.8521For batch 73, tr_loss is    0.23.\n",
      " 75/232 [========>.....................] - ETA: 2:25 - loss: 0.2315 - iou_score: 0.7452 - f1-score: 0.8521For batch 74, tr_loss is    0.23.\n",
      " 76/232 [========>.....................] - ETA: 2:23 - loss: 0.2308 - iou_score: 0.7457 - f1-score: 0.8525For batch 75, tr_loss is    0.23.\n",
      " 77/232 [========>.....................] - ETA: 2:23 - loss: 0.2304 - iou_score: 0.7462 - f1-score: 0.8529For batch 76, tr_loss is    0.23.\n",
      " 78/232 [=========>....................] - ETA: 2:21 - loss: 0.2305 - iou_score: 0.7460 - f1-score: 0.8527For batch 77, tr_loss is    0.23.\n",
      " 79/232 [=========>....................] - ETA: 2:21 - loss: 0.2297 - iou_score: 0.7469 - f1-score: 0.8533For batch 78, tr_loss is    0.23.\n",
      " 80/232 [=========>....................] - ETA: 2:20 - loss: 0.2299 - iou_score: 0.7467 - f1-score: 0.8532For batch 79, tr_loss is    0.23.\n",
      " 81/232 [=========>....................] - ETA: 2:18 - loss: 0.2305 - iou_score: 0.7461 - f1-score: 0.8528For batch 80, tr_loss is    0.23.\n",
      " 82/232 [=========>....................] - ETA: 2:17 - loss: 0.2308 - iou_score: 0.7458 - f1-score: 0.8526For batch 81, tr_loss is    0.23.\n",
      " 83/232 [=========>....................] - ETA: 2:16 - loss: 0.2310 - iou_score: 0.7453 - f1-score: 0.8523For batch 82, tr_loss is    0.23.\n",
      " 84/232 [=========>....................] - ETA: 2:15 - loss: 0.2313 - iou_score: 0.7450 - f1-score: 0.8521For batch 83, tr_loss is    0.23.\n",
      " 85/232 [=========>....................] - ETA: 2:15 - loss: 0.2315 - iou_score: 0.7447 - f1-score: 0.8520For batch 84, tr_loss is    0.23.\n",
      " 86/232 [==========>...................] - ETA: 2:13 - loss: 0.2320 - iou_score: 0.7441 - f1-score: 0.8515For batch 85, tr_loss is    0.23.\n",
      " 87/232 [==========>...................] - ETA: 2:12 - loss: 0.2315 - iou_score: 0.7445 - f1-score: 0.8518For batch 86, tr_loss is    0.23.\n",
      " 88/232 [==========>...................] - ETA: 2:11 - loss: 0.2318 - iou_score: 0.7442 - f1-score: 0.8516For batch 87, tr_loss is    0.23.\n",
      " 89/232 [==========>...................] - ETA: 2:10 - loss: 0.2313 - iou_score: 0.7447 - f1-score: 0.8520For batch 88, tr_loss is    0.23.\n",
      " 90/232 [==========>...................] - ETA: 2:09 - loss: 0.2308 - iou_score: 0.7454 - f1-score: 0.8524For batch 89, tr_loss is    0.23.\n",
      " 91/232 [==========>...................] - ETA: 2:09 - loss: 0.2305 - iou_score: 0.7454 - f1-score: 0.8525For batch 90, tr_loss is    0.23.\n",
      " 92/232 [==========>...................] - ETA: 2:08 - loss: 0.2306 - iou_score: 0.7455 - f1-score: 0.8525For batch 91, tr_loss is    0.23.\n",
      " 93/232 [===========>..................] - ETA: 2:06 - loss: 0.2308 - iou_score: 0.7450 - f1-score: 0.8522For batch 92, tr_loss is    0.23.\n",
      " 94/232 [===========>..................] - ETA: 2:06 - loss: 0.2303 - iou_score: 0.7457 - f1-score: 0.8526For batch 93, tr_loss is    0.23.\n",
      " 95/232 [===========>..................] - ETA: 2:05 - loss: 0.2306 - iou_score: 0.7453 - f1-score: 0.8524For batch 94, tr_loss is    0.23.\n",
      " 96/232 [===========>..................] - ETA: 2:04 - loss: 0.2304 - iou_score: 0.7453 - f1-score: 0.8524For batch 95, tr_loss is    0.23.\n",
      " 97/232 [===========>..................] - ETA: 2:03 - loss: 0.2304 - iou_score: 0.7454 - f1-score: 0.8524For batch 96, tr_loss is    0.23.\n",
      " 98/232 [===========>..................] - ETA: 2:02 - loss: 0.2307 - iou_score: 0.7451 - f1-score: 0.8522For batch 97, tr_loss is    0.23.\n",
      " 99/232 [===========>..................] - ETA: 2:01 - loss: 0.2299 - iou_score: 0.7461 - f1-score: 0.8529For batch 98, tr_loss is    0.23.\n",
      "100/232 [===========>..................] - ETA: 2:00 - loss: 0.2295 - iou_score: 0.7466 - f1-score: 0.8533For batch 99, tr_loss is    0.23.\n",
      "101/232 [============>.................] - ETA: 1:59 - loss: 0.2290 - iou_score: 0.7472 - f1-score: 0.8537For batch 100, tr_loss is    0.23.\n",
      "102/232 [============>.................] - ETA: 1:58 - loss: 0.2289 - iou_score: 0.7472 - f1-score: 0.8537For batch 101, tr_loss is    0.23.\n",
      "103/232 [============>.................] - ETA: 1:57 - loss: 0.2289 - iou_score: 0.7472 - f1-score: 0.8537For batch 102, tr_loss is    0.23.\n",
      "104/232 [============>.................] - ETA: 1:56 - loss: 0.2286 - iou_score: 0.7474 - f1-score: 0.8538For batch 103, tr_loss is    0.23.\n",
      "105/232 [============>.................] - ETA: 1:55 - loss: 0.2280 - iou_score: 0.7482 - f1-score: 0.8543For batch 104, tr_loss is    0.23.\n",
      "106/232 [============>.................] - ETA: 1:54 - loss: 0.2273 - iou_score: 0.7491 - f1-score: 0.8549For batch 105, tr_loss is    0.23.\n",
      "107/232 [============>.................] - ETA: 1:52 - loss: 0.2275 - iou_score: 0.7489 - f1-score: 0.8548For batch 106, tr_loss is    0.23.\n",
      "108/232 [============>.................] - ETA: 1:51 - loss: 0.2279 - iou_score: 0.7483 - f1-score: 0.8543For batch 107, tr_loss is    0.23.\n",
      "109/232 [=============>................] - ETA: 1:51 - loss: 0.2276 - iou_score: 0.7486 - f1-score: 0.8546For batch 108, tr_loss is    0.23.\n",
      "110/232 [=============>................] - ETA: 1:50 - loss: 0.2269 - iou_score: 0.7495 - f1-score: 0.8551For batch 109, tr_loss is    0.23.\n",
      "111/232 [=============>................] - ETA: 1:49 - loss: 0.2269 - iou_score: 0.7494 - f1-score: 0.8551For batch 110, tr_loss is    0.23.\n",
      "112/232 [=============>................] - ETA: 1:48 - loss: 0.2272 - iou_score: 0.7492 - f1-score: 0.8549For batch 111, tr_loss is    0.23.\n",
      "113/232 [=============>................] - ETA: 1:47 - loss: 0.2275 - iou_score: 0.7488 - f1-score: 0.8547For batch 112, tr_loss is    0.23.\n",
      "114/232 [=============>................] - ETA: 1:46 - loss: 0.2268 - iou_score: 0.7496 - f1-score: 0.8552For batch 113, tr_loss is    0.23.\n",
      "115/232 [=============>................] - ETA: 1:45 - loss: 0.2264 - iou_score: 0.7500 - f1-score: 0.8554For batch 114, tr_loss is    0.23.\n",
      "116/232 [==============>...............] - ETA: 1:44 - loss: 0.2260 - iou_score: 0.7504 - f1-score: 0.8557For batch 115, tr_loss is    0.23.\n",
      "117/232 [==============>...............] - ETA: 1:43 - loss: 0.2258 - iou_score: 0.7506 - f1-score: 0.8558For batch 116, tr_loss is    0.23.\n",
      "118/232 [==============>...............] - ETA: 1:43 - loss: 0.2254 - iou_score: 0.7512 - f1-score: 0.8562For batch 117, tr_loss is    0.23.\n",
      "119/232 [==============>...............] - ETA: 1:42 - loss: 0.2251 - iou_score: 0.7516 - f1-score: 0.8565For batch 118, tr_loss is    0.23.\n",
      "120/232 [==============>...............] - ETA: 1:40 - loss: 0.2255 - iou_score: 0.7513 - f1-score: 0.8563For batch 119, tr_loss is    0.23.\n",
      "121/232 [==============>...............] - ETA: 1:40 - loss: 0.2251 - iou_score: 0.7516 - f1-score: 0.8565For batch 120, tr_loss is    0.23.\n",
      "122/232 [==============>...............] - ETA: 1:39 - loss: 0.2254 - iou_score: 0.7513 - f1-score: 0.8563For batch 121, tr_loss is    0.23.\n",
      "123/232 [==============>...............] - ETA: 1:38 - loss: 0.2251 - iou_score: 0.7516 - f1-score: 0.8565For batch 122, tr_loss is    0.23.\n",
      "124/232 [===============>..............] - ETA: 1:36 - loss: 0.2252 - iou_score: 0.7514 - f1-score: 0.8564For batch 123, tr_loss is    0.23.\n",
      "125/232 [===============>..............] - ETA: 1:36 - loss: 0.2253 - iou_score: 0.7512 - f1-score: 0.8563For batch 124, tr_loss is    0.23.\n",
      "126/232 [===============>..............] - ETA: 1:35 - loss: 0.2252 - iou_score: 0.7514 - f1-score: 0.8564For batch 125, tr_loss is    0.23.\n",
      "127/232 [===============>..............] - ETA: 1:34 - loss: 0.2251 - iou_score: 0.7515 - f1-score: 0.8565For batch 126, tr_loss is    0.23.\n",
      "128/232 [===============>..............] - ETA: 1:33 - loss: 0.2250 - iou_score: 0.7514 - f1-score: 0.8565For batch 127, tr_loss is    0.22.\n",
      "129/232 [===============>..............] - ETA: 1:32 - loss: 0.2249 - iou_score: 0.7514 - f1-score: 0.8565For batch 128, tr_loss is    0.22.\n",
      "130/232 [===============>..............] - ETA: 1:31 - loss: 0.2246 - iou_score: 0.7516 - f1-score: 0.8566For batch 129, tr_loss is    0.22.\n",
      "131/232 [===============>..............] - ETA: 1:30 - loss: 0.2253 - iou_score: 0.7510 - f1-score: 0.8562For batch 130, tr_loss is    0.23.\n",
      "132/232 [================>.............] - ETA: 1:29 - loss: 0.2256 - iou_score: 0.7509 - f1-score: 0.8561For batch 131, tr_loss is    0.23.\n",
      "133/232 [================>.............] - ETA: 1:28 - loss: 0.2253 - iou_score: 0.7512 - f1-score: 0.8563For batch 132, tr_loss is    0.23.\n",
      "134/232 [================>.............] - ETA: 1:27 - loss: 0.2255 - iou_score: 0.7507 - f1-score: 0.8560For batch 133, tr_loss is    0.23.\n",
      "135/232 [================>.............] - ETA: 1:26 - loss: 0.2252 - iou_score: 0.7510 - f1-score: 0.8562For batch 134, tr_loss is    0.23.\n",
      "136/232 [================>.............] - ETA: 1:25 - loss: 0.2255 - iou_score: 0.7507 - f1-score: 0.8560For batch 135, tr_loss is    0.23.\n",
      "137/232 [================>.............] - ETA: 1:24 - loss: 0.2257 - iou_score: 0.7503 - f1-score: 0.8557For batch 136, tr_loss is    0.23.\n",
      "138/232 [================>.............] - ETA: 1:24 - loss: 0.2258 - iou_score: 0.7501 - f1-score: 0.8556For batch 137, tr_loss is    0.23.\n",
      "139/232 [================>.............] - ETA: 1:23 - loss: 0.2256 - iou_score: 0.7501 - f1-score: 0.8556For batch 138, tr_loss is    0.23.\n",
      "140/232 [=================>............] - ETA: 1:22 - loss: 0.2256 - iou_score: 0.7502 - f1-score: 0.8557For batch 139, tr_loss is    0.23.\n",
      "141/232 [=================>............] - ETA: 1:21 - loss: 0.2261 - iou_score: 0.7495 - f1-score: 0.8552For batch 140, tr_loss is    0.23.\n",
      "142/232 [=================>............] - ETA: 1:20 - loss: 0.2259 - iou_score: 0.7496 - f1-score: 0.8553For batch 141, tr_loss is    0.23.\n",
      "143/232 [=================>............] - ETA: 1:19 - loss: 0.2256 - iou_score: 0.7499 - f1-score: 0.8555For batch 142, tr_loss is    0.23.\n",
      "144/232 [=================>............] - ETA: 1:18 - loss: 0.2256 - iou_score: 0.7498 - f1-score: 0.8554For batch 143, tr_loss is    0.23.\n",
      "145/232 [=================>............] - ETA: 1:17 - loss: 0.2257 - iou_score: 0.7495 - f1-score: 0.8552For batch 144, tr_loss is    0.23.\n",
      "146/232 [=================>............] - ETA: 1:16 - loss: 0.2259 - iou_score: 0.7492 - f1-score: 0.8550For batch 145, tr_loss is    0.23.\n",
      "147/232 [==================>...........] - ETA: 1:15 - loss: 0.2256 - iou_score: 0.7497 - f1-score: 0.8553For batch 146, tr_loss is    0.23.\n",
      "148/232 [==================>...........] - ETA: 1:14 - loss: 0.2257 - iou_score: 0.7493 - f1-score: 0.8551For batch 147, tr_loss is    0.23.\n",
      "149/232 [==================>...........] - ETA: 1:13 - loss: 0.2256 - iou_score: 0.7496 - f1-score: 0.8553For batch 148, tr_loss is    0.23.\n",
      "150/232 [==================>...........] - ETA: 1:12 - loss: 0.2261 - iou_score: 0.7489 - f1-score: 0.8548For batch 149, tr_loss is    0.23.\n",
      "151/232 [==================>...........] - ETA: 1:11 - loss: 0.2261 - iou_score: 0.7487 - f1-score: 0.8547For batch 150, tr_loss is    0.23.\n",
      "152/232 [==================>...........] - ETA: 1:11 - loss: 0.2259 - iou_score: 0.7491 - f1-score: 0.8549For batch 151, tr_loss is    0.23.\n",
      "153/232 [==================>...........] - ETA: 1:10 - loss: 0.2258 - iou_score: 0.7490 - f1-score: 0.8549For batch 152, tr_loss is    0.23.\n",
      "154/232 [==================>...........] - ETA: 1:09 - loss: 0.2257 - iou_score: 0.7492 - f1-score: 0.8550For batch 153, tr_loss is    0.23.\n",
      "155/232 [===================>..........] - ETA: 1:08 - loss: 0.2257 - iou_score: 0.7491 - f1-score: 0.8550For batch 154, tr_loss is    0.23.\n",
      "156/232 [===================>..........] - ETA: 1:07 - loss: 0.2257 - iou_score: 0.7490 - f1-score: 0.8549For batch 155, tr_loss is    0.23.\n",
      "157/232 [===================>..........] - ETA: 1:06 - loss: 0.2260 - iou_score: 0.7487 - f1-score: 0.8547For batch 156, tr_loss is    0.23.\n",
      "158/232 [===================>..........] - ETA: 1:05 - loss: 0.2258 - iou_score: 0.7489 - f1-score: 0.8548For batch 157, tr_loss is    0.23.\n",
      "159/232 [===================>..........] - ETA: 1:04 - loss: 0.2253 - iou_score: 0.7495 - f1-score: 0.8552For batch 158, tr_loss is    0.23.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/232 [===================>..........] - ETA: 1:04 - loss: 0.2252 - iou_score: 0.7495 - f1-score: 0.8552For batch 159, tr_loss is    0.23.\n",
      "161/232 [===================>..........] - ETA: 1:03 - loss: 0.2249 - iou_score: 0.7499 - f1-score: 0.8555For batch 160, tr_loss is    0.22.\n",
      "162/232 [===================>..........] - ETA: 1:02 - loss: 0.2250 - iou_score: 0.7498 - f1-score: 0.8554For batch 161, tr_loss is    0.22.\n",
      "163/232 [====================>.........] - ETA: 1:01 - loss: 0.2248 - iou_score: 0.7500 - f1-score: 0.8555For batch 162, tr_loss is    0.22.\n",
      "164/232 [====================>.........] - ETA: 1:00 - loss: 0.2250 - iou_score: 0.7498 - f1-score: 0.8554For batch 163, tr_loss is    0.22.\n",
      "165/232 [====================>.........] - ETA: 59s - loss: 0.2250 - iou_score: 0.7497 - f1-score: 0.8554 For batch 164, tr_loss is    0.23.\n",
      "166/232 [====================>.........] - ETA: 58s - loss: 0.2247 - iou_score: 0.7500 - f1-score: 0.8556For batch 165, tr_loss is    0.22.\n",
      "167/232 [====================>.........] - ETA: 57s - loss: 0.2244 - iou_score: 0.7503 - f1-score: 0.8558For batch 166, tr_loss is    0.22.\n",
      "168/232 [====================>.........] - ETA: 56s - loss: 0.2248 - iou_score: 0.7499 - f1-score: 0.8555For batch 167, tr_loss is    0.22.\n",
      "169/232 [====================>.........] - ETA: 55s - loss: 0.2250 - iou_score: 0.7495 - f1-score: 0.8552For batch 168, tr_loss is    0.22.\n",
      "170/232 [====================>.........] - ETA: 54s - loss: 0.2249 - iou_score: 0.7496 - f1-score: 0.8553For batch 169, tr_loss is    0.22.\n",
      "171/232 [=====================>........] - ETA: 54s - loss: 0.2251 - iou_score: 0.7494 - f1-score: 0.8551For batch 170, tr_loss is    0.23.\n",
      "172/232 [=====================>........] - ETA: 53s - loss: 0.2253 - iou_score: 0.7491 - f1-score: 0.8550For batch 171, tr_loss is    0.23.\n",
      "173/232 [=====================>........] - ETA: 52s - loss: 0.2250 - iou_score: 0.7495 - f1-score: 0.8552For batch 172, tr_loss is    0.22.\n",
      "174/232 [=====================>........] - ETA: 51s - loss: 0.2247 - iou_score: 0.7498 - f1-score: 0.8554For batch 173, tr_loss is    0.22.\n",
      "175/232 [=====================>........] - ETA: 50s - loss: 0.2248 - iou_score: 0.7496 - f1-score: 0.8553For batch 174, tr_loss is    0.22.\n",
      "176/232 [=====================>........] - ETA: 49s - loss: 0.2248 - iou_score: 0.7494 - f1-score: 0.8552For batch 175, tr_loss is    0.22.\n",
      "177/232 [=====================>........] - ETA: 48s - loss: 0.2246 - iou_score: 0.7498 - f1-score: 0.8554For batch 176, tr_loss is    0.22.\n",
      "178/232 [======================>.......] - ETA: 48s - loss: 0.2244 - iou_score: 0.7500 - f1-score: 0.8556For batch 177, tr_loss is    0.22.\n",
      "179/232 [======================>.......] - ETA: 47s - loss: 0.2243 - iou_score: 0.7501 - f1-score: 0.8556For batch 178, tr_loss is    0.22.\n",
      "180/232 [======================>.......] - ETA: 46s - loss: 0.2244 - iou_score: 0.7498 - f1-score: 0.8554For batch 179, tr_loss is    0.22.\n",
      "181/232 [======================>.......] - ETA: 45s - loss: 0.2243 - iou_score: 0.7499 - f1-score: 0.8555For batch 180, tr_loss is    0.22.\n",
      "182/232 [======================>.......] - ETA: 44s - loss: 0.2243 - iou_score: 0.7498 - f1-score: 0.8555For batch 181, tr_loss is    0.22.\n",
      "183/232 [======================>.......] - ETA: 43s - loss: 0.2243 - iou_score: 0.7499 - f1-score: 0.8555For batch 182, tr_loss is    0.22.\n",
      "184/232 [======================>.......] - ETA: 42s - loss: 0.2241 - iou_score: 0.7503 - f1-score: 0.8558For batch 183, tr_loss is    0.22.\n",
      "185/232 [======================>.......] - ETA: 41s - loss: 0.2242 - iou_score: 0.7502 - f1-score: 0.8557For batch 184, tr_loss is    0.22.\n",
      "186/232 [=======================>......] - ETA: 40s - loss: 0.2242 - iou_score: 0.7501 - f1-score: 0.8556For batch 185, tr_loss is    0.22.\n",
      "187/232 [=======================>......] - ETA: 39s - loss: 0.2239 - iou_score: 0.7505 - f1-score: 0.8559For batch 186, tr_loss is    0.22.\n",
      "188/232 [=======================>......] - ETA: 39s - loss: 0.2239 - iou_score: 0.7505 - f1-score: 0.8559For batch 187, tr_loss is    0.22.\n",
      "189/232 [=======================>......] - ETA: 38s - loss: 0.2237 - iou_score: 0.7507 - f1-score: 0.8560For batch 188, tr_loss is    0.22.\n",
      "190/232 [=======================>......] - ETA: 37s - loss: 0.2235 - iou_score: 0.7509 - f1-score: 0.8561For batch 189, tr_loss is    0.22.\n",
      "191/232 [=======================>......] - ETA: 36s - loss: 0.2238 - iou_score: 0.7508 - f1-score: 0.8561For batch 190, tr_loss is    0.22.\n",
      "192/232 [=======================>......] - ETA: 35s - loss: 0.2240 - iou_score: 0.7505 - f1-score: 0.8559For batch 191, tr_loss is    0.22.\n",
      "193/232 [=======================>......] - ETA: 34s - loss: 0.2243 - iou_score: 0.7502 - f1-score: 0.8557For batch 192, tr_loss is    0.22.\n",
      "194/232 [========================>.....] - ETA: 33s - loss: 0.2242 - iou_score: 0.7502 - f1-score: 0.8557For batch 193, tr_loss is    0.22.\n",
      "195/232 [========================>.....] - ETA: 32s - loss: 0.2242 - iou_score: 0.7502 - f1-score: 0.8557For batch 194, tr_loss is    0.22.\n",
      "196/232 [========================>.....] - ETA: 31s - loss: 0.2241 - iou_score: 0.7501 - f1-score: 0.8557For batch 195, tr_loss is    0.22.\n",
      "197/232 [========================>.....] - ETA: 31s - loss: 0.2241 - iou_score: 0.7502 - f1-score: 0.8557For batch 196, tr_loss is    0.22.\n",
      "198/232 [========================>.....] - ETA: 30s - loss: 0.2238 - iou_score: 0.7507 - f1-score: 0.8560For batch 197, tr_loss is    0.22.\n",
      "199/232 [========================>.....] - ETA: 29s - loss: 0.2236 - iou_score: 0.7508 - f1-score: 0.8561For batch 198, tr_loss is    0.22.\n",
      "200/232 [========================>.....] - ETA: 28s - loss: 0.2234 - iou_score: 0.7511 - f1-score: 0.8563For batch 199, tr_loss is    0.22.\n",
      "201/232 [========================>.....] - ETA: 27s - loss: 0.2236 - iou_score: 0.7508 - f1-score: 0.8561For batch 200, tr_loss is    0.22.\n",
      "202/232 [=========================>....] - ETA: 26s - loss: 0.2235 - iou_score: 0.7509 - f1-score: 0.8562For batch 201, tr_loss is    0.22.\n",
      "203/232 [=========================>....] - ETA: 25s - loss: 0.2232 - iou_score: 0.7511 - f1-score: 0.8563For batch 202, tr_loss is    0.22.\n",
      "204/232 [=========================>....] - ETA: 24s - loss: 0.2229 - iou_score: 0.7515 - f1-score: 0.8566For batch 203, tr_loss is    0.22.\n",
      "205/232 [=========================>....] - ETA: 23s - loss: 0.2230 - iou_score: 0.7515 - f1-score: 0.8565For batch 204, tr_loss is    0.22.\n",
      "206/232 [=========================>....] - ETA: 23s - loss: 0.2231 - iou_score: 0.7513 - f1-score: 0.8564For batch 205, tr_loss is    0.22.\n",
      "207/232 [=========================>....] - ETA: 22s - loss: 0.2231 - iou_score: 0.7514 - f1-score: 0.8565For batch 206, tr_loss is    0.22.\n",
      "208/232 [=========================>....] - ETA: 21s - loss: 0.2232 - iou_score: 0.7513 - f1-score: 0.8565For batch 207, tr_loss is    0.22.\n",
      "209/232 [==========================>...] - ETA: 20s - loss: 0.2234 - iou_score: 0.7511 - f1-score: 0.8563For batch 208, tr_loss is    0.22.\n",
      "210/232 [==========================>...] - ETA: 19s - loss: 0.2238 - iou_score: 0.7507 - f1-score: 0.8560For batch 209, tr_loss is    0.22.\n",
      "211/232 [==========================>...] - ETA: 18s - loss: 0.2236 - iou_score: 0.7509 - f1-score: 0.8562For batch 210, tr_loss is    0.22.\n",
      "212/232 [==========================>...] - ETA: 17s - loss: 0.2233 - iou_score: 0.7512 - f1-score: 0.8564For batch 211, tr_loss is    0.22.\n",
      "213/232 [==========================>...] - ETA: 16s - loss: 0.2233 - iou_score: 0.7512 - f1-score: 0.8564For batch 212, tr_loss is    0.22.\n",
      "214/232 [==========================>...] - ETA: 15s - loss: 0.2233 - iou_score: 0.7513 - f1-score: 0.8565For batch 213, tr_loss is    0.22.\n",
      "215/232 [==========================>...] - ETA: 15s - loss: 0.2230 - iou_score: 0.7517 - f1-score: 0.8567For batch 214, tr_loss is    0.22.\n",
      "216/232 [==========================>...] - ETA: 14s - loss: 0.2229 - iou_score: 0.7519 - f1-score: 0.8568For batch 215, tr_loss is    0.22.\n",
      "217/232 [===========================>..] - ETA: 13s - loss: 0.2229 - iou_score: 0.7518 - f1-score: 0.8568For batch 216, tr_loss is    0.22.\n",
      "218/232 [===========================>..] - ETA: 12s - loss: 0.2229 - iou_score: 0.7518 - f1-score: 0.8568For batch 217, tr_loss is    0.22.\n",
      "219/232 [===========================>..] - ETA: 11s - loss: 0.2233 - iou_score: 0.7513 - f1-score: 0.8564For batch 218, tr_loss is    0.22.\n",
      "220/232 [===========================>..] - ETA: 10s - loss: 0.2233 - iou_score: 0.7512 - f1-score: 0.8563For batch 219, tr_loss is    0.22.\n",
      "221/232 [===========================>..] - ETA: 9s - loss: 0.2234 - iou_score: 0.7510 - f1-score: 0.8562 For batch 220, tr_loss is    0.22.\n",
      "222/232 [===========================>..] - ETA: 8s - loss: 0.2232 - iou_score: 0.7513 - f1-score: 0.8564For batch 221, tr_loss is    0.22.\n",
      "223/232 [===========================>..] - ETA: 7s - loss: 0.2233 - iou_score: 0.7510 - f1-score: 0.8563For batch 222, tr_loss is    0.22.\n",
      "224/232 [===========================>..] - ETA: 7s - loss: 0.2232 - iou_score: 0.7512 - f1-score: 0.8564For batch 223, tr_loss is    0.22.\n",
      "225/232 [============================>.] - ETA: 6s - loss: 0.2231 - iou_score: 0.7514 - f1-score: 0.8565For batch 224, tr_loss is    0.22.\n",
      "226/232 [============================>.] - ETA: 5s - loss: 0.2231 - iou_score: 0.7513 - f1-score: 0.8565For batch 225, tr_loss is    0.22.\n",
      "227/232 [============================>.] - ETA: 4s - loss: 0.2231 - iou_score: 0.7514 - f1-score: 0.8565For batch 226, tr_loss is    0.22.\n",
      "228/232 [============================>.] - ETA: 3s - loss: 0.2231 - iou_score: 0.7514 - f1-score: 0.8565For batch 227, tr_loss is    0.22.\n",
      "229/232 [============================>.] - ETA: 2s - loss: 0.2230 - iou_score: 0.7515 - f1-score: 0.8566For batch 228, tr_loss is    0.22.\n",
      "230/232 [============================>.] - ETA: 1s - loss: 0.2234 - iou_score: 0.7511 - f1-score: 0.8563For batch 229, tr_loss is    0.22.\n",
      "231/232 [============================>.] - ETA: 0s - loss: 0.2237 - iou_score: 0.7509 - f1-score: 0.8562For batch 230, tr_loss is    0.22.\n",
      "232/232 [==============================] - ETA: 0s - loss: 0.2235 - iou_score: 0.7511 - f1-score: 0.8563For batch 231, tr_loss is    0.22.\n",
      "For batch 0, vl_loss is    0.42.\n",
      "For batch 1, vl_loss is    0.40.\n",
      "For batch 2, vl_loss is    0.44.\n",
      "For batch 3, vl_loss is    0.43.\n",
      "For batch 4, vl_loss is    0.47.\n",
      "For batch 5, vl_loss is    0.46.\n",
      "For batch 6, vl_loss is    0.46.\n",
      "For batch 7, vl_loss is    0.46.\n",
      "For batch 8, vl_loss is    0.46.\n",
      "For batch 9, vl_loss is    0.46.\n",
      "For batch 10, vl_loss is    0.46.\n",
      "For batch 11, vl_loss is    0.47.\n",
      "For batch 12, vl_loss is    0.48.\n",
      "For batch 13, vl_loss is    0.48.\n",
      "For batch 14, vl_loss is    0.47.\n",
      "For batch 15, vl_loss is    0.46.\n",
      "For batch 16, vl_loss is    0.46.\n",
      "For batch 17, vl_loss is    0.46.\n",
      "For batch 18, vl_loss is    0.46.\n",
      "For batch 19, vl_loss is    0.46.\n",
      "For batch 20, vl_loss is    0.46.\n",
      "For batch 21, vl_loss is    0.47.\n",
      "For batch 22, vl_loss is    0.46.\n",
      "For batch 23, vl_loss is    0.46.\n",
      "For batch 24, vl_loss is    0.46.\n",
      "For batch 25, vl_loss is    0.45.\n",
      "For batch 26, vl_loss is    0.45.\n",
      "For batch 27, vl_loss is    0.46.\n",
      "For batch 28, vl_loss is    0.46.\n",
      "For batch 29, vl_loss is    0.46.\n",
      "For batch 30, vl_loss is    0.46.\n",
      "For batch 31, vl_loss is    0.46.\n",
      "For batch 32, vl_loss is    0.46.\n",
      "For batch 33, vl_loss is    0.46.\n",
      "For batch 34, vl_loss is    0.46.\n",
      "For batch 35, vl_loss is    0.46.\n",
      "For batch 36, vl_loss is    0.46.\n",
      "For batch 37, vl_loss is    0.46.\n",
      "For batch 38, vl_loss is    0.45.\n",
      "For batch 39, vl_loss is    0.45.\n",
      "For batch 40, vl_loss is    0.45.\n",
      "For batch 41, vl_loss is    0.46.\n",
      "For batch 42, vl_loss is    0.46.\n",
      "For batch 43, vl_loss is    0.46.\n",
      "For batch 44, vl_loss is    0.46.\n",
      "For batch 45, vl_loss is    0.46.\n",
      "For batch 46, vl_loss is    0.46.\n",
      "For batch 47, vl_loss is    0.46.\n",
      "For batch 48, vl_loss is    0.46.\n",
      "For batch 49, vl_loss is    0.46.\n",
      "For batch 50, vl_loss is    0.46.\n",
      "For batch 51, vl_loss is    0.46.\n",
      "For batch 52, vl_loss is    0.46.\n",
      "For batch 53, vl_loss is    0.46.\n",
      "For batch 54, vl_loss is    0.46.\n",
      "For batch 55, vl_loss is    0.46.\n",
      "For batch 56, vl_loss is    0.46.\n",
      "For batch 57, vl_loss is    0.46.\n",
      "For batch 58, vl_loss is    0.46.\n",
      "For batch 59, vl_loss is    0.46.\n",
      "For batch 60, vl_loss is    0.46.\n",
      "For batch 61, vl_loss is    0.46.\n",
      "For batch 62, vl_loss is    0.46.\n",
      "For batch 63, vl_loss is    0.46.\n",
      "For batch 64, vl_loss is    0.46.\n",
      "For batch 65, vl_loss is    0.46.\n",
      "For batch 66, vl_loss is    0.46.\n",
      "For batch 67, vl_loss is    0.46.\n",
      "232/232 [==============================] - 210s 896ms/step - loss: 0.2235 - iou_score: 0.7511 - f1-score: 0.8563 - val_loss: 0.4560 - val_iou_score: 0.5187 - val_f1-score: 0.6799\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.36098\n",
      "The average loss for epoch 18 is    0.22 \n",
      "47/47 [==============================] - 4s 87ms/step - loss: 0.4183 - iou_score: 0.5079 - f1-score: 0.6699\n",
      "./model/tumor_100_unet_efficientnetb0_imagenet_09292.hdf5\n",
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Number of devices: 2\n",
      "Epoch 1/200\n",
      "INFO:tensorflow:batch_all_reduce: 130 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 130 all-reduces with algorithm = nccl, num_packs = 1\n",
      "      1/Unknown - 46s 46s/step - loss: 0.6994 - iou_score: 0.1081 - f1-score: 0.1951For batch 0, tr_loss is    0.70.\n",
      "      2/Unknown - 48s 2s/step - loss: 0.6427 - iou_score: 0.1824 - f1-score: 0.3015 For batch 1, tr_loss is    0.64.\n",
      "      3/Unknown - 49s 1s/step - loss: 0.6131 - iou_score: 0.2341 - f1-score: 0.3691For batch 2, tr_loss is    0.61.\n",
      "      4/Unknown - 50s 1s/step - loss: 0.5891 - iou_score: 0.2876 - f1-score: 0.4315For batch 3, tr_loss is    0.59.\n",
      "      5/Unknown - 52s 1s/step - loss: 0.5682 - iou_score: 0.3312 - f1-score: 0.4790For batch 4, tr_loss is    0.57.\n",
      "      6/Unknown - 53s 1s/step - loss: 0.5508 - iou_score: 0.3646 - f1-score: 0.5149For batch 5, tr_loss is    0.55.\n",
      "      7/Unknown - 54s 1s/step - loss: 0.5347 - iou_score: 0.3966 - f1-score: 0.5471For batch 6, tr_loss is    0.53.\n",
      "      8/Unknown - 55s 1s/step - loss: 0.5323 - iou_score: 0.4090 - f1-score: 0.5616For batch 7, tr_loss is    0.53.\n",
      "      9/Unknown - 56s 1s/step - loss: 0.5226 - iou_score: 0.4257 - f1-score: 0.5787For batch 8, tr_loss is    0.52.\n",
      "     10/Unknown - 57s 1s/step - loss: 0.5093 - iou_score: 0.4458 - f1-score: 0.5978For batch 9, tr_loss is    0.51.\n",
      "     11/Unknown - 58s 1s/step - loss: 0.4986 - iou_score: 0.4614 - f1-score: 0.6125For batch 10, tr_loss is    0.50.\n",
      "     12/Unknown - 59s 1s/step - loss: 0.4905 - iou_score: 0.4726 - f1-score: 0.6237For batch 11, tr_loss is    0.49.\n",
      "     13/Unknown - 60s 1s/step - loss: 0.4802 - iou_score: 0.4875 - f1-score: 0.6372For batch 12, tr_loss is    0.48.\n",
      "     14/Unknown - 61s 1s/step - loss: 0.4783 - iou_score: 0.4901 - f1-score: 0.6407For batch 13, tr_loss is    0.48.\n",
      "     15/Unknown - 62s 1s/step - loss: 0.4735 - iou_score: 0.4965 - f1-score: 0.6473For batch 14, tr_loss is    0.47.\n",
      "     16/Unknown - 63s 1s/step - loss: 0.4689 - iou_score: 0.5032 - f1-score: 0.6538For batch 15, tr_loss is    0.47.\n",
      "     17/Unknown - 64s 1s/step - loss: 0.4641 - iou_score: 0.5094 - f1-score: 0.6598For batch 16, tr_loss is    0.46.\n",
      "     18/Unknown - 65s 1s/step - loss: 0.4618 - iou_score: 0.5124 - f1-score: 0.6632For batch 17, tr_loss is    0.46.\n",
      "     19/Unknown - 65s 1s/step - loss: 0.4589 - iou_score: 0.5173 - f1-score: 0.6679For batch 18, tr_loss is    0.46.\n",
      "     20/Unknown - 66s 1s/step - loss: 0.4556 - iou_score: 0.5217 - f1-score: 0.6720For batch 19, tr_loss is    0.46.\n",
      "     21/Unknown - 67s 1s/step - loss: 0.4530 - iou_score: 0.5253 - f1-score: 0.6756For batch 20, tr_loss is    0.45.\n",
      "     22/Unknown - 68s 1s/step - loss: 0.4523 - iou_score: 0.5265 - f1-score: 0.6772For batch 21, tr_loss is    0.45.\n",
      "     23/Unknown - 69s 1s/step - loss: 0.4505 - iou_score: 0.5287 - f1-score: 0.6795For batch 22, tr_loss is    0.45.\n",
      "     24/Unknown - 70s 1s/step - loss: 0.4465 - iou_score: 0.5342 - f1-score: 0.6844For batch 23, tr_loss is    0.45.\n",
      "     25/Unknown - 71s 1s/step - loss: 0.4453 - iou_score: 0.5354 - f1-score: 0.6859For batch 24, tr_loss is    0.45.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     26/Unknown - 72s 1s/step - loss: 0.4448 - iou_score: 0.5358 - f1-score: 0.6866For batch 25, tr_loss is    0.44.\n",
      "     27/Unknown - 73s 1s/step - loss: 0.4423 - iou_score: 0.5392 - f1-score: 0.6897For batch 26, tr_loss is    0.44.\n",
      "     28/Unknown - 73s 1s/step - loss: 0.4380 - iou_score: 0.5449 - f1-score: 0.6944For batch 27, tr_loss is    0.44.\n",
      "     29/Unknown - 74s 994ms/step - loss: 0.4371 - iou_score: 0.5457 - f1-score: 0.6955For batch 28, tr_loss is    0.44.\n",
      "     30/Unknown - 75s 986ms/step - loss: 0.4338 - iou_score: 0.5495 - f1-score: 0.6988For batch 29, tr_loss is    0.43.\n",
      "     31/Unknown - 76s 974ms/step - loss: 0.4303 - iou_score: 0.5539 - f1-score: 0.7025For batch 30, tr_loss is    0.43.\n",
      "     32/Unknown - 76s 965ms/step - loss: 0.4273 - iou_score: 0.5577 - f1-score: 0.7057For batch 31, tr_loss is    0.43.\n",
      "     33/Unknown - 77s 966ms/step - loss: 0.4268 - iou_score: 0.5587 - f1-score: 0.7068For batch 32, tr_loss is    0.43.\n",
      "     34/Unknown - 78s 952ms/step - loss: 0.4248 - iou_score: 0.5612 - f1-score: 0.7091For batch 33, tr_loss is    0.42.\n",
      "     35/Unknown - 78s 945ms/step - loss: 0.4249 - iou_score: 0.5614 - f1-score: 0.7095For batch 34, tr_loss is    0.42.\n",
      "     36/Unknown - 79s 941ms/step - loss: 0.4218 - iou_score: 0.5655 - f1-score: 0.7128For batch 35, tr_loss is    0.42.\n",
      "     37/Unknown - 80s 929ms/step - loss: 0.4220 - iou_score: 0.5655 - f1-score: 0.7131For batch 36, tr_loss is    0.42.\n",
      "     38/Unknown - 81s 926ms/step - loss: 0.4201 - iou_score: 0.5686 - f1-score: 0.7157For batch 37, tr_loss is    0.42.\n",
      "     39/Unknown - 82s 929ms/step - loss: 0.4173 - iou_score: 0.5722 - f1-score: 0.7186For batch 38, tr_loss is    0.42.\n",
      "     40/Unknown - 82s 925ms/step - loss: 0.4166 - iou_score: 0.5729 - f1-score: 0.7194For batch 39, tr_loss is    0.42.\n",
      "     41/Unknown - 83s 927ms/step - loss: 0.4167 - iou_score: 0.5725 - f1-score: 0.7193For batch 40, tr_loss is    0.42.\n",
      "     42/Unknown - 84s 923ms/step - loss: 0.4161 - iou_score: 0.5740 - f1-score: 0.7206For batch 41, tr_loss is    0.42.\n",
      "     43/Unknown - 85s 919ms/step - loss: 0.4161 - iou_score: 0.5736 - f1-score: 0.7205For batch 42, tr_loss is    0.42.\n",
      "     44/Unknown - 86s 921ms/step - loss: 0.4149 - iou_score: 0.5751 - f1-score: 0.7217For batch 43, tr_loss is    0.41.\n",
      "     45/Unknown - 86s 910ms/step - loss: 0.4138 - iou_score: 0.5764 - f1-score: 0.7229For batch 44, tr_loss is    0.41.\n",
      "     46/Unknown - 87s 909ms/step - loss: 0.4123 - iou_score: 0.5783 - f1-score: 0.7245For batch 45, tr_loss is    0.41.\n",
      "     47/Unknown - 88s 903ms/step - loss: 0.4107 - iou_score: 0.5800 - f1-score: 0.7259For batch 46, tr_loss is    0.41.\n",
      "     48/Unknown - 89s 907ms/step - loss: 0.4097 - iou_score: 0.5812 - f1-score: 0.7270For batch 47, tr_loss is    0.41.\n",
      "     49/Unknown - 89s 898ms/step - loss: 0.4103 - iou_score: 0.5811 - f1-score: 0.7271For batch 48, tr_loss is    0.41.\n",
      "     50/Unknown - 90s 896ms/step - loss: 0.4091 - iou_score: 0.5820 - f1-score: 0.7280For batch 49, tr_loss is    0.41.\n",
      "     51/Unknown - 91s 892ms/step - loss: 0.4088 - iou_score: 0.5821 - f1-score: 0.7281For batch 50, tr_loss is    0.41.\n",
      "     52/Unknown - 92s 896ms/step - loss: 0.4085 - iou_score: 0.5826 - f1-score: 0.7287For batch 51, tr_loss is    0.41.\n",
      "     53/Unknown - 93s 889ms/step - loss: 0.4081 - iou_score: 0.5830 - f1-score: 0.7291For batch 52, tr_loss is    0.41.\n",
      "     54/Unknown - 93s 887ms/step - loss: 0.4081 - iou_score: 0.5832 - f1-score: 0.7294For batch 53, tr_loss is    0.41.\n",
      "     55/Unknown - 94s 890ms/step - loss: 0.4068 - iou_score: 0.5849 - f1-score: 0.7308For batch 54, tr_loss is    0.41.\n",
      "     56/Unknown - 95s 893ms/step - loss: 0.4055 - iou_score: 0.5863 - f1-score: 0.7319For batch 55, tr_loss is    0.41.\n",
      "     57/Unknown - 96s 895ms/step - loss: 0.4052 - iou_score: 0.5866 - f1-score: 0.7323For batch 56, tr_loss is    0.41.\n",
      "     58/Unknown - 97s 892ms/step - loss: 0.4056 - iou_score: 0.5860 - f1-score: 0.7318For batch 57, tr_loss is    0.41.\n",
      "     59/Unknown - 98s 884ms/step - loss: 0.4045 - iou_score: 0.5880 - f1-score: 0.7334For batch 58, tr_loss is    0.40.\n",
      "     60/Unknown - 99s 888ms/step - loss: 0.4063 - iou_score: 0.5862 - f1-score: 0.7320For batch 59, tr_loss is    0.41.\n",
      "     61/Unknown - 99s 883ms/step - loss: 0.4065 - iou_score: 0.5859 - f1-score: 0.7319For batch 60, tr_loss is    0.41.\n",
      "     62/Unknown - 100s 887ms/step - loss: 0.4058 - iou_score: 0.5865 - f1-score: 0.7325For batch 61, tr_loss is    0.41.\n",
      "     63/Unknown - 101s 889ms/step - loss: 0.4057 - iou_score: 0.5872 - f1-score: 0.7331For batch 62, tr_loss is    0.41.\n",
      "     64/Unknown - 102s 884ms/step - loss: 0.4044 - iou_score: 0.5887 - f1-score: 0.7344For batch 63, tr_loss is    0.40.\n",
      "     65/Unknown - 103s 887ms/step - loss: 0.4042 - iou_score: 0.5889 - f1-score: 0.7345For batch 64, tr_loss is    0.40.\n",
      "     66/Unknown - 104s 889ms/step - loss: 0.4038 - iou_score: 0.5891 - f1-score: 0.7348For batch 65, tr_loss is    0.40.\n",
      "     67/Unknown - 105s 891ms/step - loss: 0.4028 - iou_score: 0.5906 - f1-score: 0.7360For batch 66, tr_loss is    0.40.\n",
      "     68/Unknown - 106s 892ms/step - loss: 0.4019 - iou_score: 0.5915 - f1-score: 0.7368For batch 67, tr_loss is    0.40.\n",
      "     69/Unknown - 107s 895ms/step - loss: 0.4025 - iou_score: 0.5908 - f1-score: 0.7363For batch 68, tr_loss is    0.40.\n",
      "     70/Unknown - 108s 892ms/step - loss: 0.4017 - iou_score: 0.5916 - f1-score: 0.7370For batch 69, tr_loss is    0.40.\n",
      "     71/Unknown - 108s 886ms/step - loss: 0.4013 - iou_score: 0.5920 - f1-score: 0.7374For batch 70, tr_loss is    0.40.\n",
      "     72/Unknown - 109s 885ms/step - loss: 0.4003 - iou_score: 0.5934 - f1-score: 0.7385For batch 71, tr_loss is    0.40.\n",
      "     73/Unknown - 110s 887ms/step - loss: 0.4001 - iou_score: 0.5935 - f1-score: 0.7386For batch 72, tr_loss is    0.40.\n",
      "     74/Unknown - 111s 889ms/step - loss: 0.4002 - iou_score: 0.5937 - f1-score: 0.7388For batch 73, tr_loss is    0.40.\n",
      "     75/Unknown - 112s 888ms/step - loss: 0.4000 - iou_score: 0.5936 - f1-score: 0.7388For batch 74, tr_loss is    0.40.\n",
      "     76/Unknown - 112s 882ms/step - loss: 0.3985 - iou_score: 0.5958 - f1-score: 0.7404For batch 75, tr_loss is    0.40.\n",
      "     77/Unknown - 113s 880ms/step - loss: 0.3976 - iou_score: 0.5968 - f1-score: 0.7412For batch 76, tr_loss is    0.40.\n",
      "     78/Unknown - 114s 881ms/step - loss: 0.3966 - iou_score: 0.5980 - f1-score: 0.7422For batch 77, tr_loss is    0.40.\n",
      "     79/Unknown - 115s 878ms/step - loss: 0.3959 - iou_score: 0.5986 - f1-score: 0.7427For batch 78, tr_loss is    0.40.\n",
      "     80/Unknown - 116s 882ms/step - loss: 0.3951 - iou_score: 0.5994 - f1-score: 0.7433For batch 79, tr_loss is    0.40.\n",
      "     81/Unknown - 117s 883ms/step - loss: 0.3949 - iou_score: 0.5997 - f1-score: 0.7436For batch 80, tr_loss is    0.39.\n",
      "     82/Unknown - 118s 885ms/step - loss: 0.3958 - iou_score: 0.5988 - f1-score: 0.7429For batch 81, tr_loss is    0.40.\n",
      "     83/Unknown - 119s 881ms/step - loss: 0.3946 - iou_score: 0.6002 - f1-score: 0.7440For batch 82, tr_loss is    0.39.\n",
      "     84/Unknown - 120s 883ms/step - loss: 0.3940 - iou_score: 0.6009 - f1-score: 0.7446For batch 83, tr_loss is    0.39.\n",
      "     85/Unknown - 120s 878ms/step - loss: 0.3933 - iou_score: 0.6018 - f1-score: 0.7454For batch 84, tr_loss is    0.39.\n",
      "     86/Unknown - 121s 876ms/step - loss: 0.3933 - iou_score: 0.6016 - f1-score: 0.7452For batch 85, tr_loss is    0.39.\n",
      "     87/Unknown - 122s 879ms/step - loss: 0.3927 - iou_score: 0.6023 - f1-score: 0.7458For batch 86, tr_loss is    0.39.\n",
      "     88/Unknown - 123s 881ms/step - loss: 0.3918 - iou_score: 0.6033 - f1-score: 0.7466For batch 87, tr_loss is    0.39.\n",
      "     89/Unknown - 123s 876ms/step - loss: 0.3918 - iou_score: 0.6033 - f1-score: 0.7467For batch 88, tr_loss is    0.39.\n",
      "     90/Unknown - 124s 878ms/step - loss: 0.3913 - iou_score: 0.6040 - f1-score: 0.7472For batch 89, tr_loss is    0.39.\n",
      "     91/Unknown - 125s 877ms/step - loss: 0.3922 - iou_score: 0.6028 - f1-score: 0.7463For batch 90, tr_loss is    0.39.\n",
      "     92/Unknown - 126s 874ms/step - loss: 0.3922 - iou_score: 0.6027 - f1-score: 0.7462For batch 91, tr_loss is    0.39.\n",
      "     93/Unknown - 126s 870ms/step - loss: 0.3910 - iou_score: 0.6044 - f1-score: 0.7475For batch 92, tr_loss is    0.39.\n",
      "     94/Unknown - 127s 869ms/step - loss: 0.3905 - iou_score: 0.6051 - f1-score: 0.7480For batch 93, tr_loss is    0.39.\n",
      "     95/Unknown - 128s 872ms/step - loss: 0.3906 - iou_score: 0.6049 - f1-score: 0.7479For batch 94, tr_loss is    0.39.\n",
      "     96/Unknown - 129s 874ms/step - loss: 0.3905 - iou_score: 0.6051 - f1-score: 0.7481For batch 95, tr_loss is    0.39.\n",
      "     97/Unknown - 130s 874ms/step - loss: 0.3897 - iou_score: 0.6059 - f1-score: 0.7488For batch 96, tr_loss is    0.39.\n",
      "     98/Unknown - 131s 870ms/step - loss: 0.3892 - iou_score: 0.6065 - f1-score: 0.7492For batch 97, tr_loss is    0.39.\n",
      "     99/Unknown - 132s 874ms/step - loss: 0.3885 - iou_score: 0.6073 - f1-score: 0.7499For batch 98, tr_loss is    0.39.\n",
      "    100/Unknown - 133s 871ms/step - loss: 0.3875 - iou_score: 0.6086 - f1-score: 0.7509For batch 99, tr_loss is    0.39.\n",
      "    101/Unknown - 133s 868ms/step - loss: 0.3873 - iou_score: 0.6090 - f1-score: 0.7512For batch 100, tr_loss is    0.39.\n",
      "    102/Unknown - 134s 872ms/step - loss: 0.3868 - iou_score: 0.6094 - f1-score: 0.7515For batch 101, tr_loss is    0.39.\n",
      "    103/Unknown - 135s 874ms/step - loss: 0.3863 - iou_score: 0.6100 - f1-score: 0.7520For batch 102, tr_loss is    0.39.\n",
      "    104/Unknown - 137s 876ms/step - loss: 0.3860 - iou_score: 0.6106 - f1-score: 0.7525For batch 103, tr_loss is    0.39.\n",
      "    105/Unknown - 138s 877ms/step - loss: 0.3857 - iou_score: 0.6109 - f1-score: 0.7528For batch 104, tr_loss is    0.39.\n",
      "    106/Unknown - 139s 878ms/step - loss: 0.3850 - iou_score: 0.6116 - f1-score: 0.7534For batch 105, tr_loss is    0.39.\n",
      "    107/Unknown - 140s 880ms/step - loss: 0.3844 - iou_score: 0.6123 - f1-score: 0.7539For batch 106, tr_loss is    0.38.\n",
      "    108/Unknown - 140s 876ms/step - loss: 0.3840 - iou_score: 0.6128 - f1-score: 0.7543For batch 107, tr_loss is    0.38.\n",
      "    109/Unknown - 141s 874ms/step - loss: 0.3846 - iou_score: 0.6120 - f1-score: 0.7537For batch 108, tr_loss is    0.38.\n",
      "    110/Unknown - 142s 876ms/step - loss: 0.3851 - iou_score: 0.6115 - f1-score: 0.7533For batch 109, tr_loss is    0.39.\n",
      "    111/Unknown - 142s 873ms/step - loss: 0.3852 - iou_score: 0.6111 - f1-score: 0.7530For batch 110, tr_loss is    0.39.\n",
      "    112/Unknown - 143s 875ms/step - loss: 0.3850 - iou_score: 0.6114 - f1-score: 0.7533For batch 111, tr_loss is    0.38.\n",
      "    113/Unknown - 144s 876ms/step - loss: 0.3846 - iou_score: 0.6120 - f1-score: 0.7538For batch 112, tr_loss is    0.38.\n",
      "    114/Unknown - 145s 877ms/step - loss: 0.3846 - iou_score: 0.6119 - f1-score: 0.7537For batch 113, tr_loss is    0.38.\n",
      "    115/Unknown - 146s 879ms/step - loss: 0.3842 - iou_score: 0.6125 - f1-score: 0.7542For batch 114, tr_loss is    0.38.\n",
      "    116/Unknown - 147s 876ms/step - loss: 0.3839 - iou_score: 0.6127 - f1-score: 0.7544For batch 115, tr_loss is    0.38.\n",
      "    117/Unknown - 148s 877ms/step - loss: 0.3840 - iou_score: 0.6125 - f1-score: 0.7542For batch 116, tr_loss is    0.38.\n",
      "    118/Unknown - 149s 876ms/step - loss: 0.3838 - iou_score: 0.6126 - f1-score: 0.7544For batch 117, tr_loss is    0.38.\n",
      "    119/Unknown - 149s 874ms/step - loss: 0.3834 - iou_score: 0.6131 - f1-score: 0.7548For batch 118, tr_loss is    0.38.\n",
      "    120/Unknown - 150s 875ms/step - loss: 0.3839 - iou_score: 0.6124 - f1-score: 0.7542For batch 119, tr_loss is    0.38.\n",
      "    121/Unknown - 151s 876ms/step - loss: 0.3831 - iou_score: 0.6134 - f1-score: 0.7550For batch 120, tr_loss is    0.38.\n",
      "    122/Unknown - 152s 873ms/step - loss: 0.3826 - iou_score: 0.6141 - f1-score: 0.7555For batch 121, tr_loss is    0.38.\n",
      "    123/Unknown - 153s 873ms/step - loss: 0.3830 - iou_score: 0.6137 - f1-score: 0.7552For batch 122, tr_loss is    0.38.\n",
      "    124/Unknown - 154s 875ms/step - loss: 0.3838 - iou_score: 0.6129 - f1-score: 0.7547For batch 123, tr_loss is    0.38.\n",
      "    125/Unknown - 155s 876ms/step - loss: 0.3833 - iou_score: 0.6136 - f1-score: 0.7552For batch 124, tr_loss is    0.38.\n",
      "    126/Unknown - 155s 873ms/step - loss: 0.3831 - iou_score: 0.6137 - f1-score: 0.7553For batch 125, tr_loss is    0.38.\n",
      "    127/Unknown - 156s 873ms/step - loss: 0.3830 - iou_score: 0.6137 - f1-score: 0.7553For batch 126, tr_loss is    0.38.\n",
      "    128/Unknown - 157s 874ms/step - loss: 0.3825 - iou_score: 0.6144 - f1-score: 0.7558For batch 127, tr_loss is    0.38.\n",
      "    129/Unknown - 158s 873ms/step - loss: 0.3823 - iou_score: 0.6145 - f1-score: 0.7560For batch 128, tr_loss is    0.38.\n",
      "    130/Unknown - 159s 874ms/step - loss: 0.3824 - iou_score: 0.6142 - f1-score: 0.7558For batch 129, tr_loss is    0.38.\n",
      "    131/Unknown - 160s 876ms/step - loss: 0.3817 - iou_score: 0.6150 - f1-score: 0.7564For batch 130, tr_loss is    0.38.\n",
      "    132/Unknown - 161s 877ms/step - loss: 0.3820 - iou_score: 0.6146 - f1-score: 0.7561For batch 131, tr_loss is    0.38.\n",
      "    133/Unknown - 162s 873ms/step - loss: 0.3817 - iou_score: 0.6150 - f1-score: 0.7564For batch 132, tr_loss is    0.38.\n",
      "    134/Unknown - 163s 875ms/step - loss: 0.3823 - iou_score: 0.6144 - f1-score: 0.7559For batch 133, tr_loss is    0.38.\n",
      "    135/Unknown - 163s 872ms/step - loss: 0.3823 - iou_score: 0.6143 - f1-score: 0.7559For batch 134, tr_loss is    0.38.\n",
      "    136/Unknown - 164s 871ms/step - loss: 0.3818 - iou_score: 0.6149 - f1-score: 0.7564For batch 135, tr_loss is    0.38.\n",
      "    137/Unknown - 165s 873ms/step - loss: 0.3813 - iou_score: 0.6154 - f1-score: 0.7568For batch 136, tr_loss is    0.38.\n",
      "    138/Unknown - 166s 874ms/step - loss: 0.3813 - iou_score: 0.6154 - f1-score: 0.7568For batch 137, tr_loss is    0.38.\n",
      "    139/Unknown - 167s 871ms/step - loss: 0.3813 - iou_score: 0.6153 - f1-score: 0.7568For batch 138, tr_loss is    0.38.\n",
      "    140/Unknown - 168s 874ms/step - loss: 0.3810 - iou_score: 0.6157 - f1-score: 0.7571For batch 139, tr_loss is    0.38.\n",
      "    141/Unknown - 169s 875ms/step - loss: 0.3808 - iou_score: 0.6158 - f1-score: 0.7572For batch 140, tr_loss is    0.38.\n",
      "    142/Unknown - 170s 875ms/step - loss: 0.3806 - iou_score: 0.6159 - f1-score: 0.7573For batch 141, tr_loss is    0.38.\n",
      "    143/Unknown - 171s 876ms/step - loss: 0.3800 - iou_score: 0.6168 - f1-score: 0.7579For batch 142, tr_loss is    0.38.\n",
      "    144/Unknown - 171s 873ms/step - loss: 0.3802 - iou_score: 0.6165 - f1-score: 0.7578For batch 143, tr_loss is    0.38.\n",
      "    145/Unknown - 172s 875ms/step - loss: 0.3801 - iou_score: 0.6166 - f1-score: 0.7578For batch 144, tr_loss is    0.38.\n",
      "    146/Unknown - 173s 875ms/step - loss: 0.3800 - iou_score: 0.6167 - f1-score: 0.7579For batch 145, tr_loss is    0.38.\n",
      "    147/Unknown - 174s 876ms/step - loss: 0.3800 - iou_score: 0.6167 - f1-score: 0.7580For batch 146, tr_loss is    0.38.\n",
      "    148/Unknown - 175s 874ms/step - loss: 0.3799 - iou_score: 0.6167 - f1-score: 0.7580For batch 147, tr_loss is    0.38.\n",
      "    149/Unknown - 176s 874ms/step - loss: 0.3797 - iou_score: 0.6169 - f1-score: 0.7582For batch 148, tr_loss is    0.38.\n",
      "    150/Unknown - 177s 875ms/step - loss: 0.3795 - iou_score: 0.6171 - f1-score: 0.7584For batch 149, tr_loss is    0.38.\n",
      "    151/Unknown - 177s 872ms/step - loss: 0.3793 - iou_score: 0.6174 - f1-score: 0.7586For batch 150, tr_loss is    0.38.\n",
      "    152/Unknown - 178s 870ms/step - loss: 0.3797 - iou_score: 0.6171 - f1-score: 0.7584For batch 151, tr_loss is    0.38.\n",
      "    153/Unknown - 178s 869ms/step - loss: 0.3795 - iou_score: 0.6175 - f1-score: 0.7587For batch 152, tr_loss is    0.38.\n",
      "    154/Unknown - 180s 871ms/step - loss: 0.3793 - iou_score: 0.6177 - f1-score: 0.7589For batch 153, tr_loss is    0.38.\n",
      "    155/Unknown - 181s 872ms/step - loss: 0.3793 - iou_score: 0.6177 - f1-score: 0.7590For batch 154, tr_loss is    0.38.\n",
      "    156/Unknown - 181s 869ms/step - loss: 0.3788 - iou_score: 0.6183 - f1-score: 0.7594For batch 155, tr_loss is    0.38.\n",
      "    157/Unknown - 182s 870ms/step - loss: 0.3788 - iou_score: 0.6185 - f1-score: 0.7596For batch 156, tr_loss is    0.38.\n",
      "    158/Unknown - 183s 872ms/step - loss: 0.3787 - iou_score: 0.6186 - f1-score: 0.7597For batch 157, tr_loss is    0.38.\n",
      "    159/Unknown - 184s 872ms/step - loss: 0.3786 - iou_score: 0.6186 - f1-score: 0.7597For batch 158, tr_loss is    0.38.\n",
      "    160/Unknown - 185s 873ms/step - loss: 0.3783 - iou_score: 0.6188 - f1-score: 0.7599For batch 159, tr_loss is    0.38.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    161/Unknown - 186s 871ms/step - loss: 0.3785 - iou_score: 0.6186 - f1-score: 0.7597For batch 160, tr_loss is    0.38.\n",
      "    162/Unknown - 187s 873ms/step - loss: 0.3780 - iou_score: 0.6190 - f1-score: 0.7601For batch 161, tr_loss is    0.38.\n",
      "    163/Unknown - 188s 873ms/step - loss: 0.3780 - iou_score: 0.6192 - f1-score: 0.7602For batch 162, tr_loss is    0.38.\n",
      "    164/Unknown - 189s 874ms/step - loss: 0.3779 - iou_score: 0.6194 - f1-score: 0.7604For batch 163, tr_loss is    0.38.\n",
      "    165/Unknown - 190s 874ms/step - loss: 0.3782 - iou_score: 0.6191 - f1-score: 0.7602For batch 164, tr_loss is    0.38.\n",
      "    166/Unknown - 190s 872ms/step - loss: 0.3783 - iou_score: 0.6190 - f1-score: 0.7602For batch 165, tr_loss is    0.38.\n",
      "    167/Unknown - 191s 872ms/step - loss: 0.3780 - iou_score: 0.6195 - f1-score: 0.7606For batch 166, tr_loss is    0.38.\n",
      "    168/Unknown - 192s 870ms/step - loss: 0.3775 - iou_score: 0.6200 - f1-score: 0.7609For batch 167, tr_loss is    0.38.\n",
      "    169/Unknown - 192s 869ms/step - loss: 0.3770 - iou_score: 0.6207 - f1-score: 0.7614For batch 168, tr_loss is    0.38.\n",
      "    170/Unknown - 193s 870ms/step - loss: 0.3771 - iou_score: 0.6205 - f1-score: 0.7613For batch 169, tr_loss is    0.38.\n",
      "    171/Unknown - 194s 871ms/step - loss: 0.3769 - iou_score: 0.6207 - f1-score: 0.7614For batch 170, tr_loss is    0.38.\n",
      "    172/Unknown - 195s 872ms/step - loss: 0.3767 - iou_score: 0.6208 - f1-score: 0.7616For batch 171, tr_loss is    0.38.\n",
      "    173/Unknown - 196s 871ms/step - loss: 0.3767 - iou_score: 0.6208 - f1-score: 0.7616For batch 172, tr_loss is    0.38.\n",
      "    174/Unknown - 197s 872ms/step - loss: 0.3769 - iou_score: 0.6205 - f1-score: 0.7613For batch 173, tr_loss is    0.38.\n",
      "    175/Unknown - 198s 872ms/step - loss: 0.3770 - iou_score: 0.6203 - f1-score: 0.7612For batch 174, tr_loss is    0.38.\n",
      "    176/Unknown - 199s 873ms/step - loss: 0.3768 - iou_score: 0.6206 - f1-score: 0.7614For batch 175, tr_loss is    0.38.\n",
      "    177/Unknown - 200s 874ms/step - loss: 0.3763 - iou_score: 0.6212 - f1-score: 0.7619For batch 176, tr_loss is    0.38.\n",
      "    178/Unknown - 201s 875ms/step - loss: 0.3763 - iou_score: 0.6210 - f1-score: 0.7618For batch 177, tr_loss is    0.38.\n",
      "    179/Unknown - 202s 875ms/step - loss: 0.3760 - iou_score: 0.6214 - f1-score: 0.7621For batch 178, tr_loss is    0.38.\n",
      "    180/Unknown - 203s 874ms/step - loss: 0.3759 - iou_score: 0.6215 - f1-score: 0.7622For batch 179, tr_loss is    0.38.\n",
      "    181/Unknown - 204s 875ms/step - loss: 0.3754 - iou_score: 0.6219 - f1-score: 0.7625For batch 180, tr_loss is    0.38.\n",
      "    182/Unknown - 205s 876ms/step - loss: 0.3754 - iou_score: 0.6219 - f1-score: 0.7625For batch 181, tr_loss is    0.38.\n",
      "    183/Unknown - 206s 876ms/step - loss: 0.3754 - iou_score: 0.6220 - f1-score: 0.7626For batch 182, tr_loss is    0.38.\n",
      "    184/Unknown - 207s 877ms/step - loss: 0.3754 - iou_score: 0.6220 - f1-score: 0.7626For batch 183, tr_loss is    0.38.\n",
      "    185/Unknown - 208s 878ms/step - loss: 0.3754 - iou_score: 0.6219 - f1-score: 0.7626For batch 184, tr_loss is    0.38.\n",
      "    186/Unknown - 209s 879ms/step - loss: 0.3750 - iou_score: 0.6224 - f1-score: 0.7630For batch 185, tr_loss is    0.37.\n",
      "    187/Unknown - 210s 880ms/step - loss: 0.3752 - iou_score: 0.6221 - f1-score: 0.7627For batch 186, tr_loss is    0.38.\n",
      "    188/Unknown - 211s 880ms/step - loss: 0.3751 - iou_score: 0.6222 - f1-score: 0.7628For batch 187, tr_loss is    0.38.\n",
      "    189/Unknown - 212s 881ms/step - loss: 0.3748 - iou_score: 0.6225 - f1-score: 0.7631For batch 188, tr_loss is    0.37.\n",
      "    190/Unknown - 213s 882ms/step - loss: 0.3744 - iou_score: 0.6232 - f1-score: 0.7635For batch 189, tr_loss is    0.37.\n",
      "    191/Unknown - 214s 881ms/step - loss: 0.3741 - iou_score: 0.6235 - f1-score: 0.7638For batch 190, tr_loss is    0.37.\n",
      "    192/Unknown - 215s 882ms/step - loss: 0.3741 - iou_score: 0.6235 - f1-score: 0.7638For batch 191, tr_loss is    0.37.\n",
      "    193/Unknown - 216s 882ms/step - loss: 0.3740 - iou_score: 0.6233 - f1-score: 0.7637For batch 192, tr_loss is    0.37.\n",
      "    194/Unknown - 217s 883ms/step - loss: 0.3737 - iou_score: 0.6237 - f1-score: 0.7640For batch 193, tr_loss is    0.37.\n",
      "    195/Unknown - 217s 882ms/step - loss: 0.3735 - iou_score: 0.6239 - f1-score: 0.7641For batch 194, tr_loss is    0.37.\n",
      "    196/Unknown - 218s 882ms/step - loss: 0.3734 - iou_score: 0.6239 - f1-score: 0.7642For batch 195, tr_loss is    0.37.\n",
      "    197/Unknown - 219s 880ms/step - loss: 0.3736 - iou_score: 0.6237 - f1-score: 0.7641For batch 196, tr_loss is    0.37.\n",
      "    198/Unknown - 220s 881ms/step - loss: 0.3733 - iou_score: 0.6240 - f1-score: 0.7643For batch 197, tr_loss is    0.37.\n",
      "    199/Unknown - 221s 882ms/step - loss: 0.3728 - iou_score: 0.6246 - f1-score: 0.7647For batch 198, tr_loss is    0.37.\n",
      "    200/Unknown - 222s 883ms/step - loss: 0.3728 - iou_score: 0.6247 - f1-score: 0.7649For batch 199, tr_loss is    0.37.\n",
      "    201/Unknown - 223s 881ms/step - loss: 0.3730 - iou_score: 0.6244 - f1-score: 0.7646For batch 200, tr_loss is    0.37.\n",
      "    202/Unknown - 224s 882ms/step - loss: 0.3727 - iou_score: 0.6247 - f1-score: 0.7649For batch 201, tr_loss is    0.37.\n",
      "    203/Unknown - 224s 880ms/step - loss: 0.3726 - iou_score: 0.6249 - f1-score: 0.7650For batch 202, tr_loss is    0.37.\n",
      "    204/Unknown - 225s 881ms/step - loss: 0.3723 - iou_score: 0.6252 - f1-score: 0.7652For batch 203, tr_loss is    0.37.\n",
      "    205/Unknown - 226s 881ms/step - loss: 0.3718 - iou_score: 0.6259 - f1-score: 0.7657For batch 204, tr_loss is    0.37.\n",
      "    206/Unknown - 227s 881ms/step - loss: 0.3718 - iou_score: 0.6257 - f1-score: 0.7656For batch 205, tr_loss is    0.37.\n",
      "    207/Unknown - 227s 879ms/step - loss: 0.3713 - iou_score: 0.6261 - f1-score: 0.7659For batch 206, tr_loss is    0.37.\n",
      "    208/Unknown - 229s 880ms/step - loss: 0.3713 - iou_score: 0.6260 - f1-score: 0.7659For batch 207, tr_loss is    0.37.\n",
      "    209/Unknown - 229s 881ms/step - loss: 0.3711 - iou_score: 0.6262 - f1-score: 0.7660For batch 208, tr_loss is    0.37.\n",
      "    210/Unknown - 230s 879ms/step - loss: 0.3708 - iou_score: 0.6264 - f1-score: 0.7662For batch 209, tr_loss is    0.37.\n",
      "    211/Unknown - 231s 879ms/step - loss: 0.3708 - iou_score: 0.6265 - f1-score: 0.7663For batch 210, tr_loss is    0.37.\n",
      "    212/Unknown - 232s 879ms/step - loss: 0.3707 - iou_score: 0.6265 - f1-score: 0.7663For batch 211, tr_loss is    0.37.\n",
      "    213/Unknown - 233s 880ms/step - loss: 0.3709 - iou_score: 0.6265 - f1-score: 0.7663For batch 212, tr_loss is    0.37.\n",
      "    214/Unknown - 234s 880ms/step - loss: 0.3705 - iou_score: 0.6269 - f1-score: 0.7666For batch 213, tr_loss is    0.37.\n",
      "    215/Unknown - 235s 880ms/step - loss: 0.3703 - iou_score: 0.6272 - f1-score: 0.7668For batch 214, tr_loss is    0.37.\n",
      "    216/Unknown - 236s 881ms/step - loss: 0.3702 - iou_score: 0.6273 - f1-score: 0.7669For batch 215, tr_loss is    0.37.\n",
      "    217/Unknown - 237s 882ms/step - loss: 0.3700 - iou_score: 0.6275 - f1-score: 0.7671For batch 216, tr_loss is    0.37.\n",
      "    218/Unknown - 238s 882ms/step - loss: 0.3698 - iou_score: 0.6277 - f1-score: 0.7672For batch 217, tr_loss is    0.37.\n",
      "    219/Unknown - 238s 880ms/step - loss: 0.3696 - iou_score: 0.6278 - f1-score: 0.7673For batch 218, tr_loss is    0.37.\n",
      "    220/Unknown - 239s 879ms/step - loss: 0.3696 - iou_score: 0.6277 - f1-score: 0.7673For batch 219, tr_loss is    0.37.\n",
      "    221/Unknown - 240s 880ms/step - loss: 0.3695 - iou_score: 0.6277 - f1-score: 0.7673For batch 220, tr_loss is    0.37.\n",
      "    222/Unknown - 240s 878ms/step - loss: 0.3691 - iou_score: 0.6282 - f1-score: 0.7676For batch 221, tr_loss is    0.37.\n",
      "    223/Unknown - 241s 877ms/step - loss: 0.3690 - iou_score: 0.6282 - f1-score: 0.7677For batch 222, tr_loss is    0.37.\n",
      "    224/Unknown - 242s 878ms/step - loss: 0.3688 - iou_score: 0.6284 - f1-score: 0.7679For batch 223, tr_loss is    0.37.\n",
      "    225/Unknown - 243s 878ms/step - loss: 0.3687 - iou_score: 0.6286 - f1-score: 0.7680For batch 224, tr_loss is    0.37.\n",
      "    226/Unknown - 244s 879ms/step - loss: 0.3686 - iou_score: 0.6287 - f1-score: 0.7680For batch 225, tr_loss is    0.37.\n",
      "    227/Unknown - 245s 879ms/step - loss: 0.3684 - iou_score: 0.6290 - f1-score: 0.7683For batch 226, tr_loss is    0.37.\n",
      "    228/Unknown - 246s 879ms/step - loss: 0.3682 - iou_score: 0.6292 - f1-score: 0.7685For batch 227, tr_loss is    0.37.\n",
      "    229/Unknown - 247s 880ms/step - loss: 0.3678 - iou_score: 0.6296 - f1-score: 0.7688For batch 228, tr_loss is    0.37.\n",
      "    230/Unknown - 248s 879ms/step - loss: 0.3675 - iou_score: 0.6299 - f1-score: 0.7690For batch 229, tr_loss is    0.37.\n",
      "    231/Unknown - 249s 880ms/step - loss: 0.3672 - iou_score: 0.6302 - f1-score: 0.7692For batch 230, tr_loss is    0.37.\n",
      "    232/Unknown - 250s 881ms/step - loss: 0.3671 - iou_score: 0.6304 - f1-score: 0.7694For batch 231, tr_loss is    0.37.\n",
      "    233/Unknown - 251s 881ms/step - loss: 0.3676 - iou_score: 0.6300 - f1-score: 0.7691For batch 232, tr_loss is    0.37.\n",
      "    234/Unknown - 252s 882ms/step - loss: 0.3674 - iou_score: 0.6301 - f1-score: 0.7692For batch 233, tr_loss is    0.37.\n",
      "    235/Unknown - 253s 882ms/step - loss: 0.3672 - iou_score: 0.6305 - f1-score: 0.7694For batch 234, tr_loss is    0.37.\n",
      "    236/Unknown - 253s 880ms/step - loss: 0.3672 - iou_score: 0.6305 - f1-score: 0.7694For batch 235, tr_loss is    0.37.\n",
      "    237/Unknown - 254s 879ms/step - loss: 0.3671 - iou_score: 0.6305 - f1-score: 0.7695For batch 236, tr_loss is    0.37.\n",
      "    238/Unknown - 254s 877ms/step - loss: 0.3668 - iou_score: 0.6310 - f1-score: 0.7698For batch 237, tr_loss is    0.37.\n",
      "    239/Unknown - 254s 874ms/step - loss: 0.3667 - iou_score: 0.6311 - f1-score: 0.7699For batch 238, tr_loss is    0.37.\n",
      "    240/Unknown - 255s 872ms/step - loss: 0.3665 - iou_score: 0.6313 - f1-score: 0.7701For batch 239, tr_loss is    0.37.\n",
      "    241/Unknown - 255s 870ms/step - loss: 0.3663 - iou_score: 0.6315 - f1-score: 0.7702For batch 240, tr_loss is    0.37.\n",
      "    242/Unknown - 255s 868ms/step - loss: 0.3665 - iou_score: 0.6312 - f1-score: 0.7701For batch 241, tr_loss is    0.37.\n",
      "    243/Unknown - 256s 865ms/step - loss: 0.3667 - iou_score: 0.6310 - f1-score: 0.7699For batch 242, tr_loss is    0.37.\n",
      "    244/Unknown - 256s 863ms/step - loss: 0.3666 - iou_score: 0.6310 - f1-score: 0.7699For batch 243, tr_loss is    0.37.\n",
      "For batch 0, vl_loss is    0.75.\n",
      "For batch 1, vl_loss is    0.74.\n",
      "For batch 2, vl_loss is    0.66.\n",
      "For batch 3, vl_loss is    0.74.\n",
      "For batch 4, vl_loss is    0.71.\n",
      "For batch 5, vl_loss is    0.70.\n",
      "For batch 6, vl_loss is    0.74.\n",
      "For batch 7, vl_loss is    0.73.\n",
      "For batch 8, vl_loss is    0.73.\n",
      "For batch 9, vl_loss is    0.74.\n",
      "For batch 10, vl_loss is    0.73.\n",
      "For batch 11, vl_loss is    0.74.\n",
      "For batch 12, vl_loss is    0.74.\n",
      "For batch 13, vl_loss is    0.74.\n",
      "For batch 14, vl_loss is    0.75.\n",
      "For batch 15, vl_loss is    0.74.\n",
      "For batch 16, vl_loss is    0.74.\n",
      "For batch 17, vl_loss is    0.72.\n",
      "For batch 18, vl_loss is    0.74.\n",
      "For batch 19, vl_loss is    0.73.\n",
      "For batch 20, vl_loss is    0.73.\n",
      "For batch 21, vl_loss is    0.73.\n",
      "For batch 22, vl_loss is    0.73.\n",
      "For batch 23, vl_loss is    0.73.\n",
      "For batch 24, vl_loss is    0.72.\n",
      "For batch 25, vl_loss is    0.72.\n",
      "For batch 26, vl_loss is    0.73.\n",
      "For batch 27, vl_loss is    0.74.\n",
      "For batch 28, vl_loss is    0.75.\n",
      "For batch 29, vl_loss is    0.74.\n",
      "For batch 30, vl_loss is    0.74.\n",
      "For batch 31, vl_loss is    0.74.\n",
      "For batch 32, vl_loss is    0.74.\n",
      "For batch 33, vl_loss is    0.75.\n",
      "For batch 34, vl_loss is    0.74.\n",
      "For batch 35, vl_loss is    0.74.\n",
      "For batch 36, vl_loss is    0.73.\n",
      "For batch 37, vl_loss is    0.74.\n",
      "For batch 38, vl_loss is    0.74.\n",
      "For batch 39, vl_loss is    0.75.\n",
      "For batch 40, vl_loss is    0.74.\n",
      "For batch 41, vl_loss is    0.74.\n",
      "For batch 42, vl_loss is    0.74.\n",
      "For batch 43, vl_loss is    0.74.\n",
      "For batch 44, vl_loss is    0.73.\n",
      "For batch 45, vl_loss is    0.73.\n",
      "For batch 46, vl_loss is    0.73.\n",
      "For batch 47, vl_loss is    0.73.\n",
      "For batch 48, vl_loss is    0.73.\n",
      "For batch 49, vl_loss is    0.72.\n",
      "For batch 50, vl_loss is    0.73.\n",
      "For batch 51, vl_loss is    0.73.\n",
      "For batch 52, vl_loss is    0.73.\n",
      "For batch 53, vl_loss is    0.73.\n",
      "For batch 54, vl_loss is    0.73.\n",
      "For batch 55, vl_loss is    0.73.\n",
      "244/244 [==============================] - 267s 907ms/step - loss: 0.3666 - iou_score: 0.6310 - f1-score: 0.7699 - val_loss: 0.7339 - val_iou_score: 0.5657 - val_f1-score: 0.7196\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.73390, saving model to ./model/tumor_100_unet_efficientnetb0_imagenet_09292.hdf5\n",
      "The average loss for epoch 0 is    0.37 \n",
      "Epoch 2/200\n",
      "INFO:tensorflow:batch_all_reduce: 130 all-reduces with algorithm = nccl, num_packs = 1\n",
      "  1/244 [..............................] - ETA: 2:01:30 - loss: 0.4216 - iou_score: 0.5743 - f1-score: 0.7277For batch 0, tr_loss is    0.42.\n",
      "  2/244 [..............................] - ETA: 5:31 - loss: 0.3729 - iou_score: 0.6284 - f1-score: 0.7694   For batch 1, tr_loss is    0.37.\n",
      "  3/244 [..............................] - ETA: 5:07 - loss: 0.3685 - iou_score: 0.6377 - f1-score: 0.7765For batch 2, tr_loss is    0.37.\n",
      "  4/244 [..............................] - ETA: 5:25 - loss: 0.3603 - iou_score: 0.6459 - f1-score: 0.7829For batch 3, tr_loss is    0.36.\n",
      "  5/244 [..............................] - ETA: 5:26 - loss: 0.3572 - iou_score: 0.6486 - f1-score: 0.7847For batch 4, tr_loss is    0.36.\n",
      "  6/244 [..............................] - ETA: 5:33 - loss: 0.3646 - iou_score: 0.6400 - f1-score: 0.7785For batch 5, tr_loss is    0.36.\n",
      "  7/244 [..............................] - ETA: 5:18 - loss: 0.3568 - iou_score: 0.6500 - f1-score: 0.7854For batch 6, tr_loss is    0.36.\n",
      "  8/244 [..............................] - ETA: 5:18 - loss: 0.3600 - iou_score: 0.6439 - f1-score: 0.7809For batch 7, tr_loss is    0.36.\n",
      "  9/244 [>.............................] - ETA: 5:26 - loss: 0.3645 - iou_score: 0.6379 - f1-score: 0.7765For batch 8, tr_loss is    0.36.\n",
      " 10/244 [>.............................] - ETA: 5:15 - loss: 0.3603 - iou_score: 0.6431 - f1-score: 0.7805For batch 9, tr_loss is    0.36.\n",
      " 11/244 [>.............................] - ETA: 5:06 - loss: 0.3596 - iou_score: 0.6454 - f1-score: 0.7822For batch 10, tr_loss is    0.36.\n",
      " 12/244 [>.............................] - ETA: 4:47 - loss: 0.3572 - iou_score: 0.6487 - f1-score: 0.7848For batch 11, tr_loss is    0.36.\n",
      " 13/244 [>.............................] - ETA: 4:45 - loss: 0.3529 - iou_score: 0.6551 - f1-score: 0.7894For batch 12, tr_loss is    0.35.\n",
      " 14/244 [>.............................] - ETA: 4:40 - loss: 0.3567 - iou_score: 0.6495 - f1-score: 0.7852For batch 13, tr_loss is    0.36.\n",
      " 15/244 [>.............................] - ETA: 4:32 - loss: 0.3575 - iou_score: 0.6476 - f1-score: 0.7839For batch 14, tr_loss is    0.36.\n",
      " 16/244 [>.............................] - ETA: 4:29 - loss: 0.3573 - iou_score: 0.6471 - f1-score: 0.7836For batch 15, tr_loss is    0.36.\n",
      " 17/244 [=>............................] - ETA: 4:27 - loss: 0.3544 - iou_score: 0.6497 - f1-score: 0.7856For batch 16, tr_loss is    0.35.\n",
      " 18/244 [=>............................] - ETA: 4:20 - loss: 0.3564 - iou_score: 0.6470 - f1-score: 0.7837For batch 17, tr_loss is    0.36.\n",
      " 19/244 [=>............................] - ETA: 4:15 - loss: 0.3552 - iou_score: 0.6494 - f1-score: 0.7854For batch 18, tr_loss is    0.36.\n",
      " 20/244 [=>............................] - ETA: 4:08 - loss: 0.3551 - iou_score: 0.6491 - f1-score: 0.7850For batch 19, tr_loss is    0.36.\n",
      " 21/244 [=>............................] - ETA: 4:07 - loss: 0.3551 - iou_score: 0.6489 - f1-score: 0.7849For batch 20, tr_loss is    0.36.\n",
      " 22/244 [=>............................] - ETA: 4:05 - loss: 0.3572 - iou_score: 0.6471 - f1-score: 0.7835For batch 21, tr_loss is    0.36.\n",
      " 23/244 [=>............................] - ETA: 3:59 - loss: 0.3569 - iou_score: 0.6459 - f1-score: 0.7826For batch 22, tr_loss is    0.36.\n",
      " 24/244 [=>............................] - ETA: 3:53 - loss: 0.3536 - iou_score: 0.6493 - f1-score: 0.7852For batch 23, tr_loss is    0.35.\n",
      " 25/244 [==>...........................] - ETA: 3:50 - loss: 0.3538 - iou_score: 0.6479 - f1-score: 0.7842For batch 24, tr_loss is    0.35.\n",
      " 26/244 [==>...........................] - ETA: 3:48 - loss: 0.3542 - iou_score: 0.6469 - f1-score: 0.7834For batch 25, tr_loss is    0.35.\n",
      " 27/244 [==>...........................] - ETA: 3:47 - loss: 0.3532 - iou_score: 0.6470 - f1-score: 0.7836For batch 26, tr_loss is    0.35.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 28/244 [==>...........................] - ETA: 3:43 - loss: 0.3497 - iou_score: 0.6511 - f1-score: 0.7865For batch 27, tr_loss is    0.35.\n",
      " 29/244 [==>...........................] - ETA: 3:38 - loss: 0.3489 - iou_score: 0.6506 - f1-score: 0.7862For batch 28, tr_loss is    0.35.\n",
      " 30/244 [==>...........................] - ETA: 3:37 - loss: 0.3465 - iou_score: 0.6528 - f1-score: 0.7878For batch 29, tr_loss is    0.35.\n",
      " 31/244 [==>...........................] - ETA: 3:37 - loss: 0.3444 - iou_score: 0.6553 - f1-score: 0.7896For batch 30, tr_loss is    0.34.\n",
      " 32/244 [==>...........................] - ETA: 3:36 - loss: 0.3427 - iou_score: 0.6573 - f1-score: 0.7911For batch 31, tr_loss is    0.34.\n",
      " 33/244 [===>..........................] - ETA: 3:34 - loss: 0.3431 - iou_score: 0.6565 - f1-score: 0.7906For batch 32, tr_loss is    0.34.\n",
      " 34/244 [===>..........................] - ETA: 3:30 - loss: 0.3441 - iou_score: 0.6560 - f1-score: 0.7903For batch 33, tr_loss is    0.34.\n",
      " 35/244 [===>..........................] - ETA: 3:30 - loss: 0.3462 - iou_score: 0.6549 - f1-score: 0.7895For batch 34, tr_loss is    0.35.\n",
      " 36/244 [===>..........................] - ETA: 3:26 - loss: 0.3437 - iou_score: 0.6577 - f1-score: 0.7915For batch 35, tr_loss is    0.34.\n",
      " 37/244 [===>..........................] - ETA: 3:23 - loss: 0.3450 - iou_score: 0.6565 - f1-score: 0.7906For batch 36, tr_loss is    0.34.\n",
      " 38/244 [===>..........................] - ETA: 3:22 - loss: 0.3442 - iou_score: 0.6580 - f1-score: 0.7917For batch 37, tr_loss is    0.34.\n",
      " 39/244 [===>..........................] - ETA: 3:21 - loss: 0.3423 - iou_score: 0.6602 - f1-score: 0.7932For batch 38, tr_loss is    0.34.\n",
      " 40/244 [===>..........................] - ETA: 3:20 - loss: 0.3420 - iou_score: 0.6597 - f1-score: 0.7929For batch 39, tr_loss is    0.34.\n",
      " 41/244 [====>.........................] - ETA: 3:18 - loss: 0.3427 - iou_score: 0.6581 - f1-score: 0.7918For batch 40, tr_loss is    0.34.\n",
      " 42/244 [====>.........................] - ETA: 3:16 - loss: 0.3418 - iou_score: 0.6589 - f1-score: 0.7924For batch 41, tr_loss is    0.34.\n",
      " 43/244 [====>.........................] - ETA: 3:14 - loss: 0.3426 - iou_score: 0.6571 - f1-score: 0.7911For batch 42, tr_loss is    0.34.\n",
      " 44/244 [====>.........................] - ETA: 3:13 - loss: 0.3428 - iou_score: 0.6569 - f1-score: 0.7909For batch 43, tr_loss is    0.34.\n",
      " 45/244 [====>.........................] - ETA: 3:10 - loss: 0.3422 - iou_score: 0.6571 - f1-score: 0.7910For batch 44, tr_loss is    0.34.\n",
      " 46/244 [====>.........................] - ETA: 3:08 - loss: 0.3419 - iou_score: 0.6572 - f1-score: 0.7911For batch 45, tr_loss is    0.34.\n",
      " 47/244 [====>.........................] - ETA: 3:07 - loss: 0.3408 - iou_score: 0.6583 - f1-score: 0.7919For batch 46, tr_loss is    0.34.\n",
      " 48/244 [====>.........................] - ETA: 3:04 - loss: 0.3404 - iou_score: 0.6585 - f1-score: 0.7920For batch 47, tr_loss is    0.34.\n",
      " 49/244 [=====>........................] - ETA: 3:04 - loss: 0.3418 - iou_score: 0.6577 - f1-score: 0.7915For batch 48, tr_loss is    0.34.\n",
      " 50/244 [=====>........................] - ETA: 3:03 - loss: 0.3414 - iou_score: 0.6579 - f1-score: 0.7917For batch 49, tr_loss is    0.34.\n",
      " 51/244 [=====>........................] - ETA: 3:00 - loss: 0.3419 - iou_score: 0.6570 - f1-score: 0.7911For batch 50, tr_loss is    0.34.\n",
      " 52/244 [=====>........................] - ETA: 2:59 - loss: 0.3420 - iou_score: 0.6570 - f1-score: 0.7910For batch 51, tr_loss is    0.34.\n",
      " 53/244 [=====>........................] - ETA: 2:57 - loss: 0.3420 - iou_score: 0.6565 - f1-score: 0.7907For batch 52, tr_loss is    0.34.\n",
      " 54/244 [=====>........................] - ETA: 2:55 - loss: 0.3425 - iou_score: 0.6558 - f1-score: 0.7902For batch 53, tr_loss is    0.34.\n",
      " 55/244 [=====>........................] - ETA: 2:55 - loss: 0.3412 - iou_score: 0.6570 - f1-score: 0.7911For batch 54, tr_loss is    0.34.\n",
      " 56/244 [=====>........................] - ETA: 2:53 - loss: 0.3406 - iou_score: 0.6576 - f1-score: 0.7915For batch 55, tr_loss is    0.34.\n",
      " 57/244 [======>.......................] - ETA: 2:52 - loss: 0.3405 - iou_score: 0.6576 - f1-score: 0.7915For batch 56, tr_loss is    0.34.\n",
      " 58/244 [======>.......................] - ETA: 2:50 - loss: 0.3410 - iou_score: 0.6565 - f1-score: 0.7907For batch 57, tr_loss is    0.34.\n",
      " 59/244 [======>.......................] - ETA: 2:50 - loss: 0.3405 - iou_score: 0.6580 - f1-score: 0.7918For batch 58, tr_loss is    0.34.\n",
      " 60/244 [======>.......................] - ETA: 2:48 - loss: 0.3433 - iou_score: 0.6552 - f1-score: 0.7895For batch 59, tr_loss is    0.34.\n",
      " 61/244 [======>.......................] - ETA: 2:46 - loss: 0.3441 - iou_score: 0.6540 - f1-score: 0.7886For batch 60, tr_loss is    0.34.\n",
      " 62/244 [======>.......................] - ETA: 2:46 - loss: 0.3438 - iou_score: 0.6541 - f1-score: 0.7888For batch 61, tr_loss is    0.34.\n",
      " 63/244 [======>.......................] - ETA: 2:45 - loss: 0.3442 - iou_score: 0.6543 - f1-score: 0.7889For batch 62, tr_loss is    0.34.\n",
      " 64/244 [======>.......................] - ETA: 2:44 - loss: 0.3433 - iou_score: 0.6554 - f1-score: 0.7897For batch 63, tr_loss is    0.34.\n",
      " 65/244 [======>.......................] - ETA: 2:43 - loss: 0.3433 - iou_score: 0.6552 - f1-score: 0.7895For batch 64, tr_loss is    0.34.\n",
      " 66/244 [=======>......................] - ETA: 2:42 - loss: 0.3433 - iou_score: 0.6550 - f1-score: 0.7894For batch 65, tr_loss is    0.34.\n",
      " 67/244 [=======>......................] - ETA: 2:40 - loss: 0.3428 - iou_score: 0.6559 - f1-score: 0.7901For batch 66, tr_loss is    0.34.\n",
      " 68/244 [=======>......................] - ETA: 2:39 - loss: 0.3424 - iou_score: 0.6561 - f1-score: 0.7903For batch 67, tr_loss is    0.34.\n",
      " 69/244 [=======>......................] - ETA: 2:37 - loss: 0.3431 - iou_score: 0.6553 - f1-score: 0.7897For batch 68, tr_loss is    0.34.\n",
      " 70/244 [=======>......................] - ETA: 2:36 - loss: 0.3423 - iou_score: 0.6560 - f1-score: 0.7902For batch 69, tr_loss is    0.34.\n",
      " 71/244 [=======>......................] - ETA: 2:36 - loss: 0.3423 - iou_score: 0.6560 - f1-score: 0.7902For batch 70, tr_loss is    0.34.\n",
      " 72/244 [=======>......................] - ETA: 2:35 - loss: 0.3413 - iou_score: 0.6571 - f1-score: 0.7909For batch 71, tr_loss is    0.34.\n",
      " 73/244 [=======>......................] - ETA: 2:34 - loss: 0.3416 - iou_score: 0.6569 - f1-score: 0.7908For batch 72, tr_loss is    0.34.\n",
      " 74/244 [========>.....................] - ETA: 2:34 - loss: 0.3422 - iou_score: 0.6564 - f1-score: 0.7904For batch 73, tr_loss is    0.34.\n",
      " 75/244 [========>.....................] - ETA: 2:33 - loss: 0.3423 - iou_score: 0.6561 - f1-score: 0.7902For batch 74, tr_loss is    0.34.\n",
      " 76/244 [========>.....................] - ETA: 2:31 - loss: 0.3411 - iou_score: 0.6576 - f1-score: 0.7912For batch 75, tr_loss is    0.34.\n",
      " 77/244 [========>.....................] - ETA: 2:31 - loss: 0.3409 - iou_score: 0.6580 - f1-score: 0.7915For batch 76, tr_loss is    0.34.\n",
      " 78/244 [========>.....................] - ETA: 2:30 - loss: 0.3404 - iou_score: 0.6586 - f1-score: 0.7920For batch 77, tr_loss is    0.34.\n",
      " 79/244 [========>.....................] - ETA: 2:29 - loss: 0.3399 - iou_score: 0.6593 - f1-score: 0.7924For batch 78, tr_loss is    0.34.\n",
      " 80/244 [========>.....................] - ETA: 2:28 - loss: 0.3394 - iou_score: 0.6597 - f1-score: 0.7927For batch 79, tr_loss is    0.34.\n",
      " 81/244 [========>.....................] - ETA: 2:27 - loss: 0.3398 - iou_score: 0.6595 - f1-score: 0.7925For batch 80, tr_loss is    0.34.\n",
      " 82/244 [=========>....................] - ETA: 2:26 - loss: 0.3412 - iou_score: 0.6577 - f1-score: 0.7911For batch 81, tr_loss is    0.34.\n",
      " 83/244 [=========>....................] - ETA: 2:25 - loss: 0.3403 - iou_score: 0.6587 - f1-score: 0.7918For batch 82, tr_loss is    0.34.\n",
      " 84/244 [=========>....................] - ETA: 2:25 - loss: 0.3399 - iou_score: 0.6592 - f1-score: 0.7922For batch 83, tr_loss is    0.34.\n",
      " 85/244 [=========>....................] - ETA: 2:24 - loss: 0.3394 - iou_score: 0.6597 - f1-score: 0.7926For batch 84, tr_loss is    0.34.\n",
      " 86/244 [=========>....................] - ETA: 2:23 - loss: 0.3397 - iou_score: 0.6590 - f1-score: 0.7921For batch 85, tr_loss is    0.34.\n",
      " 87/244 [=========>....................] - ETA: 2:22 - loss: 0.3394 - iou_score: 0.6593 - f1-score: 0.7923For batch 86, tr_loss is    0.34.\n",
      " 88/244 [=========>....................] - ETA: 2:21 - loss: 0.3387 - iou_score: 0.6600 - f1-score: 0.7929For batch 87, tr_loss is    0.34.\n",
      " 89/244 [=========>....................] - ETA: 2:20 - loss: 0.3390 - iou_score: 0.6596 - f1-score: 0.7926For batch 88, tr_loss is    0.34.\n",
      " 90/244 [==========>...................] - ETA: 2:20 - loss: 0.3386 - iou_score: 0.6599 - f1-score: 0.7928For batch 89, tr_loss is    0.34.\n",
      " 91/244 [==========>...................] - ETA: 2:19 - loss: 0.3402 - iou_score: 0.6582 - f1-score: 0.7915For batch 90, tr_loss is    0.34.\n",
      " 92/244 [==========>...................] - ETA: 2:18 - loss: 0.3405 - iou_score: 0.6578 - f1-score: 0.7911For batch 91, tr_loss is    0.34.\n",
      " 93/244 [==========>...................] - ETA: 2:17 - loss: 0.3397 - iou_score: 0.6590 - f1-score: 0.7920For batch 92, tr_loss is    0.34.\n",
      " 94/244 [==========>...................] - ETA: 2:15 - loss: 0.3393 - iou_score: 0.6595 - f1-score: 0.7923For batch 93, tr_loss is    0.34.\n",
      " 95/244 [==========>...................] - ETA: 2:15 - loss: 0.3397 - iou_score: 0.6589 - f1-score: 0.7919For batch 94, tr_loss is    0.34.\n",
      " 96/244 [==========>...................] - ETA: 2:14 - loss: 0.3399 - iou_score: 0.6587 - f1-score: 0.7917For batch 95, tr_loss is    0.34.\n",
      " 97/244 [==========>...................] - ETA: 2:13 - loss: 0.3393 - iou_score: 0.6593 - f1-score: 0.7921For batch 96, tr_loss is    0.34.\n",
      " 98/244 [===========>..................] - ETA: 2:12 - loss: 0.3392 - iou_score: 0.6593 - f1-score: 0.7922For batch 97, tr_loss is    0.34.\n",
      " 99/244 [===========>..................] - ETA: 2:11 - loss: 0.3388 - iou_score: 0.6599 - f1-score: 0.7926For batch 98, tr_loss is    0.34.\n",
      "100/244 [===========>..................] - ETA: 2:11 - loss: 0.3379 - iou_score: 0.6609 - f1-score: 0.7933For batch 99, tr_loss is    0.34.\n",
      "101/244 [===========>..................] - ETA: 2:10 - loss: 0.3378 - iou_score: 0.6609 - f1-score: 0.7933For batch 100, tr_loss is    0.34.\n",
      "102/244 [===========>..................] - ETA: 2:09 - loss: 0.3374 - iou_score: 0.6612 - f1-score: 0.7935For batch 101, tr_loss is    0.34.\n",
      "103/244 [===========>..................] - ETA: 2:08 - loss: 0.3369 - iou_score: 0.6617 - f1-score: 0.7939For batch 102, tr_loss is    0.34.\n",
      "104/244 [===========>..................] - ETA: 2:07 - loss: 0.3365 - iou_score: 0.6621 - f1-score: 0.7942For batch 103, tr_loss is    0.34.\n",
      "105/244 [===========>..................] - ETA: 2:06 - loss: 0.3364 - iou_score: 0.6620 - f1-score: 0.7942For batch 104, tr_loss is    0.34.\n",
      "106/244 [============>.................] - ETA: 2:05 - loss: 0.3358 - iou_score: 0.6626 - f1-score: 0.7946For batch 105, tr_loss is    0.34.\n",
      "107/244 [============>.................] - ETA: 2:04 - loss: 0.3353 - iou_score: 0.6632 - f1-score: 0.7950For batch 106, tr_loss is    0.34.\n",
      "108/244 [============>.................] - ETA: 2:03 - loss: 0.3354 - iou_score: 0.6632 - f1-score: 0.7951For batch 107, tr_loss is    0.34.\n",
      "109/244 [============>.................] - ETA: 2:02 - loss: 0.3363 - iou_score: 0.6624 - f1-score: 0.7944For batch 108, tr_loss is    0.34.\n",
      "110/244 [============>.................] - ETA: 2:01 - loss: 0.3369 - iou_score: 0.6618 - f1-score: 0.7940For batch 109, tr_loss is    0.34.\n",
      "111/244 [============>.................] - ETA: 2:00 - loss: 0.3371 - iou_score: 0.6614 - f1-score: 0.7937For batch 110, tr_loss is    0.34.\n",
      "112/244 [============>.................] - ETA: 2:00 - loss: 0.3372 - iou_score: 0.6613 - f1-score: 0.7936For batch 111, tr_loss is    0.34.\n",
      "113/244 [============>.................] - ETA: 1:58 - loss: 0.3371 - iou_score: 0.6617 - f1-score: 0.7939For batch 112, tr_loss is    0.34.\n",
      "114/244 [=============>................] - ETA: 1:58 - loss: 0.3374 - iou_score: 0.6613 - f1-score: 0.7936For batch 113, tr_loss is    0.34.\n",
      "115/244 [=============>................] - ETA: 1:56 - loss: 0.3372 - iou_score: 0.6614 - f1-score: 0.7938For batch 114, tr_loss is    0.34.\n",
      "116/244 [=============>................] - ETA: 1:55 - loss: 0.3369 - iou_score: 0.6615 - f1-score: 0.7938For batch 115, tr_loss is    0.34.\n",
      "117/244 [=============>................] - ETA: 1:54 - loss: 0.3372 - iou_score: 0.6610 - f1-score: 0.7934For batch 116, tr_loss is    0.34.\n",
      "118/244 [=============>................] - ETA: 1:54 - loss: 0.3370 - iou_score: 0.6610 - f1-score: 0.7935For batch 117, tr_loss is    0.34.\n",
      "119/244 [=============>................] - ETA: 1:53 - loss: 0.3368 - iou_score: 0.6612 - f1-score: 0.7936For batch 118, tr_loss is    0.34.\n",
      "120/244 [=============>................] - ETA: 1:52 - loss: 0.3377 - iou_score: 0.6601 - f1-score: 0.7927For batch 119, tr_loss is    0.34.\n",
      "121/244 [=============>................] - ETA: 1:51 - loss: 0.3370 - iou_score: 0.6610 - f1-score: 0.7933For batch 120, tr_loss is    0.34.\n",
      "122/244 [==============>...............] - ETA: 1:50 - loss: 0.3366 - iou_score: 0.6615 - f1-score: 0.7937For batch 121, tr_loss is    0.34.\n",
      "123/244 [==============>...............] - ETA: 1:49 - loss: 0.3370 - iou_score: 0.6610 - f1-score: 0.7934For batch 122, tr_loss is    0.34.\n",
      "124/244 [==============>...............] - ETA: 1:48 - loss: 0.3378 - iou_score: 0.6601 - f1-score: 0.7927For batch 123, tr_loss is    0.34.\n",
      "125/244 [==============>...............] - ETA: 1:47 - loss: 0.3375 - iou_score: 0.6607 - f1-score: 0.7931For batch 124, tr_loss is    0.34.\n",
      "126/244 [==============>...............] - ETA: 1:46 - loss: 0.3374 - iou_score: 0.6607 - f1-score: 0.7932For batch 125, tr_loss is    0.34.\n",
      "127/244 [==============>...............] - ETA: 1:45 - loss: 0.3376 - iou_score: 0.6603 - f1-score: 0.7929For batch 126, tr_loss is    0.34.\n",
      "128/244 [==============>...............] - ETA: 1:44 - loss: 0.3372 - iou_score: 0.6609 - f1-score: 0.7933For batch 127, tr_loss is    0.34.\n",
      "129/244 [==============>...............] - ETA: 1:43 - loss: 0.3371 - iou_score: 0.6609 - f1-score: 0.7933For batch 128, tr_loss is    0.34.\n",
      "130/244 [==============>...............] - ETA: 1:42 - loss: 0.3372 - iou_score: 0.6607 - f1-score: 0.7931For batch 129, tr_loss is    0.34.\n",
      "131/244 [===============>..............] - ETA: 1:41 - loss: 0.3368 - iou_score: 0.6611 - f1-score: 0.7934For batch 130, tr_loss is    0.34.\n",
      "132/244 [===============>..............] - ETA: 1:40 - loss: 0.3371 - iou_score: 0.6607 - f1-score: 0.7931For batch 131, tr_loss is    0.34.\n",
      "133/244 [===============>..............] - ETA: 1:39 - loss: 0.3369 - iou_score: 0.6609 - f1-score: 0.7933For batch 132, tr_loss is    0.34.\n",
      "134/244 [===============>..............] - ETA: 1:38 - loss: 0.3376 - iou_score: 0.6601 - f1-score: 0.7927For batch 133, tr_loss is    0.34.\n",
      "135/244 [===============>..............] - ETA: 1:37 - loss: 0.3379 - iou_score: 0.6597 - f1-score: 0.7924For batch 134, tr_loss is    0.34.\n",
      "136/244 [===============>..............] - ETA: 1:36 - loss: 0.3374 - iou_score: 0.6603 - f1-score: 0.7928For batch 135, tr_loss is    0.34.\n",
      "137/244 [===============>..............] - ETA: 1:35 - loss: 0.3372 - iou_score: 0.6606 - f1-score: 0.7930For batch 136, tr_loss is    0.34.\n",
      "138/244 [===============>..............] - ETA: 1:35 - loss: 0.3373 - iou_score: 0.6605 - f1-score: 0.7930For batch 137, tr_loss is    0.34.\n",
      "139/244 [================>.............] - ETA: 1:33 - loss: 0.3374 - iou_score: 0.6602 - f1-score: 0.7928For batch 138, tr_loss is    0.34.\n",
      "140/244 [================>.............] - ETA: 1:33 - loss: 0.3373 - iou_score: 0.6603 - f1-score: 0.7929For batch 139, tr_loss is    0.34.\n",
      "141/244 [================>.............] - ETA: 1:32 - loss: 0.3371 - iou_score: 0.6604 - f1-score: 0.7930For batch 140, tr_loss is    0.34.\n",
      "142/244 [================>.............] - ETA: 1:31 - loss: 0.3370 - iou_score: 0.6603 - f1-score: 0.7929For batch 141, tr_loss is    0.34.\n",
      "143/244 [================>.............] - ETA: 1:30 - loss: 0.3366 - iou_score: 0.6609 - f1-score: 0.7933For batch 142, tr_loss is    0.34.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/244 [================>.............] - ETA: 1:29 - loss: 0.3371 - iou_score: 0.6606 - f1-score: 0.7930For batch 143, tr_loss is    0.34.\n",
      "145/244 [================>.............] - ETA: 1:28 - loss: 0.3371 - iou_score: 0.6604 - f1-score: 0.7929For batch 144, tr_loss is    0.34.\n",
      "146/244 [================>.............] - ETA: 1:27 - loss: 0.3371 - iou_score: 0.6603 - f1-score: 0.7928For batch 145, tr_loss is    0.34.\n",
      "147/244 [=================>............] - ETA: 1:26 - loss: 0.3372 - iou_score: 0.6600 - f1-score: 0.7927For batch 146, tr_loss is    0.34.\n",
      "148/244 [=================>............] - ETA: 1:25 - loss: 0.3374 - iou_score: 0.6597 - f1-score: 0.7925For batch 147, tr_loss is    0.34.\n",
      "149/244 [=================>............] - ETA: 1:24 - loss: 0.3374 - iou_score: 0.6597 - f1-score: 0.7925For batch 148, tr_loss is    0.34.\n",
      "150/244 [=================>............] - ETA: 1:23 - loss: 0.3373 - iou_score: 0.6598 - f1-score: 0.7925For batch 149, tr_loss is    0.34.\n",
      "151/244 [=================>............] - ETA: 1:22 - loss: 0.3373 - iou_score: 0.6599 - f1-score: 0.7926For batch 150, tr_loss is    0.34.\n",
      "152/244 [=================>............] - ETA: 1:21 - loss: 0.3377 - iou_score: 0.6596 - f1-score: 0.7924For batch 151, tr_loss is    0.34.\n",
      "153/244 [=================>............] - ETA: 1:20 - loss: 0.3376 - iou_score: 0.6599 - f1-score: 0.7926For batch 152, tr_loss is    0.34.\n",
      "154/244 [=================>............] - ETA: 1:19 - loss: 0.3375 - iou_score: 0.6600 - f1-score: 0.7927For batch 153, tr_loss is    0.34.\n",
      "155/244 [==================>...........] - ETA: 1:18 - loss: 0.3376 - iou_score: 0.6598 - f1-score: 0.7926For batch 154, tr_loss is    0.34.\n",
      "156/244 [==================>...........] - ETA: 1:17 - loss: 0.3372 - iou_score: 0.6604 - f1-score: 0.7930For batch 155, tr_loss is    0.34.\n",
      "157/244 [==================>...........] - ETA: 1:16 - loss: 0.3371 - iou_score: 0.6606 - f1-score: 0.7932For batch 156, tr_loss is    0.34.\n",
      "158/244 [==================>...........] - ETA: 1:16 - loss: 0.3371 - iou_score: 0.6606 - f1-score: 0.7932For batch 157, tr_loss is    0.34.\n",
      "159/244 [==================>...........] - ETA: 1:15 - loss: 0.3370 - iou_score: 0.6607 - f1-score: 0.7933For batch 158, tr_loss is    0.34.\n",
      "160/244 [==================>...........] - ETA: 1:14 - loss: 0.3369 - iou_score: 0.6609 - f1-score: 0.7935For batch 159, tr_loss is    0.34.\n",
      "161/244 [==================>...........] - ETA: 1:13 - loss: 0.3369 - iou_score: 0.6608 - f1-score: 0.7934For batch 160, tr_loss is    0.34.\n",
      "162/244 [==================>...........] - ETA: 1:12 - loss: 0.3367 - iou_score: 0.6610 - f1-score: 0.7936For batch 161, tr_loss is    0.34.\n",
      "163/244 [===================>..........] - ETA: 1:11 - loss: 0.3368 - iou_score: 0.6611 - f1-score: 0.7936For batch 162, tr_loss is    0.34.\n",
      "164/244 [===================>..........] - ETA: 1:10 - loss: 0.3365 - iou_score: 0.6613 - f1-score: 0.7938For batch 163, tr_loss is    0.34.\n",
      "165/244 [===================>..........] - ETA: 1:09 - loss: 0.3368 - iou_score: 0.6611 - f1-score: 0.7936For batch 164, tr_loss is    0.34.\n",
      "166/244 [===================>..........] - ETA: 1:08 - loss: 0.3372 - iou_score: 0.6608 - f1-score: 0.7934For batch 165, tr_loss is    0.34.\n",
      "167/244 [===================>..........] - ETA: 1:07 - loss: 0.3368 - iou_score: 0.6612 - f1-score: 0.7937For batch 166, tr_loss is    0.34.\n",
      "168/244 [===================>..........] - ETA: 1:06 - loss: 0.3364 - iou_score: 0.6616 - f1-score: 0.7940For batch 167, tr_loss is    0.34.\n",
      "169/244 [===================>..........] - ETA: 1:06 - loss: 0.3359 - iou_score: 0.6622 - f1-score: 0.7944For batch 168, tr_loss is    0.34.\n",
      "170/244 [===================>..........] - ETA: 1:05 - loss: 0.3362 - iou_score: 0.6619 - f1-score: 0.7942For batch 169, tr_loss is    0.34.\n",
      "171/244 [====================>.........] - ETA: 1:04 - loss: 0.3360 - iou_score: 0.6620 - f1-score: 0.7943For batch 170, tr_loss is    0.34.\n",
      "172/244 [====================>.........] - ETA: 1:03 - loss: 0.3360 - iou_score: 0.6620 - f1-score: 0.7943For batch 171, tr_loss is    0.34.\n",
      "173/244 [====================>.........] - ETA: 1:02 - loss: 0.3361 - iou_score: 0.6619 - f1-score: 0.7942For batch 172, tr_loss is    0.34.\n",
      "174/244 [====================>.........] - ETA: 1:01 - loss: 0.3363 - iou_score: 0.6615 - f1-score: 0.7939For batch 173, tr_loss is    0.34.\n",
      "175/244 [====================>.........] - ETA: 1:00 - loss: 0.3364 - iou_score: 0.6613 - f1-score: 0.7938For batch 174, tr_loss is    0.34.\n",
      "176/244 [====================>.........] - ETA: 1:00 - loss: 0.3363 - iou_score: 0.6614 - f1-score: 0.7939For batch 175, tr_loss is    0.34.\n",
      "177/244 [====================>.........] - ETA: 59s - loss: 0.3358 - iou_score: 0.6620 - f1-score: 0.7943 For batch 176, tr_loss is    0.34.\n",
      "178/244 [====================>.........] - ETA: 58s - loss: 0.3360 - iou_score: 0.6617 - f1-score: 0.7940For batch 177, tr_loss is    0.34.\n",
      "179/244 [=====================>........] - ETA: 57s - loss: 0.3357 - iou_score: 0.6620 - f1-score: 0.7942For batch 178, tr_loss is    0.34.\n",
      "180/244 [=====================>........] - ETA: 56s - loss: 0.3358 - iou_score: 0.6620 - f1-score: 0.7942For batch 179, tr_loss is    0.34.\n",
      "181/244 [=====================>........] - ETA: 55s - loss: 0.3355 - iou_score: 0.6623 - f1-score: 0.7944For batch 180, tr_loss is    0.34.\n",
      "182/244 [=====================>........] - ETA: 54s - loss: 0.3355 - iou_score: 0.6622 - f1-score: 0.7944For batch 181, tr_loss is    0.34.\n",
      "183/244 [=====================>........] - ETA: 53s - loss: 0.3356 - iou_score: 0.6622 - f1-score: 0.7944For batch 182, tr_loss is    0.34.\n",
      "184/244 [=====================>........] - ETA: 52s - loss: 0.3357 - iou_score: 0.6620 - f1-score: 0.7943For batch 183, tr_loss is    0.34.\n",
      "185/244 [=====================>........] - ETA: 51s - loss: 0.3358 - iou_score: 0.6619 - f1-score: 0.7942For batch 184, tr_loss is    0.34.\n",
      "186/244 [=====================>........] - ETA: 50s - loss: 0.3355 - iou_score: 0.6622 - f1-score: 0.7944For batch 185, tr_loss is    0.34.\n",
      "187/244 [=====================>........] - ETA: 49s - loss: 0.3358 - iou_score: 0.6618 - f1-score: 0.7941For batch 186, tr_loss is    0.34.\n",
      "188/244 [======================>.......] - ETA: 49s - loss: 0.3358 - iou_score: 0.6618 - f1-score: 0.7941For batch 187, tr_loss is    0.34.\n",
      "189/244 [======================>.......] - ETA: 48s - loss: 0.3356 - iou_score: 0.6620 - f1-score: 0.7943For batch 188, tr_loss is    0.34.\n",
      "190/244 [======================>.......] - ETA: 47s - loss: 0.3352 - iou_score: 0.6625 - f1-score: 0.7946For batch 189, tr_loss is    0.34.\n",
      "191/244 [======================>.......] - ETA: 46s - loss: 0.3349 - iou_score: 0.6628 - f1-score: 0.7949For batch 190, tr_loss is    0.33.\n",
      "192/244 [======================>.......] - ETA: 45s - loss: 0.3349 - iou_score: 0.6628 - f1-score: 0.7948For batch 191, tr_loss is    0.33.\n",
      "193/244 [======================>.......] - ETA: 44s - loss: 0.3350 - iou_score: 0.6625 - f1-score: 0.7946For batch 192, tr_loss is    0.34.\n",
      "194/244 [======================>.......] - ETA: 43s - loss: 0.3346 - iou_score: 0.6629 - f1-score: 0.7949For batch 193, tr_loss is    0.33.\n",
      "195/244 [======================>.......] - ETA: 42s - loss: 0.3346 - iou_score: 0.6630 - f1-score: 0.7950For batch 194, tr_loss is    0.33.\n",
      "196/244 [=======================>......] - ETA: 42s - loss: 0.3347 - iou_score: 0.6630 - f1-score: 0.7950For batch 195, tr_loss is    0.33.\n",
      "197/244 [=======================>......] - ETA: 41s - loss: 0.3349 - iou_score: 0.6627 - f1-score: 0.7948For batch 196, tr_loss is    0.33.\n",
      "198/244 [=======================>......] - ETA: 40s - loss: 0.3348 - iou_score: 0.6628 - f1-score: 0.7949For batch 197, tr_loss is    0.33.\n",
      "199/244 [=======================>......] - ETA: 39s - loss: 0.3343 - iou_score: 0.6633 - f1-score: 0.7952For batch 198, tr_loss is    0.33.\n",
      "200/244 [=======================>......] - ETA: 38s - loss: 0.3346 - iou_score: 0.6632 - f1-score: 0.7952For batch 199, tr_loss is    0.33.\n",
      "201/244 [=======================>......] - ETA: 37s - loss: 0.3346 - iou_score: 0.6631 - f1-score: 0.7951For batch 200, tr_loss is    0.33.\n",
      "202/244 [=======================>......] - ETA: 36s - loss: 0.3344 - iou_score: 0.6632 - f1-score: 0.7952For batch 201, tr_loss is    0.33.\n",
      "203/244 [=======================>......] - ETA: 35s - loss: 0.3342 - iou_score: 0.6634 - f1-score: 0.7953For batch 202, tr_loss is    0.33.\n",
      "204/244 [========================>.....] - ETA: 35s - loss: 0.3339 - iou_score: 0.6637 - f1-score: 0.7955For batch 203, tr_loss is    0.33.\n",
      "205/244 [========================>.....] - ETA: 34s - loss: 0.3334 - iou_score: 0.6642 - f1-score: 0.7959For batch 204, tr_loss is    0.33.\n",
      "206/244 [========================>.....] - ETA: 33s - loss: 0.3336 - iou_score: 0.6640 - f1-score: 0.7957For batch 205, tr_loss is    0.33.\n",
      "207/244 [========================>.....] - ETA: 32s - loss: 0.3332 - iou_score: 0.6642 - f1-score: 0.7959For batch 206, tr_loss is    0.33.\n",
      "208/244 [========================>.....] - ETA: 31s - loss: 0.3332 - iou_score: 0.6641 - f1-score: 0.7958For batch 207, tr_loss is    0.33.\n",
      "209/244 [========================>.....] - ETA: 30s - loss: 0.3330 - iou_score: 0.6642 - f1-score: 0.7959For batch 208, tr_loss is    0.33.\n",
      "210/244 [========================>.....] - ETA: 29s - loss: 0.3327 - iou_score: 0.6645 - f1-score: 0.7961For batch 209, tr_loss is    0.33.\n",
      "211/244 [========================>.....] - ETA: 28s - loss: 0.3326 - iou_score: 0.6646 - f1-score: 0.7962For batch 210, tr_loss is    0.33.\n",
      "212/244 [=========================>....] - ETA: 27s - loss: 0.3326 - iou_score: 0.6645 - f1-score: 0.7961For batch 211, tr_loss is    0.33.\n",
      "213/244 [=========================>....] - ETA: 27s - loss: 0.3329 - iou_score: 0.6644 - f1-score: 0.7961For batch 212, tr_loss is    0.33.\n",
      "214/244 [=========================>....] - ETA: 26s - loss: 0.3326 - iou_score: 0.6648 - f1-score: 0.7963For batch 213, tr_loss is    0.33.\n",
      "215/244 [=========================>....] - ETA: 25s - loss: 0.3325 - iou_score: 0.6649 - f1-score: 0.7964For batch 214, tr_loss is    0.33.\n",
      "216/244 [=========================>....] - ETA: 24s - loss: 0.3326 - iou_score: 0.6649 - f1-score: 0.7964For batch 215, tr_loss is    0.33.\n",
      "217/244 [=========================>....] - ETA: 23s - loss: 0.3326 - iou_score: 0.6650 - f1-score: 0.7965For batch 216, tr_loss is    0.33.\n",
      "218/244 [=========================>....] - ETA: 22s - loss: 0.3325 - iou_score: 0.6650 - f1-score: 0.7965For batch 217, tr_loss is    0.33.\n",
      "219/244 [=========================>....] - ETA: 21s - loss: 0.3324 - iou_score: 0.6651 - f1-score: 0.7966For batch 218, tr_loss is    0.33.\n",
      "220/244 [==========================>...] - ETA: 21s - loss: 0.3323 - iou_score: 0.6651 - f1-score: 0.7966For batch 219, tr_loss is    0.33.\n",
      "221/244 [==========================>...] - ETA: 20s - loss: 0.3324 - iou_score: 0.6650 - f1-score: 0.7965For batch 220, tr_loss is    0.33.\n",
      "222/244 [==========================>...] - ETA: 19s - loss: 0.3320 - iou_score: 0.6654 - f1-score: 0.7968For batch 221, tr_loss is    0.33.\n",
      "223/244 [==========================>...] - ETA: 18s - loss: 0.3320 - iou_score: 0.6653 - f1-score: 0.7967For batch 222, tr_loss is    0.33.\n",
      "224/244 [==========================>...] - ETA: 17s - loss: 0.3320 - iou_score: 0.6654 - f1-score: 0.7968For batch 223, tr_loss is    0.33.\n",
      "225/244 [==========================>...] - ETA: 16s - loss: 0.3319 - iou_score: 0.6654 - f1-score: 0.7968For batch 224, tr_loss is    0.33.\n",
      "226/244 [==========================>...] - ETA: 15s - loss: 0.3318 - iou_score: 0.6655 - f1-score: 0.7968For batch 225, tr_loss is    0.33.\n",
      "227/244 [==========================>...] - ETA: 14s - loss: 0.3317 - iou_score: 0.6656 - f1-score: 0.7969For batch 226, tr_loss is    0.33.\n",
      "228/244 [===========================>..] - ETA: 14s - loss: 0.3317 - iou_score: 0.6656 - f1-score: 0.7970For batch 227, tr_loss is    0.33.\n",
      "229/244 [===========================>..] - ETA: 13s - loss: 0.3313 - iou_score: 0.6660 - f1-score: 0.7972For batch 228, tr_loss is    0.33.\n",
      "230/244 [===========================>..] - ETA: 12s - loss: 0.3312 - iou_score: 0.6661 - f1-score: 0.7973For batch 229, tr_loss is    0.33.\n",
      "231/244 [===========================>..] - ETA: 11s - loss: 0.3309 - iou_score: 0.6663 - f1-score: 0.7975For batch 230, tr_loss is    0.33.\n",
      "232/244 [===========================>..] - ETA: 10s - loss: 0.3310 - iou_score: 0.6663 - f1-score: 0.7975For batch 231, tr_loss is    0.33.\n",
      "233/244 [===========================>..] - ETA: 9s - loss: 0.3315 - iou_score: 0.6658 - f1-score: 0.7971 For batch 232, tr_loss is    0.33.\n",
      "234/244 [===========================>..] - ETA: 8s - loss: 0.3315 - iou_score: 0.6657 - f1-score: 0.7970For batch 233, tr_loss is    0.33.\n",
      "235/244 [===========================>..] - ETA: 7s - loss: 0.3312 - iou_score: 0.6660 - f1-score: 0.7972For batch 234, tr_loss is    0.33.\n",
      "236/244 [============================>.] - ETA: 7s - loss: 0.3313 - iou_score: 0.6660 - f1-score: 0.7972For batch 235, tr_loss is    0.33.\n",
      "237/244 [============================>.] - ETA: 6s - loss: 0.3313 - iou_score: 0.6659 - f1-score: 0.7972For batch 236, tr_loss is    0.33.\n",
      "238/244 [============================>.] - ETA: 5s - loss: 0.3311 - iou_score: 0.6662 - f1-score: 0.7974For batch 237, tr_loss is    0.33.\n",
      "239/244 [============================>.] - ETA: 4s - loss: 0.3310 - iou_score: 0.6663 - f1-score: 0.7975For batch 238, tr_loss is    0.33.\n",
      "240/244 [============================>.] - ETA: 3s - loss: 0.3308 - iou_score: 0.6665 - f1-score: 0.7976For batch 239, tr_loss is    0.33.\n",
      "241/244 [============================>.] - ETA: 2s - loss: 0.3307 - iou_score: 0.6665 - f1-score: 0.7976For batch 240, tr_loss is    0.33.\n",
      "242/244 [============================>.] - ETA: 1s - loss: 0.3309 - iou_score: 0.6662 - f1-score: 0.7974For batch 241, tr_loss is    0.33.\n",
      "243/244 [============================>.] - ETA: 0s - loss: 0.3313 - iou_score: 0.6658 - f1-score: 0.7971For batch 242, tr_loss is    0.33.\n",
      "244/244 [==============================] - ETA: 0s - loss: 0.3312 - iou_score: 0.6658 - f1-score: 0.7971For batch 243, tr_loss is    0.33.\n",
      "For batch 0, vl_loss is    0.38.\n",
      "For batch 1, vl_loss is    0.36.\n",
      "For batch 2, vl_loss is    0.34.\n",
      "For batch 3, vl_loss is    0.38.\n",
      "For batch 4, vl_loss is    0.37.\n",
      "For batch 5, vl_loss is    0.37.\n",
      "For batch 6, vl_loss is    0.39.\n",
      "For batch 7, vl_loss is    0.38.\n",
      "For batch 8, vl_loss is    0.37.\n",
      "For batch 9, vl_loss is    0.38.\n",
      "For batch 10, vl_loss is    0.38.\n",
      "For batch 11, vl_loss is    0.38.\n",
      "For batch 12, vl_loss is    0.38.\n",
      "For batch 13, vl_loss is    0.38.\n",
      "For batch 14, vl_loss is    0.38.\n",
      "For batch 15, vl_loss is    0.38.\n",
      "For batch 16, vl_loss is    0.38.\n",
      "For batch 17, vl_loss is    0.38.\n",
      "For batch 18, vl_loss is    0.38.\n",
      "For batch 19, vl_loss is    0.38.\n",
      "For batch 20, vl_loss is    0.38.\n",
      "For batch 21, vl_loss is    0.38.\n",
      "For batch 22, vl_loss is    0.38.\n",
      "For batch 23, vl_loss is    0.37.\n",
      "For batch 24, vl_loss is    0.37.\n",
      "For batch 25, vl_loss is    0.37.\n",
      "For batch 26, vl_loss is    0.38.\n",
      "For batch 27, vl_loss is    0.38.\n",
      "For batch 28, vl_loss is    0.38.\n",
      "For batch 29, vl_loss is    0.38.\n",
      "For batch 30, vl_loss is    0.38.\n",
      "For batch 31, vl_loss is    0.38.\n",
      "For batch 32, vl_loss is    0.38.\n",
      "For batch 33, vl_loss is    0.38.\n",
      "For batch 34, vl_loss is    0.38.\n",
      "For batch 35, vl_loss is    0.38.\n",
      "For batch 36, vl_loss is    0.38.\n",
      "For batch 37, vl_loss is    0.38.\n",
      "For batch 38, vl_loss is    0.38.\n",
      "For batch 39, vl_loss is    0.38.\n",
      "For batch 40, vl_loss is    0.38.\n",
      "For batch 41, vl_loss is    0.38.\n",
      "For batch 42, vl_loss is    0.38.\n",
      "For batch 43, vl_loss is    0.38.\n",
      "For batch 44, vl_loss is    0.38.\n",
      "For batch 45, vl_loss is    0.38.\n",
      "For batch 46, vl_loss is    0.37.\n",
      "For batch 47, vl_loss is    0.37.\n",
      "For batch 48, vl_loss is    0.37.\n",
      "For batch 49, vl_loss is    0.37.\n",
      "For batch 50, vl_loss is    0.37.\n",
      "For batch 51, vl_loss is    0.37.\n",
      "For batch 52, vl_loss is    0.37.\n",
      "For batch 53, vl_loss is    0.37.\n",
      "For batch 54, vl_loss is    0.37.\n",
      "For batch 55, vl_loss is    0.38.\n",
      "244/244 [==============================] - 243s 879ms/step - loss: 0.3312 - iou_score: 0.6658 - f1-score: 0.7971 - val_loss: 0.3750 - val_iou_score: 0.6288 - val_f1-score: 0.7693\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.73390 to 0.37501, saving model to ./model/tumor_100_unet_efficientnetb0_imagenet_09292.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average loss for epoch 1 is    0.33 \n",
      "Epoch 3/200\n",
      "  1/244 [..............................] - ETA: 10:18 - loss: 0.3956 - iou_score: 0.5915 - f1-score: 0.7408For batch 0, tr_loss is    0.40.\n",
      "  2/244 [..............................] - ETA: 5:58 - loss: 0.3505 - iou_score: 0.6464 - f1-score: 0.7826 For batch 1, tr_loss is    0.35.\n",
      "  3/244 [..............................] - ETA: 5:23 - loss: 0.3489 - iou_score: 0.6502 - f1-score: 0.7860For batch 2, tr_loss is    0.35.\n",
      "  4/244 [..............................] - ETA: 4:46 - loss: 0.3383 - iou_score: 0.6611 - f1-score: 0.7942For batch 3, tr_loss is    0.34.\n",
      "  5/244 [..............................] - ETA: 5:10 - loss: 0.3361 - iou_score: 0.6640 - f1-score: 0.7964For batch 4, tr_loss is    0.34.\n",
      "  6/244 [..............................] - ETA: 4:59 - loss: 0.3384 - iou_score: 0.6614 - f1-score: 0.7947For batch 5, tr_loss is    0.34.\n",
      "  7/244 [..............................] - ETA: 5:17 - loss: 0.3327 - iou_score: 0.6687 - f1-score: 0.7997For batch 6, tr_loss is    0.33.\n",
      "  8/244 [..............................] - ETA: 5:13 - loss: 0.3375 - iou_score: 0.6606 - f1-score: 0.7936For batch 7, tr_loss is    0.34.\n",
      "  9/244 [>.............................] - ETA: 5:05 - loss: 0.3394 - iou_score: 0.6576 - f1-score: 0.7914For batch 8, tr_loss is    0.34.\n",
      " 10/244 [>.............................] - ETA: 4:58 - loss: 0.3334 - iou_score: 0.6650 - f1-score: 0.7967For batch 9, tr_loss is    0.33.\n",
      " 11/244 [>.............................] - ETA: 4:51 - loss: 0.3330 - iou_score: 0.6663 - f1-score: 0.7978For batch 10, tr_loss is    0.33.\n",
      " 12/244 [>.............................] - ETA: 4:46 - loss: 0.3317 - iou_score: 0.6680 - f1-score: 0.7991For batch 11, tr_loss is    0.33.\n",
      " 13/244 [>.............................] - ETA: 4:33 - loss: 0.3280 - iou_score: 0.6730 - f1-score: 0.8027For batch 12, tr_loss is    0.33.\n",
      " 14/244 [>.............................] - ETA: 4:21 - loss: 0.3322 - iou_score: 0.6679 - f1-score: 0.7990For batch 13, tr_loss is    0.33.\n",
      " 15/244 [>.............................] - ETA: 4:13 - loss: 0.3338 - iou_score: 0.6663 - f1-score: 0.7979For batch 14, tr_loss is    0.33.\n",
      " 16/244 [>.............................] - ETA: 4:11 - loss: 0.3339 - iou_score: 0.6662 - f1-score: 0.7978For batch 15, tr_loss is    0.33.\n",
      " 17/244 [=>............................] - ETA: 4:09 - loss: 0.3306 - iou_score: 0.6701 - f1-score: 0.8007For batch 16, tr_loss is    0.33.\n",
      " 18/244 [=>............................] - ETA: 4:07 - loss: 0.3329 - iou_score: 0.6680 - f1-score: 0.7992For batch 17, tr_loss is    0.33.\n",
      " 19/244 [=>............................] - ETA: 3:59 - loss: 0.3315 - iou_score: 0.6698 - f1-score: 0.8006For batch 18, tr_loss is    0.33.\n",
      " 20/244 [=>............................] - ETA: 3:55 - loss: 0.3321 - iou_score: 0.6694 - f1-score: 0.8001For batch 19, tr_loss is    0.33.\n",
      " 21/244 [=>............................] - ETA: 3:54 - loss: 0.3322 - iou_score: 0.6690 - f1-score: 0.7998For batch 20, tr_loss is    0.33.\n",
      " 22/244 [=>............................] - ETA: 3:52 - loss: 0.3348 - iou_score: 0.6665 - f1-score: 0.7979For batch 21, tr_loss is    0.33.\n",
      " 23/244 [=>............................] - ETA: 3:51 - loss: 0.3349 - iou_score: 0.6650 - f1-score: 0.7970For batch 22, tr_loss is    0.33.\n",
      " 24/244 [=>............................] - ETA: 3:49 - loss: 0.3316 - iou_score: 0.6681 - f1-score: 0.7992For batch 23, tr_loss is    0.33.\n",
      " 25/244 [==>...........................] - ETA: 3:48 - loss: 0.3319 - iou_score: 0.6668 - f1-score: 0.7982For batch 24, tr_loss is    0.33.\n",
      " 26/244 [==>...........................] - ETA: 3:43 - loss: 0.3319 - iou_score: 0.6656 - f1-score: 0.7974For batch 25, tr_loss is    0.33.\n",
      " 27/244 [==>...........................] - ETA: 3:38 - loss: 0.3309 - iou_score: 0.6672 - f1-score: 0.7986For batch 26, tr_loss is    0.33.\n",
      " 28/244 [==>...........................] - ETA: 3:36 - loss: 0.3277 - iou_score: 0.6710 - f1-score: 0.8012For batch 27, tr_loss is    0.33.\n",
      " 29/244 [==>...........................] - ETA: 3:32 - loss: 0.3263 - iou_score: 0.6718 - f1-score: 0.8018For batch 28, tr_loss is    0.33.\n",
      " 30/244 [==>...........................] - ETA: 3:28 - loss: 0.3236 - iou_score: 0.6749 - f1-score: 0.8040For batch 29, tr_loss is    0.32.\n",
      " 31/244 [==>...........................] - ETA: 3:28 - loss: 0.3214 - iou_score: 0.6771 - f1-score: 0.8055For batch 30, tr_loss is    0.32.\n",
      " 32/244 [==>...........................] - ETA: 3:25 - loss: 0.3202 - iou_score: 0.6788 - f1-score: 0.8068For batch 31, tr_loss is    0.32.\n",
      " 33/244 [===>..........................] - ETA: 3:22 - loss: 0.3200 - iou_score: 0.6784 - f1-score: 0.8065For batch 32, tr_loss is    0.32.\n",
      " 34/244 [===>..........................] - ETA: 3:21 - loss: 0.3204 - iou_score: 0.6783 - f1-score: 0.8065For batch 33, tr_loss is    0.32.\n",
      " 35/244 [===>..........................] - ETA: 3:21 - loss: 0.3215 - iou_score: 0.6773 - f1-score: 0.8058For batch 34, tr_loss is    0.32.\n",
      " 36/244 [===>..........................] - ETA: 3:20 - loss: 0.3195 - iou_score: 0.6795 - f1-score: 0.8074For batch 35, tr_loss is    0.32.\n",
      " 37/244 [===>..........................] - ETA: 3:16 - loss: 0.3210 - iou_score: 0.6781 - f1-score: 0.8064For batch 36, tr_loss is    0.32.\n",
      " 38/244 [===>..........................] - ETA: 3:15 - loss: 0.3200 - iou_score: 0.6795 - f1-score: 0.8074For batch 37, tr_loss is    0.32.\n",
      " 39/244 [===>..........................] - ETA: 3:13 - loss: 0.3184 - iou_score: 0.6815 - f1-score: 0.8087For batch 38, tr_loss is    0.32.\n",
      " 40/244 [===>..........................] - ETA: 3:12 - loss: 0.3183 - iou_score: 0.6809 - f1-score: 0.8083For batch 39, tr_loss is    0.32.\n",
      " 41/244 [====>.........................] - ETA: 3:12 - loss: 0.3189 - iou_score: 0.6793 - f1-score: 0.8072For batch 40, tr_loss is    0.32.\n",
      " 42/244 [====>.........................] - ETA: 3:11 - loss: 0.3180 - iou_score: 0.6797 - f1-score: 0.8075For batch 41, tr_loss is    0.32.\n",
      " 43/244 [====>.........................] - ETA: 3:11 - loss: 0.3192 - iou_score: 0.6776 - f1-score: 0.8060For batch 42, tr_loss is    0.32.\n",
      " 44/244 [====>.........................] - ETA: 3:09 - loss: 0.3194 - iou_score: 0.6776 - f1-score: 0.8060For batch 43, tr_loss is    0.32.\n",
      " 45/244 [====>.........................] - ETA: 3:06 - loss: 0.3194 - iou_score: 0.6776 - f1-score: 0.8060For batch 44, tr_loss is    0.32.\n",
      " 46/244 [====>.........................] - ETA: 3:06 - loss: 0.3189 - iou_score: 0.6779 - f1-score: 0.8062For batch 45, tr_loss is    0.32.\n",
      " 47/244 [====>.........................] - ETA: 3:06 - loss: 0.3176 - iou_score: 0.6793 - f1-score: 0.8072For batch 46, tr_loss is    0.32.\n",
      " 48/244 [====>.........................] - ETA: 3:05 - loss: 0.3170 - iou_score: 0.6796 - f1-score: 0.8074For batch 47, tr_loss is    0.32.\n",
      " 49/244 [=====>........................] - ETA: 3:02 - loss: 0.3179 - iou_score: 0.6787 - f1-score: 0.8068For batch 48, tr_loss is    0.32.\n",
      " 50/244 [=====>........................] - ETA: 3:02 - loss: 0.3177 - iou_score: 0.6788 - f1-score: 0.8069For batch 49, tr_loss is    0.32.\n",
      " 51/244 [=====>........................] - ETA: 2:59 - loss: 0.3189 - iou_score: 0.6776 - f1-score: 0.8061For batch 50, tr_loss is    0.32.\n",
      " 52/244 [=====>........................] - ETA: 2:58 - loss: 0.3191 - iou_score: 0.6775 - f1-score: 0.8060For batch 51, tr_loss is    0.32.\n",
      " 53/244 [=====>........................] - ETA: 2:57 - loss: 0.3191 - iou_score: 0.6770 - f1-score: 0.8057For batch 52, tr_loss is    0.32.\n",
      " 54/244 [=====>........................] - ETA: 2:55 - loss: 0.3197 - iou_score: 0.6764 - f1-score: 0.8053For batch 53, tr_loss is    0.32.\n",
      " 55/244 [=====>........................] - ETA: 2:53 - loss: 0.3183 - iou_score: 0.6780 - f1-score: 0.8064For batch 54, tr_loss is    0.32.\n",
      " 56/244 [=====>........................] - ETA: 2:51 - loss: 0.3179 - iou_score: 0.6786 - f1-score: 0.8068For batch 55, tr_loss is    0.32.\n",
      " 57/244 [======>.......................] - ETA: 2:50 - loss: 0.3187 - iou_score: 0.6780 - f1-score: 0.8064For batch 56, tr_loss is    0.32.\n",
      " 58/244 [======>.......................] - ETA: 2:48 - loss: 0.3195 - iou_score: 0.6768 - f1-score: 0.8055For batch 57, tr_loss is    0.32.\n",
      " 59/244 [======>.......................] - ETA: 2:46 - loss: 0.3189 - iou_score: 0.6783 - f1-score: 0.8066For batch 58, tr_loss is    0.32.\n",
      " 60/244 [======>.......................] - ETA: 2:46 - loss: 0.3207 - iou_score: 0.6759 - f1-score: 0.8047For batch 59, tr_loss is    0.32.\n",
      " 61/244 [======>.......................] - ETA: 2:44 - loss: 0.3217 - iou_score: 0.6745 - f1-score: 0.8037For batch 60, tr_loss is    0.32.\n",
      " 62/244 [======>.......................] - ETA: 2:44 - loss: 0.3213 - iou_score: 0.6747 - f1-score: 0.8038For batch 61, tr_loss is    0.32.\n",
      " 63/244 [======>.......................] - ETA: 2:42 - loss: 0.3217 - iou_score: 0.6746 - f1-score: 0.8038For batch 62, tr_loss is    0.32.\n",
      " 64/244 [======>.......................] - ETA: 2:41 - loss: 0.3211 - iou_score: 0.6754 - f1-score: 0.8044For batch 63, tr_loss is    0.32.\n",
      " 65/244 [======>.......................] - ETA: 2:41 - loss: 0.3211 - iou_score: 0.6752 - f1-score: 0.8042For batch 64, tr_loss is    0.32.\n",
      " 66/244 [=======>......................] - ETA: 2:39 - loss: 0.3209 - iou_score: 0.6753 - f1-score: 0.8043For batch 65, tr_loss is    0.32.\n",
      " 67/244 [=======>......................] - ETA: 2:39 - loss: 0.3207 - iou_score: 0.6759 - f1-score: 0.8047For batch 66, tr_loss is    0.32.\n",
      " 68/244 [=======>......................] - ETA: 2:38 - loss: 0.3203 - iou_score: 0.6763 - f1-score: 0.8051For batch 67, tr_loss is    0.32.\n",
      " 69/244 [=======>......................] - ETA: 2:37 - loss: 0.3210 - iou_score: 0.6753 - f1-score: 0.8043For batch 68, tr_loss is    0.32.\n",
      " 70/244 [=======>......................] - ETA: 2:37 - loss: 0.3204 - iou_score: 0.6757 - f1-score: 0.8046For batch 69, tr_loss is    0.32.\n",
      " 71/244 [=======>......................] - ETA: 2:35 - loss: 0.3204 - iou_score: 0.6757 - f1-score: 0.8046For batch 70, tr_loss is    0.32.\n",
      " 72/244 [=======>......................] - ETA: 2:35 - loss: 0.3197 - iou_score: 0.6765 - f1-score: 0.8051For batch 71, tr_loss is    0.32.\n",
      " 73/244 [=======>......................] - ETA: 2:33 - loss: 0.3201 - iou_score: 0.6761 - f1-score: 0.8048For batch 72, tr_loss is    0.32.\n",
      " 74/244 [========>.....................] - ETA: 2:32 - loss: 0.3209 - iou_score: 0.6754 - f1-score: 0.8043For batch 73, tr_loss is    0.32.\n",
      " 75/244 [========>.....................] - ETA: 2:30 - loss: 0.3209 - iou_score: 0.6753 - f1-score: 0.8042For batch 74, tr_loss is    0.32.\n",
      " 76/244 [========>.....................] - ETA: 2:29 - loss: 0.3201 - iou_score: 0.6763 - f1-score: 0.8049For batch 75, tr_loss is    0.32.\n",
      " 77/244 [========>.....................] - ETA: 2:29 - loss: 0.3201 - iou_score: 0.6762 - f1-score: 0.8049For batch 76, tr_loss is    0.32.\n",
      " 78/244 [========>.....................] - ETA: 2:27 - loss: 0.3197 - iou_score: 0.6769 - f1-score: 0.8054For batch 77, tr_loss is    0.32.\n",
      " 79/244 [========>.....................] - ETA: 2:26 - loss: 0.3194 - iou_score: 0.6774 - f1-score: 0.8057For batch 78, tr_loss is    0.32.\n",
      " 80/244 [========>.....................] - ETA: 2:25 - loss: 0.3189 - iou_score: 0.6778 - f1-score: 0.8060For batch 79, tr_loss is    0.32.\n",
      " 81/244 [========>.....................] - ETA: 2:23 - loss: 0.3189 - iou_score: 0.6777 - f1-score: 0.8059For batch 80, tr_loss is    0.32.\n",
      " 82/244 [=========>....................] - ETA: 2:22 - loss: 0.3204 - iou_score: 0.6760 - f1-score: 0.8045For batch 81, tr_loss is    0.32.\n",
      " 83/244 [=========>....................] - ETA: 2:22 - loss: 0.3195 - iou_score: 0.6769 - f1-score: 0.8052For batch 82, tr_loss is    0.32.\n",
      " 84/244 [=========>....................] - ETA: 2:21 - loss: 0.3194 - iou_score: 0.6771 - f1-score: 0.8054For batch 83, tr_loss is    0.32.\n",
      " 85/244 [=========>....................] - ETA: 2:21 - loss: 0.3187 - iou_score: 0.6777 - f1-score: 0.8057For batch 84, tr_loss is    0.32.\n",
      " 86/244 [=========>....................] - ETA: 2:19 - loss: 0.3191 - iou_score: 0.6771 - f1-score: 0.8053For batch 85, tr_loss is    0.32.\n",
      " 87/244 [=========>....................] - ETA: 2:18 - loss: 0.3189 - iou_score: 0.6774 - f1-score: 0.8055For batch 86, tr_loss is    0.32.\n",
      " 88/244 [=========>....................] - ETA: 2:17 - loss: 0.3184 - iou_score: 0.6779 - f1-score: 0.8059For batch 87, tr_loss is    0.32.\n",
      " 89/244 [=========>....................] - ETA: 2:17 - loss: 0.3187 - iou_score: 0.6773 - f1-score: 0.8055For batch 88, tr_loss is    0.32.\n",
      " 90/244 [==========>...................] - ETA: 2:15 - loss: 0.3184 - iou_score: 0.6775 - f1-score: 0.8057For batch 89, tr_loss is    0.32.\n",
      " 91/244 [==========>...................] - ETA: 2:15 - loss: 0.3195 - iou_score: 0.6762 - f1-score: 0.8047For batch 90, tr_loss is    0.32.\n",
      " 92/244 [==========>...................] - ETA: 2:14 - loss: 0.3200 - iou_score: 0.6755 - f1-score: 0.8042For batch 91, tr_loss is    0.32.\n",
      " 93/244 [==========>...................] - ETA: 2:13 - loss: 0.3193 - iou_score: 0.6765 - f1-score: 0.8049For batch 92, tr_loss is    0.32.\n",
      " 94/244 [==========>...................] - ETA: 2:12 - loss: 0.3189 - iou_score: 0.6769 - f1-score: 0.8051For batch 93, tr_loss is    0.32.\n",
      " 95/244 [==========>...................] - ETA: 2:12 - loss: 0.3193 - iou_score: 0.6763 - f1-score: 0.8046For batch 94, tr_loss is    0.32.\n",
      " 96/244 [==========>...................] - ETA: 2:11 - loss: 0.3195 - iou_score: 0.6761 - f1-score: 0.8045For batch 95, tr_loss is    0.32.\n",
      " 97/244 [==========>...................] - ETA: 2:10 - loss: 0.3190 - iou_score: 0.6766 - f1-score: 0.8049For batch 96, tr_loss is    0.32.\n",
      " 98/244 [===========>..................] - ETA: 2:09 - loss: 0.3190 - iou_score: 0.6766 - f1-score: 0.8049For batch 97, tr_loss is    0.32.\n",
      " 99/244 [===========>..................] - ETA: 2:08 - loss: 0.3189 - iou_score: 0.6771 - f1-score: 0.8052For batch 98, tr_loss is    0.32.\n",
      "100/244 [===========>..................] - ETA: 2:07 - loss: 0.3180 - iou_score: 0.6781 - f1-score: 0.8059For batch 99, tr_loss is    0.32.\n",
      "101/244 [===========>..................] - ETA: 2:07 - loss: 0.3180 - iou_score: 0.6780 - f1-score: 0.8058For batch 100, tr_loss is    0.32.\n",
      "102/244 [===========>..................] - ETA: 2:05 - loss: 0.3177 - iou_score: 0.6781 - f1-score: 0.8060For batch 101, tr_loss is    0.32.\n",
      "103/244 [===========>..................] - ETA: 2:04 - loss: 0.3173 - iou_score: 0.6786 - f1-score: 0.8063For batch 102, tr_loss is    0.32.\n",
      "104/244 [===========>..................] - ETA: 2:03 - loss: 0.3171 - iou_score: 0.6787 - f1-score: 0.8064For batch 103, tr_loss is    0.32.\n",
      "105/244 [===========>..................] - ETA: 2:02 - loss: 0.3173 - iou_score: 0.6785 - f1-score: 0.8063For batch 104, tr_loss is    0.32.\n",
      "106/244 [============>.................] - ETA: 2:01 - loss: 0.3167 - iou_score: 0.6792 - f1-score: 0.8068For batch 105, tr_loss is    0.32.\n",
      "107/244 [============>.................] - ETA: 2:00 - loss: 0.3162 - iou_score: 0.6797 - f1-score: 0.8071For batch 106, tr_loss is    0.32.\n",
      "108/244 [============>.................] - ETA: 1:59 - loss: 0.3159 - iou_score: 0.6799 - f1-score: 0.8073For batch 107, tr_loss is    0.32.\n",
      "109/244 [============>.................] - ETA: 1:58 - loss: 0.3168 - iou_score: 0.6790 - f1-score: 0.8066For batch 108, tr_loss is    0.32.\n",
      "110/244 [============>.................] - ETA: 1:57 - loss: 0.3174 - iou_score: 0.6785 - f1-score: 0.8062For batch 109, tr_loss is    0.32.\n",
      "111/244 [============>.................] - ETA: 1:57 - loss: 0.3173 - iou_score: 0.6782 - f1-score: 0.8060For batch 110, tr_loss is    0.32.\n",
      "112/244 [============>.................] - ETA: 1:56 - loss: 0.3173 - iou_score: 0.6782 - f1-score: 0.8060For batch 111, tr_loss is    0.32.\n",
      "113/244 [============>.................] - ETA: 1:55 - loss: 0.3173 - iou_score: 0.6785 - f1-score: 0.8062For batch 112, tr_loss is    0.32.\n",
      "114/244 [=============>................] - ETA: 1:54 - loss: 0.3178 - iou_score: 0.6777 - f1-score: 0.8057For batch 113, tr_loss is    0.32.\n",
      "115/244 [=============>................] - ETA: 1:53 - loss: 0.3176 - iou_score: 0.6779 - f1-score: 0.8058For batch 114, tr_loss is    0.32.\n",
      "116/244 [=============>................] - ETA: 1:52 - loss: 0.3173 - iou_score: 0.6781 - f1-score: 0.8059For batch 115, tr_loss is    0.32.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/244 [=============>................] - ETA: 1:51 - loss: 0.3176 - iou_score: 0.6775 - f1-score: 0.8055For batch 116, tr_loss is    0.32.\n",
      "118/244 [=============>................] - ETA: 1:50 - loss: 0.3175 - iou_score: 0.6775 - f1-score: 0.8055For batch 117, tr_loss is    0.32.\n",
      "119/244 [=============>................] - ETA: 1:49 - loss: 0.3174 - iou_score: 0.6776 - f1-score: 0.8056For batch 118, tr_loss is    0.32.\n",
      "120/244 [=============>................] - ETA: 1:48 - loss: 0.3184 - iou_score: 0.6765 - f1-score: 0.8047For batch 119, tr_loss is    0.32.\n",
      "121/244 [=============>................] - ETA: 1:47 - loss: 0.3178 - iou_score: 0.6773 - f1-score: 0.8052For batch 120, tr_loss is    0.32.\n",
      "122/244 [==============>...............] - ETA: 1:47 - loss: 0.3176 - iou_score: 0.6777 - f1-score: 0.8055For batch 121, tr_loss is    0.32.\n",
      "123/244 [==============>...............] - ETA: 1:46 - loss: 0.3184 - iou_score: 0.6769 - f1-score: 0.8050For batch 122, tr_loss is    0.32.\n",
      "124/244 [==============>...............] - ETA: 1:44 - loss: 0.3190 - iou_score: 0.6761 - f1-score: 0.8044For batch 123, tr_loss is    0.32.\n",
      "125/244 [==============>...............] - ETA: 1:44 - loss: 0.3188 - iou_score: 0.6766 - f1-score: 0.8047For batch 124, tr_loss is    0.32.\n",
      "126/244 [==============>...............] - ETA: 1:43 - loss: 0.3187 - iou_score: 0.6766 - f1-score: 0.8048For batch 125, tr_loss is    0.32.\n",
      "127/244 [==============>...............] - ETA: 1:42 - loss: 0.3188 - iou_score: 0.6762 - f1-score: 0.8045For batch 126, tr_loss is    0.32.\n",
      "128/244 [==============>...............] - ETA: 1:42 - loss: 0.3185 - iou_score: 0.6767 - f1-score: 0.8048For batch 127, tr_loss is    0.32.\n",
      "129/244 [==============>...............] - ETA: 1:41 - loss: 0.3183 - iou_score: 0.6768 - f1-score: 0.8049For batch 128, tr_loss is    0.32.\n",
      "130/244 [==============>...............] - ETA: 1:40 - loss: 0.3186 - iou_score: 0.6764 - f1-score: 0.8046For batch 129, tr_loss is    0.32.\n",
      "131/244 [===============>..............] - ETA: 1:39 - loss: 0.3182 - iou_score: 0.6769 - f1-score: 0.8049For batch 130, tr_loss is    0.32.\n",
      "132/244 [===============>..............] - ETA: 1:38 - loss: 0.3185 - iou_score: 0.6764 - f1-score: 0.8046For batch 131, tr_loss is    0.32.\n",
      "133/244 [===============>..............] - ETA: 1:38 - loss: 0.3184 - iou_score: 0.6765 - f1-score: 0.8046For batch 132, tr_loss is    0.32.\n",
      "134/244 [===============>..............] - ETA: 1:36 - loss: 0.3188 - iou_score: 0.6758 - f1-score: 0.8042For batch 133, tr_loss is    0.32.\n",
      "135/244 [===============>..............] - ETA: 1:36 - loss: 0.3189 - iou_score: 0.6755 - f1-score: 0.8039For batch 134, tr_loss is    0.32.\n",
      "136/244 [===============>..............] - ETA: 1:35 - loss: 0.3185 - iou_score: 0.6760 - f1-score: 0.8043For batch 135, tr_loss is    0.32.\n",
      "137/244 [===============>..............] - ETA: 1:34 - loss: 0.3182 - iou_score: 0.6763 - f1-score: 0.8045For batch 136, tr_loss is    0.32.\n",
      "138/244 [===============>..............] - ETA: 1:33 - loss: 0.3181 - iou_score: 0.6762 - f1-score: 0.8045For batch 137, tr_loss is    0.32.\n",
      "139/244 [================>.............] - ETA: 1:32 - loss: 0.3184 - iou_score: 0.6760 - f1-score: 0.8043For batch 138, tr_loss is    0.32.\n",
      "140/244 [================>.............] - ETA: 1:31 - loss: 0.3182 - iou_score: 0.6760 - f1-score: 0.8044For batch 139, tr_loss is    0.32.\n",
      "141/244 [================>.............] - ETA: 1:30 - loss: 0.3182 - iou_score: 0.6760 - f1-score: 0.8043For batch 140, tr_loss is    0.32.\n",
      "142/244 [================>.............] - ETA: 1:29 - loss: 0.3183 - iou_score: 0.6758 - f1-score: 0.8042For batch 141, tr_loss is    0.32.\n",
      "143/244 [================>.............] - ETA: 1:28 - loss: 0.3180 - iou_score: 0.6764 - f1-score: 0.8046For batch 142, tr_loss is    0.32.\n",
      "144/244 [================>.............] - ETA: 1:27 - loss: 0.3186 - iou_score: 0.6758 - f1-score: 0.8041For batch 143, tr_loss is    0.32.\n",
      "145/244 [================>.............] - ETA: 1:26 - loss: 0.3185 - iou_score: 0.6757 - f1-score: 0.8041For batch 144, tr_loss is    0.32.\n",
      "146/244 [================>.............] - ETA: 1:25 - loss: 0.3186 - iou_score: 0.6755 - f1-score: 0.8040For batch 145, tr_loss is    0.32.\n",
      "147/244 [=================>............] - ETA: 1:24 - loss: 0.3186 - iou_score: 0.6754 - f1-score: 0.8039For batch 146, tr_loss is    0.32.\n",
      "148/244 [=================>............] - ETA: 1:24 - loss: 0.3188 - iou_score: 0.6752 - f1-score: 0.8037For batch 147, tr_loss is    0.32.\n",
      "149/244 [=================>............] - ETA: 1:22 - loss: 0.3188 - iou_score: 0.6751 - f1-score: 0.8037For batch 148, tr_loss is    0.32.\n",
      "150/244 [=================>............] - ETA: 1:22 - loss: 0.3186 - iou_score: 0.6753 - f1-score: 0.8039For batch 149, tr_loss is    0.32.\n",
      "151/244 [=================>............] - ETA: 1:21 - loss: 0.3187 - iou_score: 0.6754 - f1-score: 0.8039For batch 150, tr_loss is    0.32.\n",
      "152/244 [=================>............] - ETA: 1:20 - loss: 0.3192 - iou_score: 0.6750 - f1-score: 0.8037For batch 151, tr_loss is    0.32.\n",
      "153/244 [=================>............] - ETA: 1:19 - loss: 0.3192 - iou_score: 0.6752 - f1-score: 0.8038For batch 152, tr_loss is    0.32.\n",
      "154/244 [=================>............] - ETA: 1:18 - loss: 0.3192 - iou_score: 0.6752 - f1-score: 0.8038For batch 153, tr_loss is    0.32.\n",
      "155/244 [==================>...........] - ETA: 1:17 - loss: 0.3193 - iou_score: 0.6751 - f1-score: 0.8037For batch 154, tr_loss is    0.32.\n",
      "156/244 [==================>...........] - ETA: 1:16 - loss: 0.3188 - iou_score: 0.6757 - f1-score: 0.8042For batch 155, tr_loss is    0.32.\n",
      "157/244 [==================>...........] - ETA: 1:15 - loss: 0.3188 - iou_score: 0.6758 - f1-score: 0.8042For batch 156, tr_loss is    0.32.\n",
      "158/244 [==================>...........] - ETA: 1:15 - loss: 0.3188 - iou_score: 0.6757 - f1-score: 0.8042For batch 157, tr_loss is    0.32.\n",
      "159/244 [==================>...........] - ETA: 1:14 - loss: 0.3187 - iou_score: 0.6758 - f1-score: 0.8043For batch 158, tr_loss is    0.32.\n",
      "160/244 [==================>...........] - ETA: 1:13 - loss: 0.3186 - iou_score: 0.6760 - f1-score: 0.8044For batch 159, tr_loss is    0.32.\n",
      "161/244 [==================>...........] - ETA: 1:12 - loss: 0.3187 - iou_score: 0.6758 - f1-score: 0.8043For batch 160, tr_loss is    0.32.\n",
      "162/244 [==================>...........] - ETA: 1:11 - loss: 0.3184 - iou_score: 0.6760 - f1-score: 0.8044For batch 161, tr_loss is    0.32.\n",
      "163/244 [===================>..........] - ETA: 1:10 - loss: 0.3187 - iou_score: 0.6759 - f1-score: 0.8044For batch 162, tr_loss is    0.32.\n",
      "164/244 [===================>..........] - ETA: 1:09 - loss: 0.3186 - iou_score: 0.6761 - f1-score: 0.8045For batch 163, tr_loss is    0.32.\n",
      "165/244 [===================>..........] - ETA: 1:08 - loss: 0.3188 - iou_score: 0.6759 - f1-score: 0.8043For batch 164, tr_loss is    0.32.\n",
      "166/244 [===================>..........] - ETA: 1:07 - loss: 0.3189 - iou_score: 0.6756 - f1-score: 0.8042For batch 165, tr_loss is    0.32.\n",
      "167/244 [===================>..........] - ETA: 1:07 - loss: 0.3186 - iou_score: 0.6761 - f1-score: 0.8045For batch 166, tr_loss is    0.32.\n",
      "168/244 [===================>..........] - ETA: 1:06 - loss: 0.3182 - iou_score: 0.6763 - f1-score: 0.8047For batch 167, tr_loss is    0.32.\n",
      "169/244 [===================>..........] - ETA: 1:05 - loss: 0.3178 - iou_score: 0.6768 - f1-score: 0.8050For batch 168, tr_loss is    0.32.\n",
      "170/244 [===================>..........] - ETA: 1:04 - loss: 0.3181 - iou_score: 0.6764 - f1-score: 0.8047For batch 169, tr_loss is    0.32.\n",
      "171/244 [====================>.........] - ETA: 1:03 - loss: 0.3178 - iou_score: 0.6766 - f1-score: 0.8049For batch 170, tr_loss is    0.32.\n",
      "172/244 [====================>.........] - ETA: 1:02 - loss: 0.3179 - iou_score: 0.6766 - f1-score: 0.8049For batch 171, tr_loss is    0.32.\n",
      "173/244 [====================>.........] - ETA: 1:02 - loss: 0.3181 - iou_score: 0.6764 - f1-score: 0.8048For batch 172, tr_loss is    0.32.\n",
      "174/244 [====================>.........] - ETA: 1:01 - loss: 0.3184 - iou_score: 0.6759 - f1-score: 0.8044For batch 173, tr_loss is    0.32.\n",
      "175/244 [====================>.........] - ETA: 1:00 - loss: 0.3185 - iou_score: 0.6757 - f1-score: 0.8042For batch 174, tr_loss is    0.32.\n",
      "176/244 [====================>.........] - ETA: 59s - loss: 0.3185 - iou_score: 0.6758 - f1-score: 0.8043 For batch 175, tr_loss is    0.32.\n",
      "177/244 [====================>.........] - ETA: 58s - loss: 0.3181 - iou_score: 0.6764 - f1-score: 0.8047For batch 176, tr_loss is    0.32.\n",
      "178/244 [====================>.........] - ETA: 57s - loss: 0.3183 - iou_score: 0.6759 - f1-score: 0.8043For batch 177, tr_loss is    0.32.\n",
      "179/244 [=====================>........] - ETA: 56s - loss: 0.3181 - iou_score: 0.6762 - f1-score: 0.8045For batch 178, tr_loss is    0.32.\n",
      "180/244 [=====================>........] - ETA: 55s - loss: 0.3181 - iou_score: 0.6761 - f1-score: 0.8045For batch 179, tr_loss is    0.32.\n",
      "181/244 [=====================>........] - ETA: 54s - loss: 0.3179 - iou_score: 0.6764 - f1-score: 0.8046For batch 180, tr_loss is    0.32.\n",
      "182/244 [=====================>........] - ETA: 54s - loss: 0.3180 - iou_score: 0.6763 - f1-score: 0.8046For batch 181, tr_loss is    0.32.\n",
      "183/244 [=====================>........] - ETA: 53s - loss: 0.3181 - iou_score: 0.6762 - f1-score: 0.8046For batch 182, tr_loss is    0.32.\n",
      "184/244 [=====================>........] - ETA: 52s - loss: 0.3184 - iou_score: 0.6759 - f1-score: 0.8043For batch 183, tr_loss is    0.32.\n",
      "185/244 [=====================>........] - ETA: 51s - loss: 0.3186 - iou_score: 0.6758 - f1-score: 0.8043For batch 184, tr_loss is    0.32.\n",
      "186/244 [=====================>........] - ETA: 50s - loss: 0.3183 - iou_score: 0.6761 - f1-score: 0.8045For batch 185, tr_loss is    0.32.\n",
      "187/244 [=====================>........] - ETA: 49s - loss: 0.3187 - iou_score: 0.6758 - f1-score: 0.8042For batch 186, tr_loss is    0.32.\n",
      "188/244 [======================>.......] - ETA: 48s - loss: 0.3186 - iou_score: 0.6757 - f1-score: 0.8042For batch 187, tr_loss is    0.32.\n",
      "189/244 [======================>.......] - ETA: 47s - loss: 0.3185 - iou_score: 0.6760 - f1-score: 0.8044For batch 188, tr_loss is    0.32.\n",
      "190/244 [======================>.......] - ETA: 46s - loss: 0.3181 - iou_score: 0.6765 - f1-score: 0.8048For batch 189, tr_loss is    0.32.\n",
      "191/244 [======================>.......] - ETA: 45s - loss: 0.3178 - iou_score: 0.6767 - f1-score: 0.8049For batch 190, tr_loss is    0.32.\n",
      "192/244 [======================>.......] - ETA: 44s - loss: 0.3179 - iou_score: 0.6766 - f1-score: 0.8048For batch 191, tr_loss is    0.32.\n",
      "193/244 [======================>.......] - ETA: 44s - loss: 0.3180 - iou_score: 0.6763 - f1-score: 0.8047For batch 192, tr_loss is    0.32.\n",
      "194/244 [======================>.......] - ETA: 43s - loss: 0.3177 - iou_score: 0.6766 - f1-score: 0.8048For batch 193, tr_loss is    0.32.\n",
      "195/244 [======================>.......] - ETA: 42s - loss: 0.3179 - iou_score: 0.6765 - f1-score: 0.8048For batch 194, tr_loss is    0.32.\n",
      "196/244 [=======================>......] - ETA: 41s - loss: 0.3178 - iou_score: 0.6765 - f1-score: 0.8048For batch 195, tr_loss is    0.32.\n",
      "197/244 [=======================>......] - ETA: 40s - loss: 0.3180 - iou_score: 0.6763 - f1-score: 0.8046For batch 196, tr_loss is    0.32.\n",
      "198/244 [=======================>......] - ETA: 39s - loss: 0.3178 - iou_score: 0.6764 - f1-score: 0.8047For batch 197, tr_loss is    0.32.\n",
      "199/244 [=======================>......] - ETA: 38s - loss: 0.3174 - iou_score: 0.6769 - f1-score: 0.8051For batch 198, tr_loss is    0.32.\n",
      "200/244 [=======================>......] - ETA: 38s - loss: 0.3174 - iou_score: 0.6769 - f1-score: 0.8051For batch 199, tr_loss is    0.32.\n",
      "201/244 [=======================>......] - ETA: 37s - loss: 0.3176 - iou_score: 0.6767 - f1-score: 0.8050For batch 200, tr_loss is    0.32.\n",
      "202/244 [=======================>......] - ETA: 36s - loss: 0.3173 - iou_score: 0.6769 - f1-score: 0.8051For batch 201, tr_loss is    0.32.\n",
      "203/244 [=======================>......] - ETA: 35s - loss: 0.3172 - iou_score: 0.6771 - f1-score: 0.8052For batch 202, tr_loss is    0.32.\n",
      "204/244 [========================>.....] - ETA: 34s - loss: 0.3168 - iou_score: 0.6775 - f1-score: 0.8055For batch 203, tr_loss is    0.32.\n",
      "205/244 [========================>.....] - ETA: 33s - loss: 0.3163 - iou_score: 0.6780 - f1-score: 0.8059For batch 204, tr_loss is    0.32.\n",
      "206/244 [========================>.....] - ETA: 32s - loss: 0.3164 - iou_score: 0.6778 - f1-score: 0.8057For batch 205, tr_loss is    0.32.\n",
      "207/244 [========================>.....] - ETA: 32s - loss: 0.3160 - iou_score: 0.6781 - f1-score: 0.8059For batch 206, tr_loss is    0.32.\n",
      "208/244 [========================>.....] - ETA: 31s - loss: 0.3160 - iou_score: 0.6778 - f1-score: 0.8057For batch 207, tr_loss is    0.32.\n",
      "209/244 [========================>.....] - ETA: 30s - loss: 0.3158 - iou_score: 0.6780 - f1-score: 0.8059For batch 208, tr_loss is    0.32.\n",
      "210/244 [========================>.....] - ETA: 29s - loss: 0.3154 - iou_score: 0.6784 - f1-score: 0.8062For batch 209, tr_loss is    0.32.\n",
      "211/244 [========================>.....] - ETA: 28s - loss: 0.3153 - iou_score: 0.6785 - f1-score: 0.8062For batch 210, tr_loss is    0.32.\n",
      "212/244 [=========================>....] - ETA: 27s - loss: 0.3154 - iou_score: 0.6784 - f1-score: 0.8062For batch 211, tr_loss is    0.32.\n",
      "213/244 [=========================>....] - ETA: 26s - loss: 0.3156 - iou_score: 0.6783 - f1-score: 0.8061For batch 212, tr_loss is    0.32.\n",
      "214/244 [=========================>....] - ETA: 26s - loss: 0.3153 - iou_score: 0.6786 - f1-score: 0.8063For batch 213, tr_loss is    0.32.\n",
      "215/244 [=========================>....] - ETA: 25s - loss: 0.3152 - iou_score: 0.6788 - f1-score: 0.8065For batch 214, tr_loss is    0.32.\n",
      "216/244 [=========================>....] - ETA: 24s - loss: 0.3154 - iou_score: 0.6787 - f1-score: 0.8064For batch 215, tr_loss is    0.32.\n",
      "217/244 [=========================>....] - ETA: 23s - loss: 0.3153 - iou_score: 0.6787 - f1-score: 0.8064For batch 216, tr_loss is    0.32.\n",
      "218/244 [=========================>....] - ETA: 22s - loss: 0.3152 - iou_score: 0.6788 - f1-score: 0.8065For batch 217, tr_loss is    0.32.\n",
      "219/244 [=========================>....] - ETA: 21s - loss: 0.3151 - iou_score: 0.6788 - f1-score: 0.8065For batch 218, tr_loss is    0.32.\n",
      "220/244 [==========================>...] - ETA: 20s - loss: 0.3151 - iou_score: 0.6787 - f1-score: 0.8064For batch 219, tr_loss is    0.32.\n",
      "221/244 [==========================>...] - ETA: 20s - loss: 0.3151 - iou_score: 0.6787 - f1-score: 0.8064For batch 220, tr_loss is    0.32.\n",
      "222/244 [==========================>...] - ETA: 19s - loss: 0.3148 - iou_score: 0.6790 - f1-score: 0.8066For batch 221, tr_loss is    0.31.\n",
      "223/244 [==========================>...] - ETA: 18s - loss: 0.3147 - iou_score: 0.6790 - f1-score: 0.8066For batch 222, tr_loss is    0.31.\n",
      "224/244 [==========================>...] - ETA: 17s - loss: 0.3147 - iou_score: 0.6791 - f1-score: 0.8067For batch 223, tr_loss is    0.31.\n",
      "225/244 [==========================>...] - ETA: 16s - loss: 0.3146 - iou_score: 0.6791 - f1-score: 0.8067For batch 224, tr_loss is    0.31.\n",
      "226/244 [==========================>...] - ETA: 15s - loss: 0.3145 - iou_score: 0.6792 - f1-score: 0.8068For batch 225, tr_loss is    0.31.\n",
      "227/244 [==========================>...] - ETA: 14s - loss: 0.3144 - iou_score: 0.6794 - f1-score: 0.8069For batch 226, tr_loss is    0.31.\n",
      "228/244 [===========================>..] - ETA: 13s - loss: 0.3144 - iou_score: 0.6794 - f1-score: 0.8069For batch 227, tr_loss is    0.31.\n",
      "229/244 [===========================>..] - ETA: 13s - loss: 0.3140 - iou_score: 0.6797 - f1-score: 0.8072For batch 228, tr_loss is    0.31.\n",
      "230/244 [===========================>..] - ETA: 12s - loss: 0.3139 - iou_score: 0.6798 - f1-score: 0.8073For batch 229, tr_loss is    0.31.\n",
      "231/244 [===========================>..] - ETA: 11s - loss: 0.3137 - iou_score: 0.6800 - f1-score: 0.8074For batch 230, tr_loss is    0.31.\n",
      "232/244 [===========================>..] - ETA: 10s - loss: 0.3136 - iou_score: 0.6800 - f1-score: 0.8074For batch 231, tr_loss is    0.31.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233/244 [===========================>..] - ETA: 9s - loss: 0.3142 - iou_score: 0.6795 - f1-score: 0.8070 For batch 232, tr_loss is    0.31.\n",
      "234/244 [===========================>..] - ETA: 8s - loss: 0.3142 - iou_score: 0.6795 - f1-score: 0.8070For batch 233, tr_loss is    0.31.\n",
      "235/244 [===========================>..] - ETA: 7s - loss: 0.3140 - iou_score: 0.6797 - f1-score: 0.8072For batch 234, tr_loss is    0.31.\n",
      "236/244 [============================>.] - ETA: 6s - loss: 0.3141 - iou_score: 0.6796 - f1-score: 0.8070For batch 235, tr_loss is    0.31.\n",
      "237/244 [============================>.] - ETA: 6s - loss: 0.3141 - iou_score: 0.6796 - f1-score: 0.8071For batch 236, tr_loss is    0.31.\n",
      "238/244 [============================>.] - ETA: 5s - loss: 0.3139 - iou_score: 0.6798 - f1-score: 0.8072For batch 237, tr_loss is    0.31.\n",
      "239/244 [============================>.] - ETA: 4s - loss: 0.3139 - iou_score: 0.6799 - f1-score: 0.8073For batch 238, tr_loss is    0.31.\n",
      "240/244 [============================>.] - ETA: 3s - loss: 0.3137 - iou_score: 0.6801 - f1-score: 0.8074For batch 239, tr_loss is    0.31.\n",
      "241/244 [============================>.] - ETA: 2s - loss: 0.3137 - iou_score: 0.6801 - f1-score: 0.8074For batch 240, tr_loss is    0.31.\n",
      "242/244 [============================>.] - ETA: 1s - loss: 0.3140 - iou_score: 0.6798 - f1-score: 0.8072For batch 241, tr_loss is    0.31.\n",
      "243/244 [============================>.] - ETA: 0s - loss: 0.3142 - iou_score: 0.6795 - f1-score: 0.8070For batch 242, tr_loss is    0.31.\n",
      "244/244 [==============================] - ETA: 0s - loss: 0.3142 - iou_score: 0.6795 - f1-score: 0.8070For batch 243, tr_loss is    0.31.\n",
      "For batch 0, vl_loss is    0.33.\n",
      "For batch 1, vl_loss is    0.34.\n",
      "For batch 2, vl_loss is    0.32.\n",
      "For batch 3, vl_loss is    0.35.\n",
      "For batch 4, vl_loss is    0.34.\n",
      "For batch 5, vl_loss is    0.34.\n",
      "For batch 6, vl_loss is    0.35.\n",
      "For batch 7, vl_loss is    0.35.\n",
      "For batch 8, vl_loss is    0.35.\n",
      "For batch 9, vl_loss is    0.35.\n",
      "For batch 10, vl_loss is    0.36.\n",
      "For batch 11, vl_loss is    0.36.\n",
      "For batch 12, vl_loss is    0.36.\n",
      "For batch 13, vl_loss is    0.36.\n",
      "For batch 14, vl_loss is    0.36.\n",
      "For batch 15, vl_loss is    0.36.\n",
      "For batch 16, vl_loss is    0.36.\n",
      "For batch 17, vl_loss is    0.35.\n",
      "For batch 18, vl_loss is    0.36.\n",
      "For batch 19, vl_loss is    0.35.\n",
      "For batch 20, vl_loss is    0.35.\n",
      "For batch 21, vl_loss is    0.35.\n",
      "For batch 22, vl_loss is    0.35.\n",
      "For batch 23, vl_loss is    0.35.\n",
      "For batch 24, vl_loss is    0.35.\n",
      "For batch 25, vl_loss is    0.35.\n",
      "For batch 26, vl_loss is    0.35.\n",
      "For batch 27, vl_loss is    0.36.\n",
      "For batch 28, vl_loss is    0.36.\n",
      "For batch 29, vl_loss is    0.36.\n",
      "For batch 30, vl_loss is    0.36.\n",
      "For batch 31, vl_loss is    0.36.\n",
      "For batch 32, vl_loss is    0.36.\n",
      "For batch 33, vl_loss is    0.36.\n",
      "For batch 34, vl_loss is    0.36.\n",
      "For batch 35, vl_loss is    0.36.\n",
      "For batch 36, vl_loss is    0.35.\n",
      "For batch 37, vl_loss is    0.36.\n",
      "For batch 38, vl_loss is    0.36.\n",
      "For batch 39, vl_loss is    0.36.\n",
      "For batch 40, vl_loss is    0.36.\n",
      "For batch 41, vl_loss is    0.36.\n",
      "For batch 42, vl_loss is    0.36.\n",
      "For batch 43, vl_loss is    0.35.\n",
      "For batch 44, vl_loss is    0.35.\n",
      "For batch 45, vl_loss is    0.35.\n",
      "For batch 46, vl_loss is    0.35.\n",
      "For batch 47, vl_loss is    0.35.\n",
      "For batch 48, vl_loss is    0.35.\n",
      "For batch 49, vl_loss is    0.35.\n",
      "For batch 50, vl_loss is    0.35.\n",
      "For batch 51, vl_loss is    0.35.\n",
      "For batch 52, vl_loss is    0.35.\n",
      "For batch 53, vl_loss is    0.35.\n",
      "For batch 54, vl_loss is    0.35.\n",
      "For batch 55, vl_loss is    0.35.\n",
      "244/244 [==============================] - 214s 871ms/step - loss: 0.3142 - iou_score: 0.6795 - f1-score: 0.8070 - val_loss: 0.3500 - val_iou_score: 0.6410 - val_f1-score: 0.7789\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.37501 to 0.34998, saving model to ./model/tumor_100_unet_efficientnetb0_imagenet_09292.hdf5\n",
      "The average loss for epoch 2 is    0.31 \n",
      "Epoch 4/200\n",
      "  1/244 [..............................] - ETA: 10:31 - loss: 0.3852 - iou_score: 0.5995 - f1-score: 0.7477For batch 0, tr_loss is    0.39.\n",
      "  2/244 [..............................] - ETA: 6:15 - loss: 0.3502 - iou_score: 0.6479 - f1-score: 0.7842 For batch 1, tr_loss is    0.35.\n",
      "  3/244 [..............................] - ETA: 6:01 - loss: 0.3380 - iou_score: 0.6616 - f1-score: 0.7947For batch 2, tr_loss is    0.34.\n",
      "  4/244 [..............................] - ETA: 5:25 - loss: 0.3369 - iou_score: 0.6665 - f1-score: 0.7985For batch 3, tr_loss is    0.34.\n",
      "  5/244 [..............................] - ETA: 5:20 - loss: 0.3301 - iou_score: 0.6727 - f1-score: 0.8028For batch 4, tr_loss is    0.33.\n",
      "  6/244 [..............................] - ETA: 5:08 - loss: 0.3366 - iou_score: 0.6649 - f1-score: 0.7973For batch 5, tr_loss is    0.34.\n",
      "  7/244 [..............................] - ETA: 4:48 - loss: 0.3302 - iou_score: 0.6709 - f1-score: 0.8014For batch 6, tr_loss is    0.33.\n",
      "  8/244 [..............................] - ETA: 4:44 - loss: 0.3321 - iou_score: 0.6646 - f1-score: 0.7966For batch 7, tr_loss is    0.33.\n",
      "  9/244 [>.............................] - ETA: 5:01 - loss: 0.3331 - iou_score: 0.6620 - f1-score: 0.7948For batch 8, tr_loss is    0.33.\n",
      " 10/244 [>.............................] - ETA: 4:55 - loss: 0.3283 - iou_score: 0.6684 - f1-score: 0.7994For batch 9, tr_loss is    0.33.\n",
      " 11/244 [>.............................] - ETA: 4:50 - loss: 0.3265 - iou_score: 0.6725 - f1-score: 0.8023For batch 10, tr_loss is    0.33.\n",
      " 12/244 [>.............................] - ETA: 4:43 - loss: 0.3248 - iou_score: 0.6753 - f1-score: 0.8044For batch 11, tr_loss is    0.32.\n",
      " 13/244 [>.............................] - ETA: 4:38 - loss: 0.3205 - iou_score: 0.6802 - f1-score: 0.8079For batch 12, tr_loss is    0.32.\n",
      " 14/244 [>.............................] - ETA: 4:34 - loss: 0.3258 - iou_score: 0.6737 - f1-score: 0.8031For batch 13, tr_loss is    0.33.\n",
      " 15/244 [>.............................] - ETA: 4:31 - loss: 0.3269 - iou_score: 0.6717 - f1-score: 0.8018For batch 14, tr_loss is    0.33.\n",
      " 16/244 [>.............................] - ETA: 4:22 - loss: 0.3273 - iou_score: 0.6718 - f1-score: 0.8019For batch 15, tr_loss is    0.33.\n",
      " 17/244 [=>............................] - ETA: 4:14 - loss: 0.3232 - iou_score: 0.6766 - f1-score: 0.8053For batch 16, tr_loss is    0.32.\n",
      " 18/244 [=>............................] - ETA: 4:06 - loss: 0.3243 - iou_score: 0.6756 - f1-score: 0.8046For batch 17, tr_loss is    0.32.\n",
      " 19/244 [=>............................] - ETA: 4:05 - loss: 0.3225 - iou_score: 0.6780 - f1-score: 0.8064For batch 18, tr_loss is    0.32.\n",
      " 20/244 [=>............................] - ETA: 3:59 - loss: 0.3221 - iou_score: 0.6780 - f1-score: 0.8063For batch 19, tr_loss is    0.32.\n",
      " 21/244 [=>............................] - ETA: 3:52 - loss: 0.3227 - iou_score: 0.6765 - f1-score: 0.8052For batch 20, tr_loss is    0.32.\n",
      " 22/244 [=>............................] - ETA: 3:49 - loss: 0.3253 - iou_score: 0.6738 - f1-score: 0.8033For batch 21, tr_loss is    0.33.\n",
      " 23/244 [=>............................] - ETA: 3:49 - loss: 0.3254 - iou_score: 0.6725 - f1-score: 0.8024For batch 22, tr_loss is    0.33.\n",
      " 24/244 [=>............................] - ETA: 3:48 - loss: 0.3218 - iou_score: 0.6759 - f1-score: 0.8048For batch 23, tr_loss is    0.32.\n",
      " 25/244 [==>...........................] - ETA: 3:43 - loss: 0.3216 - iou_score: 0.6746 - f1-score: 0.8039For batch 24, tr_loss is    0.32.\n",
      " 26/244 [==>...........................] - ETA: 3:41 - loss: 0.3226 - iou_score: 0.6726 - f1-score: 0.8024For batch 25, tr_loss is    0.32.\n",
      " 27/244 [==>...........................] - ETA: 3:36 - loss: 0.3211 - iou_score: 0.6739 - f1-score: 0.8034For batch 26, tr_loss is    0.32.\n",
      " 28/244 [==>...........................] - ETA: 3:36 - loss: 0.3180 - iou_score: 0.6782 - f1-score: 0.8063For batch 27, tr_loss is    0.32.\n",
      " 29/244 [==>...........................] - ETA: 3:36 - loss: 0.3161 - iou_score: 0.6791 - f1-score: 0.8070For batch 28, tr_loss is    0.32.\n",
      " 30/244 [==>...........................] - ETA: 3:35 - loss: 0.3136 - iou_score: 0.6822 - f1-score: 0.8092For batch 29, tr_loss is    0.31.\n",
      " 31/244 [==>...........................] - ETA: 3:30 - loss: 0.3119 - iou_score: 0.6843 - f1-score: 0.8106For batch 30, tr_loss is    0.31.\n",
      " 32/244 [==>...........................] - ETA: 3:30 - loss: 0.3098 - iou_score: 0.6867 - f1-score: 0.8123For batch 31, tr_loss is    0.31.\n",
      " 33/244 [===>..........................] - ETA: 3:26 - loss: 0.3095 - iou_score: 0.6863 - f1-score: 0.8121For batch 32, tr_loss is    0.31.\n",
      " 34/244 [===>..........................] - ETA: 3:26 - loss: 0.3097 - iou_score: 0.6860 - f1-score: 0.8119For batch 33, tr_loss is    0.31.\n",
      " 35/244 [===>..........................] - ETA: 3:25 - loss: 0.3111 - iou_score: 0.6848 - f1-score: 0.8111For batch 34, tr_loss is    0.31.\n",
      " 36/244 [===>..........................] - ETA: 3:21 - loss: 0.3093 - iou_score: 0.6866 - f1-score: 0.8124For batch 35, tr_loss is    0.31.\n",
      " 37/244 [===>..........................] - ETA: 3:18 - loss: 0.3102 - iou_score: 0.6853 - f1-score: 0.8114For batch 36, tr_loss is    0.31.\n",
      " 38/244 [===>..........................] - ETA: 3:18 - loss: 0.3096 - iou_score: 0.6866 - f1-score: 0.8124For batch 37, tr_loss is    0.31.\n",
      " 39/244 [===>..........................] - ETA: 3:16 - loss: 0.3082 - iou_score: 0.6882 - f1-score: 0.8135For batch 38, tr_loss is    0.31.\n",
      " 40/244 [===>..........................] - ETA: 3:12 - loss: 0.3085 - iou_score: 0.6872 - f1-score: 0.8128For batch 39, tr_loss is    0.31.\n",
      " 41/244 [====>.........................] - ETA: 3:11 - loss: 0.3094 - iou_score: 0.6851 - f1-score: 0.8113For batch 40, tr_loss is    0.31.\n",
      " 42/244 [====>.........................] - ETA: 3:09 - loss: 0.3081 - iou_score: 0.6859 - f1-score: 0.8119For batch 41, tr_loss is    0.31.\n",
      " 43/244 [====>.........................] - ETA: 3:07 - loss: 0.3092 - iou_score: 0.6837 - f1-score: 0.8103For batch 42, tr_loss is    0.31.\n",
      " 44/244 [====>.........................] - ETA: 3:07 - loss: 0.3090 - iou_score: 0.6840 - f1-score: 0.8104For batch 43, tr_loss is    0.31.\n",
      " 45/244 [====>.........................] - ETA: 3:06 - loss: 0.3088 - iou_score: 0.6840 - f1-score: 0.8104For batch 44, tr_loss is    0.31.\n",
      " 46/244 [====>.........................] - ETA: 3:04 - loss: 0.3083 - iou_score: 0.6841 - f1-score: 0.8105For batch 45, tr_loss is    0.31.\n",
      " 47/244 [====>.........................] - ETA: 3:04 - loss: 0.3071 - iou_score: 0.6852 - f1-score: 0.8113For batch 46, tr_loss is    0.31.\n",
      " 48/244 [====>.........................] - ETA: 3:03 - loss: 0.3060 - iou_score: 0.6858 - f1-score: 0.8117For batch 47, tr_loss is    0.31.\n",
      " 49/244 [=====>........................] - ETA: 3:03 - loss: 0.3074 - iou_score: 0.6848 - f1-score: 0.8111For batch 48, tr_loss is    0.31.\n",
      " 50/244 [=====>........................] - ETA: 3:02 - loss: 0.3077 - iou_score: 0.6848 - f1-score: 0.8111For batch 49, tr_loss is    0.31.\n",
      " 51/244 [=====>........................] - ETA: 2:59 - loss: 0.3086 - iou_score: 0.6840 - f1-score: 0.8106For batch 50, tr_loss is    0.31.\n",
      " 52/244 [=====>........................] - ETA: 2:59 - loss: 0.3091 - iou_score: 0.6838 - f1-score: 0.8104For batch 51, tr_loss is    0.31.\n",
      " 53/244 [=====>........................] - ETA: 2:58 - loss: 0.3092 - iou_score: 0.6831 - f1-score: 0.8099For batch 52, tr_loss is    0.31.\n",
      " 54/244 [=====>........................] - ETA: 2:55 - loss: 0.3099 - iou_score: 0.6823 - f1-score: 0.8093For batch 53, tr_loss is    0.31.\n",
      " 55/244 [=====>........................] - ETA: 2:53 - loss: 0.3084 - iou_score: 0.6836 - f1-score: 0.8103For batch 54, tr_loss is    0.31.\n",
      " 56/244 [=====>........................] - ETA: 2:53 - loss: 0.3082 - iou_score: 0.6843 - f1-score: 0.8107For batch 55, tr_loss is    0.31.\n",
      " 57/244 [======>.......................] - ETA: 2:52 - loss: 0.3088 - iou_score: 0.6837 - f1-score: 0.8104For batch 56, tr_loss is    0.31.\n",
      " 58/244 [======>.......................] - ETA: 2:52 - loss: 0.3095 - iou_score: 0.6826 - f1-score: 0.8096For batch 57, tr_loss is    0.31.\n",
      " 59/244 [======>.......................] - ETA: 2:50 - loss: 0.3088 - iou_score: 0.6843 - f1-score: 0.8107For batch 58, tr_loss is    0.31.\n",
      " 60/244 [======>.......................] - ETA: 2:48 - loss: 0.3114 - iou_score: 0.6814 - f1-score: 0.8085For batch 59, tr_loss is    0.31.\n",
      " 61/244 [======>.......................] - ETA: 2:46 - loss: 0.3123 - iou_score: 0.6799 - f1-score: 0.8074For batch 60, tr_loss is    0.31.\n",
      " 62/244 [======>.......................] - ETA: 2:45 - loss: 0.3121 - iou_score: 0.6800 - f1-score: 0.8075For batch 61, tr_loss is    0.31.\n",
      " 63/244 [======>.......................] - ETA: 2:44 - loss: 0.3125 - iou_score: 0.6798 - f1-score: 0.8074For batch 62, tr_loss is    0.31.\n",
      " 64/244 [======>.......................] - ETA: 2:43 - loss: 0.3120 - iou_score: 0.6806 - f1-score: 0.8079For batch 63, tr_loss is    0.31.\n",
      " 65/244 [======>.......................] - ETA: 2:42 - loss: 0.3122 - iou_score: 0.6801 - f1-score: 0.8076For batch 64, tr_loss is    0.31.\n",
      " 66/244 [=======>......................] - ETA: 2:40 - loss: 0.3123 - iou_score: 0.6800 - f1-score: 0.8075For batch 65, tr_loss is    0.31.\n",
      " 67/244 [=======>......................] - ETA: 2:40 - loss: 0.3119 - iou_score: 0.6808 - f1-score: 0.8081For batch 66, tr_loss is    0.31.\n",
      " 68/244 [=======>......................] - ETA: 2:39 - loss: 0.3116 - iou_score: 0.6811 - f1-score: 0.8083For batch 67, tr_loss is    0.31.\n",
      " 69/244 [=======>......................] - ETA: 2:38 - loss: 0.3122 - iou_score: 0.6801 - f1-score: 0.8076For batch 68, tr_loss is    0.31.\n",
      " 70/244 [=======>......................] - ETA: 2:36 - loss: 0.3117 - iou_score: 0.6805 - f1-score: 0.8079For batch 69, tr_loss is    0.31.\n",
      " 71/244 [=======>......................] - ETA: 2:35 - loss: 0.3116 - iou_score: 0.6806 - f1-score: 0.8080For batch 70, tr_loss is    0.31.\n",
      " 72/244 [=======>......................] - ETA: 2:34 - loss: 0.3109 - iou_score: 0.6813 - f1-score: 0.8084For batch 71, tr_loss is    0.31.\n",
      " 73/244 [=======>......................] - ETA: 2:34 - loss: 0.3113 - iou_score: 0.6809 - f1-score: 0.8082For batch 72, tr_loss is    0.31.\n",
      " 74/244 [========>.....................] - ETA: 2:33 - loss: 0.3117 - iou_score: 0.6804 - f1-score: 0.8078For batch 73, tr_loss is    0.31.\n",
      " 75/244 [========>.....................] - ETA: 2:32 - loss: 0.3115 - iou_score: 0.6803 - f1-score: 0.8077For batch 74, tr_loss is    0.31.\n",
      " 76/244 [========>.....................] - ETA: 2:30 - loss: 0.3105 - iou_score: 0.6818 - f1-score: 0.8087For batch 75, tr_loss is    0.31.\n",
      " 77/244 [========>.....................] - ETA: 2:29 - loss: 0.3113 - iou_score: 0.6816 - f1-score: 0.8086For batch 76, tr_loss is    0.31.\n",
      " 78/244 [========>.....................] - ETA: 2:28 - loss: 0.3109 - iou_score: 0.6821 - f1-score: 0.8090For batch 77, tr_loss is    0.31.\n",
      " 79/244 [========>.....................] - ETA: 2:28 - loss: 0.3108 - iou_score: 0.6826 - f1-score: 0.8093For batch 78, tr_loss is    0.31.\n",
      " 80/244 [========>.....................] - ETA: 2:27 - loss: 0.3102 - iou_score: 0.6830 - f1-score: 0.8096For batch 79, tr_loss is    0.31.\n",
      " 81/244 [========>.....................] - ETA: 2:26 - loss: 0.3104 - iou_score: 0.6830 - f1-score: 0.8095For batch 80, tr_loss is    0.31.\n",
      " 82/244 [=========>....................] - ETA: 2:25 - loss: 0.3116 - iou_score: 0.6813 - f1-score: 0.8082For batch 81, tr_loss is    0.31.\n",
      " 83/244 [=========>....................] - ETA: 2:24 - loss: 0.3107 - iou_score: 0.6823 - f1-score: 0.8089For batch 82, tr_loss is    0.31.\n",
      " 84/244 [=========>....................] - ETA: 2:24 - loss: 0.3102 - iou_score: 0.6827 - f1-score: 0.8093For batch 83, tr_loss is    0.31.\n",
      " 85/244 [=========>....................] - ETA: 2:22 - loss: 0.3095 - iou_score: 0.6834 - f1-score: 0.8097For batch 84, tr_loss is    0.31.\n",
      " 86/244 [=========>....................] - ETA: 2:22 - loss: 0.3100 - iou_score: 0.6829 - f1-score: 0.8093For batch 85, tr_loss is    0.31.\n",
      " 87/244 [=========>....................] - ETA: 2:21 - loss: 0.3098 - iou_score: 0.6830 - f1-score: 0.8094For batch 86, tr_loss is    0.31.\n",
      " 88/244 [=========>....................] - ETA: 2:20 - loss: 0.3091 - iou_score: 0.6838 - f1-score: 0.8100For batch 87, tr_loss is    0.31.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 89/244 [=========>....................] - ETA: 2:18 - loss: 0.3098 - iou_score: 0.6830 - f1-score: 0.8094For batch 88, tr_loss is    0.31.\n",
      " 90/244 [==========>...................] - ETA: 2:18 - loss: 0.3096 - iou_score: 0.6831 - f1-score: 0.8095For batch 89, tr_loss is    0.31.\n",
      " 91/244 [==========>...................] - ETA: 2:16 - loss: 0.3110 - iou_score: 0.6816 - f1-score: 0.8084For batch 90, tr_loss is    0.31.\n",
      " 92/244 [==========>...................] - ETA: 2:16 - loss: 0.3116 - iou_score: 0.6810 - f1-score: 0.8079For batch 91, tr_loss is    0.31.\n",
      " 93/244 [==========>...................] - ETA: 2:15 - loss: 0.3108 - iou_score: 0.6821 - f1-score: 0.8086For batch 92, tr_loss is    0.31.\n",
      " 94/244 [==========>...................] - ETA: 2:14 - loss: 0.3106 - iou_score: 0.6824 - f1-score: 0.8089For batch 93, tr_loss is    0.31.\n",
      " 95/244 [==========>...................] - ETA: 2:13 - loss: 0.3108 - iou_score: 0.6819 - f1-score: 0.8085For batch 94, tr_loss is    0.31.\n",
      " 96/244 [==========>...................] - ETA: 2:12 - loss: 0.3110 - iou_score: 0.6817 - f1-score: 0.8083For batch 95, tr_loss is    0.31.\n",
      " 97/244 [==========>...................] - ETA: 2:11 - loss: 0.3105 - iou_score: 0.6822 - f1-score: 0.8087For batch 96, tr_loss is    0.31.\n",
      " 98/244 [===========>..................] - ETA: 2:10 - loss: 0.3105 - iou_score: 0.6821 - f1-score: 0.8086For batch 97, tr_loss is    0.31.\n",
      " 99/244 [===========>..................] - ETA: 2:08 - loss: 0.3102 - iou_score: 0.6826 - f1-score: 0.8090For batch 98, tr_loss is    0.31.\n",
      "100/244 [===========>..................] - ETA: 2:07 - loss: 0.3096 - iou_score: 0.6834 - f1-score: 0.8095For batch 99, tr_loss is    0.31.\n",
      "101/244 [===========>..................] - ETA: 2:06 - loss: 0.3097 - iou_score: 0.6831 - f1-score: 0.8094For batch 100, tr_loss is    0.31.\n",
      "102/244 [===========>..................] - ETA: 2:05 - loss: 0.3093 - iou_score: 0.6834 - f1-score: 0.8095For batch 101, tr_loss is    0.31.\n",
      "103/244 [===========>..................] - ETA: 2:04 - loss: 0.3089 - iou_score: 0.6838 - f1-score: 0.8099For batch 102, tr_loss is    0.31.\n",
      "104/244 [===========>..................] - ETA: 2:03 - loss: 0.3087 - iou_score: 0.6840 - f1-score: 0.8100For batch 103, tr_loss is    0.31.\n",
      "105/244 [===========>..................] - ETA: 2:02 - loss: 0.3086 - iou_score: 0.6839 - f1-score: 0.8100For batch 104, tr_loss is    0.31.\n",
      "106/244 [============>.................] - ETA: 2:00 - loss: 0.3079 - iou_score: 0.6847 - f1-score: 0.8105For batch 105, tr_loss is    0.31.\n",
      "107/244 [============>.................] - ETA: 2:00 - loss: 0.3072 - iou_score: 0.6853 - f1-score: 0.8110For batch 106, tr_loss is    0.31.\n",
      "108/244 [============>.................] - ETA: 1:59 - loss: 0.3070 - iou_score: 0.6856 - f1-score: 0.8112For batch 107, tr_loss is    0.31.\n",
      "109/244 [============>.................] - ETA: 1:57 - loss: 0.3075 - iou_score: 0.6850 - f1-score: 0.8107For batch 108, tr_loss is    0.31.\n",
      "110/244 [============>.................] - ETA: 1:57 - loss: 0.3080 - iou_score: 0.6845 - f1-score: 0.8103For batch 109, tr_loss is    0.31.\n",
      "111/244 [============>.................] - ETA: 1:56 - loss: 0.3080 - iou_score: 0.6842 - f1-score: 0.8102For batch 110, tr_loss is    0.31.\n",
      "112/244 [============>.................] - ETA: 1:55 - loss: 0.3082 - iou_score: 0.6841 - f1-score: 0.8101For batch 111, tr_loss is    0.31.\n",
      "113/244 [============>.................] - ETA: 1:54 - loss: 0.3083 - iou_score: 0.6842 - f1-score: 0.8102For batch 112, tr_loss is    0.31.\n",
      "114/244 [=============>................] - ETA: 1:53 - loss: 0.3084 - iou_score: 0.6837 - f1-score: 0.8099For batch 113, tr_loss is    0.31.\n",
      "115/244 [=============>................] - ETA: 1:52 - loss: 0.3082 - iou_score: 0.6839 - f1-score: 0.8100For batch 114, tr_loss is    0.31.\n",
      "116/244 [=============>................] - ETA: 1:51 - loss: 0.3078 - iou_score: 0.6841 - f1-score: 0.8102For batch 115, tr_loss is    0.31.\n",
      "117/244 [=============>................] - ETA: 1:51 - loss: 0.3081 - iou_score: 0.6835 - f1-score: 0.8097For batch 116, tr_loss is    0.31.\n",
      "118/244 [=============>................] - ETA: 1:50 - loss: 0.3080 - iou_score: 0.6836 - f1-score: 0.8097For batch 117, tr_loss is    0.31.\n",
      "119/244 [=============>................] - ETA: 1:49 - loss: 0.3078 - iou_score: 0.6836 - f1-score: 0.8098For batch 118, tr_loss is    0.31.\n",
      "120/244 [=============>................] - ETA: 1:48 - loss: 0.3090 - iou_score: 0.6822 - f1-score: 0.8087For batch 119, tr_loss is    0.31.\n",
      "121/244 [=============>................] - ETA: 1:46 - loss: 0.3085 - iou_score: 0.6830 - f1-score: 0.8092For batch 120, tr_loss is    0.31.\n",
      "122/244 [==============>...............] - ETA: 1:46 - loss: 0.3080 - iou_score: 0.6834 - f1-score: 0.8095For batch 121, tr_loss is    0.31.\n",
      "123/244 [==============>...............] - ETA: 1:45 - loss: 0.3086 - iou_score: 0.6827 - f1-score: 0.8090For batch 122, tr_loss is    0.31.\n",
      "124/244 [==============>...............] - ETA: 1:44 - loss: 0.3093 - iou_score: 0.6819 - f1-score: 0.8084For batch 123, tr_loss is    0.31.\n",
      "125/244 [==============>...............] - ETA: 1:43 - loss: 0.3092 - iou_score: 0.6825 - f1-score: 0.8088For batch 124, tr_loss is    0.31.\n",
      "126/244 [==============>...............] - ETA: 1:43 - loss: 0.3089 - iou_score: 0.6826 - f1-score: 0.8089For batch 125, tr_loss is    0.31.\n",
      "127/244 [==============>...............] - ETA: 1:42 - loss: 0.3090 - iou_score: 0.6823 - f1-score: 0.8088For batch 126, tr_loss is    0.31.\n",
      "128/244 [==============>...............] - ETA: 1:40 - loss: 0.3085 - iou_score: 0.6829 - f1-score: 0.8092For batch 127, tr_loss is    0.31.\n",
      "129/244 [==============>...............] - ETA: 1:40 - loss: 0.3082 - iou_score: 0.6831 - f1-score: 0.8093For batch 128, tr_loss is    0.31.\n",
      "130/244 [==============>...............] - ETA: 1:39 - loss: 0.3084 - iou_score: 0.6827 - f1-score: 0.8090For batch 129, tr_loss is    0.31.\n",
      "131/244 [===============>..............] - ETA: 1:38 - loss: 0.3080 - iou_score: 0.6831 - f1-score: 0.8093For batch 130, tr_loss is    0.31.\n",
      "132/244 [===============>..............] - ETA: 1:37 - loss: 0.3087 - iou_score: 0.6824 - f1-score: 0.8088For batch 131, tr_loss is    0.31.\n",
      "133/244 [===============>..............] - ETA: 1:36 - loss: 0.3086 - iou_score: 0.6825 - f1-score: 0.8089For batch 132, tr_loss is    0.31.\n",
      "134/244 [===============>..............] - ETA: 1:36 - loss: 0.3092 - iou_score: 0.6818 - f1-score: 0.8084For batch 133, tr_loss is    0.31.\n",
      "135/244 [===============>..............] - ETA: 1:34 - loss: 0.3094 - iou_score: 0.6815 - f1-score: 0.8081For batch 134, tr_loss is    0.31.\n",
      "136/244 [===============>..............] - ETA: 1:33 - loss: 0.3089 - iou_score: 0.6821 - f1-score: 0.8086For batch 135, tr_loss is    0.31.\n",
      "137/244 [===============>..............] - ETA: 1:33 - loss: 0.3086 - iou_score: 0.6825 - f1-score: 0.8089For batch 136, tr_loss is    0.31.\n",
      "138/244 [===============>..............] - ETA: 1:32 - loss: 0.3087 - iou_score: 0.6822 - f1-score: 0.8087For batch 137, tr_loss is    0.31.\n",
      "139/244 [================>.............] - ETA: 1:31 - loss: 0.3090 - iou_score: 0.6818 - f1-score: 0.8084For batch 138, tr_loss is    0.31.\n",
      "140/244 [================>.............] - ETA: 1:30 - loss: 0.3089 - iou_score: 0.6820 - f1-score: 0.8085For batch 139, tr_loss is    0.31.\n",
      "141/244 [================>.............] - ETA: 1:29 - loss: 0.3088 - iou_score: 0.6820 - f1-score: 0.8085For batch 140, tr_loss is    0.31.\n",
      "142/244 [================>.............] - ETA: 1:28 - loss: 0.3087 - iou_score: 0.6818 - f1-score: 0.8084For batch 141, tr_loss is    0.31.\n",
      "143/244 [================>.............] - ETA: 1:27 - loss: 0.3084 - iou_score: 0.6824 - f1-score: 0.8088For batch 142, tr_loss is    0.31.\n",
      "144/244 [================>.............] - ETA: 1:26 - loss: 0.3089 - iou_score: 0.6820 - f1-score: 0.8084For batch 143, tr_loss is    0.31.\n",
      "145/244 [================>.............] - ETA: 1:26 - loss: 0.3088 - iou_score: 0.6818 - f1-score: 0.8084For batch 144, tr_loss is    0.31.\n",
      "146/244 [================>.............] - ETA: 1:25 - loss: 0.3088 - iou_score: 0.6817 - f1-score: 0.8083For batch 145, tr_loss is    0.31.\n",
      "147/244 [=================>............] - ETA: 1:24 - loss: 0.3087 - iou_score: 0.6817 - f1-score: 0.8083For batch 146, tr_loss is    0.31.\n",
      "148/244 [=================>............] - ETA: 1:23 - loss: 0.3088 - iou_score: 0.6815 - f1-score: 0.8081For batch 147, tr_loss is    0.31.\n",
      "149/244 [=================>............] - ETA: 1:22 - loss: 0.3090 - iou_score: 0.6813 - f1-score: 0.8080For batch 148, tr_loss is    0.31.\n",
      "150/244 [=================>............] - ETA: 1:21 - loss: 0.3089 - iou_score: 0.6814 - f1-score: 0.8081For batch 149, tr_loss is    0.31.\n",
      "151/244 [=================>............] - ETA: 1:20 - loss: 0.3088 - iou_score: 0.6815 - f1-score: 0.8082For batch 150, tr_loss is    0.31.\n",
      "152/244 [=================>............] - ETA: 1:20 - loss: 0.3092 - iou_score: 0.6812 - f1-score: 0.8080For batch 151, tr_loss is    0.31.\n",
      "153/244 [=================>............] - ETA: 1:19 - loss: 0.3090 - iou_score: 0.6816 - f1-score: 0.8083For batch 152, tr_loss is    0.31.\n",
      "154/244 [=================>............] - ETA: 1:18 - loss: 0.3090 - iou_score: 0.6816 - f1-score: 0.8083For batch 153, tr_loss is    0.31.\n",
      "155/244 [==================>...........] - ETA: 1:17 - loss: 0.3090 - iou_score: 0.6815 - f1-score: 0.8083For batch 154, tr_loss is    0.31.\n",
      "156/244 [==================>...........] - ETA: 1:16 - loss: 0.3086 - iou_score: 0.6821 - f1-score: 0.8086For batch 155, tr_loss is    0.31.\n",
      "157/244 [==================>...........] - ETA: 1:15 - loss: 0.3084 - iou_score: 0.6822 - f1-score: 0.8088For batch 156, tr_loss is    0.31.\n",
      "158/244 [==================>...........] - ETA: 1:14 - loss: 0.3084 - iou_score: 0.6821 - f1-score: 0.8087For batch 157, tr_loss is    0.31.\n",
      "159/244 [==================>...........] - ETA: 1:13 - loss: 0.3082 - iou_score: 0.6824 - f1-score: 0.8089For batch 158, tr_loss is    0.31.\n",
      "160/244 [==================>...........] - ETA: 1:12 - loss: 0.3080 - iou_score: 0.6827 - f1-score: 0.8091For batch 159, tr_loss is    0.31.\n",
      "161/244 [==================>...........] - ETA: 1:12 - loss: 0.3081 - iou_score: 0.6825 - f1-score: 0.8090For batch 160, tr_loss is    0.31.\n",
      "162/244 [==================>...........] - ETA: 1:11 - loss: 0.3079 - iou_score: 0.6827 - f1-score: 0.8091For batch 161, tr_loss is    0.31.\n",
      "163/244 [===================>..........] - ETA: 1:10 - loss: 0.3081 - iou_score: 0.6827 - f1-score: 0.8091For batch 162, tr_loss is    0.31.\n",
      "164/244 [===================>..........] - ETA: 1:09 - loss: 0.3079 - iou_score: 0.6829 - f1-score: 0.8093For batch 163, tr_loss is    0.31.\n",
      "165/244 [===================>..........] - ETA: 1:08 - loss: 0.3082 - iou_score: 0.6826 - f1-score: 0.8091For batch 164, tr_loss is    0.31.\n",
      "166/244 [===================>..........] - ETA: 1:07 - loss: 0.3084 - iou_score: 0.6824 - f1-score: 0.8089For batch 165, tr_loss is    0.31.\n",
      "167/244 [===================>..........] - ETA: 1:06 - loss: 0.3081 - iou_score: 0.6828 - f1-score: 0.8092For batch 166, tr_loss is    0.31.\n",
      "168/244 [===================>..........] - ETA: 1:06 - loss: 0.3077 - iou_score: 0.6832 - f1-score: 0.8095For batch 167, tr_loss is    0.31.\n",
      "169/244 [===================>..........] - ETA: 1:05 - loss: 0.3074 - iou_score: 0.6836 - f1-score: 0.8097For batch 168, tr_loss is    0.31.\n",
      "170/244 [===================>..........] - ETA: 1:04 - loss: 0.3076 - iou_score: 0.6832 - f1-score: 0.8094For batch 169, tr_loss is    0.31.\n",
      "171/244 [====================>.........] - ETA: 1:03 - loss: 0.3073 - iou_score: 0.6835 - f1-score: 0.8097For batch 170, tr_loss is    0.31.\n",
      "172/244 [====================>.........] - ETA: 1:02 - loss: 0.3074 - iou_score: 0.6834 - f1-score: 0.8096For batch 171, tr_loss is    0.31.\n",
      "173/244 [====================>.........] - ETA: 1:01 - loss: 0.3076 - iou_score: 0.6833 - f1-score: 0.8096For batch 172, tr_loss is    0.31.\n",
      "174/244 [====================>.........] - ETA: 1:00 - loss: 0.3078 - iou_score: 0.6829 - f1-score: 0.8092For batch 173, tr_loss is    0.31.\n",
      "175/244 [====================>.........] - ETA: 1:00 - loss: 0.3080 - iou_score: 0.6825 - f1-score: 0.8090For batch 174, tr_loss is    0.31.\n",
      "176/244 [====================>.........] - ETA: 59s - loss: 0.3080 - iou_score: 0.6825 - f1-score: 0.8090 For batch 175, tr_loss is    0.31.\n",
      "177/244 [====================>.........] - ETA: 58s - loss: 0.3075 - iou_score: 0.6833 - f1-score: 0.8095For batch 176, tr_loss is    0.31.\n",
      "178/244 [====================>.........] - ETA: 57s - loss: 0.3077 - iou_score: 0.6829 - f1-score: 0.8092For batch 177, tr_loss is    0.31.\n",
      "179/244 [=====================>........] - ETA: 56s - loss: 0.3074 - iou_score: 0.6832 - f1-score: 0.8094For batch 178, tr_loss is    0.31.\n",
      "180/244 [=====================>........] - ETA: 55s - loss: 0.3073 - iou_score: 0.6831 - f1-score: 0.8094For batch 179, tr_loss is    0.31.\n",
      "181/244 [=====================>........] - ETA: 54s - loss: 0.3069 - iou_score: 0.6835 - f1-score: 0.8096For batch 180, tr_loss is    0.31.\n",
      "182/244 [=====================>........] - ETA: 53s - loss: 0.3070 - iou_score: 0.6834 - f1-score: 0.8096For batch 181, tr_loss is    0.31.\n",
      "183/244 [=====================>........] - ETA: 52s - loss: 0.3070 - iou_score: 0.6835 - f1-score: 0.8096For batch 182, tr_loss is    0.31.\n",
      "184/244 [=====================>........] - ETA: 52s - loss: 0.3072 - iou_score: 0.6832 - f1-score: 0.8094For batch 183, tr_loss is    0.31.\n",
      "185/244 [=====================>........] - ETA: 51s - loss: 0.3074 - iou_score: 0.6832 - f1-score: 0.8094For batch 184, tr_loss is    0.31.\n",
      "186/244 [=====================>........] - ETA: 50s - loss: 0.3071 - iou_score: 0.6835 - f1-score: 0.8096For batch 185, tr_loss is    0.31.\n",
      "187/244 [=====================>........] - ETA: 49s - loss: 0.3074 - iou_score: 0.6830 - f1-score: 0.8093For batch 186, tr_loss is    0.31.\n",
      "188/244 [======================>.......] - ETA: 48s - loss: 0.3074 - iou_score: 0.6829 - f1-score: 0.8092For batch 187, tr_loss is    0.31.\n",
      "189/244 [======================>.......] - ETA: 47s - loss: 0.3073 - iou_score: 0.6832 - f1-score: 0.8094For batch 188, tr_loss is    0.31.\n",
      "190/244 [======================>.......] - ETA: 46s - loss: 0.3069 - iou_score: 0.6836 - f1-score: 0.8097For batch 189, tr_loss is    0.31.\n",
      "191/244 [======================>.......] - ETA: 45s - loss: 0.3066 - iou_score: 0.6839 - f1-score: 0.8100For batch 190, tr_loss is    0.31.\n",
      "192/244 [======================>.......] - ETA: 45s - loss: 0.3067 - iou_score: 0.6838 - f1-score: 0.8099For batch 191, tr_loss is    0.31.\n",
      "193/244 [======================>.......] - ETA: 44s - loss: 0.3067 - iou_score: 0.6835 - f1-score: 0.8097For batch 192, tr_loss is    0.31.\n",
      "194/244 [======================>.......] - ETA: 43s - loss: 0.3063 - iou_score: 0.6838 - f1-score: 0.8099For batch 193, tr_loss is    0.31.\n",
      "195/244 [======================>.......] - ETA: 42s - loss: 0.3065 - iou_score: 0.6839 - f1-score: 0.8100For batch 194, tr_loss is    0.31.\n",
      "196/244 [=======================>......] - ETA: 41s - loss: 0.3065 - iou_score: 0.6839 - f1-score: 0.8100For batch 195, tr_loss is    0.31.\n",
      "197/244 [=======================>......] - ETA: 40s - loss: 0.3066 - iou_score: 0.6836 - f1-score: 0.8098For batch 196, tr_loss is    0.31.\n",
      "198/244 [=======================>......] - ETA: 39s - loss: 0.3065 - iou_score: 0.6837 - f1-score: 0.8099For batch 197, tr_loss is    0.31.\n",
      "199/244 [=======================>......] - ETA: 38s - loss: 0.3062 - iou_score: 0.6841 - f1-score: 0.8102For batch 198, tr_loss is    0.31.\n",
      "200/244 [=======================>......] - ETA: 38s - loss: 0.3063 - iou_score: 0.6842 - f1-score: 0.8102For batch 199, tr_loss is    0.31.\n",
      "201/244 [=======================>......] - ETA: 37s - loss: 0.3066 - iou_score: 0.6840 - f1-score: 0.8101For batch 200, tr_loss is    0.31.\n",
      "202/244 [=======================>......] - ETA: 36s - loss: 0.3064 - iou_score: 0.6842 - f1-score: 0.8102For batch 201, tr_loss is    0.31.\n",
      "203/244 [=======================>......] - ETA: 35s - loss: 0.3062 - iou_score: 0.6844 - f1-score: 0.8104For batch 202, tr_loss is    0.31.\n",
      "204/244 [========================>.....] - ETA: 34s - loss: 0.3059 - iou_score: 0.6846 - f1-score: 0.8105For batch 203, tr_loss is    0.31.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/244 [========================>.....] - ETA: 33s - loss: 0.3055 - iou_score: 0.6851 - f1-score: 0.8109For batch 204, tr_loss is    0.31.\n",
      "206/244 [========================>.....] - ETA: 32s - loss: 0.3057 - iou_score: 0.6848 - f1-score: 0.8106For batch 205, tr_loss is    0.31.\n",
      "207/244 [========================>.....] - ETA: 31s - loss: 0.3054 - iou_score: 0.6850 - f1-score: 0.8108For batch 206, tr_loss is    0.31.\n",
      "208/244 [========================>.....] - ETA: 30s - loss: 0.3056 - iou_score: 0.6847 - f1-score: 0.8105For batch 207, tr_loss is    0.31.\n",
      "209/244 [========================>.....] - ETA: 30s - loss: 0.3054 - iou_score: 0.6848 - f1-score: 0.8107For batch 208, tr_loss is    0.31.\n",
      "210/244 [========================>.....] - ETA: 29s - loss: 0.3051 - iou_score: 0.6852 - f1-score: 0.8109For batch 209, tr_loss is    0.31.\n",
      "211/244 [========================>.....] - ETA: 28s - loss: 0.3051 - iou_score: 0.6852 - f1-score: 0.8109For batch 210, tr_loss is    0.31.\n",
      "212/244 [=========================>....] - ETA: 27s - loss: 0.3051 - iou_score: 0.6851 - f1-score: 0.8109For batch 211, tr_loss is    0.31.\n",
      "213/244 [=========================>....] - ETA: 26s - loss: 0.3053 - iou_score: 0.6850 - f1-score: 0.8108For batch 212, tr_loss is    0.31.\n",
      "214/244 [=========================>....] - ETA: 25s - loss: 0.3050 - iou_score: 0.6854 - f1-score: 0.8111For batch 213, tr_loss is    0.30.\n",
      "215/244 [=========================>....] - ETA: 24s - loss: 0.3049 - iou_score: 0.6857 - f1-score: 0.8113For batch 214, tr_loss is    0.30.\n",
      "216/244 [=========================>....] - ETA: 24s - loss: 0.3049 - iou_score: 0.6856 - f1-score: 0.8112For batch 215, tr_loss is    0.30.\n",
      "217/244 [=========================>....] - ETA: 23s - loss: 0.3049 - iou_score: 0.6856 - f1-score: 0.8112For batch 216, tr_loss is    0.30.\n",
      "218/244 [=========================>....] - ETA: 22s - loss: 0.3048 - iou_score: 0.6857 - f1-score: 0.8113For batch 217, tr_loss is    0.30.\n",
      "219/244 [=========================>....] - ETA: 21s - loss: 0.3048 - iou_score: 0.6857 - f1-score: 0.8113For batch 218, tr_loss is    0.30.\n",
      "220/244 [==========================>...] - ETA: 20s - loss: 0.3048 - iou_score: 0.6857 - f1-score: 0.8113For batch 219, tr_loss is    0.30.\n",
      "221/244 [==========================>...] - ETA: 19s - loss: 0.3048 - iou_score: 0.6856 - f1-score: 0.8112For batch 220, tr_loss is    0.30.\n",
      "222/244 [==========================>...] - ETA: 18s - loss: 0.3044 - iou_score: 0.6860 - f1-score: 0.8115For batch 221, tr_loss is    0.30.\n",
      "223/244 [==========================>...] - ETA: 18s - loss: 0.3044 - iou_score: 0.6859 - f1-score: 0.8115For batch 222, tr_loss is    0.30.\n",
      "224/244 [==========================>...] - ETA: 17s - loss: 0.3044 - iou_score: 0.6860 - f1-score: 0.8115For batch 223, tr_loss is    0.30.\n",
      "225/244 [==========================>...] - ETA: 16s - loss: 0.3044 - iou_score: 0.6861 - f1-score: 0.8116For batch 224, tr_loss is    0.30.\n",
      "226/244 [==========================>...] - ETA: 15s - loss: 0.3042 - iou_score: 0.6862 - f1-score: 0.8117For batch 225, tr_loss is    0.30.\n",
      "227/244 [==========================>...] - ETA: 14s - loss: 0.3040 - iou_score: 0.6864 - f1-score: 0.8118For batch 226, tr_loss is    0.30.\n",
      "228/244 [===========================>..] - ETA: 13s - loss: 0.3040 - iou_score: 0.6865 - f1-score: 0.8119For batch 227, tr_loss is    0.30.\n",
      "229/244 [===========================>..] - ETA: 12s - loss: 0.3036 - iou_score: 0.6869 - f1-score: 0.8121For batch 228, tr_loss is    0.30.\n",
      "230/244 [===========================>..] - ETA: 12s - loss: 0.3035 - iou_score: 0.6869 - f1-score: 0.8122For batch 229, tr_loss is    0.30.\n",
      "231/244 [===========================>..] - ETA: 11s - loss: 0.3034 - iou_score: 0.6871 - f1-score: 0.8123For batch 230, tr_loss is    0.30.\n",
      "232/244 [===========================>..] - ETA: 10s - loss: 0.3035 - iou_score: 0.6870 - f1-score: 0.8123For batch 231, tr_loss is    0.30.\n",
      "233/244 [===========================>..] - ETA: 9s - loss: 0.3041 - iou_score: 0.6864 - f1-score: 0.8118 For batch 232, tr_loss is    0.30.\n",
      "234/244 [===========================>..] - ETA: 8s - loss: 0.3041 - iou_score: 0.6863 - f1-score: 0.8117For batch 233, tr_loss is    0.30.\n",
      "235/244 [===========================>..] - ETA: 7s - loss: 0.3038 - iou_score: 0.6866 - f1-score: 0.8119For batch 234, tr_loss is    0.30.\n",
      "236/244 [============================>.] - ETA: 6s - loss: 0.3040 - iou_score: 0.6865 - f1-score: 0.8119For batch 235, tr_loss is    0.30.\n",
      "237/244 [============================>.] - ETA: 5s - loss: 0.3041 - iou_score: 0.6864 - f1-score: 0.8118For batch 236, tr_loss is    0.30.\n",
      "238/244 [============================>.] - ETA: 5s - loss: 0.3039 - iou_score: 0.6867 - f1-score: 0.8120For batch 237, tr_loss is    0.30.\n",
      "239/244 [============================>.] - ETA: 4s - loss: 0.3040 - iou_score: 0.6867 - f1-score: 0.8120For batch 238, tr_loss is    0.30.\n",
      "240/244 [============================>.] - ETA: 3s - loss: 0.3037 - iou_score: 0.6870 - f1-score: 0.8122For batch 239, tr_loss is    0.30.\n",
      "241/244 [============================>.] - ETA: 2s - loss: 0.3037 - iou_score: 0.6870 - f1-score: 0.8122For batch 240, tr_loss is    0.30.\n",
      "242/244 [============================>.] - ETA: 1s - loss: 0.3039 - iou_score: 0.6867 - f1-score: 0.8120For batch 241, tr_loss is    0.30.\n",
      "243/244 [============================>.] - ETA: 0s - loss: 0.3042 - iou_score: 0.6863 - f1-score: 0.8117For batch 242, tr_loss is    0.30.\n",
      "244/244 [==============================] - ETA: 0s - loss: 0.3041 - iou_score: 0.6863 - f1-score: 0.8117For batch 243, tr_loss is    0.30.\n",
      "For batch 0, vl_loss is    0.36.\n",
      "For batch 1, vl_loss is    0.36.\n",
      "For batch 2, vl_loss is    0.34.\n",
      "For batch 3, vl_loss is    0.36.\n",
      "For batch 4, vl_loss is    0.35.\n",
      "For batch 5, vl_loss is    0.35.\n",
      "For batch 6, vl_loss is    0.37.\n",
      "For batch 7, vl_loss is    0.36.\n",
      "For batch 8, vl_loss is    0.36.\n",
      "For batch 9, vl_loss is    0.36.\n",
      "For batch 10, vl_loss is    0.37.\n",
      "For batch 11, vl_loss is    0.38.\n",
      "For batch 12, vl_loss is    0.37.\n",
      "For batch 13, vl_loss is    0.37.\n",
      "For batch 14, vl_loss is    0.37.\n",
      "For batch 15, vl_loss is    0.37.\n",
      "For batch 16, vl_loss is    0.37.\n",
      "For batch 17, vl_loss is    0.37.\n",
      "For batch 18, vl_loss is    0.37.\n",
      "For batch 19, vl_loss is    0.37.\n",
      "For batch 20, vl_loss is    0.37.\n",
      "For batch 21, vl_loss is    0.37.\n",
      "For batch 22, vl_loss is    0.37.\n",
      "For batch 23, vl_loss is    0.37.\n",
      "For batch 24, vl_loss is    0.37.\n",
      "For batch 25, vl_loss is    0.37.\n",
      "For batch 26, vl_loss is    0.37.\n",
      "For batch 27, vl_loss is    0.37.\n",
      "For batch 28, vl_loss is    0.37.\n",
      "For batch 29, vl_loss is    0.37.\n",
      "For batch 30, vl_loss is    0.37.\n",
      "For batch 31, vl_loss is    0.37.\n",
      "For batch 32, vl_loss is    0.37.\n",
      "For batch 33, vl_loss is    0.37.\n",
      "For batch 34, vl_loss is    0.37.\n",
      "For batch 35, vl_loss is    0.37.\n",
      "For batch 36, vl_loss is    0.37.\n",
      "For batch 37, vl_loss is    0.37.\n",
      "For batch 38, vl_loss is    0.37.\n",
      "For batch 39, vl_loss is    0.37.\n",
      "For batch 40, vl_loss is    0.37.\n",
      "For batch 41, vl_loss is    0.37.\n",
      "For batch 42, vl_loss is    0.37.\n",
      "For batch 43, vl_loss is    0.37.\n",
      "For batch 44, vl_loss is    0.37.\n",
      "For batch 45, vl_loss is    0.37.\n",
      "For batch 46, vl_loss is    0.37.\n",
      "For batch 47, vl_loss is    0.36.\n",
      "For batch 48, vl_loss is    0.36.\n",
      "For batch 49, vl_loss is    0.36.\n",
      "For batch 50, vl_loss is    0.36.\n",
      "For batch 51, vl_loss is    0.36.\n",
      "For batch 52, vl_loss is    0.36.\n",
      "For batch 53, vl_loss is    0.36.\n",
      "For batch 54, vl_loss is    0.36.\n",
      "For batch 55, vl_loss is    0.36.\n",
      "244/244 [==============================] - 212s 862ms/step - loss: 0.3041 - iou_score: 0.6863 - f1-score: 0.8117 - val_loss: 0.3643 - val_iou_score: 0.6251 - val_f1-score: 0.7671\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.34998\n",
      "The average loss for epoch 3 is    0.30 \n",
      "Epoch 5/200\n",
      "  1/244 [..............................] - ETA: 12:18 - loss: 0.3636 - iou_score: 0.6146 - f1-score: 0.7586For batch 0, tr_loss is    0.36.\n",
      "  2/244 [..............................] - ETA: 4:08 - loss: 0.3266 - iou_score: 0.6696 - f1-score: 0.7992 For batch 1, tr_loss is    0.33.\n",
      "  3/244 [..............................] - ETA: 4:29 - loss: 0.3184 - iou_score: 0.6797 - f1-score: 0.8073For batch 2, tr_loss is    0.32.\n",
      "  4/244 [..............................] - ETA: 4:28 - loss: 0.3178 - iou_score: 0.6845 - f1-score: 0.8111For batch 3, tr_loss is    0.32.\n",
      "  5/244 [..............................] - ETA: 5:08 - loss: 0.3145 - iou_score: 0.6868 - f1-score: 0.8128For batch 4, tr_loss is    0.31.\n",
      "  6/244 [..............................] - ETA: 5:07 - loss: 0.3226 - iou_score: 0.6777 - f1-score: 0.8064For batch 5, tr_loss is    0.32.\n",
      "  7/244 [..............................] - ETA: 5:11 - loss: 0.3148 - iou_score: 0.6853 - f1-score: 0.8114For batch 6, tr_loss is    0.31.\n",
      "  8/244 [..............................] - ETA: 4:57 - loss: 0.3180 - iou_score: 0.6767 - f1-score: 0.8050For batch 7, tr_loss is    0.32.\n",
      "  9/244 [>.............................] - ETA: 4:39 - loss: 0.3184 - iou_score: 0.6767 - f1-score: 0.8051For batch 8, tr_loss is    0.32.\n",
      " 10/244 [>.............................] - ETA: 4:21 - loss: 0.3128 - iou_score: 0.6835 - f1-score: 0.8099For batch 9, tr_loss is    0.31.\n",
      " 11/244 [>.............................] - ETA: 4:12 - loss: 0.3118 - iou_score: 0.6857 - f1-score: 0.8116For batch 10, tr_loss is    0.31.\n",
      " 12/244 [>.............................] - ETA: 4:11 - loss: 0.3115 - iou_score: 0.6860 - f1-score: 0.8120For batch 11, tr_loss is    0.31.\n",
      " 13/244 [>.............................] - ETA: 3:58 - loss: 0.3080 - iou_score: 0.6899 - f1-score: 0.8148For batch 12, tr_loss is    0.31.\n",
      " 14/244 [>.............................] - ETA: 3:57 - loss: 0.3130 - iou_score: 0.6844 - f1-score: 0.8108For batch 13, tr_loss is    0.31.\n",
      " 15/244 [>.............................] - ETA: 3:55 - loss: 0.3158 - iou_score: 0.6814 - f1-score: 0.8087For batch 14, tr_loss is    0.32.\n",
      " 16/244 [>.............................] - ETA: 3:54 - loss: 0.3163 - iou_score: 0.6805 - f1-score: 0.8081For batch 15, tr_loss is    0.32.\n",
      " 17/244 [=>............................] - ETA: 3:51 - loss: 0.3124 - iou_score: 0.6849 - f1-score: 0.8112For batch 16, tr_loss is    0.31.\n",
      " 18/244 [=>............................] - ETA: 3:49 - loss: 0.3134 - iou_score: 0.6830 - f1-score: 0.8099For batch 17, tr_loss is    0.31.\n",
      " 19/244 [=>............................] - ETA: 3:40 - loss: 0.3108 - iou_score: 0.6858 - f1-score: 0.8119For batch 18, tr_loss is    0.31.\n",
      " 20/244 [=>............................] - ETA: 3:43 - loss: 0.3107 - iou_score: 0.6857 - f1-score: 0.8117For batch 19, tr_loss is    0.31.\n",
      " 21/244 [=>............................] - ETA: 3:39 - loss: 0.3110 - iou_score: 0.6845 - f1-score: 0.8109For batch 20, tr_loss is    0.31.\n",
      " 22/244 [=>............................] - ETA: 3:38 - loss: 0.3133 - iou_score: 0.6821 - f1-score: 0.8092For batch 21, tr_loss is    0.31.\n",
      " 23/244 [=>............................] - ETA: 3:37 - loss: 0.3129 - iou_score: 0.6808 - f1-score: 0.8083For batch 22, tr_loss is    0.31.\n",
      " 24/244 [=>............................] - ETA: 3:36 - loss: 0.3104 - iou_score: 0.6837 - f1-score: 0.8104For batch 23, tr_loss is    0.31.\n",
      " 25/244 [==>...........................] - ETA: 3:33 - loss: 0.3107 - iou_score: 0.6823 - f1-score: 0.8094For batch 24, tr_loss is    0.31.\n",
      " 26/244 [==>...........................] - ETA: 3:32 - loss: 0.3106 - iou_score: 0.6817 - f1-score: 0.8090For batch 25, tr_loss is    0.31.\n",
      " 27/244 [==>...........................] - ETA: 3:31 - loss: 0.3103 - iou_score: 0.6820 - f1-score: 0.8093For batch 26, tr_loss is    0.31.\n",
      " 28/244 [==>...........................] - ETA: 3:31 - loss: 0.3072 - iou_score: 0.6854 - f1-score: 0.8116For batch 27, tr_loss is    0.31.\n",
      " 29/244 [==>...........................] - ETA: 3:30 - loss: 0.3058 - iou_score: 0.6857 - f1-score: 0.8118For batch 28, tr_loss is    0.31.\n",
      " 30/244 [==>...........................] - ETA: 3:27 - loss: 0.3029 - iou_score: 0.6891 - f1-score: 0.8141For batch 29, tr_loss is    0.30.\n",
      " 31/244 [==>...........................] - ETA: 3:23 - loss: 0.3013 - iou_score: 0.6909 - f1-score: 0.8154For batch 30, tr_loss is    0.30.\n",
      " 32/244 [==>...........................] - ETA: 3:23 - loss: 0.3003 - iou_score: 0.6922 - f1-score: 0.8164For batch 31, tr_loss is    0.30.\n",
      " 33/244 [===>..........................] - ETA: 3:21 - loss: 0.2997 - iou_score: 0.6922 - f1-score: 0.8164For batch 32, tr_loss is    0.30.\n",
      " 34/244 [===>..........................] - ETA: 3:20 - loss: 0.2991 - iou_score: 0.6922 - f1-score: 0.8165For batch 33, tr_loss is    0.30.\n",
      " 35/244 [===>..........................] - ETA: 3:18 - loss: 0.3007 - iou_score: 0.6908 - f1-score: 0.8155For batch 34, tr_loss is    0.30.\n",
      " 36/244 [===>..........................] - ETA: 3:14 - loss: 0.2994 - iou_score: 0.6923 - f1-score: 0.8166For batch 35, tr_loss is    0.30.\n",
      " 37/244 [===>..........................] - ETA: 3:12 - loss: 0.3007 - iou_score: 0.6910 - f1-score: 0.8157For batch 36, tr_loss is    0.30.\n",
      " 38/244 [===>..........................] - ETA: 3:10 - loss: 0.2999 - iou_score: 0.6923 - f1-score: 0.8165For batch 37, tr_loss is    0.30.\n",
      " 39/244 [===>..........................] - ETA: 3:10 - loss: 0.2984 - iou_score: 0.6941 - f1-score: 0.8178For batch 38, tr_loss is    0.30.\n",
      " 40/244 [===>..........................] - ETA: 3:08 - loss: 0.2983 - iou_score: 0.6934 - f1-score: 0.8173For batch 39, tr_loss is    0.30.\n",
      " 41/244 [====>.........................] - ETA: 3:08 - loss: 0.2989 - iou_score: 0.6920 - f1-score: 0.8163For batch 40, tr_loss is    0.30.\n",
      " 42/244 [====>.........................] - ETA: 3:05 - loss: 0.2977 - iou_score: 0.6929 - f1-score: 0.8170For batch 41, tr_loss is    0.30.\n",
      " 43/244 [====>.........................] - ETA: 3:05 - loss: 0.2987 - iou_score: 0.6911 - f1-score: 0.8157For batch 42, tr_loss is    0.30.\n",
      " 44/244 [====>.........................] - ETA: 3:04 - loss: 0.2983 - iou_score: 0.6916 - f1-score: 0.8160For batch 43, tr_loss is    0.30.\n",
      " 45/244 [====>.........................] - ETA: 3:03 - loss: 0.2982 - iou_score: 0.6912 - f1-score: 0.8157For batch 44, tr_loss is    0.30.\n",
      " 46/244 [====>.........................] - ETA: 3:02 - loss: 0.2978 - iou_score: 0.6916 - f1-score: 0.8161For batch 45, tr_loss is    0.30.\n",
      " 47/244 [====>.........................] - ETA: 3:00 - loss: 0.2965 - iou_score: 0.6928 - f1-score: 0.8169For batch 46, tr_loss is    0.30.\n",
      " 48/244 [====>.........................] - ETA: 2:59 - loss: 0.2954 - iou_score: 0.6938 - f1-score: 0.8175For batch 47, tr_loss is    0.30.\n",
      " 49/244 [=====>........................] - ETA: 2:59 - loss: 0.2965 - iou_score: 0.6928 - f1-score: 0.8169For batch 48, tr_loss is    0.30.\n",
      " 50/244 [=====>........................] - ETA: 2:58 - loss: 0.2965 - iou_score: 0.6930 - f1-score: 0.8170For batch 49, tr_loss is    0.30.\n",
      " 51/244 [=====>........................] - ETA: 2:58 - loss: 0.2976 - iou_score: 0.6918 - f1-score: 0.8162For batch 50, tr_loss is    0.30.\n",
      " 52/244 [=====>........................] - ETA: 2:56 - loss: 0.2979 - iou_score: 0.6921 - f1-score: 0.8164For batch 51, tr_loss is    0.30.\n",
      " 53/244 [=====>........................] - ETA: 2:56 - loss: 0.2977 - iou_score: 0.6919 - f1-score: 0.8163For batch 52, tr_loss is    0.30.\n",
      " 54/244 [=====>........................] - ETA: 2:55 - loss: 0.2985 - iou_score: 0.6912 - f1-score: 0.8158For batch 53, tr_loss is    0.30.\n",
      " 55/244 [=====>........................] - ETA: 2:54 - loss: 0.2970 - iou_score: 0.6926 - f1-score: 0.8168For batch 54, tr_loss is    0.30.\n",
      " 56/244 [=====>........................] - ETA: 2:52 - loss: 0.2963 - iou_score: 0.6933 - f1-score: 0.8173For batch 55, tr_loss is    0.30.\n",
      " 57/244 [======>.......................] - ETA: 2:50 - loss: 0.2969 - iou_score: 0.6929 - f1-score: 0.8170For batch 56, tr_loss is    0.30.\n",
      " 58/244 [======>.......................] - ETA: 2:50 - loss: 0.2978 - iou_score: 0.6919 - f1-score: 0.8163For batch 57, tr_loss is    0.30.\n",
      " 59/244 [======>.......................] - ETA: 2:49 - loss: 0.2965 - iou_score: 0.6943 - f1-score: 0.8178For batch 58, tr_loss is    0.30.\n",
      " 60/244 [======>.......................] - ETA: 2:47 - loss: 0.2986 - iou_score: 0.6917 - f1-score: 0.8159For batch 59, tr_loss is    0.30.\n",
      " 61/244 [======>.......................] - ETA: 2:47 - loss: 0.2995 - iou_score: 0.6901 - f1-score: 0.8147For batch 60, tr_loss is    0.30.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 62/244 [======>.......................] - ETA: 2:46 - loss: 0.2992 - iou_score: 0.6902 - f1-score: 0.8148For batch 61, tr_loss is    0.30.\n",
      " 63/244 [======>.......................] - ETA: 2:44 - loss: 0.2996 - iou_score: 0.6901 - f1-score: 0.8148For batch 62, tr_loss is    0.30.\n",
      " 64/244 [======>.......................] - ETA: 2:42 - loss: 0.2988 - iou_score: 0.6913 - f1-score: 0.8156For batch 63, tr_loss is    0.30.\n",
      " 65/244 [======>.......................] - ETA: 2:42 - loss: 0.2991 - iou_score: 0.6909 - f1-score: 0.8153For batch 64, tr_loss is    0.30.\n",
      " 66/244 [=======>......................] - ETA: 2:41 - loss: 0.2991 - iou_score: 0.6913 - f1-score: 0.8155For batch 65, tr_loss is    0.30.\n",
      " 67/244 [=======>......................] - ETA: 2:41 - loss: 0.2989 - iou_score: 0.6918 - f1-score: 0.8159For batch 66, tr_loss is    0.30.\n",
      " 68/244 [=======>......................] - ETA: 2:38 - loss: 0.2985 - iou_score: 0.6923 - f1-score: 0.8163For batch 67, tr_loss is    0.30.\n",
      " 69/244 [=======>......................] - ETA: 2:38 - loss: 0.2993 - iou_score: 0.6913 - f1-score: 0.8155For batch 68, tr_loss is    0.30.\n",
      " 70/244 [=======>......................] - ETA: 2:36 - loss: 0.2986 - iou_score: 0.6917 - f1-score: 0.8159For batch 69, tr_loss is    0.30.\n",
      " 71/244 [=======>......................] - ETA: 2:36 - loss: 0.2985 - iou_score: 0.6919 - f1-score: 0.8160For batch 70, tr_loss is    0.30.\n",
      " 72/244 [=======>......................] - ETA: 2:34 - loss: 0.2977 - iou_score: 0.6928 - f1-score: 0.8166For batch 71, tr_loss is    0.30.\n",
      " 73/244 [=======>......................] - ETA: 2:34 - loss: 0.2980 - iou_score: 0.6923 - f1-score: 0.8162For batch 72, tr_loss is    0.30.\n",
      " 74/244 [========>.....................] - ETA: 2:33 - loss: 0.2983 - iou_score: 0.6919 - f1-score: 0.8159For batch 73, tr_loss is    0.30.\n",
      " 75/244 [========>.....................] - ETA: 2:32 - loss: 0.2981 - iou_score: 0.6919 - f1-score: 0.8159For batch 74, tr_loss is    0.30.\n",
      " 76/244 [========>.....................] - ETA: 2:30 - loss: 0.2972 - iou_score: 0.6932 - f1-score: 0.8168For batch 75, tr_loss is    0.30.\n",
      " 77/244 [========>.....................] - ETA: 2:30 - loss: 0.2971 - iou_score: 0.6934 - f1-score: 0.8170For batch 76, tr_loss is    0.30.\n",
      " 78/244 [========>.....................] - ETA: 2:28 - loss: 0.2968 - iou_score: 0.6938 - f1-score: 0.8173For batch 77, tr_loss is    0.30.\n",
      " 79/244 [========>.....................] - ETA: 2:28 - loss: 0.2965 - iou_score: 0.6945 - f1-score: 0.8177For batch 78, tr_loss is    0.30.\n",
      " 80/244 [========>.....................] - ETA: 2:27 - loss: 0.2962 - iou_score: 0.6946 - f1-score: 0.8177For batch 79, tr_loss is    0.30.\n",
      " 81/244 [========>.....................] - ETA: 2:25 - loss: 0.2962 - iou_score: 0.6945 - f1-score: 0.8177For batch 80, tr_loss is    0.30.\n",
      " 82/244 [=========>....................] - ETA: 2:24 - loss: 0.2974 - iou_score: 0.6929 - f1-score: 0.8164For batch 81, tr_loss is    0.30.\n",
      " 83/244 [=========>....................] - ETA: 2:23 - loss: 0.2966 - iou_score: 0.6937 - f1-score: 0.8170For batch 82, tr_loss is    0.30.\n",
      " 84/244 [=========>....................] - ETA: 2:22 - loss: 0.2965 - iou_score: 0.6941 - f1-score: 0.8173For batch 83, tr_loss is    0.30.\n",
      " 85/244 [=========>....................] - ETA: 2:21 - loss: 0.2957 - iou_score: 0.6949 - f1-score: 0.8179For batch 84, tr_loss is    0.30.\n",
      " 86/244 [=========>....................] - ETA: 2:21 - loss: 0.2961 - iou_score: 0.6945 - f1-score: 0.8176For batch 85, tr_loss is    0.30.\n",
      " 87/244 [=========>....................] - ETA: 2:19 - loss: 0.2961 - iou_score: 0.6946 - f1-score: 0.8176For batch 86, tr_loss is    0.30.\n",
      " 88/244 [=========>....................] - ETA: 2:19 - loss: 0.2954 - iou_score: 0.6952 - f1-score: 0.8181For batch 87, tr_loss is    0.30.\n",
      " 89/244 [=========>....................] - ETA: 2:18 - loss: 0.2959 - iou_score: 0.6946 - f1-score: 0.8177For batch 88, tr_loss is    0.30.\n",
      " 90/244 [==========>...................] - ETA: 2:18 - loss: 0.2956 - iou_score: 0.6948 - f1-score: 0.8178For batch 89, tr_loss is    0.30.\n",
      " 91/244 [==========>...................] - ETA: 2:17 - loss: 0.2969 - iou_score: 0.6932 - f1-score: 0.8166For batch 90, tr_loss is    0.30.\n",
      " 92/244 [==========>...................] - ETA: 2:16 - loss: 0.2975 - iou_score: 0.6924 - f1-score: 0.8160For batch 91, tr_loss is    0.30.\n",
      " 93/244 [==========>...................] - ETA: 2:15 - loss: 0.2967 - iou_score: 0.6936 - f1-score: 0.8168For batch 92, tr_loss is    0.30.\n",
      " 94/244 [==========>...................] - ETA: 2:15 - loss: 0.2965 - iou_score: 0.6938 - f1-score: 0.8169For batch 93, tr_loss is    0.30.\n",
      " 95/244 [==========>...................] - ETA: 2:14 - loss: 0.2966 - iou_score: 0.6934 - f1-score: 0.8166For batch 94, tr_loss is    0.30.\n",
      " 96/244 [==========>...................] - ETA: 2:13 - loss: 0.2969 - iou_score: 0.6929 - f1-score: 0.8163For batch 95, tr_loss is    0.30.\n",
      " 97/244 [==========>...................] - ETA: 2:12 - loss: 0.2967 - iou_score: 0.6932 - f1-score: 0.8165For batch 96, tr_loss is    0.30.\n",
      " 98/244 [===========>..................] - ETA: 2:11 - loss: 0.2967 - iou_score: 0.6931 - f1-score: 0.8165For batch 97, tr_loss is    0.30.\n",
      " 99/244 [===========>..................] - ETA: 2:10 - loss: 0.2966 - iou_score: 0.6933 - f1-score: 0.8166For batch 98, tr_loss is    0.30.\n",
      "100/244 [===========>..................] - ETA: 2:08 - loss: 0.2958 - iou_score: 0.6943 - f1-score: 0.8173For batch 99, tr_loss is    0.30.\n",
      "101/244 [===========>..................] - ETA: 2:08 - loss: 0.2959 - iou_score: 0.6941 - f1-score: 0.8172For batch 100, tr_loss is    0.30.\n",
      "102/244 [===========>..................] - ETA: 2:07 - loss: 0.2956 - iou_score: 0.6943 - f1-score: 0.8173For batch 101, tr_loss is    0.30.\n",
      "103/244 [===========>..................] - ETA: 2:07 - loss: 0.2952 - iou_score: 0.6948 - f1-score: 0.8176For batch 102, tr_loss is    0.30.\n",
      "104/244 [===========>..................] - ETA: 2:05 - loss: 0.2948 - iou_score: 0.6950 - f1-score: 0.8178For batch 103, tr_loss is    0.29.\n",
      "105/244 [===========>..................] - ETA: 2:05 - loss: 0.2948 - iou_score: 0.6949 - f1-score: 0.8177For batch 104, tr_loss is    0.29.\n",
      "106/244 [============>.................] - ETA: 2:04 - loss: 0.2941 - iou_score: 0.6957 - f1-score: 0.8183For batch 105, tr_loss is    0.29.\n",
      "107/244 [============>.................] - ETA: 2:03 - loss: 0.2935 - iou_score: 0.6962 - f1-score: 0.8187For batch 106, tr_loss is    0.29.\n",
      "108/244 [============>.................] - ETA: 2:02 - loss: 0.2937 - iou_score: 0.6961 - f1-score: 0.8186For batch 107, tr_loss is    0.29.\n",
      "109/244 [============>.................] - ETA: 2:01 - loss: 0.2943 - iou_score: 0.6954 - f1-score: 0.8181For batch 108, tr_loss is    0.29.\n",
      "110/244 [============>.................] - ETA: 2:00 - loss: 0.2946 - iou_score: 0.6950 - f1-score: 0.8178For batch 109, tr_loss is    0.29.\n",
      "111/244 [============>.................] - ETA: 1:59 - loss: 0.2947 - iou_score: 0.6948 - f1-score: 0.8176For batch 110, tr_loss is    0.29.\n",
      "112/244 [============>.................] - ETA: 1:59 - loss: 0.2948 - iou_score: 0.6945 - f1-score: 0.8175For batch 111, tr_loss is    0.29.\n",
      "113/244 [============>.................] - ETA: 1:58 - loss: 0.2948 - iou_score: 0.6950 - f1-score: 0.8178For batch 112, tr_loss is    0.29.\n",
      "114/244 [=============>................] - ETA: 1:57 - loss: 0.2951 - iou_score: 0.6944 - f1-score: 0.8174For batch 113, tr_loss is    0.30.\n",
      "115/244 [=============>................] - ETA: 1:56 - loss: 0.2948 - iou_score: 0.6945 - f1-score: 0.8175For batch 114, tr_loss is    0.29.\n",
      "116/244 [=============>................] - ETA: 1:55 - loss: 0.2946 - iou_score: 0.6946 - f1-score: 0.8176For batch 115, tr_loss is    0.29.\n",
      "117/244 [=============>................] - ETA: 1:54 - loss: 0.2947 - iou_score: 0.6941 - f1-score: 0.8172For batch 116, tr_loss is    0.29.\n",
      "118/244 [=============>................] - ETA: 1:53 - loss: 0.2947 - iou_score: 0.6940 - f1-score: 0.8171For batch 117, tr_loss is    0.29.\n",
      "119/244 [=============>................] - ETA: 1:53 - loss: 0.2945 - iou_score: 0.6941 - f1-score: 0.8172For batch 118, tr_loss is    0.29.\n",
      "120/244 [=============>................] - ETA: 1:51 - loss: 0.2955 - iou_score: 0.6929 - f1-score: 0.8163For batch 119, tr_loss is    0.30.\n",
      "121/244 [=============>................] - ETA: 1:51 - loss: 0.2950 - iou_score: 0.6936 - f1-score: 0.8168For batch 120, tr_loss is    0.29.\n",
      "122/244 [==============>...............] - ETA: 1:50 - loss: 0.2948 - iou_score: 0.6938 - f1-score: 0.8169For batch 121, tr_loss is    0.29.\n",
      "123/244 [==============>...............] - ETA: 1:49 - loss: 0.2953 - iou_score: 0.6932 - f1-score: 0.8165For batch 122, tr_loss is    0.30.\n",
      "124/244 [==============>...............] - ETA: 1:47 - loss: 0.2959 - iou_score: 0.6924 - f1-score: 0.8160For batch 123, tr_loss is    0.30.\n",
      "125/244 [==============>...............] - ETA: 1:47 - loss: 0.2960 - iou_score: 0.6929 - f1-score: 0.8163For batch 124, tr_loss is    0.30.\n",
      "126/244 [==============>...............] - ETA: 1:46 - loss: 0.2958 - iou_score: 0.6930 - f1-score: 0.8164For batch 125, tr_loss is    0.30.\n",
      "127/244 [==============>...............] - ETA: 1:45 - loss: 0.2960 - iou_score: 0.6925 - f1-score: 0.8161For batch 126, tr_loss is    0.30.\n",
      "128/244 [==============>...............] - ETA: 1:44 - loss: 0.2955 - iou_score: 0.6931 - f1-score: 0.8165For batch 127, tr_loss is    0.30.\n",
      "129/244 [==============>...............] - ETA: 1:43 - loss: 0.2953 - iou_score: 0.6933 - f1-score: 0.8166For batch 128, tr_loss is    0.30.\n",
      "130/244 [==============>...............] - ETA: 1:42 - loss: 0.2953 - iou_score: 0.6931 - f1-score: 0.8164For batch 129, tr_loss is    0.30.\n",
      "131/244 [===============>..............] - ETA: 1:41 - loss: 0.2949 - iou_score: 0.6937 - f1-score: 0.8168For batch 130, tr_loss is    0.29.\n",
      "132/244 [===============>..............] - ETA: 1:40 - loss: 0.2954 - iou_score: 0.6930 - f1-score: 0.8163For batch 131, tr_loss is    0.30.\n",
      "133/244 [===============>..............] - ETA: 1:39 - loss: 0.2954 - iou_score: 0.6931 - f1-score: 0.8164For batch 132, tr_loss is    0.30.\n",
      "134/244 [===============>..............] - ETA: 1:39 - loss: 0.2961 - iou_score: 0.6923 - f1-score: 0.8159For batch 133, tr_loss is    0.30.\n",
      "135/244 [===============>..............] - ETA: 1:38 - loss: 0.2965 - iou_score: 0.6917 - f1-score: 0.8154For batch 134, tr_loss is    0.30.\n",
      "136/244 [===============>..............] - ETA: 1:37 - loss: 0.2962 - iou_score: 0.6921 - f1-score: 0.8157For batch 135, tr_loss is    0.30.\n",
      "137/244 [===============>..............] - ETA: 1:36 - loss: 0.2960 - iou_score: 0.6923 - f1-score: 0.8159For batch 136, tr_loss is    0.30.\n",
      "138/244 [===============>..............] - ETA: 1:35 - loss: 0.2960 - iou_score: 0.6922 - f1-score: 0.8158For batch 137, tr_loss is    0.30.\n",
      "139/244 [================>.............] - ETA: 1:34 - loss: 0.2962 - iou_score: 0.6919 - f1-score: 0.8156For batch 138, tr_loss is    0.30.\n",
      "140/244 [================>.............] - ETA: 1:33 - loss: 0.2961 - iou_score: 0.6919 - f1-score: 0.8156For batch 139, tr_loss is    0.30.\n",
      "141/244 [================>.............] - ETA: 1:32 - loss: 0.2962 - iou_score: 0.6917 - f1-score: 0.8155For batch 140, tr_loss is    0.30.\n",
      "142/244 [================>.............] - ETA: 1:31 - loss: 0.2962 - iou_score: 0.6915 - f1-score: 0.8154For batch 141, tr_loss is    0.30.\n",
      "143/244 [================>.............] - ETA: 1:30 - loss: 0.2959 - iou_score: 0.6920 - f1-score: 0.8157For batch 142, tr_loss is    0.30.\n",
      "144/244 [================>.............] - ETA: 1:29 - loss: 0.2966 - iou_score: 0.6914 - f1-score: 0.8152For batch 143, tr_loss is    0.30.\n",
      "145/244 [================>.............] - ETA: 1:28 - loss: 0.2966 - iou_score: 0.6912 - f1-score: 0.8151For batch 144, tr_loss is    0.30.\n",
      "146/244 [================>.............] - ETA: 1:28 - loss: 0.2966 - iou_score: 0.6911 - f1-score: 0.8151For batch 145, tr_loss is    0.30.\n",
      "147/244 [=================>............] - ETA: 1:27 - loss: 0.2966 - iou_score: 0.6910 - f1-score: 0.8150For batch 146, tr_loss is    0.30.\n",
      "148/244 [=================>............] - ETA: 1:26 - loss: 0.2966 - iou_score: 0.6908 - f1-score: 0.8149For batch 147, tr_loss is    0.30.\n",
      "149/244 [=================>............] - ETA: 1:25 - loss: 0.2968 - iou_score: 0.6906 - f1-score: 0.8147For batch 148, tr_loss is    0.30.\n",
      "150/244 [=================>............] - ETA: 1:25 - loss: 0.2967 - iou_score: 0.6908 - f1-score: 0.8148For batch 149, tr_loss is    0.30.\n",
      "151/244 [=================>............] - ETA: 1:23 - loss: 0.2968 - iou_score: 0.6908 - f1-score: 0.8149For batch 150, tr_loss is    0.30.\n",
      "152/244 [=================>............] - ETA: 1:23 - loss: 0.2971 - iou_score: 0.6905 - f1-score: 0.8147For batch 151, tr_loss is    0.30.\n",
      "153/244 [=================>............] - ETA: 1:22 - loss: 0.2969 - iou_score: 0.6908 - f1-score: 0.8149For batch 152, tr_loss is    0.30.\n",
      "154/244 [=================>............] - ETA: 1:21 - loss: 0.2969 - iou_score: 0.6908 - f1-score: 0.8149For batch 153, tr_loss is    0.30.\n",
      "155/244 [==================>...........] - ETA: 1:20 - loss: 0.2971 - iou_score: 0.6906 - f1-score: 0.8148For batch 154, tr_loss is    0.30.\n",
      "156/244 [==================>...........] - ETA: 1:19 - loss: 0.2967 - iou_score: 0.6910 - f1-score: 0.8151For batch 155, tr_loss is    0.30.\n",
      "157/244 [==================>...........] - ETA: 1:18 - loss: 0.2966 - iou_score: 0.6911 - f1-score: 0.8152For batch 156, tr_loss is    0.30.\n",
      "158/244 [==================>...........] - ETA: 1:17 - loss: 0.2968 - iou_score: 0.6910 - f1-score: 0.8150For batch 157, tr_loss is    0.30.\n",
      "159/244 [==================>...........] - ETA: 1:16 - loss: 0.2965 - iou_score: 0.6912 - f1-score: 0.8152For batch 158, tr_loss is    0.30.\n",
      "160/244 [==================>...........] - ETA: 1:15 - loss: 0.2962 - iou_score: 0.6915 - f1-score: 0.8154For batch 159, tr_loss is    0.30.\n",
      "161/244 [==================>...........] - ETA: 1:14 - loss: 0.2963 - iou_score: 0.6913 - f1-score: 0.8153For batch 160, tr_loss is    0.30.\n",
      "162/244 [==================>...........] - ETA: 1:13 - loss: 0.2960 - iou_score: 0.6915 - f1-score: 0.8155For batch 161, tr_loss is    0.30.\n",
      "163/244 [===================>..........] - ETA: 1:12 - loss: 0.2963 - iou_score: 0.6915 - f1-score: 0.8155For batch 162, tr_loss is    0.30.\n",
      "164/244 [===================>..........] - ETA: 1:12 - loss: 0.2961 - iou_score: 0.6918 - f1-score: 0.8157For batch 163, tr_loss is    0.30.\n",
      "165/244 [===================>..........] - ETA: 1:11 - loss: 0.2963 - iou_score: 0.6916 - f1-score: 0.8156For batch 164, tr_loss is    0.30.\n",
      "166/244 [===================>..........] - ETA: 1:10 - loss: 0.2967 - iou_score: 0.6912 - f1-score: 0.8153For batch 165, tr_loss is    0.30.\n",
      "167/244 [===================>..........] - ETA: 1:09 - loss: 0.2966 - iou_score: 0.6916 - f1-score: 0.8155For batch 166, tr_loss is    0.30.\n",
      "168/244 [===================>..........] - ETA: 1:08 - loss: 0.2962 - iou_score: 0.6919 - f1-score: 0.8157For batch 167, tr_loss is    0.30.\n",
      "169/244 [===================>..........] - ETA: 1:07 - loss: 0.2958 - iou_score: 0.6924 - f1-score: 0.8161For batch 168, tr_loss is    0.30.\n",
      "170/244 [===================>..........] - ETA: 1:06 - loss: 0.2961 - iou_score: 0.6920 - f1-score: 0.8158For batch 169, tr_loss is    0.30.\n",
      "171/244 [====================>.........] - ETA: 1:05 - loss: 0.2958 - iou_score: 0.6923 - f1-score: 0.8161For batch 170, tr_loss is    0.30.\n",
      "172/244 [====================>.........] - ETA: 1:04 - loss: 0.2959 - iou_score: 0.6922 - f1-score: 0.8160For batch 171, tr_loss is    0.30.\n",
      "173/244 [====================>.........] - ETA: 1:03 - loss: 0.2962 - iou_score: 0.6920 - f1-score: 0.8158For batch 172, tr_loss is    0.30.\n",
      "174/244 [====================>.........] - ETA: 1:02 - loss: 0.2966 - iou_score: 0.6915 - f1-score: 0.8154For batch 173, tr_loss is    0.30.\n",
      "175/244 [====================>.........] - ETA: 1:01 - loss: 0.2970 - iou_score: 0.6911 - f1-score: 0.8152For batch 174, tr_loss is    0.30.\n",
      "176/244 [====================>.........] - ETA: 1:00 - loss: 0.2970 - iou_score: 0.6912 - f1-score: 0.8152For batch 175, tr_loss is    0.30.\n",
      "177/244 [====================>.........] - ETA: 59s - loss: 0.2967 - iou_score: 0.6917 - f1-score: 0.8155 For batch 176, tr_loss is    0.30.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/244 [====================>.........] - ETA: 59s - loss: 0.2969 - iou_score: 0.6914 - f1-score: 0.8153For batch 177, tr_loss is    0.30.\n",
      "179/244 [=====================>........] - ETA: 58s - loss: 0.2967 - iou_score: 0.6916 - f1-score: 0.8155For batch 178, tr_loss is    0.30.\n",
      "180/244 [=====================>........] - ETA: 57s - loss: 0.2967 - iou_score: 0.6916 - f1-score: 0.8155For batch 179, tr_loss is    0.30.\n",
      "181/244 [=====================>........] - ETA: 56s - loss: 0.2964 - iou_score: 0.6920 - f1-score: 0.8158For batch 180, tr_loss is    0.30.\n",
      "182/244 [=====================>........] - ETA: 55s - loss: 0.2965 - iou_score: 0.6919 - f1-score: 0.8157For batch 181, tr_loss is    0.30.\n",
      "183/244 [=====================>........] - ETA: 54s - loss: 0.2965 - iou_score: 0.6919 - f1-score: 0.8157For batch 182, tr_loss is    0.30.\n",
      "184/244 [=====================>........] - ETA: 53s - loss: 0.2967 - iou_score: 0.6915 - f1-score: 0.8155For batch 183, tr_loss is    0.30.\n",
      "185/244 [=====================>........] - ETA: 52s - loss: 0.2969 - iou_score: 0.6914 - f1-score: 0.8154For batch 184, tr_loss is    0.30.\n",
      "186/244 [=====================>........] - ETA: 52s - loss: 0.2967 - iou_score: 0.6917 - f1-score: 0.8156For batch 185, tr_loss is    0.30.\n",
      "187/244 [=====================>........] - ETA: 51s - loss: 0.2970 - iou_score: 0.6914 - f1-score: 0.8153For batch 186, tr_loss is    0.30.\n",
      "188/244 [======================>.......] - ETA: 50s - loss: 0.2970 - iou_score: 0.6913 - f1-score: 0.8153For batch 187, tr_loss is    0.30.\n",
      "189/244 [======================>.......] - ETA: 49s - loss: 0.2969 - iou_score: 0.6915 - f1-score: 0.8155For batch 188, tr_loss is    0.30.\n",
      "190/244 [======================>.......] - ETA: 48s - loss: 0.2966 - iou_score: 0.6920 - f1-score: 0.8158For batch 189, tr_loss is    0.30.\n",
      "191/244 [======================>.......] - ETA: 47s - loss: 0.2963 - iou_score: 0.6923 - f1-score: 0.8160For batch 190, tr_loss is    0.30.\n",
      "192/244 [======================>.......] - ETA: 46s - loss: 0.2963 - iou_score: 0.6922 - f1-score: 0.8159For batch 191, tr_loss is    0.30.\n",
      "193/244 [======================>.......] - ETA: 45s - loss: 0.2963 - iou_score: 0.6920 - f1-score: 0.8158For batch 192, tr_loss is    0.30.\n",
      "194/244 [======================>.......] - ETA: 44s - loss: 0.2961 - iou_score: 0.6923 - f1-score: 0.8160For batch 193, tr_loss is    0.30.\n",
      "195/244 [======================>.......] - ETA: 43s - loss: 0.2963 - iou_score: 0.6922 - f1-score: 0.8160For batch 194, tr_loss is    0.30.\n",
      "196/244 [=======================>......] - ETA: 43s - loss: 0.2962 - iou_score: 0.6922 - f1-score: 0.8160For batch 195, tr_loss is    0.30.\n",
      "197/244 [=======================>......] - ETA: 42s - loss: 0.2963 - iou_score: 0.6920 - f1-score: 0.8159For batch 196, tr_loss is    0.30.\n",
      "198/244 [=======================>......] - ETA: 41s - loss: 0.2961 - iou_score: 0.6921 - f1-score: 0.8159For batch 197, tr_loss is    0.30.\n",
      "199/244 [=======================>......] - ETA: 40s - loss: 0.2959 - iou_score: 0.6924 - f1-score: 0.8161For batch 198, tr_loss is    0.30.\n",
      "200/244 [=======================>......] - ETA: 39s - loss: 0.2961 - iou_score: 0.6924 - f1-score: 0.8161For batch 199, tr_loss is    0.30.\n",
      "201/244 [=======================>......] - ETA: 38s - loss: 0.2964 - iou_score: 0.6922 - f1-score: 0.8160For batch 200, tr_loss is    0.30.\n",
      "202/244 [=======================>......] - ETA: 37s - loss: 0.2962 - iou_score: 0.6923 - f1-score: 0.8161For batch 201, tr_loss is    0.30.\n",
      "203/244 [=======================>......] - ETA: 36s - loss: 0.2961 - iou_score: 0.6925 - f1-score: 0.8162For batch 202, tr_loss is    0.30.\n",
      "204/244 [========================>.....] - ETA: 35s - loss: 0.2958 - iou_score: 0.6927 - f1-score: 0.8163For batch 203, tr_loss is    0.30.\n",
      "205/244 [========================>.....] - ETA: 35s - loss: 0.2954 - iou_score: 0.6931 - f1-score: 0.8166For batch 204, tr_loss is    0.30.\n",
      "206/244 [========================>.....] - ETA: 34s - loss: 0.2956 - iou_score: 0.6928 - f1-score: 0.8164For batch 205, tr_loss is    0.30.\n",
      "207/244 [========================>.....] - ETA: 33s - loss: 0.2953 - iou_score: 0.6930 - f1-score: 0.8166For batch 206, tr_loss is    0.30.\n",
      "208/244 [========================>.....] - ETA: 32s - loss: 0.2954 - iou_score: 0.6928 - f1-score: 0.8164For batch 207, tr_loss is    0.30.\n",
      "209/244 [========================>.....] - ETA: 31s - loss: 0.2952 - iou_score: 0.6929 - f1-score: 0.8165For batch 208, tr_loss is    0.30.\n",
      "210/244 [========================>.....] - ETA: 30s - loss: 0.2950 - iou_score: 0.6932 - f1-score: 0.8167For batch 209, tr_loss is    0.29.\n",
      "211/244 [========================>.....] - ETA: 29s - loss: 0.2949 - iou_score: 0.6932 - f1-score: 0.8167For batch 210, tr_loss is    0.29.\n",
      "212/244 [=========================>....] - ETA: 28s - loss: 0.2950 - iou_score: 0.6931 - f1-score: 0.8166For batch 211, tr_loss is    0.29.\n",
      "213/244 [=========================>....] - ETA: 27s - loss: 0.2951 - iou_score: 0.6930 - f1-score: 0.8165For batch 212, tr_loss is    0.30.\n",
      "214/244 [=========================>....] - ETA: 26s - loss: 0.2949 - iou_score: 0.6934 - f1-score: 0.8168For batch 213, tr_loss is    0.29.\n",
      "215/244 [=========================>....] - ETA: 25s - loss: 0.2948 - iou_score: 0.6936 - f1-score: 0.8170For batch 214, tr_loss is    0.29.\n",
      "216/244 [=========================>....] - ETA: 25s - loss: 0.2950 - iou_score: 0.6935 - f1-score: 0.8169For batch 215, tr_loss is    0.29.\n",
      "217/244 [=========================>....] - ETA: 24s - loss: 0.2950 - iou_score: 0.6935 - f1-score: 0.8169For batch 216, tr_loss is    0.30.\n",
      "218/244 [=========================>....] - ETA: 23s - loss: 0.2949 - iou_score: 0.6935 - f1-score: 0.8169For batch 217, tr_loss is    0.29.\n",
      "219/244 [=========================>....] - ETA: 22s - loss: 0.2948 - iou_score: 0.6936 - f1-score: 0.8170For batch 218, tr_loss is    0.29.\n",
      "220/244 [==========================>...] - ETA: 21s - loss: 0.2948 - iou_score: 0.6935 - f1-score: 0.8169For batch 219, tr_loss is    0.29.\n",
      "221/244 [==========================>...] - ETA: 20s - loss: 0.2950 - iou_score: 0.6934 - f1-score: 0.8168For batch 220, tr_loss is    0.29.\n",
      "222/244 [==========================>...] - ETA: 19s - loss: 0.2946 - iou_score: 0.6937 - f1-score: 0.8171For batch 221, tr_loss is    0.29.\n",
      "223/244 [==========================>...] - ETA: 18s - loss: 0.2946 - iou_score: 0.6937 - f1-score: 0.8171For batch 222, tr_loss is    0.29.\n",
      "224/244 [==========================>...] - ETA: 17s - loss: 0.2946 - iou_score: 0.6937 - f1-score: 0.8170For batch 223, tr_loss is    0.29.\n",
      "225/244 [==========================>...] - ETA: 16s - loss: 0.2945 - iou_score: 0.6937 - f1-score: 0.8171For batch 224, tr_loss is    0.29.\n",
      "226/244 [==========================>...] - ETA: 16s - loss: 0.2944 - iou_score: 0.6938 - f1-score: 0.8172For batch 225, tr_loss is    0.29.\n",
      "227/244 [==========================>...] - ETA: 15s - loss: 0.2942 - iou_score: 0.6940 - f1-score: 0.8173For batch 226, tr_loss is    0.29.\n",
      "228/244 [===========================>..] - ETA: 14s - loss: 0.2942 - iou_score: 0.6941 - f1-score: 0.8174For batch 227, tr_loss is    0.29.\n",
      "229/244 [===========================>..] - ETA: 13s - loss: 0.2939 - iou_score: 0.6945 - f1-score: 0.8176For batch 228, tr_loss is    0.29.\n",
      "230/244 [===========================>..] - ETA: 12s - loss: 0.2937 - iou_score: 0.6946 - f1-score: 0.8177For batch 229, tr_loss is    0.29.\n",
      "231/244 [===========================>..] - ETA: 11s - loss: 0.2935 - iou_score: 0.6948 - f1-score: 0.8178For batch 230, tr_loss is    0.29.\n",
      "232/244 [===========================>..] - ETA: 10s - loss: 0.2935 - iou_score: 0.6947 - f1-score: 0.8178For batch 231, tr_loss is    0.29.\n",
      "233/244 [===========================>..] - ETA: 9s - loss: 0.2941 - iou_score: 0.6942 - f1-score: 0.8175 For batch 232, tr_loss is    0.29.\n",
      "234/244 [===========================>..] - ETA: 8s - loss: 0.2942 - iou_score: 0.6942 - f1-score: 0.8174For batch 233, tr_loss is    0.29.\n",
      "235/244 [===========================>..] - ETA: 8s - loss: 0.2939 - iou_score: 0.6944 - f1-score: 0.8176For batch 234, tr_loss is    0.29.\n",
      "236/244 [============================>.] - ETA: 7s - loss: 0.2942 - iou_score: 0.6943 - f1-score: 0.8175For batch 235, tr_loss is    0.29.\n",
      "237/244 [============================>.] - ETA: 6s - loss: 0.2942 - iou_score: 0.6943 - f1-score: 0.8175For batch 236, tr_loss is    0.29.\n",
      "238/244 [============================>.] - ETA: 5s - loss: 0.2940 - iou_score: 0.6945 - f1-score: 0.8176For batch 237, tr_loss is    0.29.\n",
      "239/244 [============================>.] - ETA: 4s - loss: 0.2939 - iou_score: 0.6946 - f1-score: 0.8177For batch 238, tr_loss is    0.29.\n",
      "240/244 [============================>.] - ETA: 3s - loss: 0.2937 - iou_score: 0.6948 - f1-score: 0.8178For batch 239, tr_loss is    0.29.\n",
      "241/244 [============================>.] - ETA: 2s - loss: 0.2937 - iou_score: 0.6948 - f1-score: 0.8179For batch 240, tr_loss is    0.29.\n",
      "242/244 [============================>.] - ETA: 1s - loss: 0.2939 - iou_score: 0.6945 - f1-score: 0.8176For batch 241, tr_loss is    0.29.\n",
      "243/244 [============================>.] - ETA: 0s - loss: 0.2943 - iou_score: 0.6941 - f1-score: 0.8173For batch 242, tr_loss is    0.29.\n",
      "244/244 [==============================] - ETA: 0s - loss: 0.2942 - iou_score: 0.6941 - f1-score: 0.8173For batch 243, tr_loss is    0.29.\n",
      "For batch 0, vl_loss is    0.35.\n",
      "For batch 1, vl_loss is    0.35.\n",
      "For batch 2, vl_loss is    0.34.\n",
      "For batch 3, vl_loss is    0.35.\n",
      "For batch 4, vl_loss is    0.34.\n",
      "For batch 5, vl_loss is    0.34.\n",
      "For batch 6, vl_loss is    0.36.\n",
      "For batch 7, vl_loss is    0.36.\n",
      "For batch 8, vl_loss is    0.36.\n",
      "For batch 9, vl_loss is    0.36.\n",
      "For batch 10, vl_loss is    0.36.\n",
      "For batch 11, vl_loss is    0.37.\n",
      "For batch 12, vl_loss is    0.37.\n",
      "For batch 13, vl_loss is    0.37.\n",
      "For batch 14, vl_loss is    0.37.\n",
      "For batch 15, vl_loss is    0.37.\n",
      "For batch 16, vl_loss is    0.37.\n",
      "For batch 17, vl_loss is    0.37.\n",
      "For batch 18, vl_loss is    0.37.\n",
      "For batch 19, vl_loss is    0.37.\n",
      "For batch 20, vl_loss is    0.37.\n",
      "For batch 21, vl_loss is    0.37.\n",
      "For batch 22, vl_loss is    0.37.\n",
      "For batch 23, vl_loss is    0.37.\n",
      "For batch 24, vl_loss is    0.37.\n",
      "For batch 25, vl_loss is    0.37.\n",
      "For batch 26, vl_loss is    0.37.\n",
      "For batch 27, vl_loss is    0.37.\n",
      "For batch 28, vl_loss is    0.37.\n",
      "For batch 29, vl_loss is    0.37.\n",
      "For batch 30, vl_loss is    0.37.\n",
      "For batch 31, vl_loss is    0.37.\n",
      "For batch 32, vl_loss is    0.37.\n",
      "For batch 33, vl_loss is    0.37.\n",
      "For batch 34, vl_loss is    0.37.\n",
      "For batch 35, vl_loss is    0.37.\n",
      "For batch 36, vl_loss is    0.37.\n",
      "For batch 37, vl_loss is    0.37.\n",
      "For batch 38, vl_loss is    0.37.\n",
      "For batch 39, vl_loss is    0.37.\n",
      "For batch 40, vl_loss is    0.37.\n",
      "For batch 41, vl_loss is    0.37.\n",
      "For batch 42, vl_loss is    0.37.\n",
      "For batch 43, vl_loss is    0.37.\n",
      "For batch 44, vl_loss is    0.37.\n",
      "For batch 45, vl_loss is    0.37.\n",
      "For batch 46, vl_loss is    0.37.\n",
      "For batch 47, vl_loss is    0.37.\n",
      "For batch 48, vl_loss is    0.37.\n",
      "For batch 49, vl_loss is    0.36.\n",
      "For batch 50, vl_loss is    0.36.\n",
      "For batch 51, vl_loss is    0.37.\n",
      "For batch 52, vl_loss is    0.36.\n",
      "For batch 53, vl_loss is    0.36.\n",
      "For batch 54, vl_loss is    0.36.\n",
      "For batch 55, vl_loss is    0.37.\n",
      "244/244 [==============================] - 220s 895ms/step - loss: 0.2942 - iou_score: 0.6941 - f1-score: 0.8173 - val_loss: 0.3651 - val_iou_score: 0.6241 - val_f1-score: 0.7665\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.34998\n",
      "The average loss for epoch 4 is    0.29 \n",
      "Epoch 6/200\n",
      "  1/244 [..............................] - ETA: 14:54 - loss: 0.3428 - iou_score: 0.6433 - f1-score: 0.7813For batch 0, tr_loss is    0.34.\n",
      "  2/244 [..............................] - ETA: 4:29 - loss: 0.3111 - iou_score: 0.6854 - f1-score: 0.8118 For batch 1, tr_loss is    0.31.\n",
      "  3/244 [..............................] - ETA: 4:15 - loss: 0.2995 - iou_score: 0.6978 - f1-score: 0.8208For batch 2, tr_loss is    0.30.\n",
      "  4/244 [..............................] - ETA: 4:37 - loss: 0.3031 - iou_score: 0.6954 - f1-score: 0.8194For batch 3, tr_loss is    0.30.\n",
      "  5/244 [..............................] - ETA: 4:47 - loss: 0.3015 - iou_score: 0.6945 - f1-score: 0.8187For batch 4, tr_loss is    0.30.\n",
      "  6/244 [..............................] - ETA: 4:51 - loss: 0.3097 - iou_score: 0.6841 - f1-score: 0.8114For batch 5, tr_loss is    0.31.\n",
      "  7/244 [..............................] - ETA: 4:52 - loss: 0.3017 - iou_score: 0.6934 - f1-score: 0.8172For batch 6, tr_loss is    0.30.\n",
      "  8/244 [..............................] - ETA: 4:45 - loss: 0.3050 - iou_score: 0.6852 - f1-score: 0.8111For batch 7, tr_loss is    0.30.\n",
      "  9/244 [>.............................] - ETA: 4:38 - loss: 0.3079 - iou_score: 0.6831 - f1-score: 0.8096For batch 8, tr_loss is    0.31.\n",
      " 10/244 [>.............................] - ETA: 4:17 - loss: 0.3031 - iou_score: 0.6895 - f1-score: 0.8141For batch 9, tr_loss is    0.30.\n",
      " 11/244 [>.............................] - ETA: 4:09 - loss: 0.3016 - iou_score: 0.6936 - f1-score: 0.8170For batch 10, tr_loss is    0.30.\n",
      " 12/244 [>.............................] - ETA: 4:03 - loss: 0.3014 - iou_score: 0.6947 - f1-score: 0.8179For batch 11, tr_loss is    0.30.\n",
      " 13/244 [>.............................] - ETA: 4:01 - loss: 0.2978 - iou_score: 0.6990 - f1-score: 0.8209For batch 12, tr_loss is    0.30.\n",
      " 14/244 [>.............................] - ETA: 3:59 - loss: 0.3030 - iou_score: 0.6930 - f1-score: 0.8167For batch 13, tr_loss is    0.30.\n",
      " 15/244 [>.............................] - ETA: 3:48 - loss: 0.3051 - iou_score: 0.6902 - f1-score: 0.8148For batch 14, tr_loss is    0.31.\n",
      " 16/244 [>.............................] - ETA: 3:49 - loss: 0.3066 - iou_score: 0.6892 - f1-score: 0.8141For batch 15, tr_loss is    0.31.\n",
      " 17/244 [=>............................] - ETA: 3:42 - loss: 0.3034 - iou_score: 0.6929 - f1-score: 0.8168For batch 16, tr_loss is    0.30.\n",
      " 18/244 [=>............................] - ETA: 3:42 - loss: 0.3046 - iou_score: 0.6915 - f1-score: 0.8159For batch 17, tr_loss is    0.30.\n",
      " 19/244 [=>............................] - ETA: 3:38 - loss: 0.3020 - iou_score: 0.6946 - f1-score: 0.8180For batch 18, tr_loss is    0.30.\n",
      " 20/244 [=>............................] - ETA: 3:39 - loss: 0.3019 - iou_score: 0.6940 - f1-score: 0.8174For batch 19, tr_loss is    0.30.\n",
      " 21/244 [=>............................] - ETA: 3:36 - loss: 0.3013 - iou_score: 0.6937 - f1-score: 0.8172For batch 20, tr_loss is    0.30.\n",
      " 22/244 [=>............................] - ETA: 3:35 - loss: 0.3044 - iou_score: 0.6906 - f1-score: 0.8150For batch 21, tr_loss is    0.30.\n",
      " 23/244 [=>............................] - ETA: 3:29 - loss: 0.3040 - iou_score: 0.6899 - f1-score: 0.8146For batch 22, tr_loss is    0.30.\n",
      " 24/244 [=>............................] - ETA: 3:31 - loss: 0.3011 - iou_score: 0.6926 - f1-score: 0.8165For batch 23, tr_loss is    0.30.\n",
      " 25/244 [==>...........................] - ETA: 3:30 - loss: 0.3010 - iou_score: 0.6917 - f1-score: 0.8159For batch 24, tr_loss is    0.30.\n",
      " 26/244 [==>...........................] - ETA: 3:29 - loss: 0.3012 - iou_score: 0.6904 - f1-score: 0.8150For batch 25, tr_loss is    0.30.\n",
      " 27/244 [==>...........................] - ETA: 3:24 - loss: 0.3016 - iou_score: 0.6906 - f1-score: 0.8152For batch 26, tr_loss is    0.30.\n",
      " 28/244 [==>...........................] - ETA: 3:22 - loss: 0.2986 - iou_score: 0.6942 - f1-score: 0.8177For batch 27, tr_loss is    0.30.\n",
      " 29/244 [==>...........................] - ETA: 3:19 - loss: 0.2970 - iou_score: 0.6948 - f1-score: 0.8181For batch 28, tr_loss is    0.30.\n",
      " 30/244 [==>...........................] - ETA: 3:19 - loss: 0.2945 - iou_score: 0.6979 - f1-score: 0.8202For batch 29, tr_loss is    0.29.\n",
      " 31/244 [==>...........................] - ETA: 3:19 - loss: 0.2924 - iou_score: 0.7001 - f1-score: 0.8217For batch 30, tr_loss is    0.29.\n",
      " 32/244 [==>...........................] - ETA: 3:19 - loss: 0.2906 - iou_score: 0.7018 - f1-score: 0.8229For batch 31, tr_loss is    0.29.\n",
      " 33/244 [===>..........................] - ETA: 3:15 - loss: 0.2899 - iou_score: 0.7019 - f1-score: 0.8231For batch 32, tr_loss is    0.29.\n",
      " 34/244 [===>..........................] - ETA: 3:15 - loss: 0.2899 - iou_score: 0.7020 - f1-score: 0.8232For batch 33, tr_loss is    0.29.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 35/244 [===>..........................] - ETA: 3:14 - loss: 0.2920 - iou_score: 0.7001 - f1-score: 0.8219For batch 34, tr_loss is    0.29.\n",
      " 36/244 [===>..........................] - ETA: 3:13 - loss: 0.2903 - iou_score: 0.7020 - f1-score: 0.8232For batch 35, tr_loss is    0.29.\n",
      " 37/244 [===>..........................] - ETA: 3:10 - loss: 0.2916 - iou_score: 0.7001 - f1-score: 0.8218For batch 36, tr_loss is    0.29.\n",
      " 38/244 [===>..........................] - ETA: 3:08 - loss: 0.2908 - iou_score: 0.7017 - f1-score: 0.8229For batch 37, tr_loss is    0.29.\n",
      " 39/244 [===>..........................] - ETA: 3:07 - loss: 0.2894 - iou_score: 0.7035 - f1-score: 0.8241For batch 38, tr_loss is    0.29.\n",
      " 40/244 [===>..........................] - ETA: 3:04 - loss: 0.2895 - iou_score: 0.7028 - f1-score: 0.8237For batch 39, tr_loss is    0.29.\n",
      " 41/244 [====>.........................] - ETA: 3:02 - loss: 0.2903 - iou_score: 0.7013 - f1-score: 0.8227For batch 40, tr_loss is    0.29.\n",
      " 42/244 [====>.........................] - ETA: 3:00 - loss: 0.2892 - iou_score: 0.7023 - f1-score: 0.8234For batch 41, tr_loss is    0.29.\n",
      " 43/244 [====>.........................] - ETA: 3:00 - loss: 0.2900 - iou_score: 0.7009 - f1-score: 0.8224For batch 42, tr_loss is    0.29.\n",
      " 44/244 [====>.........................] - ETA: 2:57 - loss: 0.2898 - iou_score: 0.7014 - f1-score: 0.8227For batch 43, tr_loss is    0.29.\n",
      " 45/244 [====>.........................] - ETA: 2:56 - loss: 0.2897 - iou_score: 0.7011 - f1-score: 0.8226For batch 44, tr_loss is    0.29.\n",
      " 46/244 [====>.........................] - ETA: 2:55 - loss: 0.2893 - iou_score: 0.7016 - f1-score: 0.8229For batch 45, tr_loss is    0.29.\n",
      " 47/244 [====>.........................] - ETA: 2:54 - loss: 0.2881 - iou_score: 0.7027 - f1-score: 0.8237For batch 46, tr_loss is    0.29.\n",
      " 48/244 [====>.........................] - ETA: 2:54 - loss: 0.2871 - iou_score: 0.7037 - f1-score: 0.8243For batch 47, tr_loss is    0.29.\n",
      " 49/244 [=====>........................] - ETA: 2:53 - loss: 0.2881 - iou_score: 0.7025 - f1-score: 0.8235For batch 48, tr_loss is    0.29.\n",
      " 50/244 [=====>........................] - ETA: 2:53 - loss: 0.2877 - iou_score: 0.7027 - f1-score: 0.8237For batch 49, tr_loss is    0.29.\n",
      " 51/244 [=====>........................] - ETA: 2:52 - loss: 0.2892 - iou_score: 0.7013 - f1-score: 0.8227For batch 50, tr_loss is    0.29.\n",
      " 52/244 [=====>........................] - ETA: 2:52 - loss: 0.2892 - iou_score: 0.7013 - f1-score: 0.8227For batch 51, tr_loss is    0.29.\n",
      " 53/244 [=====>........................] - ETA: 2:51 - loss: 0.2892 - iou_score: 0.7009 - f1-score: 0.8224For batch 52, tr_loss is    0.29.\n",
      " 54/244 [=====>........................] - ETA: 2:51 - loss: 0.2892 - iou_score: 0.7006 - f1-score: 0.8223For batch 53, tr_loss is    0.29.\n",
      " 55/244 [=====>........................] - ETA: 2:49 - loss: 0.2879 - iou_score: 0.7017 - f1-score: 0.8230For batch 54, tr_loss is    0.29.\n",
      " 56/244 [=====>........................] - ETA: 2:49 - loss: 0.2870 - iou_score: 0.7027 - f1-score: 0.8237For batch 55, tr_loss is    0.29.\n",
      " 57/244 [======>.......................] - ETA: 2:48 - loss: 0.2877 - iou_score: 0.7021 - f1-score: 0.8233For batch 56, tr_loss is    0.29.\n",
      " 58/244 [======>.......................] - ETA: 2:47 - loss: 0.2891 - iou_score: 0.7005 - f1-score: 0.8222For batch 57, tr_loss is    0.29.\n",
      " 59/244 [======>.......................] - ETA: 2:45 - loss: 0.2880 - iou_score: 0.7027 - f1-score: 0.8236For batch 58, tr_loss is    0.29.\n",
      " 60/244 [======>.......................] - ETA: 2:45 - loss: 0.2896 - iou_score: 0.7005 - f1-score: 0.8220For batch 59, tr_loss is    0.29.\n",
      " 61/244 [======>.......................] - ETA: 2:44 - loss: 0.2908 - iou_score: 0.6986 - f1-score: 0.8206For batch 60, tr_loss is    0.29.\n",
      " 62/244 [======>.......................] - ETA: 2:44 - loss: 0.2908 - iou_score: 0.6985 - f1-score: 0.8206For batch 61, tr_loss is    0.29.\n",
      " 63/244 [======>.......................] - ETA: 2:42 - loss: 0.2911 - iou_score: 0.6983 - f1-score: 0.8205For batch 62, tr_loss is    0.29.\n",
      " 64/244 [======>.......................] - ETA: 2:41 - loss: 0.2902 - iou_score: 0.6995 - f1-score: 0.8212For batch 63, tr_loss is    0.29.\n",
      " 65/244 [======>.......................] - ETA: 2:41 - loss: 0.2901 - iou_score: 0.6993 - f1-score: 0.8211For batch 64, tr_loss is    0.29.\n",
      " 66/244 [=======>......................] - ETA: 2:40 - loss: 0.2900 - iou_score: 0.6996 - f1-score: 0.8213For batch 65, tr_loss is    0.29.\n",
      " 67/244 [=======>......................] - ETA: 2:39 - loss: 0.2896 - iou_score: 0.7002 - f1-score: 0.8218For batch 66, tr_loss is    0.29.\n",
      " 68/244 [=======>......................] - ETA: 2:38 - loss: 0.2895 - iou_score: 0.7006 - f1-score: 0.8220For batch 67, tr_loss is    0.29.\n",
      " 69/244 [=======>......................] - ETA: 2:38 - loss: 0.2903 - iou_score: 0.6993 - f1-score: 0.8211For batch 68, tr_loss is    0.29.\n",
      " 70/244 [=======>......................] - ETA: 2:37 - loss: 0.2899 - iou_score: 0.6996 - f1-score: 0.8213For batch 69, tr_loss is    0.29.\n",
      " 71/244 [=======>......................] - ETA: 2:36 - loss: 0.2899 - iou_score: 0.6996 - f1-score: 0.8213For batch 70, tr_loss is    0.29.\n",
      " 72/244 [=======>......................] - ETA: 2:35 - loss: 0.2891 - iou_score: 0.7005 - f1-score: 0.8219For batch 71, tr_loss is    0.29.\n",
      " 73/244 [=======>......................] - ETA: 2:35 - loss: 0.2895 - iou_score: 0.6998 - f1-score: 0.8214For batch 72, tr_loss is    0.29.\n",
      " 74/244 [========>.....................] - ETA: 2:34 - loss: 0.2898 - iou_score: 0.6994 - f1-score: 0.8211For batch 73, tr_loss is    0.29.\n",
      " 75/244 [========>.....................] - ETA: 2:34 - loss: 0.2897 - iou_score: 0.6992 - f1-score: 0.8210For batch 74, tr_loss is    0.29.\n",
      " 76/244 [========>.....................] - ETA: 2:32 - loss: 0.2887 - iou_score: 0.7006 - f1-score: 0.8219For batch 75, tr_loss is    0.29.\n",
      " 77/244 [========>.....................] - ETA: 2:32 - loss: 0.2887 - iou_score: 0.7006 - f1-score: 0.8219For batch 76, tr_loss is    0.29.\n",
      " 78/244 [========>.....................] - ETA: 2:31 - loss: 0.2885 - iou_score: 0.7009 - f1-score: 0.8221For batch 77, tr_loss is    0.29.\n",
      " 79/244 [========>.....................] - ETA: 2:29 - loss: 0.2886 - iou_score: 0.7013 - f1-score: 0.8223For batch 78, tr_loss is    0.29.\n",
      " 80/244 [========>.....................] - ETA: 2:29 - loss: 0.2882 - iou_score: 0.7014 - f1-score: 0.8224For batch 79, tr_loss is    0.29.\n",
      " 81/244 [========>.....................] - ETA: 2:28 - loss: 0.2887 - iou_score: 0.7011 - f1-score: 0.8222For batch 80, tr_loss is    0.29.\n",
      " 82/244 [=========>....................] - ETA: 2:27 - loss: 0.2899 - iou_score: 0.6994 - f1-score: 0.8209For batch 81, tr_loss is    0.29.\n",
      " 83/244 [=========>....................] - ETA: 2:25 - loss: 0.2891 - iou_score: 0.7003 - f1-score: 0.8215For batch 82, tr_loss is    0.29.\n",
      " 84/244 [=========>....................] - ETA: 2:25 - loss: 0.2887 - iou_score: 0.7006 - f1-score: 0.8218For batch 83, tr_loss is    0.29.\n",
      " 85/244 [=========>....................] - ETA: 2:24 - loss: 0.2881 - iou_score: 0.7013 - f1-score: 0.8222For batch 84, tr_loss is    0.29.\n",
      " 86/244 [=========>....................] - ETA: 2:23 - loss: 0.2882 - iou_score: 0.7010 - f1-score: 0.8221For batch 85, tr_loss is    0.29.\n",
      " 87/244 [=========>....................] - ETA: 2:21 - loss: 0.2879 - iou_score: 0.7013 - f1-score: 0.8222For batch 86, tr_loss is    0.29.\n",
      " 88/244 [=========>....................] - ETA: 2:21 - loss: 0.2874 - iou_score: 0.7018 - f1-score: 0.8226For batch 87, tr_loss is    0.29.\n",
      " 89/244 [=========>....................] - ETA: 2:20 - loss: 0.2877 - iou_score: 0.7012 - f1-score: 0.8222For batch 88, tr_loss is    0.29.\n",
      " 90/244 [==========>...................] - ETA: 2:19 - loss: 0.2875 - iou_score: 0.7014 - f1-score: 0.8223For batch 89, tr_loss is    0.29.\n",
      " 91/244 [==========>...................] - ETA: 2:19 - loss: 0.2891 - iou_score: 0.6999 - f1-score: 0.8213For batch 90, tr_loss is    0.29.\n",
      " 92/244 [==========>...................] - ETA: 2:17 - loss: 0.2895 - iou_score: 0.6994 - f1-score: 0.8208For batch 91, tr_loss is    0.29.\n",
      " 93/244 [==========>...................] - ETA: 2:17 - loss: 0.2887 - iou_score: 0.7005 - f1-score: 0.8216For batch 92, tr_loss is    0.29.\n",
      " 94/244 [==========>...................] - ETA: 2:16 - loss: 0.2883 - iou_score: 0.7009 - f1-score: 0.8218For batch 93, tr_loss is    0.29.\n",
      " 95/244 [==========>...................] - ETA: 2:15 - loss: 0.2883 - iou_score: 0.7007 - f1-score: 0.8217For batch 94, tr_loss is    0.29.\n",
      " 96/244 [==========>...................] - ETA: 2:13 - loss: 0.2887 - iou_score: 0.7001 - f1-score: 0.8213For batch 95, tr_loss is    0.29.\n",
      " 97/244 [==========>...................] - ETA: 2:13 - loss: 0.2884 - iou_score: 0.7004 - f1-score: 0.8215For batch 96, tr_loss is    0.29.\n",
      " 98/244 [===========>..................] - ETA: 2:12 - loss: 0.2885 - iou_score: 0.7003 - f1-score: 0.8215For batch 97, tr_loss is    0.29.\n",
      " 99/244 [===========>..................] - ETA: 2:11 - loss: 0.2882 - iou_score: 0.7007 - f1-score: 0.8217For batch 98, tr_loss is    0.29.\n",
      "100/244 [===========>..................] - ETA: 2:10 - loss: 0.2874 - iou_score: 0.7017 - f1-score: 0.8224For batch 99, tr_loss is    0.29.\n",
      "101/244 [===========>..................] - ETA: 2:09 - loss: 0.2874 - iou_score: 0.7015 - f1-score: 0.8223For batch 100, tr_loss is    0.29.\n",
      "102/244 [===========>..................] - ETA: 2:08 - loss: 0.2874 - iou_score: 0.7015 - f1-score: 0.8223For batch 101, tr_loss is    0.29.\n",
      "103/244 [===========>..................] - ETA: 2:07 - loss: 0.2869 - iou_score: 0.7021 - f1-score: 0.8227For batch 102, tr_loss is    0.29.\n",
      "104/244 [===========>..................] - ETA: 2:06 - loss: 0.2865 - iou_score: 0.7024 - f1-score: 0.8229For batch 103, tr_loss is    0.29.\n",
      "105/244 [===========>..................] - ETA: 2:05 - loss: 0.2866 - iou_score: 0.7022 - f1-score: 0.8228For batch 104, tr_loss is    0.29.\n",
      "106/244 [============>.................] - ETA: 2:04 - loss: 0.2860 - iou_score: 0.7029 - f1-score: 0.8233For batch 105, tr_loss is    0.29.\n",
      "107/244 [============>.................] - ETA: 2:04 - loss: 0.2856 - iou_score: 0.7034 - f1-score: 0.8237For batch 106, tr_loss is    0.29.\n",
      "108/244 [============>.................] - ETA: 2:02 - loss: 0.2856 - iou_score: 0.7034 - f1-score: 0.8237For batch 107, tr_loss is    0.29.\n",
      "109/244 [============>.................] - ETA: 2:01 - loss: 0.2863 - iou_score: 0.7025 - f1-score: 0.8230For batch 108, tr_loss is    0.29.\n",
      "110/244 [============>.................] - ETA: 2:00 - loss: 0.2864 - iou_score: 0.7022 - f1-score: 0.8228For batch 109, tr_loss is    0.29.\n",
      "111/244 [============>.................] - ETA: 1:59 - loss: 0.2865 - iou_score: 0.7019 - f1-score: 0.8226For batch 110, tr_loss is    0.29.\n",
      "112/244 [============>.................] - ETA: 1:58 - loss: 0.2865 - iou_score: 0.7016 - f1-score: 0.8224For batch 111, tr_loss is    0.29.\n",
      "113/244 [============>.................] - ETA: 1:57 - loss: 0.2866 - iou_score: 0.7018 - f1-score: 0.8226For batch 112, tr_loss is    0.29.\n",
      "114/244 [=============>................] - ETA: 1:56 - loss: 0.2870 - iou_score: 0.7012 - f1-score: 0.8221For batch 113, tr_loss is    0.29.\n",
      "115/244 [=============>................] - ETA: 1:55 - loss: 0.2869 - iou_score: 0.7013 - f1-score: 0.8222For batch 114, tr_loss is    0.29.\n",
      "116/244 [=============>................] - ETA: 1:54 - loss: 0.2866 - iou_score: 0.7014 - f1-score: 0.8223For batch 115, tr_loss is    0.29.\n",
      "117/244 [=============>................] - ETA: 1:54 - loss: 0.2868 - iou_score: 0.7010 - f1-score: 0.8220For batch 116, tr_loss is    0.29.\n",
      "118/244 [=============>................] - ETA: 1:52 - loss: 0.2867 - iou_score: 0.7009 - f1-score: 0.8219For batch 117, tr_loss is    0.29.\n",
      "119/244 [=============>................] - ETA: 1:51 - loss: 0.2864 - iou_score: 0.7009 - f1-score: 0.8220For batch 118, tr_loss is    0.29.\n",
      "120/244 [=============>................] - ETA: 1:51 - loss: 0.2877 - iou_score: 0.6997 - f1-score: 0.8210For batch 119, tr_loss is    0.29.\n",
      "121/244 [=============>................] - ETA: 1:49 - loss: 0.2870 - iou_score: 0.7005 - f1-score: 0.8216For batch 120, tr_loss is    0.29.\n",
      "122/244 [==============>...............] - ETA: 1:48 - loss: 0.2869 - iou_score: 0.7008 - f1-score: 0.8218For batch 121, tr_loss is    0.29.\n",
      "123/244 [==============>...............] - ETA: 1:47 - loss: 0.2874 - iou_score: 0.7000 - f1-score: 0.8212For batch 122, tr_loss is    0.29.\n",
      "124/244 [==============>...............] - ETA: 1:47 - loss: 0.2881 - iou_score: 0.6991 - f1-score: 0.8206For batch 123, tr_loss is    0.29.\n",
      "125/244 [==============>...............] - ETA: 1:46 - loss: 0.2879 - iou_score: 0.6995 - f1-score: 0.8209For batch 124, tr_loss is    0.29.\n",
      "126/244 [==============>...............] - ETA: 1:45 - loss: 0.2877 - iou_score: 0.6997 - f1-score: 0.8210For batch 125, tr_loss is    0.29.\n",
      "127/244 [==============>...............] - ETA: 1:44 - loss: 0.2879 - iou_score: 0.6992 - f1-score: 0.8206For batch 126, tr_loss is    0.29.\n",
      "128/244 [==============>...............] - ETA: 1:43 - loss: 0.2875 - iou_score: 0.6997 - f1-score: 0.8210For batch 127, tr_loss is    0.29.\n",
      "129/244 [==============>...............] - ETA: 1:42 - loss: 0.2872 - iou_score: 0.6999 - f1-score: 0.8211For batch 128, tr_loss is    0.29.\n",
      "130/244 [==============>...............] - ETA: 1:41 - loss: 0.2874 - iou_score: 0.6994 - f1-score: 0.8208For batch 129, tr_loss is    0.29.\n",
      "131/244 [===============>..............] - ETA: 1:40 - loss: 0.2870 - iou_score: 0.6998 - f1-score: 0.8211For batch 130, tr_loss is    0.29.\n",
      "132/244 [===============>..............] - ETA: 1:39 - loss: 0.2874 - iou_score: 0.6993 - f1-score: 0.8207For batch 131, tr_loss is    0.29.\n",
      "133/244 [===============>..............] - ETA: 1:38 - loss: 0.2876 - iou_score: 0.6992 - f1-score: 0.8206For batch 132, tr_loss is    0.29.\n",
      "134/244 [===============>..............] - ETA: 1:38 - loss: 0.2882 - iou_score: 0.6985 - f1-score: 0.8201For batch 133, tr_loss is    0.29.\n",
      "135/244 [===============>..............] - ETA: 1:36 - loss: 0.2883 - iou_score: 0.6981 - f1-score: 0.8199For batch 134, tr_loss is    0.29.\n",
      "136/244 [===============>..............] - ETA: 1:35 - loss: 0.2878 - iou_score: 0.6987 - f1-score: 0.8203For batch 135, tr_loss is    0.29.\n",
      "137/244 [===============>..............] - ETA: 1:35 - loss: 0.2876 - iou_score: 0.6989 - f1-score: 0.8204For batch 136, tr_loss is    0.29.\n",
      "138/244 [===============>..............] - ETA: 1:33 - loss: 0.2878 - iou_score: 0.6986 - f1-score: 0.8202For batch 137, tr_loss is    0.29.\n",
      "139/244 [================>.............] - ETA: 1:33 - loss: 0.2880 - iou_score: 0.6984 - f1-score: 0.8201For batch 138, tr_loss is    0.29.\n",
      "140/244 [================>.............] - ETA: 1:32 - loss: 0.2878 - iou_score: 0.6985 - f1-score: 0.8202For batch 139, tr_loss is    0.29.\n",
      "141/244 [================>.............] - ETA: 1:31 - loss: 0.2878 - iou_score: 0.6984 - f1-score: 0.8201For batch 140, tr_loss is    0.29.\n",
      "142/244 [================>.............] - ETA: 1:30 - loss: 0.2877 - iou_score: 0.6981 - f1-score: 0.8200For batch 141, tr_loss is    0.29.\n",
      "143/244 [================>.............] - ETA: 1:29 - loss: 0.2876 - iou_score: 0.6985 - f1-score: 0.8202For batch 142, tr_loss is    0.29.\n",
      "144/244 [================>.............] - ETA: 1:28 - loss: 0.2883 - iou_score: 0.6979 - f1-score: 0.8197For batch 143, tr_loss is    0.29.\n",
      "145/244 [================>.............] - ETA: 1:27 - loss: 0.2884 - iou_score: 0.6977 - f1-score: 0.8196For batch 144, tr_loss is    0.29.\n",
      "146/244 [================>.............] - ETA: 1:27 - loss: 0.2883 - iou_score: 0.6976 - f1-score: 0.8195For batch 145, tr_loss is    0.29.\n",
      "147/244 [=================>............] - ETA: 1:26 - loss: 0.2883 - iou_score: 0.6975 - f1-score: 0.8195For batch 146, tr_loss is    0.29.\n",
      "148/244 [=================>............] - ETA: 1:25 - loss: 0.2886 - iou_score: 0.6973 - f1-score: 0.8194For batch 147, tr_loss is    0.29.\n",
      "149/244 [=================>............] - ETA: 1:24 - loss: 0.2886 - iou_score: 0.6972 - f1-score: 0.8193For batch 148, tr_loss is    0.29.\n",
      "150/244 [=================>............] - ETA: 1:23 - loss: 0.2885 - iou_score: 0.6973 - f1-score: 0.8194For batch 149, tr_loss is    0.29.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/244 [=================>............] - ETA: 1:22 - loss: 0.2886 - iou_score: 0.6972 - f1-score: 0.8194For batch 150, tr_loss is    0.29.\n",
      "152/244 [=================>............] - ETA: 1:21 - loss: 0.2887 - iou_score: 0.6971 - f1-score: 0.8192For batch 151, tr_loss is    0.29.\n",
      "153/244 [=================>............] - ETA: 1:20 - loss: 0.2887 - iou_score: 0.6972 - f1-score: 0.8194For batch 152, tr_loss is    0.29.\n",
      "154/244 [=================>............] - ETA: 1:19 - loss: 0.2888 - iou_score: 0.6972 - f1-score: 0.8194For batch 153, tr_loss is    0.29.\n",
      "155/244 [==================>...........] - ETA: 1:18 - loss: 0.2889 - iou_score: 0.6971 - f1-score: 0.8193For batch 154, tr_loss is    0.29.\n",
      "156/244 [==================>...........] - ETA: 1:17 - loss: 0.2885 - iou_score: 0.6976 - f1-score: 0.8196For batch 155, tr_loss is    0.29.\n",
      "157/244 [==================>...........] - ETA: 1:16 - loss: 0.2884 - iou_score: 0.6976 - f1-score: 0.8197For batch 156, tr_loss is    0.29.\n",
      "158/244 [==================>...........] - ETA: 1:15 - loss: 0.2885 - iou_score: 0.6975 - f1-score: 0.8196For batch 157, tr_loss is    0.29.\n",
      "159/244 [==================>...........] - ETA: 1:14 - loss: 0.2883 - iou_score: 0.6979 - f1-score: 0.8199For batch 158, tr_loss is    0.29.\n",
      "160/244 [==================>...........] - ETA: 1:13 - loss: 0.2881 - iou_score: 0.6981 - f1-score: 0.8200For batch 159, tr_loss is    0.29.\n",
      "161/244 [==================>...........] - ETA: 1:13 - loss: 0.2882 - iou_score: 0.6979 - f1-score: 0.8199For batch 160, tr_loss is    0.29.\n",
      "162/244 [==================>...........] - ETA: 1:12 - loss: 0.2881 - iou_score: 0.6980 - f1-score: 0.8200For batch 161, tr_loss is    0.29.\n",
      "163/244 [===================>..........] - ETA: 1:11 - loss: 0.2882 - iou_score: 0.6980 - f1-score: 0.8200For batch 162, tr_loss is    0.29.\n",
      "164/244 [===================>..........] - ETA: 1:10 - loss: 0.2881 - iou_score: 0.6981 - f1-score: 0.8201For batch 163, tr_loss is    0.29.\n",
      "165/244 [===================>..........] - ETA: 1:09 - loss: 0.2882 - iou_score: 0.6980 - f1-score: 0.8200For batch 164, tr_loss is    0.29.\n",
      "166/244 [===================>..........] - ETA: 1:08 - loss: 0.2885 - iou_score: 0.6977 - f1-score: 0.8198For batch 165, tr_loss is    0.29.\n",
      "167/244 [===================>..........] - ETA: 1:07 - loss: 0.2883 - iou_score: 0.6981 - f1-score: 0.8201For batch 166, tr_loss is    0.29.\n",
      "168/244 [===================>..........] - ETA: 1:06 - loss: 0.2880 - iou_score: 0.6985 - f1-score: 0.8203For batch 167, tr_loss is    0.29.\n",
      "169/244 [===================>..........] - ETA: 1:06 - loss: 0.2877 - iou_score: 0.6988 - f1-score: 0.8206For batch 168, tr_loss is    0.29.\n",
      "170/244 [===================>..........] - ETA: 1:05 - loss: 0.2879 - iou_score: 0.6984 - f1-score: 0.8203For batch 169, tr_loss is    0.29.\n",
      "171/244 [====================>.........] - ETA: 1:04 - loss: 0.2876 - iou_score: 0.6987 - f1-score: 0.8205For batch 170, tr_loss is    0.29.\n",
      "172/244 [====================>.........] - ETA: 1:03 - loss: 0.2877 - iou_score: 0.6986 - f1-score: 0.8205For batch 171, tr_loss is    0.29.\n",
      "173/244 [====================>.........] - ETA: 1:02 - loss: 0.2880 - iou_score: 0.6985 - f1-score: 0.8203For batch 172, tr_loss is    0.29.\n",
      "174/244 [====================>.........] - ETA: 1:01 - loss: 0.2882 - iou_score: 0.6981 - f1-score: 0.8201For batch 173, tr_loss is    0.29.\n",
      "175/244 [====================>.........] - ETA: 1:00 - loss: 0.2883 - iou_score: 0.6978 - f1-score: 0.8198For batch 174, tr_loss is    0.29.\n",
      "176/244 [====================>.........] - ETA: 59s - loss: 0.2883 - iou_score: 0.6978 - f1-score: 0.8198 For batch 175, tr_loss is    0.29.\n",
      "177/244 [====================>.........] - ETA: 58s - loss: 0.2880 - iou_score: 0.6983 - f1-score: 0.8202For batch 176, tr_loss is    0.29.\n",
      "178/244 [====================>.........] - ETA: 57s - loss: 0.2883 - iou_score: 0.6979 - f1-score: 0.8199For batch 177, tr_loss is    0.29.\n",
      "179/244 [=====================>........] - ETA: 57s - loss: 0.2881 - iou_score: 0.6981 - f1-score: 0.8200For batch 178, tr_loss is    0.29.\n",
      "180/244 [=====================>........] - ETA: 56s - loss: 0.2880 - iou_score: 0.6982 - f1-score: 0.8201For batch 179, tr_loss is    0.29.\n",
      "181/244 [=====================>........] - ETA: 55s - loss: 0.2877 - iou_score: 0.6984 - f1-score: 0.8203For batch 180, tr_loss is    0.29.\n",
      "182/244 [=====================>........] - ETA: 54s - loss: 0.2879 - iou_score: 0.6983 - f1-score: 0.8202For batch 181, tr_loss is    0.29.\n",
      "183/244 [=====================>........] - ETA: 53s - loss: 0.2880 - iou_score: 0.6982 - f1-score: 0.8201For batch 182, tr_loss is    0.29.\n",
      "184/244 [=====================>........] - ETA: 52s - loss: 0.2882 - iou_score: 0.6979 - f1-score: 0.8199For batch 183, tr_loss is    0.29.\n",
      "185/244 [=====================>........] - ETA: 51s - loss: 0.2883 - iou_score: 0.6978 - f1-score: 0.8198For batch 184, tr_loss is    0.29.\n",
      "186/244 [=====================>........] - ETA: 50s - loss: 0.2881 - iou_score: 0.6981 - f1-score: 0.8201For batch 185, tr_loss is    0.29.\n",
      "187/244 [=====================>........] - ETA: 49s - loss: 0.2884 - iou_score: 0.6976 - f1-score: 0.8197For batch 186, tr_loss is    0.29.\n",
      "188/244 [======================>.......] - ETA: 49s - loss: 0.2885 - iou_score: 0.6975 - f1-score: 0.8197For batch 187, tr_loss is    0.29.\n",
      "189/244 [======================>.......] - ETA: 48s - loss: 0.2884 - iou_score: 0.6977 - f1-score: 0.8198For batch 188, tr_loss is    0.29.\n",
      "190/244 [======================>.......] - ETA: 47s - loss: 0.2881 - iou_score: 0.6981 - f1-score: 0.8201For batch 189, tr_loss is    0.29.\n",
      "191/244 [======================>.......] - ETA: 46s - loss: 0.2878 - iou_score: 0.6984 - f1-score: 0.8203For batch 190, tr_loss is    0.29.\n",
      "192/244 [======================>.......] - ETA: 45s - loss: 0.2878 - iou_score: 0.6983 - f1-score: 0.8202For batch 191, tr_loss is    0.29.\n",
      "193/244 [======================>.......] - ETA: 44s - loss: 0.2877 - iou_score: 0.6982 - f1-score: 0.8201For batch 192, tr_loss is    0.29.\n",
      "194/244 [======================>.......] - ETA: 43s - loss: 0.2875 - iou_score: 0.6984 - f1-score: 0.8203For batch 193, tr_loss is    0.29.\n",
      "195/244 [======================>.......] - ETA: 42s - loss: 0.2877 - iou_score: 0.6984 - f1-score: 0.8203For batch 194, tr_loss is    0.29.\n",
      "196/244 [=======================>......] - ETA: 41s - loss: 0.2877 - iou_score: 0.6984 - f1-score: 0.8203For batch 195, tr_loss is    0.29.\n",
      "197/244 [=======================>......] - ETA: 41s - loss: 0.2879 - iou_score: 0.6981 - f1-score: 0.8201For batch 196, tr_loss is    0.29.\n",
      "198/244 [=======================>......] - ETA: 40s - loss: 0.2878 - iou_score: 0.6983 - f1-score: 0.8203For batch 197, tr_loss is    0.29.\n",
      "199/244 [=======================>......] - ETA: 39s - loss: 0.2875 - iou_score: 0.6988 - f1-score: 0.8206For batch 198, tr_loss is    0.29.\n",
      "200/244 [=======================>......] - ETA: 38s - loss: 0.2877 - iou_score: 0.6987 - f1-score: 0.8205For batch 199, tr_loss is    0.29.\n",
      "201/244 [=======================>......] - ETA: 37s - loss: 0.2878 - iou_score: 0.6985 - f1-score: 0.8204For batch 200, tr_loss is    0.29.\n",
      "202/244 [=======================>......] - ETA: 36s - loss: 0.2877 - iou_score: 0.6987 - f1-score: 0.8205For batch 201, tr_loss is    0.29.\n",
      "203/244 [=======================>......] - ETA: 35s - loss: 0.2876 - iou_score: 0.6989 - f1-score: 0.8207For batch 202, tr_loss is    0.29.\n",
      "204/244 [========================>.....] - ETA: 35s - loss: 0.2873 - iou_score: 0.6991 - f1-score: 0.8208For batch 203, tr_loss is    0.29.\n",
      "205/244 [========================>.....] - ETA: 34s - loss: 0.2869 - iou_score: 0.6996 - f1-score: 0.8212For batch 204, tr_loss is    0.29.\n",
      "206/244 [========================>.....] - ETA: 33s - loss: 0.2872 - iou_score: 0.6992 - f1-score: 0.8209For batch 205, tr_loss is    0.29.\n",
      "207/244 [========================>.....] - ETA: 32s - loss: 0.2870 - iou_score: 0.6994 - f1-score: 0.8210For batch 206, tr_loss is    0.29.\n",
      "208/244 [========================>.....] - ETA: 31s - loss: 0.2871 - iou_score: 0.6990 - f1-score: 0.8208For batch 207, tr_loss is    0.29.\n",
      "209/244 [========================>.....] - ETA: 30s - loss: 0.2871 - iou_score: 0.6991 - f1-score: 0.8208For batch 208, tr_loss is    0.29.\n",
      "210/244 [========================>.....] - ETA: 29s - loss: 0.2869 - iou_score: 0.6993 - f1-score: 0.8210For batch 209, tr_loss is    0.29.\n",
      "211/244 [========================>.....] - ETA: 28s - loss: 0.2868 - iou_score: 0.6994 - f1-score: 0.8210For batch 210, tr_loss is    0.29.\n",
      "212/244 [=========================>....] - ETA: 28s - loss: 0.2869 - iou_score: 0.6993 - f1-score: 0.8210For batch 211, tr_loss is    0.29.\n",
      "213/244 [=========================>....] - ETA: 27s - loss: 0.2871 - iou_score: 0.6992 - f1-score: 0.8209For batch 212, tr_loss is    0.29.\n",
      "214/244 [=========================>....] - ETA: 26s - loss: 0.2868 - iou_score: 0.6996 - f1-score: 0.8212For batch 213, tr_loss is    0.29.\n",
      "215/244 [=========================>....] - ETA: 25s - loss: 0.2867 - iou_score: 0.6999 - f1-score: 0.8213For batch 214, tr_loss is    0.29.\n",
      "216/244 [=========================>....] - ETA: 24s - loss: 0.2869 - iou_score: 0.6999 - f1-score: 0.8214For batch 215, tr_loss is    0.29.\n",
      "217/244 [=========================>....] - ETA: 23s - loss: 0.2869 - iou_score: 0.6999 - f1-score: 0.8214For batch 216, tr_loss is    0.29.\n",
      "218/244 [=========================>....] - ETA: 22s - loss: 0.2868 - iou_score: 0.6999 - f1-score: 0.8214For batch 217, tr_loss is    0.29.\n",
      "219/244 [=========================>....] - ETA: 21s - loss: 0.2867 - iou_score: 0.7000 - f1-score: 0.8215For batch 218, tr_loss is    0.29.\n",
      "220/244 [==========================>...] - ETA: 21s - loss: 0.2867 - iou_score: 0.7000 - f1-score: 0.8215For batch 219, tr_loss is    0.29.\n",
      "221/244 [==========================>...] - ETA: 20s - loss: 0.2867 - iou_score: 0.6999 - f1-score: 0.8214For batch 220, tr_loss is    0.29.\n",
      "222/244 [==========================>...] - ETA: 19s - loss: 0.2864 - iou_score: 0.7004 - f1-score: 0.8217For batch 221, tr_loss is    0.29.\n",
      "223/244 [==========================>...] - ETA: 18s - loss: 0.2863 - iou_score: 0.7004 - f1-score: 0.8217For batch 222, tr_loss is    0.29.\n",
      "224/244 [==========================>...] - ETA: 17s - loss: 0.2863 - iou_score: 0.7004 - f1-score: 0.8217For batch 223, tr_loss is    0.29.\n",
      "225/244 [==========================>...] - ETA: 16s - loss: 0.2862 - iou_score: 0.7005 - f1-score: 0.8218For batch 224, tr_loss is    0.29.\n",
      "226/244 [==========================>...] - ETA: 15s - loss: 0.2860 - iou_score: 0.7006 - f1-score: 0.8219For batch 225, tr_loss is    0.29.\n",
      "227/244 [==========================>...] - ETA: 14s - loss: 0.2859 - iou_score: 0.7008 - f1-score: 0.8220For batch 226, tr_loss is    0.29.\n",
      "228/244 [===========================>..] - ETA: 14s - loss: 0.2859 - iou_score: 0.7009 - f1-score: 0.8221For batch 227, tr_loss is    0.29.\n",
      "229/244 [===========================>..] - ETA: 13s - loss: 0.2856 - iou_score: 0.7012 - f1-score: 0.8223For batch 228, tr_loss is    0.29.\n",
      "230/244 [===========================>..] - ETA: 12s - loss: 0.2855 - iou_score: 0.7012 - f1-score: 0.8223For batch 229, tr_loss is    0.29.\n",
      "231/244 [===========================>..] - ETA: 11s - loss: 0.2854 - iou_score: 0.7015 - f1-score: 0.8225For batch 230, tr_loss is    0.29.\n",
      "232/244 [===========================>..] - ETA: 10s - loss: 0.2856 - iou_score: 0.7013 - f1-score: 0.8224For batch 231, tr_loss is    0.29.\n",
      "233/244 [===========================>..] - ETA: 9s - loss: 0.2861 - iou_score: 0.7008 - f1-score: 0.8220 For batch 232, tr_loss is    0.29.\n",
      "234/244 [===========================>..] - ETA: 8s - loss: 0.2861 - iou_score: 0.7006 - f1-score: 0.8219For batch 233, tr_loss is    0.29.\n",
      "235/244 [===========================>..] - ETA: 7s - loss: 0.2859 - iou_score: 0.7009 - f1-score: 0.8221For batch 234, tr_loss is    0.29.\n",
      "236/244 [============================>.] - ETA: 7s - loss: 0.2861 - iou_score: 0.7007 - f1-score: 0.8220For batch 235, tr_loss is    0.29.\n",
      "237/244 [============================>.] - ETA: 6s - loss: 0.2862 - iou_score: 0.7007 - f1-score: 0.8219For batch 236, tr_loss is    0.29.\n",
      "238/244 [============================>.] - ETA: 5s - loss: 0.2860 - iou_score: 0.7009 - f1-score: 0.8221For batch 237, tr_loss is    0.29.\n",
      "239/244 [============================>.] - ETA: 4s - loss: 0.2861 - iou_score: 0.7010 - f1-score: 0.8221For batch 238, tr_loss is    0.29.\n",
      "240/244 [============================>.] - ETA: 3s - loss: 0.2858 - iou_score: 0.7013 - f1-score: 0.8224For batch 239, tr_loss is    0.29.\n",
      "241/244 [============================>.] - ETA: 2s - loss: 0.2860 - iou_score: 0.7013 - f1-score: 0.8223For batch 240, tr_loss is    0.29.\n",
      "242/244 [============================>.] - ETA: 1s - loss: 0.2862 - iou_score: 0.7010 - f1-score: 0.8221For batch 241, tr_loss is    0.29.\n",
      "243/244 [============================>.] - ETA: 0s - loss: 0.2866 - iou_score: 0.7006 - f1-score: 0.8218For batch 242, tr_loss is    0.29.\n",
      "244/244 [==============================] - ETA: 0s - loss: 0.2866 - iou_score: 0.7005 - f1-score: 0.8217For batch 243, tr_loss is    0.29.\n",
      "For batch 0, vl_loss is    0.32.\n",
      "For batch 1, vl_loss is    0.33.\n",
      "For batch 2, vl_loss is    0.31.\n",
      "For batch 3, vl_loss is    0.36.\n",
      "For batch 4, vl_loss is    0.35.\n",
      "For batch 5, vl_loss is    0.35.\n",
      "For batch 6, vl_loss is    0.37.\n",
      "For batch 7, vl_loss is    0.37.\n",
      "For batch 8, vl_loss is    0.36.\n",
      "For batch 9, vl_loss is    0.37.\n",
      "For batch 10, vl_loss is    0.37.\n",
      "For batch 11, vl_loss is    0.38.\n",
      "For batch 12, vl_loss is    0.37.\n",
      "For batch 13, vl_loss is    0.38.\n",
      "For batch 14, vl_loss is    0.38.\n",
      "For batch 15, vl_loss is    0.38.\n",
      "For batch 16, vl_loss is    0.37.\n",
      "For batch 17, vl_loss is    0.37.\n",
      "For batch 18, vl_loss is    0.38.\n",
      "For batch 19, vl_loss is    0.37.\n",
      "For batch 20, vl_loss is    0.37.\n",
      "For batch 21, vl_loss is    0.37.\n",
      "For batch 22, vl_loss is    0.37.\n",
      "For batch 23, vl_loss is    0.37.\n",
      "For batch 24, vl_loss is    0.37.\n",
      "For batch 25, vl_loss is    0.37.\n",
      "For batch 26, vl_loss is    0.37.\n",
      "For batch 27, vl_loss is    0.37.\n",
      "For batch 28, vl_loss is    0.38.\n",
      "For batch 29, vl_loss is    0.38.\n",
      "For batch 30, vl_loss is    0.38.\n",
      "For batch 31, vl_loss is    0.38.\n",
      "For batch 32, vl_loss is    0.38.\n",
      "For batch 33, vl_loss is    0.38.\n",
      "For batch 34, vl_loss is    0.37.\n",
      "For batch 35, vl_loss is    0.37.\n",
      "For batch 36, vl_loss is    0.37.\n",
      "For batch 37, vl_loss is    0.38.\n",
      "For batch 38, vl_loss is    0.38.\n",
      "For batch 39, vl_loss is    0.38.\n",
      "For batch 40, vl_loss is    0.38.\n",
      "For batch 41, vl_loss is    0.38.\n",
      "For batch 42, vl_loss is    0.38.\n",
      "For batch 43, vl_loss is    0.37.\n",
      "For batch 44, vl_loss is    0.37.\n",
      "For batch 45, vl_loss is    0.37.\n",
      "For batch 46, vl_loss is    0.37.\n",
      "For batch 47, vl_loss is    0.37.\n",
      "For batch 48, vl_loss is    0.37.\n",
      "For batch 49, vl_loss is    0.37.\n",
      "For batch 50, vl_loss is    0.37.\n",
      "For batch 51, vl_loss is    0.37.\n",
      "For batch 52, vl_loss is    0.37.\n",
      "For batch 53, vl_loss is    0.37.\n",
      "For batch 54, vl_loss is    0.37.\n",
      "For batch 55, vl_loss is    0.37.\n",
      "244/244 [==============================] - 218s 883ms/step - loss: 0.2866 - iou_score: 0.7005 - f1-score: 0.8217 - val_loss: 0.3668 - val_iou_score: 0.6367 - val_f1-score: 0.7757\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.34998\n",
      "The average loss for epoch 5 is    0.29 \n",
      "Epoch 7/200\n",
      "  1/244 [..............................] - ETA: 8:53 - loss: 0.3337 - iou_score: 0.6355 - f1-score: 0.7741For batch 0, tr_loss is    0.33.\n",
      "  2/244 [..............................] - ETA: 6:23 - loss: 0.3126 - iou_score: 0.6724 - f1-score: 0.8020For batch 1, tr_loss is    0.31.\n",
      "  3/244 [..............................] - ETA: 5:30 - loss: 0.3059 - iou_score: 0.6851 - f1-score: 0.8114For batch 2, tr_loss is    0.31.\n",
      "  4/244 [..............................] - ETA: 5:13 - loss: 0.3066 - iou_score: 0.6879 - f1-score: 0.8137For batch 3, tr_loss is    0.31.\n",
      "  5/244 [..............................] - ETA: 4:59 - loss: 0.3039 - iou_score: 0.6911 - f1-score: 0.8158For batch 4, tr_loss is    0.30.\n",
      "  6/244 [..............................] - ETA: 4:54 - loss: 0.3082 - iou_score: 0.6825 - f1-score: 0.8098For batch 5, tr_loss is    0.31.\n",
      "  7/244 [..............................] - ETA: 4:52 - loss: 0.3015 - iou_score: 0.6907 - f1-score: 0.8150For batch 6, tr_loss is    0.30.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8/244 [..............................] - ETA: 4:59 - loss: 0.3073 - iou_score: 0.6810 - f1-score: 0.8078For batch 7, tr_loss is    0.31.\n",
      "  9/244 [>.............................] - ETA: 5:11 - loss: 0.3095 - iou_score: 0.6795 - f1-score: 0.8068For batch 8, tr_loss is    0.31.\n",
      " 10/244 [>.............................] - ETA: 5:06 - loss: 0.3040 - iou_score: 0.6861 - f1-score: 0.8115For batch 9, tr_loss is    0.30.\n",
      " 11/244 [>.............................] - ETA: 4:49 - loss: 0.3029 - iou_score: 0.6893 - f1-score: 0.8137For batch 10, tr_loss is    0.30.\n",
      " 12/244 [>.............................] - ETA: 4:44 - loss: 0.3009 - iou_score: 0.6914 - f1-score: 0.8154For batch 11, tr_loss is    0.30.\n",
      " 13/244 [>.............................] - ETA: 4:31 - loss: 0.2987 - iou_score: 0.6940 - f1-score: 0.8173For batch 12, tr_loss is    0.30.\n",
      " 14/244 [>.............................] - ETA: 4:27 - loss: 0.3029 - iou_score: 0.6892 - f1-score: 0.8140For batch 13, tr_loss is    0.30.\n",
      " 15/244 [>.............................] - ETA: 4:16 - loss: 0.3057 - iou_score: 0.6865 - f1-score: 0.8121For batch 14, tr_loss is    0.31.\n",
      " 16/244 [>.............................] - ETA: 4:08 - loss: 0.3054 - iou_score: 0.6865 - f1-score: 0.8122For batch 15, tr_loss is    0.31.\n",
      " 17/244 [=>............................] - ETA: 4:07 - loss: 0.3019 - iou_score: 0.6913 - f1-score: 0.8155For batch 16, tr_loss is    0.30.\n",
      " 18/244 [=>............................] - ETA: 3:58 - loss: 0.3027 - iou_score: 0.6904 - f1-score: 0.8150For batch 17, tr_loss is    0.30.\n",
      " 19/244 [=>............................] - ETA: 3:52 - loss: 0.3005 - iou_score: 0.6938 - f1-score: 0.8174For batch 18, tr_loss is    0.30.\n",
      " 20/244 [=>............................] - ETA: 3:51 - loss: 0.2999 - iou_score: 0.6938 - f1-score: 0.8172For batch 19, tr_loss is    0.30.\n",
      " 21/244 [=>............................] - ETA: 3:50 - loss: 0.2991 - iou_score: 0.6935 - f1-score: 0.8170For batch 20, tr_loss is    0.30.\n",
      " 22/244 [=>............................] - ETA: 3:48 - loss: 0.3028 - iou_score: 0.6911 - f1-score: 0.8154For batch 21, tr_loss is    0.30.\n",
      " 23/244 [=>............................] - ETA: 3:46 - loss: 0.3019 - iou_score: 0.6905 - f1-score: 0.8150For batch 22, tr_loss is    0.30.\n",
      " 24/244 [=>............................] - ETA: 3:45 - loss: 0.2988 - iou_score: 0.6932 - f1-score: 0.8169For batch 23, tr_loss is    0.30.\n",
      " 25/244 [==>...........................] - ETA: 3:44 - loss: 0.2986 - iou_score: 0.6925 - f1-score: 0.8164For batch 24, tr_loss is    0.30.\n",
      " 26/244 [==>...........................] - ETA: 3:44 - loss: 0.2989 - iou_score: 0.6921 - f1-score: 0.8162For batch 25, tr_loss is    0.30.\n",
      " 27/244 [==>...........................] - ETA: 3:43 - loss: 0.2982 - iou_score: 0.6921 - f1-score: 0.8162For batch 26, tr_loss is    0.30.\n",
      " 28/244 [==>...........................] - ETA: 3:42 - loss: 0.2943 - iou_score: 0.6971 - f1-score: 0.8195For batch 27, tr_loss is    0.29.\n",
      " 29/244 [==>...........................] - ETA: 3:41 - loss: 0.2931 - iou_score: 0.6971 - f1-score: 0.8196For batch 28, tr_loss is    0.29.\n",
      " 30/244 [==>...........................] - ETA: 3:40 - loss: 0.2901 - iou_score: 0.7005 - f1-score: 0.8219For batch 29, tr_loss is    0.29.\n",
      " 31/244 [==>...........................] - ETA: 3:35 - loss: 0.2886 - iou_score: 0.7025 - f1-score: 0.8233For batch 30, tr_loss is    0.29.\n",
      " 32/244 [==>...........................] - ETA: 3:32 - loss: 0.2877 - iou_score: 0.7040 - f1-score: 0.8243For batch 31, tr_loss is    0.29.\n",
      " 33/244 [===>..........................] - ETA: 3:31 - loss: 0.2867 - iou_score: 0.7042 - f1-score: 0.8245For batch 32, tr_loss is    0.29.\n",
      " 34/244 [===>..........................] - ETA: 3:30 - loss: 0.2864 - iou_score: 0.7045 - f1-score: 0.8247For batch 33, tr_loss is    0.29.\n",
      " 35/244 [===>..........................] - ETA: 3:29 - loss: 0.2887 - iou_score: 0.7023 - f1-score: 0.8232For batch 34, tr_loss is    0.29.\n",
      " 36/244 [===>..........................] - ETA: 3:29 - loss: 0.2871 - iou_score: 0.7039 - f1-score: 0.8243For batch 35, tr_loss is    0.29.\n",
      " 37/244 [===>..........................] - ETA: 3:28 - loss: 0.2878 - iou_score: 0.7027 - f1-score: 0.8235For batch 36, tr_loss is    0.29.\n",
      " 38/244 [===>..........................] - ETA: 3:27 - loss: 0.2867 - iou_score: 0.7040 - f1-score: 0.8244For batch 37, tr_loss is    0.29.\n",
      " 39/244 [===>..........................] - ETA: 3:26 - loss: 0.2850 - iou_score: 0.7059 - f1-score: 0.8257For batch 38, tr_loss is    0.28.\n",
      " 40/244 [===>..........................] - ETA: 3:24 - loss: 0.2852 - iou_score: 0.7055 - f1-score: 0.8255For batch 39, tr_loss is    0.29.\n",
      " 41/244 [====>.........................] - ETA: 3:23 - loss: 0.2852 - iou_score: 0.7044 - f1-score: 0.8247For batch 40, tr_loss is    0.29.\n",
      " 42/244 [====>.........................] - ETA: 3:22 - loss: 0.2839 - iou_score: 0.7054 - f1-score: 0.8254For batch 41, tr_loss is    0.28.\n",
      " 43/244 [====>.........................] - ETA: 3:21 - loss: 0.2848 - iou_score: 0.7040 - f1-score: 0.8245For batch 42, tr_loss is    0.28.\n",
      " 44/244 [====>.........................] - ETA: 3:19 - loss: 0.2844 - iou_score: 0.7052 - f1-score: 0.8253For batch 43, tr_loss is    0.28.\n",
      " 45/244 [====>.........................] - ETA: 3:16 - loss: 0.2844 - iou_score: 0.7048 - f1-score: 0.8251For batch 44, tr_loss is    0.28.\n",
      " 46/244 [====>.........................] - ETA: 3:14 - loss: 0.2844 - iou_score: 0.7051 - f1-score: 0.8252For batch 45, tr_loss is    0.28.\n",
      " 47/244 [====>.........................] - ETA: 3:13 - loss: 0.2831 - iou_score: 0.7062 - f1-score: 0.8260For batch 46, tr_loss is    0.28.\n",
      " 48/244 [====>.........................] - ETA: 3:12 - loss: 0.2823 - iou_score: 0.7070 - f1-score: 0.8266For batch 47, tr_loss is    0.28.\n",
      " 49/244 [=====>........................] - ETA: 3:11 - loss: 0.2835 - iou_score: 0.7061 - f1-score: 0.8260For batch 48, tr_loss is    0.28.\n",
      " 50/244 [=====>........................] - ETA: 3:09 - loss: 0.2837 - iou_score: 0.7058 - f1-score: 0.8258For batch 49, tr_loss is    0.28.\n",
      " 51/244 [=====>........................] - ETA: 3:07 - loss: 0.2853 - iou_score: 0.7043 - f1-score: 0.8247For batch 50, tr_loss is    0.29.\n",
      " 52/244 [=====>........................] - ETA: 3:06 - loss: 0.2853 - iou_score: 0.7042 - f1-score: 0.8247For batch 51, tr_loss is    0.29.\n",
      " 53/244 [=====>........................] - ETA: 3:06 - loss: 0.2851 - iou_score: 0.7040 - f1-score: 0.8245For batch 52, tr_loss is    0.29.\n",
      " 54/244 [=====>........................] - ETA: 3:05 - loss: 0.2854 - iou_score: 0.7034 - f1-score: 0.8242For batch 53, tr_loss is    0.29.\n",
      " 55/244 [=====>........................] - ETA: 3:02 - loss: 0.2842 - iou_score: 0.7045 - f1-score: 0.8249For batch 54, tr_loss is    0.28.\n",
      " 56/244 [=====>........................] - ETA: 3:01 - loss: 0.2836 - iou_score: 0.7050 - f1-score: 0.8252For batch 55, tr_loss is    0.28.\n",
      " 57/244 [======>.......................] - ETA: 3:00 - loss: 0.2839 - iou_score: 0.7045 - f1-score: 0.8249For batch 56, tr_loss is    0.28.\n",
      " 58/244 [======>.......................] - ETA: 2:58 - loss: 0.2843 - iou_score: 0.7037 - f1-score: 0.8243For batch 57, tr_loss is    0.28.\n",
      " 59/244 [======>.......................] - ETA: 2:56 - loss: 0.2830 - iou_score: 0.7058 - f1-score: 0.8257For batch 58, tr_loss is    0.28.\n",
      " 60/244 [======>.......................] - ETA: 2:56 - loss: 0.2845 - iou_score: 0.7036 - f1-score: 0.8241For batch 59, tr_loss is    0.28.\n",
      " 61/244 [======>.......................] - ETA: 2:54 - loss: 0.2856 - iou_score: 0.7019 - f1-score: 0.8229For batch 60, tr_loss is    0.29.\n",
      " 62/244 [======>.......................] - ETA: 2:52 - loss: 0.2854 - iou_score: 0.7020 - f1-score: 0.8230For batch 61, tr_loss is    0.29.\n",
      " 63/244 [======>.......................] - ETA: 2:52 - loss: 0.2863 - iou_score: 0.7013 - f1-score: 0.8225For batch 62, tr_loss is    0.29.\n",
      " 64/244 [======>.......................] - ETA: 2:51 - loss: 0.2858 - iou_score: 0.7024 - f1-score: 0.8232For batch 63, tr_loss is    0.29.\n",
      " 65/244 [======>.......................] - ETA: 2:50 - loss: 0.2861 - iou_score: 0.7019 - f1-score: 0.8229For batch 64, tr_loss is    0.29.\n",
      " 66/244 [=======>......................] - ETA: 2:50 - loss: 0.2860 - iou_score: 0.7020 - f1-score: 0.8229For batch 65, tr_loss is    0.29.\n",
      " 67/244 [=======>......................] - ETA: 2:48 - loss: 0.2854 - iou_score: 0.7027 - f1-score: 0.8235For batch 66, tr_loss is    0.29.\n",
      " 68/244 [=======>......................] - ETA: 2:47 - loss: 0.2853 - iou_score: 0.7032 - f1-score: 0.8238For batch 67, tr_loss is    0.29.\n",
      " 69/244 [=======>......................] - ETA: 2:45 - loss: 0.2861 - iou_score: 0.7021 - f1-score: 0.8230For batch 68, tr_loss is    0.29.\n",
      " 70/244 [=======>......................] - ETA: 2:43 - loss: 0.2858 - iou_score: 0.7021 - f1-score: 0.8230For batch 69, tr_loss is    0.29.\n",
      " 71/244 [=======>......................] - ETA: 2:42 - loss: 0.2857 - iou_score: 0.7022 - f1-score: 0.8231For batch 70, tr_loss is    0.29.\n",
      " 72/244 [=======>......................] - ETA: 2:42 - loss: 0.2852 - iou_score: 0.7027 - f1-score: 0.8234For batch 71, tr_loss is    0.29.\n",
      " 73/244 [=======>......................] - ETA: 2:40 - loss: 0.2859 - iou_score: 0.7020 - f1-score: 0.8229For batch 72, tr_loss is    0.29.\n",
      " 74/244 [========>.....................] - ETA: 2:39 - loss: 0.2862 - iou_score: 0.7014 - f1-score: 0.8225For batch 73, tr_loss is    0.29.\n",
      " 75/244 [========>.....................] - ETA: 2:38 - loss: 0.2860 - iou_score: 0.7013 - f1-score: 0.8224For batch 74, tr_loss is    0.29.\n",
      " 76/244 [========>.....................] - ETA: 2:37 - loss: 0.2850 - iou_score: 0.7029 - f1-score: 0.8235For batch 75, tr_loss is    0.28.\n",
      " 77/244 [========>.....................] - ETA: 2:35 - loss: 0.2851 - iou_score: 0.7028 - f1-score: 0.8234For batch 76, tr_loss is    0.29.\n",
      " 78/244 [========>.....................] - ETA: 2:35 - loss: 0.2850 - iou_score: 0.7029 - f1-score: 0.8235For batch 77, tr_loss is    0.28.\n",
      " 79/244 [========>.....................] - ETA: 2:33 - loss: 0.2849 - iou_score: 0.7034 - f1-score: 0.8238For batch 78, tr_loss is    0.28.\n",
      " 80/244 [========>.....................] - ETA: 2:31 - loss: 0.2845 - iou_score: 0.7036 - f1-score: 0.8239For batch 79, tr_loss is    0.28.\n",
      " 81/244 [========>.....................] - ETA: 2:31 - loss: 0.2849 - iou_score: 0.7032 - f1-score: 0.8236For batch 80, tr_loss is    0.28.\n",
      " 82/244 [=========>....................] - ETA: 2:29 - loss: 0.2864 - iou_score: 0.7014 - f1-score: 0.8223For batch 81, tr_loss is    0.29.\n",
      " 83/244 [=========>....................] - ETA: 2:28 - loss: 0.2856 - iou_score: 0.7023 - f1-score: 0.8229For batch 82, tr_loss is    0.29.\n",
      " 84/244 [=========>....................] - ETA: 2:27 - loss: 0.2855 - iou_score: 0.7028 - f1-score: 0.8232For batch 83, tr_loss is    0.29.\n",
      " 85/244 [=========>....................] - ETA: 2:26 - loss: 0.2848 - iou_score: 0.7035 - f1-score: 0.8237For batch 84, tr_loss is    0.28.\n",
      " 86/244 [=========>....................] - ETA: 2:25 - loss: 0.2852 - iou_score: 0.7030 - f1-score: 0.8233For batch 85, tr_loss is    0.29.\n",
      " 87/244 [=========>....................] - ETA: 2:23 - loss: 0.2850 - iou_score: 0.7031 - f1-score: 0.8234For batch 86, tr_loss is    0.29.\n",
      " 88/244 [=========>....................] - ETA: 2:23 - loss: 0.2844 - iou_score: 0.7037 - f1-score: 0.8238For batch 87, tr_loss is    0.28.\n",
      " 89/244 [=========>....................] - ETA: 2:22 - loss: 0.2847 - iou_score: 0.7032 - f1-score: 0.8235For batch 88, tr_loss is    0.28.\n",
      " 90/244 [==========>...................] - ETA: 2:21 - loss: 0.2845 - iou_score: 0.7033 - f1-score: 0.8236For batch 89, tr_loss is    0.28.\n",
      " 91/244 [==========>...................] - ETA: 2:20 - loss: 0.2853 - iou_score: 0.7021 - f1-score: 0.8227For batch 90, tr_loss is    0.29.\n",
      " 92/244 [==========>...................] - ETA: 2:18 - loss: 0.2857 - iou_score: 0.7015 - f1-score: 0.8223For batch 91, tr_loss is    0.29.\n",
      " 93/244 [==========>...................] - ETA: 2:18 - loss: 0.2850 - iou_score: 0.7026 - f1-score: 0.8230For batch 92, tr_loss is    0.28.\n",
      " 94/244 [==========>...................] - ETA: 2:16 - loss: 0.2845 - iou_score: 0.7028 - f1-score: 0.8232For batch 93, tr_loss is    0.28.\n",
      " 95/244 [==========>...................] - ETA: 2:16 - loss: 0.2846 - iou_score: 0.7025 - f1-score: 0.8230For batch 94, tr_loss is    0.28.\n",
      " 96/244 [==========>...................] - ETA: 2:15 - loss: 0.2849 - iou_score: 0.7020 - f1-score: 0.8226For batch 95, tr_loss is    0.28.\n",
      " 97/244 [==========>...................] - ETA: 2:14 - loss: 0.2846 - iou_score: 0.7023 - f1-score: 0.8229For batch 96, tr_loss is    0.28.\n",
      " 98/244 [===========>..................] - ETA: 2:13 - loss: 0.2848 - iou_score: 0.7022 - f1-score: 0.8228For batch 97, tr_loss is    0.28.\n",
      " 99/244 [===========>..................] - ETA: 2:12 - loss: 0.2845 - iou_score: 0.7026 - f1-score: 0.8231For batch 98, tr_loss is    0.28.\n",
      "100/244 [===========>..................] - ETA: 2:11 - loss: 0.2839 - iou_score: 0.7034 - f1-score: 0.8237For batch 99, tr_loss is    0.28.\n",
      "101/244 [===========>..................] - ETA: 2:11 - loss: 0.2838 - iou_score: 0.7033 - f1-score: 0.8236For batch 100, tr_loss is    0.28.\n",
      "102/244 [===========>..................] - ETA: 2:10 - loss: 0.2835 - iou_score: 0.7035 - f1-score: 0.8237For batch 101, tr_loss is    0.28.\n",
      "103/244 [===========>..................] - ETA: 2:09 - loss: 0.2831 - iou_score: 0.7040 - f1-score: 0.8241For batch 102, tr_loss is    0.28.\n",
      "104/244 [===========>..................] - ETA: 2:08 - loss: 0.2826 - iou_score: 0.7043 - f1-score: 0.8243For batch 103, tr_loss is    0.28.\n",
      "105/244 [===========>..................] - ETA: 2:07 - loss: 0.2827 - iou_score: 0.7040 - f1-score: 0.8241For batch 104, tr_loss is    0.28.\n",
      "106/244 [============>.................] - ETA: 2:05 - loss: 0.2820 - iou_score: 0.7049 - f1-score: 0.8247For batch 105, tr_loss is    0.28.\n",
      "107/244 [============>.................] - ETA: 2:04 - loss: 0.2813 - iou_score: 0.7056 - f1-score: 0.8252For batch 106, tr_loss is    0.28.\n",
      "108/244 [============>.................] - ETA: 2:03 - loss: 0.2813 - iou_score: 0.7057 - f1-score: 0.8253For batch 107, tr_loss is    0.28.\n",
      "109/244 [============>.................] - ETA: 2:02 - loss: 0.2818 - iou_score: 0.7048 - f1-score: 0.8247For batch 108, tr_loss is    0.28.\n",
      "110/244 [============>.................] - ETA: 2:01 - loss: 0.2823 - iou_score: 0.7044 - f1-score: 0.8244For batch 109, tr_loss is    0.28.\n",
      "111/244 [============>.................] - ETA: 2:00 - loss: 0.2824 - iou_score: 0.7042 - f1-score: 0.8242For batch 110, tr_loss is    0.28.\n",
      "112/244 [============>.................] - ETA: 2:00 - loss: 0.2826 - iou_score: 0.7037 - f1-score: 0.8239For batch 111, tr_loss is    0.28.\n",
      "113/244 [============>.................] - ETA: 1:58 - loss: 0.2824 - iou_score: 0.7042 - f1-score: 0.8242For batch 112, tr_loss is    0.28.\n",
      "114/244 [=============>................] - ETA: 1:57 - loss: 0.2830 - iou_score: 0.7036 - f1-score: 0.8238For batch 113, tr_loss is    0.28.\n",
      "115/244 [=============>................] - ETA: 1:56 - loss: 0.2828 - iou_score: 0.7038 - f1-score: 0.8240For batch 114, tr_loss is    0.28.\n",
      "116/244 [=============>................] - ETA: 1:55 - loss: 0.2825 - iou_score: 0.7039 - f1-score: 0.8241For batch 115, tr_loss is    0.28.\n",
      "117/244 [=============>................] - ETA: 1:54 - loss: 0.2831 - iou_score: 0.7032 - f1-score: 0.8235For batch 116, tr_loss is    0.28.\n",
      "118/244 [=============>................] - ETA: 1:53 - loss: 0.2831 - iou_score: 0.7031 - f1-score: 0.8235For batch 117, tr_loss is    0.28.\n",
      "119/244 [=============>................] - ETA: 1:52 - loss: 0.2829 - iou_score: 0.7033 - f1-score: 0.8236For batch 118, tr_loss is    0.28.\n",
      "120/244 [=============>................] - ETA: 1:51 - loss: 0.2839 - iou_score: 0.7022 - f1-score: 0.8228For batch 119, tr_loss is    0.28.\n",
      "121/244 [=============>................] - ETA: 1:50 - loss: 0.2835 - iou_score: 0.7030 - f1-score: 0.8233For batch 120, tr_loss is    0.28.\n",
      "122/244 [==============>...............] - ETA: 1:49 - loss: 0.2833 - iou_score: 0.7031 - f1-score: 0.8234For batch 121, tr_loss is    0.28.\n",
      "123/244 [==============>...............] - ETA: 1:48 - loss: 0.2839 - iou_score: 0.7024 - f1-score: 0.8229For batch 122, tr_loss is    0.28.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/244 [==============>...............] - ETA: 1:47 - loss: 0.2847 - iou_score: 0.7015 - f1-score: 0.8223For batch 123, tr_loss is    0.28.\n",
      "125/244 [==============>...............] - ETA: 1:46 - loss: 0.2844 - iou_score: 0.7021 - f1-score: 0.8226For batch 124, tr_loss is    0.28.\n",
      "126/244 [==============>...............] - ETA: 1:45 - loss: 0.2843 - iou_score: 0.7020 - f1-score: 0.8226For batch 125, tr_loss is    0.28.\n",
      "127/244 [==============>...............] - ETA: 1:44 - loss: 0.2845 - iou_score: 0.7016 - f1-score: 0.8223For batch 126, tr_loss is    0.28.\n",
      "128/244 [==============>...............] - ETA: 1:43 - loss: 0.2841 - iou_score: 0.7020 - f1-score: 0.8226For batch 127, tr_loss is    0.28.\n",
      "129/244 [==============>...............] - ETA: 1:42 - loss: 0.2839 - iou_score: 0.7023 - f1-score: 0.8228For batch 128, tr_loss is    0.28.\n",
      "130/244 [==============>...............] - ETA: 1:41 - loss: 0.2841 - iou_score: 0.7019 - f1-score: 0.8225For batch 129, tr_loss is    0.28.\n",
      "131/244 [===============>..............] - ETA: 1:41 - loss: 0.2837 - iou_score: 0.7024 - f1-score: 0.8229For batch 130, tr_loss is    0.28.\n",
      "132/244 [===============>..............] - ETA: 1:40 - loss: 0.2842 - iou_score: 0.7018 - f1-score: 0.8224For batch 131, tr_loss is    0.28.\n",
      "133/244 [===============>..............] - ETA: 1:39 - loss: 0.2842 - iou_score: 0.7018 - f1-score: 0.8224For batch 132, tr_loss is    0.28.\n",
      "134/244 [===============>..............] - ETA: 1:37 - loss: 0.2849 - iou_score: 0.7008 - f1-score: 0.8217For batch 133, tr_loss is    0.28.\n",
      "135/244 [===============>..............] - ETA: 1:37 - loss: 0.2854 - iou_score: 0.7002 - f1-score: 0.8213For batch 134, tr_loss is    0.29.\n",
      "136/244 [===============>..............] - ETA: 1:36 - loss: 0.2851 - iou_score: 0.7006 - f1-score: 0.8216For batch 135, tr_loss is    0.29.\n",
      "137/244 [===============>..............] - ETA: 1:35 - loss: 0.2849 - iou_score: 0.7008 - f1-score: 0.8218For batch 136, tr_loss is    0.28.\n",
      "138/244 [===============>..............] - ETA: 1:34 - loss: 0.2851 - iou_score: 0.7006 - f1-score: 0.8216For batch 137, tr_loss is    0.29.\n",
      "139/244 [================>.............] - ETA: 1:33 - loss: 0.2853 - iou_score: 0.7003 - f1-score: 0.8214For batch 138, tr_loss is    0.29.\n",
      "140/244 [================>.............] - ETA: 1:32 - loss: 0.2853 - iou_score: 0.7002 - f1-score: 0.8214For batch 139, tr_loss is    0.29.\n",
      "141/244 [================>.............] - ETA: 1:31 - loss: 0.2854 - iou_score: 0.7000 - f1-score: 0.8212For batch 140, tr_loss is    0.29.\n",
      "142/244 [================>.............] - ETA: 1:30 - loss: 0.2855 - iou_score: 0.6997 - f1-score: 0.8210For batch 141, tr_loss is    0.29.\n",
      "143/244 [================>.............] - ETA: 1:29 - loss: 0.2856 - iou_score: 0.7001 - f1-score: 0.8213For batch 142, tr_loss is    0.29.\n",
      "144/244 [================>.............] - ETA: 1:28 - loss: 0.2863 - iou_score: 0.6995 - f1-score: 0.8208For batch 143, tr_loss is    0.29.\n",
      "145/244 [================>.............] - ETA: 1:27 - loss: 0.2864 - iou_score: 0.6992 - f1-score: 0.8206For batch 144, tr_loss is    0.29.\n",
      "146/244 [================>.............] - ETA: 1:26 - loss: 0.2865 - iou_score: 0.6991 - f1-score: 0.8206For batch 145, tr_loss is    0.29.\n",
      "147/244 [=================>............] - ETA: 1:25 - loss: 0.2864 - iou_score: 0.6990 - f1-score: 0.8205For batch 146, tr_loss is    0.29.\n",
      "148/244 [=================>............] - ETA: 1:24 - loss: 0.2865 - iou_score: 0.6989 - f1-score: 0.8204For batch 147, tr_loss is    0.29.\n",
      "149/244 [=================>............] - ETA: 1:24 - loss: 0.2866 - iou_score: 0.6987 - f1-score: 0.8203For batch 148, tr_loss is    0.29.\n",
      "150/244 [=================>............] - ETA: 1:23 - loss: 0.2865 - iou_score: 0.6987 - f1-score: 0.8204For batch 149, tr_loss is    0.29.\n",
      "151/244 [=================>............] - ETA: 1:22 - loss: 0.2866 - iou_score: 0.6986 - f1-score: 0.8203For batch 150, tr_loss is    0.29.\n",
      "152/244 [=================>............] - ETA: 1:21 - loss: 0.2868 - iou_score: 0.6984 - f1-score: 0.8202For batch 151, tr_loss is    0.29.\n",
      "153/244 [=================>............] - ETA: 1:20 - loss: 0.2866 - iou_score: 0.6987 - f1-score: 0.8203For batch 152, tr_loss is    0.29.\n",
      "154/244 [=================>............] - ETA: 1:19 - loss: 0.2866 - iou_score: 0.6987 - f1-score: 0.8204For batch 153, tr_loss is    0.29.\n",
      "155/244 [==================>...........] - ETA: 1:18 - loss: 0.2868 - iou_score: 0.6985 - f1-score: 0.8203For batch 154, tr_loss is    0.29.\n",
      "156/244 [==================>...........] - ETA: 1:18 - loss: 0.2863 - iou_score: 0.6991 - f1-score: 0.8206For batch 155, tr_loss is    0.29.\n",
      "157/244 [==================>...........] - ETA: 1:17 - loss: 0.2860 - iou_score: 0.6993 - f1-score: 0.8208For batch 156, tr_loss is    0.29.\n",
      "158/244 [==================>...........] - ETA: 1:16 - loss: 0.2862 - iou_score: 0.6991 - f1-score: 0.8207For batch 157, tr_loss is    0.29.\n",
      "159/244 [==================>...........] - ETA: 1:15 - loss: 0.2860 - iou_score: 0.6993 - f1-score: 0.8208For batch 158, tr_loss is    0.29.\n",
      "160/244 [==================>...........] - ETA: 1:14 - loss: 0.2858 - iou_score: 0.6996 - f1-score: 0.8210For batch 159, tr_loss is    0.29.\n",
      "161/244 [==================>...........] - ETA: 1:13 - loss: 0.2858 - iou_score: 0.6995 - f1-score: 0.8209For batch 160, tr_loss is    0.29.\n",
      "162/244 [==================>...........] - ETA: 1:12 - loss: 0.2857 - iou_score: 0.6996 - f1-score: 0.8211For batch 161, tr_loss is    0.29.\n",
      "163/244 [===================>..........] - ETA: 1:11 - loss: 0.2859 - iou_score: 0.6996 - f1-score: 0.8210For batch 162, tr_loss is    0.29.\n",
      "164/244 [===================>..........] - ETA: 1:10 - loss: 0.2858 - iou_score: 0.6998 - f1-score: 0.8212For batch 163, tr_loss is    0.29.\n",
      "165/244 [===================>..........] - ETA: 1:10 - loss: 0.2860 - iou_score: 0.6996 - f1-score: 0.8211For batch 164, tr_loss is    0.29.\n",
      "166/244 [===================>..........] - ETA: 1:09 - loss: 0.2861 - iou_score: 0.6994 - f1-score: 0.8210For batch 165, tr_loss is    0.29.\n",
      "167/244 [===================>..........] - ETA: 1:08 - loss: 0.2861 - iou_score: 0.6996 - f1-score: 0.8211For batch 166, tr_loss is    0.29.\n",
      "168/244 [===================>..........] - ETA: 1:07 - loss: 0.2857 - iou_score: 0.6999 - f1-score: 0.8213For batch 167, tr_loss is    0.29.\n",
      "169/244 [===================>..........] - ETA: 1:06 - loss: 0.2854 - iou_score: 0.7003 - f1-score: 0.8216For batch 168, tr_loss is    0.29.\n",
      "170/244 [===================>..........] - ETA: 1:05 - loss: 0.2857 - iou_score: 0.6999 - f1-score: 0.8213For batch 169, tr_loss is    0.29.\n",
      "171/244 [====================>.........] - ETA: 1:04 - loss: 0.2853 - iou_score: 0.7004 - f1-score: 0.8216For batch 170, tr_loss is    0.29.\n",
      "172/244 [====================>.........] - ETA: 1:03 - loss: 0.2855 - iou_score: 0.7003 - f1-score: 0.8216For batch 171, tr_loss is    0.29.\n",
      "173/244 [====================>.........] - ETA: 1:02 - loss: 0.2856 - iou_score: 0.7002 - f1-score: 0.8215For batch 172, tr_loss is    0.29.\n",
      "174/244 [====================>.........] - ETA: 1:01 - loss: 0.2860 - iou_score: 0.6998 - f1-score: 0.8212For batch 173, tr_loss is    0.29.\n",
      "175/244 [====================>.........] - ETA: 1:01 - loss: 0.2861 - iou_score: 0.6995 - f1-score: 0.8210For batch 174, tr_loss is    0.29.\n",
      "176/244 [====================>.........] - ETA: 1:00 - loss: 0.2860 - iou_score: 0.6996 - f1-score: 0.8211For batch 175, tr_loss is    0.29.\n",
      "177/244 [====================>.........] - ETA: 59s - loss: 0.2856 - iou_score: 0.7002 - f1-score: 0.8214 For batch 176, tr_loss is    0.29.\n",
      "178/244 [====================>.........] - ETA: 58s - loss: 0.2857 - iou_score: 0.6998 - f1-score: 0.8212For batch 177, tr_loss is    0.29.\n",
      "179/244 [=====================>........] - ETA: 57s - loss: 0.2855 - iou_score: 0.7000 - f1-score: 0.8213For batch 178, tr_loss is    0.29.\n",
      "180/244 [=====================>........] - ETA: 56s - loss: 0.2854 - iou_score: 0.7001 - f1-score: 0.8214For batch 179, tr_loss is    0.29.\n",
      "181/244 [=====================>........] - ETA: 56s - loss: 0.2852 - iou_score: 0.7004 - f1-score: 0.8216For batch 180, tr_loss is    0.29.\n",
      "182/244 [=====================>........] - ETA: 55s - loss: 0.2853 - iou_score: 0.7003 - f1-score: 0.8216For batch 181, tr_loss is    0.29.\n",
      "183/244 [=====================>........] - ETA: 54s - loss: 0.2855 - iou_score: 0.7002 - f1-score: 0.8215For batch 182, tr_loss is    0.29.\n",
      "184/244 [=====================>........] - ETA: 53s - loss: 0.2858 - iou_score: 0.6998 - f1-score: 0.8212For batch 183, tr_loss is    0.29.\n",
      "185/244 [=====================>........] - ETA: 52s - loss: 0.2860 - iou_score: 0.6997 - f1-score: 0.8211For batch 184, tr_loss is    0.29.\n",
      "186/244 [=====================>........] - ETA: 51s - loss: 0.2856 - iou_score: 0.7001 - f1-score: 0.8214For batch 185, tr_loss is    0.29.\n",
      "187/244 [=====================>........] - ETA: 50s - loss: 0.2859 - iou_score: 0.6997 - f1-score: 0.8211For batch 186, tr_loss is    0.29.\n",
      "188/244 [======================>.......] - ETA: 49s - loss: 0.2859 - iou_score: 0.6996 - f1-score: 0.8211For batch 187, tr_loss is    0.29.\n",
      "189/244 [======================>.......] - ETA: 49s - loss: 0.2859 - iou_score: 0.6997 - f1-score: 0.8211For batch 188, tr_loss is    0.29.\n",
      "190/244 [======================>.......] - ETA: 48s - loss: 0.2856 - iou_score: 0.7001 - f1-score: 0.8214For batch 189, tr_loss is    0.29.\n",
      "191/244 [======================>.......] - ETA: 47s - loss: 0.2853 - iou_score: 0.7004 - f1-score: 0.8216For batch 190, tr_loss is    0.29.\n",
      "192/244 [======================>.......] - ETA: 46s - loss: 0.2854 - iou_score: 0.7003 - f1-score: 0.8215For batch 191, tr_loss is    0.29.\n",
      "193/244 [======================>.......] - ETA: 45s - loss: 0.2854 - iou_score: 0.7001 - f1-score: 0.8214For batch 192, tr_loss is    0.29.\n",
      "194/244 [======================>.......] - ETA: 44s - loss: 0.2851 - iou_score: 0.7003 - f1-score: 0.8216For batch 193, tr_loss is    0.29.\n",
      "195/244 [======================>.......] - ETA: 43s - loss: 0.2852 - iou_score: 0.7003 - f1-score: 0.8216For batch 194, tr_loss is    0.29.\n",
      "196/244 [=======================>......] - ETA: 42s - loss: 0.2851 - iou_score: 0.7003 - f1-score: 0.8216For batch 195, tr_loss is    0.29.\n",
      "197/244 [=======================>......] - ETA: 41s - loss: 0.2853 - iou_score: 0.7001 - f1-score: 0.8214For batch 196, tr_loss is    0.29.\n",
      "198/244 [=======================>......] - ETA: 40s - loss: 0.2852 - iou_score: 0.7001 - f1-score: 0.8215For batch 197, tr_loss is    0.29.\n",
      "199/244 [=======================>......] - ETA: 40s - loss: 0.2849 - iou_score: 0.7005 - f1-score: 0.8217For batch 198, tr_loss is    0.28.\n",
      "200/244 [=======================>......] - ETA: 39s - loss: 0.2852 - iou_score: 0.7006 - f1-score: 0.8218For batch 199, tr_loss is    0.29.\n",
      "201/244 [=======================>......] - ETA: 38s - loss: 0.2854 - iou_score: 0.7005 - f1-score: 0.8217For batch 200, tr_loss is    0.29.\n",
      "202/244 [=======================>......] - ETA: 37s - loss: 0.2852 - iou_score: 0.7006 - f1-score: 0.8218For batch 201, tr_loss is    0.29.\n",
      "203/244 [=======================>......] - ETA: 36s - loss: 0.2851 - iou_score: 0.7008 - f1-score: 0.8219For batch 202, tr_loss is    0.29.\n",
      "204/244 [========================>.....] - ETA: 35s - loss: 0.2848 - iou_score: 0.7010 - f1-score: 0.8221For batch 203, tr_loss is    0.28.\n",
      "205/244 [========================>.....] - ETA: 34s - loss: 0.2844 - iou_score: 0.7015 - f1-score: 0.8224For batch 204, tr_loss is    0.28.\n",
      "206/244 [========================>.....] - ETA: 33s - loss: 0.2847 - iou_score: 0.7012 - f1-score: 0.8222For batch 205, tr_loss is    0.28.\n",
      "207/244 [========================>.....] - ETA: 32s - loss: 0.2845 - iou_score: 0.7013 - f1-score: 0.8223For batch 206, tr_loss is    0.28.\n",
      "208/244 [========================>.....] - ETA: 31s - loss: 0.2846 - iou_score: 0.7011 - f1-score: 0.8222For batch 207, tr_loss is    0.28.\n",
      "209/244 [========================>.....] - ETA: 31s - loss: 0.2844 - iou_score: 0.7012 - f1-score: 0.8222For batch 208, tr_loss is    0.28.\n",
      "210/244 [========================>.....] - ETA: 30s - loss: 0.2842 - iou_score: 0.7014 - f1-score: 0.8224For batch 209, tr_loss is    0.28.\n",
      "211/244 [========================>.....] - ETA: 29s - loss: 0.2843 - iou_score: 0.7014 - f1-score: 0.8224For batch 210, tr_loss is    0.28.\n",
      "212/244 [=========================>....] - ETA: 28s - loss: 0.2843 - iou_score: 0.7013 - f1-score: 0.8223For batch 211, tr_loss is    0.28.\n",
      "213/244 [=========================>....] - ETA: 27s - loss: 0.2845 - iou_score: 0.7011 - f1-score: 0.8222For batch 212, tr_loss is    0.28.\n",
      "214/244 [=========================>....] - ETA: 26s - loss: 0.2842 - iou_score: 0.7015 - f1-score: 0.8224For batch 213, tr_loss is    0.28.\n",
      "215/244 [=========================>....] - ETA: 25s - loss: 0.2840 - iou_score: 0.7017 - f1-score: 0.8226For batch 214, tr_loss is    0.28.\n",
      "216/244 [=========================>....] - ETA: 24s - loss: 0.2841 - iou_score: 0.7017 - f1-score: 0.8226For batch 215, tr_loss is    0.28.\n",
      "217/244 [=========================>....] - ETA: 23s - loss: 0.2841 - iou_score: 0.7017 - f1-score: 0.8226For batch 216, tr_loss is    0.28.\n",
      "218/244 [=========================>....] - ETA: 23s - loss: 0.2841 - iou_score: 0.7017 - f1-score: 0.8226For batch 217, tr_loss is    0.28.\n",
      "219/244 [=========================>....] - ETA: 22s - loss: 0.2840 - iou_score: 0.7018 - f1-score: 0.8227For batch 218, tr_loss is    0.28.\n",
      "220/244 [==========================>...] - ETA: 21s - loss: 0.2839 - iou_score: 0.7017 - f1-score: 0.8226For batch 219, tr_loss is    0.28.\n",
      "221/244 [==========================>...] - ETA: 20s - loss: 0.2841 - iou_score: 0.7017 - f1-score: 0.8226For batch 220, tr_loss is    0.28.\n",
      "222/244 [==========================>...] - ETA: 19s - loss: 0.2837 - iou_score: 0.7020 - f1-score: 0.8228For batch 221, tr_loss is    0.28.\n",
      "223/244 [==========================>...] - ETA: 18s - loss: 0.2836 - iou_score: 0.7022 - f1-score: 0.8229For batch 222, tr_loss is    0.28.\n",
      "224/244 [==========================>...] - ETA: 17s - loss: 0.2836 - iou_score: 0.7022 - f1-score: 0.8230For batch 223, tr_loss is    0.28.\n",
      "225/244 [==========================>...] - ETA: 16s - loss: 0.2836 - iou_score: 0.7022 - f1-score: 0.8229For batch 224, tr_loss is    0.28.\n",
      "226/244 [==========================>...] - ETA: 16s - loss: 0.2835 - iou_score: 0.7023 - f1-score: 0.8231For batch 225, tr_loss is    0.28.\n",
      "227/244 [==========================>...] - ETA: 15s - loss: 0.2835 - iou_score: 0.7024 - f1-score: 0.8231For batch 226, tr_loss is    0.28.\n",
      "228/244 [===========================>..] - ETA: 14s - loss: 0.2834 - iou_score: 0.7025 - f1-score: 0.8232For batch 227, tr_loss is    0.28.\n",
      "229/244 [===========================>..] - ETA: 13s - loss: 0.2831 - iou_score: 0.7028 - f1-score: 0.8234For batch 228, tr_loss is    0.28.\n",
      "230/244 [===========================>..] - ETA: 12s - loss: 0.2830 - iou_score: 0.7029 - f1-score: 0.8235For batch 229, tr_loss is    0.28.\n",
      "231/244 [===========================>..] - ETA: 11s - loss: 0.2830 - iou_score: 0.7031 - f1-score: 0.8236For batch 230, tr_loss is    0.28.\n",
      "232/244 [===========================>..] - ETA: 10s - loss: 0.2831 - iou_score: 0.7030 - f1-score: 0.8235For batch 231, tr_loss is    0.28.\n",
      "233/244 [===========================>..] - ETA: 9s - loss: 0.2837 - iou_score: 0.7025 - f1-score: 0.8232 For batch 232, tr_loss is    0.28.\n",
      "234/244 [===========================>..] - ETA: 8s - loss: 0.2837 - iou_score: 0.7024 - f1-score: 0.8231For batch 233, tr_loss is    0.28.\n",
      "235/244 [===========================>..] - ETA: 8s - loss: 0.2835 - iou_score: 0.7026 - f1-score: 0.8233For batch 234, tr_loss is    0.28.\n",
      "236/244 [============================>.] - ETA: 7s - loss: 0.2836 - iou_score: 0.7025 - f1-score: 0.8231For batch 235, tr_loss is    0.28.\n",
      "237/244 [============================>.] - ETA: 6s - loss: 0.2837 - iou_score: 0.7024 - f1-score: 0.8231For batch 236, tr_loss is    0.28.\n",
      "238/244 [============================>.] - ETA: 5s - loss: 0.2835 - iou_score: 0.7027 - f1-score: 0.8233For batch 237, tr_loss is    0.28.\n",
      "239/244 [============================>.] - ETA: 4s - loss: 0.2835 - iou_score: 0.7028 - f1-score: 0.8234For batch 238, tr_loss is    0.28.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/244 [============================>.] - ETA: 3s - loss: 0.2832 - iou_score: 0.7031 - f1-score: 0.8236For batch 239, tr_loss is    0.28.\n",
      "241/244 [============================>.] - ETA: 2s - loss: 0.2832 - iou_score: 0.7031 - f1-score: 0.8236For batch 240, tr_loss is    0.28.\n",
      "242/244 [============================>.] - ETA: 1s - loss: 0.2834 - iou_score: 0.7028 - f1-score: 0.8234For batch 241, tr_loss is    0.28.\n",
      "243/244 [============================>.] - ETA: 0s - loss: 0.2838 - iou_score: 0.7024 - f1-score: 0.8230For batch 242, tr_loss is    0.28.\n",
      "244/244 [==============================] - ETA: 0s - loss: 0.2837 - iou_score: 0.7024 - f1-score: 0.8231For batch 243, tr_loss is    0.28.\n",
      "For batch 0, vl_loss is    0.40.\n",
      "For batch 1, vl_loss is    0.39.\n",
      "For batch 2, vl_loss is    0.37.\n",
      "For batch 3, vl_loss is    0.40.\n",
      "For batch 4, vl_loss is    0.38.\n",
      "For batch 5, vl_loss is    0.38.\n",
      "For batch 6, vl_loss is    0.40.\n",
      "For batch 7, vl_loss is    0.40.\n",
      "For batch 8, vl_loss is    0.40.\n",
      "For batch 9, vl_loss is    0.40.\n",
      "For batch 10, vl_loss is    0.41.\n",
      "For batch 11, vl_loss is    0.41.\n",
      "For batch 12, vl_loss is    0.41.\n",
      "For batch 13, vl_loss is    0.41.\n",
      "For batch 14, vl_loss is    0.41.\n",
      "For batch 15, vl_loss is    0.41.\n",
      "For batch 16, vl_loss is    0.41.\n",
      "For batch 17, vl_loss is    0.41.\n",
      "For batch 18, vl_loss is    0.41.\n",
      "For batch 19, vl_loss is    0.41.\n",
      "For batch 20, vl_loss is    0.41.\n",
      "For batch 21, vl_loss is    0.41.\n",
      "For batch 22, vl_loss is    0.41.\n",
      "For batch 23, vl_loss is    0.40.\n",
      "For batch 24, vl_loss is    0.41.\n",
      "For batch 25, vl_loss is    0.41.\n",
      "For batch 26, vl_loss is    0.41.\n",
      "For batch 27, vl_loss is    0.41.\n",
      "For batch 28, vl_loss is    0.41.\n",
      "For batch 29, vl_loss is    0.42.\n",
      "For batch 30, vl_loss is    0.42.\n",
      "For batch 31, vl_loss is    0.42.\n",
      "For batch 32, vl_loss is    0.41.\n",
      "For batch 33, vl_loss is    0.41.\n",
      "For batch 34, vl_loss is    0.41.\n",
      "For batch 35, vl_loss is    0.41.\n",
      "For batch 36, vl_loss is    0.41.\n",
      "For batch 37, vl_loss is    0.42.\n",
      "For batch 38, vl_loss is    0.41.\n",
      "For batch 39, vl_loss is    0.41.\n",
      "For batch 40, vl_loss is    0.41.\n",
      "For batch 41, vl_loss is    0.41.\n",
      "For batch 42, vl_loss is    0.41.\n",
      "For batch 43, vl_loss is    0.41.\n",
      "For batch 44, vl_loss is    0.41.\n",
      "For batch 45, vl_loss is    0.41.\n",
      "For batch 46, vl_loss is    0.41.\n",
      "For batch 47, vl_loss is    0.41.\n",
      "For batch 48, vl_loss is    0.41.\n",
      "For batch 49, vl_loss is    0.40.\n",
      "For batch 50, vl_loss is    0.40.\n",
      "For batch 51, vl_loss is    0.40.\n",
      "For batch 52, vl_loss is    0.40.\n",
      "For batch 53, vl_loss is    0.40.\n",
      "For batch 54, vl_loss is    0.40.\n",
      "For batch 55, vl_loss is    0.41.\n",
      "244/244 [==============================] - 219s 891ms/step - loss: 0.2837 - iou_score: 0.7024 - f1-score: 0.8231 - val_loss: 0.4062 - val_iou_score: 0.5981 - val_f1-score: 0.7463\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.34998\n",
      "The average loss for epoch 6 is    0.28 \n",
      "Epoch 8/200\n",
      "  1/244 [..............................] - ETA: 10:30 - loss: 0.3243 - iou_score: 0.6583 - f1-score: 0.7912For batch 0, tr_loss is    0.32.\n",
      "  2/244 [..............................] - ETA: 5:31 - loss: 0.2921 - iou_score: 0.6978 - f1-score: 0.8197 For batch 1, tr_loss is    0.29.\n",
      "  3/244 [..............................] - ETA: 5:49 - loss: 0.2902 - iou_score: 0.7005 - f1-score: 0.8222For batch 2, tr_loss is    0.29.\n",
      "  4/244 [..............................] - ETA: 5:53 - loss: 0.2944 - iou_score: 0.7006 - f1-score: 0.8227For batch 3, tr_loss is    0.29.\n",
      "  5/244 [..............................] - ETA: 5:28 - loss: 0.2965 - iou_score: 0.7011 - f1-score: 0.8230For batch 4, tr_loss is    0.30.\n",
      "  6/244 [..............................] - ETA: 5:33 - loss: 0.3010 - iou_score: 0.6930 - f1-score: 0.8174For batch 5, tr_loss is    0.30.\n",
      "  7/244 [..............................] - ETA: 5:24 - loss: 0.2939 - iou_score: 0.7016 - f1-score: 0.8227For batch 6, tr_loss is    0.29.\n",
      "  8/244 [..............................] - ETA: 5:06 - loss: 0.3003 - iou_score: 0.6917 - f1-score: 0.8155For batch 7, tr_loss is    0.30.\n",
      "  9/244 [>.............................] - ETA: 4:45 - loss: 0.3031 - iou_score: 0.6878 - f1-score: 0.8125For batch 8, tr_loss is    0.30.\n",
      " 10/244 [>.............................] - ETA: 4:39 - loss: 0.2975 - iou_score: 0.6945 - f1-score: 0.8173For batch 9, tr_loss is    0.30.\n",
      " 11/244 [>.............................] - ETA: 4:33 - loss: 0.2942 - iou_score: 0.6996 - f1-score: 0.8209For batch 10, tr_loss is    0.29.\n",
      " 12/244 [>.............................] - ETA: 4:29 - loss: 0.2923 - iou_score: 0.7016 - f1-score: 0.8225For batch 11, tr_loss is    0.29.\n",
      " 13/244 [>.............................] - ETA: 4:25 - loss: 0.2905 - iou_score: 0.7035 - f1-score: 0.8239For batch 12, tr_loss is    0.29.\n",
      " 14/244 [>.............................] - ETA: 4:22 - loss: 0.2946 - iou_score: 0.6981 - f1-score: 0.8201For batch 13, tr_loss is    0.29.\n",
      " 15/244 [>.............................] - ETA: 4:12 - loss: 0.2968 - iou_score: 0.6953 - f1-score: 0.8182For batch 14, tr_loss is    0.30.\n",
      " 16/244 [>.............................] - ETA: 4:10 - loss: 0.2981 - iou_score: 0.6947 - f1-score: 0.8179For batch 15, tr_loss is    0.30.\n",
      " 17/244 [=>............................] - ETA: 4:07 - loss: 0.2936 - iou_score: 0.7002 - f1-score: 0.8216For batch 16, tr_loss is    0.29.\n",
      " 18/244 [=>............................] - ETA: 3:58 - loss: 0.2945 - iou_score: 0.6991 - f1-score: 0.8209For batch 17, tr_loss is    0.29.\n",
      " 19/244 [=>............................] - ETA: 3:57 - loss: 0.2924 - iou_score: 0.7016 - f1-score: 0.8227For batch 18, tr_loss is    0.29.\n",
      " 20/244 [=>............................] - ETA: 3:56 - loss: 0.2912 - iou_score: 0.7019 - f1-score: 0.8229For batch 19, tr_loss is    0.29.\n",
      " 21/244 [=>............................] - ETA: 3:48 - loss: 0.2905 - iou_score: 0.7016 - f1-score: 0.8227For batch 20, tr_loss is    0.29.\n",
      " 22/244 [=>............................] - ETA: 3:49 - loss: 0.2936 - iou_score: 0.6980 - f1-score: 0.8201For batch 21, tr_loss is    0.29.\n",
      " 23/244 [=>............................] - ETA: 3:48 - loss: 0.2931 - iou_score: 0.6973 - f1-score: 0.8197For batch 22, tr_loss is    0.29.\n",
      " 24/244 [=>............................] - ETA: 3:43 - loss: 0.2911 - iou_score: 0.6995 - f1-score: 0.8212For batch 23, tr_loss is    0.29.\n",
      " 25/244 [==>...........................] - ETA: 3:42 - loss: 0.2918 - iou_score: 0.6977 - f1-score: 0.8200For batch 24, tr_loss is    0.29.\n",
      " 26/244 [==>...........................] - ETA: 3:36 - loss: 0.2909 - iou_score: 0.6981 - f1-score: 0.8203For batch 25, tr_loss is    0.29.\n",
      " 27/244 [==>...........................] - ETA: 3:35 - loss: 0.2907 - iou_score: 0.6988 - f1-score: 0.8208For batch 26, tr_loss is    0.29.\n",
      " 28/244 [==>...........................] - ETA: 3:30 - loss: 0.2872 - iou_score: 0.7032 - f1-score: 0.8238For batch 27, tr_loss is    0.29.\n",
      " 29/244 [==>...........................] - ETA: 3:30 - loss: 0.2849 - iou_score: 0.7047 - f1-score: 0.8248For batch 28, tr_loss is    0.28.\n",
      " 30/244 [==>...........................] - ETA: 3:29 - loss: 0.2824 - iou_score: 0.7080 - f1-score: 0.8270For batch 29, tr_loss is    0.28.\n",
      " 31/244 [==>...........................] - ETA: 3:24 - loss: 0.2809 - iou_score: 0.7096 - f1-score: 0.8282For batch 30, tr_loss is    0.28.\n",
      " 32/244 [==>...........................] - ETA: 3:23 - loss: 0.2792 - iou_score: 0.7116 - f1-score: 0.8295For batch 31, tr_loss is    0.28.\n",
      " 33/244 [===>..........................] - ETA: 3:23 - loss: 0.2781 - iou_score: 0.7119 - f1-score: 0.8298For batch 32, tr_loss is    0.28.\n",
      " 34/244 [===>..........................] - ETA: 3:22 - loss: 0.2776 - iou_score: 0.7121 - f1-score: 0.8299For batch 33, tr_loss is    0.28.\n",
      " 35/244 [===>..........................] - ETA: 3:20 - loss: 0.2788 - iou_score: 0.7107 - f1-score: 0.8290For batch 34, tr_loss is    0.28.\n",
      " 36/244 [===>..........................] - ETA: 3:20 - loss: 0.2774 - iou_score: 0.7122 - f1-score: 0.8300For batch 35, tr_loss is    0.28.\n",
      " 37/244 [===>..........................] - ETA: 3:19 - loss: 0.2778 - iou_score: 0.7115 - f1-score: 0.8296For batch 36, tr_loss is    0.28.\n",
      " 38/244 [===>..........................] - ETA: 3:19 - loss: 0.2770 - iou_score: 0.7129 - f1-score: 0.8305For batch 37, tr_loss is    0.28.\n",
      " 39/244 [===>..........................] - ETA: 3:18 - loss: 0.2758 - iou_score: 0.7144 - f1-score: 0.8316For batch 38, tr_loss is    0.28.\n",
      " 40/244 [===>..........................] - ETA: 3:17 - loss: 0.2761 - iou_score: 0.7134 - f1-score: 0.8309For batch 39, tr_loss is    0.28.\n",
      " 41/244 [====>.........................] - ETA: 3:15 - loss: 0.2762 - iou_score: 0.7123 - f1-score: 0.8302For batch 40, tr_loss is    0.28.\n",
      " 42/244 [====>.........................] - ETA: 3:15 - loss: 0.2755 - iou_score: 0.7127 - f1-score: 0.8305For batch 41, tr_loss is    0.28.\n",
      " 43/244 [====>.........................] - ETA: 3:14 - loss: 0.2769 - iou_score: 0.7114 - f1-score: 0.8296For batch 42, tr_loss is    0.28.\n",
      " 44/244 [====>.........................] - ETA: 3:12 - loss: 0.2765 - iou_score: 0.7124 - f1-score: 0.8303For batch 43, tr_loss is    0.28.\n",
      " 45/244 [====>.........................] - ETA: 3:11 - loss: 0.2771 - iou_score: 0.7116 - f1-score: 0.8298For batch 44, tr_loss is    0.28.\n",
      " 46/244 [====>.........................] - ETA: 3:07 - loss: 0.2768 - iou_score: 0.7120 - f1-score: 0.8300For batch 45, tr_loss is    0.28.\n",
      " 47/244 [====>.........................] - ETA: 3:08 - loss: 0.2756 - iou_score: 0.7131 - f1-score: 0.8308For batch 46, tr_loss is    0.28.\n",
      " 48/244 [====>.........................] - ETA: 3:07 - loss: 0.2748 - iou_score: 0.7138 - f1-score: 0.8313For batch 47, tr_loss is    0.27.\n",
      " 49/244 [=====>........................] - ETA: 3:06 - loss: 0.2765 - iou_score: 0.7125 - f1-score: 0.8304For batch 48, tr_loss is    0.28.\n",
      " 50/244 [=====>........................] - ETA: 3:04 - loss: 0.2764 - iou_score: 0.7124 - f1-score: 0.8303For batch 49, tr_loss is    0.28.\n",
      " 51/244 [=====>........................] - ETA: 3:02 - loss: 0.2774 - iou_score: 0.7114 - f1-score: 0.8296For batch 50, tr_loss is    0.28.\n",
      " 52/244 [=====>........................] - ETA: 3:02 - loss: 0.2772 - iou_score: 0.7110 - f1-score: 0.8294For batch 51, tr_loss is    0.28.\n",
      " 53/244 [=====>........................] - ETA: 3:01 - loss: 0.2775 - iou_score: 0.7104 - f1-score: 0.8290For batch 52, tr_loss is    0.28.\n",
      " 54/244 [=====>........................] - ETA: 3:00 - loss: 0.2778 - iou_score: 0.7100 - f1-score: 0.8287For batch 53, tr_loss is    0.28.\n",
      " 55/244 [=====>........................] - ETA: 2:58 - loss: 0.2766 - iou_score: 0.7112 - f1-score: 0.8295For batch 54, tr_loss is    0.28.\n",
      " 56/244 [=====>........................] - ETA: 2:57 - loss: 0.2759 - iou_score: 0.7119 - f1-score: 0.8300For batch 55, tr_loss is    0.28.\n",
      " 57/244 [======>.......................] - ETA: 2:57 - loss: 0.2769 - iou_score: 0.7110 - f1-score: 0.8294For batch 56, tr_loss is    0.28.\n",
      " 58/244 [======>.......................] - ETA: 2:54 - loss: 0.2777 - iou_score: 0.7101 - f1-score: 0.8288For batch 57, tr_loss is    0.28.\n",
      " 59/244 [======>.......................] - ETA: 2:53 - loss: 0.2764 - iou_score: 0.7121 - f1-score: 0.8301For batch 58, tr_loss is    0.28.\n",
      " 60/244 [======>.......................] - ETA: 2:53 - loss: 0.2779 - iou_score: 0.7098 - f1-score: 0.8284For batch 59, tr_loss is    0.28.\n",
      " 61/244 [======>.......................] - ETA: 2:50 - loss: 0.2790 - iou_score: 0.7079 - f1-score: 0.8271For batch 60, tr_loss is    0.28.\n",
      " 62/244 [======>.......................] - ETA: 2:50 - loss: 0.2790 - iou_score: 0.7080 - f1-score: 0.8271For batch 61, tr_loss is    0.28.\n",
      " 63/244 [======>.......................] - ETA: 2:49 - loss: 0.2791 - iou_score: 0.7077 - f1-score: 0.8269For batch 62, tr_loss is    0.28.\n",
      " 64/244 [======>.......................] - ETA: 2:48 - loss: 0.2785 - iou_score: 0.7086 - f1-score: 0.8276For batch 63, tr_loss is    0.28.\n",
      " 65/244 [======>.......................] - ETA: 2:47 - loss: 0.2784 - iou_score: 0.7084 - f1-score: 0.8275For batch 64, tr_loss is    0.28.\n",
      " 66/244 [=======>......................] - ETA: 2:46 - loss: 0.2786 - iou_score: 0.7085 - f1-score: 0.8275For batch 65, tr_loss is    0.28.\n",
      " 67/244 [=======>......................] - ETA: 2:46 - loss: 0.2782 - iou_score: 0.7091 - f1-score: 0.8279For batch 66, tr_loss is    0.28.\n",
      " 68/244 [=======>......................] - ETA: 2:45 - loss: 0.2780 - iou_score: 0.7095 - f1-score: 0.8282For batch 67, tr_loss is    0.28.\n",
      " 69/244 [=======>......................] - ETA: 2:43 - loss: 0.2789 - iou_score: 0.7082 - f1-score: 0.8273For batch 68, tr_loss is    0.28.\n",
      " 70/244 [=======>......................] - ETA: 2:43 - loss: 0.2784 - iou_score: 0.7083 - f1-score: 0.8274For batch 69, tr_loss is    0.28.\n",
      " 71/244 [=======>......................] - ETA: 2:42 - loss: 0.2784 - iou_score: 0.7083 - f1-score: 0.8274For batch 70, tr_loss is    0.28.\n",
      " 72/244 [=======>......................] - ETA: 2:41 - loss: 0.2776 - iou_score: 0.7092 - f1-score: 0.8280For batch 71, tr_loss is    0.28.\n",
      " 73/244 [=======>......................] - ETA: 2:40 - loss: 0.2782 - iou_score: 0.7084 - f1-score: 0.8273For batch 72, tr_loss is    0.28.\n",
      " 74/244 [========>.....................] - ETA: 2:39 - loss: 0.2786 - iou_score: 0.7080 - f1-score: 0.8271For batch 73, tr_loss is    0.28.\n",
      " 75/244 [========>.....................] - ETA: 2:38 - loss: 0.2785 - iou_score: 0.7079 - f1-score: 0.8270For batch 74, tr_loss is    0.28.\n",
      " 76/244 [========>.....................] - ETA: 2:37 - loss: 0.2782 - iou_score: 0.7083 - f1-score: 0.8273For batch 75, tr_loss is    0.28.\n",
      " 77/244 [========>.....................] - ETA: 2:35 - loss: 0.2780 - iou_score: 0.7083 - f1-score: 0.8273For batch 76, tr_loss is    0.28.\n",
      " 78/244 [========>.....................] - ETA: 2:35 - loss: 0.2777 - iou_score: 0.7086 - f1-score: 0.8276For batch 77, tr_loss is    0.28.\n",
      " 79/244 [========>.....................] - ETA: 2:33 - loss: 0.2778 - iou_score: 0.7090 - f1-score: 0.8277For batch 78, tr_loss is    0.28.\n",
      " 80/244 [========>.....................] - ETA: 2:32 - loss: 0.2774 - iou_score: 0.7091 - f1-score: 0.8278For batch 79, tr_loss is    0.28.\n",
      " 81/244 [========>.....................] - ETA: 2:31 - loss: 0.2776 - iou_score: 0.7087 - f1-score: 0.8275For batch 80, tr_loss is    0.28.\n",
      " 82/244 [=========>....................] - ETA: 2:30 - loss: 0.2791 - iou_score: 0.7068 - f1-score: 0.8260For batch 81, tr_loss is    0.28.\n",
      " 83/244 [=========>....................] - ETA: 2:29 - loss: 0.2784 - iou_score: 0.7074 - f1-score: 0.8265For batch 82, tr_loss is    0.28.\n",
      " 84/244 [=========>....................] - ETA: 2:28 - loss: 0.2781 - iou_score: 0.7076 - f1-score: 0.8266For batch 83, tr_loss is    0.28.\n",
      " 85/244 [=========>....................] - ETA: 2:26 - loss: 0.2777 - iou_score: 0.7080 - f1-score: 0.8269For batch 84, tr_loss is    0.28.\n",
      " 86/244 [=========>....................] - ETA: 2:25 - loss: 0.2781 - iou_score: 0.7075 - f1-score: 0.8265For batch 85, tr_loss is    0.28.\n",
      " 87/244 [=========>....................] - ETA: 2:24 - loss: 0.2780 - iou_score: 0.7076 - f1-score: 0.8266For batch 86, tr_loss is    0.28.\n",
      " 88/244 [=========>....................] - ETA: 2:23 - loss: 0.2775 - iou_score: 0.7083 - f1-score: 0.8271For batch 87, tr_loss is    0.28.\n",
      " 89/244 [=========>....................] - ETA: 2:21 - loss: 0.2780 - iou_score: 0.7077 - f1-score: 0.8267For batch 88, tr_loss is    0.28.\n",
      " 90/244 [==========>...................] - ETA: 2:21 - loss: 0.2781 - iou_score: 0.7078 - f1-score: 0.8268For batch 89, tr_loss is    0.28.\n",
      " 91/244 [==========>...................] - ETA: 2:20 - loss: 0.2790 - iou_score: 0.7066 - f1-score: 0.8260For batch 90, tr_loss is    0.28.\n",
      " 92/244 [==========>...................] - ETA: 2:18 - loss: 0.2793 - iou_score: 0.7060 - f1-score: 0.8255For batch 91, tr_loss is    0.28.\n",
      " 93/244 [==========>...................] - ETA: 2:18 - loss: 0.2787 - iou_score: 0.7071 - f1-score: 0.8262For batch 92, tr_loss is    0.28.\n",
      " 94/244 [==========>...................] - ETA: 2:17 - loss: 0.2785 - iou_score: 0.7072 - f1-score: 0.8263For batch 93, tr_loss is    0.28.\n",
      " 95/244 [==========>...................] - ETA: 2:16 - loss: 0.2787 - iou_score: 0.7068 - f1-score: 0.8259For batch 94, tr_loss is    0.28.\n",
      " 96/244 [==========>...................] - ETA: 2:15 - loss: 0.2791 - iou_score: 0.7061 - f1-score: 0.8255For batch 95, tr_loss is    0.28.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 97/244 [==========>...................] - ETA: 2:14 - loss: 0.2788 - iou_score: 0.7065 - f1-score: 0.8258For batch 96, tr_loss is    0.28.\n",
      " 98/244 [===========>..................] - ETA: 2:12 - loss: 0.2787 - iou_score: 0.7065 - f1-score: 0.8258For batch 97, tr_loss is    0.28.\n",
      " 99/244 [===========>..................] - ETA: 2:12 - loss: 0.2788 - iou_score: 0.7066 - f1-score: 0.8259For batch 98, tr_loss is    0.28.\n",
      "100/244 [===========>..................] - ETA: 2:11 - loss: 0.2781 - iou_score: 0.7074 - f1-score: 0.8265For batch 99, tr_loss is    0.28.\n",
      "101/244 [===========>..................] - ETA: 2:10 - loss: 0.2780 - iou_score: 0.7074 - f1-score: 0.8264For batch 100, tr_loss is    0.28.\n",
      "102/244 [===========>..................] - ETA: 2:09 - loss: 0.2777 - iou_score: 0.7075 - f1-score: 0.8265For batch 101, tr_loss is    0.28.\n",
      "103/244 [===========>..................] - ETA: 2:08 - loss: 0.2772 - iou_score: 0.7081 - f1-score: 0.8269For batch 102, tr_loss is    0.28.\n",
      "104/244 [===========>..................] - ETA: 2:06 - loss: 0.2770 - iou_score: 0.7083 - f1-score: 0.8271For batch 103, tr_loss is    0.28.\n",
      "105/244 [===========>..................] - ETA: 2:05 - loss: 0.2772 - iou_score: 0.7080 - f1-score: 0.8269For batch 104, tr_loss is    0.28.\n",
      "106/244 [============>.................] - ETA: 2:05 - loss: 0.2764 - iou_score: 0.7090 - f1-score: 0.8275For batch 105, tr_loss is    0.28.\n",
      "107/244 [============>.................] - ETA: 2:03 - loss: 0.2757 - iou_score: 0.7097 - f1-score: 0.8280For batch 106, tr_loss is    0.28.\n",
      "108/244 [============>.................] - ETA: 2:02 - loss: 0.2759 - iou_score: 0.7096 - f1-score: 0.8280For batch 107, tr_loss is    0.28.\n",
      "109/244 [============>.................] - ETA: 2:01 - loss: 0.2760 - iou_score: 0.7091 - f1-score: 0.8277For batch 108, tr_loss is    0.28.\n",
      "110/244 [============>.................] - ETA: 2:01 - loss: 0.2761 - iou_score: 0.7089 - f1-score: 0.8275For batch 109, tr_loss is    0.28.\n",
      "111/244 [============>.................] - ETA: 2:00 - loss: 0.2760 - iou_score: 0.7088 - f1-score: 0.8274For batch 110, tr_loss is    0.28.\n",
      "112/244 [============>.................] - ETA: 1:59 - loss: 0.2761 - iou_score: 0.7086 - f1-score: 0.8273For batch 111, tr_loss is    0.28.\n",
      "113/244 [============>.................] - ETA: 1:58 - loss: 0.2762 - iou_score: 0.7087 - f1-score: 0.8274For batch 112, tr_loss is    0.28.\n",
      "114/244 [=============>................] - ETA: 1:57 - loss: 0.2765 - iou_score: 0.7082 - f1-score: 0.8271For batch 113, tr_loss is    0.28.\n",
      "115/244 [=============>................] - ETA: 1:56 - loss: 0.2761 - iou_score: 0.7086 - f1-score: 0.8273For batch 114, tr_loss is    0.28.\n",
      "116/244 [=============>................] - ETA: 1:55 - loss: 0.2758 - iou_score: 0.7088 - f1-score: 0.8275For batch 115, tr_loss is    0.28.\n",
      "117/244 [=============>................] - ETA: 1:54 - loss: 0.2760 - iou_score: 0.7083 - f1-score: 0.8272For batch 116, tr_loss is    0.28.\n",
      "118/244 [=============>................] - ETA: 1:53 - loss: 0.2759 - iou_score: 0.7083 - f1-score: 0.8272For batch 117, tr_loss is    0.28.\n",
      "119/244 [=============>................] - ETA: 1:53 - loss: 0.2758 - iou_score: 0.7085 - f1-score: 0.8273For batch 118, tr_loss is    0.28.\n",
      "120/244 [=============>................] - ETA: 1:51 - loss: 0.2772 - iou_score: 0.7073 - f1-score: 0.8264For batch 119, tr_loss is    0.28.\n",
      "121/244 [=============>................] - ETA: 1:50 - loss: 0.2767 - iou_score: 0.7080 - f1-score: 0.8269For batch 120, tr_loss is    0.28.\n",
      "122/244 [==============>...............] - ETA: 1:50 - loss: 0.2764 - iou_score: 0.7084 - f1-score: 0.8271For batch 121, tr_loss is    0.28.\n",
      "123/244 [==============>...............] - ETA: 1:49 - loss: 0.2769 - iou_score: 0.7077 - f1-score: 0.8267For batch 122, tr_loss is    0.28.\n",
      "124/244 [==============>...............] - ETA: 1:47 - loss: 0.2776 - iou_score: 0.7070 - f1-score: 0.8261For batch 123, tr_loss is    0.28.\n",
      "125/244 [==============>...............] - ETA: 1:46 - loss: 0.2773 - iou_score: 0.7074 - f1-score: 0.8264For batch 124, tr_loss is    0.28.\n",
      "126/244 [==============>...............] - ETA: 1:45 - loss: 0.2775 - iou_score: 0.7073 - f1-score: 0.8264For batch 125, tr_loss is    0.28.\n",
      "127/244 [==============>...............] - ETA: 1:44 - loss: 0.2777 - iou_score: 0.7069 - f1-score: 0.8261For batch 126, tr_loss is    0.28.\n",
      "128/244 [==============>...............] - ETA: 1:43 - loss: 0.2773 - iou_score: 0.7074 - f1-score: 0.8264For batch 127, tr_loss is    0.28.\n",
      "129/244 [==============>...............] - ETA: 1:43 - loss: 0.2773 - iou_score: 0.7073 - f1-score: 0.8264For batch 128, tr_loss is    0.28.\n",
      "130/244 [==============>...............] - ETA: 1:42 - loss: 0.2775 - iou_score: 0.7068 - f1-score: 0.8260For batch 129, tr_loss is    0.28.\n",
      "131/244 [===============>..............] - ETA: 1:41 - loss: 0.2772 - iou_score: 0.7072 - f1-score: 0.8263For batch 130, tr_loss is    0.28.\n",
      "132/244 [===============>..............] - ETA: 1:40 - loss: 0.2775 - iou_score: 0.7068 - f1-score: 0.8260For batch 131, tr_loss is    0.28.\n",
      "133/244 [===============>..............] - ETA: 1:39 - loss: 0.2775 - iou_score: 0.7068 - f1-score: 0.8260For batch 132, tr_loss is    0.28.\n",
      "134/244 [===============>..............] - ETA: 1:39 - loss: 0.2780 - iou_score: 0.7060 - f1-score: 0.8254For batch 133, tr_loss is    0.28.\n",
      "135/244 [===============>..............] - ETA: 1:38 - loss: 0.2781 - iou_score: 0.7056 - f1-score: 0.8252For batch 134, tr_loss is    0.28.\n",
      "136/244 [===============>..............] - ETA: 1:37 - loss: 0.2778 - iou_score: 0.7061 - f1-score: 0.8255For batch 135, tr_loss is    0.28.\n",
      "137/244 [===============>..............] - ETA: 1:36 - loss: 0.2777 - iou_score: 0.7062 - f1-score: 0.8256For batch 136, tr_loss is    0.28.\n",
      "138/244 [===============>..............] - ETA: 1:35 - loss: 0.2778 - iou_score: 0.7060 - f1-score: 0.8254For batch 137, tr_loss is    0.28.\n",
      "139/244 [================>.............] - ETA: 1:34 - loss: 0.2781 - iou_score: 0.7056 - f1-score: 0.8252For batch 138, tr_loss is    0.28.\n",
      "140/244 [================>.............] - ETA: 1:33 - loss: 0.2781 - iou_score: 0.7055 - f1-score: 0.8252For batch 139, tr_loss is    0.28.\n",
      "141/244 [================>.............] - ETA: 1:33 - loss: 0.2781 - iou_score: 0.7054 - f1-score: 0.8251For batch 140, tr_loss is    0.28.\n",
      "142/244 [================>.............] - ETA: 1:32 - loss: 0.2782 - iou_score: 0.7052 - f1-score: 0.8249For batch 141, tr_loss is    0.28.\n",
      "143/244 [================>.............] - ETA: 1:31 - loss: 0.2780 - iou_score: 0.7057 - f1-score: 0.8253For batch 142, tr_loss is    0.28.\n",
      "144/244 [================>.............] - ETA: 1:30 - loss: 0.2786 - iou_score: 0.7051 - f1-score: 0.8248For batch 143, tr_loss is    0.28.\n",
      "145/244 [================>.............] - ETA: 1:29 - loss: 0.2788 - iou_score: 0.7049 - f1-score: 0.8247For batch 144, tr_loss is    0.28.\n",
      "146/244 [================>.............] - ETA: 1:28 - loss: 0.2788 - iou_score: 0.7047 - f1-score: 0.8246For batch 145, tr_loss is    0.28.\n",
      "147/244 [=================>............] - ETA: 1:28 - loss: 0.2786 - iou_score: 0.7048 - f1-score: 0.8246For batch 146, tr_loss is    0.28.\n",
      "148/244 [=================>............] - ETA: 1:26 - loss: 0.2787 - iou_score: 0.7045 - f1-score: 0.8245For batch 147, tr_loss is    0.28.\n",
      "149/244 [=================>............] - ETA: 1:26 - loss: 0.2788 - iou_score: 0.7044 - f1-score: 0.8244For batch 148, tr_loss is    0.28.\n",
      "150/244 [=================>............] - ETA: 1:25 - loss: 0.2788 - iou_score: 0.7043 - f1-score: 0.8244For batch 149, tr_loss is    0.28.\n",
      "151/244 [=================>............] - ETA: 1:24 - loss: 0.2789 - iou_score: 0.7043 - f1-score: 0.8244For batch 150, tr_loss is    0.28.\n",
      "152/244 [=================>............] - ETA: 1:23 - loss: 0.2790 - iou_score: 0.7041 - f1-score: 0.8242For batch 151, tr_loss is    0.28.\n",
      "153/244 [=================>............] - ETA: 1:22 - loss: 0.2789 - iou_score: 0.7043 - f1-score: 0.8244For batch 152, tr_loss is    0.28.\n",
      "154/244 [=================>............] - ETA: 1:21 - loss: 0.2789 - iou_score: 0.7043 - f1-score: 0.8244For batch 153, tr_loss is    0.28.\n",
      "155/244 [==================>...........] - ETA: 1:20 - loss: 0.2790 - iou_score: 0.7041 - f1-score: 0.8242For batch 154, tr_loss is    0.28.\n",
      "156/244 [==================>...........] - ETA: 1:19 - loss: 0.2786 - iou_score: 0.7047 - f1-score: 0.8246For batch 155, tr_loss is    0.28.\n",
      "157/244 [==================>...........] - ETA: 1:18 - loss: 0.2783 - iou_score: 0.7049 - f1-score: 0.8248For batch 156, tr_loss is    0.28.\n",
      "158/244 [==================>...........] - ETA: 1:17 - loss: 0.2784 - iou_score: 0.7048 - f1-score: 0.8248For batch 157, tr_loss is    0.28.\n",
      "159/244 [==================>...........] - ETA: 1:16 - loss: 0.2782 - iou_score: 0.7051 - f1-score: 0.8249For batch 158, tr_loss is    0.28.\n",
      "160/244 [==================>...........] - ETA: 1:15 - loss: 0.2779 - iou_score: 0.7054 - f1-score: 0.8251For batch 159, tr_loss is    0.28.\n",
      "161/244 [==================>...........] - ETA: 1:15 - loss: 0.2780 - iou_score: 0.7051 - f1-score: 0.8250For batch 160, tr_loss is    0.28.\n",
      "162/244 [==================>...........] - ETA: 1:13 - loss: 0.2778 - iou_score: 0.7054 - f1-score: 0.8252For batch 161, tr_loss is    0.28.\n",
      "163/244 [===================>..........] - ETA: 1:13 - loss: 0.2779 - iou_score: 0.7054 - f1-score: 0.8252For batch 162, tr_loss is    0.28.\n",
      "164/244 [===================>..........] - ETA: 1:12 - loss: 0.2778 - iou_score: 0.7056 - f1-score: 0.8253For batch 163, tr_loss is    0.28.\n",
      "165/244 [===================>..........] - ETA: 1:11 - loss: 0.2780 - iou_score: 0.7054 - f1-score: 0.8252For batch 164, tr_loss is    0.28.\n",
      "166/244 [===================>..........] - ETA: 1:10 - loss: 0.2783 - iou_score: 0.7052 - f1-score: 0.8250For batch 165, tr_loss is    0.28.\n",
      "167/244 [===================>..........] - ETA: 1:09 - loss: 0.2780 - iou_score: 0.7056 - f1-score: 0.8253For batch 166, tr_loss is    0.28.\n",
      "168/244 [===================>..........] - ETA: 1:08 - loss: 0.2777 - iou_score: 0.7059 - f1-score: 0.8255For batch 167, tr_loss is    0.28.\n",
      "169/244 [===================>..........] - ETA: 1:07 - loss: 0.2775 - iou_score: 0.7062 - f1-score: 0.8257For batch 168, tr_loss is    0.28.\n",
      "170/244 [===================>..........] - ETA: 1:06 - loss: 0.2779 - iou_score: 0.7057 - f1-score: 0.8253For batch 169, tr_loss is    0.28.\n",
      "171/244 [====================>.........] - ETA: 1:05 - loss: 0.2776 - iou_score: 0.7060 - f1-score: 0.8256For batch 170, tr_loss is    0.28.\n",
      "172/244 [====================>.........] - ETA: 1:04 - loss: 0.2776 - iou_score: 0.7060 - f1-score: 0.8256For batch 171, tr_loss is    0.28.\n",
      "173/244 [====================>.........] - ETA: 1:03 - loss: 0.2779 - iou_score: 0.7058 - f1-score: 0.8255For batch 172, tr_loss is    0.28.\n",
      "174/244 [====================>.........] - ETA: 1:02 - loss: 0.2782 - iou_score: 0.7054 - f1-score: 0.8252For batch 173, tr_loss is    0.28.\n",
      "175/244 [====================>.........] - ETA: 1:01 - loss: 0.2782 - iou_score: 0.7052 - f1-score: 0.8250For batch 174, tr_loss is    0.28.\n",
      "176/244 [====================>.........] - ETA: 1:00 - loss: 0.2781 - iou_score: 0.7053 - f1-score: 0.8251For batch 175, tr_loss is    0.28.\n",
      "177/244 [====================>.........] - ETA: 59s - loss: 0.2777 - iou_score: 0.7058 - f1-score: 0.8254 For batch 176, tr_loss is    0.28.\n",
      "178/244 [====================>.........] - ETA: 58s - loss: 0.2779 - iou_score: 0.7054 - f1-score: 0.8251For batch 177, tr_loss is    0.28.\n",
      "179/244 [=====================>........] - ETA: 57s - loss: 0.2778 - iou_score: 0.7056 - f1-score: 0.8253For batch 178, tr_loss is    0.28.\n",
      "180/244 [=====================>........] - ETA: 56s - loss: 0.2777 - iou_score: 0.7056 - f1-score: 0.8253For batch 179, tr_loss is    0.28.\n",
      "181/244 [=====================>........] - ETA: 56s - loss: 0.2775 - iou_score: 0.7058 - f1-score: 0.8255For batch 180, tr_loss is    0.28.\n",
      "182/244 [=====================>........] - ETA: 55s - loss: 0.2775 - iou_score: 0.7058 - f1-score: 0.8254For batch 181, tr_loss is    0.28.\n",
      "183/244 [=====================>........] - ETA: 54s - loss: 0.2776 - iou_score: 0.7056 - f1-score: 0.8253For batch 182, tr_loss is    0.28.\n",
      "184/244 [=====================>........] - ETA: 53s - loss: 0.2779 - iou_score: 0.7052 - f1-score: 0.8251For batch 183, tr_loss is    0.28.\n",
      "185/244 [=====================>........] - ETA: 52s - loss: 0.2779 - iou_score: 0.7052 - f1-score: 0.8250For batch 184, tr_loss is    0.28.\n",
      "186/244 [=====================>........] - ETA: 51s - loss: 0.2775 - iou_score: 0.7056 - f1-score: 0.8253For batch 185, tr_loss is    0.28.\n",
      "187/244 [=====================>........] - ETA: 50s - loss: 0.2780 - iou_score: 0.7052 - f1-score: 0.8250For batch 186, tr_loss is    0.28.\n",
      "188/244 [======================>.......] - ETA: 49s - loss: 0.2780 - iou_score: 0.7051 - f1-score: 0.8250For batch 187, tr_loss is    0.28.\n",
      "189/244 [======================>.......] - ETA: 48s - loss: 0.2779 - iou_score: 0.7053 - f1-score: 0.8251For batch 188, tr_loss is    0.28.\n",
      "190/244 [======================>.......] - ETA: 47s - loss: 0.2775 - iou_score: 0.7057 - f1-score: 0.8254For batch 189, tr_loss is    0.28.\n",
      "191/244 [======================>.......] - ETA: 47s - loss: 0.2773 - iou_score: 0.7060 - f1-score: 0.8256For batch 190, tr_loss is    0.28.\n",
      "192/244 [======================>.......] - ETA: 46s - loss: 0.2773 - iou_score: 0.7059 - f1-score: 0.8255For batch 191, tr_loss is    0.28.\n",
      "193/244 [======================>.......] - ETA: 45s - loss: 0.2773 - iou_score: 0.7058 - f1-score: 0.8254For batch 192, tr_loss is    0.28.\n",
      "194/244 [======================>.......] - ETA: 44s - loss: 0.2770 - iou_score: 0.7060 - f1-score: 0.8256For batch 193, tr_loss is    0.28.\n",
      "195/244 [======================>.......] - ETA: 43s - loss: 0.2772 - iou_score: 0.7058 - f1-score: 0.8255For batch 194, tr_loss is    0.28.\n",
      "196/244 [=======================>......] - ETA: 42s - loss: 0.2771 - iou_score: 0.7059 - f1-score: 0.8255For batch 195, tr_loss is    0.28.\n",
      "197/244 [=======================>......] - ETA: 41s - loss: 0.2773 - iou_score: 0.7056 - f1-score: 0.8254For batch 196, tr_loss is    0.28.\n",
      "198/244 [=======================>......] - ETA: 40s - loss: 0.2772 - iou_score: 0.7057 - f1-score: 0.8254For batch 197, tr_loss is    0.28.\n",
      "199/244 [=======================>......] - ETA: 40s - loss: 0.2768 - iou_score: 0.7063 - f1-score: 0.8258For batch 198, tr_loss is    0.28.\n",
      "200/244 [=======================>......] - ETA: 39s - loss: 0.2770 - iou_score: 0.7062 - f1-score: 0.8258For batch 199, tr_loss is    0.28.\n",
      "201/244 [=======================>......] - ETA: 38s - loss: 0.2772 - iou_score: 0.7061 - f1-score: 0.8257For batch 200, tr_loss is    0.28.\n",
      "202/244 [=======================>......] - ETA: 37s - loss: 0.2770 - iou_score: 0.7062 - f1-score: 0.8257For batch 201, tr_loss is    0.28.\n",
      "203/244 [=======================>......] - ETA: 36s - loss: 0.2770 - iou_score: 0.7063 - f1-score: 0.8258For batch 202, tr_loss is    0.28.\n",
      "204/244 [========================>.....] - ETA: 35s - loss: 0.2767 - iou_score: 0.7065 - f1-score: 0.8260For batch 203, tr_loss is    0.28.\n",
      "205/244 [========================>.....] - ETA: 34s - loss: 0.2763 - iou_score: 0.7070 - f1-score: 0.8263For batch 204, tr_loss is    0.28.\n",
      "206/244 [========================>.....] - ETA: 33s - loss: 0.2766 - iou_score: 0.7066 - f1-score: 0.8260For batch 205, tr_loss is    0.28.\n",
      "207/244 [========================>.....] - ETA: 32s - loss: 0.2763 - iou_score: 0.7069 - f1-score: 0.8262For batch 206, tr_loss is    0.28.\n",
      "208/244 [========================>.....] - ETA: 31s - loss: 0.2765 - iou_score: 0.7065 - f1-score: 0.8259For batch 207, tr_loss is    0.28.\n",
      "209/244 [========================>.....] - ETA: 31s - loss: 0.2764 - iou_score: 0.7065 - f1-score: 0.8260For batch 208, tr_loss is    0.28.\n",
      "210/244 [========================>.....] - ETA: 30s - loss: 0.2761 - iou_score: 0.7068 - f1-score: 0.8262For batch 209, tr_loss is    0.28.\n",
      "211/244 [========================>.....] - ETA: 29s - loss: 0.2761 - iou_score: 0.7068 - f1-score: 0.8262For batch 210, tr_loss is    0.28.\n",
      "212/244 [=========================>....] - ETA: 28s - loss: 0.2762 - iou_score: 0.7067 - f1-score: 0.8261For batch 211, tr_loss is    0.28.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213/244 [=========================>....] - ETA: 27s - loss: 0.2763 - iou_score: 0.7067 - f1-score: 0.8261For batch 212, tr_loss is    0.28.\n",
      "214/244 [=========================>....] - ETA: 26s - loss: 0.2761 - iou_score: 0.7070 - f1-score: 0.8263For batch 213, tr_loss is    0.28.\n",
      "215/244 [=========================>....] - ETA: 25s - loss: 0.2760 - iou_score: 0.7072 - f1-score: 0.8264For batch 214, tr_loss is    0.28.\n",
      "216/244 [=========================>....] - ETA: 24s - loss: 0.2763 - iou_score: 0.7070 - f1-score: 0.8263For batch 215, tr_loss is    0.28.\n",
      "217/244 [=========================>....] - ETA: 23s - loss: 0.2763 - iou_score: 0.7070 - f1-score: 0.8263For batch 216, tr_loss is    0.28.\n",
      "218/244 [=========================>....] - ETA: 22s - loss: 0.2762 - iou_score: 0.7071 - f1-score: 0.8264For batch 217, tr_loss is    0.28.\n",
      "219/244 [=========================>....] - ETA: 22s - loss: 0.2762 - iou_score: 0.7070 - f1-score: 0.8264For batch 218, tr_loss is    0.28.\n",
      "220/244 [==========================>...] - ETA: 21s - loss: 0.2762 - iou_score: 0.7069 - f1-score: 0.8263For batch 219, tr_loss is    0.28.\n",
      "221/244 [==========================>...] - ETA: 20s - loss: 0.2763 - iou_score: 0.7069 - f1-score: 0.8262For batch 220, tr_loss is    0.28.\n",
      "222/244 [==========================>...] - ETA: 19s - loss: 0.2760 - iou_score: 0.7072 - f1-score: 0.8264For batch 221, tr_loss is    0.28.\n",
      "223/244 [==========================>...] - ETA: 18s - loss: 0.2759 - iou_score: 0.7072 - f1-score: 0.8265For batch 222, tr_loss is    0.28.\n",
      "224/244 [==========================>...] - ETA: 17s - loss: 0.2760 - iou_score: 0.7072 - f1-score: 0.8265For batch 223, tr_loss is    0.28.\n",
      "225/244 [==========================>...] - ETA: 16s - loss: 0.2759 - iou_score: 0.7073 - f1-score: 0.8265For batch 224, tr_loss is    0.28.\n",
      "226/244 [==========================>...] - ETA: 15s - loss: 0.2756 - iou_score: 0.7074 - f1-score: 0.8266For batch 225, tr_loss is    0.28.\n",
      "227/244 [==========================>...] - ETA: 15s - loss: 0.2756 - iou_score: 0.7076 - f1-score: 0.8267For batch 226, tr_loss is    0.28.\n",
      "228/244 [===========================>..] - ETA: 14s - loss: 0.2755 - iou_score: 0.7077 - f1-score: 0.8268For batch 227, tr_loss is    0.28.\n",
      "229/244 [===========================>..] - ETA: 13s - loss: 0.2752 - iou_score: 0.7080 - f1-score: 0.8270For batch 228, tr_loss is    0.28.\n",
      "230/244 [===========================>..] - ETA: 12s - loss: 0.2752 - iou_score: 0.7080 - f1-score: 0.8271For batch 229, tr_loss is    0.28.\n",
      "231/244 [===========================>..] - ETA: 11s - loss: 0.2751 - iou_score: 0.7082 - f1-score: 0.8272For batch 230, tr_loss is    0.28.\n",
      "232/244 [===========================>..] - ETA: 10s - loss: 0.2751 - iou_score: 0.7082 - f1-score: 0.8272For batch 231, tr_loss is    0.28.\n",
      "233/244 [===========================>..] - ETA: 9s - loss: 0.2758 - iou_score: 0.7076 - f1-score: 0.8268 For batch 232, tr_loss is    0.28.\n",
      "234/244 [===========================>..] - ETA: 8s - loss: 0.2758 - iou_score: 0.7076 - f1-score: 0.8267For batch 233, tr_loss is    0.28.\n",
      "235/244 [===========================>..] - ETA: 7s - loss: 0.2756 - iou_score: 0.7078 - f1-score: 0.8269For batch 234, tr_loss is    0.28.\n",
      "236/244 [============================>.] - ETA: 7s - loss: 0.2758 - iou_score: 0.7076 - f1-score: 0.8268For batch 235, tr_loss is    0.28.\n",
      "237/244 [============================>.] - ETA: 6s - loss: 0.2758 - iou_score: 0.7075 - f1-score: 0.8267For batch 236, tr_loss is    0.28.\n",
      "238/244 [============================>.] - ETA: 5s - loss: 0.2757 - iou_score: 0.7078 - f1-score: 0.8269For batch 237, tr_loss is    0.28.\n",
      "239/244 [============================>.] - ETA: 4s - loss: 0.2757 - iou_score: 0.7078 - f1-score: 0.8269For batch 238, tr_loss is    0.28.\n",
      "240/244 [============================>.] - ETA: 3s - loss: 0.2754 - iou_score: 0.7080 - f1-score: 0.8270For batch 239, tr_loss is    0.28.\n",
      "241/244 [============================>.] - ETA: 2s - loss: 0.2755 - iou_score: 0.7080 - f1-score: 0.8270For batch 240, tr_loss is    0.28.\n",
      "242/244 [============================>.] - ETA: 1s - loss: 0.2757 - iou_score: 0.7078 - f1-score: 0.8269For batch 241, tr_loss is    0.28.\n",
      "243/244 [============================>.] - ETA: 0s - loss: 0.2760 - iou_score: 0.7073 - f1-score: 0.8265For batch 242, tr_loss is    0.28.\n",
      "244/244 [==============================] - ETA: 0s - loss: 0.2760 - iou_score: 0.7072 - f1-score: 0.8265For batch 243, tr_loss is    0.28.\n",
      "For batch 0, vl_loss is    0.36.\n",
      "For batch 1, vl_loss is    0.35.\n",
      "For batch 2, vl_loss is    0.32.\n",
      "For batch 3, vl_loss is    0.36.\n",
      "For batch 4, vl_loss is    0.35.\n",
      "For batch 5, vl_loss is    0.35.\n",
      "For batch 6, vl_loss is    0.37.\n",
      "For batch 7, vl_loss is    0.36.\n",
      "For batch 8, vl_loss is    0.36.\n",
      "For batch 9, vl_loss is    0.36.\n",
      "For batch 10, vl_loss is    0.37.\n",
      "For batch 11, vl_loss is    0.37.\n",
      "For batch 12, vl_loss is    0.37.\n",
      "For batch 13, vl_loss is    0.37.\n",
      "For batch 14, vl_loss is    0.37.\n",
      "For batch 15, vl_loss is    0.37.\n",
      "For batch 16, vl_loss is    0.37.\n",
      "For batch 17, vl_loss is    0.36.\n",
      "For batch 18, vl_loss is    0.37.\n",
      "For batch 19, vl_loss is    0.36.\n",
      "For batch 20, vl_loss is    0.36.\n",
      "For batch 21, vl_loss is    0.36.\n",
      "For batch 22, vl_loss is    0.36.\n",
      "For batch 23, vl_loss is    0.36.\n",
      "For batch 24, vl_loss is    0.36.\n",
      "For batch 25, vl_loss is    0.36.\n",
      "For batch 26, vl_loss is    0.37.\n",
      "For batch 27, vl_loss is    0.37.\n",
      "For batch 28, vl_loss is    0.37.\n",
      "For batch 29, vl_loss is    0.37.\n",
      "For batch 30, vl_loss is    0.37.\n",
      "For batch 31, vl_loss is    0.37.\n",
      "For batch 32, vl_loss is    0.37.\n",
      "For batch 33, vl_loss is    0.37.\n",
      "For batch 34, vl_loss is    0.37.\n",
      "For batch 35, vl_loss is    0.36.\n",
      "For batch 36, vl_loss is    0.36.\n",
      "For batch 37, vl_loss is    0.37.\n",
      "For batch 38, vl_loss is    0.37.\n",
      "For batch 39, vl_loss is    0.37.\n",
      "For batch 40, vl_loss is    0.37.\n",
      "For batch 41, vl_loss is    0.37.\n",
      "For batch 42, vl_loss is    0.36.\n",
      "For batch 43, vl_loss is    0.36.\n",
      "For batch 44, vl_loss is    0.36.\n",
      "For batch 45, vl_loss is    0.36.\n",
      "For batch 46, vl_loss is    0.36.\n",
      "For batch 47, vl_loss is    0.36.\n",
      "For batch 48, vl_loss is    0.36.\n",
      "For batch 49, vl_loss is    0.36.\n",
      "For batch 50, vl_loss is    0.36.\n",
      "For batch 51, vl_loss is    0.36.\n",
      "For batch 52, vl_loss is    0.36.\n",
      "For batch 53, vl_loss is    0.36.\n",
      "For batch 54, vl_loss is    0.36.\n",
      "For batch 55, vl_loss is    0.36.\n",
      "244/244 [==============================] - 218s 888ms/step - loss: 0.2760 - iou_score: 0.7072 - f1-score: 0.8265 - val_loss: 0.3578 - val_iou_score: 0.6420 - val_f1-score: 0.7797\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.34998\n",
      "The average loss for epoch 7 is    0.28 \n",
      "Epoch 9/200\n",
      "  1/244 [..............................] - ETA: 10:31 - loss: 0.3340 - iou_score: 0.6398 - f1-score: 0.7795For batch 0, tr_loss is    0.33.\n",
      "  2/244 [..............................] - ETA: 6:01 - loss: 0.3077 - iou_score: 0.6858 - f1-score: 0.8121 For batch 1, tr_loss is    0.31.\n",
      "  3/244 [..............................] - ETA: 6:09 - loss: 0.3002 - iou_score: 0.6962 - f1-score: 0.8193For batch 2, tr_loss is    0.30.\n",
      "  4/244 [..............................] - ETA: 5:21 - loss: 0.3055 - iou_score: 0.6957 - f1-score: 0.8193For batch 3, tr_loss is    0.31.\n",
      "  5/244 [..............................] - ETA: 5:15 - loss: 0.3001 - iou_score: 0.6968 - f1-score: 0.8199For batch 4, tr_loss is    0.30.\n",
      "  6/244 [..............................] - ETA: 5:16 - loss: 0.3050 - iou_score: 0.6878 - f1-score: 0.8137For batch 5, tr_loss is    0.31.\n",
      "  7/244 [..............................] - ETA: 5:21 - loss: 0.2983 - iou_score: 0.6966 - f1-score: 0.8192For batch 6, tr_loss is    0.30.\n",
      "  8/244 [..............................] - ETA: 5:21 - loss: 0.3022 - iou_score: 0.6874 - f1-score: 0.8123For batch 7, tr_loss is    0.30.\n",
      "  9/244 [>.............................] - ETA: 5:11 - loss: 0.3043 - iou_score: 0.6848 - f1-score: 0.8105For batch 8, tr_loss is    0.30.\n",
      " 10/244 [>.............................] - ETA: 4:48 - loss: 0.2968 - iou_score: 0.6936 - f1-score: 0.8166For batch 9, tr_loss is    0.30.\n",
      " 11/244 [>.............................] - ETA: 4:45 - loss: 0.2935 - iou_score: 0.6978 - f1-score: 0.8196For batch 10, tr_loss is    0.29.\n",
      " 12/244 [>.............................] - ETA: 4:38 - loss: 0.2909 - iou_score: 0.7003 - f1-score: 0.8215For batch 11, tr_loss is    0.29.\n",
      " 13/244 [>.............................] - ETA: 4:24 - loss: 0.2878 - iou_score: 0.7044 - f1-score: 0.8244For batch 12, tr_loss is    0.29.\n",
      " 14/244 [>.............................] - ETA: 4:22 - loss: 0.2924 - iou_score: 0.7002 - f1-score: 0.8215For batch 13, tr_loss is    0.29.\n",
      " 15/244 [>.............................] - ETA: 4:20 - loss: 0.2939 - iou_score: 0.6970 - f1-score: 0.8194For batch 14, tr_loss is    0.29.\n",
      " 16/244 [>.............................] - ETA: 4:16 - loss: 0.2937 - iou_score: 0.6968 - f1-score: 0.8193For batch 15, tr_loss is    0.29.\n",
      " 17/244 [=>............................] - ETA: 4:10 - loss: 0.2893 - iou_score: 0.7024 - f1-score: 0.8231For batch 16, tr_loss is    0.29.\n",
      " 18/244 [=>............................] - ETA: 4:07 - loss: 0.2909 - iou_score: 0.7008 - f1-score: 0.8221For batch 17, tr_loss is    0.29.\n",
      " 19/244 [=>............................] - ETA: 4:05 - loss: 0.2883 - iou_score: 0.7044 - f1-score: 0.8246For batch 18, tr_loss is    0.29.\n",
      " 20/244 [=>............................] - ETA: 4:03 - loss: 0.2880 - iou_score: 0.7047 - f1-score: 0.8247For batch 19, tr_loss is    0.29.\n",
      " 21/244 [=>............................] - ETA: 4:01 - loss: 0.2877 - iou_score: 0.7038 - f1-score: 0.8241For batch 20, tr_loss is    0.29.\n",
      " 22/244 [=>............................] - ETA: 3:59 - loss: 0.2906 - iou_score: 0.7008 - f1-score: 0.8219For batch 21, tr_loss is    0.29.\n",
      " 23/244 [=>............................] - ETA: 3:52 - loss: 0.2913 - iou_score: 0.6988 - f1-score: 0.8206For batch 22, tr_loss is    0.29.\n",
      " 24/244 [=>............................] - ETA: 3:48 - loss: 0.2887 - iou_score: 0.7017 - f1-score: 0.8226For batch 23, tr_loss is    0.29.\n",
      " 25/244 [==>...........................] - ETA: 3:43 - loss: 0.2894 - iou_score: 0.7000 - f1-score: 0.8214For batch 24, tr_loss is    0.29.\n",
      " 26/244 [==>...........................] - ETA: 3:41 - loss: 0.2898 - iou_score: 0.6993 - f1-score: 0.8210For batch 25, tr_loss is    0.29.\n",
      " 27/244 [==>...........................] - ETA: 3:37 - loss: 0.2888 - iou_score: 0.7004 - f1-score: 0.8219For batch 26, tr_loss is    0.29.\n",
      " 28/244 [==>...........................] - ETA: 3:36 - loss: 0.2854 - iou_score: 0.7046 - f1-score: 0.8246For batch 27, tr_loss is    0.29.\n",
      " 29/244 [==>...........................] - ETA: 3:36 - loss: 0.2837 - iou_score: 0.7051 - f1-score: 0.8250For batch 28, tr_loss is    0.28.\n",
      " 30/244 [==>...........................] - ETA: 3:35 - loss: 0.2809 - iou_score: 0.7087 - f1-score: 0.8274For batch 29, tr_loss is    0.28.\n",
      " 31/244 [==>...........................] - ETA: 3:34 - loss: 0.2793 - iou_score: 0.7108 - f1-score: 0.8289For batch 30, tr_loss is    0.28.\n",
      " 32/244 [==>...........................] - ETA: 3:33 - loss: 0.2779 - iou_score: 0.7126 - f1-score: 0.8301For batch 31, tr_loss is    0.28.\n",
      " 33/244 [===>..........................] - ETA: 3:31 - loss: 0.2772 - iou_score: 0.7125 - f1-score: 0.8301For batch 32, tr_loss is    0.28.\n",
      " 34/244 [===>..........................] - ETA: 3:26 - loss: 0.2764 - iou_score: 0.7129 - f1-score: 0.8304For batch 33, tr_loss is    0.28.\n",
      " 35/244 [===>..........................] - ETA: 3:26 - loss: 0.2769 - iou_score: 0.7120 - f1-score: 0.8298For batch 34, tr_loss is    0.28.\n",
      " 36/244 [===>..........................] - ETA: 3:25 - loss: 0.2760 - iou_score: 0.7128 - f1-score: 0.8304For batch 35, tr_loss is    0.28.\n",
      " 37/244 [===>..........................] - ETA: 3:25 - loss: 0.2755 - iou_score: 0.7127 - f1-score: 0.8304For batch 36, tr_loss is    0.28.\n",
      " 38/244 [===>..........................] - ETA: 3:24 - loss: 0.2751 - iou_score: 0.7139 - f1-score: 0.8312For batch 37, tr_loss is    0.28.\n",
      " 39/244 [===>..........................] - ETA: 3:23 - loss: 0.2736 - iou_score: 0.7155 - f1-score: 0.8324For batch 38, tr_loss is    0.27.\n",
      " 40/244 [===>..........................] - ETA: 3:19 - loss: 0.2731 - iou_score: 0.7153 - f1-score: 0.8322For batch 39, tr_loss is    0.27.\n",
      " 41/244 [====>.........................] - ETA: 3:17 - loss: 0.2735 - iou_score: 0.7140 - f1-score: 0.8314For batch 40, tr_loss is    0.27.\n",
      " 42/244 [====>.........................] - ETA: 3:16 - loss: 0.2723 - iou_score: 0.7149 - f1-score: 0.8320For batch 41, tr_loss is    0.27.\n",
      " 43/244 [====>.........................] - ETA: 3:15 - loss: 0.2736 - iou_score: 0.7133 - f1-score: 0.8309For batch 42, tr_loss is    0.27.\n",
      " 44/244 [====>.........................] - ETA: 3:12 - loss: 0.2730 - iou_score: 0.7141 - f1-score: 0.8315For batch 43, tr_loss is    0.27.\n",
      " 45/244 [====>.........................] - ETA: 3:11 - loss: 0.2731 - iou_score: 0.7139 - f1-score: 0.8313For batch 44, tr_loss is    0.27.\n",
      " 46/244 [====>.........................] - ETA: 3:08 - loss: 0.2728 - iou_score: 0.7142 - f1-score: 0.8315For batch 45, tr_loss is    0.27.\n",
      " 47/244 [====>.........................] - ETA: 3:08 - loss: 0.2713 - iou_score: 0.7152 - f1-score: 0.8322For batch 46, tr_loss is    0.27.\n",
      " 48/244 [====>.........................] - ETA: 3:08 - loss: 0.2703 - iou_score: 0.7162 - f1-score: 0.8329For batch 47, tr_loss is    0.27.\n",
      " 49/244 [=====>........................] - ETA: 3:07 - loss: 0.2709 - iou_score: 0.7153 - f1-score: 0.8323For batch 48, tr_loss is    0.27.\n",
      " 50/244 [=====>........................] - ETA: 3:06 - loss: 0.2710 - iou_score: 0.7149 - f1-score: 0.8321For batch 49, tr_loss is    0.27.\n",
      " 51/244 [=====>........................] - ETA: 3:03 - loss: 0.2732 - iou_score: 0.7132 - f1-score: 0.8309For batch 50, tr_loss is    0.27.\n",
      " 52/244 [=====>........................] - ETA: 3:02 - loss: 0.2735 - iou_score: 0.7129 - f1-score: 0.8307For batch 51, tr_loss is    0.27.\n",
      " 53/244 [=====>........................] - ETA: 3:00 - loss: 0.2727 - iou_score: 0.7133 - f1-score: 0.8310For batch 52, tr_loss is    0.27.\n",
      " 54/244 [=====>........................] - ETA: 3:00 - loss: 0.2730 - iou_score: 0.7126 - f1-score: 0.8305For batch 53, tr_loss is    0.27.\n",
      " 55/244 [=====>........................] - ETA: 2:57 - loss: 0.2718 - iou_score: 0.7139 - f1-score: 0.8314For batch 54, tr_loss is    0.27.\n",
      " 56/244 [=====>........................] - ETA: 2:57 - loss: 0.2712 - iou_score: 0.7144 - f1-score: 0.8318For batch 55, tr_loss is    0.27.\n",
      " 57/244 [======>.......................] - ETA: 2:56 - loss: 0.2723 - iou_score: 0.7135 - f1-score: 0.8311For batch 56, tr_loss is    0.27.\n",
      " 58/244 [======>.......................] - ETA: 2:56 - loss: 0.2738 - iou_score: 0.7124 - f1-score: 0.8304For batch 57, tr_loss is    0.27.\n",
      " 59/244 [======>.......................] - ETA: 2:53 - loss: 0.2729 - iou_score: 0.7139 - f1-score: 0.8313For batch 58, tr_loss is    0.27.\n",
      " 60/244 [======>.......................] - ETA: 2:53 - loss: 0.2741 - iou_score: 0.7117 - f1-score: 0.8298For batch 59, tr_loss is    0.27.\n",
      " 61/244 [======>.......................] - ETA: 2:52 - loss: 0.2754 - iou_score: 0.7098 - f1-score: 0.8284For batch 60, tr_loss is    0.28.\n",
      " 62/244 [======>.......................] - ETA: 2:51 - loss: 0.2751 - iou_score: 0.7101 - f1-score: 0.8286For batch 61, tr_loss is    0.28.\n",
      " 63/244 [======>.......................] - ETA: 2:50 - loss: 0.2753 - iou_score: 0.7099 - f1-score: 0.8285For batch 62, tr_loss is    0.28.\n",
      " 64/244 [======>.......................] - ETA: 2:49 - loss: 0.2745 - iou_score: 0.7108 - f1-score: 0.8291For batch 63, tr_loss is    0.27.\n",
      " 65/244 [======>.......................] - ETA: 2:48 - loss: 0.2747 - iou_score: 0.7104 - f1-score: 0.8288For batch 64, tr_loss is    0.27.\n",
      " 66/244 [=======>......................] - ETA: 2:47 - loss: 0.2748 - iou_score: 0.7104 - f1-score: 0.8289For batch 65, tr_loss is    0.27.\n",
      " 67/244 [=======>......................] - ETA: 2:46 - loss: 0.2745 - iou_score: 0.7111 - f1-score: 0.8293For batch 66, tr_loss is    0.27.\n",
      " 68/244 [=======>......................] - ETA: 2:45 - loss: 0.2743 - iou_score: 0.7116 - f1-score: 0.8297For batch 67, tr_loss is    0.27.\n",
      " 69/244 [=======>......................] - ETA: 2:44 - loss: 0.2751 - iou_score: 0.7103 - f1-score: 0.8288For batch 68, tr_loss is    0.28.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70/244 [=======>......................] - ETA: 2:43 - loss: 0.2747 - iou_score: 0.7105 - f1-score: 0.8289For batch 69, tr_loss is    0.27.\n",
      " 71/244 [=======>......................] - ETA: 2:43 - loss: 0.2746 - iou_score: 0.7106 - f1-score: 0.8290For batch 70, tr_loss is    0.27.\n",
      " 72/244 [=======>......................] - ETA: 2:41 - loss: 0.2739 - iou_score: 0.7114 - f1-score: 0.8295For batch 71, tr_loss is    0.27.\n",
      " 73/244 [=======>......................] - ETA: 2:40 - loss: 0.2743 - iou_score: 0.7108 - f1-score: 0.8291For batch 72, tr_loss is    0.27.\n",
      " 74/244 [========>.....................] - ETA: 2:39 - loss: 0.2743 - iou_score: 0.7107 - f1-score: 0.8290For batch 73, tr_loss is    0.27.\n",
      " 75/244 [========>.....................] - ETA: 2:39 - loss: 0.2743 - iou_score: 0.7104 - f1-score: 0.8288For batch 74, tr_loss is    0.27.\n",
      " 76/244 [========>.....................] - ETA: 2:37 - loss: 0.2733 - iou_score: 0.7120 - f1-score: 0.8298For batch 75, tr_loss is    0.27.\n",
      " 77/244 [========>.....................] - ETA: 2:36 - loss: 0.2732 - iou_score: 0.7122 - f1-score: 0.8299For batch 76, tr_loss is    0.27.\n",
      " 78/244 [========>.....................] - ETA: 2:35 - loss: 0.2731 - iou_score: 0.7124 - f1-score: 0.8301For batch 77, tr_loss is    0.27.\n",
      " 79/244 [========>.....................] - ETA: 2:34 - loss: 0.2730 - iou_score: 0.7127 - f1-score: 0.8303For batch 78, tr_loss is    0.27.\n",
      " 80/244 [========>.....................] - ETA: 2:33 - loss: 0.2725 - iou_score: 0.7131 - f1-score: 0.8305For batch 79, tr_loss is    0.27.\n",
      " 81/244 [========>.....................] - ETA: 2:33 - loss: 0.2726 - iou_score: 0.7131 - f1-score: 0.8305For batch 80, tr_loss is    0.27.\n",
      " 82/244 [=========>....................] - ETA: 2:32 - loss: 0.2740 - iou_score: 0.7115 - f1-score: 0.8293For batch 81, tr_loss is    0.27.\n",
      " 83/244 [=========>....................] - ETA: 2:30 - loss: 0.2734 - iou_score: 0.7122 - f1-score: 0.8298For batch 82, tr_loss is    0.27.\n",
      " 84/244 [=========>....................] - ETA: 2:29 - loss: 0.2736 - iou_score: 0.7125 - f1-score: 0.8301For batch 83, tr_loss is    0.27.\n",
      " 85/244 [=========>....................] - ETA: 2:28 - loss: 0.2728 - iou_score: 0.7133 - f1-score: 0.8306For batch 84, tr_loss is    0.27.\n",
      " 86/244 [=========>....................] - ETA: 2:26 - loss: 0.2733 - iou_score: 0.7127 - f1-score: 0.8302For batch 85, tr_loss is    0.27.\n",
      " 87/244 [=========>....................] - ETA: 2:25 - loss: 0.2730 - iou_score: 0.7130 - f1-score: 0.8303For batch 86, tr_loss is    0.27.\n",
      " 88/244 [=========>....................] - ETA: 2:24 - loss: 0.2722 - iou_score: 0.7137 - f1-score: 0.8309For batch 87, tr_loss is    0.27.\n",
      " 89/244 [=========>....................] - ETA: 2:23 - loss: 0.2725 - iou_score: 0.7130 - f1-score: 0.8304For batch 88, tr_loss is    0.27.\n",
      " 90/244 [==========>...................] - ETA: 2:23 - loss: 0.2723 - iou_score: 0.7133 - f1-score: 0.8306For batch 89, tr_loss is    0.27.\n",
      " 91/244 [==========>...................] - ETA: 2:22 - loss: 0.2730 - iou_score: 0.7123 - f1-score: 0.8299For batch 90, tr_loss is    0.27.\n",
      " 92/244 [==========>...................] - ETA: 2:21 - loss: 0.2734 - iou_score: 0.7118 - f1-score: 0.8296For batch 91, tr_loss is    0.27.\n",
      " 93/244 [==========>...................] - ETA: 2:20 - loss: 0.2727 - iou_score: 0.7127 - f1-score: 0.8301For batch 92, tr_loss is    0.27.\n",
      " 94/244 [==========>...................] - ETA: 2:19 - loss: 0.2722 - iou_score: 0.7132 - f1-score: 0.8305For batch 93, tr_loss is    0.27.\n",
      " 95/244 [==========>...................] - ETA: 2:18 - loss: 0.2725 - iou_score: 0.7128 - f1-score: 0.8302For batch 94, tr_loss is    0.27.\n",
      " 96/244 [==========>...................] - ETA: 2:17 - loss: 0.2727 - iou_score: 0.7122 - f1-score: 0.8298For batch 95, tr_loss is    0.27.\n",
      " 97/244 [==========>...................] - ETA: 2:16 - loss: 0.2724 - iou_score: 0.7125 - f1-score: 0.8300For batch 96, tr_loss is    0.27.\n",
      " 98/244 [===========>..................] - ETA: 2:15 - loss: 0.2724 - iou_score: 0.7125 - f1-score: 0.8300For batch 97, tr_loss is    0.27.\n",
      " 99/244 [===========>..................] - ETA: 2:14 - loss: 0.2723 - iou_score: 0.7128 - f1-score: 0.8303For batch 98, tr_loss is    0.27.\n",
      "100/244 [===========>..................] - ETA: 2:12 - loss: 0.2714 - iou_score: 0.7140 - f1-score: 0.8310For batch 99, tr_loss is    0.27.\n",
      "101/244 [===========>..................] - ETA: 2:11 - loss: 0.2715 - iou_score: 0.7139 - f1-score: 0.8310For batch 100, tr_loss is    0.27.\n",
      "102/244 [===========>..................] - ETA: 2:11 - loss: 0.2713 - iou_score: 0.7140 - f1-score: 0.8310For batch 101, tr_loss is    0.27.\n",
      "103/244 [===========>..................] - ETA: 2:10 - loss: 0.2707 - iou_score: 0.7146 - f1-score: 0.8314For batch 102, tr_loss is    0.27.\n",
      "104/244 [===========>..................] - ETA: 2:09 - loss: 0.2703 - iou_score: 0.7151 - f1-score: 0.8318For batch 103, tr_loss is    0.27.\n",
      "105/244 [===========>..................] - ETA: 2:08 - loss: 0.2703 - iou_score: 0.7147 - f1-score: 0.8315For batch 104, tr_loss is    0.27.\n",
      "106/244 [============>.................] - ETA: 2:07 - loss: 0.2697 - iou_score: 0.7155 - f1-score: 0.8321For batch 105, tr_loss is    0.27.\n",
      "107/244 [============>.................] - ETA: 2:06 - loss: 0.2692 - iou_score: 0.7160 - f1-score: 0.8324For batch 106, tr_loss is    0.27.\n",
      "108/244 [============>.................] - ETA: 2:05 - loss: 0.2692 - iou_score: 0.7159 - f1-score: 0.8323For batch 107, tr_loss is    0.27.\n",
      "109/244 [============>.................] - ETA: 2:04 - loss: 0.2696 - iou_score: 0.7152 - f1-score: 0.8318For batch 108, tr_loss is    0.27.\n",
      "110/244 [============>.................] - ETA: 2:03 - loss: 0.2696 - iou_score: 0.7149 - f1-score: 0.8316For batch 109, tr_loss is    0.27.\n",
      "111/244 [============>.................] - ETA: 2:03 - loss: 0.2698 - iou_score: 0.7146 - f1-score: 0.8315For batch 110, tr_loss is    0.27.\n",
      "112/244 [============>.................] - ETA: 2:02 - loss: 0.2699 - iou_score: 0.7145 - f1-score: 0.8314For batch 111, tr_loss is    0.27.\n",
      "113/244 [============>.................] - ETA: 2:01 - loss: 0.2698 - iou_score: 0.7148 - f1-score: 0.8316For batch 112, tr_loss is    0.27.\n",
      "114/244 [=============>................] - ETA: 2:00 - loss: 0.2704 - iou_score: 0.7139 - f1-score: 0.8310For batch 113, tr_loss is    0.27.\n",
      "115/244 [=============>................] - ETA: 1:59 - loss: 0.2700 - iou_score: 0.7141 - f1-score: 0.8311For batch 114, tr_loss is    0.27.\n",
      "116/244 [=============>................] - ETA: 1:58 - loss: 0.2697 - iou_score: 0.7143 - f1-score: 0.8313For batch 115, tr_loss is    0.27.\n",
      "117/244 [=============>................] - ETA: 1:57 - loss: 0.2699 - iou_score: 0.7138 - f1-score: 0.8310For batch 116, tr_loss is    0.27.\n",
      "118/244 [=============>................] - ETA: 1:56 - loss: 0.2698 - iou_score: 0.7138 - f1-score: 0.8309For batch 117, tr_loss is    0.27.\n",
      "119/244 [=============>................] - ETA: 1:55 - loss: 0.2699 - iou_score: 0.7137 - f1-score: 0.8309For batch 118, tr_loss is    0.27.\n",
      "120/244 [=============>................] - ETA: 1:54 - loss: 0.2708 - iou_score: 0.7126 - f1-score: 0.8301For batch 119, tr_loss is    0.27.\n",
      "121/244 [=============>................] - ETA: 1:54 - loss: 0.2703 - iou_score: 0.7133 - f1-score: 0.8305For batch 120, tr_loss is    0.27.\n",
      "122/244 [==============>...............] - ETA: 1:53 - loss: 0.2700 - iou_score: 0.7136 - f1-score: 0.8308For batch 121, tr_loss is    0.27.\n",
      "123/244 [==============>...............] - ETA: 1:52 - loss: 0.2701 - iou_score: 0.7132 - f1-score: 0.8304For batch 122, tr_loss is    0.27.\n",
      "124/244 [==============>...............] - ETA: 1:51 - loss: 0.2707 - iou_score: 0.7124 - f1-score: 0.8299For batch 123, tr_loss is    0.27.\n",
      "125/244 [==============>...............] - ETA: 1:50 - loss: 0.2704 - iou_score: 0.7130 - f1-score: 0.8303For batch 124, tr_loss is    0.27.\n",
      "126/244 [==============>...............] - ETA: 1:49 - loss: 0.2702 - iou_score: 0.7131 - f1-score: 0.8304For batch 125, tr_loss is    0.27.\n",
      "127/244 [==============>...............] - ETA: 1:48 - loss: 0.2703 - iou_score: 0.7127 - f1-score: 0.8302For batch 126, tr_loss is    0.27.\n",
      "128/244 [==============>...............] - ETA: 1:47 - loss: 0.2700 - iou_score: 0.7131 - f1-score: 0.8304For batch 127, tr_loss is    0.27.\n",
      "129/244 [==============>...............] - ETA: 1:47 - loss: 0.2698 - iou_score: 0.7133 - f1-score: 0.8305For batch 128, tr_loss is    0.27.\n",
      "130/244 [==============>...............] - ETA: 1:46 - loss: 0.2701 - iou_score: 0.7130 - f1-score: 0.8303For batch 129, tr_loss is    0.27.\n",
      "131/244 [===============>..............] - ETA: 1:45 - loss: 0.2699 - iou_score: 0.7131 - f1-score: 0.8304For batch 130, tr_loss is    0.27.\n",
      "132/244 [===============>..............] - ETA: 1:44 - loss: 0.2703 - iou_score: 0.7124 - f1-score: 0.8299For batch 131, tr_loss is    0.27.\n",
      "133/244 [===============>..............] - ETA: 1:43 - loss: 0.2705 - iou_score: 0.7123 - f1-score: 0.8298For batch 132, tr_loss is    0.27.\n",
      "134/244 [===============>..............] - ETA: 1:42 - loss: 0.2712 - iou_score: 0.7114 - f1-score: 0.8292For batch 133, tr_loss is    0.27.\n",
      "135/244 [===============>..............] - ETA: 1:41 - loss: 0.2713 - iou_score: 0.7112 - f1-score: 0.8291For batch 134, tr_loss is    0.27.\n",
      "136/244 [===============>..............] - ETA: 1:40 - loss: 0.2709 - iou_score: 0.7116 - f1-score: 0.8294For batch 135, tr_loss is    0.27.\n",
      "137/244 [===============>..............] - ETA: 1:40 - loss: 0.2708 - iou_score: 0.7116 - f1-score: 0.8294For batch 136, tr_loss is    0.27.\n",
      "138/244 [===============>..............] - ETA: 1:39 - loss: 0.2710 - iou_score: 0.7113 - f1-score: 0.8292For batch 137, tr_loss is    0.27.\n",
      "139/244 [================>.............] - ETA: 1:38 - loss: 0.2712 - iou_score: 0.7111 - f1-score: 0.8291For batch 138, tr_loss is    0.27.\n",
      "140/244 [================>.............] - ETA: 1:37 - loss: 0.2713 - iou_score: 0.7111 - f1-score: 0.8291For batch 139, tr_loss is    0.27.\n",
      "141/244 [================>.............] - ETA: 1:35 - loss: 0.2715 - iou_score: 0.7109 - f1-score: 0.8289For batch 140, tr_loss is    0.27.\n",
      "142/244 [================>.............] - ETA: 1:35 - loss: 0.2716 - iou_score: 0.7104 - f1-score: 0.8286For batch 141, tr_loss is    0.27.\n",
      "143/244 [================>.............] - ETA: 1:33 - loss: 0.2713 - iou_score: 0.7110 - f1-score: 0.8289For batch 142, tr_loss is    0.27.\n",
      "144/244 [================>.............] - ETA: 1:33 - loss: 0.2717 - iou_score: 0.7105 - f1-score: 0.8286For batch 143, tr_loss is    0.27.\n",
      "145/244 [================>.............] - ETA: 1:32 - loss: 0.2719 - iou_score: 0.7102 - f1-score: 0.8284For batch 144, tr_loss is    0.27.\n",
      "146/244 [================>.............] - ETA: 1:31 - loss: 0.2719 - iou_score: 0.7099 - f1-score: 0.8282For batch 145, tr_loss is    0.27.\n",
      "147/244 [=================>............] - ETA: 1:30 - loss: 0.2717 - iou_score: 0.7101 - f1-score: 0.8283For batch 146, tr_loss is    0.27.\n",
      "148/244 [=================>............] - ETA: 1:29 - loss: 0.2719 - iou_score: 0.7098 - f1-score: 0.8281For batch 147, tr_loss is    0.27.\n",
      "149/244 [=================>............] - ETA: 1:28 - loss: 0.2722 - iou_score: 0.7095 - f1-score: 0.8279For batch 148, tr_loss is    0.27.\n",
      "150/244 [=================>............] - ETA: 1:27 - loss: 0.2721 - iou_score: 0.7096 - f1-score: 0.8280For batch 149, tr_loss is    0.27.\n",
      "151/244 [=================>............] - ETA: 1:26 - loss: 0.2722 - iou_score: 0.7096 - f1-score: 0.8281For batch 150, tr_loss is    0.27.\n",
      "152/244 [=================>............] - ETA: 1:25 - loss: 0.2725 - iou_score: 0.7094 - f1-score: 0.8279For batch 151, tr_loss is    0.27.\n",
      "153/244 [=================>............] - ETA: 1:24 - loss: 0.2726 - iou_score: 0.7096 - f1-score: 0.8281For batch 152, tr_loss is    0.27.\n",
      "154/244 [=================>............] - ETA: 1:24 - loss: 0.2726 - iou_score: 0.7097 - f1-score: 0.8281For batch 153, tr_loss is    0.27.\n",
      "155/244 [==================>...........] - ETA: 1:22 - loss: 0.2727 - iou_score: 0.7095 - f1-score: 0.8280For batch 154, tr_loss is    0.27.\n",
      "156/244 [==================>...........] - ETA: 1:21 - loss: 0.2724 - iou_score: 0.7099 - f1-score: 0.8283For batch 155, tr_loss is    0.27.\n",
      "157/244 [==================>...........] - ETA: 1:20 - loss: 0.2722 - iou_score: 0.7101 - f1-score: 0.8284For batch 156, tr_loss is    0.27.\n",
      "158/244 [==================>...........] - ETA: 1:19 - loss: 0.2723 - iou_score: 0.7099 - f1-score: 0.8283For batch 157, tr_loss is    0.27.\n",
      "159/244 [==================>...........] - ETA: 1:18 - loss: 0.2720 - iou_score: 0.7103 - f1-score: 0.8286For batch 158, tr_loss is    0.27.\n",
      "160/244 [==================>...........] - ETA: 1:17 - loss: 0.2718 - iou_score: 0.7105 - f1-score: 0.8287For batch 159, tr_loss is    0.27.\n",
      "161/244 [==================>...........] - ETA: 1:16 - loss: 0.2719 - iou_score: 0.7103 - f1-score: 0.8286For batch 160, tr_loss is    0.27.\n",
      "162/244 [==================>...........] - ETA: 1:15 - loss: 0.2717 - iou_score: 0.7106 - f1-score: 0.8288For batch 161, tr_loss is    0.27.\n",
      "163/244 [===================>..........] - ETA: 1:14 - loss: 0.2718 - iou_score: 0.7106 - f1-score: 0.8288For batch 162, tr_loss is    0.27.\n",
      "164/244 [===================>..........] - ETA: 1:14 - loss: 0.2716 - iou_score: 0.7109 - f1-score: 0.8290For batch 163, tr_loss is    0.27.\n",
      "165/244 [===================>..........] - ETA: 1:13 - loss: 0.2717 - iou_score: 0.7107 - f1-score: 0.8288For batch 164, tr_loss is    0.27.\n",
      "166/244 [===================>..........] - ETA: 1:12 - loss: 0.2718 - iou_score: 0.7105 - f1-score: 0.8287For batch 165, tr_loss is    0.27.\n",
      "167/244 [===================>..........] - ETA: 1:11 - loss: 0.2716 - iou_score: 0.7108 - f1-score: 0.8290For batch 166, tr_loss is    0.27.\n",
      "168/244 [===================>..........] - ETA: 1:10 - loss: 0.2712 - iou_score: 0.7111 - f1-score: 0.8291For batch 167, tr_loss is    0.27.\n",
      "169/244 [===================>..........] - ETA: 1:09 - loss: 0.2710 - iou_score: 0.7114 - f1-score: 0.8294For batch 168, tr_loss is    0.27.\n",
      "170/244 [===================>..........] - ETA: 1:08 - loss: 0.2713 - iou_score: 0.7110 - f1-score: 0.8291For batch 169, tr_loss is    0.27.\n",
      "171/244 [====================>.........] - ETA: 1:07 - loss: 0.2709 - iou_score: 0.7114 - f1-score: 0.8294For batch 170, tr_loss is    0.27.\n",
      "172/244 [====================>.........] - ETA: 1:06 - loss: 0.2710 - iou_score: 0.7113 - f1-score: 0.8293For batch 171, tr_loss is    0.27.\n",
      "173/244 [====================>.........] - ETA: 1:05 - loss: 0.2712 - iou_score: 0.7111 - f1-score: 0.8292For batch 172, tr_loss is    0.27.\n",
      "174/244 [====================>.........] - ETA: 1:04 - loss: 0.2715 - iou_score: 0.7107 - f1-score: 0.8289For batch 173, tr_loss is    0.27.\n",
      "175/244 [====================>.........] - ETA: 1:03 - loss: 0.2714 - iou_score: 0.7105 - f1-score: 0.8287For batch 174, tr_loss is    0.27.\n",
      "176/244 [====================>.........] - ETA: 1:02 - loss: 0.2714 - iou_score: 0.7105 - f1-score: 0.8287For batch 175, tr_loss is    0.27.\n",
      "177/244 [====================>.........] - ETA: 1:01 - loss: 0.2710 - iou_score: 0.7110 - f1-score: 0.8290For batch 176, tr_loss is    0.27.\n",
      "178/244 [====================>.........] - ETA: 1:00 - loss: 0.2713 - iou_score: 0.7106 - f1-score: 0.8288For batch 177, tr_loss is    0.27.\n",
      "179/244 [=====================>........] - ETA: 59s - loss: 0.2712 - iou_score: 0.7107 - f1-score: 0.8289 For batch 178, tr_loss is    0.27.\n",
      "180/244 [=====================>........] - ETA: 59s - loss: 0.2710 - iou_score: 0.7110 - f1-score: 0.8291For batch 179, tr_loss is    0.27.\n",
      "181/244 [=====================>........] - ETA: 58s - loss: 0.2707 - iou_score: 0.7113 - f1-score: 0.8293For batch 180, tr_loss is    0.27.\n",
      "182/244 [=====================>........] - ETA: 57s - loss: 0.2707 - iou_score: 0.7112 - f1-score: 0.8292For batch 181, tr_loss is    0.27.\n",
      "183/244 [=====================>........] - ETA: 56s - loss: 0.2710 - iou_score: 0.7111 - f1-score: 0.8291For batch 182, tr_loss is    0.27.\n",
      "184/244 [=====================>........] - ETA: 55s - loss: 0.2713 - iou_score: 0.7107 - f1-score: 0.8289For batch 183, tr_loss is    0.27.\n",
      "185/244 [=====================>........] - ETA: 54s - loss: 0.2716 - iou_score: 0.7105 - f1-score: 0.8288For batch 184, tr_loss is    0.27.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/244 [=====================>........] - ETA: 53s - loss: 0.2713 - iou_score: 0.7109 - f1-score: 0.8290For batch 185, tr_loss is    0.27.\n",
      "187/244 [=====================>........] - ETA: 52s - loss: 0.2717 - iou_score: 0.7105 - f1-score: 0.8287For batch 186, tr_loss is    0.27.\n",
      "188/244 [======================>.......] - ETA: 51s - loss: 0.2718 - iou_score: 0.7104 - f1-score: 0.8286For batch 187, tr_loss is    0.27.\n",
      "189/244 [======================>.......] - ETA: 50s - loss: 0.2716 - iou_score: 0.7106 - f1-score: 0.8288For batch 188, tr_loss is    0.27.\n",
      "190/244 [======================>.......] - ETA: 49s - loss: 0.2712 - iou_score: 0.7110 - f1-score: 0.8291For batch 189, tr_loss is    0.27.\n",
      "191/244 [======================>.......] - ETA: 48s - loss: 0.2709 - iou_score: 0.7114 - f1-score: 0.8293For batch 190, tr_loss is    0.27.\n",
      "192/244 [======================>.......] - ETA: 48s - loss: 0.2710 - iou_score: 0.7112 - f1-score: 0.8292For batch 191, tr_loss is    0.27.\n",
      "193/244 [======================>.......] - ETA: 47s - loss: 0.2710 - iou_score: 0.7111 - f1-score: 0.8291For batch 192, tr_loss is    0.27.\n",
      "194/244 [======================>.......] - ETA: 46s - loss: 0.2707 - iou_score: 0.7114 - f1-score: 0.8293For batch 193, tr_loss is    0.27.\n",
      "195/244 [======================>.......] - ETA: 45s - loss: 0.2709 - iou_score: 0.7113 - f1-score: 0.8293For batch 194, tr_loss is    0.27.\n",
      "196/244 [=======================>......] - ETA: 44s - loss: 0.2708 - iou_score: 0.7113 - f1-score: 0.8293For batch 195, tr_loss is    0.27.\n",
      "197/244 [=======================>......] - ETA: 43s - loss: 0.2710 - iou_score: 0.7110 - f1-score: 0.8291For batch 196, tr_loss is    0.27.\n",
      "198/244 [=======================>......] - ETA: 42s - loss: 0.2710 - iou_score: 0.7111 - f1-score: 0.8292For batch 197, tr_loss is    0.27.\n",
      "199/244 [=======================>......] - ETA: 41s - loss: 0.2706 - iou_score: 0.7117 - f1-score: 0.8296For batch 198, tr_loss is    0.27.\n",
      "200/244 [=======================>......] - ETA: 40s - loss: 0.2705 - iou_score: 0.7118 - f1-score: 0.8296For batch 199, tr_loss is    0.27.\n",
      "201/244 [=======================>......] - ETA: 39s - loss: 0.2707 - iou_score: 0.7116 - f1-score: 0.8295For batch 200, tr_loss is    0.27.\n",
      "202/244 [=======================>......] - ETA: 38s - loss: 0.2707 - iou_score: 0.7116 - f1-score: 0.8295For batch 201, tr_loss is    0.27.\n",
      "203/244 [=======================>......] - ETA: 37s - loss: 0.2705 - iou_score: 0.7117 - f1-score: 0.8296For batch 202, tr_loss is    0.27.\n",
      "204/244 [========================>.....] - ETA: 36s - loss: 0.2702 - iou_score: 0.7121 - f1-score: 0.8298For batch 203, tr_loss is    0.27.\n",
      "205/244 [========================>.....] - ETA: 35s - loss: 0.2699 - iou_score: 0.7124 - f1-score: 0.8300For batch 204, tr_loss is    0.27.\n",
      "206/244 [========================>.....] - ETA: 35s - loss: 0.2702 - iou_score: 0.7121 - f1-score: 0.8298For batch 205, tr_loss is    0.27.\n",
      "207/244 [========================>.....] - ETA: 34s - loss: 0.2699 - iou_score: 0.7123 - f1-score: 0.8300For batch 206, tr_loss is    0.27.\n",
      "208/244 [========================>.....] - ETA: 33s - loss: 0.2700 - iou_score: 0.7121 - f1-score: 0.8298For batch 207, tr_loss is    0.27.\n",
      "209/244 [========================>.....] - ETA: 32s - loss: 0.2699 - iou_score: 0.7121 - f1-score: 0.8299For batch 208, tr_loss is    0.27.\n",
      "210/244 [========================>.....] - ETA: 31s - loss: 0.2696 - iou_score: 0.7125 - f1-score: 0.8301For batch 209, tr_loss is    0.27.\n",
      "211/244 [========================>.....] - ETA: 30s - loss: 0.2695 - iou_score: 0.7125 - f1-score: 0.8301For batch 210, tr_loss is    0.27.\n",
      "212/244 [=========================>....] - ETA: 29s - loss: 0.2696 - iou_score: 0.7123 - f1-score: 0.8300For batch 211, tr_loss is    0.27.\n",
      "213/244 [=========================>....] - ETA: 28s - loss: 0.2697 - iou_score: 0.7122 - f1-score: 0.8299For batch 212, tr_loss is    0.27.\n",
      "214/244 [=========================>....] - ETA: 27s - loss: 0.2694 - iou_score: 0.7126 - f1-score: 0.8302For batch 213, tr_loss is    0.27.\n",
      "215/244 [=========================>....] - ETA: 26s - loss: 0.2692 - iou_score: 0.7129 - f1-score: 0.8304For batch 214, tr_loss is    0.27.\n",
      "216/244 [=========================>....] - ETA: 25s - loss: 0.2692 - iou_score: 0.7129 - f1-score: 0.8304For batch 215, tr_loss is    0.27.\n",
      "217/244 [=========================>....] - ETA: 24s - loss: 0.2692 - iou_score: 0.7130 - f1-score: 0.8305For batch 216, tr_loss is    0.27.\n",
      "218/244 [=========================>....] - ETA: 23s - loss: 0.2690 - iou_score: 0.7131 - f1-score: 0.8305For batch 217, tr_loss is    0.27.\n",
      "219/244 [=========================>....] - ETA: 23s - loss: 0.2690 - iou_score: 0.7131 - f1-score: 0.8305For batch 218, tr_loss is    0.27.\n",
      "220/244 [==========================>...] - ETA: 22s - loss: 0.2690 - iou_score: 0.7130 - f1-score: 0.8305For batch 219, tr_loss is    0.27.\n",
      "221/244 [==========================>...] - ETA: 21s - loss: 0.2691 - iou_score: 0.7130 - f1-score: 0.8305For batch 220, tr_loss is    0.27.\n",
      "222/244 [==========================>...] - ETA: 20s - loss: 0.2687 - iou_score: 0.7134 - f1-score: 0.8307For batch 221, tr_loss is    0.27.\n",
      "223/244 [==========================>...] - ETA: 19s - loss: 0.2686 - iou_score: 0.7135 - f1-score: 0.8308For batch 222, tr_loss is    0.27.\n",
      "224/244 [==========================>...] - ETA: 18s - loss: 0.2686 - iou_score: 0.7134 - f1-score: 0.8308For batch 223, tr_loss is    0.27.\n",
      "225/244 [==========================>...] - ETA: 17s - loss: 0.2686 - iou_score: 0.7135 - f1-score: 0.8308For batch 224, tr_loss is    0.27.\n",
      "226/244 [==========================>...] - ETA: 16s - loss: 0.2684 - iou_score: 0.7137 - f1-score: 0.8310For batch 225, tr_loss is    0.27.\n",
      "227/244 [==========================>...] - ETA: 15s - loss: 0.2682 - iou_score: 0.7139 - f1-score: 0.8311For batch 226, tr_loss is    0.27.\n",
      "228/244 [===========================>..] - ETA: 14s - loss: 0.2680 - iou_score: 0.7141 - f1-score: 0.8313For batch 227, tr_loss is    0.27.\n",
      "229/244 [===========================>..] - ETA: 13s - loss: 0.2677 - iou_score: 0.7144 - f1-score: 0.8315For batch 228, tr_loss is    0.27.\n",
      "230/244 [===========================>..] - ETA: 12s - loss: 0.2676 - iou_score: 0.7145 - f1-score: 0.8315For batch 229, tr_loss is    0.27.\n",
      "231/244 [===========================>..] - ETA: 11s - loss: 0.2675 - iou_score: 0.7147 - f1-score: 0.8317For batch 230, tr_loss is    0.27.\n",
      "232/244 [===========================>..] - ETA: 10s - loss: 0.2676 - iou_score: 0.7146 - f1-score: 0.8316For batch 231, tr_loss is    0.27.\n",
      "233/244 [===========================>..] - ETA: 10s - loss: 0.2684 - iou_score: 0.7141 - f1-score: 0.8312For batch 232, tr_loss is    0.27.\n",
      "234/244 [===========================>..] - ETA: 9s - loss: 0.2684 - iou_score: 0.7140 - f1-score: 0.8312 For batch 233, tr_loss is    0.27.\n",
      "235/244 [===========================>..] - ETA: 8s - loss: 0.2682 - iou_score: 0.7143 - f1-score: 0.8313For batch 234, tr_loss is    0.27.\n",
      "236/244 [============================>.] - ETA: 7s - loss: 0.2683 - iou_score: 0.7142 - f1-score: 0.8313For batch 235, tr_loss is    0.27.\n",
      "237/244 [============================>.] - ETA: 6s - loss: 0.2683 - iou_score: 0.7142 - f1-score: 0.8313For batch 236, tr_loss is    0.27.\n",
      "238/244 [============================>.] - ETA: 5s - loss: 0.2681 - iou_score: 0.7145 - f1-score: 0.8315For batch 237, tr_loss is    0.27.\n",
      "239/244 [============================>.] - ETA: 4s - loss: 0.2681 - iou_score: 0.7145 - f1-score: 0.8315For batch 238, tr_loss is    0.27.\n",
      "240/244 [============================>.] - ETA: 3s - loss: 0.2678 - iou_score: 0.7149 - f1-score: 0.8317For batch 239, tr_loss is    0.27.\n",
      "241/244 [============================>.] - ETA: 2s - loss: 0.2679 - iou_score: 0.7149 - f1-score: 0.8317For batch 240, tr_loss is    0.27.\n",
      "242/244 [============================>.] - ETA: 1s - loss: 0.2682 - iou_score: 0.7145 - f1-score: 0.8315For batch 241, tr_loss is    0.27.\n",
      "243/244 [============================>.] - ETA: 0s - loss: 0.2685 - iou_score: 0.7141 - f1-score: 0.8312For batch 242, tr_loss is    0.27.\n",
      "244/244 [==============================] - ETA: 0s - loss: 0.2685 - iou_score: 0.7140 - f1-score: 0.8312For batch 243, tr_loss is    0.27.\n",
      "For batch 0, vl_loss is    0.38.\n",
      "For batch 1, vl_loss is    0.35.\n",
      "For batch 2, vl_loss is    0.33.\n",
      "For batch 3, vl_loss is    0.37.\n",
      "For batch 4, vl_loss is    0.35.\n",
      "For batch 5, vl_loss is    0.36.\n",
      "For batch 6, vl_loss is    0.37.\n",
      "For batch 7, vl_loss is    0.37.\n",
      "For batch 8, vl_loss is    0.37.\n",
      "For batch 9, vl_loss is    0.37.\n",
      "For batch 10, vl_loss is    0.38.\n",
      "For batch 11, vl_loss is    0.39.\n",
      "For batch 12, vl_loss is    0.38.\n",
      "For batch 13, vl_loss is    0.38.\n",
      "For batch 14, vl_loss is    0.39.\n",
      "For batch 15, vl_loss is    0.39.\n",
      "For batch 16, vl_loss is    0.38.\n",
      "For batch 17, vl_loss is    0.38.\n",
      "For batch 18, vl_loss is    0.38.\n",
      "For batch 19, vl_loss is    0.38.\n",
      "For batch 20, vl_loss is    0.38.\n",
      "For batch 21, vl_loss is    0.38.\n",
      "For batch 22, vl_loss is    0.38.\n",
      "For batch 23, vl_loss is    0.38.\n",
      "For batch 24, vl_loss is    0.38.\n",
      "For batch 25, vl_loss is    0.39.\n",
      "For batch 26, vl_loss is    0.39.\n",
      "For batch 27, vl_loss is    0.39.\n",
      "For batch 28, vl_loss is    0.39.\n",
      "For batch 29, vl_loss is    0.39.\n",
      "For batch 30, vl_loss is    0.39.\n",
      "For batch 31, vl_loss is    0.39.\n",
      "For batch 32, vl_loss is    0.39.\n",
      "For batch 33, vl_loss is    0.39.\n",
      "For batch 34, vl_loss is    0.39.\n",
      "For batch 35, vl_loss is    0.39.\n",
      "For batch 36, vl_loss is    0.39.\n",
      "For batch 37, vl_loss is    0.39.\n",
      "For batch 38, vl_loss is    0.39.\n",
      "For batch 39, vl_loss is    0.39.\n",
      "For batch 40, vl_loss is    0.39.\n",
      "For batch 41, vl_loss is    0.39.\n",
      "For batch 42, vl_loss is    0.39.\n",
      "For batch 43, vl_loss is    0.39.\n",
      "For batch 44, vl_loss is    0.39.\n",
      "For batch 45, vl_loss is    0.39.\n",
      "For batch 46, vl_loss is    0.39.\n",
      "For batch 47, vl_loss is    0.38.\n",
      "For batch 48, vl_loss is    0.38.\n",
      "For batch 49, vl_loss is    0.38.\n",
      "For batch 50, vl_loss is    0.38.\n",
      "For batch 51, vl_loss is    0.38.\n",
      "For batch 52, vl_loss is    0.38.\n",
      "For batch 53, vl_loss is    0.38.\n",
      "For batch 54, vl_loss is    0.38.\n",
      "For batch 55, vl_loss is    0.38.\n",
      "244/244 [==============================] - 225s 914ms/step - loss: 0.2685 - iou_score: 0.7140 - f1-score: 0.8312 - val_loss: 0.3828 - val_iou_score: 0.6161 - val_f1-score: 0.7601\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.34998\n",
      "The average loss for epoch 8 is    0.27 \n",
      "Epoch 10/200\n",
      "  1/244 [..............................] - ETA: 9:55 - loss: 0.2620 - iou_score: 0.6971 - f1-score: 0.8199For batch 0, tr_loss is    0.26.\n",
      "  2/244 [..............................] - ETA: 6:01 - loss: 0.2637 - iou_score: 0.7188 - f1-score: 0.8352For batch 1, tr_loss is    0.26.\n",
      "  3/244 [..............................] - ETA: 6:14 - loss: 0.2604 - iou_score: 0.7246 - f1-score: 0.8395For batch 2, tr_loss is    0.26.\n",
      "  4/244 [..............................] - ETA: 6:06 - loss: 0.2686 - iou_score: 0.7269 - f1-score: 0.8412For batch 3, tr_loss is    0.27.\n",
      "  5/244 [..............................] - ETA: 5:31 - loss: 0.2721 - iou_score: 0.7219 - f1-score: 0.8378For batch 4, tr_loss is    0.27.\n",
      "  6/244 [..............................] - ETA: 5:13 - loss: 0.2773 - iou_score: 0.7140 - f1-score: 0.8324For batch 5, tr_loss is    0.28.\n",
      "  7/244 [..............................] - ETA: 5:19 - loss: 0.2757 - iou_score: 0.7166 - f1-score: 0.8334For batch 6, tr_loss is    0.28.\n",
      "  8/244 [..............................] - ETA: 5:38 - loss: 0.2820 - iou_score: 0.7047 - f1-score: 0.8247For batch 7, tr_loss is    0.28.\n",
      "  9/244 [>.............................] - ETA: 5:11 - loss: 0.2848 - iou_score: 0.7015 - f1-score: 0.8224For batch 8, tr_loss is    0.28.\n",
      " 10/244 [>.............................] - ETA: 4:54 - loss: 0.2788 - iou_score: 0.7084 - f1-score: 0.8272For batch 9, tr_loss is    0.28.\n",
      " 11/244 [>.............................] - ETA: 4:48 - loss: 0.2754 - iou_score: 0.7121 - f1-score: 0.8297For batch 10, tr_loss is    0.28.\n",
      " 12/244 [>.............................] - ETA: 4:30 - loss: 0.2743 - iou_score: 0.7137 - f1-score: 0.8310For batch 11, tr_loss is    0.27.\n",
      " 13/244 [>.............................] - ETA: 4:25 - loss: 0.2705 - iou_score: 0.7177 - f1-score: 0.8338For batch 12, tr_loss is    0.27.\n",
      " 14/244 [>.............................] - ETA: 4:22 - loss: 0.2754 - iou_score: 0.7129 - f1-score: 0.8305For batch 13, tr_loss is    0.28.\n",
      " 15/244 [>.............................] - ETA: 4:19 - loss: 0.2777 - iou_score: 0.7099 - f1-score: 0.8285For batch 14, tr_loss is    0.28.\n",
      " 16/244 [>.............................] - ETA: 4:17 - loss: 0.2794 - iou_score: 0.7088 - f1-score: 0.8278For batch 15, tr_loss is    0.28.\n",
      " 17/244 [=>............................] - ETA: 4:10 - loss: 0.2757 - iou_score: 0.7143 - f1-score: 0.8315For batch 16, tr_loss is    0.28.\n",
      " 18/244 [=>............................] - ETA: 4:09 - loss: 0.2766 - iou_score: 0.7132 - f1-score: 0.8308For batch 17, tr_loss is    0.28.\n",
      " 19/244 [=>............................] - ETA: 4:06 - loss: 0.2746 - iou_score: 0.7160 - f1-score: 0.8327For batch 18, tr_loss is    0.27.\n",
      " 20/244 [=>............................] - ETA: 3:59 - loss: 0.2749 - iou_score: 0.7151 - f1-score: 0.8320For batch 19, tr_loss is    0.27.\n",
      " 21/244 [=>............................] - ETA: 3:57 - loss: 0.2752 - iou_score: 0.7138 - f1-score: 0.8311For batch 20, tr_loss is    0.28.\n",
      " 22/244 [=>............................] - ETA: 3:55 - loss: 0.2789 - iou_score: 0.7101 - f1-score: 0.8285For batch 21, tr_loss is    0.28.\n",
      " 23/244 [=>............................] - ETA: 3:55 - loss: 0.2793 - iou_score: 0.7085 - f1-score: 0.8275For batch 22, tr_loss is    0.28.\n",
      " 24/244 [=>............................] - ETA: 3:50 - loss: 0.2774 - iou_score: 0.7104 - f1-score: 0.8288For batch 23, tr_loss is    0.28.\n",
      " 25/244 [==>...........................] - ETA: 3:45 - loss: 0.2790 - iou_score: 0.7078 - f1-score: 0.8270For batch 24, tr_loss is    0.28.\n",
      " 26/244 [==>...........................] - ETA: 3:44 - loss: 0.2792 - iou_score: 0.7069 - f1-score: 0.8264For batch 25, tr_loss is    0.28.\n",
      " 27/244 [==>...........................] - ETA: 3:39 - loss: 0.2780 - iou_score: 0.7083 - f1-score: 0.8274For batch 26, tr_loss is    0.28.\n",
      " 28/244 [==>...........................] - ETA: 3:36 - loss: 0.2750 - iou_score: 0.7127 - f1-score: 0.8303For batch 27, tr_loss is    0.28.\n",
      " 29/244 [==>...........................] - ETA: 3:33 - loss: 0.2733 - iou_score: 0.7141 - f1-score: 0.8312For batch 28, tr_loss is    0.27.\n",
      " 30/244 [==>...........................] - ETA: 3:33 - loss: 0.2712 - iou_score: 0.7168 - f1-score: 0.8330For batch 29, tr_loss is    0.27.\n",
      " 31/244 [==>...........................] - ETA: 3:29 - loss: 0.2693 - iou_score: 0.7192 - f1-score: 0.8347For batch 30, tr_loss is    0.27.\n",
      " 32/244 [==>...........................] - ETA: 3:28 - loss: 0.2677 - iou_score: 0.7212 - f1-score: 0.8360For batch 31, tr_loss is    0.27.\n",
      " 33/244 [===>..........................] - ETA: 3:27 - loss: 0.2670 - iou_score: 0.7212 - f1-score: 0.8361For batch 32, tr_loss is    0.27.\n",
      " 34/244 [===>..........................] - ETA: 3:27 - loss: 0.2666 - iou_score: 0.7213 - f1-score: 0.8362For batch 33, tr_loss is    0.27.\n",
      " 35/244 [===>..........................] - ETA: 3:23 - loss: 0.2681 - iou_score: 0.7201 - f1-score: 0.8354For batch 34, tr_loss is    0.27.\n",
      " 36/244 [===>..........................] - ETA: 3:23 - loss: 0.2672 - iou_score: 0.7209 - f1-score: 0.8360For batch 35, tr_loss is    0.27.\n",
      " 37/244 [===>..........................] - ETA: 3:23 - loss: 0.2678 - iou_score: 0.7198 - f1-score: 0.8353For batch 36, tr_loss is    0.27.\n",
      " 38/244 [===>..........................] - ETA: 3:22 - loss: 0.2665 - iou_score: 0.7214 - f1-score: 0.8363For batch 37, tr_loss is    0.27.\n",
      " 39/244 [===>..........................] - ETA: 3:20 - loss: 0.2648 - iou_score: 0.7236 - f1-score: 0.8377For batch 38, tr_loss is    0.26.\n",
      " 40/244 [===>..........................] - ETA: 3:16 - loss: 0.2652 - iou_score: 0.7227 - f1-score: 0.8372For batch 39, tr_loss is    0.27.\n",
      " 41/244 [====>.........................] - ETA: 3:17 - loss: 0.2658 - iou_score: 0.7214 - f1-score: 0.8363For batch 40, tr_loss is    0.27.\n",
      " 42/244 [====>.........................] - ETA: 3:16 - loss: 0.2650 - iou_score: 0.7220 - f1-score: 0.8367For batch 41, tr_loss is    0.26.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 43/244 [====>.........................] - ETA: 3:13 - loss: 0.2661 - iou_score: 0.7206 - f1-score: 0.8358For batch 42, tr_loss is    0.27.\n",
      " 44/244 [====>.........................] - ETA: 3:12 - loss: 0.2654 - iou_score: 0.7216 - f1-score: 0.8365For batch 43, tr_loss is    0.27.\n",
      " 45/244 [====>.........................] - ETA: 3:09 - loss: 0.2660 - iou_score: 0.7212 - f1-score: 0.8362For batch 44, tr_loss is    0.27.\n",
      " 46/244 [====>.........................] - ETA: 3:09 - loss: 0.2657 - iou_score: 0.7213 - f1-score: 0.8363For batch 45, tr_loss is    0.27.\n",
      " 47/244 [====>.........................] - ETA: 3:07 - loss: 0.2649 - iou_score: 0.7218 - f1-score: 0.8366For batch 46, tr_loss is    0.26.\n",
      " 48/244 [====>.........................] - ETA: 3:06 - loss: 0.2641 - iou_score: 0.7224 - f1-score: 0.8370For batch 47, tr_loss is    0.26.\n",
      " 49/244 [=====>........................] - ETA: 3:04 - loss: 0.2650 - iou_score: 0.7213 - f1-score: 0.8364For batch 48, tr_loss is    0.27.\n",
      " 50/244 [=====>........................] - ETA: 3:03 - loss: 0.2650 - iou_score: 0.7211 - f1-score: 0.8362For batch 49, tr_loss is    0.27.\n",
      " 51/244 [=====>........................] - ETA: 3:03 - loss: 0.2665 - iou_score: 0.7197 - f1-score: 0.8353For batch 50, tr_loss is    0.27.\n",
      " 52/244 [=====>........................] - ETA: 3:01 - loss: 0.2665 - iou_score: 0.7196 - f1-score: 0.8353For batch 51, tr_loss is    0.27.\n",
      " 53/244 [=====>........................] - ETA: 3:00 - loss: 0.2664 - iou_score: 0.7195 - f1-score: 0.8351For batch 52, tr_loss is    0.27.\n",
      " 54/244 [=====>........................] - ETA: 2:58 - loss: 0.2671 - iou_score: 0.7189 - f1-score: 0.8348For batch 53, tr_loss is    0.27.\n",
      " 55/244 [=====>........................] - ETA: 2:56 - loss: 0.2658 - iou_score: 0.7205 - f1-score: 0.8358For batch 54, tr_loss is    0.27.\n",
      " 56/244 [=====>........................] - ETA: 2:54 - loss: 0.2650 - iou_score: 0.7212 - f1-score: 0.8363For batch 55, tr_loss is    0.27.\n",
      " 57/244 [======>.......................] - ETA: 2:52 - loss: 0.2659 - iou_score: 0.7205 - f1-score: 0.8358For batch 56, tr_loss is    0.27.\n",
      " 58/244 [======>.......................] - ETA: 2:51 - loss: 0.2663 - iou_score: 0.7195 - f1-score: 0.8352For batch 57, tr_loss is    0.27.\n",
      " 59/244 [======>.......................] - ETA: 2:50 - loss: 0.2650 - iou_score: 0.7219 - f1-score: 0.8367For batch 58, tr_loss is    0.26.\n",
      " 60/244 [======>.......................] - ETA: 2:48 - loss: 0.2666 - iou_score: 0.7195 - f1-score: 0.8350For batch 59, tr_loss is    0.27.\n",
      " 61/244 [======>.......................] - ETA: 2:47 - loss: 0.2675 - iou_score: 0.7177 - f1-score: 0.8337For batch 60, tr_loss is    0.27.\n",
      " 62/244 [======>.......................] - ETA: 2:47 - loss: 0.2673 - iou_score: 0.7177 - f1-score: 0.8337For batch 61, tr_loss is    0.27.\n",
      " 63/244 [======>.......................] - ETA: 2:46 - loss: 0.2673 - iou_score: 0.7176 - f1-score: 0.8337For batch 62, tr_loss is    0.27.\n",
      " 64/244 [======>.......................] - ETA: 2:44 - loss: 0.2666 - iou_score: 0.7186 - f1-score: 0.8344For batch 63, tr_loss is    0.27.\n",
      " 65/244 [======>.......................] - ETA: 2:44 - loss: 0.2665 - iou_score: 0.7185 - f1-score: 0.8343For batch 64, tr_loss is    0.27.\n",
      " 66/244 [=======>......................] - ETA: 2:43 - loss: 0.2663 - iou_score: 0.7188 - f1-score: 0.8345For batch 65, tr_loss is    0.27.\n",
      " 67/244 [=======>......................] - ETA: 2:42 - loss: 0.2660 - iou_score: 0.7192 - f1-score: 0.8348For batch 66, tr_loss is    0.27.\n",
      " 68/244 [=======>......................] - ETA: 2:41 - loss: 0.2659 - iou_score: 0.7196 - f1-score: 0.8350For batch 67, tr_loss is    0.27.\n",
      " 69/244 [=======>......................] - ETA: 2:40 - loss: 0.2664 - iou_score: 0.7186 - f1-score: 0.8344For batch 68, tr_loss is    0.27.\n",
      " 70/244 [=======>......................] - ETA: 2:39 - loss: 0.2661 - iou_score: 0.7187 - f1-score: 0.8345For batch 69, tr_loss is    0.27.\n",
      " 71/244 [=======>......................] - ETA: 2:38 - loss: 0.2663 - iou_score: 0.7185 - f1-score: 0.8343For batch 70, tr_loss is    0.27.\n",
      " 72/244 [=======>......................] - ETA: 2:37 - loss: 0.2656 - iou_score: 0.7192 - f1-score: 0.8347For batch 71, tr_loss is    0.27.\n",
      " 73/244 [=======>......................] - ETA: 2:35 - loss: 0.2659 - iou_score: 0.7186 - f1-score: 0.8344For batch 72, tr_loss is    0.27.\n",
      " 74/244 [========>.....................] - ETA: 2:34 - loss: 0.2666 - iou_score: 0.7179 - f1-score: 0.8339For batch 73, tr_loss is    0.27.\n",
      " 75/244 [========>.....................] - ETA: 2:34 - loss: 0.2666 - iou_score: 0.7177 - f1-score: 0.8337For batch 74, tr_loss is    0.27.\n",
      " 76/244 [========>.....................] - ETA: 2:32 - loss: 0.2657 - iou_score: 0.7190 - f1-score: 0.8346For batch 75, tr_loss is    0.27.\n",
      " 77/244 [========>.....................] - ETA: 2:32 - loss: 0.2656 - iou_score: 0.7190 - f1-score: 0.8346For batch 76, tr_loss is    0.27.\n",
      " 78/244 [========>.....................] - ETA: 2:31 - loss: 0.2654 - iou_score: 0.7194 - f1-score: 0.8349For batch 77, tr_loss is    0.27.\n",
      " 79/244 [========>.....................] - ETA: 2:31 - loss: 0.2652 - iou_score: 0.7197 - f1-score: 0.8350For batch 78, tr_loss is    0.27.\n",
      " 80/244 [========>.....................] - ETA: 2:30 - loss: 0.2648 - iou_score: 0.7201 - f1-score: 0.8353For batch 79, tr_loss is    0.26.\n",
      " 81/244 [========>.....................] - ETA: 2:28 - loss: 0.2649 - iou_score: 0.7202 - f1-score: 0.8353For batch 80, tr_loss is    0.26.\n",
      " 82/244 [=========>....................] - ETA: 2:27 - loss: 0.2663 - iou_score: 0.7185 - f1-score: 0.8341For batch 81, tr_loss is    0.27.\n",
      " 83/244 [=========>....................] - ETA: 2:26 - loss: 0.2657 - iou_score: 0.7191 - f1-score: 0.8345For batch 82, tr_loss is    0.27.\n",
      " 84/244 [=========>....................] - ETA: 2:25 - loss: 0.2652 - iou_score: 0.7196 - f1-score: 0.8348For batch 83, tr_loss is    0.27.\n",
      " 85/244 [=========>....................] - ETA: 2:24 - loss: 0.2645 - iou_score: 0.7203 - f1-score: 0.8354For batch 84, tr_loss is    0.26.\n",
      " 86/244 [=========>....................] - ETA: 2:23 - loss: 0.2651 - iou_score: 0.7197 - f1-score: 0.8349For batch 85, tr_loss is    0.27.\n",
      " 87/244 [=========>....................] - ETA: 2:21 - loss: 0.2649 - iou_score: 0.7199 - f1-score: 0.8351For batch 86, tr_loss is    0.26.\n",
      " 88/244 [=========>....................] - ETA: 2:21 - loss: 0.2644 - iou_score: 0.7205 - f1-score: 0.8355For batch 87, tr_loss is    0.26.\n",
      " 89/244 [=========>....................] - ETA: 2:20 - loss: 0.2648 - iou_score: 0.7198 - f1-score: 0.8350For batch 88, tr_loss is    0.26.\n",
      " 90/244 [==========>...................] - ETA: 2:19 - loss: 0.2648 - iou_score: 0.7199 - f1-score: 0.8350For batch 89, tr_loss is    0.26.\n",
      " 91/244 [==========>...................] - ETA: 2:18 - loss: 0.2657 - iou_score: 0.7186 - f1-score: 0.8341For batch 90, tr_loss is    0.27.\n",
      " 92/244 [==========>...................] - ETA: 2:16 - loss: 0.2663 - iou_score: 0.7177 - f1-score: 0.8335For batch 91, tr_loss is    0.27.\n",
      " 93/244 [==========>...................] - ETA: 2:15 - loss: 0.2658 - iou_score: 0.7185 - f1-score: 0.8340For batch 92, tr_loss is    0.27.\n",
      " 94/244 [==========>...................] - ETA: 2:14 - loss: 0.2656 - iou_score: 0.7188 - f1-score: 0.8342For batch 93, tr_loss is    0.27.\n",
      " 95/244 [==========>...................] - ETA: 2:14 - loss: 0.2657 - iou_score: 0.7184 - f1-score: 0.8340For batch 94, tr_loss is    0.27.\n",
      " 96/244 [==========>...................] - ETA: 2:13 - loss: 0.2658 - iou_score: 0.7179 - f1-score: 0.8336For batch 95, tr_loss is    0.27.\n",
      " 97/244 [==========>...................] - ETA: 2:11 - loss: 0.2657 - iou_score: 0.7182 - f1-score: 0.8338For batch 96, tr_loss is    0.27.\n",
      " 98/244 [===========>..................] - ETA: 2:10 - loss: 0.2657 - iou_score: 0.7179 - f1-score: 0.8337For batch 97, tr_loss is    0.27.\n",
      " 99/244 [===========>..................] - ETA: 2:10 - loss: 0.2660 - iou_score: 0.7182 - f1-score: 0.8339For batch 98, tr_loss is    0.27.\n",
      "100/244 [===========>..................] - ETA: 2:09 - loss: 0.2653 - iou_score: 0.7191 - f1-score: 0.8344For batch 99, tr_loss is    0.27.\n",
      "101/244 [===========>..................] - ETA: 2:08 - loss: 0.2654 - iou_score: 0.7188 - f1-score: 0.8343For batch 100, tr_loss is    0.27.\n",
      "102/244 [===========>..................] - ETA: 2:07 - loss: 0.2652 - iou_score: 0.7190 - f1-score: 0.8344For batch 101, tr_loss is    0.27.\n",
      "103/244 [===========>..................] - ETA: 2:06 - loss: 0.2647 - iou_score: 0.7195 - f1-score: 0.8347For batch 102, tr_loss is    0.26.\n",
      "104/244 [===========>..................] - ETA: 2:05 - loss: 0.2641 - iou_score: 0.7198 - f1-score: 0.8350For batch 103, tr_loss is    0.26.\n",
      "105/244 [===========>..................] - ETA: 2:04 - loss: 0.2642 - iou_score: 0.7195 - f1-score: 0.8348For batch 104, tr_loss is    0.26.\n",
      "106/244 [============>.................] - ETA: 2:03 - loss: 0.2636 - iou_score: 0.7204 - f1-score: 0.8354For batch 105, tr_loss is    0.26.\n",
      "107/244 [============>.................] - ETA: 2:01 - loss: 0.2630 - iou_score: 0.7210 - f1-score: 0.8358For batch 106, tr_loss is    0.26.\n",
      "108/244 [============>.................] - ETA: 2:01 - loss: 0.2633 - iou_score: 0.7209 - f1-score: 0.8357For batch 107, tr_loss is    0.26.\n",
      "109/244 [============>.................] - ETA: 2:00 - loss: 0.2638 - iou_score: 0.7200 - f1-score: 0.8351For batch 108, tr_loss is    0.26.\n",
      "110/244 [============>.................] - ETA: 1:59 - loss: 0.2640 - iou_score: 0.7197 - f1-score: 0.8349For batch 109, tr_loss is    0.26.\n",
      "111/244 [============>.................] - ETA: 1:58 - loss: 0.2642 - iou_score: 0.7195 - f1-score: 0.8347For batch 110, tr_loss is    0.26.\n",
      "112/244 [============>.................] - ETA: 1:58 - loss: 0.2642 - iou_score: 0.7192 - f1-score: 0.8346For batch 111, tr_loss is    0.26.\n",
      "113/244 [============>.................] - ETA: 1:56 - loss: 0.2642 - iou_score: 0.7195 - f1-score: 0.8347For batch 112, tr_loss is    0.26.\n",
      "114/244 [=============>................] - ETA: 1:56 - loss: 0.2646 - iou_score: 0.7188 - f1-score: 0.8343For batch 113, tr_loss is    0.26.\n",
      "115/244 [=============>................] - ETA: 1:55 - loss: 0.2644 - iou_score: 0.7189 - f1-score: 0.8343For batch 114, tr_loss is    0.26.\n",
      "116/244 [=============>................] - ETA: 1:54 - loss: 0.2642 - iou_score: 0.7188 - f1-score: 0.8343For batch 115, tr_loss is    0.26.\n",
      "117/244 [=============>................] - ETA: 1:53 - loss: 0.2644 - iou_score: 0.7185 - f1-score: 0.8341For batch 116, tr_loss is    0.26.\n",
      "118/244 [=============>................] - ETA: 1:53 - loss: 0.2643 - iou_score: 0.7186 - f1-score: 0.8342For batch 117, tr_loss is    0.26.\n",
      "119/244 [=============>................] - ETA: 1:52 - loss: 0.2641 - iou_score: 0.7188 - f1-score: 0.8343For batch 118, tr_loss is    0.26.\n",
      "120/244 [=============>................] - ETA: 1:51 - loss: 0.2648 - iou_score: 0.7179 - f1-score: 0.8337For batch 119, tr_loss is    0.26.\n",
      "121/244 [=============>................] - ETA: 1:50 - loss: 0.2643 - iou_score: 0.7185 - f1-score: 0.8341For batch 120, tr_loss is    0.26.\n",
      "122/244 [==============>...............] - ETA: 1:49 - loss: 0.2642 - iou_score: 0.7187 - f1-score: 0.8342For batch 121, tr_loss is    0.26.\n",
      "123/244 [==============>...............] - ETA: 1:48 - loss: 0.2645 - iou_score: 0.7182 - f1-score: 0.8339For batch 122, tr_loss is    0.26.\n",
      "124/244 [==============>...............] - ETA: 1:48 - loss: 0.2652 - iou_score: 0.7173 - f1-score: 0.8332For batch 123, tr_loss is    0.27.\n",
      "125/244 [==============>...............] - ETA: 1:47 - loss: 0.2648 - iou_score: 0.7180 - f1-score: 0.8337For batch 124, tr_loss is    0.26.\n",
      "126/244 [==============>...............] - ETA: 1:46 - loss: 0.2645 - iou_score: 0.7181 - f1-score: 0.8338For batch 125, tr_loss is    0.26.\n",
      "127/244 [==============>...............] - ETA: 1:45 - loss: 0.2647 - iou_score: 0.7177 - f1-score: 0.8335For batch 126, tr_loss is    0.26.\n",
      "128/244 [==============>...............] - ETA: 1:44 - loss: 0.2642 - iou_score: 0.7183 - f1-score: 0.8339For batch 127, tr_loss is    0.26.\n",
      "129/244 [==============>...............] - ETA: 1:43 - loss: 0.2641 - iou_score: 0.7184 - f1-score: 0.8340For batch 128, tr_loss is    0.26.\n",
      "130/244 [==============>...............] - ETA: 1:42 - loss: 0.2642 - iou_score: 0.7180 - f1-score: 0.8337For batch 129, tr_loss is    0.26.\n",
      "131/244 [===============>..............] - ETA: 1:41 - loss: 0.2638 - iou_score: 0.7185 - f1-score: 0.8340For batch 130, tr_loss is    0.26.\n",
      "132/244 [===============>..............] - ETA: 1:40 - loss: 0.2643 - iou_score: 0.7178 - f1-score: 0.8336For batch 131, tr_loss is    0.26.\n",
      "133/244 [===============>..............] - ETA: 1:39 - loss: 0.2645 - iou_score: 0.7176 - f1-score: 0.8334For batch 132, tr_loss is    0.26.\n",
      "134/244 [===============>..............] - ETA: 1:38 - loss: 0.2656 - iou_score: 0.7167 - f1-score: 0.8328For batch 133, tr_loss is    0.27.\n",
      "135/244 [===============>..............] - ETA: 1:37 - loss: 0.2657 - iou_score: 0.7164 - f1-score: 0.8326For batch 134, tr_loss is    0.27.\n",
      "136/244 [===============>..............] - ETA: 1:36 - loss: 0.2652 - iou_score: 0.7170 - f1-score: 0.8330For batch 135, tr_loss is    0.27.\n",
      "137/244 [===============>..............] - ETA: 1:35 - loss: 0.2650 - iou_score: 0.7171 - f1-score: 0.8331For batch 136, tr_loss is    0.27.\n",
      "138/244 [===============>..............] - ETA: 1:34 - loss: 0.2650 - iou_score: 0.7170 - f1-score: 0.8330For batch 137, tr_loss is    0.26.\n",
      "139/244 [================>.............] - ETA: 1:33 - loss: 0.2651 - iou_score: 0.7168 - f1-score: 0.8329For batch 138, tr_loss is    0.27.\n",
      "140/244 [================>.............] - ETA: 1:32 - loss: 0.2652 - iou_score: 0.7166 - f1-score: 0.8328For batch 139, tr_loss is    0.27.\n",
      "141/244 [================>.............] - ETA: 1:31 - loss: 0.2651 - iou_score: 0.7166 - f1-score: 0.8328For batch 140, tr_loss is    0.27.\n",
      "142/244 [================>.............] - ETA: 1:31 - loss: 0.2651 - iou_score: 0.7163 - f1-score: 0.8326For batch 141, tr_loss is    0.27.\n",
      "143/244 [================>.............] - ETA: 1:30 - loss: 0.2651 - iou_score: 0.7167 - f1-score: 0.8328For batch 142, tr_loss is    0.27.\n",
      "144/244 [================>.............] - ETA: 1:29 - loss: 0.2654 - iou_score: 0.7163 - f1-score: 0.8326For batch 143, tr_loss is    0.27.\n",
      "145/244 [================>.............] - ETA: 1:28 - loss: 0.2656 - iou_score: 0.7161 - f1-score: 0.8324For batch 144, tr_loss is    0.27.\n",
      "146/244 [================>.............] - ETA: 1:27 - loss: 0.2656 - iou_score: 0.7159 - f1-score: 0.8323For batch 145, tr_loss is    0.27.\n",
      "147/244 [=================>............] - ETA: 1:26 - loss: 0.2656 - iou_score: 0.7158 - f1-score: 0.8323For batch 146, tr_loss is    0.27.\n",
      "148/244 [=================>............] - ETA: 1:25 - loss: 0.2658 - iou_score: 0.7156 - f1-score: 0.8321For batch 147, tr_loss is    0.27.\n",
      "149/244 [=================>............] - ETA: 1:24 - loss: 0.2660 - iou_score: 0.7153 - f1-score: 0.8319For batch 148, tr_loss is    0.27.\n",
      "150/244 [=================>............] - ETA: 1:23 - loss: 0.2660 - iou_score: 0.7153 - f1-score: 0.8319For batch 149, tr_loss is    0.27.\n",
      "151/244 [=================>............] - ETA: 1:22 - loss: 0.2659 - iou_score: 0.7153 - f1-score: 0.8320For batch 150, tr_loss is    0.27.\n",
      "152/244 [=================>............] - ETA: 1:21 - loss: 0.2662 - iou_score: 0.7151 - f1-score: 0.8318For batch 151, tr_loss is    0.27.\n",
      "153/244 [=================>............] - ETA: 1:21 - loss: 0.2661 - iou_score: 0.7152 - f1-score: 0.8319For batch 152, tr_loss is    0.27.\n",
      "154/244 [=================>............] - ETA: 1:20 - loss: 0.2661 - iou_score: 0.7151 - f1-score: 0.8318For batch 153, tr_loss is    0.27.\n",
      "155/244 [==================>...........] - ETA: 1:19 - loss: 0.2662 - iou_score: 0.7149 - f1-score: 0.8317For batch 154, tr_loss is    0.27.\n",
      "156/244 [==================>...........] - ETA: 1:18 - loss: 0.2658 - iou_score: 0.7154 - f1-score: 0.8320For batch 155, tr_loss is    0.27.\n",
      "157/244 [==================>...........] - ETA: 1:17 - loss: 0.2657 - iou_score: 0.7155 - f1-score: 0.8321For batch 156, tr_loss is    0.27.\n",
      "158/244 [==================>...........] - ETA: 1:16 - loss: 0.2658 - iou_score: 0.7153 - f1-score: 0.8320For batch 157, tr_loss is    0.27.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/244 [==================>...........] - ETA: 1:15 - loss: 0.2655 - iou_score: 0.7156 - f1-score: 0.8322For batch 158, tr_loss is    0.27.\n",
      "160/244 [==================>...........] - ETA: 1:14 - loss: 0.2654 - iou_score: 0.7158 - f1-score: 0.8323For batch 159, tr_loss is    0.27.\n",
      "161/244 [==================>...........] - ETA: 1:13 - loss: 0.2654 - iou_score: 0.7157 - f1-score: 0.8323For batch 160, tr_loss is    0.27.\n",
      "162/244 [==================>...........] - ETA: 1:12 - loss: 0.2653 - iou_score: 0.7159 - f1-score: 0.8324For batch 161, tr_loss is    0.27.\n",
      "163/244 [===================>..........] - ETA: 1:11 - loss: 0.2654 - iou_score: 0.7158 - f1-score: 0.8324For batch 162, tr_loss is    0.27.\n",
      "164/244 [===================>..........] - ETA: 1:11 - loss: 0.2653 - iou_score: 0.7160 - f1-score: 0.8325For batch 163, tr_loss is    0.27.\n",
      "165/244 [===================>..........] - ETA: 1:10 - loss: 0.2655 - iou_score: 0.7157 - f1-score: 0.8323For batch 164, tr_loss is    0.27.\n",
      "166/244 [===================>..........] - ETA: 1:08 - loss: 0.2657 - iou_score: 0.7155 - f1-score: 0.8322For batch 165, tr_loss is    0.27.\n",
      "167/244 [===================>..........] - ETA: 1:08 - loss: 0.2655 - iou_score: 0.7157 - f1-score: 0.8324For batch 166, tr_loss is    0.27.\n",
      "168/244 [===================>..........] - ETA: 1:07 - loss: 0.2652 - iou_score: 0.7161 - f1-score: 0.8326For batch 167, tr_loss is    0.27.\n",
      "169/244 [===================>..........] - ETA: 1:06 - loss: 0.2650 - iou_score: 0.7164 - f1-score: 0.8328For batch 168, tr_loss is    0.26.\n",
      "170/244 [===================>..........] - ETA: 1:05 - loss: 0.2653 - iou_score: 0.7160 - f1-score: 0.8325For batch 169, tr_loss is    0.27.\n",
      "171/244 [====================>.........] - ETA: 1:04 - loss: 0.2649 - iou_score: 0.7165 - f1-score: 0.8329For batch 170, tr_loss is    0.26.\n",
      "172/244 [====================>.........] - ETA: 1:03 - loss: 0.2649 - iou_score: 0.7164 - f1-score: 0.8328For batch 171, tr_loss is    0.26.\n",
      "173/244 [====================>.........] - ETA: 1:02 - loss: 0.2651 - iou_score: 0.7163 - f1-score: 0.8327For batch 172, tr_loss is    0.27.\n",
      "174/244 [====================>.........] - ETA: 1:01 - loss: 0.2655 - iou_score: 0.7158 - f1-score: 0.8324For batch 173, tr_loss is    0.27.\n",
      "175/244 [====================>.........] - ETA: 1:00 - loss: 0.2656 - iou_score: 0.7155 - f1-score: 0.8322For batch 174, tr_loss is    0.27.\n",
      "176/244 [====================>.........] - ETA: 1:00 - loss: 0.2656 - iou_score: 0.7156 - f1-score: 0.8322For batch 175, tr_loss is    0.27.\n",
      "177/244 [====================>.........] - ETA: 59s - loss: 0.2652 - iou_score: 0.7161 - f1-score: 0.8326 For batch 176, tr_loss is    0.27.\n",
      "178/244 [====================>.........] - ETA: 58s - loss: 0.2654 - iou_score: 0.7157 - f1-score: 0.8323For batch 177, tr_loss is    0.27.\n",
      "179/244 [=====================>........] - ETA: 57s - loss: 0.2652 - iou_score: 0.7158 - f1-score: 0.8324For batch 178, tr_loss is    0.27.\n",
      "180/244 [=====================>........] - ETA: 56s - loss: 0.2650 - iou_score: 0.7160 - f1-score: 0.8325For batch 179, tr_loss is    0.27.\n",
      "181/244 [=====================>........] - ETA: 55s - loss: 0.2648 - iou_score: 0.7162 - f1-score: 0.8326For batch 180, tr_loss is    0.26.\n",
      "182/244 [=====================>........] - ETA: 54s - loss: 0.2650 - iou_score: 0.7160 - f1-score: 0.8325For batch 181, tr_loss is    0.26.\n",
      "183/244 [=====================>........] - ETA: 53s - loss: 0.2650 - iou_score: 0.7159 - f1-score: 0.8324For batch 182, tr_loss is    0.27.\n",
      "184/244 [=====================>........] - ETA: 52s - loss: 0.2653 - iou_score: 0.7155 - f1-score: 0.8322For batch 183, tr_loss is    0.27.\n",
      "185/244 [=====================>........] - ETA: 52s - loss: 0.2653 - iou_score: 0.7155 - f1-score: 0.8322For batch 184, tr_loss is    0.27.\n",
      "186/244 [=====================>........] - ETA: 51s - loss: 0.2651 - iou_score: 0.7157 - f1-score: 0.8323For batch 185, tr_loss is    0.27.\n",
      "187/244 [=====================>........] - ETA: 50s - loss: 0.2654 - iou_score: 0.7153 - f1-score: 0.8320For batch 186, tr_loss is    0.27.\n",
      "188/244 [======================>.......] - ETA: 49s - loss: 0.2655 - iou_score: 0.7152 - f1-score: 0.8320For batch 187, tr_loss is    0.27.\n",
      "189/244 [======================>.......] - ETA: 48s - loss: 0.2653 - iou_score: 0.7154 - f1-score: 0.8321For batch 188, tr_loss is    0.27.\n",
      "190/244 [======================>.......] - ETA: 47s - loss: 0.2651 - iou_score: 0.7158 - f1-score: 0.8324For batch 189, tr_loss is    0.27.\n",
      "191/244 [======================>.......] - ETA: 46s - loss: 0.2647 - iou_score: 0.7161 - f1-score: 0.8326For batch 190, tr_loss is    0.26.\n",
      "192/244 [======================>.......] - ETA: 45s - loss: 0.2647 - iou_score: 0.7161 - f1-score: 0.8326For batch 191, tr_loss is    0.26.\n",
      "193/244 [======================>.......] - ETA: 44s - loss: 0.2647 - iou_score: 0.7160 - f1-score: 0.8325For batch 192, tr_loss is    0.26.\n",
      "194/244 [======================>.......] - ETA: 43s - loss: 0.2645 - iou_score: 0.7162 - f1-score: 0.8327For batch 193, tr_loss is    0.26.\n",
      "195/244 [======================>.......] - ETA: 43s - loss: 0.2646 - iou_score: 0.7161 - f1-score: 0.8327For batch 194, tr_loss is    0.26.\n",
      "196/244 [=======================>......] - ETA: 42s - loss: 0.2645 - iou_score: 0.7163 - f1-score: 0.8328For batch 195, tr_loss is    0.26.\n",
      "197/244 [=======================>......] - ETA: 41s - loss: 0.2647 - iou_score: 0.7160 - f1-score: 0.8326For batch 196, tr_loss is    0.26.\n",
      "198/244 [=======================>......] - ETA: 40s - loss: 0.2645 - iou_score: 0.7161 - f1-score: 0.8327For batch 197, tr_loss is    0.26.\n",
      "199/244 [=======================>......] - ETA: 39s - loss: 0.2641 - iou_score: 0.7167 - f1-score: 0.8330For batch 198, tr_loss is    0.26.\n",
      "200/244 [=======================>......] - ETA: 38s - loss: 0.2642 - iou_score: 0.7167 - f1-score: 0.8330For batch 199, tr_loss is    0.26.\n",
      "201/244 [=======================>......] - ETA: 37s - loss: 0.2643 - iou_score: 0.7164 - f1-score: 0.8328For batch 200, tr_loss is    0.26.\n",
      "202/244 [=======================>......] - ETA: 36s - loss: 0.2642 - iou_score: 0.7166 - f1-score: 0.8329For batch 201, tr_loss is    0.26.\n",
      "203/244 [=======================>......] - ETA: 35s - loss: 0.2640 - iou_score: 0.7167 - f1-score: 0.8330For batch 202, tr_loss is    0.26.\n",
      "204/244 [========================>.....] - ETA: 35s - loss: 0.2638 - iou_score: 0.7170 - f1-score: 0.8333For batch 203, tr_loss is    0.26.\n",
      "205/244 [========================>.....] - ETA: 34s - loss: 0.2634 - iou_score: 0.7174 - f1-score: 0.8335For batch 204, tr_loss is    0.26.\n",
      "206/244 [========================>.....] - ETA: 33s - loss: 0.2636 - iou_score: 0.7171 - f1-score: 0.8333For batch 205, tr_loss is    0.26.\n",
      "207/244 [========================>.....] - ETA: 32s - loss: 0.2633 - iou_score: 0.7175 - f1-score: 0.8336For batch 206, tr_loss is    0.26.\n",
      "208/244 [========================>.....] - ETA: 31s - loss: 0.2633 - iou_score: 0.7173 - f1-score: 0.8334For batch 207, tr_loss is    0.26.\n",
      "209/244 [========================>.....] - ETA: 30s - loss: 0.2632 - iou_score: 0.7174 - f1-score: 0.8335For batch 208, tr_loss is    0.26.\n",
      "210/244 [========================>.....] - ETA: 30s - loss: 0.2629 - iou_score: 0.7178 - f1-score: 0.8338For batch 209, tr_loss is    0.26.\n",
      "211/244 [========================>.....] - ETA: 29s - loss: 0.2630 - iou_score: 0.7178 - f1-score: 0.8338For batch 210, tr_loss is    0.26.\n",
      "212/244 [=========================>....] - ETA: 28s - loss: 0.2633 - iou_score: 0.7175 - f1-score: 0.8336For batch 211, tr_loss is    0.26.\n",
      "213/244 [=========================>....] - ETA: 27s - loss: 0.2635 - iou_score: 0.7174 - f1-score: 0.8335For batch 212, tr_loss is    0.26.\n",
      "214/244 [=========================>....] - ETA: 26s - loss: 0.2632 - iou_score: 0.7177 - f1-score: 0.8337For batch 213, tr_loss is    0.26.\n",
      "215/244 [=========================>....] - ETA: 25s - loss: 0.2630 - iou_score: 0.7180 - f1-score: 0.8339For batch 214, tr_loss is    0.26.\n",
      "216/244 [=========================>....] - ETA: 24s - loss: 0.2633 - iou_score: 0.7178 - f1-score: 0.8338For batch 215, tr_loss is    0.26.\n",
      "217/244 [=========================>....] - ETA: 23s - loss: 0.2633 - iou_score: 0.7179 - f1-score: 0.8338For batch 216, tr_loss is    0.26.\n",
      "218/244 [=========================>....] - ETA: 22s - loss: 0.2632 - iou_score: 0.7179 - f1-score: 0.8339For batch 217, tr_loss is    0.26.\n",
      "219/244 [=========================>....] - ETA: 22s - loss: 0.2631 - iou_score: 0.7179 - f1-score: 0.8339For batch 218, tr_loss is    0.26.\n",
      "220/244 [==========================>...] - ETA: 21s - loss: 0.2631 - iou_score: 0.7179 - f1-score: 0.8339For batch 219, tr_loss is    0.26.\n",
      "221/244 [==========================>...] - ETA: 20s - loss: 0.2632 - iou_score: 0.7178 - f1-score: 0.8338For batch 220, tr_loss is    0.26.\n",
      "222/244 [==========================>...] - ETA: 19s - loss: 0.2629 - iou_score: 0.7181 - f1-score: 0.8340For batch 221, tr_loss is    0.26.\n",
      "223/244 [==========================>...] - ETA: 18s - loss: 0.2629 - iou_score: 0.7181 - f1-score: 0.8340For batch 222, tr_loss is    0.26.\n",
      "224/244 [==========================>...] - ETA: 17s - loss: 0.2629 - iou_score: 0.7181 - f1-score: 0.8340For batch 223, tr_loss is    0.26.\n",
      "225/244 [==========================>...] - ETA: 16s - loss: 0.2629 - iou_score: 0.7180 - f1-score: 0.8339For batch 224, tr_loss is    0.26.\n",
      "226/244 [==========================>...] - ETA: 15s - loss: 0.2628 - iou_score: 0.7182 - f1-score: 0.8341For batch 225, tr_loss is    0.26.\n",
      "227/244 [==========================>...] - ETA: 15s - loss: 0.2628 - iou_score: 0.7183 - f1-score: 0.8341For batch 226, tr_loss is    0.26.\n",
      "228/244 [===========================>..] - ETA: 14s - loss: 0.2626 - iou_score: 0.7185 - f1-score: 0.8343For batch 227, tr_loss is    0.26.\n",
      "229/244 [===========================>..] - ETA: 13s - loss: 0.2624 - iou_score: 0.7188 - f1-score: 0.8345For batch 228, tr_loss is    0.26.\n",
      "230/244 [===========================>..] - ETA: 12s - loss: 0.2623 - iou_score: 0.7189 - f1-score: 0.8345For batch 229, tr_loss is    0.26.\n",
      "231/244 [===========================>..] - ETA: 11s - loss: 0.2621 - iou_score: 0.7191 - f1-score: 0.8347For batch 230, tr_loss is    0.26.\n",
      "232/244 [===========================>..] - ETA: 10s - loss: 0.2622 - iou_score: 0.7191 - f1-score: 0.8347For batch 231, tr_loss is    0.26.\n",
      "233/244 [===========================>..] - ETA: 9s - loss: 0.2628 - iou_score: 0.7185 - f1-score: 0.8343 For batch 232, tr_loss is    0.26.\n",
      "234/244 [===========================>..] - ETA: 8s - loss: 0.2628 - iou_score: 0.7184 - f1-score: 0.8342For batch 233, tr_loss is    0.26.\n",
      "235/244 [===========================>..] - ETA: 7s - loss: 0.2626 - iou_score: 0.7187 - f1-score: 0.8344For batch 234, tr_loss is    0.26.\n",
      "236/244 [============================>.] - ETA: 7s - loss: 0.2628 - iou_score: 0.7187 - f1-score: 0.8344For batch 235, tr_loss is    0.26.\n",
      "237/244 [============================>.] - ETA: 6s - loss: 0.2629 - iou_score: 0.7186 - f1-score: 0.8343For batch 236, tr_loss is    0.26.\n",
      "238/244 [============================>.] - ETA: 5s - loss: 0.2627 - iou_score: 0.7188 - f1-score: 0.8344For batch 237, tr_loss is    0.26.\n",
      "239/244 [============================>.] - ETA: 4s - loss: 0.2627 - iou_score: 0.7189 - f1-score: 0.8345For batch 238, tr_loss is    0.26.\n",
      "240/244 [============================>.] - ETA: 3s - loss: 0.2624 - iou_score: 0.7193 - f1-score: 0.8348For batch 239, tr_loss is    0.26.\n",
      "241/244 [============================>.] - ETA: 2s - loss: 0.2624 - iou_score: 0.7193 - f1-score: 0.8348For batch 240, tr_loss is    0.26.\n",
      "242/244 [============================>.] - ETA: 1s - loss: 0.2627 - iou_score: 0.7189 - f1-score: 0.8345For batch 241, tr_loss is    0.26.\n",
      "243/244 [============================>.] - ETA: 0s - loss: 0.2632 - iou_score: 0.7184 - f1-score: 0.8341For batch 242, tr_loss is    0.26.\n",
      "244/244 [==============================] - ETA: 0s - loss: 0.2632 - iou_score: 0.7184 - f1-score: 0.8341For batch 243, tr_loss is    0.26.\n",
      "For batch 0, vl_loss is    0.36.\n",
      "For batch 1, vl_loss is    0.33.\n",
      "For batch 2, vl_loss is    0.33.\n",
      "For batch 3, vl_loss is    0.36.\n",
      "For batch 4, vl_loss is    0.34.\n",
      "For batch 5, vl_loss is    0.34.\n",
      "For batch 6, vl_loss is    0.36.\n",
      "For batch 7, vl_loss is    0.36.\n",
      "For batch 8, vl_loss is    0.36.\n",
      "For batch 9, vl_loss is    0.36.\n",
      "For batch 10, vl_loss is    0.37.\n",
      "For batch 11, vl_loss is    0.38.\n",
      "For batch 12, vl_loss is    0.37.\n",
      "For batch 13, vl_loss is    0.37.\n",
      "For batch 14, vl_loss is    0.37.\n",
      "For batch 15, vl_loss is    0.38.\n",
      "For batch 16, vl_loss is    0.37.\n",
      "For batch 17, vl_loss is    0.37.\n",
      "For batch 18, vl_loss is    0.37.\n",
      "For batch 19, vl_loss is    0.37.\n",
      "For batch 20, vl_loss is    0.37.\n",
      "For batch 21, vl_loss is    0.37.\n",
      "For batch 22, vl_loss is    0.37.\n",
      "For batch 23, vl_loss is    0.37.\n",
      "For batch 24, vl_loss is    0.37.\n",
      "For batch 25, vl_loss is    0.37.\n",
      "For batch 26, vl_loss is    0.37.\n",
      "For batch 27, vl_loss is    0.37.\n",
      "For batch 28, vl_loss is    0.37.\n",
      "For batch 29, vl_loss is    0.37.\n",
      "For batch 30, vl_loss is    0.37.\n",
      "For batch 31, vl_loss is    0.38.\n",
      "For batch 32, vl_loss is    0.37.\n",
      "For batch 33, vl_loss is    0.38.\n",
      "For batch 34, vl_loss is    0.37.\n",
      "For batch 35, vl_loss is    0.37.\n",
      "For batch 36, vl_loss is    0.37.\n",
      "For batch 37, vl_loss is    0.38.\n",
      "For batch 38, vl_loss is    0.37.\n",
      "For batch 39, vl_loss is    0.38.\n",
      "For batch 40, vl_loss is    0.37.\n",
      "For batch 41, vl_loss is    0.38.\n",
      "For batch 42, vl_loss is    0.37.\n",
      "For batch 43, vl_loss is    0.37.\n",
      "For batch 44, vl_loss is    0.37.\n",
      "For batch 45, vl_loss is    0.37.\n",
      "For batch 46, vl_loss is    0.37.\n",
      "For batch 47, vl_loss is    0.37.\n",
      "For batch 48, vl_loss is    0.37.\n",
      "For batch 49, vl_loss is    0.37.\n",
      "For batch 50, vl_loss is    0.37.\n",
      "For batch 51, vl_loss is    0.37.\n",
      "For batch 52, vl_loss is    0.37.\n",
      "For batch 53, vl_loss is    0.37.\n",
      "For batch 54, vl_loss is    0.37.\n",
      "For batch 55, vl_loss is    0.37.\n",
      "244/244 [==============================] - 218s 888ms/step - loss: 0.2632 - iou_score: 0.7184 - f1-score: 0.8341 - val_loss: 0.3663 - val_iou_score: 0.6216 - val_f1-score: 0.7643\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.34998\n",
      "The average loss for epoch 9 is    0.26 \n",
      "Epoch 11/200\n",
      "  1/244 [..............................] - ETA: 9:02 - loss: 0.2860 - iou_score: 0.6819 - f1-score: 0.8081For batch 0, tr_loss is    0.29.\n",
      "  2/244 [..............................] - ETA: 5:00 - loss: 0.2622 - iou_score: 0.7262 - f1-score: 0.8389For batch 1, tr_loss is    0.26.\n",
      "  3/244 [..............................] - ETA: 5:12 - loss: 0.2591 - iou_score: 0.7292 - f1-score: 0.8415For batch 2, tr_loss is    0.26.\n",
      "  4/244 [..............................] - ETA: 5:11 - loss: 0.2645 - iou_score: 0.7258 - f1-score: 0.8397For batch 3, tr_loss is    0.26.\n",
      "  5/244 [..............................] - ETA: 5:00 - loss: 0.2706 - iou_score: 0.7212 - f1-score: 0.8366For batch 4, tr_loss is    0.27.\n",
      "  6/244 [..............................] - ETA: 4:55 - loss: 0.2760 - iou_score: 0.7126 - f1-score: 0.8309For batch 5, tr_loss is    0.28.\n",
      "  7/244 [..............................] - ETA: 5:04 - loss: 0.2717 - iou_score: 0.7192 - f1-score: 0.8349For batch 6, tr_loss is    0.27.\n",
      "  8/244 [..............................] - ETA: 5:08 - loss: 0.2806 - iou_score: 0.7052 - f1-score: 0.8246For batch 7, tr_loss is    0.28.\n",
      "  9/244 [>.............................] - ETA: 5:01 - loss: 0.2854 - iou_score: 0.6988 - f1-score: 0.8201For batch 8, tr_loss is    0.29.\n",
      " 10/244 [>.............................] - ETA: 4:52 - loss: 0.2786 - iou_score: 0.7069 - f1-score: 0.8258For batch 9, tr_loss is    0.28.\n",
      " 11/244 [>.............................] - ETA: 4:46 - loss: 0.2755 - iou_score: 0.7100 - f1-score: 0.8280For batch 10, tr_loss is    0.28.\n",
      " 12/244 [>.............................] - ETA: 4:35 - loss: 0.2729 - iou_score: 0.7132 - f1-score: 0.8304For batch 11, tr_loss is    0.27.\n",
      " 13/244 [>.............................] - ETA: 4:20 - loss: 0.2688 - iou_score: 0.7181 - f1-score: 0.8337For batch 12, tr_loss is    0.27.\n",
      " 14/244 [>.............................] - ETA: 4:19 - loss: 0.2733 - iou_score: 0.7121 - f1-score: 0.8295For batch 13, tr_loss is    0.27.\n",
      " 15/244 [>.............................] - ETA: 4:09 - loss: 0.2766 - iou_score: 0.7083 - f1-score: 0.8270For batch 14, tr_loss is    0.28.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16/244 [>.............................] - ETA: 4:09 - loss: 0.2768 - iou_score: 0.7084 - f1-score: 0.8271For batch 15, tr_loss is    0.28.\n",
      " 17/244 [=>............................] - ETA: 4:06 - loss: 0.2735 - iou_score: 0.7134 - f1-score: 0.8305For batch 16, tr_loss is    0.27.\n",
      " 18/244 [=>............................] - ETA: 3:58 - loss: 0.2752 - iou_score: 0.7117 - f1-score: 0.8295For batch 17, tr_loss is    0.28.\n",
      " 19/244 [=>............................] - ETA: 3:52 - loss: 0.2735 - iou_score: 0.7139 - f1-score: 0.8311For batch 18, tr_loss is    0.27.\n",
      " 20/244 [=>............................] - ETA: 3:53 - loss: 0.2728 - iou_score: 0.7139 - f1-score: 0.8309For batch 19, tr_loss is    0.27.\n",
      " 21/244 [=>............................] - ETA: 3:52 - loss: 0.2726 - iou_score: 0.7130 - f1-score: 0.8304For batch 20, tr_loss is    0.27.\n",
      " 22/244 [=>............................] - ETA: 3:47 - loss: 0.2749 - iou_score: 0.7098 - f1-score: 0.8281For batch 21, tr_loss is    0.27.\n",
      " 23/244 [=>............................] - ETA: 3:44 - loss: 0.2742 - iou_score: 0.7094 - f1-score: 0.8279For batch 22, tr_loss is    0.27.\n",
      " 24/244 [=>............................] - ETA: 3:43 - loss: 0.2724 - iou_score: 0.7115 - f1-score: 0.8294For batch 23, tr_loss is    0.27.\n",
      " 25/244 [==>...........................] - ETA: 3:42 - loss: 0.2737 - iou_score: 0.7094 - f1-score: 0.8279For batch 24, tr_loss is    0.27.\n",
      " 26/244 [==>...........................] - ETA: 3:38 - loss: 0.2738 - iou_score: 0.7092 - f1-score: 0.8278For batch 25, tr_loss is    0.27.\n",
      " 27/244 [==>...........................] - ETA: 3:34 - loss: 0.2733 - iou_score: 0.7098 - f1-score: 0.8283For batch 26, tr_loss is    0.27.\n",
      " 28/244 [==>...........................] - ETA: 3:31 - loss: 0.2709 - iou_score: 0.7134 - f1-score: 0.8307For batch 27, tr_loss is    0.27.\n",
      " 29/244 [==>...........................] - ETA: 3:32 - loss: 0.2693 - iou_score: 0.7144 - f1-score: 0.8315For batch 28, tr_loss is    0.27.\n",
      " 30/244 [==>...........................] - ETA: 3:27 - loss: 0.2667 - iou_score: 0.7173 - f1-score: 0.8334For batch 29, tr_loss is    0.27.\n",
      " 31/244 [==>...........................] - ETA: 3:27 - loss: 0.2657 - iou_score: 0.7185 - f1-score: 0.8343For batch 30, tr_loss is    0.27.\n",
      " 32/244 [==>...........................] - ETA: 3:23 - loss: 0.2644 - iou_score: 0.7201 - f1-score: 0.8353For batch 31, tr_loss is    0.26.\n",
      " 33/244 [===>..........................] - ETA: 3:24 - loss: 0.2639 - iou_score: 0.7198 - f1-score: 0.8352For batch 32, tr_loss is    0.26.\n",
      " 34/244 [===>..........................] - ETA: 3:21 - loss: 0.2635 - iou_score: 0.7200 - f1-score: 0.8354For batch 33, tr_loss is    0.26.\n",
      " 35/244 [===>..........................] - ETA: 3:19 - loss: 0.2644 - iou_score: 0.7195 - f1-score: 0.8351For batch 34, tr_loss is    0.26.\n",
      " 36/244 [===>..........................] - ETA: 3:19 - loss: 0.2633 - iou_score: 0.7205 - f1-score: 0.8358For batch 35, tr_loss is    0.26.\n",
      " 37/244 [===>..........................] - ETA: 3:19 - loss: 0.2638 - iou_score: 0.7200 - f1-score: 0.8355For batch 36, tr_loss is    0.26.\n",
      " 38/244 [===>..........................] - ETA: 3:17 - loss: 0.2629 - iou_score: 0.7214 - f1-score: 0.8365For batch 37, tr_loss is    0.26.\n",
      " 39/244 [===>..........................] - ETA: 3:14 - loss: 0.2616 - iou_score: 0.7233 - f1-score: 0.8377For batch 38, tr_loss is    0.26.\n",
      " 40/244 [===>..........................] - ETA: 3:14 - loss: 0.2619 - iou_score: 0.7226 - f1-score: 0.8372For batch 39, tr_loss is    0.26.\n",
      " 41/244 [====>.........................] - ETA: 3:12 - loss: 0.2628 - iou_score: 0.7210 - f1-score: 0.8361For batch 40, tr_loss is    0.26.\n",
      " 42/244 [====>.........................] - ETA: 3:09 - loss: 0.2614 - iou_score: 0.7223 - f1-score: 0.8370For batch 41, tr_loss is    0.26.\n",
      " 43/244 [====>.........................] - ETA: 3:07 - loss: 0.2633 - iou_score: 0.7201 - f1-score: 0.8355For batch 42, tr_loss is    0.26.\n",
      " 44/244 [====>.........................] - ETA: 3:05 - loss: 0.2636 - iou_score: 0.7208 - f1-score: 0.8360For batch 43, tr_loss is    0.26.\n",
      " 45/244 [====>.........................] - ETA: 3:04 - loss: 0.2634 - iou_score: 0.7206 - f1-score: 0.8359For batch 44, tr_loss is    0.26.\n",
      " 46/244 [====>.........................] - ETA: 3:03 - loss: 0.2630 - iou_score: 0.7209 - f1-score: 0.8361For batch 45, tr_loss is    0.26.\n",
      " 47/244 [====>.........................] - ETA: 3:02 - loss: 0.2619 - iou_score: 0.7219 - f1-score: 0.8368For batch 46, tr_loss is    0.26.\n",
      " 48/244 [====>.........................] - ETA: 3:01 - loss: 0.2612 - iou_score: 0.7225 - f1-score: 0.8372For batch 47, tr_loss is    0.26.\n",
      " 49/244 [=====>........................] - ETA: 3:01 - loss: 0.2617 - iou_score: 0.7219 - f1-score: 0.8368For batch 48, tr_loss is    0.26.\n",
      " 50/244 [=====>........................] - ETA: 3:00 - loss: 0.2619 - iou_score: 0.7219 - f1-score: 0.8368For batch 49, tr_loss is    0.26.\n",
      " 51/244 [=====>........................] - ETA: 3:00 - loss: 0.2636 - iou_score: 0.7202 - f1-score: 0.8357For batch 50, tr_loss is    0.26.\n",
      " 52/244 [=====>........................] - ETA: 2:57 - loss: 0.2632 - iou_score: 0.7205 - f1-score: 0.8359For batch 51, tr_loss is    0.26.\n",
      " 53/244 [=====>........................] - ETA: 2:56 - loss: 0.2630 - iou_score: 0.7205 - f1-score: 0.8359For batch 52, tr_loss is    0.26.\n",
      " 54/244 [=====>........................] - ETA: 2:54 - loss: 0.2632 - iou_score: 0.7203 - f1-score: 0.8358For batch 53, tr_loss is    0.26.\n",
      " 55/244 [=====>........................] - ETA: 2:54 - loss: 0.2622 - iou_score: 0.7214 - f1-score: 0.8365For batch 54, tr_loss is    0.26.\n",
      " 56/244 [=====>........................] - ETA: 2:53 - loss: 0.2618 - iou_score: 0.7219 - f1-score: 0.8369For batch 55, tr_loss is    0.26.\n",
      " 57/244 [======>.......................] - ETA: 2:52 - loss: 0.2624 - iou_score: 0.7213 - f1-score: 0.8365For batch 56, tr_loss is    0.26.\n",
      " 58/244 [======>.......................] - ETA: 2:50 - loss: 0.2630 - iou_score: 0.7205 - f1-score: 0.8359For batch 57, tr_loss is    0.26.\n",
      " 59/244 [======>.......................] - ETA: 2:49 - loss: 0.2617 - iou_score: 0.7224 - f1-score: 0.8372For batch 58, tr_loss is    0.26.\n",
      " 60/244 [======>.......................] - ETA: 2:48 - loss: 0.2632 - iou_score: 0.7201 - f1-score: 0.8355For batch 59, tr_loss is    0.26.\n",
      " 61/244 [======>.......................] - ETA: 2:48 - loss: 0.2646 - iou_score: 0.7180 - f1-score: 0.8340For batch 60, tr_loss is    0.26.\n",
      " 62/244 [======>.......................] - ETA: 2:45 - loss: 0.2645 - iou_score: 0.7182 - f1-score: 0.8342For batch 61, tr_loss is    0.26.\n",
      " 63/244 [======>.......................] - ETA: 2:44 - loss: 0.2645 - iou_score: 0.7183 - f1-score: 0.8343For batch 62, tr_loss is    0.26.\n",
      " 64/244 [======>.......................] - ETA: 2:42 - loss: 0.2638 - iou_score: 0.7194 - f1-score: 0.8350For batch 63, tr_loss is    0.26.\n",
      " 65/244 [======>.......................] - ETA: 2:42 - loss: 0.2638 - iou_score: 0.7192 - f1-score: 0.8348For batch 64, tr_loss is    0.26.\n",
      " 66/244 [=======>......................] - ETA: 2:41 - loss: 0.2637 - iou_score: 0.7194 - f1-score: 0.8349For batch 65, tr_loss is    0.26.\n",
      " 67/244 [=======>......................] - ETA: 2:40 - loss: 0.2634 - iou_score: 0.7199 - f1-score: 0.8354For batch 66, tr_loss is    0.26.\n",
      " 68/244 [=======>......................] - ETA: 2:38 - loss: 0.2635 - iou_score: 0.7203 - f1-score: 0.8356For batch 67, tr_loss is    0.26.\n",
      " 69/244 [=======>......................] - ETA: 2:37 - loss: 0.2639 - iou_score: 0.7193 - f1-score: 0.8349For batch 68, tr_loss is    0.26.\n",
      " 70/244 [=======>......................] - ETA: 2:37 - loss: 0.2636 - iou_score: 0.7193 - f1-score: 0.8349For batch 69, tr_loss is    0.26.\n",
      " 71/244 [=======>......................] - ETA: 2:36 - loss: 0.2636 - iou_score: 0.7194 - f1-score: 0.8350For batch 70, tr_loss is    0.26.\n",
      " 72/244 [=======>......................] - ETA: 2:35 - loss: 0.2627 - iou_score: 0.7203 - f1-score: 0.8356For batch 71, tr_loss is    0.26.\n",
      " 73/244 [=======>......................] - ETA: 2:35 - loss: 0.2630 - iou_score: 0.7197 - f1-score: 0.8352For batch 72, tr_loss is    0.26.\n",
      " 74/244 [========>.....................] - ETA: 2:34 - loss: 0.2633 - iou_score: 0.7194 - f1-score: 0.8350For batch 73, tr_loss is    0.26.\n",
      " 75/244 [========>.....................] - ETA: 2:34 - loss: 0.2632 - iou_score: 0.7194 - f1-score: 0.8349For batch 74, tr_loss is    0.26.\n",
      " 76/244 [========>.....................] - ETA: 2:33 - loss: 0.2625 - iou_score: 0.7205 - f1-score: 0.8357For batch 75, tr_loss is    0.26.\n",
      " 77/244 [========>.....................] - ETA: 2:32 - loss: 0.2625 - iou_score: 0.7206 - f1-score: 0.8358For batch 76, tr_loss is    0.26.\n",
      " 78/244 [========>.....................] - ETA: 2:32 - loss: 0.2623 - iou_score: 0.7212 - f1-score: 0.8362For batch 77, tr_loss is    0.26.\n",
      " 79/244 [========>.....................] - ETA: 2:31 - loss: 0.2626 - iou_score: 0.7214 - f1-score: 0.8362For batch 78, tr_loss is    0.26.\n",
      " 80/244 [========>.....................] - ETA: 2:29 - loss: 0.2624 - iou_score: 0.7214 - f1-score: 0.8363For batch 79, tr_loss is    0.26.\n",
      " 81/244 [========>.....................] - ETA: 2:29 - loss: 0.2627 - iou_score: 0.7212 - f1-score: 0.8361For batch 80, tr_loss is    0.26.\n",
      " 82/244 [=========>....................] - ETA: 2:27 - loss: 0.2638 - iou_score: 0.7197 - f1-score: 0.8350For batch 81, tr_loss is    0.26.\n",
      " 83/244 [=========>....................] - ETA: 2:26 - loss: 0.2632 - iou_score: 0.7204 - f1-score: 0.8355For batch 82, tr_loss is    0.26.\n",
      " 84/244 [=========>....................] - ETA: 2:25 - loss: 0.2630 - iou_score: 0.7206 - f1-score: 0.8357For batch 83, tr_loss is    0.26.\n",
      " 85/244 [=========>....................] - ETA: 2:25 - loss: 0.2623 - iou_score: 0.7214 - f1-score: 0.8362For batch 84, tr_loss is    0.26.\n",
      " 86/244 [=========>....................] - ETA: 2:24 - loss: 0.2624 - iou_score: 0.7211 - f1-score: 0.8360For batch 85, tr_loss is    0.26.\n",
      " 87/244 [=========>....................] - ETA: 2:23 - loss: 0.2622 - iou_score: 0.7214 - f1-score: 0.8362For batch 86, tr_loss is    0.26.\n",
      " 88/244 [=========>....................] - ETA: 2:22 - loss: 0.2616 - iou_score: 0.7220 - f1-score: 0.8366For batch 87, tr_loss is    0.26.\n",
      " 89/244 [=========>....................] - ETA: 2:21 - loss: 0.2618 - iou_score: 0.7216 - f1-score: 0.8363For batch 88, tr_loss is    0.26.\n",
      " 90/244 [==========>...................] - ETA: 2:21 - loss: 0.2617 - iou_score: 0.7218 - f1-score: 0.8364For batch 89, tr_loss is    0.26.\n",
      " 91/244 [==========>...................] - ETA: 2:19 - loss: 0.2627 - iou_score: 0.7205 - f1-score: 0.8356For batch 90, tr_loss is    0.26.\n",
      " 92/244 [==========>...................] - ETA: 2:19 - loss: 0.2633 - iou_score: 0.7198 - f1-score: 0.8350For batch 91, tr_loss is    0.26.\n",
      " 93/244 [==========>...................] - ETA: 2:18 - loss: 0.2627 - iou_score: 0.7206 - f1-score: 0.8356For batch 92, tr_loss is    0.26.\n",
      " 94/244 [==========>...................] - ETA: 2:17 - loss: 0.2626 - iou_score: 0.7211 - f1-score: 0.8359For batch 93, tr_loss is    0.26.\n",
      " 95/244 [==========>...................] - ETA: 2:16 - loss: 0.2628 - iou_score: 0.7207 - f1-score: 0.8356For batch 94, tr_loss is    0.26.\n",
      " 96/244 [==========>...................] - ETA: 2:15 - loss: 0.2630 - iou_score: 0.7202 - f1-score: 0.8353For batch 95, tr_loss is    0.26.\n",
      " 97/244 [==========>...................] - ETA: 2:15 - loss: 0.2628 - iou_score: 0.7205 - f1-score: 0.8355For batch 96, tr_loss is    0.26.\n",
      " 98/244 [===========>..................] - ETA: 2:13 - loss: 0.2630 - iou_score: 0.7203 - f1-score: 0.8354For batch 97, tr_loss is    0.26.\n",
      " 99/244 [===========>..................] - ETA: 2:12 - loss: 0.2630 - iou_score: 0.7206 - f1-score: 0.8356For batch 98, tr_loss is    0.26.\n",
      "100/244 [===========>..................] - ETA: 2:11 - loss: 0.2624 - iou_score: 0.7214 - f1-score: 0.8362For batch 99, tr_loss is    0.26.\n",
      "101/244 [===========>..................] - ETA: 2:10 - loss: 0.2623 - iou_score: 0.7213 - f1-score: 0.8361For batch 100, tr_loss is    0.26.\n",
      "102/244 [===========>..................] - ETA: 2:09 - loss: 0.2621 - iou_score: 0.7215 - f1-score: 0.8362For batch 101, tr_loss is    0.26.\n",
      "103/244 [===========>..................] - ETA: 2:08 - loss: 0.2615 - iou_score: 0.7221 - f1-score: 0.8366For batch 102, tr_loss is    0.26.\n",
      "104/244 [===========>..................] - ETA: 2:07 - loss: 0.2612 - iou_score: 0.7223 - f1-score: 0.8367For batch 103, tr_loss is    0.26.\n",
      "105/244 [===========>..................] - ETA: 2:06 - loss: 0.2614 - iou_score: 0.7220 - f1-score: 0.8366For batch 104, tr_loss is    0.26.\n",
      "106/244 [============>.................] - ETA: 2:05 - loss: 0.2607 - iou_score: 0.7230 - f1-score: 0.8372For batch 105, tr_loss is    0.26.\n",
      "107/244 [============>.................] - ETA: 2:04 - loss: 0.2601 - iou_score: 0.7237 - f1-score: 0.8377For batch 106, tr_loss is    0.26.\n",
      "108/244 [============>.................] - ETA: 2:02 - loss: 0.2602 - iou_score: 0.7235 - f1-score: 0.8376For batch 107, tr_loss is    0.26.\n",
      "109/244 [============>.................] - ETA: 2:02 - loss: 0.2607 - iou_score: 0.7228 - f1-score: 0.8371For batch 108, tr_loss is    0.26.\n",
      "110/244 [============>.................] - ETA: 2:01 - loss: 0.2611 - iou_score: 0.7224 - f1-score: 0.8368For batch 109, tr_loss is    0.26.\n",
      "111/244 [============>.................] - ETA: 2:00 - loss: 0.2609 - iou_score: 0.7224 - f1-score: 0.8368For batch 110, tr_loss is    0.26.\n",
      "112/244 [============>.................] - ETA: 1:59 - loss: 0.2609 - iou_score: 0.7222 - f1-score: 0.8367For batch 111, tr_loss is    0.26.\n",
      "113/244 [============>.................] - ETA: 1:58 - loss: 0.2608 - iou_score: 0.7225 - f1-score: 0.8369For batch 112, tr_loss is    0.26.\n",
      "114/244 [=============>................] - ETA: 1:57 - loss: 0.2613 - iou_score: 0.7220 - f1-score: 0.8365For batch 113, tr_loss is    0.26.\n",
      "115/244 [=============>................] - ETA: 1:57 - loss: 0.2612 - iou_score: 0.7220 - f1-score: 0.8366For batch 114, tr_loss is    0.26.\n",
      "116/244 [=============>................] - ETA: 1:55 - loss: 0.2609 - iou_score: 0.7222 - f1-score: 0.8367For batch 115, tr_loss is    0.26.\n",
      "117/244 [=============>................] - ETA: 1:54 - loss: 0.2610 - iou_score: 0.7218 - f1-score: 0.8365For batch 116, tr_loss is    0.26.\n",
      "118/244 [=============>................] - ETA: 1:54 - loss: 0.2609 - iou_score: 0.7218 - f1-score: 0.8365For batch 117, tr_loss is    0.26.\n",
      "119/244 [=============>................] - ETA: 1:52 - loss: 0.2607 - iou_score: 0.7220 - f1-score: 0.8366For batch 118, tr_loss is    0.26.\n",
      "120/244 [=============>................] - ETA: 1:51 - loss: 0.2618 - iou_score: 0.7208 - f1-score: 0.8357For batch 119, tr_loss is    0.26.\n",
      "121/244 [=============>................] - ETA: 1:50 - loss: 0.2613 - iou_score: 0.7214 - f1-score: 0.8361For batch 120, tr_loss is    0.26.\n",
      "122/244 [==============>...............] - ETA: 1:49 - loss: 0.2612 - iou_score: 0.7217 - f1-score: 0.8363For batch 121, tr_loss is    0.26.\n",
      "123/244 [==============>...............] - ETA: 1:48 - loss: 0.2620 - iou_score: 0.7210 - f1-score: 0.8358For batch 122, tr_loss is    0.26.\n",
      "124/244 [==============>...............] - ETA: 1:47 - loss: 0.2624 - iou_score: 0.7202 - f1-score: 0.8352For batch 123, tr_loss is    0.26.\n",
      "125/244 [==============>...............] - ETA: 1:46 - loss: 0.2626 - iou_score: 0.7205 - f1-score: 0.8355For batch 124, tr_loss is    0.26.\n",
      "126/244 [==============>...............] - ETA: 1:46 - loss: 0.2623 - iou_score: 0.7207 - f1-score: 0.8356For batch 125, tr_loss is    0.26.\n",
      "127/244 [==============>...............] - ETA: 1:45 - loss: 0.2625 - iou_score: 0.7204 - f1-score: 0.8354For batch 126, tr_loss is    0.26.\n",
      "128/244 [==============>...............] - ETA: 1:44 - loss: 0.2622 - iou_score: 0.7207 - f1-score: 0.8356For batch 127, tr_loss is    0.26.\n",
      "129/244 [==============>...............] - ETA: 1:43 - loss: 0.2621 - iou_score: 0.7209 - f1-score: 0.8357For batch 128, tr_loss is    0.26.\n",
      "130/244 [==============>...............] - ETA: 1:42 - loss: 0.2623 - iou_score: 0.7205 - f1-score: 0.8355For batch 129, tr_loss is    0.26.\n",
      "131/244 [===============>..............] - ETA: 1:42 - loss: 0.2619 - iou_score: 0.7209 - f1-score: 0.8358For batch 130, tr_loss is    0.26.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/244 [===============>..............] - ETA: 1:41 - loss: 0.2625 - iou_score: 0.7202 - f1-score: 0.8353For batch 131, tr_loss is    0.26.\n",
      "133/244 [===============>..............] - ETA: 1:40 - loss: 0.2625 - iou_score: 0.7202 - f1-score: 0.8353For batch 132, tr_loss is    0.26.\n",
      "134/244 [===============>..............] - ETA: 1:39 - loss: 0.2632 - iou_score: 0.7193 - f1-score: 0.8346For batch 133, tr_loss is    0.26.\n",
      "135/244 [===============>..............] - ETA: 1:37 - loss: 0.2633 - iou_score: 0.7190 - f1-score: 0.8345For batch 134, tr_loss is    0.26.\n",
      "136/244 [===============>..............] - ETA: 1:37 - loss: 0.2628 - iou_score: 0.7196 - f1-score: 0.8348For batch 135, tr_loss is    0.26.\n",
      "137/244 [===============>..............] - ETA: 1:36 - loss: 0.2626 - iou_score: 0.7198 - f1-score: 0.8350For batch 136, tr_loss is    0.26.\n",
      "138/244 [===============>..............] - ETA: 1:35 - loss: 0.2629 - iou_score: 0.7194 - f1-score: 0.8347For batch 137, tr_loss is    0.26.\n",
      "139/244 [================>.............] - ETA: 1:34 - loss: 0.2630 - iou_score: 0.7193 - f1-score: 0.8347For batch 138, tr_loss is    0.26.\n",
      "140/244 [================>.............] - ETA: 1:33 - loss: 0.2630 - iou_score: 0.7193 - f1-score: 0.8347For batch 139, tr_loss is    0.26.\n",
      "141/244 [================>.............] - ETA: 1:33 - loss: 0.2630 - iou_score: 0.7192 - f1-score: 0.8346For batch 140, tr_loss is    0.26.\n",
      "142/244 [================>.............] - ETA: 1:32 - loss: 0.2630 - iou_score: 0.7189 - f1-score: 0.8344For batch 141, tr_loss is    0.26.\n",
      "143/244 [================>.............] - ETA: 1:31 - loss: 0.2628 - iou_score: 0.7193 - f1-score: 0.8347For batch 142, tr_loss is    0.26.\n",
      "144/244 [================>.............] - ETA: 1:30 - loss: 0.2633 - iou_score: 0.7187 - f1-score: 0.8342For batch 143, tr_loss is    0.26.\n",
      "145/244 [================>.............] - ETA: 1:29 - loss: 0.2635 - iou_score: 0.7184 - f1-score: 0.8340For batch 144, tr_loss is    0.26.\n",
      "146/244 [================>.............] - ETA: 1:28 - loss: 0.2635 - iou_score: 0.7182 - f1-score: 0.8339For batch 145, tr_loss is    0.26.\n",
      "147/244 [=================>............] - ETA: 1:27 - loss: 0.2633 - iou_score: 0.7182 - f1-score: 0.8339For batch 146, tr_loss is    0.26.\n",
      "148/244 [=================>............] - ETA: 1:26 - loss: 0.2635 - iou_score: 0.7179 - f1-score: 0.8337For batch 147, tr_loss is    0.26.\n",
      "149/244 [=================>............] - ETA: 1:25 - loss: 0.2637 - iou_score: 0.7177 - f1-score: 0.8336For batch 148, tr_loss is    0.26.\n",
      "150/244 [=================>............] - ETA: 1:25 - loss: 0.2635 - iou_score: 0.7178 - f1-score: 0.8337For batch 149, tr_loss is    0.26.\n",
      "151/244 [=================>............] - ETA: 1:23 - loss: 0.2636 - iou_score: 0.7178 - f1-score: 0.8336For batch 150, tr_loss is    0.26.\n",
      "152/244 [=================>............] - ETA: 1:23 - loss: 0.2639 - iou_score: 0.7175 - f1-score: 0.8335For batch 151, tr_loss is    0.26.\n",
      "153/244 [=================>............] - ETA: 1:22 - loss: 0.2637 - iou_score: 0.7177 - f1-score: 0.8336For batch 152, tr_loss is    0.26.\n",
      "154/244 [=================>............] - ETA: 1:21 - loss: 0.2637 - iou_score: 0.7176 - f1-score: 0.8336For batch 153, tr_loss is    0.26.\n",
      "155/244 [==================>...........] - ETA: 1:20 - loss: 0.2639 - iou_score: 0.7173 - f1-score: 0.8334For batch 154, tr_loss is    0.26.\n",
      "156/244 [==================>...........] - ETA: 1:19 - loss: 0.2634 - iou_score: 0.7178 - f1-score: 0.8337For batch 155, tr_loss is    0.26.\n",
      "157/244 [==================>...........] - ETA: 1:18 - loss: 0.2633 - iou_score: 0.7180 - f1-score: 0.8338For batch 156, tr_loss is    0.26.\n",
      "158/244 [==================>...........] - ETA: 1:17 - loss: 0.2635 - iou_score: 0.7178 - f1-score: 0.8337For batch 157, tr_loss is    0.26.\n",
      "159/244 [==================>...........] - ETA: 1:16 - loss: 0.2634 - iou_score: 0.7180 - f1-score: 0.8338For batch 158, tr_loss is    0.26.\n",
      "160/244 [==================>...........] - ETA: 1:15 - loss: 0.2632 - iou_score: 0.7182 - f1-score: 0.8340For batch 159, tr_loss is    0.26.\n",
      "161/244 [==================>...........] - ETA: 1:14 - loss: 0.2633 - iou_score: 0.7179 - f1-score: 0.8338For batch 160, tr_loss is    0.26.\n",
      "162/244 [==================>...........] - ETA: 1:13 - loss: 0.2631 - iou_score: 0.7181 - f1-score: 0.8339For batch 161, tr_loss is    0.26.\n",
      "163/244 [===================>..........] - ETA: 1:12 - loss: 0.2632 - iou_score: 0.7181 - f1-score: 0.8339For batch 162, tr_loss is    0.26.\n",
      "164/244 [===================>..........] - ETA: 1:12 - loss: 0.2631 - iou_score: 0.7182 - f1-score: 0.8340For batch 163, tr_loss is    0.26.\n",
      "165/244 [===================>..........] - ETA: 1:11 - loss: 0.2634 - iou_score: 0.7180 - f1-score: 0.8339For batch 164, tr_loss is    0.26.\n",
      "166/244 [===================>..........] - ETA: 1:10 - loss: 0.2634 - iou_score: 0.7179 - f1-score: 0.8338For batch 165, tr_loss is    0.26.\n",
      "167/244 [===================>..........] - ETA: 1:09 - loss: 0.2633 - iou_score: 0.7182 - f1-score: 0.8340For batch 166, tr_loss is    0.26.\n",
      "168/244 [===================>..........] - ETA: 1:08 - loss: 0.2628 - iou_score: 0.7186 - f1-score: 0.8343For batch 167, tr_loss is    0.26.\n",
      "169/244 [===================>..........] - ETA: 1:07 - loss: 0.2626 - iou_score: 0.7189 - f1-score: 0.8345For batch 168, tr_loss is    0.26.\n",
      "170/244 [===================>..........] - ETA: 1:06 - loss: 0.2631 - iou_score: 0.7185 - f1-score: 0.8342For batch 169, tr_loss is    0.26.\n",
      "171/244 [====================>.........] - ETA: 1:05 - loss: 0.2627 - iou_score: 0.7189 - f1-score: 0.8345For batch 170, tr_loss is    0.26.\n",
      "172/244 [====================>.........] - ETA: 1:04 - loss: 0.2627 - iou_score: 0.7188 - f1-score: 0.8345For batch 171, tr_loss is    0.26.\n",
      "173/244 [====================>.........] - ETA: 1:03 - loss: 0.2630 - iou_score: 0.7186 - f1-score: 0.8343For batch 172, tr_loss is    0.26.\n",
      "174/244 [====================>.........] - ETA: 1:02 - loss: 0.2633 - iou_score: 0.7181 - f1-score: 0.8340For batch 173, tr_loss is    0.26.\n",
      "175/244 [====================>.........] - ETA: 1:01 - loss: 0.2635 - iou_score: 0.7178 - f1-score: 0.8337For batch 174, tr_loss is    0.26.\n",
      "176/244 [====================>.........] - ETA: 1:01 - loss: 0.2633 - iou_score: 0.7179 - f1-score: 0.8338For batch 175, tr_loss is    0.26.\n",
      "177/244 [====================>.........] - ETA: 1:00 - loss: 0.2630 - iou_score: 0.7182 - f1-score: 0.8340For batch 176, tr_loss is    0.26.\n",
      "178/244 [====================>.........] - ETA: 59s - loss: 0.2632 - iou_score: 0.7179 - f1-score: 0.8338 For batch 177, tr_loss is    0.26.\n",
      "179/244 [=====================>........] - ETA: 58s - loss: 0.2631 - iou_score: 0.7179 - f1-score: 0.8338For batch 178, tr_loss is    0.26.\n",
      "180/244 [=====================>........] - ETA: 57s - loss: 0.2631 - iou_score: 0.7179 - f1-score: 0.8338For batch 179, tr_loss is    0.26.\n",
      "181/244 [=====================>........] - ETA: 56s - loss: 0.2629 - iou_score: 0.7182 - f1-score: 0.8340For batch 180, tr_loss is    0.26.\n",
      "182/244 [=====================>........] - ETA: 55s - loss: 0.2630 - iou_score: 0.7180 - f1-score: 0.8339For batch 181, tr_loss is    0.26.\n",
      "183/244 [=====================>........] - ETA: 54s - loss: 0.2632 - iou_score: 0.7179 - f1-score: 0.8338For batch 182, tr_loss is    0.26.\n",
      "184/244 [=====================>........] - ETA: 53s - loss: 0.2635 - iou_score: 0.7175 - f1-score: 0.8336For batch 183, tr_loss is    0.26.\n",
      "185/244 [=====================>........] - ETA: 52s - loss: 0.2636 - iou_score: 0.7175 - f1-score: 0.8336For batch 184, tr_loss is    0.26.\n",
      "186/244 [=====================>........] - ETA: 51s - loss: 0.2633 - iou_score: 0.7179 - f1-score: 0.8338For batch 185, tr_loss is    0.26.\n",
      "187/244 [=====================>........] - ETA: 50s - loss: 0.2636 - iou_score: 0.7176 - f1-score: 0.8337For batch 186, tr_loss is    0.26.\n",
      "188/244 [======================>.......] - ETA: 49s - loss: 0.2635 - iou_score: 0.7176 - f1-score: 0.8337For batch 187, tr_loss is    0.26.\n",
      "189/244 [======================>.......] - ETA: 48s - loss: 0.2634 - iou_score: 0.7177 - f1-score: 0.8337For batch 188, tr_loss is    0.26.\n",
      "190/244 [======================>.......] - ETA: 47s - loss: 0.2631 - iou_score: 0.7182 - f1-score: 0.8340For batch 189, tr_loss is    0.26.\n",
      "191/244 [======================>.......] - ETA: 47s - loss: 0.2628 - iou_score: 0.7184 - f1-score: 0.8342For batch 190, tr_loss is    0.26.\n",
      "192/244 [======================>.......] - ETA: 46s - loss: 0.2628 - iou_score: 0.7183 - f1-score: 0.8341For batch 191, tr_loss is    0.26.\n",
      "193/244 [======================>.......] - ETA: 45s - loss: 0.2628 - iou_score: 0.7182 - f1-score: 0.8340For batch 192, tr_loss is    0.26.\n",
      "194/244 [======================>.......] - ETA: 44s - loss: 0.2625 - iou_score: 0.7184 - f1-score: 0.8342For batch 193, tr_loss is    0.26.\n",
      "195/244 [======================>.......] - ETA: 43s - loss: 0.2627 - iou_score: 0.7184 - f1-score: 0.8342For batch 194, tr_loss is    0.26.\n",
      "196/244 [=======================>......] - ETA: 42s - loss: 0.2626 - iou_score: 0.7185 - f1-score: 0.8343For batch 195, tr_loss is    0.26.\n",
      "197/244 [=======================>......] - ETA: 41s - loss: 0.2628 - iou_score: 0.7182 - f1-score: 0.8341For batch 196, tr_loss is    0.26.\n",
      "198/244 [=======================>......] - ETA: 40s - loss: 0.2627 - iou_score: 0.7183 - f1-score: 0.8342For batch 197, tr_loss is    0.26.\n",
      "199/244 [=======================>......] - ETA: 39s - loss: 0.2623 - iou_score: 0.7189 - f1-score: 0.8346For batch 198, tr_loss is    0.26.\n",
      "200/244 [=======================>......] - ETA: 39s - loss: 0.2623 - iou_score: 0.7191 - f1-score: 0.8347For batch 199, tr_loss is    0.26.\n",
      "201/244 [=======================>......] - ETA: 38s - loss: 0.2625 - iou_score: 0.7188 - f1-score: 0.8345For batch 200, tr_loss is    0.26.\n",
      "202/244 [=======================>......] - ETA: 37s - loss: 0.2623 - iou_score: 0.7190 - f1-score: 0.8346For batch 201, tr_loss is    0.26.\n",
      "203/244 [=======================>......] - ETA: 36s - loss: 0.2623 - iou_score: 0.7190 - f1-score: 0.8346For batch 202, tr_loss is    0.26.\n",
      "204/244 [========================>.....] - ETA: 35s - loss: 0.2620 - iou_score: 0.7194 - f1-score: 0.8349For batch 203, tr_loss is    0.26.\n",
      "205/244 [========================>.....] - ETA: 34s - loss: 0.2616 - iou_score: 0.7197 - f1-score: 0.8351For batch 204, tr_loss is    0.26.\n",
      "206/244 [========================>.....] - ETA: 33s - loss: 0.2620 - iou_score: 0.7194 - f1-score: 0.8349For batch 205, tr_loss is    0.26.\n",
      "207/244 [========================>.....] - ETA: 32s - loss: 0.2618 - iou_score: 0.7197 - f1-score: 0.8351For batch 206, tr_loss is    0.26.\n",
      "208/244 [========================>.....] - ETA: 31s - loss: 0.2619 - iou_score: 0.7194 - f1-score: 0.8349For batch 207, tr_loss is    0.26.\n",
      "209/244 [========================>.....] - ETA: 30s - loss: 0.2617 - iou_score: 0.7195 - f1-score: 0.8350For batch 208, tr_loss is    0.26.\n",
      "210/244 [========================>.....] - ETA: 29s - loss: 0.2615 - iou_score: 0.7197 - f1-score: 0.8351For batch 209, tr_loss is    0.26.\n",
      "211/244 [========================>.....] - ETA: 29s - loss: 0.2615 - iou_score: 0.7198 - f1-score: 0.8351For batch 210, tr_loss is    0.26.\n",
      "212/244 [=========================>....] - ETA: 28s - loss: 0.2616 - iou_score: 0.7196 - f1-score: 0.8351For batch 211, tr_loss is    0.26.\n",
      "213/244 [=========================>....] - ETA: 27s - loss: 0.2617 - iou_score: 0.7195 - f1-score: 0.8350For batch 212, tr_loss is    0.26.\n",
      "214/244 [=========================>....] - ETA: 26s - loss: 0.2614 - iou_score: 0.7200 - f1-score: 0.8353For batch 213, tr_loss is    0.26.\n",
      "215/244 [=========================>....] - ETA: 25s - loss: 0.2613 - iou_score: 0.7202 - f1-score: 0.8354For batch 214, tr_loss is    0.26.\n",
      "216/244 [=========================>....] - ETA: 24s - loss: 0.2613 - iou_score: 0.7201 - f1-score: 0.8354For batch 215, tr_loss is    0.26.\n",
      "217/244 [=========================>....] - ETA: 23s - loss: 0.2614 - iou_score: 0.7201 - f1-score: 0.8354For batch 216, tr_loss is    0.26.\n",
      "218/244 [=========================>....] - ETA: 23s - loss: 0.2613 - iou_score: 0.7202 - f1-score: 0.8354For batch 217, tr_loss is    0.26.\n",
      "219/244 [=========================>....] - ETA: 22s - loss: 0.2611 - iou_score: 0.7203 - f1-score: 0.8355For batch 218, tr_loss is    0.26.\n",
      "220/244 [==========================>...] - ETA: 21s - loss: 0.2611 - iou_score: 0.7203 - f1-score: 0.8355For batch 219, tr_loss is    0.26.\n",
      "221/244 [==========================>...] - ETA: 20s - loss: 0.2612 - iou_score: 0.7203 - f1-score: 0.8355For batch 220, tr_loss is    0.26.\n",
      "222/244 [==========================>...] - ETA: 19s - loss: 0.2608 - iou_score: 0.7207 - f1-score: 0.8358For batch 221, tr_loss is    0.26.\n",
      "223/244 [==========================>...] - ETA: 18s - loss: 0.2607 - iou_score: 0.7207 - f1-score: 0.8358For batch 222, tr_loss is    0.26.\n",
      "224/244 [==========================>...] - ETA: 17s - loss: 0.2607 - iou_score: 0.7207 - f1-score: 0.8358For batch 223, tr_loss is    0.26.\n",
      "225/244 [==========================>...] - ETA: 16s - loss: 0.2606 - iou_score: 0.7207 - f1-score: 0.8358For batch 224, tr_loss is    0.26.\n",
      "226/244 [==========================>...] - ETA: 15s - loss: 0.2604 - iou_score: 0.7209 - f1-score: 0.8359For batch 225, tr_loss is    0.26.\n",
      "227/244 [==========================>...] - ETA: 14s - loss: 0.2604 - iou_score: 0.7210 - f1-score: 0.8360For batch 226, tr_loss is    0.26.\n",
      "228/244 [===========================>..] - ETA: 14s - loss: 0.2602 - iou_score: 0.7212 - f1-score: 0.8361For batch 227, tr_loss is    0.26.\n",
      "229/244 [===========================>..] - ETA: 13s - loss: 0.2600 - iou_score: 0.7215 - f1-score: 0.8363For batch 228, tr_loss is    0.26.\n",
      "230/244 [===========================>..] - ETA: 12s - loss: 0.2598 - iou_score: 0.7216 - f1-score: 0.8364For batch 229, tr_loss is    0.26.\n",
      "231/244 [===========================>..] - ETA: 11s - loss: 0.2597 - iou_score: 0.7218 - f1-score: 0.8366For batch 230, tr_loss is    0.26.\n",
      "232/244 [===========================>..] - ETA: 10s - loss: 0.2598 - iou_score: 0.7218 - f1-score: 0.8365For batch 231, tr_loss is    0.26.\n",
      "233/244 [===========================>..] - ETA: 9s - loss: 0.2605 - iou_score: 0.7212 - f1-score: 0.8361 For batch 232, tr_loss is    0.26.\n",
      "234/244 [===========================>..] - ETA: 8s - loss: 0.2604 - iou_score: 0.7211 - f1-score: 0.8361For batch 233, tr_loss is    0.26.\n",
      "235/244 [===========================>..] - ETA: 7s - loss: 0.2602 - iou_score: 0.7214 - f1-score: 0.8363For batch 234, tr_loss is    0.26.\n",
      "236/244 [============================>.] - ETA: 7s - loss: 0.2603 - iou_score: 0.7213 - f1-score: 0.8362For batch 235, tr_loss is    0.26.\n",
      "237/244 [============================>.] - ETA: 6s - loss: 0.2604 - iou_score: 0.7213 - f1-score: 0.8362For batch 236, tr_loss is    0.26.\n",
      "238/244 [============================>.] - ETA: 5s - loss: 0.2602 - iou_score: 0.7215 - f1-score: 0.8363For batch 237, tr_loss is    0.26.\n",
      "239/244 [============================>.] - ETA: 4s - loss: 0.2601 - iou_score: 0.7216 - f1-score: 0.8364For batch 238, tr_loss is    0.26.\n",
      "240/244 [============================>.] - ETA: 3s - loss: 0.2598 - iou_score: 0.7220 - f1-score: 0.8367For batch 239, tr_loss is    0.26.\n",
      "241/244 [============================>.] - ETA: 2s - loss: 0.2598 - iou_score: 0.7220 - f1-score: 0.8366For batch 240, tr_loss is    0.26.\n",
      "242/244 [============================>.] - ETA: 1s - loss: 0.2601 - iou_score: 0.7216 - f1-score: 0.8364For batch 241, tr_loss is    0.26.\n",
      "243/244 [============================>.] - ETA: 0s - loss: 0.2605 - iou_score: 0.7212 - f1-score: 0.8361For batch 242, tr_loss is    0.26.\n",
      "244/244 [==============================] - ETA: 0s - loss: 0.2605 - iou_score: 0.7212 - f1-score: 0.8361For batch 243, tr_loss is    0.26.\n",
      "For batch 0, vl_loss is    0.35.\n",
      "For batch 1, vl_loss is    0.33.\n",
      "For batch 2, vl_loss is    0.31.\n",
      "For batch 3, vl_loss is    0.36.\n",
      "For batch 4, vl_loss is    0.35.\n",
      "For batch 5, vl_loss is    0.35.\n",
      "For batch 6, vl_loss is    0.37.\n",
      "For batch 7, vl_loss is    0.37.\n",
      "For batch 8, vl_loss is    0.36.\n",
      "For batch 9, vl_loss is    0.36.\n",
      "For batch 10, vl_loss is    0.37.\n",
      "For batch 11, vl_loss is    0.38.\n",
      "For batch 12, vl_loss is    0.37.\n",
      "For batch 13, vl_loss is    0.37.\n",
      "For batch 14, vl_loss is    0.38.\n",
      "For batch 15, vl_loss is    0.38.\n",
      "For batch 16, vl_loss is    0.37.\n",
      "For batch 17, vl_loss is    0.37.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 18, vl_loss is    0.37.\n",
      "For batch 19, vl_loss is    0.37.\n",
      "For batch 20, vl_loss is    0.37.\n",
      "For batch 21, vl_loss is    0.37.\n",
      "For batch 22, vl_loss is    0.37.\n",
      "For batch 23, vl_loss is    0.37.\n",
      "For batch 24, vl_loss is    0.37.\n",
      "For batch 25, vl_loss is    0.37.\n",
      "For batch 26, vl_loss is    0.37.\n",
      "For batch 27, vl_loss is    0.37.\n",
      "For batch 28, vl_loss is    0.37.\n",
      "For batch 29, vl_loss is    0.38.\n",
      "For batch 30, vl_loss is    0.38.\n",
      "For batch 31, vl_loss is    0.38.\n",
      "For batch 32, vl_loss is    0.37.\n",
      "For batch 33, vl_loss is    0.38.\n",
      "For batch 34, vl_loss is    0.37.\n",
      "For batch 35, vl_loss is    0.37.\n",
      "For batch 36, vl_loss is    0.37.\n",
      "For batch 37, vl_loss is    0.38.\n",
      "For batch 38, vl_loss is    0.37.\n",
      "For batch 39, vl_loss is    0.37.\n",
      "For batch 40, vl_loss is    0.38.\n",
      "For batch 41, vl_loss is    0.38.\n",
      "For batch 42, vl_loss is    0.38.\n",
      "For batch 43, vl_loss is    0.37.\n",
      "For batch 44, vl_loss is    0.37.\n",
      "For batch 45, vl_loss is    0.37.\n",
      "For batch 46, vl_loss is    0.37.\n",
      "For batch 47, vl_loss is    0.37.\n",
      "For batch 48, vl_loss is    0.37.\n",
      "For batch 49, vl_loss is    0.37.\n",
      "For batch 50, vl_loss is    0.37.\n",
      "For batch 51, vl_loss is    0.37.\n",
      "For batch 52, vl_loss is    0.37.\n",
      "For batch 53, vl_loss is    0.37.\n",
      "For batch 54, vl_loss is    0.37.\n",
      "For batch 55, vl_loss is    0.37.\n",
      "244/244 [==============================] - 216s 881ms/step - loss: 0.2605 - iou_score: 0.7212 - f1-score: 0.8361 - val_loss: 0.3682 - val_iou_score: 0.6252 - val_f1-score: 0.7670\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.34998\n",
      "The average loss for epoch 10 is    0.26 \n",
      "Epoch 12/200\n",
      "  1/244 [..............................] - ETA: 10:00 - loss: 0.2867 - iou_score: 0.6741 - f1-score: 0.8035For batch 0, tr_loss is    0.29.\n",
      "  2/244 [..............................] - ETA: 5:23 - loss: 0.2730 - iou_score: 0.6987 - f1-score: 0.8214 For batch 1, tr_loss is    0.27.\n",
      "  3/244 [..............................] - ETA: 5:14 - loss: 0.2674 - iou_score: 0.7184 - f1-score: 0.8350For batch 2, tr_loss is    0.27.\n",
      "  4/244 [..............................] - ETA: 5:16 - loss: 0.2755 - iou_score: 0.7182 - f1-score: 0.8351For batch 3, tr_loss is    0.28.\n",
      "  5/244 [..............................] - ETA: 5:00 - loss: 0.2801 - iou_score: 0.7101 - f1-score: 0.8293For batch 4, tr_loss is    0.28.\n",
      "  6/244 [..............................] - ETA: 4:50 - loss: 0.2866 - iou_score: 0.7031 - f1-score: 0.8246For batch 5, tr_loss is    0.29.\n",
      "  7/244 [..............................] - ETA: 4:51 - loss: 0.2863 - iou_score: 0.7070 - f1-score: 0.8268For batch 6, tr_loss is    0.29.\n",
      "  8/244 [..............................] - ETA: 4:50 - loss: 0.2920 - iou_score: 0.6972 - f1-score: 0.8195For batch 7, tr_loss is    0.29.\n",
      "  9/244 [>.............................] - ETA: 4:58 - loss: 0.2925 - iou_score: 0.6947 - f1-score: 0.8178For batch 8, tr_loss is    0.29.\n",
      " 10/244 [>.............................] - ETA: 4:53 - loss: 0.2859 - iou_score: 0.7018 - f1-score: 0.8228For batch 9, tr_loss is    0.29.\n",
      " 11/244 [>.............................] - ETA: 4:45 - loss: 0.2811 - iou_score: 0.7082 - f1-score: 0.8271For batch 10, tr_loss is    0.28.\n",
      " 12/244 [>.............................] - ETA: 4:38 - loss: 0.2783 - iou_score: 0.7111 - f1-score: 0.8292For batch 11, tr_loss is    0.28.\n",
      " 13/244 [>.............................] - ETA: 4:24 - loss: 0.2749 - iou_score: 0.7147 - f1-score: 0.8317For batch 12, tr_loss is    0.27.\n",
      " 14/244 [>.............................] - ETA: 4:23 - loss: 0.2794 - iou_score: 0.7092 - f1-score: 0.8279For batch 13, tr_loss is    0.28.\n",
      " 15/244 [>.............................] - ETA: 4:20 - loss: 0.2807 - iou_score: 0.7064 - f1-score: 0.8260For batch 14, tr_loss is    0.28.\n",
      " 16/244 [>.............................] - ETA: 4:18 - loss: 0.2805 - iou_score: 0.7069 - f1-score: 0.8264For batch 15, tr_loss is    0.28.\n",
      " 17/244 [=>............................] - ETA: 4:07 - loss: 0.2760 - iou_score: 0.7126 - f1-score: 0.8302For batch 16, tr_loss is    0.28.\n",
      " 18/244 [=>............................] - ETA: 4:08 - loss: 0.2777 - iou_score: 0.7115 - f1-score: 0.8296For batch 17, tr_loss is    0.28.\n",
      " 19/244 [=>............................] - ETA: 4:07 - loss: 0.2752 - iou_score: 0.7148 - f1-score: 0.8318For batch 18, tr_loss is    0.28.\n",
      " 20/244 [=>............................] - ETA: 4:03 - loss: 0.2743 - iou_score: 0.7151 - f1-score: 0.8319For batch 19, tr_loss is    0.27.\n",
      " 21/244 [=>............................] - ETA: 3:57 - loss: 0.2739 - iou_score: 0.7142 - f1-score: 0.8314For batch 20, tr_loss is    0.27.\n",
      " 22/244 [=>............................] - ETA: 3:52 - loss: 0.2783 - iou_score: 0.7102 - f1-score: 0.8286For batch 21, tr_loss is    0.28.\n",
      " 23/244 [=>............................] - ETA: 3:48 - loss: 0.2774 - iou_score: 0.7101 - f1-score: 0.8285For batch 22, tr_loss is    0.28.\n",
      " 24/244 [=>............................] - ETA: 3:43 - loss: 0.2756 - iou_score: 0.7126 - f1-score: 0.8303For batch 23, tr_loss is    0.28.\n",
      " 25/244 [==>...........................] - ETA: 3:42 - loss: 0.2763 - iou_score: 0.7111 - f1-score: 0.8292For batch 24, tr_loss is    0.28.\n",
      " 26/244 [==>...........................] - ETA: 3:36 - loss: 0.2759 - iou_score: 0.7107 - f1-score: 0.8290For batch 25, tr_loss is    0.28.\n",
      " 27/244 [==>...........................] - ETA: 3:36 - loss: 0.2756 - iou_score: 0.7116 - f1-score: 0.8297For batch 26, tr_loss is    0.28.\n",
      " 28/244 [==>...........................] - ETA: 3:32 - loss: 0.2723 - iou_score: 0.7160 - f1-score: 0.8325For batch 27, tr_loss is    0.27.\n",
      " 29/244 [==>...........................] - ETA: 3:28 - loss: 0.2702 - iou_score: 0.7175 - f1-score: 0.8336For batch 28, tr_loss is    0.27.\n",
      " 30/244 [==>...........................] - ETA: 3:28 - loss: 0.2675 - iou_score: 0.7203 - f1-score: 0.8355For batch 29, tr_loss is    0.27.\n",
      " 31/244 [==>...........................] - ETA: 3:27 - loss: 0.2670 - iou_score: 0.7216 - f1-score: 0.8363For batch 30, tr_loss is    0.27.\n",
      " 32/244 [==>...........................] - ETA: 3:25 - loss: 0.2655 - iou_score: 0.7234 - f1-score: 0.8376For batch 31, tr_loss is    0.27.\n",
      " 33/244 [===>..........................] - ETA: 3:22 - loss: 0.2648 - iou_score: 0.7236 - f1-score: 0.8378For batch 32, tr_loss is    0.26.\n",
      " 34/244 [===>..........................] - ETA: 3:22 - loss: 0.2650 - iou_score: 0.7231 - f1-score: 0.8375For batch 33, tr_loss is    0.27.\n",
      " 35/244 [===>..........................] - ETA: 3:18 - loss: 0.2654 - iou_score: 0.7225 - f1-score: 0.8372For batch 34, tr_loss is    0.27.\n",
      " 36/244 [===>..........................] - ETA: 3:18 - loss: 0.2639 - iou_score: 0.7240 - f1-score: 0.8382For batch 35, tr_loss is    0.26.\n",
      " 37/244 [===>..........................] - ETA: 3:14 - loss: 0.2647 - iou_score: 0.7228 - f1-score: 0.8373For batch 36, tr_loss is    0.26.\n",
      " 38/244 [===>..........................] - ETA: 3:15 - loss: 0.2635 - iou_score: 0.7241 - f1-score: 0.8383For batch 37, tr_loss is    0.26.\n",
      " 39/244 [===>..........................] - ETA: 3:11 - loss: 0.2620 - iou_score: 0.7258 - f1-score: 0.8394For batch 38, tr_loss is    0.26.\n",
      " 40/244 [===>..........................] - ETA: 3:09 - loss: 0.2619 - iou_score: 0.7254 - f1-score: 0.8391For batch 39, tr_loss is    0.26.\n",
      " 41/244 [====>.........................] - ETA: 3:09 - loss: 0.2625 - iou_score: 0.7241 - f1-score: 0.8383For batch 40, tr_loss is    0.26.\n",
      " 42/244 [====>.........................] - ETA: 3:08 - loss: 0.2614 - iou_score: 0.7250 - f1-score: 0.8389For batch 41, tr_loss is    0.26.\n",
      " 43/244 [====>.........................] - ETA: 3:06 - loss: 0.2624 - iou_score: 0.7238 - f1-score: 0.8381For batch 42, tr_loss is    0.26.\n",
      " 44/244 [====>.........................] - ETA: 3:04 - loss: 0.2615 - iou_score: 0.7248 - f1-score: 0.8388For batch 43, tr_loss is    0.26.\n",
      " 45/244 [====>.........................] - ETA: 3:04 - loss: 0.2619 - iou_score: 0.7242 - f1-score: 0.8384For batch 44, tr_loss is    0.26.\n",
      " 46/244 [====>.........................] - ETA: 3:03 - loss: 0.2616 - iou_score: 0.7242 - f1-score: 0.8384For batch 45, tr_loss is    0.26.\n",
      " 47/244 [====>.........................] - ETA: 3:01 - loss: 0.2604 - iou_score: 0.7253 - f1-score: 0.8392For batch 46, tr_loss is    0.26.\n",
      " 48/244 [====>.........................] - ETA: 2:59 - loss: 0.2593 - iou_score: 0.7261 - f1-score: 0.8397For batch 47, tr_loss is    0.26.\n",
      " 49/244 [=====>........................] - ETA: 2:57 - loss: 0.2602 - iou_score: 0.7250 - f1-score: 0.8389For batch 48, tr_loss is    0.26.\n",
      " 50/244 [=====>........................] - ETA: 2:57 - loss: 0.2601 - iou_score: 0.7246 - f1-score: 0.8387For batch 49, tr_loss is    0.26.\n",
      " 51/244 [=====>........................] - ETA: 2:54 - loss: 0.2610 - iou_score: 0.7234 - f1-score: 0.8379For batch 50, tr_loss is    0.26.\n",
      " 52/244 [=====>........................] - ETA: 2:53 - loss: 0.2610 - iou_score: 0.7229 - f1-score: 0.8375For batch 51, tr_loss is    0.26.\n",
      " 53/244 [=====>........................] - ETA: 2:53 - loss: 0.2610 - iou_score: 0.7228 - f1-score: 0.8375For batch 52, tr_loss is    0.26.\n",
      " 54/244 [=====>........................] - ETA: 2:50 - loss: 0.2609 - iou_score: 0.7225 - f1-score: 0.8373For batch 53, tr_loss is    0.26.\n",
      " 55/244 [=====>........................] - ETA: 2:49 - loss: 0.2598 - iou_score: 0.7236 - f1-score: 0.8381For batch 54, tr_loss is    0.26.\n",
      " 56/244 [=====>........................] - ETA: 2:48 - loss: 0.2588 - iou_score: 0.7246 - f1-score: 0.8387For batch 55, tr_loss is    0.26.\n",
      " 57/244 [======>.......................] - ETA: 2:45 - loss: 0.2599 - iou_score: 0.7239 - f1-score: 0.8382For batch 56, tr_loss is    0.26.\n",
      " 58/244 [======>.......................] - ETA: 2:45 - loss: 0.2609 - iou_score: 0.7229 - f1-score: 0.8376For batch 57, tr_loss is    0.26.\n",
      " 59/244 [======>.......................] - ETA: 2:43 - loss: 0.2592 - iou_score: 0.7253 - f1-score: 0.8391For batch 58, tr_loss is    0.26.\n",
      " 60/244 [======>.......................] - ETA: 2:43 - loss: 0.2601 - iou_score: 0.7236 - f1-score: 0.8379For batch 59, tr_loss is    0.26.\n",
      " 61/244 [======>.......................] - ETA: 2:43 - loss: 0.2611 - iou_score: 0.7220 - f1-score: 0.8368For batch 60, tr_loss is    0.26.\n",
      " 62/244 [======>.......................] - ETA: 2:41 - loss: 0.2608 - iou_score: 0.7220 - f1-score: 0.8368For batch 61, tr_loss is    0.26.\n",
      " 63/244 [======>.......................] - ETA: 2:41 - loss: 0.2612 - iou_score: 0.7216 - f1-score: 0.8365For batch 62, tr_loss is    0.26.\n",
      " 64/244 [======>.......................] - ETA: 2:41 - loss: 0.2607 - iou_score: 0.7223 - f1-score: 0.8370For batch 63, tr_loss is    0.26.\n",
      " 65/244 [======>.......................] - ETA: 2:40 - loss: 0.2607 - iou_score: 0.7220 - f1-score: 0.8368For batch 64, tr_loss is    0.26.\n",
      " 66/244 [=======>......................] - ETA: 2:40 - loss: 0.2607 - iou_score: 0.7221 - f1-score: 0.8369For batch 65, tr_loss is    0.26.\n",
      " 67/244 [=======>......................] - ETA: 2:37 - loss: 0.2603 - iou_score: 0.7227 - f1-score: 0.8373For batch 66, tr_loss is    0.26.\n",
      " 68/244 [=======>......................] - ETA: 2:37 - loss: 0.2600 - iou_score: 0.7233 - f1-score: 0.8377For batch 67, tr_loss is    0.26.\n",
      " 69/244 [=======>......................] - ETA: 2:37 - loss: 0.2607 - iou_score: 0.7220 - f1-score: 0.8368For batch 68, tr_loss is    0.26.\n",
      " 70/244 [=======>......................] - ETA: 2:36 - loss: 0.2603 - iou_score: 0.7222 - f1-score: 0.8369For batch 69, tr_loss is    0.26.\n",
      " 71/244 [=======>......................] - ETA: 2:35 - loss: 0.2603 - iou_score: 0.7221 - f1-score: 0.8369For batch 70, tr_loss is    0.26.\n",
      " 72/244 [=======>......................] - ETA: 2:33 - loss: 0.2596 - iou_score: 0.7229 - f1-score: 0.8374For batch 71, tr_loss is    0.26.\n",
      " 73/244 [=======>......................] - ETA: 2:32 - loss: 0.2604 - iou_score: 0.7222 - f1-score: 0.8369For batch 72, tr_loss is    0.26.\n",
      " 74/244 [========>.....................] - ETA: 2:31 - loss: 0.2607 - iou_score: 0.7218 - f1-score: 0.8366For batch 73, tr_loss is    0.26.\n",
      " 75/244 [========>.....................] - ETA: 2:30 - loss: 0.2605 - iou_score: 0.7217 - f1-score: 0.8365For batch 74, tr_loss is    0.26.\n",
      " 76/244 [========>.....................] - ETA: 2:29 - loss: 0.2594 - iou_score: 0.7232 - f1-score: 0.8375For batch 75, tr_loss is    0.26.\n",
      " 77/244 [========>.....................] - ETA: 2:27 - loss: 0.2590 - iou_score: 0.7236 - f1-score: 0.8377For batch 76, tr_loss is    0.26.\n",
      " 78/244 [========>.....................] - ETA: 2:27 - loss: 0.2589 - iou_score: 0.7239 - f1-score: 0.8380For batch 77, tr_loss is    0.26.\n",
      " 79/244 [========>.....................] - ETA: 2:25 - loss: 0.2587 - iou_score: 0.7243 - f1-score: 0.8382For batch 78, tr_loss is    0.26.\n",
      " 80/244 [========>.....................] - ETA: 2:25 - loss: 0.2584 - iou_score: 0.7244 - f1-score: 0.8383For batch 79, tr_loss is    0.26.\n",
      " 81/244 [========>.....................] - ETA: 2:23 - loss: 0.2588 - iou_score: 0.7240 - f1-score: 0.8380For batch 80, tr_loss is    0.26.\n",
      " 82/244 [=========>....................] - ETA: 2:22 - loss: 0.2603 - iou_score: 0.7222 - f1-score: 0.8367For batch 81, tr_loss is    0.26.\n",
      " 83/244 [=========>....................] - ETA: 2:21 - loss: 0.2596 - iou_score: 0.7230 - f1-score: 0.8372For batch 82, tr_loss is    0.26.\n",
      " 84/244 [=========>....................] - ETA: 2:20 - loss: 0.2594 - iou_score: 0.7231 - f1-score: 0.8374For batch 83, tr_loss is    0.26.\n",
      " 85/244 [=========>....................] - ETA: 2:19 - loss: 0.2588 - iou_score: 0.7238 - f1-score: 0.8378For batch 84, tr_loss is    0.26.\n",
      " 86/244 [=========>....................] - ETA: 2:18 - loss: 0.2594 - iou_score: 0.7233 - f1-score: 0.8375For batch 85, tr_loss is    0.26.\n",
      " 87/244 [=========>....................] - ETA: 2:17 - loss: 0.2593 - iou_score: 0.7236 - f1-score: 0.8377For batch 86, tr_loss is    0.26.\n",
      " 88/244 [=========>....................] - ETA: 2:16 - loss: 0.2587 - iou_score: 0.7243 - f1-score: 0.8381For batch 87, tr_loss is    0.26.\n",
      " 89/244 [=========>....................] - ETA: 2:16 - loss: 0.2589 - iou_score: 0.7237 - f1-score: 0.8377For batch 88, tr_loss is    0.26.\n",
      " 90/244 [==========>...................] - ETA: 2:15 - loss: 0.2587 - iou_score: 0.7239 - f1-score: 0.8379For batch 89, tr_loss is    0.26.\n",
      " 91/244 [==========>...................] - ETA: 2:15 - loss: 0.2594 - iou_score: 0.7227 - f1-score: 0.8371For batch 90, tr_loss is    0.26.\n",
      " 92/244 [==========>...................] - ETA: 2:14 - loss: 0.2600 - iou_score: 0.7218 - f1-score: 0.8364For batch 91, tr_loss is    0.26.\n",
      " 93/244 [==========>...................] - ETA: 2:13 - loss: 0.2593 - iou_score: 0.7227 - f1-score: 0.8370For batch 92, tr_loss is    0.26.\n",
      " 94/244 [==========>...................] - ETA: 2:13 - loss: 0.2588 - iou_score: 0.7233 - f1-score: 0.8374For batch 93, tr_loss is    0.26.\n",
      " 95/244 [==========>...................] - ETA: 2:12 - loss: 0.2589 - iou_score: 0.7231 - f1-score: 0.8372For batch 94, tr_loss is    0.26.\n",
      " 96/244 [==========>...................] - ETA: 2:11 - loss: 0.2592 - iou_score: 0.7225 - f1-score: 0.8368For batch 95, tr_loss is    0.26.\n",
      " 97/244 [==========>...................] - ETA: 2:10 - loss: 0.2590 - iou_score: 0.7229 - f1-score: 0.8371For batch 96, tr_loss is    0.26.\n",
      " 98/244 [===========>..................] - ETA: 2:09 - loss: 0.2590 - iou_score: 0.7227 - f1-score: 0.8370For batch 97, tr_loss is    0.26.\n",
      " 99/244 [===========>..................] - ETA: 2:08 - loss: 0.2591 - iou_score: 0.7230 - f1-score: 0.8372For batch 98, tr_loss is    0.26.\n",
      "100/244 [===========>..................] - ETA: 2:07 - loss: 0.2584 - iou_score: 0.7237 - f1-score: 0.8377For batch 99, tr_loss is    0.26.\n",
      "101/244 [===========>..................] - ETA: 2:06 - loss: 0.2584 - iou_score: 0.7237 - f1-score: 0.8377For batch 100, tr_loss is    0.26.\n",
      "102/244 [===========>..................] - ETA: 2:05 - loss: 0.2583 - iou_score: 0.7238 - f1-score: 0.8377For batch 101, tr_loss is    0.26.\n",
      "103/244 [===========>..................] - ETA: 2:05 - loss: 0.2579 - iou_score: 0.7241 - f1-score: 0.8380For batch 102, tr_loss is    0.26.\n",
      "104/244 [===========>..................] - ETA: 2:03 - loss: 0.2574 - iou_score: 0.7246 - f1-score: 0.8383For batch 103, tr_loss is    0.26.\n",
      "105/244 [===========>..................] - ETA: 2:02 - loss: 0.2576 - iou_score: 0.7242 - f1-score: 0.8380For batch 104, tr_loss is    0.26.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/244 [============>.................] - ETA: 2:02 - loss: 0.2568 - iou_score: 0.7252 - f1-score: 0.8387For batch 105, tr_loss is    0.26.\n",
      "107/244 [============>.................] - ETA: 2:00 - loss: 0.2563 - iou_score: 0.7258 - f1-score: 0.8391For batch 106, tr_loss is    0.26.\n",
      "108/244 [============>.................] - ETA: 1:59 - loss: 0.2565 - iou_score: 0.7255 - f1-score: 0.8389For batch 107, tr_loss is    0.26.\n",
      "109/244 [============>.................] - ETA: 1:58 - loss: 0.2566 - iou_score: 0.7248 - f1-score: 0.8385For batch 108, tr_loss is    0.26.\n",
      "110/244 [============>.................] - ETA: 1:57 - loss: 0.2567 - iou_score: 0.7248 - f1-score: 0.8384For batch 109, tr_loss is    0.26.\n",
      "111/244 [============>.................] - ETA: 1:57 - loss: 0.2568 - iou_score: 0.7244 - f1-score: 0.8382For batch 110, tr_loss is    0.26.\n",
      "112/244 [============>.................] - ETA: 1:56 - loss: 0.2569 - iou_score: 0.7243 - f1-score: 0.8381For batch 111, tr_loss is    0.26.\n",
      "113/244 [============>.................] - ETA: 1:55 - loss: 0.2567 - iou_score: 0.7246 - f1-score: 0.8383For batch 112, tr_loss is    0.26.\n",
      "114/244 [=============>................] - ETA: 1:54 - loss: 0.2572 - iou_score: 0.7239 - f1-score: 0.8379For batch 113, tr_loss is    0.26.\n",
      "115/244 [=============>................] - ETA: 1:53 - loss: 0.2570 - iou_score: 0.7242 - f1-score: 0.8381For batch 114, tr_loss is    0.26.\n",
      "116/244 [=============>................] - ETA: 1:52 - loss: 0.2568 - iou_score: 0.7242 - f1-score: 0.8381For batch 115, tr_loss is    0.26.\n",
      "117/244 [=============>................] - ETA: 1:52 - loss: 0.2571 - iou_score: 0.7238 - f1-score: 0.8378For batch 116, tr_loss is    0.26.\n",
      "118/244 [=============>................] - ETA: 1:51 - loss: 0.2571 - iou_score: 0.7237 - f1-score: 0.8377For batch 117, tr_loss is    0.26.\n",
      "119/244 [=============>................] - ETA: 1:50 - loss: 0.2569 - iou_score: 0.7239 - f1-score: 0.8379For batch 118, tr_loss is    0.26.\n",
      "120/244 [=============>................] - ETA: 1:49 - loss: 0.2577 - iou_score: 0.7228 - f1-score: 0.8371For batch 119, tr_loss is    0.26.\n",
      "121/244 [=============>................] - ETA: 1:48 - loss: 0.2572 - iou_score: 0.7236 - f1-score: 0.8376For batch 120, tr_loss is    0.26.\n",
      "122/244 [==============>...............] - ETA: 1:47 - loss: 0.2572 - iou_score: 0.7240 - f1-score: 0.8379For batch 121, tr_loss is    0.26.\n",
      "123/244 [==============>...............] - ETA: 1:47 - loss: 0.2577 - iou_score: 0.7234 - f1-score: 0.8375For batch 122, tr_loss is    0.26.\n",
      "124/244 [==============>...............] - ETA: 1:45 - loss: 0.2579 - iou_score: 0.7227 - f1-score: 0.8370For batch 123, tr_loss is    0.26.\n",
      "125/244 [==============>...............] - ETA: 1:44 - loss: 0.2576 - iou_score: 0.7231 - f1-score: 0.8372For batch 124, tr_loss is    0.26.\n",
      "126/244 [==============>...............] - ETA: 1:43 - loss: 0.2576 - iou_score: 0.7231 - f1-score: 0.8373For batch 125, tr_loss is    0.26.\n",
      "127/244 [==============>...............] - ETA: 1:42 - loss: 0.2578 - iou_score: 0.7226 - f1-score: 0.8370For batch 126, tr_loss is    0.26.\n",
      "128/244 [==============>...............] - ETA: 1:42 - loss: 0.2575 - iou_score: 0.7230 - f1-score: 0.8372For batch 127, tr_loss is    0.26.\n",
      "129/244 [==============>...............] - ETA: 1:41 - loss: 0.2574 - iou_score: 0.7231 - f1-score: 0.8373For batch 128, tr_loss is    0.26.\n",
      "130/244 [==============>...............] - ETA: 1:40 - loss: 0.2578 - iou_score: 0.7226 - f1-score: 0.8370For batch 129, tr_loss is    0.26.\n",
      "131/244 [===============>..............] - ETA: 1:39 - loss: 0.2574 - iou_score: 0.7230 - f1-score: 0.8373For batch 130, tr_loss is    0.26.\n",
      "132/244 [===============>..............] - ETA: 1:38 - loss: 0.2579 - iou_score: 0.7224 - f1-score: 0.8368For batch 131, tr_loss is    0.26.\n",
      "133/244 [===============>..............] - ETA: 1:37 - loss: 0.2582 - iou_score: 0.7222 - f1-score: 0.8367For batch 132, tr_loss is    0.26.\n",
      "134/244 [===============>..............] - ETA: 1:36 - loss: 0.2586 - iou_score: 0.7214 - f1-score: 0.8361For batch 133, tr_loss is    0.26.\n",
      "135/244 [===============>..............] - ETA: 1:36 - loss: 0.2588 - iou_score: 0.7211 - f1-score: 0.8359For batch 134, tr_loss is    0.26.\n",
      "136/244 [===============>..............] - ETA: 1:35 - loss: 0.2583 - iou_score: 0.7217 - f1-score: 0.8363For batch 135, tr_loss is    0.26.\n",
      "137/244 [===============>..............] - ETA: 1:33 - loss: 0.2581 - iou_score: 0.7219 - f1-score: 0.8364For batch 136, tr_loss is    0.26.\n",
      "138/244 [===============>..............] - ETA: 1:33 - loss: 0.2583 - iou_score: 0.7216 - f1-score: 0.8363For batch 137, tr_loss is    0.26.\n",
      "139/244 [================>.............] - ETA: 1:32 - loss: 0.2584 - iou_score: 0.7214 - f1-score: 0.8361For batch 138, tr_loss is    0.26.\n",
      "140/244 [================>.............] - ETA: 1:31 - loss: 0.2584 - iou_score: 0.7213 - f1-score: 0.8361For batch 139, tr_loss is    0.26.\n",
      "141/244 [================>.............] - ETA: 1:31 - loss: 0.2585 - iou_score: 0.7211 - f1-score: 0.8359For batch 140, tr_loss is    0.26.\n",
      "142/244 [================>.............] - ETA: 1:30 - loss: 0.2585 - iou_score: 0.7208 - f1-score: 0.8358For batch 141, tr_loss is    0.26.\n",
      "143/244 [================>.............] - ETA: 1:29 - loss: 0.2584 - iou_score: 0.7212 - f1-score: 0.8360For batch 142, tr_loss is    0.26.\n",
      "144/244 [================>.............] - ETA: 1:28 - loss: 0.2588 - iou_score: 0.7206 - f1-score: 0.8356For batch 143, tr_loss is    0.26.\n",
      "145/244 [================>.............] - ETA: 1:27 - loss: 0.2589 - iou_score: 0.7204 - f1-score: 0.8354For batch 144, tr_loss is    0.26.\n",
      "146/244 [================>.............] - ETA: 1:26 - loss: 0.2591 - iou_score: 0.7201 - f1-score: 0.8353For batch 145, tr_loss is    0.26.\n",
      "147/244 [=================>............] - ETA: 1:25 - loss: 0.2591 - iou_score: 0.7200 - f1-score: 0.8352For batch 146, tr_loss is    0.26.\n",
      "148/244 [=================>............] - ETA: 1:24 - loss: 0.2591 - iou_score: 0.7198 - f1-score: 0.8351For batch 147, tr_loss is    0.26.\n",
      "149/244 [=================>............] - ETA: 1:24 - loss: 0.2591 - iou_score: 0.7197 - f1-score: 0.8350For batch 148, tr_loss is    0.26.\n",
      "150/244 [=================>............] - ETA: 1:23 - loss: 0.2590 - iou_score: 0.7197 - f1-score: 0.8351For batch 149, tr_loss is    0.26.\n",
      "151/244 [=================>............] - ETA: 1:21 - loss: 0.2590 - iou_score: 0.7196 - f1-score: 0.8350For batch 150, tr_loss is    0.26.\n",
      "152/244 [=================>............] - ETA: 1:21 - loss: 0.2595 - iou_score: 0.7193 - f1-score: 0.8347For batch 151, tr_loss is    0.26.\n",
      "153/244 [=================>............] - ETA: 1:20 - loss: 0.2595 - iou_score: 0.7195 - f1-score: 0.8349For batch 152, tr_loss is    0.26.\n",
      "154/244 [=================>............] - ETA: 1:19 - loss: 0.2594 - iou_score: 0.7196 - f1-score: 0.8350For batch 153, tr_loss is    0.26.\n",
      "155/244 [==================>...........] - ETA: 1:18 - loss: 0.2596 - iou_score: 0.7193 - f1-score: 0.8348For batch 154, tr_loss is    0.26.\n",
      "156/244 [==================>...........] - ETA: 1:17 - loss: 0.2592 - iou_score: 0.7198 - f1-score: 0.8351For batch 155, tr_loss is    0.26.\n",
      "157/244 [==================>...........] - ETA: 1:16 - loss: 0.2589 - iou_score: 0.7201 - f1-score: 0.8353For batch 156, tr_loss is    0.26.\n",
      "158/244 [==================>...........] - ETA: 1:16 - loss: 0.2591 - iou_score: 0.7200 - f1-score: 0.8353For batch 157, tr_loss is    0.26.\n",
      "159/244 [==================>...........] - ETA: 1:15 - loss: 0.2590 - iou_score: 0.7200 - f1-score: 0.8353For batch 158, tr_loss is    0.26.\n",
      "160/244 [==================>...........] - ETA: 1:14 - loss: 0.2587 - iou_score: 0.7203 - f1-score: 0.8355For batch 159, tr_loss is    0.26.\n",
      "161/244 [==================>...........] - ETA: 1:13 - loss: 0.2588 - iou_score: 0.7201 - f1-score: 0.8354For batch 160, tr_loss is    0.26.\n",
      "162/244 [==================>...........] - ETA: 1:12 - loss: 0.2587 - iou_score: 0.7203 - f1-score: 0.8355For batch 161, tr_loss is    0.26.\n",
      "163/244 [===================>..........] - ETA: 1:11 - loss: 0.2588 - iou_score: 0.7204 - f1-score: 0.8356For batch 162, tr_loss is    0.26.\n",
      "164/244 [===================>..........] - ETA: 1:10 - loss: 0.2586 - iou_score: 0.7205 - f1-score: 0.8357For batch 163, tr_loss is    0.26.\n",
      "165/244 [===================>..........] - ETA: 1:09 - loss: 0.2587 - iou_score: 0.7203 - f1-score: 0.8356For batch 164, tr_loss is    0.26.\n",
      "166/244 [===================>..........] - ETA: 1:08 - loss: 0.2589 - iou_score: 0.7202 - f1-score: 0.8355For batch 165, tr_loss is    0.26.\n",
      "167/244 [===================>..........] - ETA: 1:07 - loss: 0.2589 - iou_score: 0.7204 - f1-score: 0.8356For batch 166, tr_loss is    0.26.\n",
      "168/244 [===================>..........] - ETA: 1:06 - loss: 0.2586 - iou_score: 0.7207 - f1-score: 0.8358For batch 167, tr_loss is    0.26.\n",
      "169/244 [===================>..........] - ETA: 1:06 - loss: 0.2583 - iou_score: 0.7210 - f1-score: 0.8360For batch 168, tr_loss is    0.26.\n",
      "170/244 [===================>..........] - ETA: 1:05 - loss: 0.2585 - iou_score: 0.7207 - f1-score: 0.8358For batch 169, tr_loss is    0.26.\n",
      "171/244 [====================>.........] - ETA: 1:04 - loss: 0.2582 - iou_score: 0.7211 - f1-score: 0.8361For batch 170, tr_loss is    0.26.\n",
      "172/244 [====================>.........] - ETA: 1:03 - loss: 0.2583 - iou_score: 0.7209 - f1-score: 0.8360For batch 171, tr_loss is    0.26.\n",
      "173/244 [====================>.........] - ETA: 1:02 - loss: 0.2586 - iou_score: 0.7208 - f1-score: 0.8359For batch 172, tr_loss is    0.26.\n",
      "174/244 [====================>.........] - ETA: 1:01 - loss: 0.2589 - iou_score: 0.7204 - f1-score: 0.8356For batch 173, tr_loss is    0.26.\n",
      "175/244 [====================>.........] - ETA: 1:00 - loss: 0.2589 - iou_score: 0.7202 - f1-score: 0.8355For batch 174, tr_loss is    0.26.\n",
      "176/244 [====================>.........] - ETA: 59s - loss: 0.2589 - iou_score: 0.7202 - f1-score: 0.8355 For batch 175, tr_loss is    0.26.\n",
      "177/244 [====================>.........] - ETA: 58s - loss: 0.2586 - iou_score: 0.7207 - f1-score: 0.8358For batch 176, tr_loss is    0.26.\n",
      "178/244 [====================>.........] - ETA: 58s - loss: 0.2587 - iou_score: 0.7204 - f1-score: 0.8356For batch 177, tr_loss is    0.26.\n",
      "179/244 [=====================>........] - ETA: 57s - loss: 0.2586 - iou_score: 0.7205 - f1-score: 0.8356For batch 178, tr_loss is    0.26.\n",
      "180/244 [=====================>........] - ETA: 56s - loss: 0.2586 - iou_score: 0.7205 - f1-score: 0.8356For batch 179, tr_loss is    0.26.\n",
      "181/244 [=====================>........] - ETA: 55s - loss: 0.2584 - iou_score: 0.7208 - f1-score: 0.8359For batch 180, tr_loss is    0.26.\n",
      "182/244 [=====================>........] - ETA: 54s - loss: 0.2585 - iou_score: 0.7207 - f1-score: 0.8358For batch 181, tr_loss is    0.26.\n",
      "183/244 [=====================>........] - ETA: 53s - loss: 0.2587 - iou_score: 0.7205 - f1-score: 0.8357For batch 182, tr_loss is    0.26.\n",
      "184/244 [=====================>........] - ETA: 52s - loss: 0.2590 - iou_score: 0.7201 - f1-score: 0.8354For batch 183, tr_loss is    0.26.\n",
      "185/244 [=====================>........] - ETA: 51s - loss: 0.2591 - iou_score: 0.7201 - f1-score: 0.8354For batch 184, tr_loss is    0.26.\n",
      "186/244 [=====================>........] - ETA: 50s - loss: 0.2588 - iou_score: 0.7205 - f1-score: 0.8356For batch 185, tr_loss is    0.26.\n",
      "187/244 [=====================>........] - ETA: 50s - loss: 0.2591 - iou_score: 0.7200 - f1-score: 0.8353For batch 186, tr_loss is    0.26.\n",
      "188/244 [======================>.......] - ETA: 49s - loss: 0.2591 - iou_score: 0.7199 - f1-score: 0.8353For batch 187, tr_loss is    0.26.\n",
      "189/244 [======================>.......] - ETA: 48s - loss: 0.2590 - iou_score: 0.7201 - f1-score: 0.8354For batch 188, tr_loss is    0.26.\n",
      "190/244 [======================>.......] - ETA: 47s - loss: 0.2587 - iou_score: 0.7205 - f1-score: 0.8357For batch 189, tr_loss is    0.26.\n",
      "191/244 [======================>.......] - ETA: 46s - loss: 0.2584 - iou_score: 0.7208 - f1-score: 0.8359For batch 190, tr_loss is    0.26.\n",
      "192/244 [======================>.......] - ETA: 45s - loss: 0.2585 - iou_score: 0.7207 - f1-score: 0.8358For batch 191, tr_loss is    0.26.\n",
      "193/244 [======================>.......] - ETA: 44s - loss: 0.2585 - iou_score: 0.7206 - f1-score: 0.8357For batch 192, tr_loss is    0.26.\n",
      "194/244 [======================>.......] - ETA: 44s - loss: 0.2582 - iou_score: 0.7208 - f1-score: 0.8359For batch 193, tr_loss is    0.26.\n",
      "195/244 [======================>.......] - ETA: 43s - loss: 0.2586 - iou_score: 0.7207 - f1-score: 0.8358For batch 194, tr_loss is    0.26.\n",
      "196/244 [=======================>......] - ETA: 42s - loss: 0.2585 - iou_score: 0.7208 - f1-score: 0.8359For batch 195, tr_loss is    0.26.\n",
      "197/244 [=======================>......] - ETA: 41s - loss: 0.2586 - iou_score: 0.7204 - f1-score: 0.8357For batch 196, tr_loss is    0.26.\n",
      "198/244 [=======================>......] - ETA: 40s - loss: 0.2586 - iou_score: 0.7205 - f1-score: 0.8357For batch 197, tr_loss is    0.26.\n",
      "199/244 [=======================>......] - ETA: 39s - loss: 0.2582 - iou_score: 0.7211 - f1-score: 0.8361For batch 198, tr_loss is    0.26.\n",
      "200/244 [=======================>......] - ETA: 38s - loss: 0.2582 - iou_score: 0.7212 - f1-score: 0.8362For batch 199, tr_loss is    0.26.\n",
      "201/244 [=======================>......] - ETA: 37s - loss: 0.2584 - iou_score: 0.7209 - f1-score: 0.8360For batch 200, tr_loss is    0.26.\n",
      "202/244 [=======================>......] - ETA: 36s - loss: 0.2582 - iou_score: 0.7210 - f1-score: 0.8360For batch 201, tr_loss is    0.26.\n",
      "203/244 [=======================>......] - ETA: 36s - loss: 0.2581 - iou_score: 0.7212 - f1-score: 0.8362For batch 202, tr_loss is    0.26.\n",
      "204/244 [========================>.....] - ETA: 35s - loss: 0.2578 - iou_score: 0.7214 - f1-score: 0.8363For batch 203, tr_loss is    0.26.\n",
      "205/244 [========================>.....] - ETA: 34s - loss: 0.2574 - iou_score: 0.7217 - f1-score: 0.8365For batch 204, tr_loss is    0.26.\n",
      "206/244 [========================>.....] - ETA: 33s - loss: 0.2576 - iou_score: 0.7215 - f1-score: 0.8364For batch 205, tr_loss is    0.26.\n",
      "207/244 [========================>.....] - ETA: 32s - loss: 0.2574 - iou_score: 0.7217 - f1-score: 0.8365For batch 206, tr_loss is    0.26.\n",
      "208/244 [========================>.....] - ETA: 31s - loss: 0.2575 - iou_score: 0.7214 - f1-score: 0.8363For batch 207, tr_loss is    0.26.\n",
      "209/244 [========================>.....] - ETA: 30s - loss: 0.2574 - iou_score: 0.7216 - f1-score: 0.8364For batch 208, tr_loss is    0.26.\n",
      "210/244 [========================>.....] - ETA: 30s - loss: 0.2571 - iou_score: 0.7219 - f1-score: 0.8366For batch 209, tr_loss is    0.26.\n",
      "211/244 [========================>.....] - ETA: 29s - loss: 0.2571 - iou_score: 0.7219 - f1-score: 0.8367For batch 210, tr_loss is    0.26.\n",
      "212/244 [=========================>....] - ETA: 28s - loss: 0.2572 - iou_score: 0.7218 - f1-score: 0.8366For batch 211, tr_loss is    0.26.\n",
      "213/244 [=========================>....] - ETA: 27s - loss: 0.2573 - iou_score: 0.7217 - f1-score: 0.8365For batch 212, tr_loss is    0.26.\n",
      "214/244 [=========================>....] - ETA: 26s - loss: 0.2570 - iou_score: 0.7221 - f1-score: 0.8368For batch 213, tr_loss is    0.26.\n",
      "215/244 [=========================>....] - ETA: 25s - loss: 0.2568 - iou_score: 0.7223 - f1-score: 0.8369For batch 214, tr_loss is    0.26.\n",
      "216/244 [=========================>....] - ETA: 24s - loss: 0.2570 - iou_score: 0.7222 - f1-score: 0.8368For batch 215, tr_loss is    0.26.\n",
      "217/244 [=========================>....] - ETA: 23s - loss: 0.2569 - iou_score: 0.7223 - f1-score: 0.8369For batch 216, tr_loss is    0.26.\n",
      "218/244 [=========================>....] - ETA: 22s - loss: 0.2569 - iou_score: 0.7222 - f1-score: 0.8369For batch 217, tr_loss is    0.26.\n",
      "219/244 [=========================>....] - ETA: 22s - loss: 0.2569 - iou_score: 0.7222 - f1-score: 0.8369For batch 218, tr_loss is    0.26.\n",
      "220/244 [==========================>...] - ETA: 21s - loss: 0.2570 - iou_score: 0.7221 - f1-score: 0.8368For batch 219, tr_loss is    0.26.\n",
      "221/244 [==========================>...] - ETA: 20s - loss: 0.2570 - iou_score: 0.7221 - f1-score: 0.8368For batch 220, tr_loss is    0.26.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222/244 [==========================>...] - ETA: 19s - loss: 0.2567 - iou_score: 0.7225 - f1-score: 0.8370For batch 221, tr_loss is    0.26.\n",
      "223/244 [==========================>...] - ETA: 18s - loss: 0.2565 - iou_score: 0.7226 - f1-score: 0.8371For batch 222, tr_loss is    0.26.\n",
      "224/244 [==========================>...] - ETA: 17s - loss: 0.2566 - iou_score: 0.7226 - f1-score: 0.8371For batch 223, tr_loss is    0.26.\n",
      "225/244 [==========================>...] - ETA: 16s - loss: 0.2566 - iou_score: 0.7225 - f1-score: 0.8371For batch 224, tr_loss is    0.26.\n",
      "226/244 [==========================>...] - ETA: 15s - loss: 0.2564 - iou_score: 0.7227 - f1-score: 0.8372For batch 225, tr_loss is    0.26.\n",
      "227/244 [==========================>...] - ETA: 15s - loss: 0.2563 - iou_score: 0.7228 - f1-score: 0.8373For batch 226, tr_loss is    0.26.\n",
      "228/244 [===========================>..] - ETA: 14s - loss: 0.2562 - iou_score: 0.7230 - f1-score: 0.8374For batch 227, tr_loss is    0.26.\n",
      "229/244 [===========================>..] - ETA: 13s - loss: 0.2559 - iou_score: 0.7232 - f1-score: 0.8376For batch 228, tr_loss is    0.26.\n",
      "230/244 [===========================>..] - ETA: 12s - loss: 0.2559 - iou_score: 0.7233 - f1-score: 0.8377For batch 229, tr_loss is    0.26.\n",
      "231/244 [===========================>..] - ETA: 11s - loss: 0.2558 - iou_score: 0.7236 - f1-score: 0.8378For batch 230, tr_loss is    0.26.\n",
      "232/244 [===========================>..] - ETA: 10s - loss: 0.2558 - iou_score: 0.7235 - f1-score: 0.8378For batch 231, tr_loss is    0.26.\n",
      "233/244 [===========================>..] - ETA: 9s - loss: 0.2564 - iou_score: 0.7230 - f1-score: 0.8374 For batch 232, tr_loss is    0.26.\n",
      "234/244 [===========================>..] - ETA: 8s - loss: 0.2564 - iou_score: 0.7229 - f1-score: 0.8373For batch 233, tr_loss is    0.26.\n",
      "235/244 [===========================>..] - ETA: 7s - loss: 0.2562 - iou_score: 0.7232 - f1-score: 0.8376For batch 234, tr_loss is    0.26.\n",
      "236/244 [============================>.] - ETA: 7s - loss: 0.2564 - iou_score: 0.7231 - f1-score: 0.8375For batch 235, tr_loss is    0.26.\n",
      "237/244 [============================>.] - ETA: 6s - loss: 0.2565 - iou_score: 0.7231 - f1-score: 0.8374For batch 236, tr_loss is    0.26.\n",
      "238/244 [============================>.] - ETA: 5s - loss: 0.2563 - iou_score: 0.7233 - f1-score: 0.8376For batch 237, tr_loss is    0.26.\n",
      "239/244 [============================>.] - ETA: 4s - loss: 0.2562 - iou_score: 0.7235 - f1-score: 0.8377For batch 238, tr_loss is    0.26.\n",
      "240/244 [============================>.] - ETA: 3s - loss: 0.2559 - iou_score: 0.7239 - f1-score: 0.8380For batch 239, tr_loss is    0.26.\n",
      "241/244 [============================>.] - ETA: 2s - loss: 0.2559 - iou_score: 0.7238 - f1-score: 0.8380For batch 240, tr_loss is    0.26.\n",
      "242/244 [============================>.] - ETA: 1s - loss: 0.2562 - iou_score: 0.7235 - f1-score: 0.8378For batch 241, tr_loss is    0.26.\n",
      "243/244 [============================>.] - ETA: 0s - loss: 0.2565 - iou_score: 0.7231 - f1-score: 0.8375For batch 242, tr_loss is    0.26.\n",
      "244/244 [==============================] - ETA: 0s - loss: 0.2564 - iou_score: 0.7232 - f1-score: 0.8375For batch 243, tr_loss is    0.26.\n",
      "For batch 0, vl_loss is    0.37.\n",
      "For batch 1, vl_loss is    0.35.\n",
      "For batch 2, vl_loss is    0.34.\n",
      "For batch 3, vl_loss is    0.36.\n",
      "For batch 4, vl_loss is    0.35.\n",
      "For batch 5, vl_loss is    0.35.\n",
      "For batch 6, vl_loss is    0.37.\n",
      "For batch 7, vl_loss is    0.37.\n",
      "For batch 8, vl_loss is    0.36.\n",
      "For batch 9, vl_loss is    0.37.\n",
      "For batch 10, vl_loss is    0.37.\n",
      "For batch 11, vl_loss is    0.38.\n",
      "For batch 12, vl_loss is    0.38.\n",
      "For batch 13, vl_loss is    0.38.\n",
      "For batch 14, vl_loss is    0.38.\n",
      "For batch 15, vl_loss is    0.38.\n",
      "For batch 16, vl_loss is    0.38.\n",
      "For batch 17, vl_loss is    0.37.\n",
      "For batch 18, vl_loss is    0.38.\n",
      "For batch 19, vl_loss is    0.37.\n",
      "For batch 20, vl_loss is    0.37.\n",
      "For batch 21, vl_loss is    0.37.\n",
      "For batch 22, vl_loss is    0.37.\n",
      "For batch 23, vl_loss is    0.37.\n",
      "For batch 24, vl_loss is    0.37.\n",
      "For batch 25, vl_loss is    0.37.\n",
      "For batch 26, vl_loss is    0.38.\n",
      "For batch 27, vl_loss is    0.38.\n",
      "For batch 28, vl_loss is    0.38.\n",
      "For batch 29, vl_loss is    0.38.\n",
      "For batch 30, vl_loss is    0.38.\n",
      "For batch 31, vl_loss is    0.38.\n",
      "For batch 32, vl_loss is    0.38.\n",
      "For batch 33, vl_loss is    0.38.\n",
      "For batch 34, vl_loss is    0.38.\n",
      "For batch 35, vl_loss is    0.38.\n",
      "For batch 36, vl_loss is    0.38.\n",
      "For batch 37, vl_loss is    0.38.\n",
      "For batch 38, vl_loss is    0.38.\n",
      "For batch 39, vl_loss is    0.38.\n",
      "For batch 40, vl_loss is    0.38.\n",
      "For batch 41, vl_loss is    0.38.\n",
      "For batch 42, vl_loss is    0.38.\n",
      "For batch 43, vl_loss is    0.38.\n",
      "For batch 44, vl_loss is    0.38.\n",
      "For batch 45, vl_loss is    0.38.\n",
      "For batch 46, vl_loss is    0.38.\n",
      "For batch 47, vl_loss is    0.37.\n",
      "For batch 48, vl_loss is    0.37.\n",
      "For batch 49, vl_loss is    0.37.\n",
      "For batch 50, vl_loss is    0.37.\n",
      "For batch 51, vl_loss is    0.37.\n",
      "For batch 52, vl_loss is    0.37.\n",
      "For batch 53, vl_loss is    0.37.\n",
      "For batch 54, vl_loss is    0.37.\n",
      "For batch 55, vl_loss is    0.37.\n",
      "244/244 [==============================] - 218s 888ms/step - loss: 0.2564 - iou_score: 0.7232 - f1-score: 0.8375 - val_loss: 0.3734 - val_iou_score: 0.6131 - val_f1-score: 0.7577\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.34998\n",
      "The average loss for epoch 11 is    0.26 \n",
      "Epoch 13/200\n",
      "  1/244 [..............................] - ETA: 10:19 - loss: 0.2948 - iou_score: 0.6619 - f1-score: 0.7942For batch 0, tr_loss is    0.29.\n",
      "  2/244 [..............................] - ETA: 5:37 - loss: 0.2630 - iou_score: 0.7107 - f1-score: 0.8287 For batch 1, tr_loss is    0.26.\n",
      "  3/244 [..............................] - ETA: 5:52 - loss: 0.2669 - iou_score: 0.7172 - f1-score: 0.8338For batch 2, tr_loss is    0.27.\n",
      "  4/244 [..............................] - ETA: 5:26 - loss: 0.2733 - iou_score: 0.7198 - f1-score: 0.8359For batch 3, tr_loss is    0.27.\n",
      "  5/244 [..............................] - ETA: 5:23 - loss: 0.2761 - iou_score: 0.7172 - f1-score: 0.8340For batch 4, tr_loss is    0.28.\n",
      "  6/244 [..............................] - ETA: 5:35 - loss: 0.2755 - iou_score: 0.7149 - f1-score: 0.8326For batch 5, tr_loss is    0.28.\n",
      "  7/244 [..............................] - ETA: 5:37 - loss: 0.2748 - iou_score: 0.7202 - f1-score: 0.8357For batch 6, tr_loss is    0.27.\n",
      "  8/244 [..............................] - ETA: 5:27 - loss: 0.2802 - iou_score: 0.7106 - f1-score: 0.8287For batch 7, tr_loss is    0.28.\n",
      "  9/244 [>.............................] - ETA: 5:03 - loss: 0.2856 - iou_score: 0.7032 - f1-score: 0.8235For batch 8, tr_loss is    0.29.\n",
      " 10/244 [>.............................] - ETA: 4:43 - loss: 0.2784 - iou_score: 0.7122 - f1-score: 0.8296For batch 9, tr_loss is    0.28.\n",
      " 11/244 [>.............................] - ETA: 4:40 - loss: 0.2746 - iou_score: 0.7160 - f1-score: 0.8324For batch 10, tr_loss is    0.27.\n",
      " 12/244 [>.............................] - ETA: 4:35 - loss: 0.2724 - iou_score: 0.7168 - f1-score: 0.8330For batch 11, tr_loss is    0.27.\n",
      " 13/244 [>.............................] - ETA: 4:21 - loss: 0.2683 - iou_score: 0.7210 - f1-score: 0.8359For batch 12, tr_loss is    0.27.\n",
      " 14/244 [>.............................] - ETA: 4:11 - loss: 0.2712 - iou_score: 0.7160 - f1-score: 0.8325For batch 13, tr_loss is    0.27.\n",
      " 15/244 [>.............................] - ETA: 4:13 - loss: 0.2732 - iou_score: 0.7132 - f1-score: 0.8307For batch 14, tr_loss is    0.27.\n",
      " 16/244 [>.............................] - ETA: 4:05 - loss: 0.2739 - iou_score: 0.7132 - f1-score: 0.8308For batch 15, tr_loss is    0.27.\n",
      " 17/244 [=>............................] - ETA: 3:59 - loss: 0.2695 - iou_score: 0.7188 - f1-score: 0.8345For batch 16, tr_loss is    0.27.\n",
      " 18/244 [=>............................] - ETA: 3:58 - loss: 0.2717 - iou_score: 0.7176 - f1-score: 0.8338For batch 17, tr_loss is    0.27.\n",
      " 19/244 [=>............................] - ETA: 3:57 - loss: 0.2693 - iou_score: 0.7203 - f1-score: 0.8356For batch 18, tr_loss is    0.27.\n",
      " 20/244 [=>............................] - ETA: 3:55 - loss: 0.2689 - iou_score: 0.7203 - f1-score: 0.8355For batch 19, tr_loss is    0.27.\n",
      " 21/244 [=>............................] - ETA: 3:54 - loss: 0.2683 - iou_score: 0.7198 - f1-score: 0.8352For batch 20, tr_loss is    0.27.\n",
      " 22/244 [=>............................] - ETA: 3:49 - loss: 0.2717 - iou_score: 0.7163 - f1-score: 0.8327For batch 21, tr_loss is    0.27.\n",
      " 23/244 [=>............................] - ETA: 3:43 - loss: 0.2715 - iou_score: 0.7152 - f1-score: 0.8320For batch 22, tr_loss is    0.27.\n",
      " 24/244 [=>............................] - ETA: 3:41 - loss: 0.2690 - iou_score: 0.7174 - f1-score: 0.8336For batch 23, tr_loss is    0.27.\n",
      " 25/244 [==>...........................] - ETA: 3:37 - loss: 0.2704 - iou_score: 0.7153 - f1-score: 0.8321For batch 24, tr_loss is    0.27.\n",
      " 26/244 [==>...........................] - ETA: 3:32 - loss: 0.2712 - iou_score: 0.7140 - f1-score: 0.8312For batch 25, tr_loss is    0.27.\n",
      " 27/244 [==>...........................] - ETA: 3:28 - loss: 0.2702 - iou_score: 0.7146 - f1-score: 0.8317For batch 26, tr_loss is    0.27.\n",
      " 28/244 [==>...........................] - ETA: 3:25 - loss: 0.2670 - iou_score: 0.7191 - f1-score: 0.8346For batch 27, tr_loss is    0.27.\n",
      " 29/244 [==>...........................] - ETA: 3:23 - loss: 0.2655 - iou_score: 0.7201 - f1-score: 0.8353For batch 28, tr_loss is    0.27.\n",
      " 30/244 [==>...........................] - ETA: 3:22 - loss: 0.2626 - iou_score: 0.7236 - f1-score: 0.8376For batch 29, tr_loss is    0.26.\n",
      " 31/244 [==>...........................] - ETA: 3:18 - loss: 0.2616 - iou_score: 0.7254 - f1-score: 0.8388For batch 30, tr_loss is    0.26.\n",
      " 32/244 [==>...........................] - ETA: 3:18 - loss: 0.2602 - iou_score: 0.7271 - f1-score: 0.8400For batch 31, tr_loss is    0.26.\n",
      " 33/244 [===>..........................] - ETA: 3:18 - loss: 0.2591 - iou_score: 0.7274 - f1-score: 0.8403For batch 32, tr_loss is    0.26.\n",
      " 34/244 [===>..........................] - ETA: 3:17 - loss: 0.2587 - iou_score: 0.7272 - f1-score: 0.8401For batch 33, tr_loss is    0.26.\n",
      " 35/244 [===>..........................] - ETA: 3:17 - loss: 0.2592 - iou_score: 0.7267 - f1-score: 0.8398For batch 34, tr_loss is    0.26.\n",
      " 36/244 [===>..........................] - ETA: 3:16 - loss: 0.2579 - iou_score: 0.7276 - f1-score: 0.8405For batch 35, tr_loss is    0.26.\n",
      " 37/244 [===>..........................] - ETA: 3:12 - loss: 0.2601 - iou_score: 0.7258 - f1-score: 0.8393For batch 36, tr_loss is    0.26.\n",
      " 38/244 [===>..........................] - ETA: 3:12 - loss: 0.2595 - iou_score: 0.7272 - f1-score: 0.8402For batch 37, tr_loss is    0.26.\n",
      " 39/244 [===>..........................] - ETA: 3:09 - loss: 0.2582 - iou_score: 0.7287 - f1-score: 0.8412For batch 38, tr_loss is    0.26.\n",
      " 40/244 [===>..........................] - ETA: 3:07 - loss: 0.2587 - iou_score: 0.7280 - f1-score: 0.8408For batch 39, tr_loss is    0.26.\n",
      " 41/244 [====>.........................] - ETA: 3:05 - loss: 0.2597 - iou_score: 0.7264 - f1-score: 0.8397For batch 40, tr_loss is    0.26.\n",
      " 42/244 [====>.........................] - ETA: 3:04 - loss: 0.2584 - iou_score: 0.7277 - f1-score: 0.8406For batch 41, tr_loss is    0.26.\n",
      " 43/244 [====>.........................] - ETA: 3:03 - loss: 0.2598 - iou_score: 0.7259 - f1-score: 0.8394For batch 42, tr_loss is    0.26.\n",
      " 44/244 [====>.........................] - ETA: 3:03 - loss: 0.2591 - iou_score: 0.7268 - f1-score: 0.8400For batch 43, tr_loss is    0.26.\n",
      " 45/244 [====>.........................] - ETA: 3:02 - loss: 0.2593 - iou_score: 0.7265 - f1-score: 0.8398For batch 44, tr_loss is    0.26.\n",
      " 46/244 [====>.........................] - ETA: 2:59 - loss: 0.2588 - iou_score: 0.7269 - f1-score: 0.8401For batch 45, tr_loss is    0.26.\n",
      " 47/244 [====>.........................] - ETA: 2:57 - loss: 0.2575 - iou_score: 0.7282 - f1-score: 0.8409For batch 46, tr_loss is    0.26.\n",
      " 48/244 [====>.........................] - ETA: 2:57 - loss: 0.2564 - iou_score: 0.7291 - f1-score: 0.8415For batch 47, tr_loss is    0.26.\n",
      " 49/244 [=====>........................] - ETA: 2:54 - loss: 0.2568 - iou_score: 0.7287 - f1-score: 0.8413For batch 48, tr_loss is    0.26.\n",
      " 50/244 [=====>........................] - ETA: 2:53 - loss: 0.2568 - iou_score: 0.7283 - f1-score: 0.8410For batch 49, tr_loss is    0.26.\n",
      " 51/244 [=====>........................] - ETA: 2:51 - loss: 0.2579 - iou_score: 0.7270 - f1-score: 0.8401For batch 50, tr_loss is    0.26.\n",
      " 52/244 [=====>........................] - ETA: 2:51 - loss: 0.2582 - iou_score: 0.7264 - f1-score: 0.8398For batch 51, tr_loss is    0.26.\n",
      " 53/244 [=====>........................] - ETA: 2:51 - loss: 0.2583 - iou_score: 0.7261 - f1-score: 0.8395For batch 52, tr_loss is    0.26.\n",
      " 54/244 [=====>........................] - ETA: 2:50 - loss: 0.2587 - iou_score: 0.7256 - f1-score: 0.8393For batch 53, tr_loss is    0.26.\n",
      " 55/244 [=====>........................] - ETA: 2:49 - loss: 0.2578 - iou_score: 0.7264 - f1-score: 0.8398For batch 54, tr_loss is    0.26.\n",
      " 56/244 [=====>........................] - ETA: 2:48 - loss: 0.2567 - iou_score: 0.7274 - f1-score: 0.8404For batch 55, tr_loss is    0.26.\n",
      " 57/244 [======>.......................] - ETA: 2:46 - loss: 0.2571 - iou_score: 0.7270 - f1-score: 0.8402For batch 56, tr_loss is    0.26.\n",
      " 58/244 [======>.......................] - ETA: 2:44 - loss: 0.2575 - iou_score: 0.7260 - f1-score: 0.8396For batch 57, tr_loss is    0.26.\n",
      " 59/244 [======>.......................] - ETA: 2:43 - loss: 0.2560 - iou_score: 0.7285 - f1-score: 0.8411For batch 58, tr_loss is    0.26.\n",
      " 60/244 [======>.......................] - ETA: 2:42 - loss: 0.2572 - iou_score: 0.7264 - f1-score: 0.8396For batch 59, tr_loss is    0.26.\n",
      " 61/244 [======>.......................] - ETA: 2:42 - loss: 0.2583 - iou_score: 0.7245 - f1-score: 0.8383For batch 60, tr_loss is    0.26.\n",
      " 62/244 [======>.......................] - ETA: 2:41 - loss: 0.2580 - iou_score: 0.7246 - f1-score: 0.8384For batch 61, tr_loss is    0.26.\n",
      " 63/244 [======>.......................] - ETA: 2:41 - loss: 0.2580 - iou_score: 0.7245 - f1-score: 0.8383For batch 62, tr_loss is    0.26.\n",
      " 64/244 [======>.......................] - ETA: 2:40 - loss: 0.2573 - iou_score: 0.7253 - f1-score: 0.8389For batch 63, tr_loss is    0.26.\n",
      " 65/244 [======>.......................] - ETA: 2:39 - loss: 0.2575 - iou_score: 0.7250 - f1-score: 0.8387For batch 64, tr_loss is    0.26.\n",
      " 66/244 [=======>......................] - ETA: 2:38 - loss: 0.2576 - iou_score: 0.7250 - f1-score: 0.8387For batch 65, tr_loss is    0.26.\n",
      " 67/244 [=======>......................] - ETA: 2:37 - loss: 0.2574 - iou_score: 0.7255 - f1-score: 0.8390For batch 66, tr_loss is    0.26.\n",
      " 68/244 [=======>......................] - ETA: 2:37 - loss: 0.2574 - iou_score: 0.7261 - f1-score: 0.8394For batch 67, tr_loss is    0.26.\n",
      " 69/244 [=======>......................] - ETA: 2:35 - loss: 0.2580 - iou_score: 0.7251 - f1-score: 0.8387For batch 68, tr_loss is    0.26.\n",
      " 70/244 [=======>......................] - ETA: 2:34 - loss: 0.2574 - iou_score: 0.7255 - f1-score: 0.8390For batch 69, tr_loss is    0.26.\n",
      " 71/244 [=======>......................] - ETA: 2:32 - loss: 0.2577 - iou_score: 0.7254 - f1-score: 0.8389For batch 70, tr_loss is    0.26.\n",
      " 72/244 [=======>......................] - ETA: 2:31 - loss: 0.2567 - iou_score: 0.7264 - f1-score: 0.8396For batch 71, tr_loss is    0.26.\n",
      " 73/244 [=======>......................] - ETA: 2:30 - loss: 0.2574 - iou_score: 0.7254 - f1-score: 0.8389For batch 72, tr_loss is    0.26.\n",
      " 74/244 [========>.....................] - ETA: 2:29 - loss: 0.2576 - iou_score: 0.7252 - f1-score: 0.8387For batch 73, tr_loss is    0.26.\n",
      " 75/244 [========>.....................] - ETA: 2:27 - loss: 0.2577 - iou_score: 0.7249 - f1-score: 0.8385For batch 74, tr_loss is    0.26.\n",
      " 76/244 [========>.....................] - ETA: 2:26 - loss: 0.2570 - iou_score: 0.7260 - f1-score: 0.8392For batch 75, tr_loss is    0.26.\n",
      " 77/244 [========>.....................] - ETA: 2:25 - loss: 0.2570 - iou_score: 0.7260 - f1-score: 0.8393For batch 76, tr_loss is    0.26.\n",
      " 78/244 [========>.....................] - ETA: 2:24 - loss: 0.2563 - iou_score: 0.7267 - f1-score: 0.8398For batch 77, tr_loss is    0.26.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 79/244 [========>.....................] - ETA: 2:23 - loss: 0.2564 - iou_score: 0.7269 - f1-score: 0.8398For batch 78, tr_loss is    0.26.\n",
      " 80/244 [========>.....................] - ETA: 2:22 - loss: 0.2559 - iou_score: 0.7273 - f1-score: 0.8401For batch 79, tr_loss is    0.26.\n",
      " 81/244 [========>.....................] - ETA: 2:21 - loss: 0.2563 - iou_score: 0.7271 - f1-score: 0.8399For batch 80, tr_loss is    0.26.\n",
      " 82/244 [=========>....................] - ETA: 2:20 - loss: 0.2576 - iou_score: 0.7254 - f1-score: 0.8387For batch 81, tr_loss is    0.26.\n",
      " 83/244 [=========>....................] - ETA: 2:19 - loss: 0.2570 - iou_score: 0.7261 - f1-score: 0.8392For batch 82, tr_loss is    0.26.\n",
      " 84/244 [=========>....................] - ETA: 2:17 - loss: 0.2566 - iou_score: 0.7265 - f1-score: 0.8395For batch 83, tr_loss is    0.26.\n",
      " 85/244 [=========>....................] - ETA: 2:16 - loss: 0.2559 - iou_score: 0.7272 - f1-score: 0.8400For batch 84, tr_loss is    0.26.\n",
      " 86/244 [=========>....................] - ETA: 2:15 - loss: 0.2566 - iou_score: 0.7264 - f1-score: 0.8394For batch 85, tr_loss is    0.26.\n",
      " 87/244 [=========>....................] - ETA: 2:15 - loss: 0.2565 - iou_score: 0.7265 - f1-score: 0.8395For batch 86, tr_loss is    0.26.\n",
      " 88/244 [=========>....................] - ETA: 2:13 - loss: 0.2558 - iou_score: 0.7273 - f1-score: 0.8400For batch 87, tr_loss is    0.26.\n",
      " 89/244 [=========>....................] - ETA: 2:12 - loss: 0.2561 - iou_score: 0.7267 - f1-score: 0.8396For batch 88, tr_loss is    0.26.\n",
      " 90/244 [==========>...................] - ETA: 2:11 - loss: 0.2558 - iou_score: 0.7270 - f1-score: 0.8398For batch 89, tr_loss is    0.26.\n",
      " 91/244 [==========>...................] - ETA: 2:10 - loss: 0.2570 - iou_score: 0.7257 - f1-score: 0.8389For batch 90, tr_loss is    0.26.\n",
      " 92/244 [==========>...................] - ETA: 2:09 - loss: 0.2576 - iou_score: 0.7249 - f1-score: 0.8383For batch 91, tr_loss is    0.26.\n",
      " 93/244 [==========>...................] - ETA: 2:08 - loss: 0.2570 - iou_score: 0.7257 - f1-score: 0.8389For batch 92, tr_loss is    0.26.\n",
      " 94/244 [==========>...................] - ETA: 2:07 - loss: 0.2566 - iou_score: 0.7262 - f1-score: 0.8392For batch 93, tr_loss is    0.26.\n",
      " 95/244 [==========>...................] - ETA: 2:07 - loss: 0.2566 - iou_score: 0.7258 - f1-score: 0.8389For batch 94, tr_loss is    0.26.\n",
      " 96/244 [==========>...................] - ETA: 2:06 - loss: 0.2569 - iou_score: 0.7251 - f1-score: 0.8384For batch 95, tr_loss is    0.26.\n",
      " 97/244 [==========>...................] - ETA: 2:04 - loss: 0.2565 - iou_score: 0.7256 - f1-score: 0.8388For batch 96, tr_loss is    0.26.\n",
      " 98/244 [===========>..................] - ETA: 2:04 - loss: 0.2565 - iou_score: 0.7254 - f1-score: 0.8387For batch 97, tr_loss is    0.26.\n",
      " 99/244 [===========>..................] - ETA: 2:03 - loss: 0.2563 - iou_score: 0.7257 - f1-score: 0.8389For batch 98, tr_loss is    0.26.\n",
      "100/244 [===========>..................] - ETA: 2:02 - loss: 0.2556 - iou_score: 0.7265 - f1-score: 0.8394For batch 99, tr_loss is    0.26.\n",
      "101/244 [===========>..................] - ETA: 2:02 - loss: 0.2552 - iou_score: 0.7266 - f1-score: 0.8395For batch 100, tr_loss is    0.26.\n",
      "102/244 [===========>..................] - ETA: 2:01 - loss: 0.2551 - iou_score: 0.7267 - f1-score: 0.8396For batch 101, tr_loss is    0.26.\n",
      "103/244 [===========>..................] - ETA: 2:00 - loss: 0.2547 - iou_score: 0.7272 - f1-score: 0.8399For batch 102, tr_loss is    0.25.\n",
      "104/244 [===========>..................] - ETA: 1:59 - loss: 0.2542 - iou_score: 0.7276 - f1-score: 0.8402For batch 103, tr_loss is    0.25.\n",
      "105/244 [===========>..................] - ETA: 1:58 - loss: 0.2544 - iou_score: 0.7272 - f1-score: 0.8399For batch 104, tr_loss is    0.25.\n",
      "106/244 [============>.................] - ETA: 1:58 - loss: 0.2539 - iou_score: 0.7279 - f1-score: 0.8404For batch 105, tr_loss is    0.25.\n",
      "107/244 [============>.................] - ETA: 1:56 - loss: 0.2535 - iou_score: 0.7283 - f1-score: 0.8407For batch 106, tr_loss is    0.25.\n",
      "108/244 [============>.................] - ETA: 1:55 - loss: 0.2537 - iou_score: 0.7282 - f1-score: 0.8406For batch 107, tr_loss is    0.25.\n",
      "109/244 [============>.................] - ETA: 1:55 - loss: 0.2542 - iou_score: 0.7277 - f1-score: 0.8403For batch 108, tr_loss is    0.25.\n",
      "110/244 [============>.................] - ETA: 1:54 - loss: 0.2543 - iou_score: 0.7274 - f1-score: 0.8401For batch 109, tr_loss is    0.25.\n",
      "111/244 [============>.................] - ETA: 1:53 - loss: 0.2543 - iou_score: 0.7272 - f1-score: 0.8400For batch 110, tr_loss is    0.25.\n",
      "112/244 [============>.................] - ETA: 1:52 - loss: 0.2543 - iou_score: 0.7271 - f1-score: 0.8399For batch 111, tr_loss is    0.25.\n",
      "113/244 [============>.................] - ETA: 1:51 - loss: 0.2541 - iou_score: 0.7276 - f1-score: 0.8402For batch 112, tr_loss is    0.25.\n",
      "114/244 [=============>................] - ETA: 1:51 - loss: 0.2546 - iou_score: 0.7270 - f1-score: 0.8398For batch 113, tr_loss is    0.25.\n",
      "115/244 [=============>................] - ETA: 1:50 - loss: 0.2546 - iou_score: 0.7272 - f1-score: 0.8400For batch 114, tr_loss is    0.25.\n",
      "116/244 [=============>................] - ETA: 1:48 - loss: 0.2542 - iou_score: 0.7274 - f1-score: 0.8401For batch 115, tr_loss is    0.25.\n",
      "117/244 [=============>................] - ETA: 1:47 - loss: 0.2546 - iou_score: 0.7267 - f1-score: 0.8396For batch 116, tr_loss is    0.25.\n",
      "118/244 [=============>................] - ETA: 1:46 - loss: 0.2546 - iou_score: 0.7266 - f1-score: 0.8396For batch 117, tr_loss is    0.25.\n",
      "119/244 [=============>................] - ETA: 1:46 - loss: 0.2547 - iou_score: 0.7265 - f1-score: 0.8395For batch 118, tr_loss is    0.25.\n",
      "120/244 [=============>................] - ETA: 1:45 - loss: 0.2557 - iou_score: 0.7255 - f1-score: 0.8387For batch 119, tr_loss is    0.26.\n",
      "121/244 [=============>................] - ETA: 1:44 - loss: 0.2552 - iou_score: 0.7261 - f1-score: 0.8392For batch 120, tr_loss is    0.26.\n",
      "122/244 [==============>...............] - ETA: 1:42 - loss: 0.2550 - iou_score: 0.7264 - f1-score: 0.8394For batch 121, tr_loss is    0.26.\n",
      "123/244 [==============>...............] - ETA: 1:42 - loss: 0.2554 - iou_score: 0.7259 - f1-score: 0.8390For batch 122, tr_loss is    0.26.\n",
      "124/244 [==============>...............] - ETA: 1:41 - loss: 0.2558 - iou_score: 0.7252 - f1-score: 0.8385For batch 123, tr_loss is    0.26.\n",
      "125/244 [==============>...............] - ETA: 1:40 - loss: 0.2556 - iou_score: 0.7255 - f1-score: 0.8388For batch 124, tr_loss is    0.26.\n",
      "126/244 [==============>...............] - ETA: 1:39 - loss: 0.2554 - iou_score: 0.7257 - f1-score: 0.8389For batch 125, tr_loss is    0.26.\n",
      "127/244 [==============>...............] - ETA: 1:38 - loss: 0.2557 - iou_score: 0.7252 - f1-score: 0.8386For batch 126, tr_loss is    0.26.\n",
      "128/244 [==============>...............] - ETA: 1:38 - loss: 0.2554 - iou_score: 0.7256 - f1-score: 0.8388For batch 127, tr_loss is    0.26.\n",
      "129/244 [==============>...............] - ETA: 1:37 - loss: 0.2553 - iou_score: 0.7258 - f1-score: 0.8390For batch 128, tr_loss is    0.26.\n",
      "130/244 [==============>...............] - ETA: 1:36 - loss: 0.2555 - iou_score: 0.7253 - f1-score: 0.8387For batch 129, tr_loss is    0.26.\n",
      "131/244 [===============>..............] - ETA: 1:35 - loss: 0.2552 - iou_score: 0.7257 - f1-score: 0.8389For batch 130, tr_loss is    0.26.\n",
      "132/244 [===============>..............] - ETA: 1:34 - loss: 0.2555 - iou_score: 0.7251 - f1-score: 0.8385For batch 131, tr_loss is    0.26.\n",
      "133/244 [===============>..............] - ETA: 1:34 - loss: 0.2558 - iou_score: 0.7249 - f1-score: 0.8384For batch 132, tr_loss is    0.26.\n",
      "134/244 [===============>..............] - ETA: 1:33 - loss: 0.2563 - iou_score: 0.7240 - f1-score: 0.8377For batch 133, tr_loss is    0.26.\n",
      "135/244 [===============>..............] - ETA: 1:32 - loss: 0.2564 - iou_score: 0.7237 - f1-score: 0.8375For batch 134, tr_loss is    0.26.\n",
      "136/244 [===============>..............] - ETA: 1:31 - loss: 0.2560 - iou_score: 0.7243 - f1-score: 0.8379For batch 135, tr_loss is    0.26.\n",
      "137/244 [===============>..............] - ETA: 1:30 - loss: 0.2558 - iou_score: 0.7244 - f1-score: 0.8380For batch 136, tr_loss is    0.26.\n",
      "138/244 [===============>..............] - ETA: 1:29 - loss: 0.2558 - iou_score: 0.7243 - f1-score: 0.8379For batch 137, tr_loss is    0.26.\n",
      "139/244 [================>.............] - ETA: 1:29 - loss: 0.2560 - iou_score: 0.7241 - f1-score: 0.8378For batch 138, tr_loss is    0.26.\n",
      "140/244 [================>.............] - ETA: 1:28 - loss: 0.2561 - iou_score: 0.7239 - f1-score: 0.8377For batch 139, tr_loss is    0.26.\n",
      "141/244 [================>.............] - ETA: 1:27 - loss: 0.2562 - iou_score: 0.7238 - f1-score: 0.8376For batch 140, tr_loss is    0.26.\n",
      "142/244 [================>.............] - ETA: 1:26 - loss: 0.2564 - iou_score: 0.7232 - f1-score: 0.8373For batch 141, tr_loss is    0.26.\n",
      "143/244 [================>.............] - ETA: 1:26 - loss: 0.2562 - iou_score: 0.7235 - f1-score: 0.8375For batch 142, tr_loss is    0.26.\n",
      "144/244 [================>.............] - ETA: 1:25 - loss: 0.2568 - iou_score: 0.7229 - f1-score: 0.8370For batch 143, tr_loss is    0.26.\n",
      "145/244 [================>.............] - ETA: 1:24 - loss: 0.2570 - iou_score: 0.7226 - f1-score: 0.8368For batch 144, tr_loss is    0.26.\n",
      "146/244 [================>.............] - ETA: 1:23 - loss: 0.2570 - iou_score: 0.7225 - f1-score: 0.8367For batch 145, tr_loss is    0.26.\n",
      "147/244 [=================>............] - ETA: 1:22 - loss: 0.2569 - iou_score: 0.7225 - f1-score: 0.8368For batch 146, tr_loss is    0.26.\n",
      "148/244 [=================>............] - ETA: 1:22 - loss: 0.2570 - iou_score: 0.7222 - f1-score: 0.8366For batch 147, tr_loss is    0.26.\n",
      "149/244 [=================>............] - ETA: 1:21 - loss: 0.2572 - iou_score: 0.7220 - f1-score: 0.8365For batch 148, tr_loss is    0.26.\n",
      "150/244 [=================>............] - ETA: 1:20 - loss: 0.2571 - iou_score: 0.7220 - f1-score: 0.8365For batch 149, tr_loss is    0.26.\n",
      "151/244 [=================>............] - ETA: 1:19 - loss: 0.2572 - iou_score: 0.7220 - f1-score: 0.8365For batch 150, tr_loss is    0.26.\n",
      "152/244 [=================>............] - ETA: 1:18 - loss: 0.2575 - iou_score: 0.7218 - f1-score: 0.8364For batch 151, tr_loss is    0.26.\n",
      "153/244 [=================>............] - ETA: 1:17 - loss: 0.2575 - iou_score: 0.7220 - f1-score: 0.8365For batch 152, tr_loss is    0.26.\n",
      "154/244 [=================>............] - ETA: 1:16 - loss: 0.2574 - iou_score: 0.7220 - f1-score: 0.8365For batch 153, tr_loss is    0.26.\n",
      "155/244 [==================>...........] - ETA: 1:16 - loss: 0.2576 - iou_score: 0.7218 - f1-score: 0.8364For batch 154, tr_loss is    0.26.\n",
      "156/244 [==================>...........] - ETA: 1:15 - loss: 0.2572 - iou_score: 0.7222 - f1-score: 0.8366For batch 155, tr_loss is    0.26.\n",
      "157/244 [==================>...........] - ETA: 1:14 - loss: 0.2570 - iou_score: 0.7223 - f1-score: 0.8368For batch 156, tr_loss is    0.26.\n",
      "158/244 [==================>...........] - ETA: 1:13 - loss: 0.2570 - iou_score: 0.7223 - f1-score: 0.8368For batch 157, tr_loss is    0.26.\n",
      "159/244 [==================>...........] - ETA: 1:12 - loss: 0.2569 - iou_score: 0.7224 - f1-score: 0.8368For batch 158, tr_loss is    0.26.\n",
      "160/244 [==================>...........] - ETA: 1:11 - loss: 0.2566 - iou_score: 0.7228 - f1-score: 0.8371For batch 159, tr_loss is    0.26.\n",
      "161/244 [==================>...........] - ETA: 1:11 - loss: 0.2567 - iou_score: 0.7227 - f1-score: 0.8370For batch 160, tr_loss is    0.26.\n",
      "162/244 [==================>...........] - ETA: 1:10 - loss: 0.2564 - iou_score: 0.7230 - f1-score: 0.8372For batch 161, tr_loss is    0.26.\n",
      "163/244 [===================>..........] - ETA: 1:09 - loss: 0.2564 - iou_score: 0.7230 - f1-score: 0.8372For batch 162, tr_loss is    0.26.\n",
      "164/244 [===================>..........] - ETA: 1:08 - loss: 0.2563 - iou_score: 0.7232 - f1-score: 0.8374For batch 163, tr_loss is    0.26.\n",
      "165/244 [===================>..........] - ETA: 1:07 - loss: 0.2565 - iou_score: 0.7230 - f1-score: 0.8372For batch 164, tr_loss is    0.26.\n",
      "166/244 [===================>..........] - ETA: 1:06 - loss: 0.2565 - iou_score: 0.7228 - f1-score: 0.8372For batch 165, tr_loss is    0.26.\n",
      "167/244 [===================>..........] - ETA: 1:05 - loss: 0.2563 - iou_score: 0.7231 - f1-score: 0.8374For batch 166, tr_loss is    0.26.\n",
      "168/244 [===================>..........] - ETA: 1:04 - loss: 0.2560 - iou_score: 0.7235 - f1-score: 0.8376For batch 167, tr_loss is    0.26.\n",
      "169/244 [===================>..........] - ETA: 1:04 - loss: 0.2558 - iou_score: 0.7237 - f1-score: 0.8377For batch 168, tr_loss is    0.26.\n",
      "170/244 [===================>..........] - ETA: 1:03 - loss: 0.2560 - iou_score: 0.7234 - f1-score: 0.8376For batch 169, tr_loss is    0.26.\n",
      "171/244 [====================>.........] - ETA: 1:02 - loss: 0.2556 - iou_score: 0.7238 - f1-score: 0.8378For batch 170, tr_loss is    0.26.\n",
      "172/244 [====================>.........] - ETA: 1:01 - loss: 0.2557 - iou_score: 0.7237 - f1-score: 0.8377For batch 171, tr_loss is    0.26.\n",
      "173/244 [====================>.........] - ETA: 1:00 - loss: 0.2560 - iou_score: 0.7235 - f1-score: 0.8376For batch 172, tr_loss is    0.26.\n",
      "174/244 [====================>.........] - ETA: 59s - loss: 0.2563 - iou_score: 0.7229 - f1-score: 0.8372 For batch 173, tr_loss is    0.26.\n",
      "175/244 [====================>.........] - ETA: 59s - loss: 0.2564 - iou_score: 0.7227 - f1-score: 0.8371For batch 174, tr_loss is    0.26.\n",
      "176/244 [====================>.........] - ETA: 58s - loss: 0.2562 - iou_score: 0.7229 - f1-score: 0.8372For batch 175, tr_loss is    0.26.\n",
      "177/244 [====================>.........] - ETA: 57s - loss: 0.2559 - iou_score: 0.7233 - f1-score: 0.8375For batch 176, tr_loss is    0.26.\n",
      "178/244 [====================>.........] - ETA: 56s - loss: 0.2562 - iou_score: 0.7229 - f1-score: 0.8372For batch 177, tr_loss is    0.26.\n",
      "179/244 [=====================>........] - ETA: 55s - loss: 0.2562 - iou_score: 0.7230 - f1-score: 0.8373For batch 178, tr_loss is    0.26.\n",
      "180/244 [=====================>........] - ETA: 54s - loss: 0.2560 - iou_score: 0.7232 - f1-score: 0.8374For batch 179, tr_loss is    0.26.\n",
      "181/244 [=====================>........] - ETA: 53s - loss: 0.2558 - iou_score: 0.7236 - f1-score: 0.8377For batch 180, tr_loss is    0.26.\n",
      "182/244 [=====================>........] - ETA: 52s - loss: 0.2559 - iou_score: 0.7234 - f1-score: 0.8376For batch 181, tr_loss is    0.26.\n",
      "183/244 [=====================>........] - ETA: 52s - loss: 0.2560 - iou_score: 0.7233 - f1-score: 0.8375For batch 182, tr_loss is    0.26.\n",
      "184/244 [=====================>........] - ETA: 51s - loss: 0.2561 - iou_score: 0.7231 - f1-score: 0.8373For batch 183, tr_loss is    0.26.\n",
      "185/244 [=====================>........] - ETA: 50s - loss: 0.2563 - iou_score: 0.7230 - f1-score: 0.8373For batch 184, tr_loss is    0.26.\n",
      "186/244 [=====================>........] - ETA: 49s - loss: 0.2559 - iou_score: 0.7235 - f1-score: 0.8376For batch 185, tr_loss is    0.26.\n",
      "187/244 [=====================>........] - ETA: 48s - loss: 0.2562 - iou_score: 0.7230 - f1-score: 0.8373For batch 186, tr_loss is    0.26.\n",
      "188/244 [======================>.......] - ETA: 47s - loss: 0.2565 - iou_score: 0.7228 - f1-score: 0.8372For batch 187, tr_loss is    0.26.\n",
      "189/244 [======================>.......] - ETA: 47s - loss: 0.2564 - iou_score: 0.7229 - f1-score: 0.8372For batch 188, tr_loss is    0.26.\n",
      "190/244 [======================>.......] - ETA: 46s - loss: 0.2560 - iou_score: 0.7233 - f1-score: 0.8375For batch 189, tr_loss is    0.26.\n",
      "191/244 [======================>.......] - ETA: 45s - loss: 0.2558 - iou_score: 0.7237 - f1-score: 0.8377For batch 190, tr_loss is    0.26.\n",
      "192/244 [======================>.......] - ETA: 44s - loss: 0.2557 - iou_score: 0.7236 - f1-score: 0.8377For batch 191, tr_loss is    0.26.\n",
      "193/244 [======================>.......] - ETA: 43s - loss: 0.2557 - iou_score: 0.7235 - f1-score: 0.8377For batch 192, tr_loss is    0.26.\n",
      "194/244 [======================>.......] - ETA: 42s - loss: 0.2555 - iou_score: 0.7238 - f1-score: 0.8378For batch 193, tr_loss is    0.26.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195/244 [======================>.......] - ETA: 42s - loss: 0.2557 - iou_score: 0.7237 - f1-score: 0.8378For batch 194, tr_loss is    0.26.\n",
      "196/244 [=======================>......] - ETA: 41s - loss: 0.2557 - iou_score: 0.7237 - f1-score: 0.8378For batch 195, tr_loss is    0.26.\n",
      "197/244 [=======================>......] - ETA: 40s - loss: 0.2559 - iou_score: 0.7234 - f1-score: 0.8376For batch 196, tr_loss is    0.26.\n",
      "198/244 [=======================>......] - ETA: 39s - loss: 0.2557 - iou_score: 0.7236 - f1-score: 0.8378For batch 197, tr_loss is    0.26.\n",
      "199/244 [=======================>......] - ETA: 38s - loss: 0.2554 - iou_score: 0.7241 - f1-score: 0.8381For batch 198, tr_loss is    0.26.\n",
      "200/244 [=======================>......] - ETA: 37s - loss: 0.2553 - iou_score: 0.7242 - f1-score: 0.8382For batch 199, tr_loss is    0.26.\n",
      "201/244 [=======================>......] - ETA: 37s - loss: 0.2555 - iou_score: 0.7240 - f1-score: 0.8380For batch 200, tr_loss is    0.26.\n",
      "202/244 [=======================>......] - ETA: 36s - loss: 0.2553 - iou_score: 0.7241 - f1-score: 0.8381For batch 201, tr_loss is    0.26.\n",
      "203/244 [=======================>......] - ETA: 35s - loss: 0.2552 - iou_score: 0.7243 - f1-score: 0.8382For batch 202, tr_loss is    0.26.\n",
      "204/244 [========================>.....] - ETA: 34s - loss: 0.2548 - iou_score: 0.7247 - f1-score: 0.8385For batch 203, tr_loss is    0.25.\n",
      "205/244 [========================>.....] - ETA: 33s - loss: 0.2545 - iou_score: 0.7250 - f1-score: 0.8387For batch 204, tr_loss is    0.25.\n",
      "206/244 [========================>.....] - ETA: 32s - loss: 0.2548 - iou_score: 0.7248 - f1-score: 0.8385For batch 205, tr_loss is    0.25.\n",
      "207/244 [========================>.....] - ETA: 31s - loss: 0.2545 - iou_score: 0.7251 - f1-score: 0.8387For batch 206, tr_loss is    0.25.\n",
      "208/244 [========================>.....] - ETA: 30s - loss: 0.2546 - iou_score: 0.7250 - f1-score: 0.8387For batch 207, tr_loss is    0.25.\n",
      "209/244 [========================>.....] - ETA: 30s - loss: 0.2545 - iou_score: 0.7250 - f1-score: 0.8387For batch 208, tr_loss is    0.25.\n",
      "210/244 [========================>.....] - ETA: 29s - loss: 0.2542 - iou_score: 0.7254 - f1-score: 0.8389For batch 209, tr_loss is    0.25.\n",
      "211/244 [========================>.....] - ETA: 28s - loss: 0.2543 - iou_score: 0.7253 - f1-score: 0.8389For batch 210, tr_loss is    0.25.\n",
      "212/244 [=========================>....] - ETA: 27s - loss: 0.2543 - iou_score: 0.7252 - f1-score: 0.8389For batch 211, tr_loss is    0.25.\n",
      "213/244 [=========================>....] - ETA: 26s - loss: 0.2544 - iou_score: 0.7251 - f1-score: 0.8388For batch 212, tr_loss is    0.25.\n",
      "214/244 [=========================>....] - ETA: 25s - loss: 0.2541 - iou_score: 0.7255 - f1-score: 0.8390For batch 213, tr_loss is    0.25.\n",
      "215/244 [=========================>....] - ETA: 25s - loss: 0.2539 - iou_score: 0.7258 - f1-score: 0.8392For batch 214, tr_loss is    0.25.\n",
      "216/244 [=========================>....] - ETA: 24s - loss: 0.2539 - iou_score: 0.7258 - f1-score: 0.8392For batch 215, tr_loss is    0.25.\n",
      "217/244 [=========================>....] - ETA: 23s - loss: 0.2540 - iou_score: 0.7258 - f1-score: 0.8392For batch 216, tr_loss is    0.25.\n",
      "218/244 [=========================>....] - ETA: 22s - loss: 0.2538 - iou_score: 0.7258 - f1-score: 0.8392For batch 217, tr_loss is    0.25.\n",
      "219/244 [=========================>....] - ETA: 21s - loss: 0.2538 - iou_score: 0.7259 - f1-score: 0.8393For batch 218, tr_loss is    0.25.\n",
      "220/244 [==========================>...] - ETA: 20s - loss: 0.2537 - iou_score: 0.7259 - f1-score: 0.8393For batch 219, tr_loss is    0.25.\n",
      "221/244 [==========================>...] - ETA: 19s - loss: 0.2538 - iou_score: 0.7258 - f1-score: 0.8392For batch 220, tr_loss is    0.25.\n",
      "222/244 [==========================>...] - ETA: 19s - loss: 0.2535 - iou_score: 0.7262 - f1-score: 0.8395For batch 221, tr_loss is    0.25.\n",
      "223/244 [==========================>...] - ETA: 18s - loss: 0.2534 - iou_score: 0.7263 - f1-score: 0.8396For batch 222, tr_loss is    0.25.\n",
      "224/244 [==========================>...] - ETA: 17s - loss: 0.2534 - iou_score: 0.7262 - f1-score: 0.8395For batch 223, tr_loss is    0.25.\n",
      "225/244 [==========================>...] - ETA: 16s - loss: 0.2534 - iou_score: 0.7261 - f1-score: 0.8395For batch 224, tr_loss is    0.25.\n",
      "226/244 [==========================>...] - ETA: 15s - loss: 0.2532 - iou_score: 0.7264 - f1-score: 0.8396For batch 225, tr_loss is    0.25.\n",
      "227/244 [==========================>...] - ETA: 14s - loss: 0.2531 - iou_score: 0.7265 - f1-score: 0.8397For batch 226, tr_loss is    0.25.\n",
      "228/244 [===========================>..] - ETA: 13s - loss: 0.2530 - iou_score: 0.7267 - f1-score: 0.8398For batch 227, tr_loss is    0.25.\n",
      "229/244 [===========================>..] - ETA: 12s - loss: 0.2528 - iou_score: 0.7268 - f1-score: 0.8399For batch 228, tr_loss is    0.25.\n",
      "230/244 [===========================>..] - ETA: 12s - loss: 0.2527 - iou_score: 0.7269 - f1-score: 0.8400For batch 229, tr_loss is    0.25.\n",
      "231/244 [===========================>..] - ETA: 11s - loss: 0.2525 - iou_score: 0.7272 - f1-score: 0.8402For batch 230, tr_loss is    0.25.\n",
      "232/244 [===========================>..] - ETA: 10s - loss: 0.2525 - iou_score: 0.7272 - f1-score: 0.8402For batch 231, tr_loss is    0.25.\n",
      "233/244 [===========================>..] - ETA: 9s - loss: 0.2532 - iou_score: 0.7266 - f1-score: 0.8397 For batch 232, tr_loss is    0.25.\n",
      "234/244 [===========================>..] - ETA: 8s - loss: 0.2531 - iou_score: 0.7266 - f1-score: 0.8397For batch 233, tr_loss is    0.25.\n",
      "235/244 [===========================>..] - ETA: 7s - loss: 0.2528 - iou_score: 0.7269 - f1-score: 0.8400For batch 234, tr_loss is    0.25.\n",
      "236/244 [============================>.] - ETA: 6s - loss: 0.2530 - iou_score: 0.7267 - f1-score: 0.8398For batch 235, tr_loss is    0.25.\n",
      "237/244 [============================>.] - ETA: 6s - loss: 0.2530 - iou_score: 0.7267 - f1-score: 0.8398For batch 236, tr_loss is    0.25.\n",
      "238/244 [============================>.] - ETA: 5s - loss: 0.2529 - iou_score: 0.7269 - f1-score: 0.8399For batch 237, tr_loss is    0.25.\n",
      "239/244 [============================>.] - ETA: 4s - loss: 0.2529 - iou_score: 0.7269 - f1-score: 0.8400For batch 238, tr_loss is    0.25.\n",
      "240/244 [============================>.] - ETA: 3s - loss: 0.2526 - iou_score: 0.7273 - f1-score: 0.8402For batch 239, tr_loss is    0.25.\n",
      "241/244 [============================>.] - ETA: 2s - loss: 0.2526 - iou_score: 0.7273 - f1-score: 0.8402For batch 240, tr_loss is    0.25.\n",
      "242/244 [============================>.] - ETA: 1s - loss: 0.2529 - iou_score: 0.7270 - f1-score: 0.8400For batch 241, tr_loss is    0.25.\n",
      "243/244 [============================>.] - ETA: 0s - loss: 0.2532 - iou_score: 0.7265 - f1-score: 0.8397For batch 242, tr_loss is    0.25.\n",
      "244/244 [==============================] - ETA: 0s - loss: 0.2532 - iou_score: 0.7264 - f1-score: 0.8396For batch 243, tr_loss is    0.25.\n",
      "For batch 0, vl_loss is    0.37.\n",
      "For batch 1, vl_loss is    0.34.\n",
      "For batch 2, vl_loss is    0.33.\n",
      "For batch 3, vl_loss is    0.37.\n",
      "For batch 4, vl_loss is    0.36.\n",
      "For batch 5, vl_loss is    0.36.\n",
      "For batch 6, vl_loss is    0.38.\n",
      "For batch 7, vl_loss is    0.37.\n",
      "For batch 8, vl_loss is    0.37.\n",
      "For batch 9, vl_loss is    0.37.\n",
      "For batch 10, vl_loss is    0.38.\n",
      "For batch 11, vl_loss is    0.38.\n",
      "For batch 12, vl_loss is    0.38.\n",
      "For batch 13, vl_loss is    0.38.\n",
      "For batch 14, vl_loss is    0.39.\n",
      "For batch 15, vl_loss is    0.39.\n",
      "For batch 16, vl_loss is    0.38.\n",
      "For batch 17, vl_loss is    0.38.\n",
      "For batch 18, vl_loss is    0.38.\n",
      "For batch 19, vl_loss is    0.38.\n",
      "For batch 20, vl_loss is    0.38.\n",
      "For batch 21, vl_loss is    0.38.\n",
      "For batch 22, vl_loss is    0.38.\n",
      "For batch 23, vl_loss is    0.38.\n",
      "For batch 24, vl_loss is    0.38.\n",
      "For batch 25, vl_loss is    0.38.\n",
      "For batch 26, vl_loss is    0.38.\n",
      "For batch 27, vl_loss is    0.38.\n",
      "For batch 28, vl_loss is    0.39.\n",
      "For batch 29, vl_loss is    0.39.\n",
      "For batch 30, vl_loss is    0.39.\n",
      "For batch 31, vl_loss is    0.39.\n",
      "For batch 32, vl_loss is    0.39.\n",
      "For batch 33, vl_loss is    0.39.\n",
      "For batch 34, vl_loss is    0.39.\n",
      "For batch 35, vl_loss is    0.39.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 36, vl_loss is    0.38.\n",
      "For batch 37, vl_loss is    0.39.\n",
      "For batch 38, vl_loss is    0.39.\n",
      "For batch 39, vl_loss is    0.39.\n",
      "For batch 40, vl_loss is    0.39.\n",
      "For batch 41, vl_loss is    0.39.\n",
      "For batch 42, vl_loss is    0.39.\n",
      "For batch 43, vl_loss is    0.39.\n",
      "For batch 44, vl_loss is    0.38.\n",
      "For batch 45, vl_loss is    0.38.\n",
      "For batch 46, vl_loss is    0.38.\n",
      "For batch 47, vl_loss is    0.38.\n",
      "For batch 48, vl_loss is    0.38.\n",
      "For batch 49, vl_loss is    0.38.\n",
      "For batch 50, vl_loss is    0.38.\n",
      "For batch 51, vl_loss is    0.38.\n",
      "For batch 52, vl_loss is    0.38.\n",
      "For batch 53, vl_loss is    0.38.\n",
      "For batch 54, vl_loss is    0.38.\n",
      "For batch 55, vl_loss is    0.38.\n",
      "244/244 [==============================] - 213s 866ms/step - loss: 0.2532 - iou_score: 0.7264 - f1-score: 0.8396 - val_loss: 0.3797 - val_iou_score: 0.6147 - val_f1-score: 0.7591\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.34998\n",
      "The average loss for epoch 12 is    0.25 \n",
      "47/47 [==============================] - 4s 87ms/step - loss: 0.3628 - iou_score: 0.6097 - f1-score: 0.7546\n",
      "./model/tumor_100_unet_efficientnetb0_imagenet_09293.hdf5\n",
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Number of devices: 2\n",
      "Epoch 1/200\n",
      "INFO:tensorflow:batch_all_reduce: 130 all-reduces with algorithm = nccl, num_packs = 1\n",
      "      1/Unknown - 47s 47s/step - loss: 0.5405 - iou_score: 0.3534 - f1-score: 0.5211For batch 0, tr_loss is    0.54.\n",
      "      2/Unknown - 48s 2s/step - loss: 0.5453 - iou_score: 0.3678 - f1-score: 0.5366 For batch 1, tr_loss is    0.55.\n",
      "      3/Unknown - 50s 1s/step - loss: 0.5350 - iou_score: 0.3832 - f1-score: 0.5529For batch 2, tr_loss is    0.54.\n",
      "      4/Unknown - 51s 1s/step - loss: 0.5101 - iou_score: 0.4177 - f1-score: 0.5853For batch 3, tr_loss is    0.51.\n",
      "      5/Unknown - 52s 1s/step - loss: 0.4965 - iou_score: 0.4377 - f1-score: 0.6047For batch 4, tr_loss is    0.50.\n",
      "      6/Unknown - 54s 1s/step - loss: 0.5021 - iou_score: 0.4347 - f1-score: 0.6023For batch 5, tr_loss is    0.50.\n",
      "      7/Unknown - 55s 1s/step - loss: 0.5017 - iou_score: 0.4415 - f1-score: 0.6088For batch 6, tr_loss is    0.50.\n",
      "      8/Unknown - 56s 1s/step - loss: 0.4968 - iou_score: 0.4542 - f1-score: 0.6206For batch 7, tr_loss is    0.50.\n",
      "      9/Unknown - 57s 1s/step - loss: 0.4932 - iou_score: 0.4651 - f1-score: 0.6300For batch 8, tr_loss is    0.49.\n",
      "     10/Unknown - 58s 1s/step - loss: 0.4904 - iou_score: 0.4740 - f1-score: 0.6381For batch 9, tr_loss is    0.49.\n",
      "     11/Unknown - 59s 1s/step - loss: 0.4841 - iou_score: 0.4856 - f1-score: 0.6482For batch 10, tr_loss is    0.48.\n",
      "     12/Unknown - 60s 1s/step - loss: 0.4842 - iou_score: 0.4887 - f1-score: 0.6513For batch 11, tr_loss is    0.48.\n",
      "     13/Unknown - 60s 1s/step - loss: 0.4869 - iou_score: 0.4881 - f1-score: 0.6511For batch 12, tr_loss is    0.49.\n",
      "     14/Unknown - 61s 1s/step - loss: 0.4816 - iou_score: 0.4958 - f1-score: 0.6579For batch 13, tr_loss is    0.48.\n",
      "     15/Unknown - 62s 1s/step - loss: 0.4781 - iou_score: 0.5004 - f1-score: 0.6621For batch 14, tr_loss is    0.48.\n",
      "     16/Unknown - 63s 1s/step - loss: 0.4765 - iou_score: 0.5027 - f1-score: 0.6640For batch 15, tr_loss is    0.48.\n",
      "     17/Unknown - 64s 1s/step - loss: 0.4713 - iou_score: 0.5095 - f1-score: 0.6699For batch 16, tr_loss is    0.47.\n",
      "     18/Unknown - 65s 1s/step - loss: 0.4695 - iou_score: 0.5123 - f1-score: 0.6725For batch 17, tr_loss is    0.47.\n",
      "     19/Unknown - 66s 1s/step - loss: 0.4642 - iou_score: 0.5196 - f1-score: 0.6785For batch 18, tr_loss is    0.46.\n",
      "     20/Unknown - 67s 1s/step - loss: 0.4609 - iou_score: 0.5222 - f1-score: 0.6809For batch 19, tr_loss is    0.46.\n",
      "     21/Unknown - 67s 1s/step - loss: 0.4576 - iou_score: 0.5248 - f1-score: 0.6833For batch 20, tr_loss is    0.46.\n",
      "     22/Unknown - 68s 1s/step - loss: 0.4536 - iou_score: 0.5297 - f1-score: 0.6875For batch 21, tr_loss is    0.45.\n",
      "     23/Unknown - 69s 1s/step - loss: 0.4569 - iou_score: 0.5267 - f1-score: 0.6850For batch 22, tr_loss is    0.46.\n",
      "     24/Unknown - 70s 987ms/step - loss: 0.4564 - iou_score: 0.5279 - f1-score: 0.6862For batch 23, tr_loss is    0.46.\n",
      "     25/Unknown - 70s 973ms/step - loss: 0.4546 - iou_score: 0.5304 - f1-score: 0.6885For batch 24, tr_loss is    0.45.\n",
      "     26/Unknown - 71s 980ms/step - loss: 0.4503 - iou_score: 0.5360 - f1-score: 0.6930For batch 25, tr_loss is    0.45.\n",
      "     27/Unknown - 72s 983ms/step - loss: 0.4495 - iou_score: 0.5367 - f1-score: 0.6938For batch 26, tr_loss is    0.45.\n",
      "     28/Unknown - 73s 984ms/step - loss: 0.4470 - iou_score: 0.5396 - f1-score: 0.6962For batch 27, tr_loss is    0.45.\n",
      "     29/Unknown - 74s 977ms/step - loss: 0.4444 - iou_score: 0.5431 - f1-score: 0.6988For batch 28, tr_loss is    0.44.\n",
      "     30/Unknown - 75s 961ms/step - loss: 0.4425 - iou_score: 0.5449 - f1-score: 0.7004For batch 29, tr_loss is    0.44.\n",
      "     31/Unknown - 76s 964ms/step - loss: 0.4401 - iou_score: 0.5479 - f1-score: 0.7029For batch 30, tr_loss is    0.44.\n",
      "     32/Unknown - 76s 947ms/step - loss: 0.4376 - iou_score: 0.5510 - f1-score: 0.7055For batch 31, tr_loss is    0.44.\n",
      "     33/Unknown - 78s 960ms/step - loss: 0.4350 - iou_score: 0.5550 - f1-score: 0.7087For batch 32, tr_loss is    0.44.\n",
      "     34/Unknown - 79s 961ms/step - loss: 0.4331 - iou_score: 0.5571 - f1-score: 0.7104For batch 33, tr_loss is    0.43.\n",
      "     35/Unknown - 79s 954ms/step - loss: 0.4331 - iou_score: 0.5576 - f1-score: 0.7109For batch 34, tr_loss is    0.43.\n",
      "     36/Unknown - 80s 957ms/step - loss: 0.4300 - iou_score: 0.5612 - f1-score: 0.7138For batch 35, tr_loss is    0.43.\n",
      "     37/Unknown - 81s 943ms/step - loss: 0.4288 - iou_score: 0.5628 - f1-score: 0.7152For batch 36, tr_loss is    0.43.\n",
      "     38/Unknown - 82s 947ms/step - loss: 0.4255 - iou_score: 0.5665 - f1-score: 0.7180For batch 37, tr_loss is    0.43.\n",
      "     39/Unknown - 83s 943ms/step - loss: 0.4256 - iou_score: 0.5662 - f1-score: 0.7179For batch 38, tr_loss is    0.43.\n",
      "     40/Unknown - 83s 937ms/step - loss: 0.4225 - iou_score: 0.5698 - f1-score: 0.7207For batch 39, tr_loss is    0.42.\n",
      "     41/Unknown - 84s 939ms/step - loss: 0.4211 - iou_score: 0.5710 - f1-score: 0.7218For batch 40, tr_loss is    0.42.\n",
      "     42/Unknown - 85s 928ms/step - loss: 0.4201 - iou_score: 0.5717 - f1-score: 0.7224For batch 41, tr_loss is    0.42.\n",
      "     43/Unknown - 86s 924ms/step - loss: 0.4179 - iou_score: 0.5741 - f1-score: 0.7244For batch 42, tr_loss is    0.42.\n",
      "     44/Unknown - 87s 928ms/step - loss: 0.4167 - iou_score: 0.5754 - f1-score: 0.7255For batch 43, tr_loss is    0.42.\n",
      "     45/Unknown - 88s 930ms/step - loss: 0.4160 - iou_score: 0.5762 - f1-score: 0.7262For batch 44, tr_loss is    0.42.\n",
      "     46/Unknown - 89s 931ms/step - loss: 0.4156 - iou_score: 0.5767 - f1-score: 0.7267For batch 45, tr_loss is    0.42.\n",
      "     47/Unknown - 89s 920ms/step - loss: 0.4137 - iou_score: 0.5792 - f1-score: 0.7287For batch 46, tr_loss is    0.41.\n",
      "     48/Unknown - 90s 916ms/step - loss: 0.4129 - iou_score: 0.5803 - f1-score: 0.7296For batch 47, tr_loss is    0.41.\n",
      "     49/Unknown - 91s 919ms/step - loss: 0.4126 - iou_score: 0.5805 - f1-score: 0.7298For batch 48, tr_loss is    0.41.\n",
      "     50/Unknown - 92s 921ms/step - loss: 0.4133 - iou_score: 0.5798 - f1-score: 0.7293For batch 49, tr_loss is    0.41.\n",
      "     51/Unknown - 92s 911ms/step - loss: 0.4126 - iou_score: 0.5810 - f1-score: 0.7303For batch 50, tr_loss is    0.41.\n",
      "     52/Unknown - 93s 909ms/step - loss: 0.4117 - iou_score: 0.5820 - f1-score: 0.7312For batch 51, tr_loss is    0.41.\n",
      "     53/Unknown - 94s 911ms/step - loss: 0.4114 - iou_score: 0.5821 - f1-score: 0.7313For batch 52, tr_loss is    0.41.\n",
      "     54/Unknown - 95s 914ms/step - loss: 0.4104 - iou_score: 0.5831 - f1-score: 0.7322For batch 53, tr_loss is    0.41.\n",
      "     55/Unknown - 96s 916ms/step - loss: 0.4099 - iou_score: 0.5838 - f1-score: 0.7328For batch 54, tr_loss is    0.41.\n",
      "     56/Unknown - 97s 909ms/step - loss: 0.4091 - iou_score: 0.5847 - f1-score: 0.7335For batch 55, tr_loss is    0.41.\n",
      "     57/Unknown - 98s 905ms/step - loss: 0.4088 - iou_score: 0.5849 - f1-score: 0.7338For batch 56, tr_loss is    0.41.\n",
      "     58/Unknown - 99s 907ms/step - loss: 0.4078 - iou_score: 0.5859 - f1-score: 0.7346For batch 57, tr_loss is    0.41.\n",
      "     59/Unknown - 100s 908ms/step - loss: 0.4066 - iou_score: 0.5873 - f1-score: 0.7357For batch 58, tr_loss is    0.41.\n",
      "     60/Unknown - 100s 902ms/step - loss: 0.4062 - iou_score: 0.5876 - f1-score: 0.7360For batch 59, tr_loss is    0.41.\n",
      "     61/Unknown - 101s 903ms/step - loss: 0.4061 - iou_score: 0.5879 - f1-score: 0.7363For batch 60, tr_loss is    0.41.\n",
      "     62/Unknown - 102s 898ms/step - loss: 0.4059 - iou_score: 0.5886 - f1-score: 0.7369For batch 61, tr_loss is    0.41.\n",
      "     63/Unknown - 103s 903ms/step - loss: 0.4058 - iou_score: 0.5887 - f1-score: 0.7370For batch 62, tr_loss is    0.41.\n",
      "     64/Unknown - 104s 905ms/step - loss: 0.4062 - iou_score: 0.5882 - f1-score: 0.7367For batch 63, tr_loss is    0.41.\n",
      "     65/Unknown - 105s 906ms/step - loss: 0.4044 - iou_score: 0.5906 - f1-score: 0.7385For batch 64, tr_loss is    0.40.\n",
      "     66/Unknown - 106s 907ms/step - loss: 0.4039 - iou_score: 0.5912 - f1-score: 0.7389For batch 65, tr_loss is    0.40.\n",
      "     67/Unknown - 106s 901ms/step - loss: 0.4037 - iou_score: 0.5911 - f1-score: 0.7389For batch 66, tr_loss is    0.40.\n",
      "     68/Unknown - 107s 897ms/step - loss: 0.4027 - iou_score: 0.5924 - f1-score: 0.7399For batch 67, tr_loss is    0.40.\n",
      "     69/Unknown - 108s 899ms/step - loss: 0.4029 - iou_score: 0.5921 - f1-score: 0.7397For batch 68, tr_loss is    0.40.\n",
      "     70/Unknown - 109s 895ms/step - loss: 0.4026 - iou_score: 0.5925 - f1-score: 0.7400For batch 69, tr_loss is    0.40.\n",
      "     71/Unknown - 109s 894ms/step - loss: 0.4019 - iou_score: 0.5930 - f1-score: 0.7405For batch 70, tr_loss is    0.40.\n",
      "     72/Unknown - 110s 895ms/step - loss: 0.4019 - iou_score: 0.5928 - f1-score: 0.7403For batch 71, tr_loss is    0.40.\n",
      "     73/Unknown - 111s 896ms/step - loss: 0.4017 - iou_score: 0.5930 - f1-score: 0.7405For batch 72, tr_loss is    0.40.\n",
      "     74/Unknown - 112s 897ms/step - loss: 0.4023 - iou_score: 0.5920 - f1-score: 0.7397For batch 73, tr_loss is    0.40.\n",
      "     75/Unknown - 113s 891ms/step - loss: 0.4023 - iou_score: 0.5921 - f1-score: 0.7398For batch 74, tr_loss is    0.40.\n",
      "     76/Unknown - 114s 892ms/step - loss: 0.4015 - iou_score: 0.5932 - f1-score: 0.7406For batch 75, tr_loss is    0.40.\n",
      "     77/Unknown - 115s 895ms/step - loss: 0.4009 - iou_score: 0.5937 - f1-score: 0.7411For batch 76, tr_loss is    0.40.\n",
      "     78/Unknown - 116s 894ms/step - loss: 0.4016 - iou_score: 0.5928 - f1-score: 0.7404For batch 77, tr_loss is    0.40.\n",
      "     79/Unknown - 116s 889ms/step - loss: 0.4012 - iou_score: 0.5935 - f1-score: 0.7409For batch 78, tr_loss is    0.40.\n",
      "     80/Unknown - 117s 886ms/step - loss: 0.4000 - iou_score: 0.5950 - f1-score: 0.7421For batch 79, tr_loss is    0.40.\n",
      "     81/Unknown - 118s 890ms/step - loss: 0.3991 - iou_score: 0.5961 - f1-score: 0.7429For batch 80, tr_loss is    0.40.\n",
      "     82/Unknown - 119s 889ms/step - loss: 0.3981 - iou_score: 0.5972 - f1-score: 0.7438For batch 81, tr_loss is    0.40.\n",
      "     83/Unknown - 120s 890ms/step - loss: 0.3981 - iou_score: 0.5972 - f1-score: 0.7438For batch 82, tr_loss is    0.40.\n",
      "     84/Unknown - 121s 888ms/step - loss: 0.3968 - iou_score: 0.5986 - f1-score: 0.7449For batch 83, tr_loss is    0.40.\n",
      "     85/Unknown - 122s 889ms/step - loss: 0.3961 - iou_score: 0.5995 - f1-score: 0.7456For batch 84, tr_loss is    0.40.\n",
      "     86/Unknown - 122s 885ms/step - loss: 0.3955 - iou_score: 0.6002 - f1-score: 0.7462For batch 85, tr_loss is    0.40.\n",
      "     87/Unknown - 123s 883ms/step - loss: 0.3944 - iou_score: 0.6013 - f1-score: 0.7470For batch 86, tr_loss is    0.39.\n",
      "     88/Unknown - 124s 885ms/step - loss: 0.3935 - iou_score: 0.6022 - f1-score: 0.7477For batch 87, tr_loss is    0.39.\n",
      "     89/Unknown - 125s 887ms/step - loss: 0.3931 - iou_score: 0.6028 - f1-score: 0.7482For batch 88, tr_loss is    0.39.\n",
      "     90/Unknown - 126s 885ms/step - loss: 0.3920 - iou_score: 0.6039 - f1-score: 0.7490For batch 89, tr_loss is    0.39.\n",
      "     91/Unknown - 126s 882ms/step - loss: 0.3927 - iou_score: 0.6029 - f1-score: 0.7482For batch 90, tr_loss is    0.39.\n",
      "     92/Unknown - 127s 879ms/step - loss: 0.3925 - iou_score: 0.6033 - f1-score: 0.7485For batch 91, tr_loss is    0.39.\n",
      "     93/Unknown - 128s 877ms/step - loss: 0.3913 - iou_score: 0.6046 - f1-score: 0.7495For batch 92, tr_loss is    0.39.\n",
      "     94/Unknown - 129s 879ms/step - loss: 0.3915 - iou_score: 0.6045 - f1-score: 0.7494For batch 93, tr_loss is    0.39.\n",
      "     95/Unknown - 129s 878ms/step - loss: 0.3909 - iou_score: 0.6054 - f1-score: 0.7501For batch 94, tr_loss is    0.39.\n",
      "     96/Unknown - 130s 879ms/step - loss: 0.3912 - iou_score: 0.6049 - f1-score: 0.7498For batch 95, tr_loss is    0.39.\n",
      "     97/Unknown - 131s 881ms/step - loss: 0.3908 - iou_score: 0.6052 - f1-score: 0.7500For batch 96, tr_loss is    0.39.\n",
      "     98/Unknown - 133s 883ms/step - loss: 0.3909 - iou_score: 0.6049 - f1-score: 0.7498For batch 97, tr_loss is    0.39.\n",
      "     99/Unknown - 133s 881ms/step - loss: 0.3903 - iou_score: 0.6056 - f1-score: 0.7503For batch 98, tr_loss is    0.39.\n",
      "    100/Unknown - 134s 883ms/step - loss: 0.3903 - iou_score: 0.6055 - f1-score: 0.7503For batch 99, tr_loss is    0.39.\n",
      "    101/Unknown - 135s 884ms/step - loss: 0.3902 - iou_score: 0.6055 - f1-score: 0.7503For batch 100, tr_loss is    0.39.\n",
      "    102/Unknown - 136s 884ms/step - loss: 0.3895 - iou_score: 0.6064 - f1-score: 0.7509For batch 101, tr_loss is    0.39.\n",
      "    103/Unknown - 137s 881ms/step - loss: 0.3893 - iou_score: 0.6066 - f1-score: 0.7511For batch 102, tr_loss is    0.39.\n",
      "    104/Unknown - 138s 883ms/step - loss: 0.3889 - iou_score: 0.6070 - f1-score: 0.7515For batch 103, tr_loss is    0.39.\n",
      "    105/Unknown - 139s 884ms/step - loss: 0.3887 - iou_score: 0.6075 - f1-score: 0.7518For batch 104, tr_loss is    0.39.\n",
      "    106/Unknown - 140s 886ms/step - loss: 0.3881 - iou_score: 0.6079 - f1-score: 0.7521For batch 105, tr_loss is    0.39.\n",
      "    107/Unknown - 140s 882ms/step - loss: 0.3876 - iou_score: 0.6085 - f1-score: 0.7526For batch 106, tr_loss is    0.39.\n",
      "    108/Unknown - 141s 883ms/step - loss: 0.3874 - iou_score: 0.6085 - f1-score: 0.7526For batch 107, tr_loss is    0.39.\n",
      "    109/Unknown - 142s 885ms/step - loss: 0.3867 - iou_score: 0.6093 - f1-score: 0.7532For batch 108, tr_loss is    0.39.\n",
      "    110/Unknown - 143s 886ms/step - loss: 0.3861 - iou_score: 0.6100 - f1-score: 0.7538For batch 109, tr_loss is    0.39.\n",
      "    111/Unknown - 145s 888ms/step - loss: 0.3862 - iou_score: 0.6099 - f1-score: 0.7537For batch 110, tr_loss is    0.39.\n",
      "    112/Unknown - 146s 889ms/step - loss: 0.3859 - iou_score: 0.6104 - f1-score: 0.7541For batch 111, tr_loss is    0.39.\n",
      "    113/Unknown - 147s 890ms/step - loss: 0.3851 - iou_score: 0.6112 - f1-score: 0.7547For batch 112, tr_loss is    0.39.\n",
      "    114/Unknown - 147s 887ms/step - loss: 0.3845 - iou_score: 0.6120 - f1-score: 0.7553For batch 113, tr_loss is    0.38.\n",
      "    115/Unknown - 148s 889ms/step - loss: 0.3838 - iou_score: 0.6128 - f1-score: 0.7559For batch 114, tr_loss is    0.38.\n",
      "    116/Unknown - 149s 891ms/step - loss: 0.3835 - iou_score: 0.6132 - f1-score: 0.7562For batch 115, tr_loss is    0.38.\n",
      "    117/Unknown - 150s 889ms/step - loss: 0.3833 - iou_score: 0.6135 - f1-score: 0.7565For batch 116, tr_loss is    0.38.\n",
      "    118/Unknown - 151s 887ms/step - loss: 0.3830 - iou_score: 0.6139 - f1-score: 0.7567For batch 117, tr_loss is    0.38.\n",
      "    119/Unknown - 151s 885ms/step - loss: 0.3823 - iou_score: 0.6146 - f1-score: 0.7573For batch 118, tr_loss is    0.38.\n",
      "    120/Unknown - 152s 885ms/step - loss: 0.3822 - iou_score: 0.6146 - f1-score: 0.7573For batch 119, tr_loss is    0.38.\n",
      "    121/Unknown - 153s 883ms/step - loss: 0.3814 - iou_score: 0.6154 - f1-score: 0.7580For batch 120, tr_loss is    0.38.\n",
      "    122/Unknown - 154s 885ms/step - loss: 0.3808 - iou_score: 0.6161 - f1-score: 0.7584For batch 121, tr_loss is    0.38.\n",
      "    123/Unknown - 155s 883ms/step - loss: 0.3803 - iou_score: 0.6168 - f1-score: 0.7590For batch 122, tr_loss is    0.38.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    124/Unknown - 156s 885ms/step - loss: 0.3801 - iou_score: 0.6169 - f1-score: 0.7591For batch 123, tr_loss is    0.38.\n",
      "    125/Unknown - 157s 884ms/step - loss: 0.3802 - iou_score: 0.6170 - f1-score: 0.7592For batch 124, tr_loss is    0.38.\n",
      "    126/Unknown - 157s 882ms/step - loss: 0.3801 - iou_score: 0.6172 - f1-score: 0.7593For batch 125, tr_loss is    0.38.\n",
      "    127/Unknown - 158s 883ms/step - loss: 0.3799 - iou_score: 0.6173 - f1-score: 0.7594For batch 126, tr_loss is    0.38.\n",
      "    128/Unknown - 159s 884ms/step - loss: 0.3791 - iou_score: 0.6182 - f1-score: 0.7600For batch 127, tr_loss is    0.38.\n",
      "    129/Unknown - 160s 885ms/step - loss: 0.3793 - iou_score: 0.6178 - f1-score: 0.7597For batch 128, tr_loss is    0.38.\n",
      "    130/Unknown - 161s 882ms/step - loss: 0.3788 - iou_score: 0.6184 - f1-score: 0.7602For batch 129, tr_loss is    0.38.\n",
      "    131/Unknown - 162s 884ms/step - loss: 0.3786 - iou_score: 0.6185 - f1-score: 0.7603For batch 130, tr_loss is    0.38.\n",
      "    132/Unknown - 162s 881ms/step - loss: 0.3780 - iou_score: 0.6191 - f1-score: 0.7608For batch 131, tr_loss is    0.38.\n",
      "    133/Unknown - 163s 880ms/step - loss: 0.3780 - iou_score: 0.6191 - f1-score: 0.7608For batch 132, tr_loss is    0.38.\n",
      "    134/Unknown - 164s 879ms/step - loss: 0.3776 - iou_score: 0.6195 - f1-score: 0.7611For batch 133, tr_loss is    0.38.\n",
      "    135/Unknown - 165s 880ms/step - loss: 0.3775 - iou_score: 0.6196 - f1-score: 0.7611For batch 134, tr_loss is    0.38.\n",
      "    136/Unknown - 166s 879ms/step - loss: 0.3774 - iou_score: 0.6194 - f1-score: 0.7611For batch 135, tr_loss is    0.38.\n",
      "    137/Unknown - 167s 880ms/step - loss: 0.3773 - iou_score: 0.6195 - f1-score: 0.7612For batch 136, tr_loss is    0.38.\n",
      "    138/Unknown - 168s 882ms/step - loss: 0.3772 - iou_score: 0.6196 - f1-score: 0.7613For batch 137, tr_loss is    0.38.\n",
      "    139/Unknown - 168s 880ms/step - loss: 0.3771 - iou_score: 0.6196 - f1-score: 0.7613For batch 138, tr_loss is    0.38.\n",
      "    140/Unknown - 169s 881ms/step - loss: 0.3776 - iou_score: 0.6190 - f1-score: 0.7608For batch 139, tr_loss is    0.38.\n",
      "    141/Unknown - 170s 882ms/step - loss: 0.3771 - iou_score: 0.6196 - f1-score: 0.7612For batch 140, tr_loss is    0.38.\n",
      "    142/Unknown - 171s 883ms/step - loss: 0.3769 - iou_score: 0.6199 - f1-score: 0.7615For batch 141, tr_loss is    0.38.\n",
      "    143/Unknown - 173s 885ms/step - loss: 0.3766 - iou_score: 0.6201 - f1-score: 0.7616For batch 142, tr_loss is    0.38.\n",
      "    144/Unknown - 173s 884ms/step - loss: 0.3766 - iou_score: 0.6202 - f1-score: 0.7617For batch 143, tr_loss is    0.38.\n",
      "    145/Unknown - 174s 883ms/step - loss: 0.3764 - iou_score: 0.6202 - f1-score: 0.7617For batch 144, tr_loss is    0.38.\n",
      "    146/Unknown - 175s 883ms/step - loss: 0.3760 - iou_score: 0.6206 - f1-score: 0.7620For batch 145, tr_loss is    0.38.\n",
      "    147/Unknown - 176s 884ms/step - loss: 0.3757 - iou_score: 0.6210 - f1-score: 0.7624For batch 146, tr_loss is    0.38.\n",
      "    148/Unknown - 177s 885ms/step - loss: 0.3754 - iou_score: 0.6213 - f1-score: 0.7626For batch 147, tr_loss is    0.38.\n",
      "    149/Unknown - 177s 882ms/step - loss: 0.3751 - iou_score: 0.6216 - f1-score: 0.7629For batch 148, tr_loss is    0.38.\n",
      "    150/Unknown - 179s 885ms/step - loss: 0.3752 - iou_score: 0.6216 - f1-score: 0.7628For batch 149, tr_loss is    0.38.\n",
      "    151/Unknown - 179s 883ms/step - loss: 0.3753 - iou_score: 0.6214 - f1-score: 0.7628For batch 150, tr_loss is    0.38.\n",
      "    152/Unknown - 180s 884ms/step - loss: 0.3749 - iou_score: 0.6219 - f1-score: 0.7631For batch 151, tr_loss is    0.37.\n",
      "    153/Unknown - 181s 885ms/step - loss: 0.3749 - iou_score: 0.6219 - f1-score: 0.7632For batch 152, tr_loss is    0.37.\n",
      "    154/Unknown - 182s 884ms/step - loss: 0.3747 - iou_score: 0.6221 - f1-score: 0.7633For batch 153, tr_loss is    0.37.\n",
      "    155/Unknown - 183s 882ms/step - loss: 0.3755 - iou_score: 0.6210 - f1-score: 0.7624For batch 154, tr_loss is    0.38.\n",
      "    156/Unknown - 184s 884ms/step - loss: 0.3758 - iou_score: 0.6208 - f1-score: 0.7622For batch 155, tr_loss is    0.38.\n",
      "    157/Unknown - 185s 885ms/step - loss: 0.3756 - iou_score: 0.6209 - f1-score: 0.7623For batch 156, tr_loss is    0.38.\n",
      "    158/Unknown - 185s 882ms/step - loss: 0.3756 - iou_score: 0.6209 - f1-score: 0.7623For batch 157, tr_loss is    0.38.\n",
      "    159/Unknown - 187s 884ms/step - loss: 0.3754 - iou_score: 0.6212 - f1-score: 0.7626For batch 158, tr_loss is    0.38.\n",
      "    160/Unknown - 188s 884ms/step - loss: 0.3753 - iou_score: 0.6214 - f1-score: 0.7627For batch 159, tr_loss is    0.38.\n",
      "    161/Unknown - 189s 885ms/step - loss: 0.3748 - iou_score: 0.6220 - f1-score: 0.7632For batch 160, tr_loss is    0.37.\n",
      "    162/Unknown - 190s 886ms/step - loss: 0.3745 - iou_score: 0.6223 - f1-score: 0.7634For batch 161, tr_loss is    0.37.\n",
      "    163/Unknown - 191s 887ms/step - loss: 0.3746 - iou_score: 0.6222 - f1-score: 0.7634For batch 162, tr_loss is    0.37.\n",
      "    164/Unknown - 191s 884ms/step - loss: 0.3745 - iou_score: 0.6224 - f1-score: 0.7636For batch 163, tr_loss is    0.37.\n",
      "    165/Unknown - 192s 883ms/step - loss: 0.3741 - iou_score: 0.6229 - f1-score: 0.7639For batch 164, tr_loss is    0.37.\n",
      "    166/Unknown - 193s 885ms/step - loss: 0.3746 - iou_score: 0.6224 - f1-score: 0.7635For batch 165, tr_loss is    0.37.\n",
      "    167/Unknown - 193s 882ms/step - loss: 0.3744 - iou_score: 0.6226 - f1-score: 0.7637For batch 166, tr_loss is    0.37.\n",
      "    168/Unknown - 195s 884ms/step - loss: 0.3735 - iou_score: 0.6237 - f1-score: 0.7644For batch 167, tr_loss is    0.37.\n",
      "    169/Unknown - 196s 885ms/step - loss: 0.3731 - iou_score: 0.6242 - f1-score: 0.7648For batch 168, tr_loss is    0.37.\n",
      "    170/Unknown - 196s 882ms/step - loss: 0.3732 - iou_score: 0.6240 - f1-score: 0.7647For batch 169, tr_loss is    0.37.\n",
      "    171/Unknown - 197s 881ms/step - loss: 0.3732 - iou_score: 0.6239 - f1-score: 0.7647For batch 170, tr_loss is    0.37.\n",
      "    172/Unknown - 198s 882ms/step - loss: 0.3735 - iou_score: 0.6236 - f1-score: 0.7644For batch 171, tr_loss is    0.37.\n",
      "    173/Unknown - 198s 880ms/step - loss: 0.3738 - iou_score: 0.6233 - f1-score: 0.7642For batch 172, tr_loss is    0.37.\n",
      "    174/Unknown - 199s 881ms/step - loss: 0.3735 - iou_score: 0.6234 - f1-score: 0.7643For batch 173, tr_loss is    0.37.\n",
      "    175/Unknown - 200s 878ms/step - loss: 0.3735 - iou_score: 0.6234 - f1-score: 0.7643For batch 174, tr_loss is    0.37.\n",
      "    176/Unknown - 200s 877ms/step - loss: 0.3736 - iou_score: 0.6232 - f1-score: 0.7641For batch 175, tr_loss is    0.37.\n",
      "    177/Unknown - 201s 878ms/step - loss: 0.3732 - iou_score: 0.6239 - f1-score: 0.7646For batch 176, tr_loss is    0.37.\n",
      "    178/Unknown - 202s 879ms/step - loss: 0.3731 - iou_score: 0.6240 - f1-score: 0.7647For batch 177, tr_loss is    0.37.\n",
      "    179/Unknown - 203s 878ms/step - loss: 0.3729 - iou_score: 0.6242 - f1-score: 0.7649For batch 178, tr_loss is    0.37.\n",
      "    180/Unknown - 204s 879ms/step - loss: 0.3732 - iou_score: 0.6239 - f1-score: 0.7647For batch 179, tr_loss is    0.37.\n",
      "    181/Unknown - 205s 878ms/step - loss: 0.3731 - iou_score: 0.6240 - f1-score: 0.7648For batch 180, tr_loss is    0.37.\n",
      "    182/Unknown - 206s 877ms/step - loss: 0.3728 - iou_score: 0.6243 - f1-score: 0.7651For batch 181, tr_loss is    0.37.\n",
      "    183/Unknown - 206s 876ms/step - loss: 0.3728 - iou_score: 0.6244 - f1-score: 0.7652For batch 182, tr_loss is    0.37.\n",
      "    184/Unknown - 207s 877ms/step - loss: 0.3725 - iou_score: 0.6247 - f1-score: 0.7653For batch 183, tr_loss is    0.37.\n",
      "    185/Unknown - 208s 878ms/step - loss: 0.3723 - iou_score: 0.6249 - f1-score: 0.7655For batch 184, tr_loss is    0.37.\n",
      "    186/Unknown - 209s 878ms/step - loss: 0.3723 - iou_score: 0.6250 - f1-score: 0.7656For batch 185, tr_loss is    0.37.\n",
      "    187/Unknown - 210s 876ms/step - loss: 0.3718 - iou_score: 0.6255 - f1-score: 0.7660For batch 186, tr_loss is    0.37.\n",
      "    188/Unknown - 211s 878ms/step - loss: 0.3715 - iou_score: 0.6258 - f1-score: 0.7662For batch 187, tr_loss is    0.37.\n",
      "    189/Unknown - 212s 879ms/step - loss: 0.3711 - iou_score: 0.6264 - f1-score: 0.7666For batch 188, tr_loss is    0.37.\n",
      "    190/Unknown - 213s 879ms/step - loss: 0.3707 - iou_score: 0.6267 - f1-score: 0.7669For batch 189, tr_loss is    0.37.\n",
      "    191/Unknown - 214s 880ms/step - loss: 0.3703 - iou_score: 0.6271 - f1-score: 0.7672For batch 190, tr_loss is    0.37.\n",
      "    192/Unknown - 215s 881ms/step - loss: 0.3698 - iou_score: 0.6276 - f1-score: 0.7676For batch 191, tr_loss is    0.37.\n",
      "    193/Unknown - 216s 881ms/step - loss: 0.3696 - iou_score: 0.6278 - f1-score: 0.7677For batch 192, tr_loss is    0.37.\n",
      "    194/Unknown - 217s 879ms/step - loss: 0.3695 - iou_score: 0.6279 - f1-score: 0.7678For batch 193, tr_loss is    0.37.\n",
      "    195/Unknown - 217s 878ms/step - loss: 0.3692 - iou_score: 0.6283 - f1-score: 0.7681For batch 194, tr_loss is    0.37.\n",
      "    196/Unknown - 218s 879ms/step - loss: 0.3688 - iou_score: 0.6286 - f1-score: 0.7683For batch 195, tr_loss is    0.37.\n",
      "    197/Unknown - 219s 878ms/step - loss: 0.3689 - iou_score: 0.6284 - f1-score: 0.7682For batch 196, tr_loss is    0.37.\n",
      "    198/Unknown - 220s 879ms/step - loss: 0.3684 - iou_score: 0.6290 - f1-score: 0.7686For batch 197, tr_loss is    0.37.\n",
      "    199/Unknown - 221s 880ms/step - loss: 0.3690 - iou_score: 0.6283 - f1-score: 0.7681For batch 198, tr_loss is    0.37.\n",
      "    200/Unknown - 222s 881ms/step - loss: 0.3685 - iou_score: 0.6287 - f1-score: 0.7684For batch 199, tr_loss is    0.37.\n",
      "    201/Unknown - 223s 882ms/step - loss: 0.3685 - iou_score: 0.6287 - f1-score: 0.7684For batch 200, tr_loss is    0.37.\n",
      "    202/Unknown - 224s 882ms/step - loss: 0.3681 - iou_score: 0.6292 - f1-score: 0.7688For batch 201, tr_loss is    0.37.\n",
      "    203/Unknown - 225s 882ms/step - loss: 0.3677 - iou_score: 0.6296 - f1-score: 0.7691For batch 202, tr_loss is    0.37.\n",
      "    204/Unknown - 226s 882ms/step - loss: 0.3672 - iou_score: 0.6302 - f1-score: 0.7695For batch 203, tr_loss is    0.37.\n",
      "    205/Unknown - 227s 883ms/step - loss: 0.3670 - iou_score: 0.6304 - f1-score: 0.7697For batch 204, tr_loss is    0.37.\n",
      "    206/Unknown - 228s 884ms/step - loss: 0.3667 - iou_score: 0.6307 - f1-score: 0.7699For batch 205, tr_loss is    0.37.\n",
      "    207/Unknown - 229s 885ms/step - loss: 0.3666 - iou_score: 0.6307 - f1-score: 0.7699For batch 206, tr_loss is    0.37.\n",
      "    208/Unknown - 230s 886ms/step - loss: 0.3665 - iou_score: 0.6307 - f1-score: 0.7699For batch 207, tr_loss is    0.37.\n",
      "    209/Unknown - 231s 886ms/step - loss: 0.3661 - iou_score: 0.6312 - f1-score: 0.7703For batch 208, tr_loss is    0.37.\n",
      "    210/Unknown - 232s 885ms/step - loss: 0.3662 - iou_score: 0.6311 - f1-score: 0.7702For batch 209, tr_loss is    0.37.\n",
      "    211/Unknown - 233s 884ms/step - loss: 0.3662 - iou_score: 0.6311 - f1-score: 0.7703For batch 210, tr_loss is    0.37.\n",
      "    212/Unknown - 234s 885ms/step - loss: 0.3662 - iou_score: 0.6312 - f1-score: 0.7703For batch 211, tr_loss is    0.37.\n",
      "    213/Unknown - 235s 885ms/step - loss: 0.3664 - iou_score: 0.6310 - f1-score: 0.7702For batch 212, tr_loss is    0.37.\n",
      "    214/Unknown - 235s 884ms/step - loss: 0.3663 - iou_score: 0.6310 - f1-score: 0.7702For batch 213, tr_loss is    0.37.\n",
      "    215/Unknown - 236s 883ms/step - loss: 0.3659 - iou_score: 0.6315 - f1-score: 0.7706For batch 214, tr_loss is    0.37.\n",
      "    216/Unknown - 237s 884ms/step - loss: 0.3656 - iou_score: 0.6319 - f1-score: 0.7708For batch 215, tr_loss is    0.37.\n",
      "    217/Unknown - 238s 884ms/step - loss: 0.3651 - iou_score: 0.6325 - f1-score: 0.7713For batch 216, tr_loss is    0.37.\n",
      "    218/Unknown - 238s 883ms/step - loss: 0.3648 - iou_score: 0.6328 - f1-score: 0.7715For batch 217, tr_loss is    0.36.\n",
      "    219/Unknown - 239s 880ms/step - loss: 0.3646 - iou_score: 0.6331 - f1-score: 0.7717For batch 218, tr_loss is    0.36.\n",
      "    220/Unknown - 239s 877ms/step - loss: 0.3643 - iou_score: 0.6334 - f1-score: 0.7720For batch 219, tr_loss is    0.36.\n",
      "    221/Unknown - 239s 875ms/step - loss: 0.3645 - iou_score: 0.6332 - f1-score: 0.7718For batch 220, tr_loss is    0.36.\n",
      "    222/Unknown - 240s 872ms/step - loss: 0.3645 - iou_score: 0.6332 - f1-score: 0.7718For batch 221, tr_loss is    0.36.\n",
      "    223/Unknown - 240s 870ms/step - loss: 0.3646 - iou_score: 0.6331 - f1-score: 0.7718For batch 222, tr_loss is    0.36.\n",
      "    224/Unknown - 240s 867ms/step - loss: 0.3647 - iou_score: 0.6329 - f1-score: 0.7716For batch 223, tr_loss is    0.36.\n",
      "    225/Unknown - 241s 865ms/step - loss: 0.3644 - iou_score: 0.6332 - f1-score: 0.7718For batch 224, tr_loss is    0.36.\n",
      "For batch 0, vl_loss is    1.12.\n",
      "For batch 1, vl_loss is    1.14.\n",
      "For batch 2, vl_loss is    1.27.\n",
      "For batch 3, vl_loss is    1.25.\n",
      "For batch 4, vl_loss is    1.21.\n",
      "For batch 5, vl_loss is    1.20.\n",
      "For batch 6, vl_loss is    1.21.\n",
      "For batch 7, vl_loss is    1.23.\n",
      "For batch 8, vl_loss is    1.24.\n",
      "For batch 9, vl_loss is    1.22.\n",
      "For batch 10, vl_loss is    1.21.\n",
      "For batch 11, vl_loss is    1.24.\n",
      "For batch 12, vl_loss is    1.22.\n",
      "For batch 13, vl_loss is    1.22.\n",
      "For batch 14, vl_loss is    1.24.\n",
      "For batch 15, vl_loss is    1.26.\n",
      "For batch 16, vl_loss is    1.28.\n",
      "For batch 17, vl_loss is    1.29.\n",
      "For batch 18, vl_loss is    1.29.\n",
      "For batch 19, vl_loss is    1.31.\n",
      "For batch 20, vl_loss is    1.32.\n",
      "For batch 21, vl_loss is    1.31.\n",
      "For batch 22, vl_loss is    1.33.\n",
      "For batch 23, vl_loss is    1.32.\n",
      "For batch 24, vl_loss is    1.32.\n",
      "For batch 25, vl_loss is    1.32.\n",
      "For batch 26, vl_loss is    1.30.\n",
      "For batch 27, vl_loss is    1.30.\n",
      "For batch 28, vl_loss is    1.31.\n",
      "For batch 29, vl_loss is    1.31.\n",
      "For batch 30, vl_loss is    1.32.\n",
      "For batch 31, vl_loss is    1.31.\n",
      "For batch 32, vl_loss is    1.32.\n",
      "For batch 33, vl_loss is    1.32.\n",
      "For batch 34, vl_loss is    1.31.\n",
      "For batch 35, vl_loss is    1.30.\n",
      "For batch 36, vl_loss is    1.30.\n",
      "For batch 37, vl_loss is    1.30.\n",
      "For batch 38, vl_loss is    1.30.\n",
      "For batch 39, vl_loss is    1.29.\n",
      "For batch 40, vl_loss is    1.29.\n",
      "For batch 41, vl_loss is    1.29.\n",
      "For batch 42, vl_loss is    1.28.\n",
      "For batch 43, vl_loss is    1.28.\n",
      "For batch 44, vl_loss is    1.29.\n",
      "For batch 45, vl_loss is    1.28.\n",
      "For batch 46, vl_loss is    1.28.\n",
      "For batch 47, vl_loss is    1.27.\n",
      "For batch 48, vl_loss is    1.27.\n",
      "For batch 49, vl_loss is    1.27.\n",
      "For batch 50, vl_loss is    1.27.\n",
      "For batch 51, vl_loss is    1.27.\n",
      "For batch 52, vl_loss is    1.27.\n",
      "For batch 53, vl_loss is    1.27.\n",
      "For batch 54, vl_loss is    1.28.\n",
      "For batch 55, vl_loss is    1.28.\n",
      "For batch 56, vl_loss is    1.29.\n",
      "For batch 57, vl_loss is    1.29.\n",
      "For batch 58, vl_loss is    1.29.\n",
      "For batch 59, vl_loss is    1.29.\n",
      "For batch 60, vl_loss is    1.29.\n",
      "For batch 61, vl_loss is    1.29.\n",
      "For batch 62, vl_loss is    1.29.\n",
      "For batch 63, vl_loss is    1.29.\n",
      "For batch 64, vl_loss is    1.30.\n",
      "For batch 65, vl_loss is    1.29.\n",
      "For batch 66, vl_loss is    1.29.\n",
      "For batch 67, vl_loss is    1.30.\n",
      "For batch 68, vl_loss is    1.29.\n",
      "For batch 69, vl_loss is    1.29.\n",
      "For batch 70, vl_loss is    1.29.\n",
      "For batch 71, vl_loss is    1.29.\n",
      "For batch 72, vl_loss is    1.29.\n",
      "For batch 73, vl_loss is    1.30.\n",
      "For batch 74, vl_loss is    1.29.\n",
      "225/225 [==============================] - 253s 919ms/step - loss: 0.3644 - iou_score: 0.6332 - f1-score: 0.7718 - val_loss: 1.2930 - val_iou_score: 0.5093 - val_f1-score: 0.6721\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.29298, saving model to ./model/tumor_100_unet_efficientnetb0_imagenet_09293.hdf5\n",
      "The average loss for epoch 0 is    0.36 \n",
      "Epoch 2/200\n",
      "  1/225 [..............................] - ETA: 1:48:48 - loss: 0.3726 - iou_score: 0.6327 - f1-score: 0.7750For batch 0, tr_loss is    0.37.\n",
      "  2/225 [..............................] - ETA: 5:54 - loss: 0.3524 - iou_score: 0.6390 - f1-score: 0.7795   For batch 1, tr_loss is    0.35.\n",
      "  3/225 [..............................] - ETA: 4:59 - loss: 0.3504 - iou_score: 0.6415 - f1-score: 0.7812For batch 2, tr_loss is    0.35.\n",
      "  4/225 [..............................] - ETA: 5:56 - loss: 0.3409 - iou_score: 0.6604 - f1-score: 0.7943For batch 3, tr_loss is    0.34.\n",
      "  5/225 [..............................] - ETA: 5:59 - loss: 0.3366 - iou_score: 0.6678 - f1-score: 0.7997For batch 4, tr_loss is    0.34.\n",
      "  6/225 [..............................] - ETA: 5:52 - loss: 0.3441 - iou_score: 0.6552 - f1-score: 0.7901For batch 5, tr_loss is    0.34.\n",
      "  7/225 [..............................] - ETA: 5:53 - loss: 0.3447 - iou_score: 0.6533 - f1-score: 0.7886For batch 6, tr_loss is    0.34.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8/225 [>.............................] - ETA: 5:43 - loss: 0.3440 - iou_score: 0.6521 - f1-score: 0.7878For batch 7, tr_loss is    0.34.\n",
      "  9/225 [>.............................] - ETA: 5:31 - loss: 0.3361 - iou_score: 0.6612 - f1-score: 0.7937For batch 8, tr_loss is    0.34.\n",
      " 10/225 [>.............................] - ETA: 5:12 - loss: 0.3386 - iou_score: 0.6592 - f1-score: 0.7923For batch 9, tr_loss is    0.34.\n",
      " 11/225 [>.............................] - ETA: 5:01 - loss: 0.3368 - iou_score: 0.6606 - f1-score: 0.7930For batch 10, tr_loss is    0.34.\n",
      " 12/225 [>.............................] - ETA: 4:41 - loss: 0.3422 - iou_score: 0.6546 - f1-score: 0.7885For batch 11, tr_loss is    0.34.\n",
      " 13/225 [>.............................] - ETA: 4:31 - loss: 0.3448 - iou_score: 0.6514 - f1-score: 0.7863For batch 12, tr_loss is    0.34.\n",
      " 14/225 [>.............................] - ETA: 4:24 - loss: 0.3451 - iou_score: 0.6520 - f1-score: 0.7868For batch 13, tr_loss is    0.35.\n",
      " 15/225 [=>............................] - ETA: 4:20 - loss: 0.3456 - iou_score: 0.6505 - f1-score: 0.7859For batch 14, tr_loss is    0.35.\n",
      " 16/225 [=>............................] - ETA: 4:11 - loss: 0.3468 - iou_score: 0.6497 - f1-score: 0.7850For batch 15, tr_loss is    0.35.\n",
      " 17/225 [=>............................] - ETA: 4:07 - loss: 0.3456 - iou_score: 0.6523 - f1-score: 0.7870For batch 16, tr_loss is    0.35.\n",
      " 18/225 [=>............................] - ETA: 4:03 - loss: 0.3460 - iou_score: 0.6518 - f1-score: 0.7867For batch 17, tr_loss is    0.35.\n",
      " 19/225 [=>............................] - ETA: 4:00 - loss: 0.3440 - iou_score: 0.6551 - f1-score: 0.7891For batch 18, tr_loss is    0.34.\n",
      " 20/225 [=>............................] - ETA: 3:57 - loss: 0.3419 - iou_score: 0.6578 - f1-score: 0.7911For batch 19, tr_loss is    0.34.\n",
      " 21/225 [=>............................] - ETA: 3:50 - loss: 0.3413 - iou_score: 0.6586 - f1-score: 0.7918For batch 20, tr_loss is    0.34.\n",
      " 22/225 [=>............................] - ETA: 3:44 - loss: 0.3400 - iou_score: 0.6601 - f1-score: 0.7929For batch 21, tr_loss is    0.34.\n",
      " 23/225 [==>...........................] - ETA: 3:42 - loss: 0.3460 - iou_score: 0.6527 - f1-score: 0.7871For batch 22, tr_loss is    0.35.\n",
      " 24/225 [==>...........................] - ETA: 3:40 - loss: 0.3478 - iou_score: 0.6503 - f1-score: 0.7853For batch 23, tr_loss is    0.35.\n",
      " 25/225 [==>...........................] - ETA: 3:35 - loss: 0.3482 - iou_score: 0.6492 - f1-score: 0.7846For batch 24, tr_loss is    0.35.\n",
      " 26/225 [==>...........................] - ETA: 3:33 - loss: 0.3454 - iou_score: 0.6532 - f1-score: 0.7875For batch 25, tr_loss is    0.35.\n",
      " 27/225 [==>...........................] - ETA: 3:27 - loss: 0.3464 - iou_score: 0.6516 - f1-score: 0.7864For batch 26, tr_loss is    0.35.\n",
      " 28/225 [==>...........................] - ETA: 3:24 - loss: 0.3455 - iou_score: 0.6523 - f1-score: 0.7869For batch 27, tr_loss is    0.35.\n",
      " 29/225 [==>...........................] - ETA: 3:20 - loss: 0.3444 - iou_score: 0.6538 - f1-score: 0.7878For batch 28, tr_loss is    0.34.\n",
      " 30/225 [===>..........................] - ETA: 3:19 - loss: 0.3438 - iou_score: 0.6541 - f1-score: 0.7881For batch 29, tr_loss is    0.34.\n",
      " 31/225 [===>..........................] - ETA: 3:18 - loss: 0.3428 - iou_score: 0.6549 - f1-score: 0.7888For batch 30, tr_loss is    0.34.\n",
      " 32/225 [===>..........................] - ETA: 3:17 - loss: 0.3422 - iou_score: 0.6556 - f1-score: 0.7894For batch 31, tr_loss is    0.34.\n",
      " 33/225 [===>..........................] - ETA: 3:16 - loss: 0.3406 - iou_score: 0.6580 - f1-score: 0.7911For batch 32, tr_loss is    0.34.\n",
      " 34/225 [===>..........................] - ETA: 3:12 - loss: 0.3410 - iou_score: 0.6580 - f1-score: 0.7910For batch 33, tr_loss is    0.34.\n",
      " 35/225 [===>..........................] - ETA: 3:09 - loss: 0.3420 - iou_score: 0.6569 - f1-score: 0.7902For batch 34, tr_loss is    0.34.\n",
      " 36/225 [===>..........................] - ETA: 3:08 - loss: 0.3398 - iou_score: 0.6593 - f1-score: 0.7920For batch 35, tr_loss is    0.34.\n",
      " 37/225 [===>..........................] - ETA: 3:05 - loss: 0.3389 - iou_score: 0.6598 - f1-score: 0.7924For batch 36, tr_loss is    0.34.\n",
      " 38/225 [====>.........................] - ETA: 3:04 - loss: 0.3365 - iou_score: 0.6620 - f1-score: 0.7940For batch 37, tr_loss is    0.34.\n",
      " 39/225 [====>.........................] - ETA: 3:01 - loss: 0.3369 - iou_score: 0.6605 - f1-score: 0.7929For batch 38, tr_loss is    0.34.\n",
      " 40/225 [====>.........................] - ETA: 3:01 - loss: 0.3349 - iou_score: 0.6633 - f1-score: 0.7949For batch 39, tr_loss is    0.33.\n",
      " 41/225 [====>.........................] - ETA: 3:00 - loss: 0.3341 - iou_score: 0.6634 - f1-score: 0.7950For batch 40, tr_loss is    0.33.\n",
      " 42/225 [====>.........................] - ETA: 2:59 - loss: 0.3345 - iou_score: 0.6628 - f1-score: 0.7946For batch 41, tr_loss is    0.33.\n",
      " 43/225 [====>.........................] - ETA: 2:57 - loss: 0.3324 - iou_score: 0.6646 - f1-score: 0.7959For batch 42, tr_loss is    0.33.\n",
      " 44/225 [====>.........................] - ETA: 2:54 - loss: 0.3327 - iou_score: 0.6645 - f1-score: 0.7959For batch 43, tr_loss is    0.33.\n",
      " 45/225 [=====>........................] - ETA: 2:54 - loss: 0.3324 - iou_score: 0.6647 - f1-score: 0.7960For batch 44, tr_loss is    0.33.\n",
      " 46/225 [=====>........................] - ETA: 2:51 - loss: 0.3329 - iou_score: 0.6639 - f1-score: 0.7955For batch 45, tr_loss is    0.33.\n",
      " 47/225 [=====>........................] - ETA: 2:49 - loss: 0.3319 - iou_score: 0.6652 - f1-score: 0.7965For batch 46, tr_loss is    0.33.\n",
      " 48/225 [=====>........................] - ETA: 2:47 - loss: 0.3317 - iou_score: 0.6657 - f1-score: 0.7968For batch 47, tr_loss is    0.33.\n",
      " 49/225 [=====>........................] - ETA: 2:45 - loss: 0.3331 - iou_score: 0.6639 - f1-score: 0.7955For batch 48, tr_loss is    0.33.\n",
      " 50/225 [=====>........................] - ETA: 2:43 - loss: 0.3355 - iou_score: 0.6618 - f1-score: 0.7939For batch 49, tr_loss is    0.34.\n",
      " 51/225 [=====>........................] - ETA: 2:43 - loss: 0.3354 - iou_score: 0.6621 - f1-score: 0.7942For batch 50, tr_loss is    0.34.\n",
      " 52/225 [=====>........................] - ETA: 2:40 - loss: 0.3354 - iou_score: 0.6622 - f1-score: 0.7943For batch 51, tr_loss is    0.34.\n",
      " 53/225 [======>.......................] - ETA: 2:39 - loss: 0.3358 - iou_score: 0.6616 - f1-score: 0.7939For batch 52, tr_loss is    0.34.\n",
      " 54/225 [======>.......................] - ETA: 2:38 - loss: 0.3357 - iou_score: 0.6617 - f1-score: 0.7939For batch 53, tr_loss is    0.34.\n",
      " 55/225 [======>.......................] - ETA: 2:37 - loss: 0.3350 - iou_score: 0.6623 - f1-score: 0.7944For batch 54, tr_loss is    0.34.\n",
      " 56/225 [======>.......................] - ETA: 2:37 - loss: 0.3346 - iou_score: 0.6623 - f1-score: 0.7944For batch 55, tr_loss is    0.33.\n",
      " 57/225 [======>.......................] - ETA: 2:36 - loss: 0.3351 - iou_score: 0.6616 - f1-score: 0.7940For batch 56, tr_loss is    0.34.\n",
      " 58/225 [======>.......................] - ETA: 2:36 - loss: 0.3342 - iou_score: 0.6620 - f1-score: 0.7943For batch 57, tr_loss is    0.33.\n",
      " 59/225 [======>.......................] - ETA: 2:35 - loss: 0.3335 - iou_score: 0.6627 - f1-score: 0.7948For batch 58, tr_loss is    0.33.\n",
      " 60/225 [=======>......................] - ETA: 2:33 - loss: 0.3341 - iou_score: 0.6622 - f1-score: 0.7944For batch 59, tr_loss is    0.33.\n",
      " 61/225 [=======>......................] - ETA: 2:31 - loss: 0.3344 - iou_score: 0.6620 - f1-score: 0.7943For batch 60, tr_loss is    0.33.\n",
      " 62/225 [=======>......................] - ETA: 2:30 - loss: 0.3346 - iou_score: 0.6622 - f1-score: 0.7945For batch 61, tr_loss is    0.33.\n",
      " 63/225 [=======>......................] - ETA: 2:29 - loss: 0.3350 - iou_score: 0.6617 - f1-score: 0.7941For batch 62, tr_loss is    0.34.\n",
      " 64/225 [=======>......................] - ETA: 2:27 - loss: 0.3358 - iou_score: 0.6607 - f1-score: 0.7934For batch 63, tr_loss is    0.34.\n",
      " 65/225 [=======>......................] - ETA: 2:27 - loss: 0.3343 - iou_score: 0.6625 - f1-score: 0.7947For batch 64, tr_loss is    0.33.\n",
      " 66/225 [=======>......................] - ETA: 2:26 - loss: 0.3343 - iou_score: 0.6627 - f1-score: 0.7948For batch 65, tr_loss is    0.33.\n",
      " 67/225 [=======>......................] - ETA: 2:25 - loss: 0.3344 - iou_score: 0.6621 - f1-score: 0.7943For batch 66, tr_loss is    0.33.\n",
      " 68/225 [========>.....................] - ETA: 2:24 - loss: 0.3338 - iou_score: 0.6627 - f1-score: 0.7948For batch 67, tr_loss is    0.33.\n",
      " 69/225 [========>.....................] - ETA: 2:24 - loss: 0.3345 - iou_score: 0.6620 - f1-score: 0.7942For batch 68, tr_loss is    0.33.\n",
      " 70/225 [========>.....................] - ETA: 2:23 - loss: 0.3351 - iou_score: 0.6614 - f1-score: 0.7938For batch 69, tr_loss is    0.34.\n",
      " 71/225 [========>.....................] - ETA: 2:22 - loss: 0.3344 - iou_score: 0.6619 - f1-score: 0.7943For batch 70, tr_loss is    0.33.\n",
      " 72/225 [========>.....................] - ETA: 2:22 - loss: 0.3346 - iou_score: 0.6613 - f1-score: 0.7938For batch 71, tr_loss is    0.33.\n",
      " 73/225 [========>.....................] - ETA: 2:21 - loss: 0.3351 - iou_score: 0.6610 - f1-score: 0.7935For batch 72, tr_loss is    0.34.\n",
      " 74/225 [========>.....................] - ETA: 2:20 - loss: 0.3359 - iou_score: 0.6596 - f1-score: 0.7925For batch 73, tr_loss is    0.34.\n",
      " 75/225 [=========>....................] - ETA: 2:19 - loss: 0.3362 - iou_score: 0.6593 - f1-score: 0.7922For batch 74, tr_loss is    0.34.\n",
      " 76/225 [=========>....................] - ETA: 2:19 - loss: 0.3360 - iou_score: 0.6597 - f1-score: 0.7925For batch 75, tr_loss is    0.34.\n",
      " 77/225 [=========>....................] - ETA: 2:18 - loss: 0.3356 - iou_score: 0.6597 - f1-score: 0.7925For batch 76, tr_loss is    0.34.\n",
      " 78/225 [=========>....................] - ETA: 2:16 - loss: 0.3373 - iou_score: 0.6584 - f1-score: 0.7915For batch 77, tr_loss is    0.34.\n",
      " 79/225 [=========>....................] - ETA: 2:16 - loss: 0.3372 - iou_score: 0.6586 - f1-score: 0.7917For batch 78, tr_loss is    0.34.\n",
      " 80/225 [=========>....................] - ETA: 2:14 - loss: 0.3364 - iou_score: 0.6596 - f1-score: 0.7924For batch 79, tr_loss is    0.34.\n",
      " 81/225 [=========>....................] - ETA: 2:13 - loss: 0.3359 - iou_score: 0.6602 - f1-score: 0.7928For batch 80, tr_loss is    0.34.\n",
      " 82/225 [=========>....................] - ETA: 2:12 - loss: 0.3353 - iou_score: 0.6609 - f1-score: 0.7933For batch 81, tr_loss is    0.34.\n",
      " 83/225 [==========>...................] - ETA: 2:11 - loss: 0.3357 - iou_score: 0.6604 - f1-score: 0.7930For batch 82, tr_loss is    0.34.\n",
      " 84/225 [==========>...................] - ETA: 2:10 - loss: 0.3351 - iou_score: 0.6610 - f1-score: 0.7934For batch 83, tr_loss is    0.34.\n",
      " 85/225 [==========>...................] - ETA: 2:10 - loss: 0.3349 - iou_score: 0.6613 - f1-score: 0.7937For batch 84, tr_loss is    0.33.\n",
      " 86/225 [==========>...................] - ETA: 2:08 - loss: 0.3343 - iou_score: 0.6619 - f1-score: 0.7941For batch 85, tr_loss is    0.33.\n",
      " 87/225 [==========>...................] - ETA: 2:07 - loss: 0.3337 - iou_score: 0.6625 - f1-score: 0.7946For batch 86, tr_loss is    0.33.\n",
      " 88/225 [==========>...................] - ETA: 2:07 - loss: 0.3332 - iou_score: 0.6628 - f1-score: 0.7948For batch 87, tr_loss is    0.33.\n",
      " 89/225 [==========>...................] - ETA: 2:05 - loss: 0.3332 - iou_score: 0.6630 - f1-score: 0.7950For batch 88, tr_loss is    0.33.\n",
      " 90/225 [===========>..................] - ETA: 2:04 - loss: 0.3327 - iou_score: 0.6636 - f1-score: 0.7954For batch 89, tr_loss is    0.33.\n",
      " 91/225 [===========>..................] - ETA: 2:03 - loss: 0.3338 - iou_score: 0.6623 - f1-score: 0.7944For batch 90, tr_loss is    0.33.\n",
      " 92/225 [===========>..................] - ETA: 2:02 - loss: 0.3337 - iou_score: 0.6623 - f1-score: 0.7944For batch 91, tr_loss is    0.33.\n",
      " 93/225 [===========>..................] - ETA: 2:02 - loss: 0.3325 - iou_score: 0.6637 - f1-score: 0.7953For batch 92, tr_loss is    0.33.\n",
      " 94/225 [===========>..................] - ETA: 2:00 - loss: 0.3329 - iou_score: 0.6633 - f1-score: 0.7950For batch 93, tr_loss is    0.33.\n",
      " 95/225 [===========>..................] - ETA: 2:00 - loss: 0.3326 - iou_score: 0.6640 - f1-score: 0.7955For batch 94, tr_loss is    0.33.\n",
      " 96/225 [===========>..................] - ETA: 1:58 - loss: 0.3332 - iou_score: 0.6632 - f1-score: 0.7950For batch 95, tr_loss is    0.33.\n",
      " 97/225 [===========>..................] - ETA: 1:58 - loss: 0.3329 - iou_score: 0.6634 - f1-score: 0.7951For batch 96, tr_loss is    0.33.\n",
      " 98/225 [============>.................] - ETA: 1:56 - loss: 0.3328 - iou_score: 0.6630 - f1-score: 0.7948For batch 97, tr_loss is    0.33.\n",
      " 99/225 [============>.................] - ETA: 1:56 - loss: 0.3326 - iou_score: 0.6635 - f1-score: 0.7952For batch 98, tr_loss is    0.33.\n",
      "100/225 [============>.................] - ETA: 1:55 - loss: 0.3328 - iou_score: 0.6630 - f1-score: 0.7949For batch 99, tr_loss is    0.33.\n",
      "101/225 [============>.................] - ETA: 1:53 - loss: 0.3328 - iou_score: 0.6632 - f1-score: 0.7949For batch 100, tr_loss is    0.33.\n",
      "102/225 [============>.................] - ETA: 1:52 - loss: 0.3323 - iou_score: 0.6637 - f1-score: 0.7953For batch 101, tr_loss is    0.33.\n",
      "103/225 [============>.................] - ETA: 1:51 - loss: 0.3328 - iou_score: 0.6633 - f1-score: 0.7950For batch 102, tr_loss is    0.33.\n",
      "104/225 [============>.................] - ETA: 1:50 - loss: 0.3325 - iou_score: 0.6636 - f1-score: 0.7953For batch 103, tr_loss is    0.33.\n",
      "105/225 [=============>................] - ETA: 1:50 - loss: 0.3323 - iou_score: 0.6641 - f1-score: 0.7956For batch 104, tr_loss is    0.33.\n",
      "106/225 [=============>................] - ETA: 1:49 - loss: 0.3318 - iou_score: 0.6644 - f1-score: 0.7959For batch 105, tr_loss is    0.33.\n",
      "107/225 [=============>................] - ETA: 1:48 - loss: 0.3314 - iou_score: 0.6650 - f1-score: 0.7962For batch 106, tr_loss is    0.33.\n",
      "108/225 [=============>................] - ETA: 1:47 - loss: 0.3315 - iou_score: 0.6647 - f1-score: 0.7961For batch 107, tr_loss is    0.33.\n",
      "109/225 [=============>................] - ETA: 1:46 - loss: 0.3309 - iou_score: 0.6653 - f1-score: 0.7965For batch 108, tr_loss is    0.33.\n",
      "110/225 [=============>................] - ETA: 1:45 - loss: 0.3304 - iou_score: 0.6659 - f1-score: 0.7969For batch 109, tr_loss is    0.33.\n",
      "111/225 [=============>................] - ETA: 1:44 - loss: 0.3305 - iou_score: 0.6656 - f1-score: 0.7967For batch 110, tr_loss is    0.33.\n",
      "112/225 [=============>................] - ETA: 1:44 - loss: 0.3302 - iou_score: 0.6659 - f1-score: 0.7969For batch 111, tr_loss is    0.33.\n",
      "113/225 [==============>...............] - ETA: 1:43 - loss: 0.3304 - iou_score: 0.6660 - f1-score: 0.7970For batch 112, tr_loss is    0.33.\n",
      "114/225 [==============>...............] - ETA: 1:41 - loss: 0.3299 - iou_score: 0.6669 - f1-score: 0.7977For batch 113, tr_loss is    0.33.\n",
      "115/225 [==============>...............] - ETA: 1:41 - loss: 0.3291 - iou_score: 0.6678 - f1-score: 0.7983For batch 114, tr_loss is    0.33.\n",
      "116/225 [==============>...............] - ETA: 1:40 - loss: 0.3290 - iou_score: 0.6680 - f1-score: 0.7984For batch 115, tr_loss is    0.33.\n",
      "117/225 [==============>...............] - ETA: 1:39 - loss: 0.3289 - iou_score: 0.6681 - f1-score: 0.7985For batch 116, tr_loss is    0.33.\n",
      "118/225 [==============>...............] - ETA: 1:38 - loss: 0.3285 - iou_score: 0.6684 - f1-score: 0.7987For batch 117, tr_loss is    0.33.\n",
      "119/225 [==============>...............] - ETA: 1:37 - loss: 0.3280 - iou_score: 0.6688 - f1-score: 0.7990For batch 118, tr_loss is    0.33.\n",
      "120/225 [===============>..............] - ETA: 1:36 - loss: 0.3283 - iou_score: 0.6684 - f1-score: 0.7988For batch 119, tr_loss is    0.33.\n",
      "121/225 [===============>..............] - ETA: 1:35 - loss: 0.3279 - iou_score: 0.6688 - f1-score: 0.7990For batch 120, tr_loss is    0.33.\n",
      "122/225 [===============>..............] - ETA: 1:35 - loss: 0.3277 - iou_score: 0.6691 - f1-score: 0.7992For batch 121, tr_loss is    0.33.\n",
      "123/225 [===============>..............] - ETA: 1:34 - loss: 0.3272 - iou_score: 0.6697 - f1-score: 0.7996For batch 122, tr_loss is    0.33.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/225 [===============>..............] - ETA: 1:33 - loss: 0.3271 - iou_score: 0.6698 - f1-score: 0.7997For batch 123, tr_loss is    0.33.\n",
      "125/225 [===============>..............] - ETA: 1:32 - loss: 0.3275 - iou_score: 0.6698 - f1-score: 0.7997For batch 124, tr_loss is    0.33.\n",
      "126/225 [===============>..............] - ETA: 1:31 - loss: 0.3274 - iou_score: 0.6698 - f1-score: 0.7997For batch 125, tr_loss is    0.33.\n",
      "127/225 [===============>..............] - ETA: 1:30 - loss: 0.3273 - iou_score: 0.6697 - f1-score: 0.7996For batch 126, tr_loss is    0.33.\n",
      "128/225 [================>.............] - ETA: 1:29 - loss: 0.3269 - iou_score: 0.6702 - f1-score: 0.7999For batch 127, tr_loss is    0.33.\n",
      "129/225 [================>.............] - ETA: 1:28 - loss: 0.3272 - iou_score: 0.6697 - f1-score: 0.7996For batch 128, tr_loss is    0.33.\n",
      "130/225 [================>.............] - ETA: 1:27 - loss: 0.3269 - iou_score: 0.6701 - f1-score: 0.7999For batch 129, tr_loss is    0.33.\n",
      "131/225 [================>.............] - ETA: 1:26 - loss: 0.3268 - iou_score: 0.6701 - f1-score: 0.7999For batch 130, tr_loss is    0.33.\n",
      "132/225 [================>.............] - ETA: 1:25 - loss: 0.3264 - iou_score: 0.6707 - f1-score: 0.8003For batch 131, tr_loss is    0.33.\n",
      "133/225 [================>.............] - ETA: 1:24 - loss: 0.3267 - iou_score: 0.6704 - f1-score: 0.8001For batch 132, tr_loss is    0.33.\n",
      "134/225 [================>.............] - ETA: 1:23 - loss: 0.3263 - iou_score: 0.6707 - f1-score: 0.8003For batch 133, tr_loss is    0.33.\n",
      "135/225 [=================>............] - ETA: 1:22 - loss: 0.3264 - iou_score: 0.6706 - f1-score: 0.8002For batch 134, tr_loss is    0.33.\n",
      "136/225 [=================>............] - ETA: 1:21 - loss: 0.3265 - iou_score: 0.6704 - f1-score: 0.8001For batch 135, tr_loss is    0.33.\n",
      "137/225 [=================>............] - ETA: 1:20 - loss: 0.3266 - iou_score: 0.6703 - f1-score: 0.8001For batch 136, tr_loss is    0.33.\n",
      "138/225 [=================>............] - ETA: 1:19 - loss: 0.3268 - iou_score: 0.6702 - f1-score: 0.8000For batch 137, tr_loss is    0.33.\n",
      "139/225 [=================>............] - ETA: 1:18 - loss: 0.3269 - iou_score: 0.6700 - f1-score: 0.7999For batch 138, tr_loss is    0.33.\n",
      "140/225 [=================>............] - ETA: 1:17 - loss: 0.3277 - iou_score: 0.6691 - f1-score: 0.7992For batch 139, tr_loss is    0.33.\n",
      "141/225 [=================>............] - ETA: 1:16 - loss: 0.3274 - iou_score: 0.6695 - f1-score: 0.7995For batch 140, tr_loss is    0.33.\n",
      "142/225 [=================>............] - ETA: 1:15 - loss: 0.3274 - iou_score: 0.6696 - f1-score: 0.7996For batch 141, tr_loss is    0.33.\n",
      "143/225 [==================>...........] - ETA: 1:15 - loss: 0.3273 - iou_score: 0.6695 - f1-score: 0.7995For batch 142, tr_loss is    0.33.\n",
      "144/225 [==================>...........] - ETA: 1:14 - loss: 0.3276 - iou_score: 0.6694 - f1-score: 0.7994For batch 143, tr_loss is    0.33.\n",
      "145/225 [==================>...........] - ETA: 1:13 - loss: 0.3276 - iou_score: 0.6692 - f1-score: 0.7992For batch 144, tr_loss is    0.33.\n",
      "146/225 [==================>...........] - ETA: 1:12 - loss: 0.3275 - iou_score: 0.6693 - f1-score: 0.7993For batch 145, tr_loss is    0.33.\n",
      "147/225 [==================>...........] - ETA: 1:11 - loss: 0.3272 - iou_score: 0.6698 - f1-score: 0.7997For batch 146, tr_loss is    0.33.\n",
      "148/225 [==================>...........] - ETA: 1:10 - loss: 0.3271 - iou_score: 0.6699 - f1-score: 0.7998For batch 147, tr_loss is    0.33.\n",
      "149/225 [==================>...........] - ETA: 1:09 - loss: 0.3269 - iou_score: 0.6701 - f1-score: 0.7999For batch 148, tr_loss is    0.33.\n",
      "150/225 [===================>..........] - ETA: 1:08 - loss: 0.3270 - iou_score: 0.6699 - f1-score: 0.7998For batch 149, tr_loss is    0.33.\n",
      "151/225 [===================>..........] - ETA: 1:07 - loss: 0.3272 - iou_score: 0.6697 - f1-score: 0.7997For batch 150, tr_loss is    0.33.\n",
      "152/225 [===================>..........] - ETA: 1:06 - loss: 0.3271 - iou_score: 0.6700 - f1-score: 0.7998For batch 151, tr_loss is    0.33.\n",
      "153/225 [===================>..........] - ETA: 1:05 - loss: 0.3271 - iou_score: 0.6700 - f1-score: 0.7998For batch 152, tr_loss is    0.33.\n",
      "154/225 [===================>..........] - ETA: 1:04 - loss: 0.3270 - iou_score: 0.6699 - f1-score: 0.7998For batch 153, tr_loss is    0.33.\n",
      "155/225 [===================>..........] - ETA: 1:03 - loss: 0.3280 - iou_score: 0.6688 - f1-score: 0.7989For batch 154, tr_loss is    0.33.\n",
      "156/225 [===================>..........] - ETA: 1:02 - loss: 0.3284 - iou_score: 0.6684 - f1-score: 0.7987For batch 155, tr_loss is    0.33.\n",
      "157/225 [===================>..........] - ETA: 1:01 - loss: 0.3283 - iou_score: 0.6684 - f1-score: 0.7986For batch 156, tr_loss is    0.33.\n",
      "158/225 [====================>.........] - ETA: 1:00 - loss: 0.3284 - iou_score: 0.6682 - f1-score: 0.7985For batch 157, tr_loss is    0.33.\n",
      "159/225 [====================>.........] - ETA: 59s - loss: 0.3283 - iou_score: 0.6684 - f1-score: 0.7987 For batch 158, tr_loss is    0.33.\n",
      "160/225 [====================>.........] - ETA: 58s - loss: 0.3283 - iou_score: 0.6684 - f1-score: 0.7986For batch 159, tr_loss is    0.33.\n",
      "161/225 [====================>.........] - ETA: 57s - loss: 0.3279 - iou_score: 0.6689 - f1-score: 0.7990For batch 160, tr_loss is    0.33.\n",
      "162/225 [====================>.........] - ETA: 56s - loss: 0.3277 - iou_score: 0.6690 - f1-score: 0.7991For batch 161, tr_loss is    0.33.\n",
      "163/225 [====================>.........] - ETA: 55s - loss: 0.3279 - iou_score: 0.6687 - f1-score: 0.7989For batch 162, tr_loss is    0.33.\n",
      "164/225 [====================>.........] - ETA: 54s - loss: 0.3282 - iou_score: 0.6686 - f1-score: 0.7988For batch 163, tr_loss is    0.33.\n",
      "165/225 [=====================>........] - ETA: 53s - loss: 0.3282 - iou_score: 0.6687 - f1-score: 0.7989For batch 164, tr_loss is    0.33.\n",
      "166/225 [=====================>........] - ETA: 53s - loss: 0.3287 - iou_score: 0.6680 - f1-score: 0.7984For batch 165, tr_loss is    0.33.\n",
      "167/225 [=====================>........] - ETA: 52s - loss: 0.3286 - iou_score: 0.6681 - f1-score: 0.7985For batch 166, tr_loss is    0.33.\n",
      "168/225 [=====================>........] - ETA: 51s - loss: 0.3279 - iou_score: 0.6690 - f1-score: 0.7991For batch 167, tr_loss is    0.33.\n",
      "169/225 [=====================>........] - ETA: 50s - loss: 0.3276 - iou_score: 0.6693 - f1-score: 0.7993For batch 168, tr_loss is    0.33.\n",
      "170/225 [=====================>........] - ETA: 49s - loss: 0.3280 - iou_score: 0.6690 - f1-score: 0.7991For batch 169, tr_loss is    0.33.\n",
      "171/225 [=====================>........] - ETA: 48s - loss: 0.3282 - iou_score: 0.6687 - f1-score: 0.7989For batch 170, tr_loss is    0.33.\n",
      "172/225 [=====================>........] - ETA: 47s - loss: 0.3287 - iou_score: 0.6681 - f1-score: 0.7984For batch 171, tr_loss is    0.33.\n",
      "173/225 [======================>.......] - ETA: 46s - loss: 0.3290 - iou_score: 0.6677 - f1-score: 0.7981For batch 172, tr_loss is    0.33.\n",
      "174/225 [======================>.......] - ETA: 45s - loss: 0.3289 - iou_score: 0.6677 - f1-score: 0.7981For batch 173, tr_loss is    0.33.\n",
      "175/225 [======================>.......] - ETA: 44s - loss: 0.3290 - iou_score: 0.6674 - f1-score: 0.7979For batch 174, tr_loss is    0.33.\n",
      "176/225 [======================>.......] - ETA: 43s - loss: 0.3291 - iou_score: 0.6672 - f1-score: 0.7978For batch 175, tr_loss is    0.33.\n",
      "177/225 [======================>.......] - ETA: 43s - loss: 0.3287 - iou_score: 0.6677 - f1-score: 0.7981For batch 176, tr_loss is    0.33.\n",
      "178/225 [======================>.......] - ETA: 42s - loss: 0.3286 - iou_score: 0.6678 - f1-score: 0.7982For batch 177, tr_loss is    0.33.\n",
      "179/225 [======================>.......] - ETA: 41s - loss: 0.3284 - iou_score: 0.6679 - f1-score: 0.7983For batch 178, tr_loss is    0.33.\n",
      "180/225 [=======================>......] - ETA: 40s - loss: 0.3288 - iou_score: 0.6675 - f1-score: 0.7980For batch 179, tr_loss is    0.33.\n",
      "181/225 [=======================>......] - ETA: 39s - loss: 0.3289 - iou_score: 0.6675 - f1-score: 0.7980For batch 180, tr_loss is    0.33.\n",
      "182/225 [=======================>......] - ETA: 38s - loss: 0.3287 - iou_score: 0.6677 - f1-score: 0.7982For batch 181, tr_loss is    0.33.\n",
      "183/225 [=======================>......] - ETA: 37s - loss: 0.3288 - iou_score: 0.6677 - f1-score: 0.7982For batch 182, tr_loss is    0.33.\n",
      "184/225 [=======================>......] - ETA: 36s - loss: 0.3288 - iou_score: 0.6677 - f1-score: 0.7982For batch 183, tr_loss is    0.33.\n",
      "185/225 [=======================>......] - ETA: 35s - loss: 0.3287 - iou_score: 0.6677 - f1-score: 0.7982For batch 184, tr_loss is    0.33.\n",
      "186/225 [=======================>......] - ETA: 35s - loss: 0.3289 - iou_score: 0.6676 - f1-score: 0.7982For batch 185, tr_loss is    0.33.\n",
      "187/225 [=======================>......] - ETA: 34s - loss: 0.3285 - iou_score: 0.6681 - f1-score: 0.7985For batch 186, tr_loss is    0.33.\n",
      "188/225 [========================>.....] - ETA: 33s - loss: 0.3283 - iou_score: 0.6684 - f1-score: 0.7987For batch 187, tr_loss is    0.33.\n",
      "189/225 [========================>.....] - ETA: 32s - loss: 0.3279 - iou_score: 0.6688 - f1-score: 0.7990For batch 188, tr_loss is    0.33.\n",
      "190/225 [========================>.....] - ETA: 31s - loss: 0.3277 - iou_score: 0.6690 - f1-score: 0.7991For batch 189, tr_loss is    0.33.\n",
      "191/225 [========================>.....] - ETA: 30s - loss: 0.3274 - iou_score: 0.6693 - f1-score: 0.7994For batch 190, tr_loss is    0.33.\n",
      "192/225 [========================>.....] - ETA: 29s - loss: 0.3270 - iou_score: 0.6697 - f1-score: 0.7997For batch 191, tr_loss is    0.33.\n",
      "193/225 [========================>.....] - ETA: 28s - loss: 0.3269 - iou_score: 0.6698 - f1-score: 0.7997For batch 192, tr_loss is    0.33.\n",
      "194/225 [========================>.....] - ETA: 27s - loss: 0.3270 - iou_score: 0.6697 - f1-score: 0.7997For batch 193, tr_loss is    0.33.\n",
      "195/225 [=========================>....] - ETA: 27s - loss: 0.3267 - iou_score: 0.6701 - f1-score: 0.7999For batch 194, tr_loss is    0.33.\n",
      "196/225 [=========================>....] - ETA: 26s - loss: 0.3264 - iou_score: 0.6702 - f1-score: 0.8001For batch 195, tr_loss is    0.33.\n",
      "197/225 [=========================>....] - ETA: 25s - loss: 0.3266 - iou_score: 0.6700 - f1-score: 0.7999For batch 196, tr_loss is    0.33.\n",
      "198/225 [=========================>....] - ETA: 24s - loss: 0.3261 - iou_score: 0.6705 - f1-score: 0.8002For batch 197, tr_loss is    0.33.\n",
      "199/225 [=========================>....] - ETA: 23s - loss: 0.3269 - iou_score: 0.6697 - f1-score: 0.7996For batch 198, tr_loss is    0.33.\n",
      "200/225 [=========================>....] - ETA: 22s - loss: 0.3265 - iou_score: 0.6701 - f1-score: 0.7999For batch 199, tr_loss is    0.33.\n",
      "201/225 [=========================>....] - ETA: 21s - loss: 0.3267 - iou_score: 0.6700 - f1-score: 0.7998For batch 200, tr_loss is    0.33.\n",
      "202/225 [=========================>....] - ETA: 20s - loss: 0.3265 - iou_score: 0.6704 - f1-score: 0.8001For batch 201, tr_loss is    0.33.\n",
      "203/225 [==========================>...] - ETA: 19s - loss: 0.3263 - iou_score: 0.6706 - f1-score: 0.8003For batch 202, tr_loss is    0.33.\n",
      "204/225 [==========================>...] - ETA: 18s - loss: 0.3260 - iou_score: 0.6711 - f1-score: 0.8006For batch 203, tr_loss is    0.33.\n",
      "205/225 [==========================>...] - ETA: 18s - loss: 0.3258 - iou_score: 0.6713 - f1-score: 0.8007For batch 204, tr_loss is    0.33.\n",
      "206/225 [==========================>...] - ETA: 17s - loss: 0.3256 - iou_score: 0.6714 - f1-score: 0.8008For batch 205, tr_loss is    0.33.\n",
      "207/225 [==========================>...] - ETA: 16s - loss: 0.3256 - iou_score: 0.6713 - f1-score: 0.8007For batch 206, tr_loss is    0.33.\n",
      "208/225 [==========================>...] - ETA: 15s - loss: 0.3257 - iou_score: 0.6710 - f1-score: 0.8006For batch 207, tr_loss is    0.33.\n",
      "209/225 [==========================>...] - ETA: 14s - loss: 0.3255 - iou_score: 0.6714 - f1-score: 0.8008For batch 208, tr_loss is    0.33.\n",
      "210/225 [===========================>..] - ETA: 13s - loss: 0.3257 - iou_score: 0.6711 - f1-score: 0.8006For batch 209, tr_loss is    0.33.\n",
      "211/225 [===========================>..] - ETA: 12s - loss: 0.3257 - iou_score: 0.6711 - f1-score: 0.8006For batch 210, tr_loss is    0.33.\n",
      "212/225 [===========================>..] - ETA: 11s - loss: 0.3257 - iou_score: 0.6710 - f1-score: 0.8006For batch 211, tr_loss is    0.33.\n",
      "213/225 [===========================>..] - ETA: 10s - loss: 0.3259 - iou_score: 0.6707 - f1-score: 0.8004For batch 212, tr_loss is    0.33.\n",
      "214/225 [===========================>..] - ETA: 9s - loss: 0.3261 - iou_score: 0.6707 - f1-score: 0.8003 For batch 213, tr_loss is    0.33.\n",
      "215/225 [===========================>..] - ETA: 9s - loss: 0.3258 - iou_score: 0.6710 - f1-score: 0.8006For batch 214, tr_loss is    0.33.\n",
      "216/225 [===========================>..] - ETA: 8s - loss: 0.3255 - iou_score: 0.6713 - f1-score: 0.8008For batch 215, tr_loss is    0.33.\n",
      "217/225 [===========================>..] - ETA: 7s - loss: 0.3253 - iou_score: 0.6717 - f1-score: 0.8011For batch 216, tr_loss is    0.33.\n",
      "218/225 [============================>.] - ETA: 6s - loss: 0.3251 - iou_score: 0.6720 - f1-score: 0.8013For batch 217, tr_loss is    0.33.\n",
      "219/225 [============================>.] - ETA: 5s - loss: 0.3250 - iou_score: 0.6721 - f1-score: 0.8013For batch 218, tr_loss is    0.33.\n",
      "220/225 [============================>.] - ETA: 4s - loss: 0.3248 - iou_score: 0.6722 - f1-score: 0.8015For batch 219, tr_loss is    0.32.\n",
      "221/225 [============================>.] - ETA: 3s - loss: 0.3251 - iou_score: 0.6720 - f1-score: 0.8013For batch 220, tr_loss is    0.33.\n",
      "222/225 [============================>.] - ETA: 2s - loss: 0.3251 - iou_score: 0.6720 - f1-score: 0.8013For batch 221, tr_loss is    0.33.\n",
      "223/225 [============================>.] - ETA: 1s - loss: 0.3253 - iou_score: 0.6718 - f1-score: 0.8012For batch 222, tr_loss is    0.33.\n",
      "224/225 [============================>.] - ETA: 0s - loss: 0.3256 - iou_score: 0.6715 - f1-score: 0.8010For batch 223, tr_loss is    0.33.\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.3253 - iou_score: 0.6718 - f1-score: 0.8011For batch 224, tr_loss is    0.33.\n",
      "For batch 0, vl_loss is    0.39.\n",
      "For batch 1, vl_loss is    0.38.\n",
      "For batch 2, vl_loss is    0.44.\n",
      "For batch 3, vl_loss is    0.43.\n",
      "For batch 4, vl_loss is    0.40.\n",
      "For batch 5, vl_loss is    0.40.\n",
      "For batch 6, vl_loss is    0.40.\n",
      "For batch 7, vl_loss is    0.40.\n",
      "For batch 8, vl_loss is    0.40.\n",
      "For batch 9, vl_loss is    0.40.\n",
      "For batch 10, vl_loss is    0.40.\n",
      "For batch 11, vl_loss is    0.40.\n",
      "For batch 12, vl_loss is    0.39.\n",
      "For batch 13, vl_loss is    0.39.\n",
      "For batch 14, vl_loss is    0.39.\n",
      "For batch 15, vl_loss is    0.40.\n",
      "For batch 16, vl_loss is    0.40.\n",
      "For batch 17, vl_loss is    0.40.\n",
      "For batch 18, vl_loss is    0.40.\n",
      "For batch 19, vl_loss is    0.40.\n",
      "For batch 20, vl_loss is    0.40.\n",
      "For batch 21, vl_loss is    0.41.\n",
      "For batch 22, vl_loss is    0.41.\n",
      "For batch 23, vl_loss is    0.41.\n",
      "For batch 24, vl_loss is    0.41.\n",
      "For batch 25, vl_loss is    0.41.\n",
      "For batch 26, vl_loss is    0.41.\n",
      "For batch 27, vl_loss is    0.41.\n",
      "For batch 28, vl_loss is    0.41.\n",
      "For batch 29, vl_loss is    0.41.\n",
      "For batch 30, vl_loss is    0.41.\n",
      "For batch 31, vl_loss is    0.41.\n",
      "For batch 32, vl_loss is    0.41.\n",
      "For batch 33, vl_loss is    0.41.\n",
      "For batch 34, vl_loss is    0.41.\n",
      "For batch 35, vl_loss is    0.41.\n",
      "For batch 36, vl_loss is    0.41.\n",
      "For batch 37, vl_loss is    0.41.\n",
      "For batch 38, vl_loss is    0.41.\n",
      "For batch 39, vl_loss is    0.41.\n",
      "For batch 40, vl_loss is    0.41.\n",
      "For batch 41, vl_loss is    0.41.\n",
      "For batch 42, vl_loss is    0.41.\n",
      "For batch 43, vl_loss is    0.41.\n",
      "For batch 44, vl_loss is    0.41.\n",
      "For batch 45, vl_loss is    0.41.\n",
      "For batch 46, vl_loss is    0.40.\n",
      "For batch 47, vl_loss is    0.40.\n",
      "For batch 48, vl_loss is    0.40.\n",
      "For batch 49, vl_loss is    0.40.\n",
      "For batch 50, vl_loss is    0.40.\n",
      "For batch 51, vl_loss is    0.40.\n",
      "For batch 52, vl_loss is    0.40.\n",
      "For batch 53, vl_loss is    0.40.\n",
      "For batch 54, vl_loss is    0.40.\n",
      "For batch 55, vl_loss is    0.40.\n",
      "For batch 56, vl_loss is    0.40.\n",
      "For batch 57, vl_loss is    0.40.\n",
      "For batch 58, vl_loss is    0.40.\n",
      "For batch 59, vl_loss is    0.40.\n",
      "For batch 60, vl_loss is    0.40.\n",
      "For batch 61, vl_loss is    0.40.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 62, vl_loss is    0.40.\n",
      "For batch 63, vl_loss is    0.40.\n",
      "For batch 64, vl_loss is    0.41.\n",
      "For batch 65, vl_loss is    0.40.\n",
      "For batch 66, vl_loss is    0.41.\n",
      "For batch 67, vl_loss is    0.41.\n",
      "For batch 68, vl_loss is    0.41.\n",
      "For batch 69, vl_loss is    0.41.\n",
      "For batch 70, vl_loss is    0.41.\n",
      "For batch 71, vl_loss is    0.41.\n",
      "For batch 72, vl_loss is    0.41.\n",
      "For batch 73, vl_loss is    0.41.\n",
      "For batch 74, vl_loss is    0.41.\n",
      "225/225 [==============================] - 233s 911ms/step - loss: 0.3253 - iou_score: 0.6718 - f1-score: 0.8011 - val_loss: 0.4061 - val_iou_score: 0.6287 - val_f1-score: 0.7695\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.29298 to 0.40609, saving model to ./model/tumor_100_unet_efficientnetb0_imagenet_09293.hdf5\n",
      "The average loss for epoch 1 is    0.33 \n",
      "Epoch 3/200\n",
      "  1/225 [..............................] - ETA: 9:59 - loss: 0.3579 - iou_score: 0.6431 - f1-score: 0.7827For batch 0, tr_loss is    0.36.\n",
      "  2/225 [..............................] - ETA: 4:07 - loss: 0.3353 - iou_score: 0.6639 - f1-score: 0.7975For batch 1, tr_loss is    0.34.\n",
      "  3/225 [..............................] - ETA: 4:16 - loss: 0.3339 - iou_score: 0.6630 - f1-score: 0.7966For batch 2, tr_loss is    0.33.\n",
      "  4/225 [..............................] - ETA: 4:13 - loss: 0.3230 - iou_score: 0.6783 - f1-score: 0.8072For batch 3, tr_loss is    0.32.\n",
      "  5/225 [..............................] - ETA: 4:34 - loss: 0.3201 - iou_score: 0.6805 - f1-score: 0.8089For batch 4, tr_loss is    0.32.\n",
      "  6/225 [..............................] - ETA: 4:14 - loss: 0.3235 - iou_score: 0.6745 - f1-score: 0.8046For batch 5, tr_loss is    0.32.\n",
      "  7/225 [..............................] - ETA: 4:08 - loss: 0.3246 - iou_score: 0.6713 - f1-score: 0.8018For batch 6, tr_loss is    0.32.\n",
      "  8/225 [>.............................] - ETA: 4:00 - loss: 0.3258 - iou_score: 0.6683 - f1-score: 0.7995For batch 7, tr_loss is    0.33.\n",
      "  9/225 [>.............................] - ETA: 4:11 - loss: 0.3163 - iou_score: 0.6782 - f1-score: 0.8060For batch 8, tr_loss is    0.32.\n",
      " 10/225 [>.............................] - ETA: 4:02 - loss: 0.3184 - iou_score: 0.6757 - f1-score: 0.8042For batch 9, tr_loss is    0.32.\n",
      " 11/225 [>.............................] - ETA: 3:51 - loss: 0.3171 - iou_score: 0.6758 - f1-score: 0.8042For batch 10, tr_loss is    0.32.\n",
      " 12/225 [>.............................] - ETA: 3:40 - loss: 0.3209 - iou_score: 0.6697 - f1-score: 0.7996For batch 11, tr_loss is    0.32.\n",
      " 13/225 [>.............................] - ETA: 3:43 - loss: 0.3215 - iou_score: 0.6671 - f1-score: 0.7979For batch 12, tr_loss is    0.32.\n",
      " 14/225 [>.............................] - ETA: 3:37 - loss: 0.3198 - iou_score: 0.6685 - f1-score: 0.7990For batch 13, tr_loss is    0.32.\n",
      " 15/225 [=>............................] - ETA: 3:36 - loss: 0.3195 - iou_score: 0.6679 - f1-score: 0.7988For batch 14, tr_loss is    0.32.\n",
      " 16/225 [=>............................] - ETA: 3:28 - loss: 0.3212 - iou_score: 0.6679 - f1-score: 0.7986For batch 15, tr_loss is    0.32.\n",
      " 17/225 [=>............................] - ETA: 3:29 - loss: 0.3189 - iou_score: 0.6709 - f1-score: 0.8009For batch 16, tr_loss is    0.32.\n",
      " 18/225 [=>............................] - ETA: 3:23 - loss: 0.3180 - iou_score: 0.6704 - f1-score: 0.8005For batch 17, tr_loss is    0.32.\n",
      " 19/225 [=>............................] - ETA: 3:24 - loss: 0.3158 - iou_score: 0.6745 - f1-score: 0.8034For batch 18, tr_loss is    0.32.\n",
      " 20/225 [=>............................] - ETA: 3:24 - loss: 0.3144 - iou_score: 0.6758 - f1-score: 0.8043For batch 19, tr_loss is    0.31.\n",
      " 21/225 [=>............................] - ETA: 3:21 - loss: 0.3145 - iou_score: 0.6758 - f1-score: 0.8044For batch 20, tr_loss is    0.31.\n",
      " 22/225 [=>............................] - ETA: 3:17 - loss: 0.3138 - iou_score: 0.6769 - f1-score: 0.8053For batch 21, tr_loss is    0.31.\n",
      " 23/225 [==>...........................] - ETA: 3:17 - loss: 0.3207 - iou_score: 0.6700 - f1-score: 0.8000For batch 22, tr_loss is    0.32.\n",
      " 24/225 [==>...........................] - ETA: 3:14 - loss: 0.3215 - iou_score: 0.6685 - f1-score: 0.7989For batch 23, tr_loss is    0.32.\n",
      " 25/225 [==>...........................] - ETA: 3:11 - loss: 0.3224 - iou_score: 0.6672 - f1-score: 0.7981For batch 24, tr_loss is    0.32.\n",
      " 26/225 [==>...........................] - ETA: 3:08 - loss: 0.3199 - iou_score: 0.6709 - f1-score: 0.8007For batch 25, tr_loss is    0.32.\n",
      " 27/225 [==>...........................] - ETA: 3:09 - loss: 0.3204 - iou_score: 0.6700 - f1-score: 0.8001For batch 26, tr_loss is    0.32.\n",
      " 28/225 [==>...........................] - ETA: 3:05 - loss: 0.3200 - iou_score: 0.6704 - f1-score: 0.8004For batch 27, tr_loss is    0.32.\n",
      " 29/225 [==>...........................] - ETA: 3:05 - loss: 0.3192 - iou_score: 0.6717 - f1-score: 0.8013For batch 28, tr_loss is    0.32.\n",
      " 30/225 [===>..........................] - ETA: 3:04 - loss: 0.3179 - iou_score: 0.6733 - f1-score: 0.8024For batch 29, tr_loss is    0.32.\n",
      " 31/225 [===>..........................] - ETA: 3:00 - loss: 0.3172 - iou_score: 0.6743 - f1-score: 0.8032For batch 30, tr_loss is    0.32.\n",
      " 32/225 [===>..........................] - ETA: 2:58 - loss: 0.3169 - iou_score: 0.6747 - f1-score: 0.8036For batch 31, tr_loss is    0.32.\n",
      " 33/225 [===>..........................] - ETA: 2:58 - loss: 0.3154 - iou_score: 0.6772 - f1-score: 0.8053For batch 32, tr_loss is    0.32.\n",
      " 34/225 [===>..........................] - ETA: 2:58 - loss: 0.3156 - iou_score: 0.6774 - f1-score: 0.8054For batch 33, tr_loss is    0.32.\n",
      " 35/225 [===>..........................] - ETA: 2:54 - loss: 0.3165 - iou_score: 0.6761 - f1-score: 0.8045For batch 34, tr_loss is    0.32.\n",
      " 36/225 [===>..........................] - ETA: 2:52 - loss: 0.3151 - iou_score: 0.6780 - f1-score: 0.8059For batch 35, tr_loss is    0.32.\n",
      " 37/225 [===>..........................] - ETA: 2:52 - loss: 0.3137 - iou_score: 0.6794 - f1-score: 0.8069For batch 36, tr_loss is    0.31.\n",
      " 38/225 [====>.........................] - ETA: 2:52 - loss: 0.3112 - iou_score: 0.6817 - f1-score: 0.8085For batch 37, tr_loss is    0.31.\n",
      " 39/225 [====>.........................] - ETA: 2:52 - loss: 0.3125 - iou_score: 0.6802 - f1-score: 0.8074For batch 38, tr_loss is    0.31.\n",
      " 40/225 [====>.........................] - ETA: 2:48 - loss: 0.3103 - iou_score: 0.6832 - f1-score: 0.8094For batch 39, tr_loss is    0.31.\n",
      " 41/225 [====>.........................] - ETA: 2:48 - loss: 0.3100 - iou_score: 0.6833 - f1-score: 0.8096For batch 40, tr_loss is    0.31.\n",
      " 42/225 [====>.........................] - ETA: 2:45 - loss: 0.3100 - iou_score: 0.6827 - f1-score: 0.8092For batch 41, tr_loss is    0.31.\n",
      " 43/225 [====>.........................] - ETA: 2:44 - loss: 0.3084 - iou_score: 0.6838 - f1-score: 0.8100For batch 42, tr_loss is    0.31.\n",
      " 44/225 [====>.........................] - ETA: 2:43 - loss: 0.3086 - iou_score: 0.6837 - f1-score: 0.8100For batch 43, tr_loss is    0.31.\n",
      " 45/225 [=====>........................] - ETA: 2:41 - loss: 0.3084 - iou_score: 0.6837 - f1-score: 0.8100For batch 44, tr_loss is    0.31.\n",
      " 46/225 [=====>........................] - ETA: 2:40 - loss: 0.3092 - iou_score: 0.6829 - f1-score: 0.8095For batch 45, tr_loss is    0.31.\n",
      " 47/225 [=====>........................] - ETA: 2:40 - loss: 0.3081 - iou_score: 0.6841 - f1-score: 0.8104For batch 46, tr_loss is    0.31.\n",
      " 48/225 [=====>........................] - ETA: 2:39 - loss: 0.3081 - iou_score: 0.6846 - f1-score: 0.8107For batch 47, tr_loss is    0.31.\n",
      " 49/225 [=====>........................] - ETA: 2:39 - loss: 0.3091 - iou_score: 0.6831 - f1-score: 0.8097For batch 48, tr_loss is    0.31.\n",
      " 50/225 [=====>........................] - ETA: 2:37 - loss: 0.3110 - iou_score: 0.6809 - f1-score: 0.8080For batch 49, tr_loss is    0.31.\n",
      " 51/225 [=====>........................] - ETA: 2:35 - loss: 0.3111 - iou_score: 0.6805 - f1-score: 0.8077For batch 50, tr_loss is    0.31.\n",
      " 52/225 [=====>........................] - ETA: 2:34 - loss: 0.3114 - iou_score: 0.6799 - f1-score: 0.8073For batch 51, tr_loss is    0.31.\n",
      " 53/225 [======>.......................] - ETA: 2:34 - loss: 0.3122 - iou_score: 0.6786 - f1-score: 0.8064For batch 52, tr_loss is    0.31.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 54/225 [======>.......................] - ETA: 2:32 - loss: 0.3122 - iou_score: 0.6782 - f1-score: 0.8061For batch 53, tr_loss is    0.31.\n",
      " 55/225 [======>.......................] - ETA: 2:30 - loss: 0.3117 - iou_score: 0.6787 - f1-score: 0.8065For batch 54, tr_loss is    0.31.\n",
      " 56/225 [======>.......................] - ETA: 2:29 - loss: 0.3114 - iou_score: 0.6788 - f1-score: 0.8066For batch 55, tr_loss is    0.31.\n",
      " 57/225 [======>.......................] - ETA: 2:27 - loss: 0.3121 - iou_score: 0.6779 - f1-score: 0.8060For batch 56, tr_loss is    0.31.\n",
      " 58/225 [======>.......................] - ETA: 2:26 - loss: 0.3114 - iou_score: 0.6781 - f1-score: 0.8061For batch 57, tr_loss is    0.31.\n",
      " 59/225 [======>.......................] - ETA: 2:24 - loss: 0.3107 - iou_score: 0.6790 - f1-score: 0.8068For batch 58, tr_loss is    0.31.\n",
      " 60/225 [=======>......................] - ETA: 2:24 - loss: 0.3108 - iou_score: 0.6790 - f1-score: 0.8068For batch 59, tr_loss is    0.31.\n",
      " 61/225 [=======>......................] - ETA: 2:22 - loss: 0.3112 - iou_score: 0.6785 - f1-score: 0.8065For batch 60, tr_loss is    0.31.\n",
      " 62/225 [=======>......................] - ETA: 2:22 - loss: 0.3113 - iou_score: 0.6791 - f1-score: 0.8069For batch 61, tr_loss is    0.31.\n",
      " 63/225 [=======>......................] - ETA: 2:21 - loss: 0.3115 - iou_score: 0.6788 - f1-score: 0.8066For batch 62, tr_loss is    0.31.\n",
      " 64/225 [=======>......................] - ETA: 2:19 - loss: 0.3125 - iou_score: 0.6777 - f1-score: 0.8059For batch 63, tr_loss is    0.31.\n",
      " 65/225 [=======>......................] - ETA: 2:18 - loss: 0.3113 - iou_score: 0.6793 - f1-score: 0.8070For batch 64, tr_loss is    0.31.\n",
      " 66/225 [=======>......................] - ETA: 2:17 - loss: 0.3112 - iou_score: 0.6797 - f1-score: 0.8072For batch 65, tr_loss is    0.31.\n",
      " 67/225 [=======>......................] - ETA: 2:17 - loss: 0.3112 - iou_score: 0.6794 - f1-score: 0.8070For batch 66, tr_loss is    0.31.\n",
      " 68/225 [========>.....................] - ETA: 2:17 - loss: 0.3107 - iou_score: 0.6800 - f1-score: 0.8074For batch 67, tr_loss is    0.31.\n",
      " 69/225 [========>.....................] - ETA: 2:15 - loss: 0.3114 - iou_score: 0.6793 - f1-score: 0.8069For batch 68, tr_loss is    0.31.\n",
      " 70/225 [========>.....................] - ETA: 2:13 - loss: 0.3118 - iou_score: 0.6789 - f1-score: 0.8067For batch 69, tr_loss is    0.31.\n",
      " 71/225 [========>.....................] - ETA: 2:13 - loss: 0.3112 - iou_score: 0.6794 - f1-score: 0.8070For batch 70, tr_loss is    0.31.\n",
      " 72/225 [========>.....................] - ETA: 2:11 - loss: 0.3117 - iou_score: 0.6786 - f1-score: 0.8064For batch 71, tr_loss is    0.31.\n",
      " 73/225 [========>.....................] - ETA: 2:11 - loss: 0.3120 - iou_score: 0.6783 - f1-score: 0.8061For batch 72, tr_loss is    0.31.\n",
      " 74/225 [========>.....................] - ETA: 2:10 - loss: 0.3134 - iou_score: 0.6766 - f1-score: 0.8049For batch 73, tr_loss is    0.31.\n",
      " 75/225 [=========>....................] - ETA: 2:08 - loss: 0.3140 - iou_score: 0.6762 - f1-score: 0.8046For batch 74, tr_loss is    0.31.\n",
      " 76/225 [=========>....................] - ETA: 2:08 - loss: 0.3138 - iou_score: 0.6765 - f1-score: 0.8048For batch 75, tr_loss is    0.31.\n",
      " 77/225 [=========>....................] - ETA: 2:07 - loss: 0.3136 - iou_score: 0.6764 - f1-score: 0.8048For batch 76, tr_loss is    0.31.\n",
      " 78/225 [=========>....................] - ETA: 2:06 - loss: 0.3152 - iou_score: 0.6750 - f1-score: 0.8037For batch 77, tr_loss is    0.32.\n",
      " 79/225 [=========>....................] - ETA: 2:06 - loss: 0.3152 - iou_score: 0.6752 - f1-score: 0.8038For batch 78, tr_loss is    0.32.\n",
      " 80/225 [=========>....................] - ETA: 2:05 - loss: 0.3146 - iou_score: 0.6761 - f1-score: 0.8044For batch 79, tr_loss is    0.31.\n",
      " 81/225 [=========>....................] - ETA: 2:03 - loss: 0.3142 - iou_score: 0.6766 - f1-score: 0.8048For batch 80, tr_loss is    0.31.\n",
      " 82/225 [=========>....................] - ETA: 2:02 - loss: 0.3135 - iou_score: 0.6775 - f1-score: 0.8054For batch 81, tr_loss is    0.31.\n",
      " 83/225 [==========>...................] - ETA: 2:02 - loss: 0.3140 - iou_score: 0.6769 - f1-score: 0.8050For batch 82, tr_loss is    0.31.\n",
      " 84/225 [==========>...................] - ETA: 2:00 - loss: 0.3137 - iou_score: 0.6774 - f1-score: 0.8054For batch 83, tr_loss is    0.31.\n",
      " 85/225 [==========>...................] - ETA: 2:00 - loss: 0.3136 - iou_score: 0.6778 - f1-score: 0.8056For batch 84, tr_loss is    0.31.\n",
      " 86/225 [==========>...................] - ETA: 1:59 - loss: 0.3133 - iou_score: 0.6781 - f1-score: 0.8059For batch 85, tr_loss is    0.31.\n",
      " 87/225 [==========>...................] - ETA: 1:58 - loss: 0.3130 - iou_score: 0.6786 - f1-score: 0.8063For batch 86, tr_loss is    0.31.\n",
      " 88/225 [==========>...................] - ETA: 1:57 - loss: 0.3125 - iou_score: 0.6790 - f1-score: 0.8066For batch 87, tr_loss is    0.31.\n",
      " 89/225 [==========>...................] - ETA: 1:56 - loss: 0.3127 - iou_score: 0.6790 - f1-score: 0.8066For batch 88, tr_loss is    0.31.\n",
      " 90/225 [===========>..................] - ETA: 1:55 - loss: 0.3120 - iou_score: 0.6799 - f1-score: 0.8072For batch 89, tr_loss is    0.31.\n",
      " 91/225 [===========>..................] - ETA: 1:54 - loss: 0.3130 - iou_score: 0.6788 - f1-score: 0.8064For batch 90, tr_loss is    0.31.\n",
      " 92/225 [===========>..................] - ETA: 1:54 - loss: 0.3127 - iou_score: 0.6791 - f1-score: 0.8066For batch 91, tr_loss is    0.31.\n",
      " 93/225 [===========>..................] - ETA: 1:53 - loss: 0.3116 - iou_score: 0.6805 - f1-score: 0.8075For batch 92, tr_loss is    0.31.\n",
      " 94/225 [===========>..................] - ETA: 1:52 - loss: 0.3120 - iou_score: 0.6801 - f1-score: 0.8072For batch 93, tr_loss is    0.31.\n",
      " 95/225 [===========>..................] - ETA: 1:52 - loss: 0.3116 - iou_score: 0.6806 - f1-score: 0.8076For batch 94, tr_loss is    0.31.\n",
      " 96/225 [===========>..................] - ETA: 1:51 - loss: 0.3125 - iou_score: 0.6794 - f1-score: 0.8067For batch 95, tr_loss is    0.31.\n",
      " 97/225 [===========>..................] - ETA: 1:50 - loss: 0.3123 - iou_score: 0.6794 - f1-score: 0.8067For batch 96, tr_loss is    0.31.\n",
      " 98/225 [============>.................] - ETA: 1:49 - loss: 0.3124 - iou_score: 0.6788 - f1-score: 0.8063For batch 97, tr_loss is    0.31.\n",
      " 99/225 [============>.................] - ETA: 1:49 - loss: 0.3122 - iou_score: 0.6792 - f1-score: 0.8066For batch 98, tr_loss is    0.31.\n",
      "100/225 [============>.................] - ETA: 1:48 - loss: 0.3122 - iou_score: 0.6788 - f1-score: 0.8063For batch 99, tr_loss is    0.31.\n",
      "101/225 [============>.................] - ETA: 1:47 - loss: 0.3127 - iou_score: 0.6785 - f1-score: 0.8061For batch 100, tr_loss is    0.31.\n",
      "102/225 [============>.................] - ETA: 1:46 - loss: 0.3123 - iou_score: 0.6791 - f1-score: 0.8065For batch 101, tr_loss is    0.31.\n",
      "103/225 [============>.................] - ETA: 1:45 - loss: 0.3133 - iou_score: 0.6787 - f1-score: 0.8062For batch 102, tr_loss is    0.31.\n",
      "104/225 [============>.................] - ETA: 1:44 - loss: 0.3129 - iou_score: 0.6789 - f1-score: 0.8064For batch 103, tr_loss is    0.31.\n",
      "105/225 [=============>................] - ETA: 1:43 - loss: 0.3128 - iou_score: 0.6791 - f1-score: 0.8065For batch 104, tr_loss is    0.31.\n",
      "106/225 [=============>................] - ETA: 1:42 - loss: 0.3122 - iou_score: 0.6797 - f1-score: 0.8069For batch 105, tr_loss is    0.31.\n",
      "107/225 [=============>................] - ETA: 1:42 - loss: 0.3118 - iou_score: 0.6801 - f1-score: 0.8072For batch 106, tr_loss is    0.31.\n",
      "108/225 [=============>................] - ETA: 1:41 - loss: 0.3118 - iou_score: 0.6799 - f1-score: 0.8070For batch 107, tr_loss is    0.31.\n",
      "109/225 [=============>................] - ETA: 1:40 - loss: 0.3113 - iou_score: 0.6804 - f1-score: 0.8074For batch 108, tr_loss is    0.31.\n",
      "110/225 [=============>................] - ETA: 1:39 - loss: 0.3110 - iou_score: 0.6808 - f1-score: 0.8077For batch 109, tr_loss is    0.31.\n",
      "111/225 [=============>................] - ETA: 1:39 - loss: 0.3115 - iou_score: 0.6803 - f1-score: 0.8073For batch 110, tr_loss is    0.31.\n",
      "112/225 [=============>................] - ETA: 1:38 - loss: 0.3112 - iou_score: 0.6806 - f1-score: 0.8076For batch 111, tr_loss is    0.31.\n",
      "113/225 [==============>...............] - ETA: 1:37 - loss: 0.3110 - iou_score: 0.6810 - f1-score: 0.8079For batch 112, tr_loss is    0.31.\n",
      "114/225 [==============>...............] - ETA: 1:36 - loss: 0.3105 - iou_score: 0.6817 - f1-score: 0.8083For batch 113, tr_loss is    0.31.\n",
      "115/225 [==============>...............] - ETA: 1:35 - loss: 0.3098 - iou_score: 0.6826 - f1-score: 0.8089For batch 114, tr_loss is    0.31.\n",
      "116/225 [==============>...............] - ETA: 1:34 - loss: 0.3094 - iou_score: 0.6830 - f1-score: 0.8092For batch 115, tr_loss is    0.31.\n",
      "117/225 [==============>...............] - ETA: 1:33 - loss: 0.3092 - iou_score: 0.6830 - f1-score: 0.8092For batch 116, tr_loss is    0.31.\n",
      "118/225 [==============>...............] - ETA: 1:32 - loss: 0.3089 - iou_score: 0.6832 - f1-score: 0.8094For batch 117, tr_loss is    0.31.\n",
      "119/225 [==============>...............] - ETA: 1:31 - loss: 0.3087 - iou_score: 0.6833 - f1-score: 0.8095For batch 118, tr_loss is    0.31.\n",
      "120/225 [===============>..............] - ETA: 1:31 - loss: 0.3091 - iou_score: 0.6831 - f1-score: 0.8093For batch 119, tr_loss is    0.31.\n",
      "121/225 [===============>..............] - ETA: 1:30 - loss: 0.3087 - iou_score: 0.6833 - f1-score: 0.8095For batch 120, tr_loss is    0.31.\n",
      "122/225 [===============>..............] - ETA: 1:29 - loss: 0.3085 - iou_score: 0.6836 - f1-score: 0.8097For batch 121, tr_loss is    0.31.\n",
      "123/225 [===============>..............] - ETA: 1:28 - loss: 0.3080 - iou_score: 0.6841 - f1-score: 0.8100For batch 122, tr_loss is    0.31.\n",
      "124/225 [===============>..............] - ETA: 1:27 - loss: 0.3080 - iou_score: 0.6839 - f1-score: 0.8099For batch 123, tr_loss is    0.31.\n",
      "125/225 [===============>..............] - ETA: 1:26 - loss: 0.3084 - iou_score: 0.6838 - f1-score: 0.8099For batch 124, tr_loss is    0.31.\n",
      "126/225 [===============>..............] - ETA: 1:26 - loss: 0.3084 - iou_score: 0.6837 - f1-score: 0.8097For batch 125, tr_loss is    0.31.\n",
      "127/225 [===============>..............] - ETA: 1:25 - loss: 0.3084 - iou_score: 0.6835 - f1-score: 0.8096For batch 126, tr_loss is    0.31.\n",
      "128/225 [================>.............] - ETA: 1:24 - loss: 0.3081 - iou_score: 0.6840 - f1-score: 0.8099For batch 127, tr_loss is    0.31.\n",
      "129/225 [================>.............] - ETA: 1:23 - loss: 0.3087 - iou_score: 0.6831 - f1-score: 0.8093For batch 128, tr_loss is    0.31.\n",
      "130/225 [================>.............] - ETA: 1:22 - loss: 0.3083 - iou_score: 0.6836 - f1-score: 0.8096For batch 129, tr_loss is    0.31.\n",
      "131/225 [================>.............] - ETA: 1:21 - loss: 0.3083 - iou_score: 0.6835 - f1-score: 0.8096For batch 130, tr_loss is    0.31.\n",
      "132/225 [================>.............] - ETA: 1:21 - loss: 0.3079 - iou_score: 0.6840 - f1-score: 0.8099For batch 131, tr_loss is    0.31.\n",
      "133/225 [================>.............] - ETA: 1:20 - loss: 0.3081 - iou_score: 0.6838 - f1-score: 0.8097For batch 132, tr_loss is    0.31.\n",
      "134/225 [================>.............] - ETA: 1:19 - loss: 0.3078 - iou_score: 0.6841 - f1-score: 0.8100For batch 133, tr_loss is    0.31.\n",
      "135/225 [=================>............] - ETA: 1:18 - loss: 0.3079 - iou_score: 0.6841 - f1-score: 0.8100For batch 134, tr_loss is    0.31.\n",
      "136/225 [=================>............] - ETA: 1:17 - loss: 0.3080 - iou_score: 0.6839 - f1-score: 0.8098For batch 135, tr_loss is    0.31.\n",
      "137/225 [=================>............] - ETA: 1:16 - loss: 0.3078 - iou_score: 0.6839 - f1-score: 0.8099For batch 136, tr_loss is    0.31.\n",
      "138/225 [=================>............] - ETA: 1:15 - loss: 0.3081 - iou_score: 0.6838 - f1-score: 0.8098For batch 137, tr_loss is    0.31.\n",
      "139/225 [=================>............] - ETA: 1:15 - loss: 0.3082 - iou_score: 0.6837 - f1-score: 0.8097For batch 138, tr_loss is    0.31.\n",
      "140/225 [=================>............] - ETA: 1:14 - loss: 0.3092 - iou_score: 0.6828 - f1-score: 0.8091For batch 139, tr_loss is    0.31.\n",
      "141/225 [=================>............] - ETA: 1:13 - loss: 0.3088 - iou_score: 0.6833 - f1-score: 0.8094For batch 140, tr_loss is    0.31.\n",
      "142/225 [=================>............] - ETA: 1:12 - loss: 0.3086 - iou_score: 0.6835 - f1-score: 0.8096For batch 141, tr_loss is    0.31.\n",
      "143/225 [==================>...........] - ETA: 1:11 - loss: 0.3087 - iou_score: 0.6833 - f1-score: 0.8094For batch 142, tr_loss is    0.31.\n",
      "144/225 [==================>...........] - ETA: 1:10 - loss: 0.3090 - iou_score: 0.6831 - f1-score: 0.8093For batch 143, tr_loss is    0.31.\n",
      "145/225 [==================>...........] - ETA: 1:09 - loss: 0.3091 - iou_score: 0.6828 - f1-score: 0.8091For batch 144, tr_loss is    0.31.\n",
      "146/225 [==================>...........] - ETA: 1:08 - loss: 0.3090 - iou_score: 0.6830 - f1-score: 0.8092For batch 145, tr_loss is    0.31.\n",
      "147/225 [==================>...........] - ETA: 1:08 - loss: 0.3088 - iou_score: 0.6832 - f1-score: 0.8094For batch 146, tr_loss is    0.31.\n",
      "148/225 [==================>...........] - ETA: 1:07 - loss: 0.3088 - iou_score: 0.6832 - f1-score: 0.8094For batch 147, tr_loss is    0.31.\n",
      "149/225 [==================>...........] - ETA: 1:06 - loss: 0.3086 - iou_score: 0.6835 - f1-score: 0.8096For batch 148, tr_loss is    0.31.\n",
      "150/225 [===================>..........] - ETA: 1:05 - loss: 0.3086 - iou_score: 0.6834 - f1-score: 0.8095For batch 149, tr_loss is    0.31.\n",
      "151/225 [===================>..........] - ETA: 1:04 - loss: 0.3087 - iou_score: 0.6832 - f1-score: 0.8094For batch 150, tr_loss is    0.31.\n",
      "152/225 [===================>..........] - ETA: 1:03 - loss: 0.3085 - iou_score: 0.6834 - f1-score: 0.8095For batch 151, tr_loss is    0.31.\n",
      "153/225 [===================>..........] - ETA: 1:02 - loss: 0.3086 - iou_score: 0.6833 - f1-score: 0.8095For batch 152, tr_loss is    0.31.\n",
      "154/225 [===================>..........] - ETA: 1:02 - loss: 0.3086 - iou_score: 0.6832 - f1-score: 0.8094For batch 153, tr_loss is    0.31.\n",
      "155/225 [===================>..........] - ETA: 1:01 - loss: 0.3097 - iou_score: 0.6819 - f1-score: 0.8084For batch 154, tr_loss is    0.31.\n",
      "156/225 [===================>..........] - ETA: 1:00 - loss: 0.3101 - iou_score: 0.6815 - f1-score: 0.8082For batch 155, tr_loss is    0.31.\n",
      "157/225 [===================>..........] - ETA: 59s - loss: 0.3102 - iou_score: 0.6814 - f1-score: 0.8081 For batch 156, tr_loss is    0.31.\n",
      "158/225 [====================>.........] - ETA: 58s - loss: 0.3104 - iou_score: 0.6811 - f1-score: 0.8079For batch 157, tr_loss is    0.31.\n",
      "159/225 [====================>.........] - ETA: 57s - loss: 0.3104 - iou_score: 0.6812 - f1-score: 0.8080For batch 158, tr_loss is    0.31.\n",
      "160/225 [====================>.........] - ETA: 56s - loss: 0.3103 - iou_score: 0.6812 - f1-score: 0.8080For batch 159, tr_loss is    0.31.\n",
      "161/225 [====================>.........] - ETA: 55s - loss: 0.3099 - iou_score: 0.6817 - f1-score: 0.8083For batch 160, tr_loss is    0.31.\n",
      "162/225 [====================>.........] - ETA: 54s - loss: 0.3099 - iou_score: 0.6816 - f1-score: 0.8083For batch 161, tr_loss is    0.31.\n",
      "163/225 [====================>.........] - ETA: 54s - loss: 0.3101 - iou_score: 0.6814 - f1-score: 0.8081For batch 162, tr_loss is    0.31.\n",
      "164/225 [====================>.........] - ETA: 53s - loss: 0.3102 - iou_score: 0.6814 - f1-score: 0.8081For batch 163, tr_loss is    0.31.\n",
      "165/225 [=====================>........] - ETA: 52s - loss: 0.3101 - iou_score: 0.6815 - f1-score: 0.8082For batch 164, tr_loss is    0.31.\n",
      "166/225 [=====================>........] - ETA: 51s - loss: 0.3108 - iou_score: 0.6808 - f1-score: 0.8077For batch 165, tr_loss is    0.31.\n",
      "167/225 [=====================>........] - ETA: 50s - loss: 0.3107 - iou_score: 0.6809 - f1-score: 0.8078For batch 166, tr_loss is    0.31.\n",
      "168/225 [=====================>........] - ETA: 49s - loss: 0.3100 - iou_score: 0.6817 - f1-score: 0.8083For batch 167, tr_loss is    0.31.\n",
      "169/225 [=====================>........] - ETA: 49s - loss: 0.3098 - iou_score: 0.6821 - f1-score: 0.8086For batch 168, tr_loss is    0.31.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/225 [=====================>........] - ETA: 48s - loss: 0.3102 - iou_score: 0.6817 - f1-score: 0.8083For batch 169, tr_loss is    0.31.\n",
      "171/225 [=====================>........] - ETA: 47s - loss: 0.3104 - iou_score: 0.6815 - f1-score: 0.8082For batch 170, tr_loss is    0.31.\n",
      "172/225 [=====================>........] - ETA: 46s - loss: 0.3108 - iou_score: 0.6810 - f1-score: 0.8078For batch 171, tr_loss is    0.31.\n",
      "173/225 [======================>.......] - ETA: 45s - loss: 0.3112 - iou_score: 0.6805 - f1-score: 0.8075For batch 172, tr_loss is    0.31.\n",
      "174/225 [======================>.......] - ETA: 44s - loss: 0.3111 - iou_score: 0.6806 - f1-score: 0.8075For batch 173, tr_loss is    0.31.\n",
      "175/225 [======================>.......] - ETA: 43s - loss: 0.3112 - iou_score: 0.6804 - f1-score: 0.8073For batch 174, tr_loss is    0.31.\n",
      "176/225 [======================>.......] - ETA: 42s - loss: 0.3112 - iou_score: 0.6802 - f1-score: 0.8072For batch 175, tr_loss is    0.31.\n",
      "177/225 [======================>.......] - ETA: 41s - loss: 0.3109 - iou_score: 0.6807 - f1-score: 0.8076For batch 176, tr_loss is    0.31.\n",
      "178/225 [======================>.......] - ETA: 41s - loss: 0.3108 - iou_score: 0.6808 - f1-score: 0.8077For batch 177, tr_loss is    0.31.\n",
      "179/225 [======================>.......] - ETA: 40s - loss: 0.3107 - iou_score: 0.6809 - f1-score: 0.8078For batch 178, tr_loss is    0.31.\n",
      "180/225 [=======================>......] - ETA: 39s - loss: 0.3110 - iou_score: 0.6806 - f1-score: 0.8075For batch 179, tr_loss is    0.31.\n",
      "181/225 [=======================>......] - ETA: 38s - loss: 0.3111 - iou_score: 0.6805 - f1-score: 0.8075For batch 180, tr_loss is    0.31.\n",
      "182/225 [=======================>......] - ETA: 37s - loss: 0.3110 - iou_score: 0.6807 - f1-score: 0.8076For batch 181, tr_loss is    0.31.\n",
      "183/225 [=======================>......] - ETA: 36s - loss: 0.3111 - iou_score: 0.6806 - f1-score: 0.8075For batch 182, tr_loss is    0.31.\n",
      "184/225 [=======================>......] - ETA: 35s - loss: 0.3111 - iou_score: 0.6805 - f1-score: 0.8075For batch 183, tr_loss is    0.31.\n",
      "185/225 [=======================>......] - ETA: 34s - loss: 0.3111 - iou_score: 0.6805 - f1-score: 0.8075For batch 184, tr_loss is    0.31.\n",
      "186/225 [=======================>......] - ETA: 34s - loss: 0.3112 - iou_score: 0.6805 - f1-score: 0.8075For batch 185, tr_loss is    0.31.\n",
      "187/225 [=======================>......] - ETA: 33s - loss: 0.3109 - iou_score: 0.6809 - f1-score: 0.8078For batch 186, tr_loss is    0.31.\n",
      "188/225 [========================>.....] - ETA: 32s - loss: 0.3107 - iou_score: 0.6811 - f1-score: 0.8080For batch 187, tr_loss is    0.31.\n",
      "189/225 [========================>.....] - ETA: 31s - loss: 0.3104 - iou_score: 0.6815 - f1-score: 0.8082For batch 188, tr_loss is    0.31.\n",
      "190/225 [========================>.....] - ETA: 30s - loss: 0.3102 - iou_score: 0.6816 - f1-score: 0.8083For batch 189, tr_loss is    0.31.\n",
      "191/225 [========================>.....] - ETA: 29s - loss: 0.3099 - iou_score: 0.6819 - f1-score: 0.8085For batch 190, tr_loss is    0.31.\n",
      "192/225 [========================>.....] - ETA: 28s - loss: 0.3095 - iou_score: 0.6823 - f1-score: 0.8088For batch 191, tr_loss is    0.31.\n",
      "193/225 [========================>.....] - ETA: 28s - loss: 0.3095 - iou_score: 0.6823 - f1-score: 0.8088For batch 192, tr_loss is    0.31.\n",
      "194/225 [========================>.....] - ETA: 27s - loss: 0.3094 - iou_score: 0.6824 - f1-score: 0.8089For batch 193, tr_loss is    0.31.\n",
      "195/225 [=========================>....] - ETA: 26s - loss: 0.3093 - iou_score: 0.6826 - f1-score: 0.8091For batch 194, tr_loss is    0.31.\n",
      "196/225 [=========================>....] - ETA: 25s - loss: 0.3091 - iou_score: 0.6828 - f1-score: 0.8092For batch 195, tr_loss is    0.31.\n",
      "197/225 [=========================>....] - ETA: 24s - loss: 0.3094 - iou_score: 0.6825 - f1-score: 0.8090For batch 196, tr_loss is    0.31.\n",
      "198/225 [=========================>....] - ETA: 23s - loss: 0.3090 - iou_score: 0.6829 - f1-score: 0.8093For batch 197, tr_loss is    0.31.\n",
      "199/225 [=========================>....] - ETA: 22s - loss: 0.3098 - iou_score: 0.6822 - f1-score: 0.8087For batch 198, tr_loss is    0.31.\n",
      "200/225 [=========================>....] - ETA: 21s - loss: 0.3095 - iou_score: 0.6825 - f1-score: 0.8089For batch 199, tr_loss is    0.31.\n",
      "201/225 [=========================>....] - ETA: 21s - loss: 0.3096 - iou_score: 0.6824 - f1-score: 0.8089For batch 200, tr_loss is    0.31.\n",
      "202/225 [=========================>....] - ETA: 20s - loss: 0.3093 - iou_score: 0.6829 - f1-score: 0.8092For batch 201, tr_loss is    0.31.\n",
      "203/225 [==========================>...] - ETA: 19s - loss: 0.3091 - iou_score: 0.6831 - f1-score: 0.8094For batch 202, tr_loss is    0.31.\n",
      "204/225 [==========================>...] - ETA: 18s - loss: 0.3087 - iou_score: 0.6836 - f1-score: 0.8097For batch 203, tr_loss is    0.31.\n",
      "205/225 [==========================>...] - ETA: 17s - loss: 0.3086 - iou_score: 0.6837 - f1-score: 0.8098For batch 204, tr_loss is    0.31.\n",
      "206/225 [==========================>...] - ETA: 16s - loss: 0.3085 - iou_score: 0.6838 - f1-score: 0.8098For batch 205, tr_loss is    0.31.\n",
      "207/225 [==========================>...] - ETA: 15s - loss: 0.3084 - iou_score: 0.6838 - f1-score: 0.8098For batch 206, tr_loss is    0.31.\n",
      "208/225 [==========================>...] - ETA: 14s - loss: 0.3087 - iou_score: 0.6835 - f1-score: 0.8096For batch 207, tr_loss is    0.31.\n",
      "209/225 [==========================>...] - ETA: 14s - loss: 0.3084 - iou_score: 0.6839 - f1-score: 0.8099For batch 208, tr_loss is    0.31.\n",
      "210/225 [===========================>..] - ETA: 13s - loss: 0.3085 - iou_score: 0.6837 - f1-score: 0.8098For batch 209, tr_loss is    0.31.\n",
      "211/225 [===========================>..] - ETA: 12s - loss: 0.3085 - iou_score: 0.6837 - f1-score: 0.8098For batch 210, tr_loss is    0.31.\n",
      "212/225 [===========================>..] - ETA: 11s - loss: 0.3085 - iou_score: 0.6836 - f1-score: 0.8097For batch 211, tr_loss is    0.31.\n",
      "213/225 [===========================>..] - ETA: 10s - loss: 0.3086 - iou_score: 0.6835 - f1-score: 0.8096For batch 212, tr_loss is    0.31.\n",
      "214/225 [===========================>..] - ETA: 9s - loss: 0.3087 - iou_score: 0.6833 - f1-score: 0.8095 For batch 213, tr_loss is    0.31.\n",
      "215/225 [===========================>..] - ETA: 8s - loss: 0.3085 - iou_score: 0.6836 - f1-score: 0.8097For batch 214, tr_loss is    0.31.\n",
      "216/225 [===========================>..] - ETA: 7s - loss: 0.3082 - iou_score: 0.6840 - f1-score: 0.8100For batch 215, tr_loss is    0.31.\n",
      "217/225 [===========================>..] - ETA: 6s - loss: 0.3079 - iou_score: 0.6844 - f1-score: 0.8103For batch 216, tr_loss is    0.31.\n",
      "218/225 [============================>.] - ETA: 6s - loss: 0.3076 - iou_score: 0.6848 - f1-score: 0.8105For batch 217, tr_loss is    0.31.\n",
      "219/225 [============================>.] - ETA: 5s - loss: 0.3075 - iou_score: 0.6848 - f1-score: 0.8106For batch 218, tr_loss is    0.31.\n",
      "220/225 [============================>.] - ETA: 4s - loss: 0.3074 - iou_score: 0.6849 - f1-score: 0.8106For batch 219, tr_loss is    0.31.\n",
      "221/225 [============================>.] - ETA: 3s - loss: 0.3075 - iou_score: 0.6847 - f1-score: 0.8105For batch 220, tr_loss is    0.31.\n",
      "222/225 [============================>.] - ETA: 2s - loss: 0.3075 - iou_score: 0.6847 - f1-score: 0.8105For batch 221, tr_loss is    0.31.\n",
      "223/225 [============================>.] - ETA: 1s - loss: 0.3075 - iou_score: 0.6846 - f1-score: 0.8104For batch 222, tr_loss is    0.31.\n",
      "224/225 [============================>.] - ETA: 0s - loss: 0.3077 - iou_score: 0.6844 - f1-score: 0.8103For batch 223, tr_loss is    0.31.\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.3075 - iou_score: 0.6847 - f1-score: 0.8105For batch 224, tr_loss is    0.31.\n",
      "For batch 0, vl_loss is    0.44.\n",
      "For batch 1, vl_loss is    0.42.\n",
      "For batch 2, vl_loss is    0.48.\n",
      "For batch 3, vl_loss is    0.49.\n",
      "For batch 4, vl_loss is    0.46.\n",
      "For batch 5, vl_loss is    0.46.\n",
      "For batch 6, vl_loss is    0.46.\n",
      "For batch 7, vl_loss is    0.46.\n",
      "For batch 8, vl_loss is    0.46.\n",
      "For batch 9, vl_loss is    0.45.\n",
      "For batch 10, vl_loss is    0.45.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 11, vl_loss is    0.44.\n",
      "For batch 12, vl_loss is    0.43.\n",
      "For batch 13, vl_loss is    0.43.\n",
      "For batch 14, vl_loss is    0.43.\n",
      "For batch 15, vl_loss is    0.44.\n",
      "For batch 16, vl_loss is    0.44.\n",
      "For batch 17, vl_loss is    0.44.\n",
      "For batch 18, vl_loss is    0.44.\n",
      "For batch 19, vl_loss is    0.44.\n",
      "For batch 20, vl_loss is    0.44.\n",
      "For batch 21, vl_loss is    0.44.\n",
      "For batch 22, vl_loss is    0.44.\n",
      "For batch 23, vl_loss is    0.44.\n",
      "For batch 24, vl_loss is    0.44.\n",
      "For batch 25, vl_loss is    0.44.\n",
      "For batch 26, vl_loss is    0.44.\n",
      "For batch 27, vl_loss is    0.44.\n",
      "For batch 28, vl_loss is    0.44.\n",
      "For batch 29, vl_loss is    0.44.\n",
      "For batch 30, vl_loss is    0.44.\n",
      "For batch 31, vl_loss is    0.44.\n",
      "For batch 32, vl_loss is    0.44.\n",
      "For batch 33, vl_loss is    0.44.\n",
      "For batch 34, vl_loss is    0.44.\n",
      "For batch 35, vl_loss is    0.44.\n",
      "For batch 36, vl_loss is    0.44.\n",
      "For batch 37, vl_loss is    0.44.\n",
      "For batch 38, vl_loss is    0.44.\n",
      "For batch 39, vl_loss is    0.44.\n",
      "For batch 40, vl_loss is    0.44.\n",
      "For batch 41, vl_loss is    0.44.\n",
      "For batch 42, vl_loss is    0.43.\n",
      "For batch 43, vl_loss is    0.44.\n",
      "For batch 44, vl_loss is    0.44.\n",
      "For batch 45, vl_loss is    0.43.\n",
      "For batch 46, vl_loss is    0.43.\n",
      "For batch 47, vl_loss is    0.43.\n",
      "For batch 48, vl_loss is    0.43.\n",
      "For batch 49, vl_loss is    0.43.\n",
      "For batch 50, vl_loss is    0.43.\n",
      "For batch 51, vl_loss is    0.43.\n",
      "For batch 52, vl_loss is    0.43.\n",
      "For batch 53, vl_loss is    0.43.\n",
      "For batch 54, vl_loss is    0.43.\n",
      "For batch 55, vl_loss is    0.43.\n",
      "For batch 56, vl_loss is    0.43.\n",
      "For batch 57, vl_loss is    0.43.\n",
      "For batch 58, vl_loss is    0.43.\n",
      "For batch 59, vl_loss is    0.43.\n",
      "For batch 60, vl_loss is    0.43.\n",
      "For batch 61, vl_loss is    0.43.\n",
      "For batch 62, vl_loss is    0.43.\n",
      "For batch 63, vl_loss is    0.43.\n",
      "For batch 64, vl_loss is    0.44.\n",
      "For batch 65, vl_loss is    0.44.\n",
      "For batch 66, vl_loss is    0.44.\n",
      "For batch 67, vl_loss is    0.44.\n",
      "For batch 68, vl_loss is    0.44.\n",
      "For batch 69, vl_loss is    0.43.\n",
      "For batch 70, vl_loss is    0.43.\n",
      "For batch 71, vl_loss is    0.43.\n",
      "For batch 72, vl_loss is    0.43.\n",
      "For batch 73, vl_loss is    0.43.\n",
      "For batch 74, vl_loss is    0.43.\n",
      "225/225 [==============================] - 201s 885ms/step - loss: 0.3075 - iou_score: 0.6847 - f1-score: 0.8105 - val_loss: 0.4333 - val_iou_score: 0.6203 - val_f1-score: 0.7633\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.40609\n",
      "The average loss for epoch 2 is    0.31 \n",
      "Epoch 4/200\n",
      "  1/225 [..............................] - ETA: 9:30 - loss: 0.3357 - iou_score: 0.6732 - f1-score: 0.8045For batch 0, tr_loss is    0.34.\n",
      "  2/225 [..............................] - ETA: 3:57 - loss: 0.3089 - iou_score: 0.6832 - f1-score: 0.8114For batch 1, tr_loss is    0.31.\n",
      "  3/225 [..............................] - ETA: 4:33 - loss: 0.3012 - iou_score: 0.6831 - f1-score: 0.8113For batch 2, tr_loss is    0.30.\n",
      "  4/225 [..............................] - ETA: 4:52 - loss: 0.3002 - iou_score: 0.6914 - f1-score: 0.8170For batch 3, tr_loss is    0.30.\n",
      "  5/225 [..............................] - ETA: 4:29 - loss: 0.2973 - iou_score: 0.6983 - f1-score: 0.8217For batch 4, tr_loss is    0.30.\n",
      "  6/225 [..............................] - ETA: 4:33 - loss: 0.3052 - iou_score: 0.6905 - f1-score: 0.8160For batch 5, tr_loss is    0.31.\n",
      "  7/225 [..............................] - ETA: 4:22 - loss: 0.3068 - iou_score: 0.6878 - f1-score: 0.8138For batch 6, tr_loss is    0.31.\n",
      "  8/225 [>.............................] - ETA: 4:20 - loss: 0.3075 - iou_score: 0.6829 - f1-score: 0.8100For batch 7, tr_loss is    0.31.\n",
      "  9/225 [>.............................] - ETA: 4:16 - loss: 0.2984 - iou_score: 0.6924 - f1-score: 0.8161For batch 8, tr_loss is    0.30.\n",
      " 10/225 [>.............................] - ETA: 4:10 - loss: 0.3001 - iou_score: 0.6892 - f1-score: 0.8139For batch 9, tr_loss is    0.30.\n",
      " 11/225 [>.............................] - ETA: 4:06 - loss: 0.2996 - iou_score: 0.6899 - f1-score: 0.8142For batch 10, tr_loss is    0.30.\n",
      " 12/225 [>.............................] - ETA: 4:02 - loss: 0.3050 - iou_score: 0.6831 - f1-score: 0.8093For batch 11, tr_loss is    0.30.\n",
      " 13/225 [>.............................] - ETA: 3:59 - loss: 0.3065 - iou_score: 0.6793 - f1-score: 0.8067For batch 12, tr_loss is    0.31.\n",
      " 14/225 [>.............................] - ETA: 3:56 - loss: 0.3061 - iou_score: 0.6800 - f1-score: 0.8073For batch 13, tr_loss is    0.31.\n",
      " 15/225 [=>............................] - ETA: 3:45 - loss: 0.3061 - iou_score: 0.6791 - f1-score: 0.8068For batch 14, tr_loss is    0.31.\n",
      " 16/225 [=>............................] - ETA: 3:41 - loss: 0.3079 - iou_score: 0.6774 - f1-score: 0.8054For batch 15, tr_loss is    0.31.\n",
      " 17/225 [=>............................] - ETA: 3:40 - loss: 0.3057 - iou_score: 0.6809 - f1-score: 0.8078For batch 16, tr_loss is    0.31.\n",
      " 18/225 [=>............................] - ETA: 3:38 - loss: 0.3054 - iou_score: 0.6806 - f1-score: 0.8076For batch 17, tr_loss is    0.31.\n",
      " 19/225 [=>............................] - ETA: 3:34 - loss: 0.3025 - iou_score: 0.6845 - f1-score: 0.8104For batch 18, tr_loss is    0.30.\n",
      " 20/225 [=>............................] - ETA: 3:32 - loss: 0.3000 - iou_score: 0.6863 - f1-score: 0.8116For batch 19, tr_loss is    0.30.\n",
      " 21/225 [=>............................] - ETA: 3:28 - loss: 0.2992 - iou_score: 0.6873 - f1-score: 0.8124For batch 20, tr_loss is    0.30.\n",
      " 22/225 [=>............................] - ETA: 3:24 - loss: 0.2992 - iou_score: 0.6885 - f1-score: 0.8134For batch 21, tr_loss is    0.30.\n",
      " 23/225 [==>...........................] - ETA: 3:20 - loss: 0.3054 - iou_score: 0.6811 - f1-score: 0.8077For batch 22, tr_loss is    0.31.\n",
      " 24/225 [==>...........................] - ETA: 3:20 - loss: 0.3062 - iou_score: 0.6800 - f1-score: 0.8070For batch 23, tr_loss is    0.31.\n",
      " 25/225 [==>...........................] - ETA: 3:16 - loss: 0.3073 - iou_score: 0.6785 - f1-score: 0.8060For batch 24, tr_loss is    0.31.\n",
      " 26/225 [==>...........................] - ETA: 3:12 - loss: 0.3044 - iou_score: 0.6826 - f1-score: 0.8088For batch 25, tr_loss is    0.30.\n",
      " 27/225 [==>...........................] - ETA: 3:09 - loss: 0.3062 - iou_score: 0.6806 - f1-score: 0.8074For batch 26, tr_loss is    0.31.\n",
      " 28/225 [==>...........................] - ETA: 3:09 - loss: 0.3059 - iou_score: 0.6815 - f1-score: 0.8081For batch 27, tr_loss is    0.31.\n",
      " 29/225 [==>...........................] - ETA: 3:08 - loss: 0.3050 - iou_score: 0.6826 - f1-score: 0.8088For batch 28, tr_loss is    0.30.\n",
      " 30/225 [===>..........................] - ETA: 3:07 - loss: 0.3043 - iou_score: 0.6834 - f1-score: 0.8094For batch 29, tr_loss is    0.30.\n",
      " 31/225 [===>..........................] - ETA: 3:07 - loss: 0.3035 - iou_score: 0.6842 - f1-score: 0.8100For batch 30, tr_loss is    0.30.\n",
      " 32/225 [===>..........................] - ETA: 3:06 - loss: 0.3031 - iou_score: 0.6846 - f1-score: 0.8104For batch 31, tr_loss is    0.30.\n",
      " 33/225 [===>..........................] - ETA: 3:03 - loss: 0.3015 - iou_score: 0.6869 - f1-score: 0.8120For batch 32, tr_loss is    0.30.\n",
      " 34/225 [===>..........................] - ETA: 3:01 - loss: 0.3024 - iou_score: 0.6864 - f1-score: 0.8116For batch 33, tr_loss is    0.30.\n",
      " 35/225 [===>..........................] - ETA: 3:00 - loss: 0.3031 - iou_score: 0.6851 - f1-score: 0.8108For batch 34, tr_loss is    0.30.\n",
      " 36/225 [===>..........................] - ETA: 2:56 - loss: 0.3018 - iou_score: 0.6866 - f1-score: 0.8119For batch 35, tr_loss is    0.30.\n",
      " 37/225 [===>..........................] - ETA: 2:55 - loss: 0.3013 - iou_score: 0.6871 - f1-score: 0.8123For batch 36, tr_loss is    0.30.\n",
      " 38/225 [====>.........................] - ETA: 2:53 - loss: 0.2992 - iou_score: 0.6895 - f1-score: 0.8139For batch 37, tr_loss is    0.30.\n",
      " 39/225 [====>.........................] - ETA: 2:52 - loss: 0.3009 - iou_score: 0.6881 - f1-score: 0.8130For batch 38, tr_loss is    0.30.\n",
      " 40/225 [====>.........................] - ETA: 2:52 - loss: 0.2988 - iou_score: 0.6910 - f1-score: 0.8149For batch 39, tr_loss is    0.30.\n",
      " 41/225 [====>.........................] - ETA: 2:50 - loss: 0.2983 - iou_score: 0.6911 - f1-score: 0.8150For batch 40, tr_loss is    0.30.\n",
      " 42/225 [====>.........................] - ETA: 2:50 - loss: 0.2982 - iou_score: 0.6911 - f1-score: 0.8150For batch 41, tr_loss is    0.30.\n",
      " 43/225 [====>.........................] - ETA: 2:47 - loss: 0.2971 - iou_score: 0.6921 - f1-score: 0.8158For batch 42, tr_loss is    0.30.\n",
      " 44/225 [====>.........................] - ETA: 2:47 - loss: 0.2976 - iou_score: 0.6918 - f1-score: 0.8156For batch 43, tr_loss is    0.30.\n",
      " 45/225 [=====>........................] - ETA: 2:46 - loss: 0.2975 - iou_score: 0.6921 - f1-score: 0.8158For batch 44, tr_loss is    0.30.\n",
      " 46/225 [=====>........................] - ETA: 2:45 - loss: 0.2980 - iou_score: 0.6913 - f1-score: 0.8153For batch 45, tr_loss is    0.30.\n",
      " 47/225 [=====>........................] - ETA: 2:42 - loss: 0.2966 - iou_score: 0.6931 - f1-score: 0.8166For batch 46, tr_loss is    0.30.\n",
      " 48/225 [=====>........................] - ETA: 2:42 - loss: 0.2962 - iou_score: 0.6935 - f1-score: 0.8169For batch 47, tr_loss is    0.30.\n",
      " 49/225 [=====>........................] - ETA: 2:40 - loss: 0.2973 - iou_score: 0.6920 - f1-score: 0.8158For batch 48, tr_loss is    0.30.\n",
      " 50/225 [=====>........................] - ETA: 2:39 - loss: 0.2997 - iou_score: 0.6899 - f1-score: 0.8143For batch 49, tr_loss is    0.30.\n",
      " 51/225 [=====>........................] - ETA: 2:39 - loss: 0.2997 - iou_score: 0.6901 - f1-score: 0.8144For batch 50, tr_loss is    0.30.\n",
      " 52/225 [=====>........................] - ETA: 2:38 - loss: 0.2990 - iou_score: 0.6909 - f1-score: 0.8150For batch 51, tr_loss is    0.30.\n",
      " 53/225 [======>.......................] - ETA: 2:35 - loss: 0.2995 - iou_score: 0.6904 - f1-score: 0.8146For batch 52, tr_loss is    0.30.\n",
      " 54/225 [======>.......................] - ETA: 2:35 - loss: 0.2988 - iou_score: 0.6907 - f1-score: 0.8149For batch 53, tr_loss is    0.30.\n",
      " 55/225 [======>.......................] - ETA: 2:34 - loss: 0.2984 - iou_score: 0.6911 - f1-score: 0.8151For batch 54, tr_loss is    0.30.\n",
      " 56/225 [======>.......................] - ETA: 2:34 - loss: 0.2978 - iou_score: 0.6915 - f1-score: 0.8154For batch 55, tr_loss is    0.30.\n",
      " 57/225 [======>.......................] - ETA: 2:31 - loss: 0.2987 - iou_score: 0.6909 - f1-score: 0.8151For batch 56, tr_loss is    0.30.\n",
      " 58/225 [======>.......................] - ETA: 2:30 - loss: 0.2983 - iou_score: 0.6909 - f1-score: 0.8151For batch 57, tr_loss is    0.30.\n",
      " 59/225 [======>.......................] - ETA: 2:29 - loss: 0.2977 - iou_score: 0.6918 - f1-score: 0.8157For batch 58, tr_loss is    0.30.\n",
      " 60/225 [=======>......................] - ETA: 2:27 - loss: 0.2977 - iou_score: 0.6919 - f1-score: 0.8158For batch 59, tr_loss is    0.30.\n",
      " 61/225 [=======>......................] - ETA: 2:27 - loss: 0.2978 - iou_score: 0.6917 - f1-score: 0.8157For batch 60, tr_loss is    0.30.\n",
      " 62/225 [=======>......................] - ETA: 2:26 - loss: 0.2974 - iou_score: 0.6921 - f1-score: 0.8160For batch 61, tr_loss is    0.30.\n",
      " 63/225 [=======>......................] - ETA: 2:26 - loss: 0.2978 - iou_score: 0.6916 - f1-score: 0.8156For batch 62, tr_loss is    0.30.\n",
      " 64/225 [=======>......................] - ETA: 2:25 - loss: 0.2985 - iou_score: 0.6905 - f1-score: 0.8149For batch 63, tr_loss is    0.30.\n",
      " 65/225 [=======>......................] - ETA: 2:23 - loss: 0.2973 - iou_score: 0.6919 - f1-score: 0.8158For batch 64, tr_loss is    0.30.\n",
      " 66/225 [=======>......................] - ETA: 2:22 - loss: 0.2975 - iou_score: 0.6920 - f1-score: 0.8158For batch 65, tr_loss is    0.30.\n",
      " 67/225 [=======>......................] - ETA: 2:21 - loss: 0.2977 - iou_score: 0.6915 - f1-score: 0.8155For batch 66, tr_loss is    0.30.\n",
      " 68/225 [========>.....................] - ETA: 2:19 - loss: 0.2971 - iou_score: 0.6920 - f1-score: 0.8158For batch 67, tr_loss is    0.30.\n",
      " 69/225 [========>.....................] - ETA: 2:18 - loss: 0.2976 - iou_score: 0.6912 - f1-score: 0.8153For batch 68, tr_loss is    0.30.\n",
      " 70/225 [========>.....................] - ETA: 2:17 - loss: 0.2983 - iou_score: 0.6902 - f1-score: 0.8146For batch 69, tr_loss is    0.30.\n",
      " 71/225 [========>.....................] - ETA: 2:17 - loss: 0.2976 - iou_score: 0.6910 - f1-score: 0.8151For batch 70, tr_loss is    0.30.\n",
      " 72/225 [========>.....................] - ETA: 2:15 - loss: 0.2978 - iou_score: 0.6903 - f1-score: 0.8146For batch 71, tr_loss is    0.30.\n",
      " 73/225 [========>.....................] - ETA: 2:14 - loss: 0.2978 - iou_score: 0.6902 - f1-score: 0.8145For batch 72, tr_loss is    0.30.\n",
      " 74/225 [========>.....................] - ETA: 2:14 - loss: 0.2989 - iou_score: 0.6891 - f1-score: 0.8137For batch 73, tr_loss is    0.30.\n",
      " 75/225 [=========>....................] - ETA: 2:13 - loss: 0.3002 - iou_score: 0.6884 - f1-score: 0.8132For batch 74, tr_loss is    0.30.\n",
      " 76/225 [=========>....................] - ETA: 2:12 - loss: 0.3001 - iou_score: 0.6888 - f1-score: 0.8135For batch 75, tr_loss is    0.30.\n",
      " 77/225 [=========>....................] - ETA: 2:10 - loss: 0.2995 - iou_score: 0.6890 - f1-score: 0.8137For batch 76, tr_loss is    0.30.\n",
      " 78/225 [=========>....................] - ETA: 2:09 - loss: 0.3015 - iou_score: 0.6875 - f1-score: 0.8125For batch 77, tr_loss is    0.30.\n",
      " 79/225 [=========>....................] - ETA: 2:08 - loss: 0.3012 - iou_score: 0.6878 - f1-score: 0.8127For batch 78, tr_loss is    0.30.\n",
      " 80/225 [=========>....................] - ETA: 2:08 - loss: 0.3007 - iou_score: 0.6885 - f1-score: 0.8132For batch 79, tr_loss is    0.30.\n",
      " 81/225 [=========>....................] - ETA: 2:06 - loss: 0.3000 - iou_score: 0.6892 - f1-score: 0.8137For batch 80, tr_loss is    0.30.\n",
      " 82/225 [=========>....................] - ETA: 2:05 - loss: 0.2994 - iou_score: 0.6899 - f1-score: 0.8142For batch 81, tr_loss is    0.30.\n",
      " 83/225 [==========>...................] - ETA: 2:05 - loss: 0.2997 - iou_score: 0.6896 - f1-score: 0.8139For batch 82, tr_loss is    0.30.\n",
      " 84/225 [==========>...................] - ETA: 2:04 - loss: 0.2993 - iou_score: 0.6901 - f1-score: 0.8143For batch 83, tr_loss is    0.30.\n",
      " 85/225 [==========>...................] - ETA: 2:03 - loss: 0.2993 - iou_score: 0.6903 - f1-score: 0.8145For batch 84, tr_loss is    0.30.\n",
      " 86/225 [==========>...................] - ETA: 2:02 - loss: 0.2991 - iou_score: 0.6905 - f1-score: 0.8146For batch 85, tr_loss is    0.30.\n",
      " 87/225 [==========>...................] - ETA: 2:00 - loss: 0.2987 - iou_score: 0.6910 - f1-score: 0.8150For batch 86, tr_loss is    0.30.\n",
      " 88/225 [==========>...................] - ETA: 2:00 - loss: 0.2982 - iou_score: 0.6915 - f1-score: 0.8153For batch 87, tr_loss is    0.30.\n",
      " 89/225 [==========>...................] - ETA: 1:59 - loss: 0.2983 - iou_score: 0.6914 - f1-score: 0.8153For batch 88, tr_loss is    0.30.\n",
      " 90/225 [===========>..................] - ETA: 1:57 - loss: 0.2977 - iou_score: 0.6922 - f1-score: 0.8159For batch 89, tr_loss is    0.30.\n",
      " 91/225 [===========>..................] - ETA: 1:57 - loss: 0.2982 - iou_score: 0.6915 - f1-score: 0.8154For batch 90, tr_loss is    0.30.\n",
      " 92/225 [===========>..................] - ETA: 1:56 - loss: 0.2981 - iou_score: 0.6918 - f1-score: 0.8156For batch 91, tr_loss is    0.30.\n",
      " 93/225 [===========>..................] - ETA: 1:55 - loss: 0.2971 - iou_score: 0.6930 - f1-score: 0.8164For batch 92, tr_loss is    0.30.\n",
      " 94/225 [===========>..................] - ETA: 1:53 - loss: 0.2978 - iou_score: 0.6925 - f1-score: 0.8160For batch 93, tr_loss is    0.30.\n",
      " 95/225 [===========>..................] - ETA: 1:52 - loss: 0.2975 - iou_score: 0.6931 - f1-score: 0.8164For batch 94, tr_loss is    0.30.\n",
      " 96/225 [===========>..................] - ETA: 1:51 - loss: 0.2982 - iou_score: 0.6921 - f1-score: 0.8157For batch 95, tr_loss is    0.30.\n",
      " 97/225 [===========>..................] - ETA: 1:50 - loss: 0.2979 - iou_score: 0.6923 - f1-score: 0.8159For batch 96, tr_loss is    0.30.\n",
      " 98/225 [============>.................] - ETA: 1:49 - loss: 0.2980 - iou_score: 0.6917 - f1-score: 0.8155For batch 97, tr_loss is    0.30.\n",
      " 99/225 [============>.................] - ETA: 1:48 - loss: 0.2980 - iou_score: 0.6918 - f1-score: 0.8156For batch 98, tr_loss is    0.30.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/225 [============>.................] - ETA: 1:47 - loss: 0.2982 - iou_score: 0.6914 - f1-score: 0.8153For batch 99, tr_loss is    0.30.\n",
      "101/225 [============>.................] - ETA: 1:46 - loss: 0.2985 - iou_score: 0.6913 - f1-score: 0.8151For batch 100, tr_loss is    0.30.\n",
      "102/225 [============>.................] - ETA: 1:45 - loss: 0.2982 - iou_score: 0.6916 - f1-score: 0.8154For batch 101, tr_loss is    0.30.\n",
      "103/225 [============>.................] - ETA: 1:45 - loss: 0.2990 - iou_score: 0.6913 - f1-score: 0.8151For batch 102, tr_loss is    0.30.\n",
      "104/225 [============>.................] - ETA: 1:44 - loss: 0.2987 - iou_score: 0.6914 - f1-score: 0.8153For batch 103, tr_loss is    0.30.\n",
      "105/225 [=============>................] - ETA: 1:43 - loss: 0.2987 - iou_score: 0.6917 - f1-score: 0.8155For batch 104, tr_loss is    0.30.\n",
      "106/225 [=============>................] - ETA: 1:42 - loss: 0.2983 - iou_score: 0.6921 - f1-score: 0.8158For batch 105, tr_loss is    0.30.\n",
      "107/225 [=============>................] - ETA: 1:41 - loss: 0.2980 - iou_score: 0.6924 - f1-score: 0.8160For batch 106, tr_loss is    0.30.\n",
      "108/225 [=============>................] - ETA: 1:41 - loss: 0.2980 - iou_score: 0.6922 - f1-score: 0.8158For batch 107, tr_loss is    0.30.\n",
      "109/225 [=============>................] - ETA: 1:39 - loss: 0.2975 - iou_score: 0.6927 - f1-score: 0.8162For batch 108, tr_loss is    0.30.\n",
      "110/225 [=============>................] - ETA: 1:39 - loss: 0.2972 - iou_score: 0.6931 - f1-score: 0.8165For batch 109, tr_loss is    0.30.\n",
      "111/225 [=============>................] - ETA: 1:38 - loss: 0.2975 - iou_score: 0.6928 - f1-score: 0.8162For batch 110, tr_loss is    0.30.\n",
      "112/225 [=============>................] - ETA: 1:37 - loss: 0.2972 - iou_score: 0.6932 - f1-score: 0.8165For batch 111, tr_loss is    0.30.\n",
      "113/225 [==============>...............] - ETA: 1:36 - loss: 0.2973 - iou_score: 0.6934 - f1-score: 0.8167For batch 112, tr_loss is    0.30.\n",
      "114/225 [==============>...............] - ETA: 1:35 - loss: 0.2968 - iou_score: 0.6941 - f1-score: 0.8172For batch 113, tr_loss is    0.30.\n",
      "115/225 [==============>...............] - ETA: 1:34 - loss: 0.2962 - iou_score: 0.6948 - f1-score: 0.8176For batch 114, tr_loss is    0.30.\n",
      "116/225 [==============>...............] - ETA: 1:33 - loss: 0.2959 - iou_score: 0.6951 - f1-score: 0.8178For batch 115, tr_loss is    0.30.\n",
      "117/225 [==============>...............] - ETA: 1:32 - loss: 0.2959 - iou_score: 0.6951 - f1-score: 0.8178For batch 116, tr_loss is    0.30.\n",
      "118/225 [==============>...............] - ETA: 1:31 - loss: 0.2958 - iou_score: 0.6951 - f1-score: 0.8179For batch 117, tr_loss is    0.30.\n",
      "119/225 [==============>...............] - ETA: 1:31 - loss: 0.2953 - iou_score: 0.6954 - f1-score: 0.8181For batch 118, tr_loss is    0.30.\n",
      "120/225 [===============>..............] - ETA: 1:30 - loss: 0.2955 - iou_score: 0.6952 - f1-score: 0.8179For batch 119, tr_loss is    0.30.\n",
      "121/225 [===============>..............] - ETA: 1:29 - loss: 0.2949 - iou_score: 0.6957 - f1-score: 0.8183For batch 120, tr_loss is    0.29.\n",
      "122/225 [===============>..............] - ETA: 1:28 - loss: 0.2946 - iou_score: 0.6961 - f1-score: 0.8185For batch 121, tr_loss is    0.29.\n",
      "123/225 [===============>..............] - ETA: 1:27 - loss: 0.2944 - iou_score: 0.6963 - f1-score: 0.8187For batch 122, tr_loss is    0.29.\n",
      "124/225 [===============>..............] - ETA: 1:26 - loss: 0.2946 - iou_score: 0.6960 - f1-score: 0.8185For batch 123, tr_loss is    0.29.\n",
      "125/225 [===============>..............] - ETA: 1:25 - loss: 0.2948 - iou_score: 0.6959 - f1-score: 0.8185For batch 124, tr_loss is    0.29.\n",
      "126/225 [===============>..............] - ETA: 1:24 - loss: 0.2951 - iou_score: 0.6958 - f1-score: 0.8184For batch 125, tr_loss is    0.30.\n",
      "127/225 [===============>..............] - ETA: 1:23 - loss: 0.2949 - iou_score: 0.6958 - f1-score: 0.8183For batch 126, tr_loss is    0.29.\n",
      "128/225 [================>.............] - ETA: 1:22 - loss: 0.2945 - iou_score: 0.6962 - f1-score: 0.8186For batch 127, tr_loss is    0.29.\n",
      "129/225 [================>.............] - ETA: 1:22 - loss: 0.2951 - iou_score: 0.6954 - f1-score: 0.8180For batch 128, tr_loss is    0.30.\n",
      "130/225 [================>.............] - ETA: 1:20 - loss: 0.2947 - iou_score: 0.6958 - f1-score: 0.8183For batch 129, tr_loss is    0.29.\n",
      "131/225 [================>.............] - ETA: 1:20 - loss: 0.2948 - iou_score: 0.6956 - f1-score: 0.8182For batch 130, tr_loss is    0.29.\n",
      "132/225 [================>.............] - ETA: 1:19 - loss: 0.2944 - iou_score: 0.6961 - f1-score: 0.8186For batch 131, tr_loss is    0.29.\n",
      "133/225 [================>.............] - ETA: 1:18 - loss: 0.2947 - iou_score: 0.6958 - f1-score: 0.8183For batch 132, tr_loss is    0.29.\n",
      "134/225 [================>.............] - ETA: 1:18 - loss: 0.2944 - iou_score: 0.6961 - f1-score: 0.8185For batch 133, tr_loss is    0.29.\n",
      "135/225 [=================>............] - ETA: 1:17 - loss: 0.2945 - iou_score: 0.6960 - f1-score: 0.8185For batch 134, tr_loss is    0.29.\n",
      "136/225 [=================>............] - ETA: 1:16 - loss: 0.2948 - iou_score: 0.6956 - f1-score: 0.8182For batch 135, tr_loss is    0.29.\n",
      "137/225 [=================>............] - ETA: 1:15 - loss: 0.2948 - iou_score: 0.6956 - f1-score: 0.8182For batch 136, tr_loss is    0.29.\n",
      "138/225 [=================>............] - ETA: 1:14 - loss: 0.2953 - iou_score: 0.6954 - f1-score: 0.8181For batch 137, tr_loss is    0.30.\n",
      "139/225 [=================>............] - ETA: 1:13 - loss: 0.2955 - iou_score: 0.6951 - f1-score: 0.8179For batch 138, tr_loss is    0.30.\n",
      "140/225 [=================>............] - ETA: 1:12 - loss: 0.2962 - iou_score: 0.6944 - f1-score: 0.8173For batch 139, tr_loss is    0.30.\n",
      "141/225 [=================>............] - ETA: 1:12 - loss: 0.2960 - iou_score: 0.6947 - f1-score: 0.8176For batch 140, tr_loss is    0.30.\n",
      "142/225 [=================>............] - ETA: 1:11 - loss: 0.2960 - iou_score: 0.6947 - f1-score: 0.8176For batch 141, tr_loss is    0.30.\n",
      "143/225 [==================>...........] - ETA: 1:10 - loss: 0.2962 - iou_score: 0.6944 - f1-score: 0.8174For batch 142, tr_loss is    0.30.\n",
      "144/225 [==================>...........] - ETA: 1:09 - loss: 0.2963 - iou_score: 0.6945 - f1-score: 0.8174For batch 143, tr_loss is    0.30.\n",
      "145/225 [==================>...........] - ETA: 1:09 - loss: 0.2964 - iou_score: 0.6942 - f1-score: 0.8172For batch 144, tr_loss is    0.30.\n",
      "146/225 [==================>...........] - ETA: 1:08 - loss: 0.2964 - iou_score: 0.6943 - f1-score: 0.8173For batch 145, tr_loss is    0.30.\n",
      "147/225 [==================>...........] - ETA: 1:07 - loss: 0.2962 - iou_score: 0.6947 - f1-score: 0.8176For batch 146, tr_loss is    0.30.\n",
      "148/225 [==================>...........] - ETA: 1:06 - loss: 0.2962 - iou_score: 0.6947 - f1-score: 0.8176For batch 147, tr_loss is    0.30.\n",
      "149/225 [==================>...........] - ETA: 1:05 - loss: 0.2961 - iou_score: 0.6948 - f1-score: 0.8177For batch 148, tr_loss is    0.30.\n",
      "150/225 [===================>..........] - ETA: 1:04 - loss: 0.2961 - iou_score: 0.6946 - f1-score: 0.8175For batch 149, tr_loss is    0.30.\n",
      "151/225 [===================>..........] - ETA: 1:04 - loss: 0.2963 - iou_score: 0.6943 - f1-score: 0.8173For batch 150, tr_loss is    0.30.\n",
      "152/225 [===================>..........] - ETA: 1:03 - loss: 0.2964 - iou_score: 0.6943 - f1-score: 0.8173For batch 151, tr_loss is    0.30.\n",
      "153/225 [===================>..........] - ETA: 1:02 - loss: 0.2963 - iou_score: 0.6942 - f1-score: 0.8173For batch 152, tr_loss is    0.30.\n",
      "154/225 [===================>..........] - ETA: 1:01 - loss: 0.2961 - iou_score: 0.6944 - f1-score: 0.8174For batch 153, tr_loss is    0.30.\n",
      "155/225 [===================>..........] - ETA: 1:00 - loss: 0.2975 - iou_score: 0.6931 - f1-score: 0.8163For batch 154, tr_loss is    0.30.\n",
      "156/225 [===================>..........] - ETA: 59s - loss: 0.2981 - iou_score: 0.6926 - f1-score: 0.8160 For batch 155, tr_loss is    0.30.\n",
      "157/225 [===================>..........] - ETA: 58s - loss: 0.2981 - iou_score: 0.6925 - f1-score: 0.8160For batch 156, tr_loss is    0.30.\n",
      "158/225 [====================>.........] - ETA: 58s - loss: 0.2983 - iou_score: 0.6922 - f1-score: 0.8157For batch 157, tr_loss is    0.30.\n",
      "159/225 [====================>.........] - ETA: 57s - loss: 0.2985 - iou_score: 0.6921 - f1-score: 0.8157For batch 158, tr_loss is    0.30.\n",
      "160/225 [====================>.........] - ETA: 56s - loss: 0.2984 - iou_score: 0.6920 - f1-score: 0.8156For batch 159, tr_loss is    0.30.\n",
      "161/225 [====================>.........] - ETA: 55s - loss: 0.2980 - iou_score: 0.6926 - f1-score: 0.8160For batch 160, tr_loss is    0.30.\n",
      "162/225 [====================>.........] - ETA: 54s - loss: 0.2980 - iou_score: 0.6924 - f1-score: 0.8159For batch 161, tr_loss is    0.30.\n",
      "163/225 [====================>.........] - ETA: 53s - loss: 0.2982 - iou_score: 0.6922 - f1-score: 0.8158For batch 162, tr_loss is    0.30.\n",
      "164/225 [====================>.........] - ETA: 52s - loss: 0.2982 - iou_score: 0.6922 - f1-score: 0.8158For batch 163, tr_loss is    0.30.\n",
      "165/225 [=====================>........] - ETA: 51s - loss: 0.2984 - iou_score: 0.6922 - f1-score: 0.8158For batch 164, tr_loss is    0.30.\n",
      "166/225 [=====================>........] - ETA: 51s - loss: 0.2990 - iou_score: 0.6914 - f1-score: 0.8152For batch 165, tr_loss is    0.30.\n",
      "167/225 [=====================>........] - ETA: 50s - loss: 0.2988 - iou_score: 0.6916 - f1-score: 0.8153For batch 166, tr_loss is    0.30.\n",
      "168/225 [=====================>........] - ETA: 49s - loss: 0.2982 - iou_score: 0.6924 - f1-score: 0.8159For batch 167, tr_loss is    0.30.\n",
      "169/225 [=====================>........] - ETA: 48s - loss: 0.2981 - iou_score: 0.6927 - f1-score: 0.8161For batch 168, tr_loss is    0.30.\n",
      "170/225 [=====================>........] - ETA: 47s - loss: 0.2985 - iou_score: 0.6923 - f1-score: 0.8158For batch 169, tr_loss is    0.30.\n",
      "171/225 [=====================>........] - ETA: 46s - loss: 0.2987 - iou_score: 0.6920 - f1-score: 0.8156For batch 170, tr_loss is    0.30.\n",
      "172/225 [=====================>........] - ETA: 45s - loss: 0.2991 - iou_score: 0.6915 - f1-score: 0.8153For batch 171, tr_loss is    0.30.\n",
      "173/225 [======================>.......] - ETA: 45s - loss: 0.2995 - iou_score: 0.6910 - f1-score: 0.8149For batch 172, tr_loss is    0.30.\n",
      "174/225 [======================>.......] - ETA: 44s - loss: 0.2995 - iou_score: 0.6909 - f1-score: 0.8148For batch 173, tr_loss is    0.30.\n",
      "175/225 [======================>.......] - ETA: 43s - loss: 0.2998 - iou_score: 0.6905 - f1-score: 0.8145For batch 174, tr_loss is    0.30.\n",
      "176/225 [======================>.......] - ETA: 42s - loss: 0.2999 - iou_score: 0.6904 - f1-score: 0.8145For batch 175, tr_loss is    0.30.\n",
      "177/225 [======================>.......] - ETA: 41s - loss: 0.2996 - iou_score: 0.6909 - f1-score: 0.8148For batch 176, tr_loss is    0.30.\n",
      "178/225 [======================>.......] - ETA: 40s - loss: 0.2995 - iou_score: 0.6911 - f1-score: 0.8150For batch 177, tr_loss is    0.30.\n",
      "179/225 [======================>.......] - ETA: 39s - loss: 0.2994 - iou_score: 0.6913 - f1-score: 0.8151For batch 178, tr_loss is    0.30.\n",
      "180/225 [=======================>......] - ETA: 39s - loss: 0.2996 - iou_score: 0.6910 - f1-score: 0.8149For batch 179, tr_loss is    0.30.\n",
      "181/225 [=======================>......] - ETA: 38s - loss: 0.2997 - iou_score: 0.6909 - f1-score: 0.8148For batch 180, tr_loss is    0.30.\n",
      "182/225 [=======================>......] - ETA: 37s - loss: 0.2996 - iou_score: 0.6911 - f1-score: 0.8150For batch 181, tr_loss is    0.30.\n",
      "183/225 [=======================>......] - ETA: 36s - loss: 0.2996 - iou_score: 0.6910 - f1-score: 0.8149For batch 182, tr_loss is    0.30.\n",
      "184/225 [=======================>......] - ETA: 35s - loss: 0.2996 - iou_score: 0.6910 - f1-score: 0.8150For batch 183, tr_loss is    0.30.\n",
      "185/225 [=======================>......] - ETA: 34s - loss: 0.2994 - iou_score: 0.6911 - f1-score: 0.8150For batch 184, tr_loss is    0.30.\n",
      "186/225 [=======================>......] - ETA: 33s - loss: 0.2996 - iou_score: 0.6911 - f1-score: 0.8150For batch 185, tr_loss is    0.30.\n",
      "187/225 [=======================>......] - ETA: 32s - loss: 0.2993 - iou_score: 0.6915 - f1-score: 0.8153For batch 186, tr_loss is    0.30.\n",
      "188/225 [========================>.....] - ETA: 32s - loss: 0.2991 - iou_score: 0.6917 - f1-score: 0.8154For batch 187, tr_loss is    0.30.\n",
      "189/225 [========================>.....] - ETA: 31s - loss: 0.2987 - iou_score: 0.6922 - f1-score: 0.8158For batch 188, tr_loss is    0.30.\n",
      "190/225 [========================>.....] - ETA: 30s - loss: 0.2985 - iou_score: 0.6923 - f1-score: 0.8158For batch 189, tr_loss is    0.30.\n",
      "191/225 [========================>.....] - ETA: 29s - loss: 0.2983 - iou_score: 0.6924 - f1-score: 0.8159For batch 190, tr_loss is    0.30.\n",
      "192/225 [========================>.....] - ETA: 28s - loss: 0.2980 - iou_score: 0.6927 - f1-score: 0.8161For batch 191, tr_loss is    0.30.\n",
      "193/225 [========================>.....] - ETA: 27s - loss: 0.2979 - iou_score: 0.6927 - f1-score: 0.8162For batch 192, tr_loss is    0.30.\n",
      "194/225 [========================>.....] - ETA: 26s - loss: 0.2979 - iou_score: 0.6928 - f1-score: 0.8162For batch 193, tr_loss is    0.30.\n",
      "195/225 [=========================>....] - ETA: 25s - loss: 0.2978 - iou_score: 0.6929 - f1-score: 0.8163For batch 194, tr_loss is    0.30.\n",
      "196/225 [=========================>....] - ETA: 25s - loss: 0.2978 - iou_score: 0.6930 - f1-score: 0.8164For batch 195, tr_loss is    0.30.\n",
      "197/225 [=========================>....] - ETA: 24s - loss: 0.2980 - iou_score: 0.6927 - f1-score: 0.8161For batch 196, tr_loss is    0.30.\n",
      "198/225 [=========================>....] - ETA: 23s - loss: 0.2978 - iou_score: 0.6930 - f1-score: 0.8164For batch 197, tr_loss is    0.30.\n",
      "199/225 [=========================>....] - ETA: 22s - loss: 0.2988 - iou_score: 0.6923 - f1-score: 0.8158For batch 198, tr_loss is    0.30.\n",
      "200/225 [=========================>....] - ETA: 21s - loss: 0.2987 - iou_score: 0.6926 - f1-score: 0.8160For batch 199, tr_loss is    0.30.\n",
      "201/225 [=========================>....] - ETA: 20s - loss: 0.2988 - iou_score: 0.6924 - f1-score: 0.8159For batch 200, tr_loss is    0.30.\n",
      "202/225 [=========================>....] - ETA: 19s - loss: 0.2985 - iou_score: 0.6927 - f1-score: 0.8161For batch 201, tr_loss is    0.30.\n",
      "203/225 [==========================>...] - ETA: 18s - loss: 0.2983 - iou_score: 0.6929 - f1-score: 0.8163For batch 202, tr_loss is    0.30.\n",
      "204/225 [==========================>...] - ETA: 18s - loss: 0.2981 - iou_score: 0.6933 - f1-score: 0.8165For batch 203, tr_loss is    0.30.\n",
      "205/225 [==========================>...] - ETA: 17s - loss: 0.2979 - iou_score: 0.6935 - f1-score: 0.8167For batch 204, tr_loss is    0.30.\n",
      "206/225 [==========================>...] - ETA: 16s - loss: 0.2978 - iou_score: 0.6936 - f1-score: 0.8168For batch 205, tr_loss is    0.30.\n",
      "207/225 [==========================>...] - ETA: 15s - loss: 0.2978 - iou_score: 0.6935 - f1-score: 0.8167For batch 206, tr_loss is    0.30.\n",
      "208/225 [==========================>...] - ETA: 14s - loss: 0.2979 - iou_score: 0.6933 - f1-score: 0.8166For batch 207, tr_loss is    0.30.\n",
      "209/225 [==========================>...] - ETA: 13s - loss: 0.2977 - iou_score: 0.6937 - f1-score: 0.8168For batch 208, tr_loss is    0.30.\n",
      "210/225 [===========================>..] - ETA: 13s - loss: 0.2978 - iou_score: 0.6934 - f1-score: 0.8166For batch 209, tr_loss is    0.30.\n",
      "211/225 [===========================>..] - ETA: 12s - loss: 0.2978 - iou_score: 0.6935 - f1-score: 0.8167For batch 210, tr_loss is    0.30.\n",
      "212/225 [===========================>..] - ETA: 11s - loss: 0.2979 - iou_score: 0.6933 - f1-score: 0.8165For batch 211, tr_loss is    0.30.\n",
      "213/225 [===========================>..] - ETA: 10s - loss: 0.2981 - iou_score: 0.6930 - f1-score: 0.8163For batch 212, tr_loss is    0.30.\n",
      "214/225 [===========================>..] - ETA: 9s - loss: 0.2983 - iou_score: 0.6929 - f1-score: 0.8163 For batch 213, tr_loss is    0.30.\n",
      "215/225 [===========================>..] - ETA: 8s - loss: 0.2980 - iou_score: 0.6932 - f1-score: 0.8165For batch 214, tr_loss is    0.30.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216/225 [===========================>..] - ETA: 7s - loss: 0.2978 - iou_score: 0.6934 - f1-score: 0.8166For batch 215, tr_loss is    0.30.\n",
      "217/225 [===========================>..] - ETA: 6s - loss: 0.2974 - iou_score: 0.6939 - f1-score: 0.8170For batch 216, tr_loss is    0.30.\n",
      "218/225 [============================>.] - ETA: 6s - loss: 0.2971 - iou_score: 0.6943 - f1-score: 0.8172For batch 217, tr_loss is    0.30.\n",
      "219/225 [============================>.] - ETA: 5s - loss: 0.2970 - iou_score: 0.6944 - f1-score: 0.8173For batch 218, tr_loss is    0.30.\n",
      "220/225 [============================>.] - ETA: 4s - loss: 0.2968 - iou_score: 0.6945 - f1-score: 0.8174For batch 219, tr_loss is    0.30.\n",
      "221/225 [============================>.] - ETA: 3s - loss: 0.2970 - iou_score: 0.6942 - f1-score: 0.8172For batch 220, tr_loss is    0.30.\n",
      "222/225 [============================>.] - ETA: 2s - loss: 0.2970 - iou_score: 0.6942 - f1-score: 0.8172For batch 221, tr_loss is    0.30.\n",
      "223/225 [============================>.] - ETA: 1s - loss: 0.2971 - iou_score: 0.6941 - f1-score: 0.8171For batch 222, tr_loss is    0.30.\n",
      "224/225 [============================>.] - ETA: 0s - loss: 0.2974 - iou_score: 0.6937 - f1-score: 0.8168For batch 223, tr_loss is    0.30.\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.2971 - iou_score: 0.6940 - f1-score: 0.8170For batch 224, tr_loss is    0.30.\n",
      "For batch 0, vl_loss is    0.40.\n",
      "For batch 1, vl_loss is    0.37.\n",
      "For batch 2, vl_loss is    0.42.\n",
      "For batch 3, vl_loss is    0.43.\n",
      "For batch 4, vl_loss is    0.40.\n",
      "For batch 5, vl_loss is    0.40.\n",
      "For batch 6, vl_loss is    0.40.\n",
      "For batch 7, vl_loss is    0.40.\n",
      "For batch 8, vl_loss is    0.40.\n",
      "For batch 9, vl_loss is    0.39.\n",
      "For batch 10, vl_loss is    0.39.\n",
      "For batch 11, vl_loss is    0.39.\n",
      "For batch 12, vl_loss is    0.38.\n",
      "For batch 13, vl_loss is    0.38.\n",
      "For batch 14, vl_loss is    0.38.\n",
      "For batch 15, vl_loss is    0.39.\n",
      "For batch 16, vl_loss is    0.39.\n",
      "For batch 17, vl_loss is    0.39.\n",
      "For batch 18, vl_loss is    0.39.\n",
      "For batch 19, vl_loss is    0.39.\n",
      "For batch 20, vl_loss is    0.39.\n",
      "For batch 21, vl_loss is    0.40.\n",
      "For batch 22, vl_loss is    0.40.\n",
      "For batch 23, vl_loss is    0.39.\n",
      "For batch 24, vl_loss is    0.39.\n",
      "For batch 25, vl_loss is    0.39.\n",
      "For batch 26, vl_loss is    0.40.\n",
      "For batch 27, vl_loss is    0.40.\n",
      "For batch 28, vl_loss is    0.40.\n",
      "For batch 29, vl_loss is    0.39.\n",
      "For batch 30, vl_loss is    0.40.\n",
      "For batch 31, vl_loss is    0.39.\n",
      "For batch 32, vl_loss is    0.40.\n",
      "For batch 33, vl_loss is    0.40.\n",
      "For batch 34, vl_loss is    0.40.\n",
      "For batch 35, vl_loss is    0.40.\n",
      "For batch 36, vl_loss is    0.40.\n",
      "For batch 37, vl_loss is    0.40.\n",
      "For batch 38, vl_loss is    0.40.\n",
      "For batch 39, vl_loss is    0.40.\n",
      "For batch 40, vl_loss is    0.39.\n",
      "For batch 41, vl_loss is    0.39.\n",
      "For batch 42, vl_loss is    0.39.\n",
      "For batch 43, vl_loss is    0.39.\n",
      "For batch 44, vl_loss is    0.39.\n",
      "For batch 45, vl_loss is    0.39.\n",
      "For batch 46, vl_loss is    0.39.\n",
      "For batch 47, vl_loss is    0.39.\n",
      "For batch 48, vl_loss is    0.39.\n",
      "For batch 49, vl_loss is    0.39.\n",
      "For batch 50, vl_loss is    0.39.\n",
      "For batch 51, vl_loss is    0.39.\n",
      "For batch 52, vl_loss is    0.39.\n",
      "For batch 53, vl_loss is    0.39.\n",
      "For batch 54, vl_loss is    0.39.\n",
      "For batch 55, vl_loss is    0.39.\n",
      "For batch 56, vl_loss is    0.39.\n",
      "For batch 57, vl_loss is    0.39.\n",
      "For batch 58, vl_loss is    0.39.\n",
      "For batch 59, vl_loss is    0.39.\n",
      "For batch 60, vl_loss is    0.39.\n",
      "For batch 61, vl_loss is    0.39.\n",
      "For batch 62, vl_loss is    0.39.\n",
      "For batch 63, vl_loss is    0.39.\n",
      "For batch 64, vl_loss is    0.39.\n",
      "For batch 65, vl_loss is    0.39.\n",
      "For batch 66, vl_loss is    0.39.\n",
      "For batch 67, vl_loss is    0.39.\n",
      "For batch 68, vl_loss is    0.39.\n",
      "For batch 69, vl_loss is    0.39.\n",
      "For batch 70, vl_loss is    0.39.\n",
      "For batch 71, vl_loss is    0.39.\n",
      "For batch 72, vl_loss is    0.39.\n",
      "For batch 73, vl_loss is    0.39.\n",
      "For batch 74, vl_loss is    0.39.\n",
      "225/225 [==============================] - 200s 880ms/step - loss: 0.2971 - iou_score: 0.6940 - f1-score: 0.8170 - val_loss: 0.3877 - val_iou_score: 0.6241 - val_f1-score: 0.7660\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.40609 to 0.38772, saving model to ./model/tumor_100_unet_efficientnetb0_imagenet_09293.hdf5\n",
      "The average loss for epoch 3 is    0.30 \n",
      "Epoch 5/200\n",
      "  1/225 [..............................] - ETA: 9:59 - loss: 0.3240 - iou_score: 0.6741 - f1-score: 0.8053For batch 0, tr_loss is    0.32.\n",
      "  2/225 [..............................] - ETA: 5:26 - loss: 0.2974 - iou_score: 0.6863 - f1-score: 0.8138For batch 1, tr_loss is    0.30.\n",
      "  3/225 [..............................] - ETA: 4:49 - loss: 0.2943 - iou_score: 0.6864 - f1-score: 0.8139For batch 2, tr_loss is    0.29.\n",
      "  4/225 [..............................] - ETA: 4:44 - loss: 0.2857 - iou_score: 0.7052 - f1-score: 0.8259For batch 3, tr_loss is    0.29.\n",
      "  5/225 [..............................] - ETA: 4:37 - loss: 0.2832 - iou_score: 0.7072 - f1-score: 0.8272For batch 4, tr_loss is    0.28.\n",
      "  6/225 [..............................] - ETA: 5:06 - loss: 0.2928 - iou_score: 0.7031 - f1-score: 0.8245For batch 5, tr_loss is    0.29.\n",
      "  7/225 [..............................] - ETA: 5:16 - loss: 0.2920 - iou_score: 0.6990 - f1-score: 0.8213For batch 6, tr_loss is    0.29.\n",
      "  8/225 [>.............................] - ETA: 5:00 - loss: 0.2924 - iou_score: 0.6946 - f1-score: 0.8182For batch 7, tr_loss is    0.29.\n",
      "  9/225 [>.............................] - ETA: 4:35 - loss: 0.2839 - iou_score: 0.7030 - f1-score: 0.8236For batch 8, tr_loss is    0.28.\n",
      " 10/225 [>.............................] - ETA: 4:25 - loss: 0.2879 - iou_score: 0.6997 - f1-score: 0.8213For batch 9, tr_loss is    0.29.\n",
      " 11/225 [>.............................] - ETA: 4:19 - loss: 0.2862 - iou_score: 0.7002 - f1-score: 0.8215For batch 10, tr_loss is    0.29.\n",
      " 12/225 [>.............................] - ETA: 4:14 - loss: 0.2917 - iou_score: 0.6937 - f1-score: 0.8166For batch 11, tr_loss is    0.29.\n",
      " 13/225 [>.............................] - ETA: 4:10 - loss: 0.2926 - iou_score: 0.6900 - f1-score: 0.8141For batch 12, tr_loss is    0.29.\n",
      " 14/225 [>.............................] - ETA: 4:07 - loss: 0.2922 - iou_score: 0.6913 - f1-score: 0.8151For batch 13, tr_loss is    0.29.\n",
      " 15/225 [=>............................] - ETA: 4:03 - loss: 0.2929 - iou_score: 0.6902 - f1-score: 0.8145For batch 14, tr_loss is    0.29.\n",
      " 16/225 [=>............................] - ETA: 4:00 - loss: 0.2944 - iou_score: 0.6888 - f1-score: 0.8133For batch 15, tr_loss is    0.29.\n",
      " 17/225 [=>............................] - ETA: 3:57 - loss: 0.2927 - iou_score: 0.6918 - f1-score: 0.8155For batch 16, tr_loss is    0.29.\n",
      " 18/225 [=>............................] - ETA: 3:52 - loss: 0.2934 - iou_score: 0.6904 - f1-score: 0.8146For batch 17, tr_loss is    0.29.\n",
      " 19/225 [=>............................] - ETA: 3:50 - loss: 0.2925 - iou_score: 0.6925 - f1-score: 0.8161For batch 18, tr_loss is    0.29.\n",
      " 20/225 [=>............................] - ETA: 3:48 - loss: 0.2909 - iou_score: 0.6936 - f1-score: 0.8169For batch 19, tr_loss is    0.29.\n",
      " 21/225 [=>............................] - ETA: 3:46 - loss: 0.2926 - iou_score: 0.6937 - f1-score: 0.8170For batch 20, tr_loss is    0.29.\n",
      " 22/225 [=>............................] - ETA: 3:44 - loss: 0.2911 - iou_score: 0.6954 - f1-score: 0.8183For batch 21, tr_loss is    0.29.\n",
      " 23/225 [==>...........................] - ETA: 3:42 - loss: 0.2995 - iou_score: 0.6873 - f1-score: 0.8120For batch 22, tr_loss is    0.30.\n",
      " 24/225 [==>...........................] - ETA: 3:36 - loss: 0.2999 - iou_score: 0.6865 - f1-score: 0.8115For batch 23, tr_loss is    0.30.\n",
      " 25/225 [==>...........................] - ETA: 3:34 - loss: 0.3010 - iou_score: 0.6851 - f1-score: 0.8106For batch 24, tr_loss is    0.30.\n",
      " 26/225 [==>...........................] - ETA: 3:33 - loss: 0.2992 - iou_score: 0.6883 - f1-score: 0.8128For batch 25, tr_loss is    0.30.\n",
      " 27/225 [==>...........................] - ETA: 3:27 - loss: 0.2990 - iou_score: 0.6877 - f1-score: 0.8125For batch 26, tr_loss is    0.30.\n",
      " 28/225 [==>...........................] - ETA: 3:27 - loss: 0.2980 - iou_score: 0.6884 - f1-score: 0.8130For batch 27, tr_loss is    0.30.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 29/225 [==>...........................] - ETA: 3:25 - loss: 0.2971 - iou_score: 0.6897 - f1-score: 0.8139For batch 28, tr_loss is    0.30.\n",
      " 30/225 [===>..........................] - ETA: 3:22 - loss: 0.2964 - iou_score: 0.6909 - f1-score: 0.8147For batch 29, tr_loss is    0.30.\n",
      " 31/225 [===>..........................] - ETA: 3:21 - loss: 0.2955 - iou_score: 0.6920 - f1-score: 0.8156For batch 30, tr_loss is    0.30.\n",
      " 32/225 [===>..........................] - ETA: 3:20 - loss: 0.2952 - iou_score: 0.6918 - f1-score: 0.8155For batch 31, tr_loss is    0.30.\n",
      " 33/225 [===>..........................] - ETA: 3:15 - loss: 0.2938 - iou_score: 0.6939 - f1-score: 0.8170For batch 32, tr_loss is    0.29.\n",
      " 34/225 [===>..........................] - ETA: 3:14 - loss: 0.2957 - iou_score: 0.6930 - f1-score: 0.8163For batch 33, tr_loss is    0.30.\n",
      " 35/225 [===>..........................] - ETA: 3:10 - loss: 0.2967 - iou_score: 0.6914 - f1-score: 0.8152For batch 34, tr_loss is    0.30.\n",
      " 36/225 [===>..........................] - ETA: 3:10 - loss: 0.2952 - iou_score: 0.6930 - f1-score: 0.8164For batch 35, tr_loss is    0.30.\n",
      " 37/225 [===>..........................] - ETA: 3:07 - loss: 0.2948 - iou_score: 0.6931 - f1-score: 0.8165For batch 36, tr_loss is    0.29.\n",
      " 38/225 [====>.........................] - ETA: 3:07 - loss: 0.2925 - iou_score: 0.6951 - f1-score: 0.8179For batch 37, tr_loss is    0.29.\n",
      " 39/225 [====>.........................] - ETA: 3:06 - loss: 0.2932 - iou_score: 0.6939 - f1-score: 0.8171For batch 38, tr_loss is    0.29.\n",
      " 40/225 [====>.........................] - ETA: 3:05 - loss: 0.2910 - iou_score: 0.6965 - f1-score: 0.8188For batch 39, tr_loss is    0.29.\n",
      " 41/225 [====>.........................] - ETA: 3:02 - loss: 0.2899 - iou_score: 0.6970 - f1-score: 0.8192For batch 40, tr_loss is    0.29.\n",
      " 42/225 [====>.........................] - ETA: 2:59 - loss: 0.2905 - iou_score: 0.6961 - f1-score: 0.8187For batch 41, tr_loss is    0.29.\n",
      " 43/225 [====>.........................] - ETA: 2:58 - loss: 0.2897 - iou_score: 0.6967 - f1-score: 0.8191For batch 42, tr_loss is    0.29.\n",
      " 44/225 [====>.........................] - ETA: 2:57 - loss: 0.2894 - iou_score: 0.6970 - f1-score: 0.8194For batch 43, tr_loss is    0.29.\n",
      " 45/225 [=====>........................] - ETA: 2:57 - loss: 0.2896 - iou_score: 0.6971 - f1-score: 0.8194For batch 44, tr_loss is    0.29.\n",
      " 46/225 [=====>........................] - ETA: 2:56 - loss: 0.2900 - iou_score: 0.6967 - f1-score: 0.8192For batch 45, tr_loss is    0.29.\n",
      " 47/225 [=====>........................] - ETA: 2:55 - loss: 0.2886 - iou_score: 0.6982 - f1-score: 0.8203For batch 46, tr_loss is    0.29.\n",
      " 48/225 [=====>........................] - ETA: 2:52 - loss: 0.2887 - iou_score: 0.6984 - f1-score: 0.8204For batch 47, tr_loss is    0.29.\n",
      " 49/225 [=====>........................] - ETA: 2:52 - loss: 0.2907 - iou_score: 0.6964 - f1-score: 0.8190For batch 48, tr_loss is    0.29.\n",
      " 50/225 [=====>........................] - ETA: 2:51 - loss: 0.2930 - iou_score: 0.6941 - f1-score: 0.8173For batch 49, tr_loss is    0.29.\n",
      " 51/225 [=====>........................] - ETA: 2:50 - loss: 0.2932 - iou_score: 0.6939 - f1-score: 0.8172For batch 50, tr_loss is    0.29.\n",
      " 52/225 [=====>........................] - ETA: 2:50 - loss: 0.2931 - iou_score: 0.6940 - f1-score: 0.8173For batch 51, tr_loss is    0.29.\n",
      " 53/225 [======>.......................] - ETA: 2:49 - loss: 0.2940 - iou_score: 0.6929 - f1-score: 0.8165For batch 52, tr_loss is    0.29.\n",
      " 54/225 [======>.......................] - ETA: 2:48 - loss: 0.2934 - iou_score: 0.6930 - f1-score: 0.8165For batch 53, tr_loss is    0.29.\n",
      " 55/225 [======>.......................] - ETA: 2:47 - loss: 0.2928 - iou_score: 0.6937 - f1-score: 0.8170For batch 54, tr_loss is    0.29.\n",
      " 56/225 [======>.......................] - ETA: 2:46 - loss: 0.2925 - iou_score: 0.6937 - f1-score: 0.8171For batch 55, tr_loss is    0.29.\n",
      " 57/225 [======>.......................] - ETA: 2:44 - loss: 0.2935 - iou_score: 0.6932 - f1-score: 0.8168For batch 56, tr_loss is    0.29.\n",
      " 58/225 [======>.......................] - ETA: 2:43 - loss: 0.2930 - iou_score: 0.6934 - f1-score: 0.8169For batch 57, tr_loss is    0.29.\n",
      " 59/225 [======>.......................] - ETA: 2:42 - loss: 0.2927 - iou_score: 0.6942 - f1-score: 0.8174For batch 58, tr_loss is    0.29.\n",
      " 60/225 [=======>......................] - ETA: 2:41 - loss: 0.2930 - iou_score: 0.6940 - f1-score: 0.8173For batch 59, tr_loss is    0.29.\n",
      " 61/225 [=======>......................] - ETA: 2:40 - loss: 0.2929 - iou_score: 0.6942 - f1-score: 0.8175For batch 60, tr_loss is    0.29.\n",
      " 62/225 [=======>......................] - ETA: 2:39 - loss: 0.2933 - iou_score: 0.6947 - f1-score: 0.8178For batch 61, tr_loss is    0.29.\n",
      " 63/225 [=======>......................] - ETA: 2:38 - loss: 0.2935 - iou_score: 0.6944 - f1-score: 0.8176For batch 62, tr_loss is    0.29.\n",
      " 64/225 [=======>......................] - ETA: 2:37 - loss: 0.2945 - iou_score: 0.6931 - f1-score: 0.8167For batch 63, tr_loss is    0.29.\n",
      " 65/225 [=======>......................] - ETA: 2:36 - loss: 0.2932 - iou_score: 0.6948 - f1-score: 0.8178For batch 64, tr_loss is    0.29.\n",
      " 66/225 [=======>......................] - ETA: 2:34 - loss: 0.2933 - iou_score: 0.6949 - f1-score: 0.8179For batch 65, tr_loss is    0.29.\n",
      " 67/225 [=======>......................] - ETA: 2:33 - loss: 0.2936 - iou_score: 0.6943 - f1-score: 0.8174For batch 66, tr_loss is    0.29.\n",
      " 68/225 [========>.....................] - ETA: 2:32 - loss: 0.2931 - iou_score: 0.6948 - f1-score: 0.8178For batch 67, tr_loss is    0.29.\n",
      " 69/225 [========>.....................] - ETA: 2:31 - loss: 0.2933 - iou_score: 0.6943 - f1-score: 0.8175For batch 68, tr_loss is    0.29.\n",
      " 70/225 [========>.....................] - ETA: 2:29 - loss: 0.2933 - iou_score: 0.6940 - f1-score: 0.8173For batch 69, tr_loss is    0.29.\n",
      " 71/225 [========>.....................] - ETA: 2:28 - loss: 0.2926 - iou_score: 0.6944 - f1-score: 0.8176For batch 70, tr_loss is    0.29.\n",
      " 72/225 [========>.....................] - ETA: 2:27 - loss: 0.2930 - iou_score: 0.6940 - f1-score: 0.8172For batch 71, tr_loss is    0.29.\n",
      " 73/225 [========>.....................] - ETA: 2:26 - loss: 0.2931 - iou_score: 0.6940 - f1-score: 0.8172For batch 72, tr_loss is    0.29.\n",
      " 74/225 [========>.....................] - ETA: 2:25 - loss: 0.2943 - iou_score: 0.6929 - f1-score: 0.8164For batch 73, tr_loss is    0.29.\n",
      " 75/225 [=========>....................] - ETA: 2:24 - loss: 0.2952 - iou_score: 0.6920 - f1-score: 0.8158For batch 74, tr_loss is    0.30.\n",
      " 76/225 [=========>....................] - ETA: 2:23 - loss: 0.2955 - iou_score: 0.6917 - f1-score: 0.8156For batch 75, tr_loss is    0.30.\n",
      " 77/225 [=========>....................] - ETA: 2:22 - loss: 0.2950 - iou_score: 0.6918 - f1-score: 0.8157For batch 76, tr_loss is    0.29.\n",
      " 78/225 [=========>....................] - ETA: 2:21 - loss: 0.2965 - iou_score: 0.6902 - f1-score: 0.8144For batch 77, tr_loss is    0.30.\n",
      " 79/225 [=========>....................] - ETA: 2:19 - loss: 0.2965 - iou_score: 0.6903 - f1-score: 0.8145For batch 78, tr_loss is    0.30.\n",
      " 80/225 [=========>....................] - ETA: 2:18 - loss: 0.2957 - iou_score: 0.6912 - f1-score: 0.8151For batch 79, tr_loss is    0.30.\n",
      " 81/225 [=========>....................] - ETA: 2:16 - loss: 0.2951 - iou_score: 0.6919 - f1-score: 0.8157For batch 80, tr_loss is    0.30.\n",
      " 82/225 [=========>....................] - ETA: 2:15 - loss: 0.2945 - iou_score: 0.6927 - f1-score: 0.8162For batch 81, tr_loss is    0.29.\n",
      " 83/225 [==========>...................] - ETA: 2:14 - loss: 0.2947 - iou_score: 0.6925 - f1-score: 0.8161For batch 82, tr_loss is    0.29.\n",
      " 84/225 [==========>...................] - ETA: 2:13 - loss: 0.2943 - iou_score: 0.6929 - f1-score: 0.8164For batch 83, tr_loss is    0.29.\n",
      " 85/225 [==========>...................] - ETA: 2:12 - loss: 0.2943 - iou_score: 0.6931 - f1-score: 0.8165For batch 84, tr_loss is    0.29.\n",
      " 86/225 [==========>...................] - ETA: 2:10 - loss: 0.2939 - iou_score: 0.6936 - f1-score: 0.8168For batch 85, tr_loss is    0.29.\n",
      " 87/225 [==========>...................] - ETA: 2:09 - loss: 0.2935 - iou_score: 0.6941 - f1-score: 0.8173For batch 86, tr_loss is    0.29.\n",
      " 88/225 [==========>...................] - ETA: 2:08 - loss: 0.2930 - iou_score: 0.6946 - f1-score: 0.8176For batch 87, tr_loss is    0.29.\n",
      " 89/225 [==========>...................] - ETA: 2:06 - loss: 0.2934 - iou_score: 0.6946 - f1-score: 0.8176For batch 88, tr_loss is    0.29.\n",
      " 90/225 [===========>..................] - ETA: 2:05 - loss: 0.2929 - iou_score: 0.6953 - f1-score: 0.8181For batch 89, tr_loss is    0.29.\n",
      " 91/225 [===========>..................] - ETA: 2:04 - loss: 0.2935 - iou_score: 0.6945 - f1-score: 0.8175For batch 90, tr_loss is    0.29.\n",
      " 92/225 [===========>..................] - ETA: 2:03 - loss: 0.2934 - iou_score: 0.6945 - f1-score: 0.8175For batch 91, tr_loss is    0.29.\n",
      " 93/225 [===========>..................] - ETA: 2:02 - loss: 0.2922 - iou_score: 0.6962 - f1-score: 0.8186For batch 92, tr_loss is    0.29.\n",
      " 94/225 [===========>..................] - ETA: 2:01 - loss: 0.2925 - iou_score: 0.6959 - f1-score: 0.8184For batch 93, tr_loss is    0.29.\n",
      " 95/225 [===========>..................] - ETA: 2:00 - loss: 0.2923 - iou_score: 0.6965 - f1-score: 0.8188For batch 94, tr_loss is    0.29.\n",
      " 96/225 [===========>..................] - ETA: 1:58 - loss: 0.2928 - iou_score: 0.6956 - f1-score: 0.8182For batch 95, tr_loss is    0.29.\n",
      " 97/225 [===========>..................] - ETA: 1:58 - loss: 0.2925 - iou_score: 0.6958 - f1-score: 0.8183For batch 96, tr_loss is    0.29.\n",
      " 98/225 [============>.................] - ETA: 1:57 - loss: 0.2925 - iou_score: 0.6954 - f1-score: 0.8180For batch 97, tr_loss is    0.29.\n",
      " 99/225 [============>.................] - ETA: 1:55 - loss: 0.2922 - iou_score: 0.6957 - f1-score: 0.8183For batch 98, tr_loss is    0.29.\n",
      "100/225 [============>.................] - ETA: 1:54 - loss: 0.2924 - iou_score: 0.6953 - f1-score: 0.8180For batch 99, tr_loss is    0.29.\n",
      "101/225 [============>.................] - ETA: 1:53 - loss: 0.2929 - iou_score: 0.6951 - f1-score: 0.8178For batch 100, tr_loss is    0.29.\n",
      "102/225 [============>.................] - ETA: 1:53 - loss: 0.2928 - iou_score: 0.6954 - f1-score: 0.8180For batch 101, tr_loss is    0.29.\n",
      "103/225 [============>.................] - ETA: 1:52 - loss: 0.2933 - iou_score: 0.6952 - f1-score: 0.8178For batch 102, tr_loss is    0.29.\n",
      "104/225 [============>.................] - ETA: 1:50 - loss: 0.2930 - iou_score: 0.6954 - f1-score: 0.8180For batch 103, tr_loss is    0.29.\n",
      "105/225 [=============>................] - ETA: 1:49 - loss: 0.2926 - iou_score: 0.6960 - f1-score: 0.8184For batch 104, tr_loss is    0.29.\n",
      "106/225 [=============>................] - ETA: 1:49 - loss: 0.2920 - iou_score: 0.6964 - f1-score: 0.8187For batch 105, tr_loss is    0.29.\n",
      "107/225 [=============>................] - ETA: 1:48 - loss: 0.2915 - iou_score: 0.6968 - f1-score: 0.8190For batch 106, tr_loss is    0.29.\n",
      "108/225 [=============>................] - ETA: 1:47 - loss: 0.2915 - iou_score: 0.6966 - f1-score: 0.8189For batch 107, tr_loss is    0.29.\n",
      "109/225 [=============>................] - ETA: 1:46 - loss: 0.2910 - iou_score: 0.6971 - f1-score: 0.8192For batch 108, tr_loss is    0.29.\n",
      "110/225 [=============>................] - ETA: 1:46 - loss: 0.2907 - iou_score: 0.6974 - f1-score: 0.8195For batch 109, tr_loss is    0.29.\n",
      "111/225 [=============>................] - ETA: 1:45 - loss: 0.2911 - iou_score: 0.6971 - f1-score: 0.8192For batch 110, tr_loss is    0.29.\n",
      "112/225 [=============>................] - ETA: 1:43 - loss: 0.2907 - iou_score: 0.6974 - f1-score: 0.8194For batch 111, tr_loss is    0.29.\n",
      "113/225 [==============>...............] - ETA: 1:43 - loss: 0.2907 - iou_score: 0.6976 - f1-score: 0.8196For batch 112, tr_loss is    0.29.\n",
      "114/225 [==============>...............] - ETA: 1:42 - loss: 0.2902 - iou_score: 0.6985 - f1-score: 0.8202For batch 113, tr_loss is    0.29.\n",
      "115/225 [==============>...............] - ETA: 1:41 - loss: 0.2896 - iou_score: 0.6992 - f1-score: 0.8206For batch 114, tr_loss is    0.29.\n",
      "116/225 [==============>...............] - ETA: 1:40 - loss: 0.2892 - iou_score: 0.6996 - f1-score: 0.8209For batch 115, tr_loss is    0.29.\n",
      "117/225 [==============>...............] - ETA: 1:39 - loss: 0.2889 - iou_score: 0.6999 - f1-score: 0.8211For batch 116, tr_loss is    0.29.\n",
      "118/225 [==============>...............] - ETA: 1:38 - loss: 0.2889 - iou_score: 0.6998 - f1-score: 0.8211For batch 117, tr_loss is    0.29.\n",
      "119/225 [==============>...............] - ETA: 1:38 - loss: 0.2886 - iou_score: 0.7001 - f1-score: 0.8213For batch 118, tr_loss is    0.29.\n",
      "120/225 [===============>..............] - ETA: 1:37 - loss: 0.2888 - iou_score: 0.6998 - f1-score: 0.8211For batch 119, tr_loss is    0.29.\n",
      "121/225 [===============>..............] - ETA: 1:36 - loss: 0.2882 - iou_score: 0.7003 - f1-score: 0.8215For batch 120, tr_loss is    0.29.\n",
      "122/225 [===============>..............] - ETA: 1:35 - loss: 0.2880 - iou_score: 0.7006 - f1-score: 0.8216For batch 121, tr_loss is    0.29.\n",
      "123/225 [===============>..............] - ETA: 1:34 - loss: 0.2876 - iou_score: 0.7010 - f1-score: 0.8219For batch 122, tr_loss is    0.29.\n",
      "124/225 [===============>..............] - ETA: 1:33 - loss: 0.2877 - iou_score: 0.7008 - f1-score: 0.8218For batch 123, tr_loss is    0.29.\n",
      "125/225 [===============>..............] - ETA: 1:32 - loss: 0.2880 - iou_score: 0.7007 - f1-score: 0.8218For batch 124, tr_loss is    0.29.\n",
      "126/225 [===============>..............] - ETA: 1:31 - loss: 0.2880 - iou_score: 0.7006 - f1-score: 0.8217For batch 125, tr_loss is    0.29.\n",
      "127/225 [===============>..............] - ETA: 1:30 - loss: 0.2878 - iou_score: 0.7006 - f1-score: 0.8216For batch 126, tr_loss is    0.29.\n",
      "128/225 [================>.............] - ETA: 1:29 - loss: 0.2876 - iou_score: 0.7009 - f1-score: 0.8219For batch 127, tr_loss is    0.29.\n",
      "129/225 [================>.............] - ETA: 1:29 - loss: 0.2880 - iou_score: 0.7003 - f1-score: 0.8214For batch 128, tr_loss is    0.29.\n",
      "130/225 [================>.............] - ETA: 1:28 - loss: 0.2876 - iou_score: 0.7007 - f1-score: 0.8217For batch 129, tr_loss is    0.29.\n",
      "131/225 [================>.............] - ETA: 1:27 - loss: 0.2877 - iou_score: 0.7005 - f1-score: 0.8216For batch 130, tr_loss is    0.29.\n",
      "132/225 [================>.............] - ETA: 1:26 - loss: 0.2873 - iou_score: 0.7011 - f1-score: 0.8220For batch 131, tr_loss is    0.29.\n",
      "133/225 [================>.............] - ETA: 1:24 - loss: 0.2876 - iou_score: 0.7007 - f1-score: 0.8217For batch 132, tr_loss is    0.29.\n",
      "134/225 [================>.............] - ETA: 1:24 - loss: 0.2872 - iou_score: 0.7011 - f1-score: 0.8220For batch 133, tr_loss is    0.29.\n",
      "135/225 [=================>............] - ETA: 1:23 - loss: 0.2872 - iou_score: 0.7011 - f1-score: 0.8220For batch 134, tr_loss is    0.29.\n",
      "136/225 [=================>............] - ETA: 1:22 - loss: 0.2875 - iou_score: 0.7008 - f1-score: 0.8217For batch 135, tr_loss is    0.29.\n",
      "137/225 [=================>............] - ETA: 1:20 - loss: 0.2876 - iou_score: 0.7007 - f1-score: 0.8217For batch 136, tr_loss is    0.29.\n",
      "138/225 [=================>............] - ETA: 1:20 - loss: 0.2878 - iou_score: 0.7006 - f1-score: 0.8217For batch 137, tr_loss is    0.29.\n",
      "139/225 [=================>............] - ETA: 1:19 - loss: 0.2878 - iou_score: 0.7005 - f1-score: 0.8216For batch 138, tr_loss is    0.29.\n",
      "140/225 [=================>............] - ETA: 1:18 - loss: 0.2888 - iou_score: 0.6997 - f1-score: 0.8210For batch 139, tr_loss is    0.29.\n",
      "141/225 [=================>............] - ETA: 1:17 - loss: 0.2884 - iou_score: 0.7002 - f1-score: 0.8214For batch 140, tr_loss is    0.29.\n",
      "142/225 [=================>............] - ETA: 1:16 - loss: 0.2882 - iou_score: 0.7004 - f1-score: 0.8215For batch 141, tr_loss is    0.29.\n",
      "143/225 [==================>...........] - ETA: 1:15 - loss: 0.2883 - iou_score: 0.7003 - f1-score: 0.8214For batch 142, tr_loss is    0.29.\n",
      "144/225 [==================>...........] - ETA: 1:14 - loss: 0.2885 - iou_score: 0.7002 - f1-score: 0.8213For batch 143, tr_loss is    0.29.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/225 [==================>...........] - ETA: 1:13 - loss: 0.2886 - iou_score: 0.6999 - f1-score: 0.8211For batch 144, tr_loss is    0.29.\n",
      "146/225 [==================>...........] - ETA: 1:12 - loss: 0.2884 - iou_score: 0.7001 - f1-score: 0.8213For batch 145, tr_loss is    0.29.\n",
      "147/225 [==================>...........] - ETA: 1:11 - loss: 0.2881 - iou_score: 0.7007 - f1-score: 0.8217For batch 146, tr_loss is    0.29.\n",
      "148/225 [==================>...........] - ETA: 1:10 - loss: 0.2881 - iou_score: 0.7006 - f1-score: 0.8217For batch 147, tr_loss is    0.29.\n",
      "149/225 [==================>...........] - ETA: 1:09 - loss: 0.2880 - iou_score: 0.7009 - f1-score: 0.8219For batch 148, tr_loss is    0.29.\n",
      "150/225 [===================>..........] - ETA: 1:08 - loss: 0.2881 - iou_score: 0.7007 - f1-score: 0.8218For batch 149, tr_loss is    0.29.\n",
      "151/225 [===================>..........] - ETA: 1:07 - loss: 0.2882 - iou_score: 0.7006 - f1-score: 0.8217For batch 150, tr_loss is    0.29.\n",
      "152/225 [===================>..........] - ETA: 1:06 - loss: 0.2880 - iou_score: 0.7008 - f1-score: 0.8219For batch 151, tr_loss is    0.29.\n",
      "153/225 [===================>..........] - ETA: 1:05 - loss: 0.2880 - iou_score: 0.7006 - f1-score: 0.8217For batch 152, tr_loss is    0.29.\n",
      "154/225 [===================>..........] - ETA: 1:05 - loss: 0.2879 - iou_score: 0.7007 - f1-score: 0.8218For batch 153, tr_loss is    0.29.\n",
      "155/225 [===================>..........] - ETA: 1:04 - loss: 0.2890 - iou_score: 0.6995 - f1-score: 0.8209For batch 154, tr_loss is    0.29.\n",
      "156/225 [===================>..........] - ETA: 1:03 - loss: 0.2896 - iou_score: 0.6991 - f1-score: 0.8205For batch 155, tr_loss is    0.29.\n",
      "157/225 [===================>..........] - ETA: 1:02 - loss: 0.2896 - iou_score: 0.6989 - f1-score: 0.8205For batch 156, tr_loss is    0.29.\n",
      "158/225 [====================>.........] - ETA: 1:01 - loss: 0.2898 - iou_score: 0.6986 - f1-score: 0.8202For batch 157, tr_loss is    0.29.\n",
      "159/225 [====================>.........] - ETA: 1:00 - loss: 0.2899 - iou_score: 0.6986 - f1-score: 0.8202For batch 158, tr_loss is    0.29.\n",
      "160/225 [====================>.........] - ETA: 59s - loss: 0.2897 - iou_score: 0.6985 - f1-score: 0.8202 For batch 159, tr_loss is    0.29.\n",
      "161/225 [====================>.........] - ETA: 58s - loss: 0.2894 - iou_score: 0.6990 - f1-score: 0.8205For batch 160, tr_loss is    0.29.\n",
      "162/225 [====================>.........] - ETA: 57s - loss: 0.2894 - iou_score: 0.6989 - f1-score: 0.8205For batch 161, tr_loss is    0.29.\n",
      "163/225 [====================>.........] - ETA: 56s - loss: 0.2896 - iou_score: 0.6987 - f1-score: 0.8203For batch 162, tr_loss is    0.29.\n",
      "164/225 [====================>.........] - ETA: 55s - loss: 0.2896 - iou_score: 0.6987 - f1-score: 0.8204For batch 163, tr_loss is    0.29.\n",
      "165/225 [=====================>........] - ETA: 54s - loss: 0.2897 - iou_score: 0.6987 - f1-score: 0.8203For batch 164, tr_loss is    0.29.\n",
      "166/225 [=====================>........] - ETA: 53s - loss: 0.2902 - iou_score: 0.6981 - f1-score: 0.8199For batch 165, tr_loss is    0.29.\n",
      "167/225 [=====================>........] - ETA: 52s - loss: 0.2900 - iou_score: 0.6982 - f1-score: 0.8200For batch 166, tr_loss is    0.29.\n",
      "168/225 [=====================>........] - ETA: 51s - loss: 0.2894 - iou_score: 0.6991 - f1-score: 0.8205For batch 167, tr_loss is    0.29.\n",
      "169/225 [=====================>........] - ETA: 50s - loss: 0.2893 - iou_score: 0.6992 - f1-score: 0.8206For batch 168, tr_loss is    0.29.\n",
      "170/225 [=====================>........] - ETA: 49s - loss: 0.2897 - iou_score: 0.6988 - f1-score: 0.8204For batch 169, tr_loss is    0.29.\n",
      "171/225 [=====================>........] - ETA: 48s - loss: 0.2900 - iou_score: 0.6985 - f1-score: 0.8201For batch 170, tr_loss is    0.29.\n",
      "172/225 [=====================>........] - ETA: 47s - loss: 0.2904 - iou_score: 0.6980 - f1-score: 0.8198For batch 171, tr_loss is    0.29.\n",
      "173/225 [======================>.......] - ETA: 46s - loss: 0.2909 - iou_score: 0.6974 - f1-score: 0.8194For batch 172, tr_loss is    0.29.\n",
      "174/225 [======================>.......] - ETA: 46s - loss: 0.2909 - iou_score: 0.6974 - f1-score: 0.8194For batch 173, tr_loss is    0.29.\n",
      "175/225 [======================>.......] - ETA: 45s - loss: 0.2912 - iou_score: 0.6971 - f1-score: 0.8192For batch 174, tr_loss is    0.29.\n",
      "176/225 [======================>.......] - ETA: 44s - loss: 0.2911 - iou_score: 0.6970 - f1-score: 0.8191For batch 175, tr_loss is    0.29.\n",
      "177/225 [======================>.......] - ETA: 43s - loss: 0.2908 - iou_score: 0.6975 - f1-score: 0.8195For batch 176, tr_loss is    0.29.\n",
      "178/225 [======================>.......] - ETA: 42s - loss: 0.2908 - iou_score: 0.6974 - f1-score: 0.8194For batch 177, tr_loss is    0.29.\n",
      "179/225 [======================>.......] - ETA: 41s - loss: 0.2907 - iou_score: 0.6976 - f1-score: 0.8196For batch 178, tr_loss is    0.29.\n",
      "180/225 [=======================>......] - ETA: 40s - loss: 0.2909 - iou_score: 0.6974 - f1-score: 0.8194For batch 179, tr_loss is    0.29.\n",
      "181/225 [=======================>......] - ETA: 39s - loss: 0.2910 - iou_score: 0.6973 - f1-score: 0.8193For batch 180, tr_loss is    0.29.\n",
      "182/225 [=======================>......] - ETA: 38s - loss: 0.2909 - iou_score: 0.6974 - f1-score: 0.8194For batch 181, tr_loss is    0.29.\n",
      "183/225 [=======================>......] - ETA: 37s - loss: 0.2911 - iou_score: 0.6974 - f1-score: 0.8194For batch 182, tr_loss is    0.29.\n",
      "184/225 [=======================>......] - ETA: 37s - loss: 0.2910 - iou_score: 0.6974 - f1-score: 0.8194For batch 183, tr_loss is    0.29.\n",
      "185/225 [=======================>......] - ETA: 36s - loss: 0.2909 - iou_score: 0.6975 - f1-score: 0.8195For batch 184, tr_loss is    0.29.\n",
      "186/225 [=======================>......] - ETA: 35s - loss: 0.2908 - iou_score: 0.6975 - f1-score: 0.8195For batch 185, tr_loss is    0.29.\n",
      "187/225 [=======================>......] - ETA: 34s - loss: 0.2906 - iou_score: 0.6978 - f1-score: 0.8197For batch 186, tr_loss is    0.29.\n",
      "188/225 [========================>.....] - ETA: 33s - loss: 0.2903 - iou_score: 0.6982 - f1-score: 0.8200For batch 187, tr_loss is    0.29.\n",
      "189/225 [========================>.....] - ETA: 32s - loss: 0.2900 - iou_score: 0.6985 - f1-score: 0.8202For batch 188, tr_loss is    0.29.\n",
      "190/225 [========================>.....] - ETA: 31s - loss: 0.2898 - iou_score: 0.6986 - f1-score: 0.8203For batch 189, tr_loss is    0.29.\n",
      "191/225 [========================>.....] - ETA: 30s - loss: 0.2895 - iou_score: 0.6989 - f1-score: 0.8205For batch 190, tr_loss is    0.29.\n",
      "192/225 [========================>.....] - ETA: 29s - loss: 0.2893 - iou_score: 0.6992 - f1-score: 0.8207For batch 191, tr_loss is    0.29.\n",
      "193/225 [========================>.....] - ETA: 28s - loss: 0.2893 - iou_score: 0.6992 - f1-score: 0.8207For batch 192, tr_loss is    0.29.\n",
      "194/225 [========================>.....] - ETA: 27s - loss: 0.2892 - iou_score: 0.6992 - f1-score: 0.8207For batch 193, tr_loss is    0.29.\n",
      "195/225 [=========================>....] - ETA: 26s - loss: 0.2891 - iou_score: 0.6994 - f1-score: 0.8209For batch 194, tr_loss is    0.29.\n",
      "196/225 [=========================>....] - ETA: 26s - loss: 0.2888 - iou_score: 0.6997 - f1-score: 0.8211For batch 195, tr_loss is    0.29.\n",
      "197/225 [=========================>....] - ETA: 25s - loss: 0.2891 - iou_score: 0.6993 - f1-score: 0.8208For batch 196, tr_loss is    0.29.\n",
      "198/225 [=========================>....] - ETA: 24s - loss: 0.2887 - iou_score: 0.6997 - f1-score: 0.8211For batch 197, tr_loss is    0.29.\n",
      "199/225 [=========================>....] - ETA: 23s - loss: 0.2894 - iou_score: 0.6990 - f1-score: 0.8205For batch 198, tr_loss is    0.29.\n",
      "200/225 [=========================>....] - ETA: 22s - loss: 0.2892 - iou_score: 0.6993 - f1-score: 0.8207For batch 199, tr_loss is    0.29.\n",
      "201/225 [=========================>....] - ETA: 21s - loss: 0.2896 - iou_score: 0.6991 - f1-score: 0.8206For batch 200, tr_loss is    0.29.\n",
      "202/225 [=========================>....] - ETA: 20s - loss: 0.2893 - iou_score: 0.6995 - f1-score: 0.8209For batch 201, tr_loss is    0.29.\n",
      "203/225 [==========================>...] - ETA: 19s - loss: 0.2892 - iou_score: 0.6996 - f1-score: 0.8210For batch 202, tr_loss is    0.29.\n",
      "204/225 [==========================>...] - ETA: 18s - loss: 0.2890 - iou_score: 0.7000 - f1-score: 0.8212For batch 203, tr_loss is    0.29.\n",
      "205/225 [==========================>...] - ETA: 17s - loss: 0.2889 - iou_score: 0.7001 - f1-score: 0.8213For batch 204, tr_loss is    0.29.\n",
      "206/225 [==========================>...] - ETA: 16s - loss: 0.2888 - iou_score: 0.7001 - f1-score: 0.8213For batch 205, tr_loss is    0.29.\n",
      "207/225 [==========================>...] - ETA: 16s - loss: 0.2888 - iou_score: 0.6999 - f1-score: 0.8212For batch 206, tr_loss is    0.29.\n",
      "208/225 [==========================>...] - ETA: 15s - loss: 0.2889 - iou_score: 0.6998 - f1-score: 0.8211For batch 207, tr_loss is    0.29.\n",
      "209/225 [==========================>...] - ETA: 14s - loss: 0.2887 - iou_score: 0.7000 - f1-score: 0.8213For batch 208, tr_loss is    0.29.\n",
      "210/225 [===========================>..] - ETA: 13s - loss: 0.2891 - iou_score: 0.6997 - f1-score: 0.8211For batch 209, tr_loss is    0.29.\n",
      "211/225 [===========================>..] - ETA: 12s - loss: 0.2890 - iou_score: 0.6998 - f1-score: 0.8211For batch 210, tr_loss is    0.29.\n",
      "212/225 [===========================>..] - ETA: 11s - loss: 0.2892 - iou_score: 0.6995 - f1-score: 0.8209For batch 211, tr_loss is    0.29.\n",
      "213/225 [===========================>..] - ETA: 10s - loss: 0.2893 - iou_score: 0.6993 - f1-score: 0.8208For batch 212, tr_loss is    0.29.\n",
      "214/225 [===========================>..] - ETA: 9s - loss: 0.2894 - iou_score: 0.6993 - f1-score: 0.8208 For batch 213, tr_loss is    0.29.\n",
      "215/225 [===========================>..] - ETA: 8s - loss: 0.2892 - iou_score: 0.6996 - f1-score: 0.8210For batch 214, tr_loss is    0.29.\n",
      "216/225 [===========================>..] - ETA: 8s - loss: 0.2889 - iou_score: 0.6999 - f1-score: 0.8212For batch 215, tr_loss is    0.29.\n",
      "217/225 [===========================>..] - ETA: 7s - loss: 0.2887 - iou_score: 0.7002 - f1-score: 0.8214For batch 216, tr_loss is    0.29.\n",
      "218/225 [============================>.] - ETA: 6s - loss: 0.2885 - iou_score: 0.7004 - f1-score: 0.8216For batch 217, tr_loss is    0.29.\n",
      "219/225 [============================>.] - ETA: 5s - loss: 0.2884 - iou_score: 0.7005 - f1-score: 0.8216For batch 218, tr_loss is    0.29.\n",
      "220/225 [============================>.] - ETA: 4s - loss: 0.2883 - iou_score: 0.7005 - f1-score: 0.8216For batch 219, tr_loss is    0.29.\n",
      "221/225 [============================>.] - ETA: 3s - loss: 0.2884 - iou_score: 0.7004 - f1-score: 0.8216For batch 220, tr_loss is    0.29.\n",
      "222/225 [============================>.] - ETA: 2s - loss: 0.2885 - iou_score: 0.7003 - f1-score: 0.8215For batch 221, tr_loss is    0.29.\n",
      "223/225 [============================>.] - ETA: 1s - loss: 0.2886 - iou_score: 0.7002 - f1-score: 0.8214For batch 222, tr_loss is    0.29.\n",
      "224/225 [============================>.] - ETA: 0s - loss: 0.2888 - iou_score: 0.7000 - f1-score: 0.8213For batch 223, tr_loss is    0.29.\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.2887 - iou_score: 0.7001 - f1-score: 0.8214For batch 224, tr_loss is    0.29.\n",
      "For batch 0, vl_loss is    0.41.\n",
      "For batch 1, vl_loss is    0.39.\n",
      "For batch 2, vl_loss is    0.49.\n",
      "For batch 3, vl_loss is    0.49.\n",
      "For batch 4, vl_loss is    0.45.\n",
      "For batch 5, vl_loss is    0.45.\n",
      "For batch 6, vl_loss is    0.45.\n",
      "For batch 7, vl_loss is    0.46.\n",
      "For batch 8, vl_loss is    0.46.\n",
      "For batch 9, vl_loss is    0.45.\n",
      "For batch 10, vl_loss is    0.45.\n",
      "For batch 11, vl_loss is    0.45.\n",
      "For batch 12, vl_loss is    0.44.\n",
      "For batch 13, vl_loss is    0.44.\n",
      "For batch 14, vl_loss is    0.45.\n",
      "For batch 15, vl_loss is    0.46.\n",
      "For batch 16, vl_loss is    0.46.\n",
      "For batch 17, vl_loss is    0.46.\n",
      "For batch 18, vl_loss is    0.46.\n",
      "For batch 19, vl_loss is    0.46.\n",
      "For batch 20, vl_loss is    0.47.\n",
      "For batch 21, vl_loss is    0.47.\n",
      "For batch 22, vl_loss is    0.47.\n",
      "For batch 23, vl_loss is    0.47.\n",
      "For batch 24, vl_loss is    0.47.\n",
      "For batch 25, vl_loss is    0.47.\n",
      "For batch 26, vl_loss is    0.47.\n",
      "For batch 27, vl_loss is    0.47.\n",
      "For batch 28, vl_loss is    0.47.\n",
      "For batch 29, vl_loss is    0.47.\n",
      "For batch 30, vl_loss is    0.47.\n",
      "For batch 31, vl_loss is    0.46.\n",
      "For batch 32, vl_loss is    0.47.\n",
      "For batch 33, vl_loss is    0.47.\n",
      "For batch 34, vl_loss is    0.47.\n",
      "For batch 35, vl_loss is    0.46.\n",
      "For batch 36, vl_loss is    0.47.\n",
      "For batch 37, vl_loss is    0.47.\n",
      "For batch 38, vl_loss is    0.46.\n",
      "For batch 39, vl_loss is    0.46.\n",
      "For batch 40, vl_loss is    0.46.\n",
      "For batch 41, vl_loss is    0.46.\n",
      "For batch 42, vl_loss is    0.46.\n",
      "For batch 43, vl_loss is    0.46.\n",
      "For batch 44, vl_loss is    0.46.\n",
      "For batch 45, vl_loss is    0.46.\n",
      "For batch 46, vl_loss is    0.46.\n",
      "For batch 47, vl_loss is    0.45.\n",
      "For batch 48, vl_loss is    0.45.\n",
      "For batch 49, vl_loss is    0.45.\n",
      "For batch 50, vl_loss is    0.45.\n",
      "For batch 51, vl_loss is    0.45.\n",
      "For batch 52, vl_loss is    0.45.\n",
      "For batch 53, vl_loss is    0.45.\n",
      "For batch 54, vl_loss is    0.46.\n",
      "For batch 55, vl_loss is    0.45.\n",
      "For batch 56, vl_loss is    0.46.\n",
      "For batch 57, vl_loss is    0.46.\n",
      "For batch 58, vl_loss is    0.46.\n",
      "For batch 59, vl_loss is    0.45.\n",
      "For batch 60, vl_loss is    0.46.\n",
      "For batch 61, vl_loss is    0.46.\n",
      "For batch 62, vl_loss is    0.46.\n",
      "For batch 63, vl_loss is    0.46.\n",
      "For batch 64, vl_loss is    0.46.\n",
      "For batch 65, vl_loss is    0.46.\n",
      "For batch 66, vl_loss is    0.46.\n",
      "For batch 67, vl_loss is    0.46.\n",
      "For batch 68, vl_loss is    0.46.\n",
      "For batch 69, vl_loss is    0.46.\n",
      "For batch 70, vl_loss is    0.46.\n",
      "For batch 71, vl_loss is    0.46.\n",
      "For batch 72, vl_loss is    0.46.\n",
      "For batch 73, vl_loss is    0.46.\n",
      "For batch 74, vl_loss is    0.46.\n",
      "225/225 [==============================] - 205s 905ms/step - loss: 0.2887 - iou_score: 0.7001 - f1-score: 0.8214 - val_loss: 0.4580 - val_iou_score: 0.6378 - val_f1-score: 0.7764\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.38772\n",
      "The average loss for epoch 4 is    0.29 \n",
      "Epoch 6/200\n",
      "  1/225 [..............................] - ETA: 8:27 - loss: 0.3072 - iou_score: 0.6611 - f1-score: 0.7957For batch 0, tr_loss is    0.31.\n",
      "  2/225 [..............................] - ETA: 4:50 - loss: 0.2967 - iou_score: 0.6780 - f1-score: 0.8078For batch 1, tr_loss is    0.30.\n",
      "  3/225 [..............................] - ETA: 5:04 - loss: 0.2879 - iou_score: 0.6853 - f1-score: 0.8129For batch 2, tr_loss is    0.29.\n",
      "  4/225 [..............................] - ETA: 5:32 - loss: 0.2881 - iou_score: 0.6993 - f1-score: 0.8222For batch 3, tr_loss is    0.29.\n",
      "  5/225 [..............................] - ETA: 5:19 - loss: 0.2950 - iou_score: 0.6951 - f1-score: 0.8194For batch 4, tr_loss is    0.30.\n",
      "  6/225 [..............................] - ETA: 5:24 - loss: 0.3025 - iou_score: 0.6903 - f1-score: 0.8160For batch 5, tr_loss is    0.30.\n",
      "  7/225 [..............................] - ETA: 5:34 - loss: 0.3028 - iou_score: 0.6859 - f1-score: 0.8123For batch 6, tr_loss is    0.30.\n",
      "  8/225 [>.............................] - ETA: 5:04 - loss: 0.3040 - iou_score: 0.6804 - f1-score: 0.8084For batch 7, tr_loss is    0.30.\n",
      "  9/225 [>.............................] - ETA: 4:39 - loss: 0.2964 - iou_score: 0.6890 - f1-score: 0.8140For batch 8, tr_loss is    0.30.\n",
      " 10/225 [>.............................] - ETA: 4:23 - loss: 0.2989 - iou_score: 0.6870 - f1-score: 0.8126For batch 9, tr_loss is    0.30.\n",
      " 11/225 [>.............................] - ETA: 4:18 - loss: 0.2973 - iou_score: 0.6884 - f1-score: 0.8134For batch 10, tr_loss is    0.30.\n",
      " 12/225 [>.............................] - ETA: 4:12 - loss: 0.3034 - iou_score: 0.6815 - f1-score: 0.8082For batch 11, tr_loss is    0.30.\n",
      " 13/225 [>.............................] - ETA: 4:08 - loss: 0.3056 - iou_score: 0.6785 - f1-score: 0.8061For batch 12, tr_loss is    0.31.\n",
      " 14/225 [>.............................] - ETA: 4:04 - loss: 0.3030 - iou_score: 0.6820 - f1-score: 0.8087For batch 13, tr_loss is    0.30.\n",
      " 15/225 [=>............................] - ETA: 4:01 - loss: 0.3031 - iou_score: 0.6821 - f1-score: 0.8088For batch 14, tr_loss is    0.30.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16/225 [=>............................] - ETA: 3:51 - loss: 0.3041 - iou_score: 0.6817 - f1-score: 0.8084For batch 15, tr_loss is    0.30.\n",
      " 17/225 [=>............................] - ETA: 3:51 - loss: 0.3042 - iou_score: 0.6837 - f1-score: 0.8099For batch 16, tr_loss is    0.30.\n",
      " 18/225 [=>............................] - ETA: 3:49 - loss: 0.3050 - iou_score: 0.6831 - f1-score: 0.8095For batch 17, tr_loss is    0.30.\n",
      " 19/225 [=>............................] - ETA: 3:47 - loss: 0.3038 - iou_score: 0.6851 - f1-score: 0.8110For batch 18, tr_loss is    0.30.\n",
      " 20/225 [=>............................] - ETA: 3:45 - loss: 0.3010 - iou_score: 0.6868 - f1-score: 0.8121For batch 19, tr_loss is    0.30.\n",
      " 21/225 [=>............................] - ETA: 3:37 - loss: 0.2991 - iou_score: 0.6885 - f1-score: 0.8134For batch 20, tr_loss is    0.30.\n",
      " 22/225 [=>............................] - ETA: 3:36 - loss: 0.2971 - iou_score: 0.6904 - f1-score: 0.8148For batch 21, tr_loss is    0.30.\n",
      " 23/225 [==>...........................] - ETA: 3:35 - loss: 0.3058 - iou_score: 0.6827 - f1-score: 0.8089For batch 22, tr_loss is    0.31.\n",
      " 24/225 [==>...........................] - ETA: 3:33 - loss: 0.3059 - iou_score: 0.6812 - f1-score: 0.8079For batch 23, tr_loss is    0.31.\n",
      " 25/225 [==>...........................] - ETA: 3:28 - loss: 0.3072 - iou_score: 0.6790 - f1-score: 0.8064For batch 24, tr_loss is    0.31.\n",
      " 26/225 [==>...........................] - ETA: 3:25 - loss: 0.3045 - iou_score: 0.6822 - f1-score: 0.8086For batch 25, tr_loss is    0.30.\n",
      " 27/225 [==>...........................] - ETA: 3:24 - loss: 0.3054 - iou_score: 0.6804 - f1-score: 0.8074For batch 26, tr_loss is    0.31.\n",
      " 28/225 [==>...........................] - ETA: 3:19 - loss: 0.3046 - iou_score: 0.6809 - f1-score: 0.8078For batch 27, tr_loss is    0.30.\n",
      " 29/225 [==>...........................] - ETA: 3:16 - loss: 0.3033 - iou_score: 0.6825 - f1-score: 0.8088For batch 28, tr_loss is    0.30.\n",
      " 30/225 [===>..........................] - ETA: 3:13 - loss: 0.3026 - iou_score: 0.6840 - f1-score: 0.8099For batch 29, tr_loss is    0.30.\n",
      " 31/225 [===>..........................] - ETA: 3:10 - loss: 0.3015 - iou_score: 0.6850 - f1-score: 0.8107For batch 30, tr_loss is    0.30.\n",
      " 32/225 [===>..........................] - ETA: 3:10 - loss: 0.3007 - iou_score: 0.6853 - f1-score: 0.8110For batch 31, tr_loss is    0.30.\n",
      " 33/225 [===>..........................] - ETA: 3:09 - loss: 0.2995 - iou_score: 0.6874 - f1-score: 0.8125For batch 32, tr_loss is    0.30.\n",
      " 34/225 [===>..........................] - ETA: 3:08 - loss: 0.3004 - iou_score: 0.6874 - f1-score: 0.8124For batch 33, tr_loss is    0.30.\n",
      " 35/225 [===>..........................] - ETA: 3:05 - loss: 0.3012 - iou_score: 0.6858 - f1-score: 0.8113For batch 34, tr_loss is    0.30.\n",
      " 36/225 [===>..........................] - ETA: 3:05 - loss: 0.2998 - iou_score: 0.6878 - f1-score: 0.8127For batch 35, tr_loss is    0.30.\n",
      " 37/225 [===>..........................] - ETA: 3:04 - loss: 0.2988 - iou_score: 0.6888 - f1-score: 0.8134For batch 36, tr_loss is    0.30.\n",
      " 38/225 [====>.........................] - ETA: 3:03 - loss: 0.2959 - iou_score: 0.6917 - f1-score: 0.8154For batch 37, tr_loss is    0.30.\n",
      " 39/225 [====>.........................] - ETA: 3:02 - loss: 0.2966 - iou_score: 0.6908 - f1-score: 0.8148For batch 38, tr_loss is    0.30.\n",
      " 40/225 [====>.........................] - ETA: 3:00 - loss: 0.2943 - iou_score: 0.6936 - f1-score: 0.8167For batch 39, tr_loss is    0.29.\n",
      " 41/225 [====>.........................] - ETA: 2:59 - loss: 0.2936 - iou_score: 0.6939 - f1-score: 0.8169For batch 40, tr_loss is    0.29.\n",
      " 42/225 [====>.........................] - ETA: 2:59 - loss: 0.2933 - iou_score: 0.6938 - f1-score: 0.8169For batch 41, tr_loss is    0.29.\n",
      " 43/225 [====>.........................] - ETA: 2:58 - loss: 0.2914 - iou_score: 0.6954 - f1-score: 0.8181For batch 42, tr_loss is    0.29.\n",
      " 44/225 [====>.........................] - ETA: 2:56 - loss: 0.2904 - iou_score: 0.6961 - f1-score: 0.8186For batch 43, tr_loss is    0.29.\n",
      " 45/225 [=====>........................] - ETA: 2:55 - loss: 0.2899 - iou_score: 0.6963 - f1-score: 0.8187For batch 44, tr_loss is    0.29.\n",
      " 46/225 [=====>........................] - ETA: 2:53 - loss: 0.2906 - iou_score: 0.6961 - f1-score: 0.8186For batch 45, tr_loss is    0.29.\n",
      " 47/225 [=====>........................] - ETA: 2:51 - loss: 0.2898 - iou_score: 0.6968 - f1-score: 0.8192For batch 46, tr_loss is    0.29.\n",
      " 48/225 [=====>........................] - ETA: 2:50 - loss: 0.2898 - iou_score: 0.6975 - f1-score: 0.8197For batch 47, tr_loss is    0.29.\n",
      " 49/225 [=====>........................] - ETA: 2:48 - loss: 0.2903 - iou_score: 0.6965 - f1-score: 0.8190For batch 48, tr_loss is    0.29.\n",
      " 50/225 [=====>........................] - ETA: 2:47 - loss: 0.2914 - iou_score: 0.6949 - f1-score: 0.8178For batch 49, tr_loss is    0.29.\n",
      " 51/225 [=====>........................] - ETA: 2:46 - loss: 0.2915 - iou_score: 0.6945 - f1-score: 0.8176For batch 50, tr_loss is    0.29.\n",
      " 52/225 [=====>........................] - ETA: 2:46 - loss: 0.2907 - iou_score: 0.6954 - f1-score: 0.8183For batch 51, tr_loss is    0.29.\n",
      " 53/225 [======>.......................] - ETA: 2:45 - loss: 0.2912 - iou_score: 0.6949 - f1-score: 0.8178For batch 52, tr_loss is    0.29.\n",
      " 54/225 [======>.......................] - ETA: 2:44 - loss: 0.2906 - iou_score: 0.6950 - f1-score: 0.8180For batch 53, tr_loss is    0.29.\n",
      " 55/225 [======>.......................] - ETA: 2:43 - loss: 0.2899 - iou_score: 0.6957 - f1-score: 0.8184For batch 54, tr_loss is    0.29.\n",
      " 56/225 [======>.......................] - ETA: 2:41 - loss: 0.2895 - iou_score: 0.6956 - f1-score: 0.8184For batch 55, tr_loss is    0.29.\n",
      " 57/225 [======>.......................] - ETA: 2:40 - loss: 0.2898 - iou_score: 0.6951 - f1-score: 0.8181For batch 56, tr_loss is    0.29.\n",
      " 58/225 [======>.......................] - ETA: 2:40 - loss: 0.2892 - iou_score: 0.6952 - f1-score: 0.8182For batch 57, tr_loss is    0.29.\n",
      " 59/225 [======>.......................] - ETA: 2:39 - loss: 0.2887 - iou_score: 0.6959 - f1-score: 0.8186For batch 58, tr_loss is    0.29.\n",
      " 60/225 [=======>......................] - ETA: 2:38 - loss: 0.2886 - iou_score: 0.6959 - f1-score: 0.8187For batch 59, tr_loss is    0.29.\n",
      " 61/225 [=======>......................] - ETA: 2:38 - loss: 0.2883 - iou_score: 0.6961 - f1-score: 0.8189For batch 60, tr_loss is    0.29.\n",
      " 62/225 [=======>......................] - ETA: 2:37 - loss: 0.2881 - iou_score: 0.6967 - f1-score: 0.8193For batch 61, tr_loss is    0.29.\n",
      " 63/225 [=======>......................] - ETA: 2:34 - loss: 0.2882 - iou_score: 0.6965 - f1-score: 0.8191For batch 62, tr_loss is    0.29.\n",
      " 64/225 [=======>......................] - ETA: 2:33 - loss: 0.2889 - iou_score: 0.6955 - f1-score: 0.8184For batch 63, tr_loss is    0.29.\n",
      " 65/225 [=======>......................] - ETA: 2:31 - loss: 0.2877 - iou_score: 0.6970 - f1-score: 0.8194For batch 64, tr_loss is    0.29.\n",
      " 66/225 [=======>......................] - ETA: 2:31 - loss: 0.2872 - iou_score: 0.6973 - f1-score: 0.8196For batch 65, tr_loss is    0.29.\n",
      " 67/225 [=======>......................] - ETA: 2:29 - loss: 0.2876 - iou_score: 0.6967 - f1-score: 0.8192For batch 66, tr_loss is    0.29.\n",
      " 68/225 [========>.....................] - ETA: 2:29 - loss: 0.2871 - iou_score: 0.6972 - f1-score: 0.8195For batch 67, tr_loss is    0.29.\n",
      " 69/225 [========>.....................] - ETA: 2:28 - loss: 0.2873 - iou_score: 0.6966 - f1-score: 0.8191For batch 68, tr_loss is    0.29.\n",
      " 70/225 [========>.....................] - ETA: 2:27 - loss: 0.2879 - iou_score: 0.6959 - f1-score: 0.8186For batch 69, tr_loss is    0.29.\n",
      " 71/225 [========>.....................] - ETA: 2:26 - loss: 0.2872 - iou_score: 0.6965 - f1-score: 0.8190For batch 70, tr_loss is    0.29.\n",
      " 72/225 [========>.....................] - ETA: 2:24 - loss: 0.2871 - iou_score: 0.6961 - f1-score: 0.8188For batch 71, tr_loss is    0.29.\n",
      " 73/225 [========>.....................] - ETA: 2:23 - loss: 0.2875 - iou_score: 0.6961 - f1-score: 0.8187For batch 72, tr_loss is    0.29.\n",
      " 74/225 [========>.....................] - ETA: 2:23 - loss: 0.2883 - iou_score: 0.6952 - f1-score: 0.8181For batch 73, tr_loss is    0.29.\n",
      " 75/225 [=========>....................] - ETA: 2:22 - loss: 0.2898 - iou_score: 0.6945 - f1-score: 0.8176For batch 74, tr_loss is    0.29.\n",
      " 76/225 [=========>....................] - ETA: 2:20 - loss: 0.2896 - iou_score: 0.6948 - f1-score: 0.8178For batch 75, tr_loss is    0.29.\n",
      " 77/225 [=========>....................] - ETA: 2:19 - loss: 0.2891 - iou_score: 0.6950 - f1-score: 0.8180For batch 76, tr_loss is    0.29.\n",
      " 78/225 [=========>....................] - ETA: 2:18 - loss: 0.2907 - iou_score: 0.6937 - f1-score: 0.8169For batch 77, tr_loss is    0.29.\n",
      " 79/225 [=========>....................] - ETA: 2:17 - loss: 0.2903 - iou_score: 0.6944 - f1-score: 0.8174For batch 78, tr_loss is    0.29.\n",
      " 80/225 [=========>....................] - ETA: 2:15 - loss: 0.2897 - iou_score: 0.6951 - f1-score: 0.8179For batch 79, tr_loss is    0.29.\n",
      " 81/225 [=========>....................] - ETA: 2:15 - loss: 0.2890 - iou_score: 0.6957 - f1-score: 0.8183For batch 80, tr_loss is    0.29.\n",
      " 82/225 [=========>....................] - ETA: 2:14 - loss: 0.2884 - iou_score: 0.6965 - f1-score: 0.8189For batch 81, tr_loss is    0.29.\n",
      " 83/225 [==========>...................] - ETA: 2:13 - loss: 0.2888 - iou_score: 0.6960 - f1-score: 0.8186For batch 82, tr_loss is    0.29.\n",
      " 84/225 [==========>...................] - ETA: 2:11 - loss: 0.2882 - iou_score: 0.6967 - f1-score: 0.8190For batch 83, tr_loss is    0.29.\n",
      " 85/225 [==========>...................] - ETA: 2:10 - loss: 0.2880 - iou_score: 0.6970 - f1-score: 0.8193For batch 84, tr_loss is    0.29.\n",
      " 86/225 [==========>...................] - ETA: 2:09 - loss: 0.2876 - iou_score: 0.6975 - f1-score: 0.8196For batch 85, tr_loss is    0.29.\n",
      " 87/225 [==========>...................] - ETA: 2:08 - loss: 0.2872 - iou_score: 0.6981 - f1-score: 0.8200For batch 86, tr_loss is    0.29.\n",
      " 88/225 [==========>...................] - ETA: 2:08 - loss: 0.2869 - iou_score: 0.6984 - f1-score: 0.8203For batch 87, tr_loss is    0.29.\n",
      " 89/225 [==========>...................] - ETA: 2:07 - loss: 0.2869 - iou_score: 0.6985 - f1-score: 0.8203For batch 88, tr_loss is    0.29.\n",
      " 90/225 [===========>..................] - ETA: 2:06 - loss: 0.2863 - iou_score: 0.6994 - f1-score: 0.8209For batch 89, tr_loss is    0.29.\n",
      " 91/225 [===========>..................] - ETA: 2:04 - loss: 0.2864 - iou_score: 0.6992 - f1-score: 0.8208For batch 90, tr_loss is    0.29.\n",
      " 92/225 [===========>..................] - ETA: 2:03 - loss: 0.2862 - iou_score: 0.6995 - f1-score: 0.8210For batch 91, tr_loss is    0.29.\n",
      " 93/225 [===========>..................] - ETA: 2:02 - loss: 0.2851 - iou_score: 0.7009 - f1-score: 0.8219For batch 92, tr_loss is    0.29.\n",
      " 94/225 [===========>..................] - ETA: 2:01 - loss: 0.2855 - iou_score: 0.7007 - f1-score: 0.8218For batch 93, tr_loss is    0.29.\n",
      " 95/225 [===========>..................] - ETA: 2:01 - loss: 0.2852 - iou_score: 0.7010 - f1-score: 0.8220For batch 94, tr_loss is    0.29.\n",
      " 96/225 [===========>..................] - ETA: 2:00 - loss: 0.2860 - iou_score: 0.7001 - f1-score: 0.8214For batch 95, tr_loss is    0.29.\n",
      " 97/225 [===========>..................] - ETA: 1:59 - loss: 0.2857 - iou_score: 0.7004 - f1-score: 0.8216For batch 96, tr_loss is    0.29.\n",
      " 98/225 [============>.................] - ETA: 1:58 - loss: 0.2857 - iou_score: 0.6999 - f1-score: 0.8213For batch 97, tr_loss is    0.29.\n",
      " 99/225 [============>.................] - ETA: 1:57 - loss: 0.2855 - iou_score: 0.7002 - f1-score: 0.8215For batch 98, tr_loss is    0.29.\n",
      "100/225 [============>.................] - ETA: 1:56 - loss: 0.2856 - iou_score: 0.6999 - f1-score: 0.8213For batch 99, tr_loss is    0.29.\n",
      "101/225 [============>.................] - ETA: 1:55 - loss: 0.2863 - iou_score: 0.6994 - f1-score: 0.8209For batch 100, tr_loss is    0.29.\n",
      "102/225 [============>.................] - ETA: 1:54 - loss: 0.2860 - iou_score: 0.6999 - f1-score: 0.8212For batch 101, tr_loss is    0.29.\n",
      "103/225 [============>.................] - ETA: 1:53 - loss: 0.2864 - iou_score: 0.6994 - f1-score: 0.8208For batch 102, tr_loss is    0.29.\n",
      "104/225 [============>.................] - ETA: 1:52 - loss: 0.2862 - iou_score: 0.6994 - f1-score: 0.8209For batch 103, tr_loss is    0.29.\n",
      "105/225 [=============>................] - ETA: 1:50 - loss: 0.2859 - iou_score: 0.6999 - f1-score: 0.8212For batch 104, tr_loss is    0.29.\n",
      "106/225 [=============>................] - ETA: 1:49 - loss: 0.2854 - iou_score: 0.7005 - f1-score: 0.8216For batch 105, tr_loss is    0.29.\n",
      "107/225 [=============>................] - ETA: 1:48 - loss: 0.2850 - iou_score: 0.7009 - f1-score: 0.8218For batch 106, tr_loss is    0.29.\n",
      "108/225 [=============>................] - ETA: 1:47 - loss: 0.2850 - iou_score: 0.7007 - f1-score: 0.8217For batch 107, tr_loss is    0.28.\n",
      "109/225 [=============>................] - ETA: 1:46 - loss: 0.2845 - iou_score: 0.7011 - f1-score: 0.8220For batch 108, tr_loss is    0.28.\n",
      "110/225 [=============>................] - ETA: 1:46 - loss: 0.2842 - iou_score: 0.7015 - f1-score: 0.8223For batch 109, tr_loss is    0.28.\n",
      "111/225 [=============>................] - ETA: 1:44 - loss: 0.2843 - iou_score: 0.7011 - f1-score: 0.8220For batch 110, tr_loss is    0.28.\n",
      "112/225 [=============>................] - ETA: 1:43 - loss: 0.2840 - iou_score: 0.7015 - f1-score: 0.8223For batch 111, tr_loss is    0.28.\n",
      "113/225 [==============>...............] - ETA: 1:42 - loss: 0.2840 - iou_score: 0.7018 - f1-score: 0.8225For batch 112, tr_loss is    0.28.\n",
      "114/225 [==============>...............] - ETA: 1:41 - loss: 0.2834 - iou_score: 0.7028 - f1-score: 0.8232For batch 113, tr_loss is    0.28.\n",
      "115/225 [==============>...............] - ETA: 1:40 - loss: 0.2828 - iou_score: 0.7034 - f1-score: 0.8236For batch 114, tr_loss is    0.28.\n",
      "116/225 [==============>...............] - ETA: 1:39 - loss: 0.2824 - iou_score: 0.7039 - f1-score: 0.8239For batch 115, tr_loss is    0.28.\n",
      "117/225 [==============>...............] - ETA: 1:38 - loss: 0.2823 - iou_score: 0.7040 - f1-score: 0.8240For batch 116, tr_loss is    0.28.\n",
      "118/225 [==============>...............] - ETA: 1:38 - loss: 0.2822 - iou_score: 0.7040 - f1-score: 0.8240For batch 117, tr_loss is    0.28.\n",
      "119/225 [==============>...............] - ETA: 1:37 - loss: 0.2819 - iou_score: 0.7042 - f1-score: 0.8242For batch 118, tr_loss is    0.28.\n",
      "120/225 [===============>..............] - ETA: 1:36 - loss: 0.2822 - iou_score: 0.7040 - f1-score: 0.8240For batch 119, tr_loss is    0.28.\n",
      "121/225 [===============>..............] - ETA: 1:35 - loss: 0.2818 - iou_score: 0.7043 - f1-score: 0.8243For batch 120, tr_loss is    0.28.\n",
      "122/225 [===============>..............] - ETA: 1:34 - loss: 0.2817 - iou_score: 0.7046 - f1-score: 0.8244For batch 121, tr_loss is    0.28.\n",
      "123/225 [===============>..............] - ETA: 1:33 - loss: 0.2812 - iou_score: 0.7052 - f1-score: 0.8248For batch 122, tr_loss is    0.28.\n",
      "124/225 [===============>..............] - ETA: 1:32 - loss: 0.2812 - iou_score: 0.7050 - f1-score: 0.8247For batch 123, tr_loss is    0.28.\n",
      "125/225 [===============>..............] - ETA: 1:31 - loss: 0.2815 - iou_score: 0.7049 - f1-score: 0.8246For batch 124, tr_loss is    0.28.\n",
      "126/225 [===============>..............] - ETA: 1:30 - loss: 0.2817 - iou_score: 0.7048 - f1-score: 0.8246For batch 125, tr_loss is    0.28.\n",
      "127/225 [===============>..............] - ETA: 1:29 - loss: 0.2814 - iou_score: 0.7048 - f1-score: 0.8245For batch 126, tr_loss is    0.28.\n",
      "128/225 [================>.............] - ETA: 1:28 - loss: 0.2811 - iou_score: 0.7051 - f1-score: 0.8248For batch 127, tr_loss is    0.28.\n",
      "129/225 [================>.............] - ETA: 1:27 - loss: 0.2816 - iou_score: 0.7045 - f1-score: 0.8243For batch 128, tr_loss is    0.28.\n",
      "130/225 [================>.............] - ETA: 1:26 - loss: 0.2812 - iou_score: 0.7049 - f1-score: 0.8246For batch 129, tr_loss is    0.28.\n",
      "131/225 [================>.............] - ETA: 1:25 - loss: 0.2814 - iou_score: 0.7047 - f1-score: 0.8245For batch 130, tr_loss is    0.28.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/225 [================>.............] - ETA: 1:24 - loss: 0.2810 - iou_score: 0.7052 - f1-score: 0.8248For batch 131, tr_loss is    0.28.\n",
      "133/225 [================>.............] - ETA: 1:23 - loss: 0.2814 - iou_score: 0.7049 - f1-score: 0.8246For batch 132, tr_loss is    0.28.\n",
      "134/225 [================>.............] - ETA: 1:22 - loss: 0.2809 - iou_score: 0.7053 - f1-score: 0.8249For batch 133, tr_loss is    0.28.\n",
      "135/225 [=================>............] - ETA: 1:21 - loss: 0.2810 - iou_score: 0.7052 - f1-score: 0.8248For batch 134, tr_loss is    0.28.\n",
      "136/225 [=================>............] - ETA: 1:21 - loss: 0.2812 - iou_score: 0.7049 - f1-score: 0.8246For batch 135, tr_loss is    0.28.\n",
      "137/225 [=================>............] - ETA: 1:19 - loss: 0.2812 - iou_score: 0.7049 - f1-score: 0.8247For batch 136, tr_loss is    0.28.\n",
      "138/225 [=================>............] - ETA: 1:19 - loss: 0.2816 - iou_score: 0.7048 - f1-score: 0.8246For batch 137, tr_loss is    0.28.\n",
      "139/225 [=================>............] - ETA: 1:17 - loss: 0.2818 - iou_score: 0.7047 - f1-score: 0.8245For batch 138, tr_loss is    0.28.\n",
      "140/225 [=================>............] - ETA: 1:16 - loss: 0.2825 - iou_score: 0.7040 - f1-score: 0.8240For batch 139, tr_loss is    0.28.\n",
      "141/225 [=================>............] - ETA: 1:16 - loss: 0.2822 - iou_score: 0.7043 - f1-score: 0.8243For batch 140, tr_loss is    0.28.\n",
      "142/225 [=================>............] - ETA: 1:15 - loss: 0.2822 - iou_score: 0.7042 - f1-score: 0.8242For batch 141, tr_loss is    0.28.\n",
      "143/225 [==================>...........] - ETA: 1:14 - loss: 0.2823 - iou_score: 0.7041 - f1-score: 0.8241For batch 142, tr_loss is    0.28.\n",
      "144/225 [==================>...........] - ETA: 1:13 - loss: 0.2826 - iou_score: 0.7041 - f1-score: 0.8241For batch 143, tr_loss is    0.28.\n",
      "145/225 [==================>...........] - ETA: 1:12 - loss: 0.2829 - iou_score: 0.7037 - f1-score: 0.8238For batch 144, tr_loss is    0.28.\n",
      "146/225 [==================>...........] - ETA: 1:11 - loss: 0.2828 - iou_score: 0.7040 - f1-score: 0.8240For batch 145, tr_loss is    0.28.\n",
      "147/225 [==================>...........] - ETA: 1:10 - loss: 0.2826 - iou_score: 0.7043 - f1-score: 0.8242For batch 146, tr_loss is    0.28.\n",
      "148/225 [==================>...........] - ETA: 1:09 - loss: 0.2826 - iou_score: 0.7043 - f1-score: 0.8243For batch 147, tr_loss is    0.28.\n",
      "149/225 [==================>...........] - ETA: 1:08 - loss: 0.2824 - iou_score: 0.7045 - f1-score: 0.8244For batch 148, tr_loss is    0.28.\n",
      "150/225 [===================>..........] - ETA: 1:07 - loss: 0.2826 - iou_score: 0.7043 - f1-score: 0.8243For batch 149, tr_loss is    0.28.\n",
      "151/225 [===================>..........] - ETA: 1:07 - loss: 0.2826 - iou_score: 0.7044 - f1-score: 0.8244For batch 150, tr_loss is    0.28.\n",
      "152/225 [===================>..........] - ETA: 1:06 - loss: 0.2825 - iou_score: 0.7045 - f1-score: 0.8244For batch 151, tr_loss is    0.28.\n",
      "153/225 [===================>..........] - ETA: 1:05 - loss: 0.2827 - iou_score: 0.7043 - f1-score: 0.8243For batch 152, tr_loss is    0.28.\n",
      "154/225 [===================>..........] - ETA: 1:04 - loss: 0.2825 - iou_score: 0.7045 - f1-score: 0.8244For batch 153, tr_loss is    0.28.\n",
      "155/225 [===================>..........] - ETA: 1:03 - loss: 0.2835 - iou_score: 0.7033 - f1-score: 0.8235For batch 154, tr_loss is    0.28.\n",
      "156/225 [===================>..........] - ETA: 1:02 - loss: 0.2841 - iou_score: 0.7028 - f1-score: 0.8231For batch 155, tr_loss is    0.28.\n",
      "157/225 [===================>..........] - ETA: 1:01 - loss: 0.2841 - iou_score: 0.7028 - f1-score: 0.8232For batch 156, tr_loss is    0.28.\n",
      "158/225 [====================>.........] - ETA: 1:00 - loss: 0.2841 - iou_score: 0.7027 - f1-score: 0.8231For batch 157, tr_loss is    0.28.\n",
      "159/225 [====================>.........] - ETA: 59s - loss: 0.2840 - iou_score: 0.7028 - f1-score: 0.8232 For batch 158, tr_loss is    0.28.\n",
      "160/225 [====================>.........] - ETA: 58s - loss: 0.2838 - iou_score: 0.7029 - f1-score: 0.8232For batch 159, tr_loss is    0.28.\n",
      "161/225 [====================>.........] - ETA: 58s - loss: 0.2834 - iou_score: 0.7035 - f1-score: 0.8237For batch 160, tr_loss is    0.28.\n",
      "162/225 [====================>.........] - ETA: 56s - loss: 0.2833 - iou_score: 0.7035 - f1-score: 0.8237For batch 161, tr_loss is    0.28.\n",
      "163/225 [====================>.........] - ETA: 56s - loss: 0.2835 - iou_score: 0.7033 - f1-score: 0.8235For batch 162, tr_loss is    0.28.\n",
      "164/225 [====================>.........] - ETA: 55s - loss: 0.2835 - iou_score: 0.7034 - f1-score: 0.8236For batch 163, tr_loss is    0.28.\n",
      "165/225 [=====================>........] - ETA: 54s - loss: 0.2836 - iou_score: 0.7034 - f1-score: 0.8236For batch 164, tr_loss is    0.28.\n",
      "166/225 [=====================>........] - ETA: 53s - loss: 0.2840 - iou_score: 0.7029 - f1-score: 0.8232For batch 165, tr_loss is    0.28.\n",
      "167/225 [=====================>........] - ETA: 52s - loss: 0.2838 - iou_score: 0.7031 - f1-score: 0.8234For batch 166, tr_loss is    0.28.\n",
      "168/225 [=====================>........] - ETA: 51s - loss: 0.2832 - iou_score: 0.7039 - f1-score: 0.8239For batch 167, tr_loss is    0.28.\n",
      "169/225 [=====================>........] - ETA: 50s - loss: 0.2831 - iou_score: 0.7040 - f1-score: 0.8240For batch 168, tr_loss is    0.28.\n",
      "170/225 [=====================>........] - ETA: 49s - loss: 0.2836 - iou_score: 0.7037 - f1-score: 0.8238For batch 169, tr_loss is    0.28.\n",
      "171/225 [=====================>........] - ETA: 48s - loss: 0.2838 - iou_score: 0.7034 - f1-score: 0.8236For batch 170, tr_loss is    0.28.\n",
      "172/225 [=====================>........] - ETA: 47s - loss: 0.2841 - iou_score: 0.7029 - f1-score: 0.8232For batch 171, tr_loss is    0.28.\n",
      "173/225 [======================>.......] - ETA: 46s - loss: 0.2845 - iou_score: 0.7023 - f1-score: 0.8228For batch 172, tr_loss is    0.28.\n",
      "174/225 [======================>.......] - ETA: 45s - loss: 0.2845 - iou_score: 0.7023 - f1-score: 0.8228For batch 173, tr_loss is    0.28.\n",
      "175/225 [======================>.......] - ETA: 44s - loss: 0.2848 - iou_score: 0.7019 - f1-score: 0.8225For batch 174, tr_loss is    0.28.\n",
      "176/225 [======================>.......] - ETA: 44s - loss: 0.2849 - iou_score: 0.7017 - f1-score: 0.8224For batch 175, tr_loss is    0.28.\n",
      "177/225 [======================>.......] - ETA: 43s - loss: 0.2846 - iou_score: 0.7023 - f1-score: 0.8228For batch 176, tr_loss is    0.28.\n",
      "178/225 [======================>.......] - ETA: 42s - loss: 0.2845 - iou_score: 0.7024 - f1-score: 0.8229For batch 177, tr_loss is    0.28.\n",
      "179/225 [======================>.......] - ETA: 41s - loss: 0.2844 - iou_score: 0.7026 - f1-score: 0.8230For batch 178, tr_loss is    0.28.\n",
      "180/225 [=======================>......] - ETA: 40s - loss: 0.2847 - iou_score: 0.7021 - f1-score: 0.8227For batch 179, tr_loss is    0.28.\n",
      "181/225 [=======================>......] - ETA: 39s - loss: 0.2849 - iou_score: 0.7020 - f1-score: 0.8226For batch 180, tr_loss is    0.28.\n",
      "182/225 [=======================>......] - ETA: 38s - loss: 0.2849 - iou_score: 0.7020 - f1-score: 0.8226For batch 181, tr_loss is    0.28.\n",
      "183/225 [=======================>......] - ETA: 37s - loss: 0.2850 - iou_score: 0.7019 - f1-score: 0.8225For batch 182, tr_loss is    0.29.\n",
      "184/225 [=======================>......] - ETA: 36s - loss: 0.2849 - iou_score: 0.7019 - f1-score: 0.8226For batch 183, tr_loss is    0.28.\n",
      "185/225 [=======================>......] - ETA: 35s - loss: 0.2848 - iou_score: 0.7020 - f1-score: 0.8227For batch 184, tr_loss is    0.28.\n",
      "186/225 [=======================>......] - ETA: 34s - loss: 0.2847 - iou_score: 0.7022 - f1-score: 0.8228For batch 185, tr_loss is    0.28.\n",
      "187/225 [=======================>......] - ETA: 34s - loss: 0.2844 - iou_score: 0.7026 - f1-score: 0.8231For batch 186, tr_loss is    0.28.\n",
      "188/225 [========================>.....] - ETA: 33s - loss: 0.2842 - iou_score: 0.7029 - f1-score: 0.8232For batch 187, tr_loss is    0.28.\n",
      "189/225 [========================>.....] - ETA: 32s - loss: 0.2838 - iou_score: 0.7033 - f1-score: 0.8235For batch 188, tr_loss is    0.28.\n",
      "190/225 [========================>.....] - ETA: 31s - loss: 0.2835 - iou_score: 0.7035 - f1-score: 0.8237For batch 189, tr_loss is    0.28.\n",
      "191/225 [========================>.....] - ETA: 30s - loss: 0.2832 - iou_score: 0.7038 - f1-score: 0.8239For batch 190, tr_loss is    0.28.\n",
      "192/225 [========================>.....] - ETA: 29s - loss: 0.2830 - iou_score: 0.7041 - f1-score: 0.8241For batch 191, tr_loss is    0.28.\n",
      "193/225 [========================>.....] - ETA: 28s - loss: 0.2831 - iou_score: 0.7041 - f1-score: 0.8241For batch 192, tr_loss is    0.28.\n",
      "194/225 [========================>.....] - ETA: 27s - loss: 0.2831 - iou_score: 0.7041 - f1-score: 0.8241For batch 193, tr_loss is    0.28.\n",
      "195/225 [=========================>....] - ETA: 26s - loss: 0.2829 - iou_score: 0.7043 - f1-score: 0.8243For batch 194, tr_loss is    0.28.\n",
      "196/225 [=========================>....] - ETA: 25s - loss: 0.2826 - iou_score: 0.7045 - f1-score: 0.8244For batch 195, tr_loss is    0.28.\n",
      "197/225 [=========================>....] - ETA: 25s - loss: 0.2827 - iou_score: 0.7043 - f1-score: 0.8242For batch 196, tr_loss is    0.28.\n",
      "198/225 [=========================>....] - ETA: 24s - loss: 0.2825 - iou_score: 0.7046 - f1-score: 0.8245For batch 197, tr_loss is    0.28.\n",
      "199/225 [=========================>....] - ETA: 23s - loss: 0.2829 - iou_score: 0.7041 - f1-score: 0.8241For batch 198, tr_loss is    0.28.\n",
      "200/225 [=========================>....] - ETA: 22s - loss: 0.2827 - iou_score: 0.7044 - f1-score: 0.8243For batch 199, tr_loss is    0.28.\n",
      "201/225 [=========================>....] - ETA: 21s - loss: 0.2830 - iou_score: 0.7042 - f1-score: 0.8242For batch 200, tr_loss is    0.28.\n",
      "202/225 [=========================>....] - ETA: 20s - loss: 0.2828 - iou_score: 0.7046 - f1-score: 0.8244For batch 201, tr_loss is    0.28.\n",
      "203/225 [==========================>...] - ETA: 19s - loss: 0.2826 - iou_score: 0.7048 - f1-score: 0.8246For batch 202, tr_loss is    0.28.\n",
      "204/225 [==========================>...] - ETA: 18s - loss: 0.2823 - iou_score: 0.7052 - f1-score: 0.8249For batch 203, tr_loss is    0.28.\n",
      "205/225 [==========================>...] - ETA: 17s - loss: 0.2822 - iou_score: 0.7053 - f1-score: 0.8250For batch 204, tr_loss is    0.28.\n",
      "206/225 [==========================>...] - ETA: 17s - loss: 0.2821 - iou_score: 0.7054 - f1-score: 0.8250For batch 205, tr_loss is    0.28.\n",
      "207/225 [==========================>...] - ETA: 16s - loss: 0.2821 - iou_score: 0.7053 - f1-score: 0.8249For batch 206, tr_loss is    0.28.\n",
      "208/225 [==========================>...] - ETA: 15s - loss: 0.2824 - iou_score: 0.7050 - f1-score: 0.8247For batch 207, tr_loss is    0.28.\n",
      "209/225 [==========================>...] - ETA: 14s - loss: 0.2821 - iou_score: 0.7053 - f1-score: 0.8250For batch 208, tr_loss is    0.28.\n",
      "210/225 [===========================>..] - ETA: 13s - loss: 0.2824 - iou_score: 0.7050 - f1-score: 0.8247For batch 209, tr_loss is    0.28.\n",
      "211/225 [===========================>..] - ETA: 12s - loss: 0.2824 - iou_score: 0.7050 - f1-score: 0.8247For batch 210, tr_loss is    0.28.\n",
      "212/225 [===========================>..] - ETA: 11s - loss: 0.2827 - iou_score: 0.7048 - f1-score: 0.8246For batch 211, tr_loss is    0.28.\n",
      "213/225 [===========================>..] - ETA: 10s - loss: 0.2827 - iou_score: 0.7047 - f1-score: 0.8245For batch 212, tr_loss is    0.28.\n",
      "214/225 [===========================>..] - ETA: 9s - loss: 0.2827 - iou_score: 0.7047 - f1-score: 0.8246 For batch 213, tr_loss is    0.28.\n",
      "215/225 [===========================>..] - ETA: 8s - loss: 0.2826 - iou_score: 0.7050 - f1-score: 0.8248For batch 214, tr_loss is    0.28.\n",
      "216/225 [===========================>..] - ETA: 8s - loss: 0.2823 - iou_score: 0.7053 - f1-score: 0.8249For batch 215, tr_loss is    0.28.\n",
      "217/225 [===========================>..] - ETA: 7s - loss: 0.2821 - iou_score: 0.7056 - f1-score: 0.8252For batch 216, tr_loss is    0.28.\n",
      "218/225 [============================>.] - ETA: 6s - loss: 0.2818 - iou_score: 0.7059 - f1-score: 0.8254For batch 217, tr_loss is    0.28.\n",
      "219/225 [============================>.] - ETA: 5s - loss: 0.2817 - iou_score: 0.7060 - f1-score: 0.8254For batch 218, tr_loss is    0.28.\n",
      "220/225 [============================>.] - ETA: 4s - loss: 0.2816 - iou_score: 0.7061 - f1-score: 0.8255For batch 219, tr_loss is    0.28.\n",
      "221/225 [============================>.] - ETA: 3s - loss: 0.2817 - iou_score: 0.7060 - f1-score: 0.8254For batch 220, tr_loss is    0.28.\n",
      "222/225 [============================>.] - ETA: 2s - loss: 0.2816 - iou_score: 0.7060 - f1-score: 0.8255For batch 221, tr_loss is    0.28.\n",
      "223/225 [============================>.] - ETA: 1s - loss: 0.2817 - iou_score: 0.7059 - f1-score: 0.8254For batch 222, tr_loss is    0.28.\n",
      "224/225 [============================>.] - ETA: 0s - loss: 0.2819 - iou_score: 0.7057 - f1-score: 0.8252For batch 223, tr_loss is    0.28.\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.2817 - iou_score: 0.7059 - f1-score: 0.8254For batch 224, tr_loss is    0.28.\n",
      "For batch 0, vl_loss is    0.40.\n",
      "For batch 1, vl_loss is    0.38.\n",
      "For batch 2, vl_loss is    0.41.\n",
      "For batch 3, vl_loss is    0.40.\n",
      "For batch 4, vl_loss is    0.38.\n",
      "For batch 5, vl_loss is    0.37.\n",
      "For batch 6, vl_loss is    0.37.\n",
      "For batch 7, vl_loss is    0.38.\n",
      "For batch 8, vl_loss is    0.37.\n",
      "For batch 9, vl_loss is    0.37.\n",
      "For batch 10, vl_loss is    0.37.\n",
      "For batch 11, vl_loss is    0.37.\n",
      "For batch 12, vl_loss is    0.37.\n",
      "For batch 13, vl_loss is    0.36.\n",
      "For batch 14, vl_loss is    0.37.\n",
      "For batch 15, vl_loss is    0.37.\n",
      "For batch 16, vl_loss is    0.37.\n",
      "For batch 17, vl_loss is    0.37.\n",
      "For batch 18, vl_loss is    0.37.\n",
      "For batch 19, vl_loss is    0.37.\n",
      "For batch 20, vl_loss is    0.38.\n",
      "For batch 21, vl_loss is    0.38.\n",
      "For batch 22, vl_loss is    0.38.\n",
      "For batch 23, vl_loss is    0.38.\n",
      "For batch 24, vl_loss is    0.38.\n",
      "For batch 25, vl_loss is    0.38.\n",
      "For batch 26, vl_loss is    0.38.\n",
      "For batch 27, vl_loss is    0.38.\n",
      "For batch 28, vl_loss is    0.38.\n",
      "For batch 29, vl_loss is    0.38.\n",
      "For batch 30, vl_loss is    0.38.\n",
      "For batch 31, vl_loss is    0.38.\n",
      "For batch 32, vl_loss is    0.38.\n",
      "For batch 33, vl_loss is    0.38.\n",
      "For batch 34, vl_loss is    0.38.\n",
      "For batch 35, vl_loss is    0.38.\n",
      "For batch 36, vl_loss is    0.38.\n",
      "For batch 37, vl_loss is    0.38.\n",
      "For batch 38, vl_loss is    0.38.\n",
      "For batch 39, vl_loss is    0.38.\n",
      "For batch 40, vl_loss is    0.38.\n",
      "For batch 41, vl_loss is    0.38.\n",
      "For batch 42, vl_loss is    0.38.\n",
      "For batch 43, vl_loss is    0.38.\n",
      "For batch 44, vl_loss is    0.38.\n",
      "For batch 45, vl_loss is    0.38.\n",
      "For batch 46, vl_loss is    0.37.\n",
      "For batch 47, vl_loss is    0.37.\n",
      "For batch 48, vl_loss is    0.37.\n",
      "For batch 49, vl_loss is    0.37.\n",
      "For batch 50, vl_loss is    0.37.\n",
      "For batch 51, vl_loss is    0.37.\n",
      "For batch 52, vl_loss is    0.37.\n",
      "For batch 53, vl_loss is    0.37.\n",
      "For batch 54, vl_loss is    0.37.\n",
      "For batch 55, vl_loss is    0.37.\n",
      "For batch 56, vl_loss is    0.37.\n",
      "For batch 57, vl_loss is    0.37.\n",
      "For batch 58, vl_loss is    0.37.\n",
      "For batch 59, vl_loss is    0.37.\n",
      "For batch 60, vl_loss is    0.37.\n",
      "For batch 61, vl_loss is    0.37.\n",
      "For batch 62, vl_loss is    0.37.\n",
      "For batch 63, vl_loss is    0.37.\n",
      "For batch 64, vl_loss is    0.37.\n",
      "For batch 65, vl_loss is    0.37.\n",
      "For batch 66, vl_loss is    0.37.\n",
      "For batch 67, vl_loss is    0.38.\n",
      "For batch 68, vl_loss is    0.37.\n",
      "For batch 69, vl_loss is    0.37.\n",
      "For batch 70, vl_loss is    0.37.\n",
      "For batch 71, vl_loss is    0.37.\n",
      "For batch 72, vl_loss is    0.37.\n",
      "For batch 73, vl_loss is    0.37.\n",
      "For batch 74, vl_loss is    0.37.\n",
      "225/225 [==============================] - 205s 907ms/step - loss: 0.2817 - iou_score: 0.7059 - f1-score: 0.8254 - val_loss: 0.3729 - val_iou_score: 0.6344 - val_f1-score: 0.7739\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.38772 to 0.37292, saving model to ./model/tumor_100_unet_efficientnetb0_imagenet_09293.hdf5\n",
      "The average loss for epoch 5 is    0.28 \n",
      "Epoch 7/200\n",
      "  1/225 [..............................] - ETA: 11:51 - loss: 0.3122 - iou_score: 0.6869 - f1-score: 0.8142For batch 0, tr_loss is    0.31.\n",
      "  2/225 [..............................] - ETA: 5:42 - loss: 0.2966 - iou_score: 0.6929 - f1-score: 0.8184 For batch 1, tr_loss is    0.30.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3/225 [..............................] - ETA: 6:08 - loss: 0.2848 - iou_score: 0.6976 - f1-score: 0.8214For batch 2, tr_loss is    0.28.\n",
      "  4/225 [..............................] - ETA: 5:35 - loss: 0.2782 - iou_score: 0.7142 - f1-score: 0.8320For batch 3, tr_loss is    0.28.\n",
      "  5/225 [..............................] - ETA: 5:06 - loss: 0.2714 - iou_score: 0.7211 - f1-score: 0.8367For batch 4, tr_loss is    0.27.\n",
      "  6/225 [..............................] - ETA: 5:27 - loss: 0.2780 - iou_score: 0.7169 - f1-score: 0.8339For batch 5, tr_loss is    0.28.\n",
      "  7/225 [..............................] - ETA: 5:11 - loss: 0.2778 - iou_score: 0.7130 - f1-score: 0.8307For batch 6, tr_loss is    0.28.\n",
      "  8/225 [>.............................] - ETA: 4:40 - loss: 0.2809 - iou_score: 0.7057 - f1-score: 0.8257For batch 7, tr_loss is    0.28.\n",
      "  9/225 [>.............................] - ETA: 4:33 - loss: 0.2724 - iou_score: 0.7138 - f1-score: 0.8308For batch 8, tr_loss is    0.27.\n",
      " 10/225 [>.............................] - ETA: 4:16 - loss: 0.2765 - iou_score: 0.7108 - f1-score: 0.8288For batch 9, tr_loss is    0.28.\n",
      " 11/225 [>.............................] - ETA: 4:04 - loss: 0.2774 - iou_score: 0.7091 - f1-score: 0.8274For batch 10, tr_loss is    0.28.\n",
      " 12/225 [>.............................] - ETA: 3:54 - loss: 0.2822 - iou_score: 0.7025 - f1-score: 0.8227For batch 11, tr_loss is    0.28.\n",
      " 13/225 [>.............................] - ETA: 3:46 - loss: 0.2851 - iou_score: 0.6982 - f1-score: 0.8198For batch 12, tr_loss is    0.29.\n",
      " 14/225 [>.............................] - ETA: 3:44 - loss: 0.2833 - iou_score: 0.6988 - f1-score: 0.8203For batch 13, tr_loss is    0.28.\n",
      " 15/225 [=>............................] - ETA: 3:34 - loss: 0.2850 - iou_score: 0.6971 - f1-score: 0.8193For batch 14, tr_loss is    0.29.\n",
      " 16/225 [=>............................] - ETA: 3:30 - loss: 0.2856 - iou_score: 0.6964 - f1-score: 0.8187For batch 15, tr_loss is    0.29.\n",
      " 17/225 [=>............................] - ETA: 3:29 - loss: 0.2840 - iou_score: 0.6986 - f1-score: 0.8203For batch 16, tr_loss is    0.28.\n",
      " 18/225 [=>............................] - ETA: 3:20 - loss: 0.2849 - iou_score: 0.6970 - f1-score: 0.8192For batch 17, tr_loss is    0.28.\n",
      " 19/225 [=>............................] - ETA: 3:20 - loss: 0.2833 - iou_score: 0.6991 - f1-score: 0.8207For batch 18, tr_loss is    0.28.\n",
      " 20/225 [=>............................] - ETA: 3:15 - loss: 0.2813 - iou_score: 0.7002 - f1-score: 0.8215For batch 19, tr_loss is    0.28.\n",
      " 21/225 [=>............................] - ETA: 3:14 - loss: 0.2815 - iou_score: 0.7009 - f1-score: 0.8221For batch 20, tr_loss is    0.28.\n",
      " 22/225 [=>............................] - ETA: 3:09 - loss: 0.2806 - iou_score: 0.7026 - f1-score: 0.8233For batch 21, tr_loss is    0.28.\n",
      " 23/225 [==>...........................] - ETA: 3:08 - loss: 0.2885 - iou_score: 0.6955 - f1-score: 0.8180For batch 22, tr_loss is    0.29.\n",
      " 24/225 [==>...........................] - ETA: 3:08 - loss: 0.2889 - iou_score: 0.6940 - f1-score: 0.8170For batch 23, tr_loss is    0.29.\n",
      " 25/225 [==>...........................] - ETA: 3:06 - loss: 0.2900 - iou_score: 0.6925 - f1-score: 0.8160For batch 24, tr_loss is    0.29.\n",
      " 26/225 [==>...........................] - ETA: 3:05 - loss: 0.2876 - iou_score: 0.6958 - f1-score: 0.8183For batch 25, tr_loss is    0.29.\n",
      " 27/225 [==>...........................] - ETA: 3:01 - loss: 0.2878 - iou_score: 0.6953 - f1-score: 0.8180For batch 26, tr_loss is    0.29.\n",
      " 28/225 [==>...........................] - ETA: 3:02 - loss: 0.2863 - iou_score: 0.6960 - f1-score: 0.8185For batch 27, tr_loss is    0.29.\n",
      " 29/225 [==>...........................] - ETA: 3:02 - loss: 0.2858 - iou_score: 0.6966 - f1-score: 0.8189For batch 28, tr_loss is    0.29.\n",
      " 30/225 [===>..........................] - ETA: 3:00 - loss: 0.2851 - iou_score: 0.6975 - f1-score: 0.8195For batch 29, tr_loss is    0.29.\n",
      " 31/225 [===>..........................] - ETA: 3:00 - loss: 0.2845 - iou_score: 0.6987 - f1-score: 0.8204For batch 30, tr_loss is    0.28.\n",
      " 32/225 [===>..........................] - ETA: 2:57 - loss: 0.2844 - iou_score: 0.6986 - f1-score: 0.8204For batch 31, tr_loss is    0.28.\n",
      " 33/225 [===>..........................] - ETA: 2:53 - loss: 0.2823 - iou_score: 0.7017 - f1-score: 0.8225For batch 32, tr_loss is    0.28.\n",
      " 34/225 [===>..........................] - ETA: 2:52 - loss: 0.2828 - iou_score: 0.7015 - f1-score: 0.8223For batch 33, tr_loss is    0.28.\n",
      " 35/225 [===>..........................] - ETA: 2:49 - loss: 0.2832 - iou_score: 0.7002 - f1-score: 0.8215For batch 34, tr_loss is    0.28.\n",
      " 36/225 [===>..........................] - ETA: 2:50 - loss: 0.2815 - iou_score: 0.7021 - f1-score: 0.8228For batch 35, tr_loss is    0.28.\n",
      " 37/225 [===>..........................] - ETA: 2:49 - loss: 0.2804 - iou_score: 0.7031 - f1-score: 0.8236For batch 36, tr_loss is    0.28.\n",
      " 38/225 [====>.........................] - ETA: 2:49 - loss: 0.2782 - iou_score: 0.7054 - f1-score: 0.8251For batch 37, tr_loss is    0.28.\n",
      " 39/225 [====>.........................] - ETA: 2:49 - loss: 0.2794 - iou_score: 0.7037 - f1-score: 0.8239For batch 38, tr_loss is    0.28.\n",
      " 40/225 [====>.........................] - ETA: 2:46 - loss: 0.2771 - iou_score: 0.7065 - f1-score: 0.8258For batch 39, tr_loss is    0.28.\n",
      " 41/225 [====>.........................] - ETA: 2:44 - loss: 0.2763 - iou_score: 0.7069 - f1-score: 0.8261For batch 40, tr_loss is    0.28.\n",
      " 42/225 [====>.........................] - ETA: 2:44 - loss: 0.2767 - iou_score: 0.7066 - f1-score: 0.8259For batch 41, tr_loss is    0.28.\n",
      " 43/225 [====>.........................] - ETA: 2:44 - loss: 0.2756 - iou_score: 0.7074 - f1-score: 0.8265For batch 42, tr_loss is    0.28.\n",
      " 44/225 [====>.........................] - ETA: 2:43 - loss: 0.2752 - iou_score: 0.7079 - f1-score: 0.8269For batch 43, tr_loss is    0.28.\n",
      " 45/225 [=====>........................] - ETA: 2:43 - loss: 0.2751 - iou_score: 0.7079 - f1-score: 0.8269For batch 44, tr_loss is    0.28.\n",
      " 46/225 [=====>........................] - ETA: 2:42 - loss: 0.2755 - iou_score: 0.7076 - f1-score: 0.8267For batch 45, tr_loss is    0.28.\n",
      " 47/225 [=====>........................] - ETA: 2:42 - loss: 0.2743 - iou_score: 0.7087 - f1-score: 0.8276For batch 46, tr_loss is    0.27.\n",
      " 48/225 [=====>........................] - ETA: 2:41 - loss: 0.2745 - iou_score: 0.7090 - f1-score: 0.8278For batch 47, tr_loss is    0.27.\n",
      " 49/225 [=====>........................] - ETA: 2:38 - loss: 0.2763 - iou_score: 0.7071 - f1-score: 0.8264For batch 48, tr_loss is    0.28.\n",
      " 50/225 [=====>........................] - ETA: 2:37 - loss: 0.2783 - iou_score: 0.7049 - f1-score: 0.8248For batch 49, tr_loss is    0.28.\n",
      " 51/225 [=====>........................] - ETA: 2:37 - loss: 0.2781 - iou_score: 0.7048 - f1-score: 0.8248For batch 50, tr_loss is    0.28.\n",
      " 52/225 [=====>........................] - ETA: 2:34 - loss: 0.2777 - iou_score: 0.7055 - f1-score: 0.8253For batch 51, tr_loss is    0.28.\n",
      " 53/225 [======>.......................] - ETA: 2:35 - loss: 0.2784 - iou_score: 0.7048 - f1-score: 0.8247For batch 52, tr_loss is    0.28.\n",
      " 54/225 [======>.......................] - ETA: 2:34 - loss: 0.2777 - iou_score: 0.7048 - f1-score: 0.8248For batch 53, tr_loss is    0.28.\n",
      " 55/225 [======>.......................] - ETA: 2:33 - loss: 0.2772 - iou_score: 0.7052 - f1-score: 0.8251For batch 54, tr_loss is    0.28.\n",
      " 56/225 [======>.......................] - ETA: 2:31 - loss: 0.2769 - iou_score: 0.7051 - f1-score: 0.8251For batch 55, tr_loss is    0.28.\n",
      " 57/225 [======>.......................] - ETA: 2:29 - loss: 0.2772 - iou_score: 0.7048 - f1-score: 0.8249For batch 56, tr_loss is    0.28.\n",
      " 58/225 [======>.......................] - ETA: 2:29 - loss: 0.2768 - iou_score: 0.7048 - f1-score: 0.8249For batch 57, tr_loss is    0.28.\n",
      " 59/225 [======>.......................] - ETA: 2:28 - loss: 0.2762 - iou_score: 0.7055 - f1-score: 0.8253For batch 58, tr_loss is    0.28.\n",
      " 60/225 [=======>......................] - ETA: 2:26 - loss: 0.2763 - iou_score: 0.7055 - f1-score: 0.8254For batch 59, tr_loss is    0.28.\n",
      " 61/225 [=======>......................] - ETA: 2:24 - loss: 0.2764 - iou_score: 0.7053 - f1-score: 0.8253For batch 60, tr_loss is    0.28.\n",
      " 62/225 [=======>......................] - ETA: 2:23 - loss: 0.2761 - iou_score: 0.7060 - f1-score: 0.8258For batch 61, tr_loss is    0.28.\n",
      " 63/225 [=======>......................] - ETA: 2:21 - loss: 0.2765 - iou_score: 0.7056 - f1-score: 0.8255For batch 62, tr_loss is    0.28.\n",
      " 64/225 [=======>......................] - ETA: 2:21 - loss: 0.2774 - iou_score: 0.7046 - f1-score: 0.8248For batch 63, tr_loss is    0.28.\n",
      " 65/225 [=======>......................] - ETA: 2:21 - loss: 0.2764 - iou_score: 0.7059 - f1-score: 0.8256For batch 64, tr_loss is    0.28.\n",
      " 66/225 [=======>......................] - ETA: 2:20 - loss: 0.2764 - iou_score: 0.7060 - f1-score: 0.8258For batch 65, tr_loss is    0.28.\n",
      " 67/225 [=======>......................] - ETA: 2:19 - loss: 0.2767 - iou_score: 0.7056 - f1-score: 0.8254For batch 66, tr_loss is    0.28.\n",
      " 68/225 [========>.....................] - ETA: 2:18 - loss: 0.2764 - iou_score: 0.7061 - f1-score: 0.8257For batch 67, tr_loss is    0.28.\n",
      " 69/225 [========>.....................] - ETA: 2:18 - loss: 0.2766 - iou_score: 0.7056 - f1-score: 0.8254For batch 68, tr_loss is    0.28.\n",
      " 70/225 [========>.....................] - ETA: 2:17 - loss: 0.2770 - iou_score: 0.7050 - f1-score: 0.8250For batch 69, tr_loss is    0.28.\n",
      " 71/225 [========>.....................] - ETA: 2:17 - loss: 0.2763 - iou_score: 0.7055 - f1-score: 0.8254For batch 70, tr_loss is    0.28.\n",
      " 72/225 [========>.....................] - ETA: 2:15 - loss: 0.2764 - iou_score: 0.7051 - f1-score: 0.8250For batch 71, tr_loss is    0.28.\n",
      " 73/225 [========>.....................] - ETA: 2:14 - loss: 0.2767 - iou_score: 0.7047 - f1-score: 0.8247For batch 72, tr_loss is    0.28.\n",
      " 74/225 [========>.....................] - ETA: 2:13 - loss: 0.2779 - iou_score: 0.7034 - f1-score: 0.8238For batch 73, tr_loss is    0.28.\n",
      " 75/225 [=========>....................] - ETA: 2:12 - loss: 0.2788 - iou_score: 0.7031 - f1-score: 0.8236For batch 74, tr_loss is    0.28.\n",
      " 76/225 [=========>....................] - ETA: 2:12 - loss: 0.2787 - iou_score: 0.7033 - f1-score: 0.8238For batch 75, tr_loss is    0.28.\n",
      " 77/225 [=========>....................] - ETA: 2:10 - loss: 0.2784 - iou_score: 0.7037 - f1-score: 0.8241For batch 76, tr_loss is    0.28.\n",
      " 78/225 [=========>....................] - ETA: 2:09 - loss: 0.2805 - iou_score: 0.7020 - f1-score: 0.8228For batch 77, tr_loss is    0.28.\n",
      " 79/225 [=========>....................] - ETA: 2:08 - loss: 0.2802 - iou_score: 0.7025 - f1-score: 0.8231For batch 78, tr_loss is    0.28.\n",
      " 80/225 [=========>....................] - ETA: 2:08 - loss: 0.2799 - iou_score: 0.7032 - f1-score: 0.8235For batch 79, tr_loss is    0.28.\n",
      " 81/225 [=========>....................] - ETA: 2:07 - loss: 0.2793 - iou_score: 0.7039 - f1-score: 0.8241For batch 80, tr_loss is    0.28.\n",
      " 82/225 [=========>....................] - ETA: 2:06 - loss: 0.2786 - iou_score: 0.7047 - f1-score: 0.8246For batch 81, tr_loss is    0.28.\n",
      " 83/225 [==========>...................] - ETA: 2:05 - loss: 0.2793 - iou_score: 0.7042 - f1-score: 0.8243For batch 82, tr_loss is    0.28.\n",
      " 84/225 [==========>...................] - ETA: 2:05 - loss: 0.2790 - iou_score: 0.7046 - f1-score: 0.8246For batch 83, tr_loss is    0.28.\n",
      " 85/225 [==========>...................] - ETA: 2:03 - loss: 0.2789 - iou_score: 0.7048 - f1-score: 0.8247For batch 84, tr_loss is    0.28.\n",
      " 86/225 [==========>...................] - ETA: 2:02 - loss: 0.2787 - iou_score: 0.7051 - f1-score: 0.8249For batch 85, tr_loss is    0.28.\n",
      " 87/225 [==========>...................] - ETA: 2:01 - loss: 0.2784 - iou_score: 0.7054 - f1-score: 0.8252For batch 86, tr_loss is    0.28.\n",
      " 88/225 [==========>...................] - ETA: 2:01 - loss: 0.2782 - iou_score: 0.7056 - f1-score: 0.8253For batch 87, tr_loss is    0.28.\n",
      " 89/225 [==========>...................] - ETA: 1:59 - loss: 0.2784 - iou_score: 0.7054 - f1-score: 0.8252For batch 88, tr_loss is    0.28.\n",
      " 90/225 [===========>..................] - ETA: 1:59 - loss: 0.2780 - iou_score: 0.7061 - f1-score: 0.8256For batch 89, tr_loss is    0.28.\n",
      " 91/225 [===========>..................] - ETA: 1:58 - loss: 0.2783 - iou_score: 0.7057 - f1-score: 0.8254For batch 90, tr_loss is    0.28.\n",
      " 92/225 [===========>..................] - ETA: 1:57 - loss: 0.2784 - iou_score: 0.7057 - f1-score: 0.8254For batch 91, tr_loss is    0.28.\n",
      " 93/225 [===========>..................] - ETA: 1:56 - loss: 0.2772 - iou_score: 0.7073 - f1-score: 0.8264For batch 92, tr_loss is    0.28.\n",
      " 94/225 [===========>..................] - ETA: 1:55 - loss: 0.2774 - iou_score: 0.7072 - f1-score: 0.8263For batch 93, tr_loss is    0.28.\n",
      " 95/225 [===========>..................] - ETA: 1:54 - loss: 0.2770 - iou_score: 0.7077 - f1-score: 0.8267For batch 94, tr_loss is    0.28.\n",
      " 96/225 [===========>..................] - ETA: 1:53 - loss: 0.2776 - iou_score: 0.7068 - f1-score: 0.8261For batch 95, tr_loss is    0.28.\n",
      " 97/225 [===========>..................] - ETA: 1:52 - loss: 0.2774 - iou_score: 0.7070 - f1-score: 0.8262For batch 96, tr_loss is    0.28.\n",
      " 98/225 [============>.................] - ETA: 1:51 - loss: 0.2777 - iou_score: 0.7062 - f1-score: 0.8257For batch 97, tr_loss is    0.28.\n",
      " 99/225 [============>.................] - ETA: 1:50 - loss: 0.2775 - iou_score: 0.7065 - f1-score: 0.8259For batch 98, tr_loss is    0.28.\n",
      "100/225 [============>.................] - ETA: 1:49 - loss: 0.2777 - iou_score: 0.7061 - f1-score: 0.8256For batch 99, tr_loss is    0.28.\n",
      "101/225 [============>.................] - ETA: 1:48 - loss: 0.2782 - iou_score: 0.7058 - f1-score: 0.8254For batch 100, tr_loss is    0.28.\n",
      "102/225 [============>.................] - ETA: 1:47 - loss: 0.2779 - iou_score: 0.7063 - f1-score: 0.8257For batch 101, tr_loss is    0.28.\n",
      "103/225 [============>.................] - ETA: 1:46 - loss: 0.2781 - iou_score: 0.7061 - f1-score: 0.8255For batch 102, tr_loss is    0.28.\n",
      "104/225 [============>.................] - ETA: 1:46 - loss: 0.2779 - iou_score: 0.7063 - f1-score: 0.8257For batch 103, tr_loss is    0.28.\n",
      "105/225 [=============>................] - ETA: 1:45 - loss: 0.2777 - iou_score: 0.7068 - f1-score: 0.8261For batch 104, tr_loss is    0.28.\n",
      "106/225 [=============>................] - ETA: 1:44 - loss: 0.2771 - iou_score: 0.7073 - f1-score: 0.8264For batch 105, tr_loss is    0.28.\n",
      "107/225 [=============>................] - ETA: 1:43 - loss: 0.2767 - iou_score: 0.7078 - f1-score: 0.8267For batch 106, tr_loss is    0.28.\n",
      "108/225 [=============>................] - ETA: 1:43 - loss: 0.2767 - iou_score: 0.7075 - f1-score: 0.8265For batch 107, tr_loss is    0.28.\n",
      "109/225 [=============>................] - ETA: 1:42 - loss: 0.2762 - iou_score: 0.7079 - f1-score: 0.8268For batch 108, tr_loss is    0.28.\n",
      "110/225 [=============>................] - ETA: 1:41 - loss: 0.2760 - iou_score: 0.7083 - f1-score: 0.8271For batch 109, tr_loss is    0.28.\n",
      "111/225 [=============>................] - ETA: 1:40 - loss: 0.2764 - iou_score: 0.7079 - f1-score: 0.8268For batch 110, tr_loss is    0.28.\n",
      "112/225 [=============>................] - ETA: 1:39 - loss: 0.2761 - iou_score: 0.7082 - f1-score: 0.8270For batch 111, tr_loss is    0.28.\n",
      "113/225 [==============>...............] - ETA: 1:38 - loss: 0.2761 - iou_score: 0.7086 - f1-score: 0.8273For batch 112, tr_loss is    0.28.\n",
      "114/225 [==============>...............] - ETA: 1:37 - loss: 0.2756 - iou_score: 0.7094 - f1-score: 0.8278For batch 113, tr_loss is    0.28.\n",
      "115/225 [==============>...............] - ETA: 1:37 - loss: 0.2749 - iou_score: 0.7102 - f1-score: 0.8284For batch 114, tr_loss is    0.27.\n",
      "116/225 [==============>...............] - ETA: 1:36 - loss: 0.2743 - iou_score: 0.7108 - f1-score: 0.8288For batch 115, tr_loss is    0.27.\n",
      "117/225 [==============>...............] - ETA: 1:35 - loss: 0.2741 - iou_score: 0.7109 - f1-score: 0.8289For batch 116, tr_loss is    0.27.\n",
      "118/225 [==============>...............] - ETA: 1:34 - loss: 0.2741 - iou_score: 0.7109 - f1-score: 0.8289For batch 117, tr_loss is    0.27.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119/225 [==============>...............] - ETA: 1:33 - loss: 0.2738 - iou_score: 0.7112 - f1-score: 0.8291For batch 118, tr_loss is    0.27.\n",
      "120/225 [===============>..............] - ETA: 1:32 - loss: 0.2742 - iou_score: 0.7108 - f1-score: 0.8289For batch 119, tr_loss is    0.27.\n",
      "121/225 [===============>..............] - ETA: 1:31 - loss: 0.2739 - iou_score: 0.7111 - f1-score: 0.8290For batch 120, tr_loss is    0.27.\n",
      "122/225 [===============>..............] - ETA: 1:30 - loss: 0.2739 - iou_score: 0.7112 - f1-score: 0.8291For batch 121, tr_loss is    0.27.\n",
      "123/225 [===============>..............] - ETA: 1:30 - loss: 0.2735 - iou_score: 0.7119 - f1-score: 0.8295For batch 122, tr_loss is    0.27.\n",
      "124/225 [===============>..............] - ETA: 1:29 - loss: 0.2735 - iou_score: 0.7117 - f1-score: 0.8294For batch 123, tr_loss is    0.27.\n",
      "125/225 [===============>..............] - ETA: 1:27 - loss: 0.2736 - iou_score: 0.7116 - f1-score: 0.8294For batch 124, tr_loss is    0.27.\n",
      "126/225 [===============>..............] - ETA: 1:27 - loss: 0.2738 - iou_score: 0.7114 - f1-score: 0.8292For batch 125, tr_loss is    0.27.\n",
      "127/225 [===============>..............] - ETA: 1:26 - loss: 0.2736 - iou_score: 0.7114 - f1-score: 0.8292For batch 126, tr_loss is    0.27.\n",
      "128/225 [================>.............] - ETA: 1:25 - loss: 0.2734 - iou_score: 0.7117 - f1-score: 0.8294For batch 127, tr_loss is    0.27.\n",
      "129/225 [================>.............] - ETA: 1:24 - loss: 0.2741 - iou_score: 0.7108 - f1-score: 0.8288For batch 128, tr_loss is    0.27.\n",
      "130/225 [================>.............] - ETA: 1:23 - loss: 0.2737 - iou_score: 0.7113 - f1-score: 0.8291For batch 129, tr_loss is    0.27.\n",
      "131/225 [================>.............] - ETA: 1:22 - loss: 0.2738 - iou_score: 0.7112 - f1-score: 0.8291For batch 130, tr_loss is    0.27.\n",
      "132/225 [================>.............] - ETA: 1:22 - loss: 0.2734 - iou_score: 0.7118 - f1-score: 0.8294For batch 131, tr_loss is    0.27.\n",
      "133/225 [================>.............] - ETA: 1:20 - loss: 0.2738 - iou_score: 0.7113 - f1-score: 0.8291For batch 132, tr_loss is    0.27.\n",
      "134/225 [================>.............] - ETA: 1:19 - loss: 0.2735 - iou_score: 0.7117 - f1-score: 0.8294For batch 133, tr_loss is    0.27.\n",
      "135/225 [=================>............] - ETA: 1:19 - loss: 0.2736 - iou_score: 0.7117 - f1-score: 0.8294For batch 134, tr_loss is    0.27.\n",
      "136/225 [=================>............] - ETA: 1:17 - loss: 0.2738 - iou_score: 0.7114 - f1-score: 0.8292For batch 135, tr_loss is    0.27.\n",
      "137/225 [=================>............] - ETA: 1:17 - loss: 0.2740 - iou_score: 0.7113 - f1-score: 0.8291For batch 136, tr_loss is    0.27.\n",
      "138/225 [=================>............] - ETA: 1:16 - loss: 0.2743 - iou_score: 0.7112 - f1-score: 0.8291For batch 137, tr_loss is    0.27.\n",
      "139/225 [=================>............] - ETA: 1:15 - loss: 0.2744 - iou_score: 0.7110 - f1-score: 0.8290For batch 138, tr_loss is    0.27.\n",
      "140/225 [=================>............] - ETA: 1:14 - loss: 0.2751 - iou_score: 0.7103 - f1-score: 0.8285For batch 139, tr_loss is    0.28.\n",
      "141/225 [=================>............] - ETA: 1:14 - loss: 0.2748 - iou_score: 0.7108 - f1-score: 0.8288For batch 140, tr_loss is    0.27.\n",
      "142/225 [=================>............] - ETA: 1:13 - loss: 0.2748 - iou_score: 0.7108 - f1-score: 0.8288For batch 141, tr_loss is    0.27.\n",
      "143/225 [==================>...........] - ETA: 1:12 - loss: 0.2748 - iou_score: 0.7108 - f1-score: 0.8288For batch 142, tr_loss is    0.27.\n",
      "144/225 [==================>...........] - ETA: 1:11 - loss: 0.2751 - iou_score: 0.7107 - f1-score: 0.8287For batch 143, tr_loss is    0.28.\n",
      "145/225 [==================>...........] - ETA: 1:10 - loss: 0.2752 - iou_score: 0.7103 - f1-score: 0.8285For batch 144, tr_loss is    0.28.\n",
      "146/225 [==================>...........] - ETA: 1:09 - loss: 0.2751 - iou_score: 0.7106 - f1-score: 0.8286For batch 145, tr_loss is    0.28.\n",
      "147/225 [==================>...........] - ETA: 1:08 - loss: 0.2749 - iou_score: 0.7110 - f1-score: 0.8289For batch 146, tr_loss is    0.27.\n",
      "148/225 [==================>...........] - ETA: 1:07 - loss: 0.2750 - iou_score: 0.7110 - f1-score: 0.8289For batch 147, tr_loss is    0.27.\n",
      "149/225 [==================>...........] - ETA: 1:06 - loss: 0.2748 - iou_score: 0.7112 - f1-score: 0.8290For batch 148, tr_loss is    0.27.\n",
      "150/225 [===================>..........] - ETA: 1:06 - loss: 0.2749 - iou_score: 0.7109 - f1-score: 0.8289For batch 149, tr_loss is    0.27.\n",
      "151/225 [===================>..........] - ETA: 1:05 - loss: 0.2750 - iou_score: 0.7109 - f1-score: 0.8289For batch 150, tr_loss is    0.27.\n",
      "152/225 [===================>..........] - ETA: 1:04 - loss: 0.2749 - iou_score: 0.7111 - f1-score: 0.8290For batch 151, tr_loss is    0.27.\n",
      "153/225 [===================>..........] - ETA: 1:03 - loss: 0.2750 - iou_score: 0.7109 - f1-score: 0.8288For batch 152, tr_loss is    0.27.\n",
      "154/225 [===================>..........] - ETA: 1:02 - loss: 0.2749 - iou_score: 0.7110 - f1-score: 0.8289For batch 153, tr_loss is    0.27.\n",
      "155/225 [===================>..........] - ETA: 1:01 - loss: 0.2760 - iou_score: 0.7097 - f1-score: 0.8279For batch 154, tr_loss is    0.28.\n",
      "156/225 [===================>..........] - ETA: 1:00 - loss: 0.2763 - iou_score: 0.7093 - f1-score: 0.8277For batch 155, tr_loss is    0.28.\n",
      "157/225 [===================>..........] - ETA: 59s - loss: 0.2764 - iou_score: 0.7091 - f1-score: 0.8275 For batch 156, tr_loss is    0.28.\n",
      "158/225 [====================>.........] - ETA: 58s - loss: 0.2765 - iou_score: 0.7088 - f1-score: 0.8273For batch 157, tr_loss is    0.28.\n",
      "159/225 [====================>.........] - ETA: 57s - loss: 0.2765 - iou_score: 0.7089 - f1-score: 0.8274For batch 158, tr_loss is    0.28.\n",
      "160/225 [====================>.........] - ETA: 57s - loss: 0.2764 - iou_score: 0.7088 - f1-score: 0.8273For batch 159, tr_loss is    0.28.\n",
      "161/225 [====================>.........] - ETA: 56s - loss: 0.2760 - iou_score: 0.7093 - f1-score: 0.8277For batch 160, tr_loss is    0.28.\n",
      "162/225 [====================>.........] - ETA: 55s - loss: 0.2760 - iou_score: 0.7093 - f1-score: 0.8277For batch 161, tr_loss is    0.28.\n",
      "163/225 [====================>.........] - ETA: 54s - loss: 0.2761 - iou_score: 0.7089 - f1-score: 0.8274For batch 162, tr_loss is    0.28.\n",
      "164/225 [====================>.........] - ETA: 53s - loss: 0.2762 - iou_score: 0.7090 - f1-score: 0.8275For batch 163, tr_loss is    0.28.\n",
      "165/225 [=====================>........] - ETA: 52s - loss: 0.2763 - iou_score: 0.7089 - f1-score: 0.8274For batch 164, tr_loss is    0.28.\n",
      "166/225 [=====================>........] - ETA: 51s - loss: 0.2769 - iou_score: 0.7082 - f1-score: 0.8269For batch 165, tr_loss is    0.28.\n",
      "167/225 [=====================>........] - ETA: 50s - loss: 0.2766 - iou_score: 0.7084 - f1-score: 0.8271For batch 166, tr_loss is    0.28.\n",
      "168/225 [=====================>........] - ETA: 50s - loss: 0.2761 - iou_score: 0.7092 - f1-score: 0.8276For batch 167, tr_loss is    0.28.\n",
      "169/225 [=====================>........] - ETA: 49s - loss: 0.2759 - iou_score: 0.7094 - f1-score: 0.8277For batch 168, tr_loss is    0.28.\n",
      "170/225 [=====================>........] - ETA: 48s - loss: 0.2766 - iou_score: 0.7091 - f1-score: 0.8275For batch 169, tr_loss is    0.28.\n",
      "171/225 [=====================>........] - ETA: 47s - loss: 0.2769 - iou_score: 0.7087 - f1-score: 0.8272For batch 170, tr_loss is    0.28.\n",
      "172/225 [=====================>........] - ETA: 46s - loss: 0.2771 - iou_score: 0.7083 - f1-score: 0.8269For batch 171, tr_loss is    0.28.\n",
      "173/225 [======================>.......] - ETA: 45s - loss: 0.2775 - iou_score: 0.7077 - f1-score: 0.8266For batch 172, tr_loss is    0.28.\n",
      "174/225 [======================>.......] - ETA: 44s - loss: 0.2775 - iou_score: 0.7077 - f1-score: 0.8266For batch 173, tr_loss is    0.28.\n",
      "175/225 [======================>.......] - ETA: 43s - loss: 0.2778 - iou_score: 0.7074 - f1-score: 0.8263For batch 174, tr_loss is    0.28.\n",
      "176/225 [======================>.......] - ETA: 42s - loss: 0.2779 - iou_score: 0.7072 - f1-score: 0.8262For batch 175, tr_loss is    0.28.\n",
      "177/225 [======================>.......] - ETA: 42s - loss: 0.2775 - iou_score: 0.7078 - f1-score: 0.8266For batch 176, tr_loss is    0.28.\n",
      "178/225 [======================>.......] - ETA: 41s - loss: 0.2775 - iou_score: 0.7077 - f1-score: 0.8266For batch 177, tr_loss is    0.28.\n",
      "179/225 [======================>.......] - ETA: 40s - loss: 0.2775 - iou_score: 0.7079 - f1-score: 0.8267For batch 178, tr_loss is    0.28.\n",
      "180/225 [=======================>......] - ETA: 39s - loss: 0.2777 - iou_score: 0.7075 - f1-score: 0.8264For batch 179, tr_loss is    0.28.\n",
      "181/225 [=======================>......] - ETA: 38s - loss: 0.2780 - iou_score: 0.7073 - f1-score: 0.8263For batch 180, tr_loss is    0.28.\n",
      "182/225 [=======================>......] - ETA: 37s - loss: 0.2779 - iou_score: 0.7073 - f1-score: 0.8263For batch 181, tr_loss is    0.28.\n",
      "183/225 [=======================>......] - ETA: 36s - loss: 0.2781 - iou_score: 0.7071 - f1-score: 0.8262For batch 182, tr_loss is    0.28.\n",
      "184/225 [=======================>......] - ETA: 35s - loss: 0.2779 - iou_score: 0.7072 - f1-score: 0.8263For batch 183, tr_loss is    0.28.\n",
      "185/225 [=======================>......] - ETA: 34s - loss: 0.2778 - iou_score: 0.7073 - f1-score: 0.8263For batch 184, tr_loss is    0.28.\n",
      "186/225 [=======================>......] - ETA: 33s - loss: 0.2778 - iou_score: 0.7073 - f1-score: 0.8263For batch 185, tr_loss is    0.28.\n",
      "187/225 [=======================>......] - ETA: 33s - loss: 0.2777 - iou_score: 0.7076 - f1-score: 0.8265For batch 186, tr_loss is    0.28.\n",
      "188/225 [========================>.....] - ETA: 32s - loss: 0.2775 - iou_score: 0.7079 - f1-score: 0.8267For batch 187, tr_loss is    0.28.\n",
      "189/225 [========================>.....] - ETA: 31s - loss: 0.2773 - iou_score: 0.7082 - f1-score: 0.8269For batch 188, tr_loss is    0.28.\n",
      "190/225 [========================>.....] - ETA: 30s - loss: 0.2771 - iou_score: 0.7084 - f1-score: 0.8271For batch 189, tr_loss is    0.28.\n",
      "191/225 [========================>.....] - ETA: 29s - loss: 0.2769 - iou_score: 0.7086 - f1-score: 0.8273For batch 190, tr_loss is    0.28.\n",
      "192/225 [========================>.....] - ETA: 28s - loss: 0.2766 - iou_score: 0.7089 - f1-score: 0.8274For batch 191, tr_loss is    0.28.\n",
      "193/225 [========================>.....] - ETA: 27s - loss: 0.2766 - iou_score: 0.7089 - f1-score: 0.8275For batch 192, tr_loss is    0.28.\n",
      "194/225 [========================>.....] - ETA: 26s - loss: 0.2767 - iou_score: 0.7088 - f1-score: 0.8274For batch 193, tr_loss is    0.28.\n",
      "195/225 [=========================>....] - ETA: 26s - loss: 0.2767 - iou_score: 0.7089 - f1-score: 0.8275For batch 194, tr_loss is    0.28.\n",
      "196/225 [=========================>....] - ETA: 25s - loss: 0.2765 - iou_score: 0.7091 - f1-score: 0.8276For batch 195, tr_loss is    0.28.\n",
      "197/225 [=========================>....] - ETA: 24s - loss: 0.2768 - iou_score: 0.7088 - f1-score: 0.8274For batch 196, tr_loss is    0.28.\n",
      "198/225 [=========================>....] - ETA: 23s - loss: 0.2763 - iou_score: 0.7093 - f1-score: 0.8277For batch 197, tr_loss is    0.28.\n",
      "199/225 [=========================>....] - ETA: 22s - loss: 0.2769 - iou_score: 0.7086 - f1-score: 0.8272For batch 198, tr_loss is    0.28.\n",
      "200/225 [=========================>....] - ETA: 21s - loss: 0.2767 - iou_score: 0.7089 - f1-score: 0.8274For batch 199, tr_loss is    0.28.\n",
      "201/225 [=========================>....] - ETA: 20s - loss: 0.2768 - iou_score: 0.7087 - f1-score: 0.8273For batch 200, tr_loss is    0.28.\n",
      "202/225 [=========================>....] - ETA: 19s - loss: 0.2767 - iou_score: 0.7090 - f1-score: 0.8275For batch 201, tr_loss is    0.28.\n",
      "203/225 [==========================>...] - ETA: 19s - loss: 0.2766 - iou_score: 0.7092 - f1-score: 0.8276For batch 202, tr_loss is    0.28.\n",
      "204/225 [==========================>...] - ETA: 18s - loss: 0.2764 - iou_score: 0.7095 - f1-score: 0.8278For batch 203, tr_loss is    0.28.\n",
      "205/225 [==========================>...] - ETA: 17s - loss: 0.2762 - iou_score: 0.7096 - f1-score: 0.8279For batch 204, tr_loss is    0.28.\n",
      "206/225 [==========================>...] - ETA: 16s - loss: 0.2761 - iou_score: 0.7096 - f1-score: 0.8279For batch 205, tr_loss is    0.28.\n",
      "207/225 [==========================>...] - ETA: 15s - loss: 0.2763 - iou_score: 0.7095 - f1-score: 0.8278For batch 206, tr_loss is    0.28.\n",
      "208/225 [==========================>...] - ETA: 14s - loss: 0.2765 - iou_score: 0.7093 - f1-score: 0.8277For batch 207, tr_loss is    0.28.\n",
      "209/225 [==========================>...] - ETA: 13s - loss: 0.2763 - iou_score: 0.7096 - f1-score: 0.8279For batch 208, tr_loss is    0.28.\n",
      "210/225 [===========================>..] - ETA: 13s - loss: 0.2766 - iou_score: 0.7093 - f1-score: 0.8277For batch 209, tr_loss is    0.28.\n",
      "211/225 [===========================>..] - ETA: 12s - loss: 0.2766 - iou_score: 0.7091 - f1-score: 0.8276For batch 210, tr_loss is    0.28.\n",
      "212/225 [===========================>..] - ETA: 11s - loss: 0.2769 - iou_score: 0.7090 - f1-score: 0.8275For batch 211, tr_loss is    0.28.\n",
      "213/225 [===========================>..] - ETA: 10s - loss: 0.2769 - iou_score: 0.7088 - f1-score: 0.8274For batch 212, tr_loss is    0.28.\n",
      "214/225 [===========================>..] - ETA: 9s - loss: 0.2771 - iou_score: 0.7088 - f1-score: 0.8273 For batch 213, tr_loss is    0.28.\n",
      "215/225 [===========================>..] - ETA: 8s - loss: 0.2769 - iou_score: 0.7090 - f1-score: 0.8275For batch 214, tr_loss is    0.28.\n",
      "216/225 [===========================>..] - ETA: 7s - loss: 0.2766 - iou_score: 0.7093 - f1-score: 0.8277For batch 215, tr_loss is    0.28.\n",
      "217/225 [===========================>..] - ETA: 6s - loss: 0.2764 - iou_score: 0.7096 - f1-score: 0.8279For batch 216, tr_loss is    0.28.\n",
      "218/225 [============================>.] - ETA: 6s - loss: 0.2762 - iou_score: 0.7099 - f1-score: 0.8281For batch 217, tr_loss is    0.28.\n",
      "219/225 [============================>.] - ETA: 5s - loss: 0.2762 - iou_score: 0.7099 - f1-score: 0.8281For batch 218, tr_loss is    0.28.\n",
      "220/225 [============================>.] - ETA: 4s - loss: 0.2761 - iou_score: 0.7099 - f1-score: 0.8282For batch 219, tr_loss is    0.28.\n",
      "221/225 [============================>.] - ETA: 3s - loss: 0.2762 - iou_score: 0.7098 - f1-score: 0.8281For batch 220, tr_loss is    0.28.\n",
      "222/225 [============================>.] - ETA: 2s - loss: 0.2761 - iou_score: 0.7098 - f1-score: 0.8281For batch 221, tr_loss is    0.28.\n",
      "223/225 [============================>.] - ETA: 1s - loss: 0.2762 - iou_score: 0.7097 - f1-score: 0.8280For batch 222, tr_loss is    0.28.\n",
      "224/225 [============================>.] - ETA: 0s - loss: 0.2764 - iou_score: 0.7095 - f1-score: 0.8279For batch 223, tr_loss is    0.28.\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.2763 - iou_score: 0.7097 - f1-score: 0.8280For batch 224, tr_loss is    0.28.\n",
      "For batch 0, vl_loss is    0.40.\n",
      "For batch 1, vl_loss is    0.41.\n",
      "For batch 2, vl_loss is    0.46.\n",
      "For batch 3, vl_loss is    0.45.\n",
      "For batch 4, vl_loss is    0.43.\n",
      "For batch 5, vl_loss is    0.42.\n",
      "For batch 6, vl_loss is    0.42.\n",
      "For batch 7, vl_loss is    0.42.\n",
      "For batch 8, vl_loss is    0.42.\n",
      "For batch 9, vl_loss is    0.41.\n",
      "For batch 10, vl_loss is    0.41.\n",
      "For batch 11, vl_loss is    0.41.\n",
      "For batch 12, vl_loss is    0.40.\n",
      "For batch 13, vl_loss is    0.40.\n",
      "For batch 14, vl_loss is    0.41.\n",
      "For batch 15, vl_loss is    0.42.\n",
      "For batch 16, vl_loss is    0.41.\n",
      "For batch 17, vl_loss is    0.41.\n",
      "For batch 18, vl_loss is    0.41.\n",
      "For batch 19, vl_loss is    0.41.\n",
      "For batch 20, vl_loss is    0.42.\n",
      "For batch 21, vl_loss is    0.42.\n",
      "For batch 22, vl_loss is    0.42.\n",
      "For batch 23, vl_loss is    0.42.\n",
      "For batch 24, vl_loss is    0.42.\n",
      "For batch 25, vl_loss is    0.42.\n",
      "For batch 26, vl_loss is    0.42.\n",
      "For batch 27, vl_loss is    0.42.\n",
      "For batch 28, vl_loss is    0.42.\n",
      "For batch 29, vl_loss is    0.42.\n",
      "For batch 30, vl_loss is    0.42.\n",
      "For batch 31, vl_loss is    0.42.\n",
      "For batch 32, vl_loss is    0.42.\n",
      "For batch 33, vl_loss is    0.42.\n",
      "For batch 34, vl_loss is    0.42.\n",
      "For batch 35, vl_loss is    0.42.\n",
      "For batch 36, vl_loss is    0.42.\n",
      "For batch 37, vl_loss is    0.42.\n",
      "For batch 38, vl_loss is    0.42.\n",
      "For batch 39, vl_loss is    0.42.\n",
      "For batch 40, vl_loss is    0.41.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 41, vl_loss is    0.42.\n",
      "For batch 42, vl_loss is    0.41.\n",
      "For batch 43, vl_loss is    0.42.\n",
      "For batch 44, vl_loss is    0.42.\n",
      "For batch 45, vl_loss is    0.41.\n",
      "For batch 46, vl_loss is    0.41.\n",
      "For batch 47, vl_loss is    0.41.\n",
      "For batch 48, vl_loss is    0.41.\n",
      "For batch 49, vl_loss is    0.41.\n",
      "For batch 50, vl_loss is    0.41.\n",
      "For batch 51, vl_loss is    0.41.\n",
      "For batch 52, vl_loss is    0.41.\n",
      "For batch 53, vl_loss is    0.41.\n",
      "For batch 54, vl_loss is    0.41.\n",
      "For batch 55, vl_loss is    0.41.\n",
      "For batch 56, vl_loss is    0.41.\n",
      "For batch 57, vl_loss is    0.41.\n",
      "For batch 58, vl_loss is    0.41.\n",
      "For batch 59, vl_loss is    0.41.\n",
      "For batch 60, vl_loss is    0.41.\n",
      "For batch 61, vl_loss is    0.41.\n",
      "For batch 62, vl_loss is    0.41.\n",
      "For batch 63, vl_loss is    0.41.\n",
      "For batch 64, vl_loss is    0.41.\n",
      "For batch 65, vl_loss is    0.41.\n",
      "For batch 66, vl_loss is    0.41.\n",
      "For batch 67, vl_loss is    0.41.\n",
      "For batch 68, vl_loss is    0.41.\n",
      "For batch 69, vl_loss is    0.41.\n",
      "For batch 70, vl_loss is    0.41.\n",
      "For batch 71, vl_loss is    0.41.\n",
      "For batch 72, vl_loss is    0.41.\n",
      "For batch 73, vl_loss is    0.41.\n",
      "For batch 74, vl_loss is    0.41.\n",
      "225/225 [==============================] - 200s 878ms/step - loss: 0.2763 - iou_score: 0.7097 - f1-score: 0.8280 - val_loss: 0.4110 - val_iou_score: 0.6245 - val_f1-score: 0.7664\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.37292\n",
      "The average loss for epoch 6 is    0.28 \n",
      "Epoch 8/200\n",
      "  1/225 [..............................] - ETA: 7:33 - loss: 0.2856 - iou_score: 0.6949 - f1-score: 0.8196For batch 0, tr_loss is    0.29.\n",
      "  2/225 [..............................] - ETA: 5:29 - loss: 0.2721 - iou_score: 0.7039 - f1-score: 0.8260For batch 1, tr_loss is    0.27.\n",
      "  3/225 [..............................] - ETA: 4:39 - loss: 0.2684 - iou_score: 0.7025 - f1-score: 0.8248For batch 2, tr_loss is    0.27.\n",
      "  4/225 [..............................] - ETA: 4:27 - loss: 0.2670 - iou_score: 0.7129 - f1-score: 0.8315For batch 3, tr_loss is    0.27.\n",
      "  5/225 [..............................] - ETA: 4:34 - loss: 0.2652 - iou_score: 0.7163 - f1-score: 0.8337For batch 4, tr_loss is    0.27.\n",
      "  6/225 [..............................] - ETA: 4:32 - loss: 0.2646 - iou_score: 0.7204 - f1-score: 0.8364For batch 5, tr_loss is    0.26.\n",
      "  7/225 [..............................] - ETA: 4:34 - loss: 0.2640 - iou_score: 0.7170 - f1-score: 0.8338For batch 6, tr_loss is    0.26.\n",
      "  8/225 [>.............................] - ETA: 4:45 - loss: 0.2696 - iou_score: 0.7092 - f1-score: 0.8282For batch 7, tr_loss is    0.27.\n",
      "  9/225 [>.............................] - ETA: 4:45 - loss: 0.2625 - iou_score: 0.7180 - f1-score: 0.8340For batch 8, tr_loss is    0.26.\n",
      " 10/225 [>.............................] - ETA: 4:35 - loss: 0.2651 - iou_score: 0.7141 - f1-score: 0.8313For batch 9, tr_loss is    0.27.\n",
      " 11/225 [>.............................] - ETA: 4:18 - loss: 0.2648 - iou_score: 0.7135 - f1-score: 0.8307For batch 10, tr_loss is    0.26.\n",
      " 12/225 [>.............................] - ETA: 4:07 - loss: 0.2727 - iou_score: 0.7053 - f1-score: 0.8247For batch 11, tr_loss is    0.27.\n",
      " 13/225 [>.............................] - ETA: 4:04 - loss: 0.2743 - iou_score: 0.7015 - f1-score: 0.8221For batch 12, tr_loss is    0.27.\n",
      " 14/225 [>.............................] - ETA: 4:01 - loss: 0.2735 - iou_score: 0.7032 - f1-score: 0.8234For batch 13, tr_loss is    0.27.\n",
      " 15/225 [=>............................] - ETA: 3:53 - loss: 0.2742 - iou_score: 0.7020 - f1-score: 0.8227For batch 14, tr_loss is    0.27.\n",
      " 16/225 [=>............................] - ETA: 3:50 - loss: 0.2772 - iou_score: 0.7009 - f1-score: 0.8218For batch 15, tr_loss is    0.28.\n",
      " 17/225 [=>............................] - ETA: 3:48 - loss: 0.2750 - iou_score: 0.7040 - f1-score: 0.8240For batch 16, tr_loss is    0.27.\n",
      " 18/225 [=>............................] - ETA: 3:40 - loss: 0.2754 - iou_score: 0.7020 - f1-score: 0.8227For batch 17, tr_loss is    0.28.\n",
      " 19/225 [=>............................] - ETA: 3:35 - loss: 0.2743 - iou_score: 0.7031 - f1-score: 0.8235For batch 18, tr_loss is    0.27.\n",
      " 20/225 [=>............................] - ETA: 3:35 - loss: 0.2730 - iou_score: 0.7038 - f1-score: 0.8240For batch 19, tr_loss is    0.27.\n",
      " 21/225 [=>............................] - ETA: 3:31 - loss: 0.2731 - iou_score: 0.7046 - f1-score: 0.8246For batch 20, tr_loss is    0.27.\n",
      " 22/225 [=>............................] - ETA: 3:30 - loss: 0.2716 - iou_score: 0.7066 - f1-score: 0.8260For batch 21, tr_loss is    0.27.\n",
      " 23/225 [==>...........................] - ETA: 3:29 - loss: 0.2775 - iou_score: 0.7002 - f1-score: 0.8213For batch 22, tr_loss is    0.28.\n",
      " 24/225 [==>...........................] - ETA: 3:28 - loss: 0.2775 - iou_score: 0.6992 - f1-score: 0.8207For batch 23, tr_loss is    0.28.\n",
      " 25/225 [==>...........................] - ETA: 3:28 - loss: 0.2796 - iou_score: 0.6973 - f1-score: 0.8193For batch 24, tr_loss is    0.28.\n",
      " 26/225 [==>...........................] - ETA: 3:27 - loss: 0.2774 - iou_score: 0.7007 - f1-score: 0.8217For batch 25, tr_loss is    0.28.\n",
      " 27/225 [==>...........................] - ETA: 3:26 - loss: 0.2783 - iou_score: 0.6995 - f1-score: 0.8209For batch 26, tr_loss is    0.28.\n",
      " 28/225 [==>...........................] - ETA: 3:26 - loss: 0.2773 - iou_score: 0.7001 - f1-score: 0.8214For batch 27, tr_loss is    0.28.\n",
      " 29/225 [==>...........................] - ETA: 3:23 - loss: 0.2770 - iou_score: 0.7009 - f1-score: 0.8219For batch 28, tr_loss is    0.28.\n",
      " 30/225 [===>..........................] - ETA: 3:21 - loss: 0.2766 - iou_score: 0.7022 - f1-score: 0.8228For batch 29, tr_loss is    0.28.\n",
      " 31/225 [===>..........................] - ETA: 3:20 - loss: 0.2762 - iou_score: 0.7031 - f1-score: 0.8235For batch 30, tr_loss is    0.28.\n",
      " 32/225 [===>..........................] - ETA: 3:19 - loss: 0.2762 - iou_score: 0.7027 - f1-score: 0.8233For batch 31, tr_loss is    0.28.\n",
      " 33/225 [===>..........................] - ETA: 3:18 - loss: 0.2748 - iou_score: 0.7052 - f1-score: 0.8250For batch 32, tr_loss is    0.27.\n",
      " 34/225 [===>..........................] - ETA: 3:17 - loss: 0.2767 - iou_score: 0.7044 - f1-score: 0.8244For batch 33, tr_loss is    0.28.\n",
      " 35/225 [===>..........................] - ETA: 3:17 - loss: 0.2771 - iou_score: 0.7030 - f1-score: 0.8234For batch 34, tr_loss is    0.28.\n",
      " 36/225 [===>..........................] - ETA: 3:16 - loss: 0.2760 - iou_score: 0.7047 - f1-score: 0.8246For batch 35, tr_loss is    0.28.\n",
      " 37/225 [===>..........................] - ETA: 3:14 - loss: 0.2754 - iou_score: 0.7052 - f1-score: 0.8250For batch 36, tr_loss is    0.28.\n",
      " 38/225 [====>.........................] - ETA: 3:13 - loss: 0.2732 - iou_score: 0.7075 - f1-score: 0.8266For batch 37, tr_loss is    0.27.\n",
      " 39/225 [====>.........................] - ETA: 3:11 - loss: 0.2741 - iou_score: 0.7065 - f1-score: 0.8259For batch 38, tr_loss is    0.27.\n",
      " 40/225 [====>.........................] - ETA: 3:10 - loss: 0.2722 - iou_score: 0.7089 - f1-score: 0.8276For batch 39, tr_loss is    0.27.\n",
      " 41/225 [====>.........................] - ETA: 3:09 - loss: 0.2720 - iou_score: 0.7088 - f1-score: 0.8275For batch 40, tr_loss is    0.27.\n",
      " 42/225 [====>.........................] - ETA: 3:07 - loss: 0.2720 - iou_score: 0.7084 - f1-score: 0.8273For batch 41, tr_loss is    0.27.\n",
      " 43/225 [====>.........................] - ETA: 3:06 - loss: 0.2704 - iou_score: 0.7099 - f1-score: 0.8283For batch 42, tr_loss is    0.27.\n",
      " 44/225 [====>.........................] - ETA: 3:05 - loss: 0.2692 - iou_score: 0.7111 - f1-score: 0.8291For batch 43, tr_loss is    0.27.\n",
      " 45/225 [=====>........................] - ETA: 3:01 - loss: 0.2691 - iou_score: 0.7111 - f1-score: 0.8292For batch 44, tr_loss is    0.27.\n",
      " 46/225 [=====>........................] - ETA: 3:01 - loss: 0.2692 - iou_score: 0.7106 - f1-score: 0.8289For batch 45, tr_loss is    0.27.\n",
      " 47/225 [=====>........................] - ETA: 3:00 - loss: 0.2683 - iou_score: 0.7120 - f1-score: 0.8298For batch 46, tr_loss is    0.27.\n",
      " 48/225 [=====>........................] - ETA: 2:59 - loss: 0.2682 - iou_score: 0.7124 - f1-score: 0.8301For batch 47, tr_loss is    0.27.\n",
      " 49/225 [=====>........................] - ETA: 2:58 - loss: 0.2691 - iou_score: 0.7112 - f1-score: 0.8293For batch 48, tr_loss is    0.27.\n",
      " 50/225 [=====>........................] - ETA: 2:57 - loss: 0.2706 - iou_score: 0.7092 - f1-score: 0.8279For batch 49, tr_loss is    0.27.\n",
      " 51/225 [=====>........................] - ETA: 2:56 - loss: 0.2702 - iou_score: 0.7093 - f1-score: 0.8280For batch 50, tr_loss is    0.27.\n",
      " 52/225 [=====>........................] - ETA: 2:55 - loss: 0.2696 - iou_score: 0.7101 - f1-score: 0.8286For batch 51, tr_loss is    0.27.\n",
      " 53/225 [======>.......................] - ETA: 2:53 - loss: 0.2701 - iou_score: 0.7096 - f1-score: 0.8281For batch 52, tr_loss is    0.27.\n",
      " 54/225 [======>.......................] - ETA: 2:52 - loss: 0.2695 - iou_score: 0.7098 - f1-score: 0.8283For batch 53, tr_loss is    0.27.\n",
      " 55/225 [======>.......................] - ETA: 2:49 - loss: 0.2688 - iou_score: 0.7109 - f1-score: 0.8290For batch 54, tr_loss is    0.27.\n",
      " 56/225 [======>.......................] - ETA: 2:48 - loss: 0.2686 - iou_score: 0.7109 - f1-score: 0.8291For batch 55, tr_loss is    0.27.\n",
      " 57/225 [======>.......................] - ETA: 2:47 - loss: 0.2698 - iou_score: 0.7103 - f1-score: 0.8287For batch 56, tr_loss is    0.27.\n",
      " 58/225 [======>.......................] - ETA: 2:46 - loss: 0.2694 - iou_score: 0.7104 - f1-score: 0.8288For batch 57, tr_loss is    0.27.\n",
      " 59/225 [======>.......................] - ETA: 2:45 - loss: 0.2688 - iou_score: 0.7112 - f1-score: 0.8293For batch 58, tr_loss is    0.27.\n",
      " 60/225 [=======>......................] - ETA: 2:44 - loss: 0.2690 - iou_score: 0.7112 - f1-score: 0.8294For batch 59, tr_loss is    0.27.\n",
      " 61/225 [=======>......................] - ETA: 2:43 - loss: 0.2688 - iou_score: 0.7114 - f1-score: 0.8295For batch 60, tr_loss is    0.27.\n",
      " 62/225 [=======>......................] - ETA: 2:40 - loss: 0.2687 - iou_score: 0.7118 - f1-score: 0.8298For batch 61, tr_loss is    0.27.\n",
      " 63/225 [=======>......................] - ETA: 2:39 - loss: 0.2689 - iou_score: 0.7115 - f1-score: 0.8295For batch 62, tr_loss is    0.27.\n",
      " 64/225 [=======>......................] - ETA: 2:38 - loss: 0.2700 - iou_score: 0.7104 - f1-score: 0.8287For batch 63, tr_loss is    0.27.\n",
      " 65/225 [=======>......................] - ETA: 2:37 - loss: 0.2688 - iou_score: 0.7119 - f1-score: 0.8298For batch 64, tr_loss is    0.27.\n",
      " 66/225 [=======>......................] - ETA: 2:35 - loss: 0.2688 - iou_score: 0.7118 - f1-score: 0.8297For batch 65, tr_loss is    0.27.\n",
      " 67/225 [=======>......................] - ETA: 2:35 - loss: 0.2694 - iou_score: 0.7112 - f1-score: 0.8292For batch 66, tr_loss is    0.27.\n",
      " 68/225 [========>.....................] - ETA: 2:33 - loss: 0.2692 - iou_score: 0.7114 - f1-score: 0.8294For batch 67, tr_loss is    0.27.\n",
      " 69/225 [========>.....................] - ETA: 2:32 - loss: 0.2695 - iou_score: 0.7109 - f1-score: 0.8290For batch 68, tr_loss is    0.27.\n",
      " 70/225 [========>.....................] - ETA: 2:31 - loss: 0.2704 - iou_score: 0.7103 - f1-score: 0.8286For batch 69, tr_loss is    0.27.\n",
      " 71/225 [========>.....................] - ETA: 2:30 - loss: 0.2697 - iou_score: 0.7108 - f1-score: 0.8290For batch 70, tr_loss is    0.27.\n",
      " 72/225 [========>.....................] - ETA: 2:30 - loss: 0.2698 - iou_score: 0.7104 - f1-score: 0.8287For batch 71, tr_loss is    0.27.\n",
      " 73/225 [========>.....................] - ETA: 2:28 - loss: 0.2701 - iou_score: 0.7103 - f1-score: 0.8286For batch 72, tr_loss is    0.27.\n",
      " 74/225 [========>.....................] - ETA: 2:27 - loss: 0.2711 - iou_score: 0.7091 - f1-score: 0.8278For batch 73, tr_loss is    0.27.\n",
      " 75/225 [=========>....................] - ETA: 2:26 - loss: 0.2717 - iou_score: 0.7088 - f1-score: 0.8276For batch 74, tr_loss is    0.27.\n",
      " 76/225 [=========>....................] - ETA: 2:25 - loss: 0.2718 - iou_score: 0.7089 - f1-score: 0.8277For batch 75, tr_loss is    0.27.\n",
      " 77/225 [=========>....................] - ETA: 2:23 - loss: 0.2717 - iou_score: 0.7091 - f1-score: 0.8278For batch 76, tr_loss is    0.27.\n",
      " 78/225 [=========>....................] - ETA: 2:22 - loss: 0.2732 - iou_score: 0.7074 - f1-score: 0.8265For batch 77, tr_loss is    0.27.\n",
      " 79/225 [=========>....................] - ETA: 2:21 - loss: 0.2729 - iou_score: 0.7078 - f1-score: 0.8267For batch 78, tr_loss is    0.27.\n",
      " 80/225 [=========>....................] - ETA: 2:20 - loss: 0.2726 - iou_score: 0.7082 - f1-score: 0.8270For batch 79, tr_loss is    0.27.\n",
      " 81/225 [=========>....................] - ETA: 2:19 - loss: 0.2721 - iou_score: 0.7089 - f1-score: 0.8275For batch 80, tr_loss is    0.27.\n",
      " 82/225 [=========>....................] - ETA: 2:18 - loss: 0.2716 - iou_score: 0.7096 - f1-score: 0.8280For batch 81, tr_loss is    0.27.\n",
      " 83/225 [==========>...................] - ETA: 2:16 - loss: 0.2718 - iou_score: 0.7093 - f1-score: 0.8278For batch 82, tr_loss is    0.27.\n",
      " 84/225 [==========>...................] - ETA: 2:16 - loss: 0.2714 - iou_score: 0.7099 - f1-score: 0.8282For batch 83, tr_loss is    0.27.\n",
      " 85/225 [==========>...................] - ETA: 2:15 - loss: 0.2714 - iou_score: 0.7101 - f1-score: 0.8283For batch 84, tr_loss is    0.27.\n",
      " 86/225 [==========>...................] - ETA: 2:14 - loss: 0.2715 - iou_score: 0.7103 - f1-score: 0.8285For batch 85, tr_loss is    0.27.\n",
      " 87/225 [==========>...................] - ETA: 2:13 - loss: 0.2713 - iou_score: 0.7107 - f1-score: 0.8288For batch 86, tr_loss is    0.27.\n",
      " 88/225 [==========>...................] - ETA: 2:13 - loss: 0.2710 - iou_score: 0.7108 - f1-score: 0.8289For batch 87, tr_loss is    0.27.\n",
      " 89/225 [==========>...................] - ETA: 2:12 - loss: 0.2714 - iou_score: 0.7105 - f1-score: 0.8287For batch 88, tr_loss is    0.27.\n",
      " 90/225 [===========>..................] - ETA: 2:11 - loss: 0.2709 - iou_score: 0.7112 - f1-score: 0.8292For batch 89, tr_loss is    0.27.\n",
      " 91/225 [===========>..................] - ETA: 2:10 - loss: 0.2716 - iou_score: 0.7105 - f1-score: 0.8287For batch 90, tr_loss is    0.27.\n",
      " 92/225 [===========>..................] - ETA: 2:09 - loss: 0.2716 - iou_score: 0.7107 - f1-score: 0.8288For batch 91, tr_loss is    0.27.\n",
      " 93/225 [===========>..................] - ETA: 2:07 - loss: 0.2705 - iou_score: 0.7120 - f1-score: 0.8297For batch 92, tr_loss is    0.27.\n",
      " 94/225 [===========>..................] - ETA: 2:07 - loss: 0.2708 - iou_score: 0.7118 - f1-score: 0.8295For batch 93, tr_loss is    0.27.\n",
      " 95/225 [===========>..................] - ETA: 2:06 - loss: 0.2705 - iou_score: 0.7122 - f1-score: 0.8298For batch 94, tr_loss is    0.27.\n",
      " 96/225 [===========>..................] - ETA: 2:05 - loss: 0.2712 - iou_score: 0.7114 - f1-score: 0.8292For batch 95, tr_loss is    0.27.\n",
      " 97/225 [===========>..................] - ETA: 2:04 - loss: 0.2709 - iou_score: 0.7116 - f1-score: 0.8294For batch 96, tr_loss is    0.27.\n",
      " 98/225 [============>.................] - ETA: 2:02 - loss: 0.2711 - iou_score: 0.7109 - f1-score: 0.8289For batch 97, tr_loss is    0.27.\n",
      " 99/225 [============>.................] - ETA: 2:02 - loss: 0.2711 - iou_score: 0.7112 - f1-score: 0.8291For batch 98, tr_loss is    0.27.\n",
      "100/225 [============>.................] - ETA: 2:01 - loss: 0.2716 - iou_score: 0.7106 - f1-score: 0.8287For batch 99, tr_loss is    0.27.\n",
      "101/225 [============>.................] - ETA: 2:00 - loss: 0.2718 - iou_score: 0.7105 - f1-score: 0.8286For batch 100, tr_loss is    0.27.\n",
      "102/225 [============>.................] - ETA: 1:59 - loss: 0.2715 - iou_score: 0.7109 - f1-score: 0.8289For batch 101, tr_loss is    0.27.\n",
      "103/225 [============>.................] - ETA: 1:58 - loss: 0.2718 - iou_score: 0.7105 - f1-score: 0.8286For batch 102, tr_loss is    0.27.\n",
      "104/225 [============>.................] - ETA: 1:56 - loss: 0.2718 - iou_score: 0.7107 - f1-score: 0.8287For batch 103, tr_loss is    0.27.\n",
      "105/225 [=============>................] - ETA: 1:55 - loss: 0.2716 - iou_score: 0.7112 - f1-score: 0.8291For batch 104, tr_loss is    0.27.\n",
      "106/225 [=============>................] - ETA: 1:54 - loss: 0.2710 - iou_score: 0.7118 - f1-score: 0.8295For batch 105, tr_loss is    0.27.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/225 [=============>................] - ETA: 1:53 - loss: 0.2707 - iou_score: 0.7122 - f1-score: 0.8297For batch 106, tr_loss is    0.27.\n",
      "108/225 [=============>................] - ETA: 1:52 - loss: 0.2707 - iou_score: 0.7120 - f1-score: 0.8296For batch 107, tr_loss is    0.27.\n",
      "109/225 [=============>................] - ETA: 1:51 - loss: 0.2702 - iou_score: 0.7124 - f1-score: 0.8299For batch 108, tr_loss is    0.27.\n",
      "110/225 [=============>................] - ETA: 1:50 - loss: 0.2700 - iou_score: 0.7127 - f1-score: 0.8301For batch 109, tr_loss is    0.27.\n",
      "111/225 [=============>................] - ETA: 1:49 - loss: 0.2704 - iou_score: 0.7122 - f1-score: 0.8298For batch 110, tr_loss is    0.27.\n",
      "112/225 [=============>................] - ETA: 1:49 - loss: 0.2702 - iou_score: 0.7124 - f1-score: 0.8299For batch 111, tr_loss is    0.27.\n",
      "113/225 [==============>...............] - ETA: 1:48 - loss: 0.2700 - iou_score: 0.7129 - f1-score: 0.8303For batch 112, tr_loss is    0.27.\n",
      "114/225 [==============>...............] - ETA: 1:47 - loss: 0.2695 - iou_score: 0.7137 - f1-score: 0.8308For batch 113, tr_loss is    0.27.\n",
      "115/225 [==============>...............] - ETA: 1:46 - loss: 0.2688 - iou_score: 0.7145 - f1-score: 0.8313For batch 114, tr_loss is    0.27.\n",
      "116/225 [==============>...............] - ETA: 1:45 - loss: 0.2682 - iou_score: 0.7151 - f1-score: 0.8317For batch 115, tr_loss is    0.27.\n",
      "117/225 [==============>...............] - ETA: 1:44 - loss: 0.2684 - iou_score: 0.7151 - f1-score: 0.8318For batch 116, tr_loss is    0.27.\n",
      "118/225 [==============>...............] - ETA: 1:43 - loss: 0.2684 - iou_score: 0.7151 - f1-score: 0.8318For batch 117, tr_loss is    0.27.\n",
      "119/225 [==============>...............] - ETA: 1:42 - loss: 0.2682 - iou_score: 0.7154 - f1-score: 0.8320For batch 118, tr_loss is    0.27.\n",
      "120/225 [===============>..............] - ETA: 1:41 - loss: 0.2683 - iou_score: 0.7152 - f1-score: 0.8319For batch 119, tr_loss is    0.27.\n",
      "121/225 [===============>..............] - ETA: 1:40 - loss: 0.2679 - iou_score: 0.7156 - f1-score: 0.8322For batch 120, tr_loss is    0.27.\n",
      "122/225 [===============>..............] - ETA: 1:39 - loss: 0.2676 - iou_score: 0.7159 - f1-score: 0.8323For batch 121, tr_loss is    0.27.\n",
      "123/225 [===============>..............] - ETA: 1:38 - loss: 0.2672 - iou_score: 0.7163 - f1-score: 0.8326For batch 122, tr_loss is    0.27.\n",
      "124/225 [===============>..............] - ETA: 1:37 - loss: 0.2672 - iou_score: 0.7160 - f1-score: 0.8324For batch 123, tr_loss is    0.27.\n",
      "125/225 [===============>..............] - ETA: 1:36 - loss: 0.2676 - iou_score: 0.7159 - f1-score: 0.8323For batch 124, tr_loss is    0.27.\n",
      "126/225 [===============>..............] - ETA: 1:35 - loss: 0.2677 - iou_score: 0.7157 - f1-score: 0.8322For batch 125, tr_loss is    0.27.\n",
      "127/225 [===============>..............] - ETA: 1:33 - loss: 0.2675 - iou_score: 0.7156 - f1-score: 0.8321For batch 126, tr_loss is    0.27.\n",
      "128/225 [================>.............] - ETA: 1:32 - loss: 0.2673 - iou_score: 0.7159 - f1-score: 0.8323For batch 127, tr_loss is    0.27.\n",
      "129/225 [================>.............] - ETA: 1:31 - loss: 0.2679 - iou_score: 0.7151 - f1-score: 0.8317For batch 128, tr_loss is    0.27.\n",
      "130/225 [================>.............] - ETA: 1:30 - loss: 0.2675 - iou_score: 0.7156 - f1-score: 0.8321For batch 129, tr_loss is    0.27.\n",
      "131/225 [================>.............] - ETA: 1:29 - loss: 0.2676 - iou_score: 0.7153 - f1-score: 0.8319For batch 130, tr_loss is    0.27.\n",
      "132/225 [================>.............] - ETA: 1:28 - loss: 0.2672 - iou_score: 0.7159 - f1-score: 0.8323For batch 131, tr_loss is    0.27.\n",
      "133/225 [================>.............] - ETA: 1:27 - loss: 0.2677 - iou_score: 0.7155 - f1-score: 0.8320For batch 132, tr_loss is    0.27.\n",
      "134/225 [================>.............] - ETA: 1:26 - loss: 0.2673 - iou_score: 0.7160 - f1-score: 0.8323For batch 133, tr_loss is    0.27.\n",
      "135/225 [=================>............] - ETA: 1:25 - loss: 0.2675 - iou_score: 0.7159 - f1-score: 0.8323For batch 134, tr_loss is    0.27.\n",
      "136/225 [=================>............] - ETA: 1:24 - loss: 0.2678 - iou_score: 0.7155 - f1-score: 0.8320For batch 135, tr_loss is    0.27.\n",
      "137/225 [=================>............] - ETA: 1:23 - loss: 0.2677 - iou_score: 0.7156 - f1-score: 0.8321For batch 136, tr_loss is    0.27.\n",
      "138/225 [=================>............] - ETA: 1:22 - loss: 0.2679 - iou_score: 0.7156 - f1-score: 0.8321For batch 137, tr_loss is    0.27.\n",
      "139/225 [=================>............] - ETA: 1:21 - loss: 0.2682 - iou_score: 0.7154 - f1-score: 0.8320For batch 138, tr_loss is    0.27.\n",
      "140/225 [=================>............] - ETA: 1:20 - loss: 0.2694 - iou_score: 0.7147 - f1-score: 0.8315For batch 139, tr_loss is    0.27.\n",
      "141/225 [=================>............] - ETA: 1:19 - loss: 0.2692 - iou_score: 0.7151 - f1-score: 0.8317For batch 140, tr_loss is    0.27.\n",
      "142/225 [=================>............] - ETA: 1:18 - loss: 0.2689 - iou_score: 0.7153 - f1-score: 0.8319For batch 141, tr_loss is    0.27.\n",
      "143/225 [==================>...........] - ETA: 1:17 - loss: 0.2691 - iou_score: 0.7151 - f1-score: 0.8318For batch 142, tr_loss is    0.27.\n",
      "144/225 [==================>...........] - ETA: 1:16 - loss: 0.2692 - iou_score: 0.7151 - f1-score: 0.8318For batch 143, tr_loss is    0.27.\n",
      "145/225 [==================>...........] - ETA: 1:15 - loss: 0.2694 - iou_score: 0.7148 - f1-score: 0.8315For batch 144, tr_loss is    0.27.\n",
      "146/225 [==================>...........] - ETA: 1:14 - loss: 0.2693 - iou_score: 0.7149 - f1-score: 0.8316For batch 145, tr_loss is    0.27.\n",
      "147/225 [==================>...........] - ETA: 1:13 - loss: 0.2689 - iou_score: 0.7156 - f1-score: 0.8321For batch 146, tr_loss is    0.27.\n",
      "148/225 [==================>...........] - ETA: 1:12 - loss: 0.2690 - iou_score: 0.7156 - f1-score: 0.8321For batch 147, tr_loss is    0.27.\n",
      "149/225 [==================>...........] - ETA: 1:11 - loss: 0.2690 - iou_score: 0.7157 - f1-score: 0.8322For batch 148, tr_loss is    0.27.\n",
      "150/225 [===================>..........] - ETA: 1:10 - loss: 0.2691 - iou_score: 0.7154 - f1-score: 0.8320For batch 149, tr_loss is    0.27.\n",
      "151/225 [===================>..........] - ETA: 1:09 - loss: 0.2691 - iou_score: 0.7155 - f1-score: 0.8320For batch 150, tr_loss is    0.27.\n",
      "152/225 [===================>..........] - ETA: 1:08 - loss: 0.2690 - iou_score: 0.7156 - f1-score: 0.8321For batch 151, tr_loss is    0.27.\n",
      "153/225 [===================>..........] - ETA: 1:07 - loss: 0.2689 - iou_score: 0.7156 - f1-score: 0.8321For batch 152, tr_loss is    0.27.\n",
      "154/225 [===================>..........] - ETA: 1:07 - loss: 0.2688 - iou_score: 0.7156 - f1-score: 0.8322For batch 153, tr_loss is    0.27.\n",
      "155/225 [===================>..........] - ETA: 1:06 - loss: 0.2697 - iou_score: 0.7147 - f1-score: 0.8314For batch 154, tr_loss is    0.27.\n",
      "156/225 [===================>..........] - ETA: 1:05 - loss: 0.2701 - iou_score: 0.7141 - f1-score: 0.8311For batch 155, tr_loss is    0.27.\n",
      "157/225 [===================>..........] - ETA: 1:04 - loss: 0.2702 - iou_score: 0.7140 - f1-score: 0.8309For batch 156, tr_loss is    0.27.\n",
      "158/225 [====================>.........] - ETA: 1:03 - loss: 0.2705 - iou_score: 0.7137 - f1-score: 0.8308For batch 157, tr_loss is    0.27.\n",
      "159/225 [====================>.........] - ETA: 1:02 - loss: 0.2705 - iou_score: 0.7137 - f1-score: 0.8308For batch 158, tr_loss is    0.27.\n",
      "160/225 [====================>.........] - ETA: 1:01 - loss: 0.2705 - iou_score: 0.7136 - f1-score: 0.8307For batch 159, tr_loss is    0.27.\n",
      "161/225 [====================>.........] - ETA: 1:00 - loss: 0.2701 - iou_score: 0.7141 - f1-score: 0.8310For batch 160, tr_loss is    0.27.\n",
      "162/225 [====================>.........] - ETA: 59s - loss: 0.2701 - iou_score: 0.7140 - f1-score: 0.8310 For batch 161, tr_loss is    0.27.\n",
      "163/225 [====================>.........] - ETA: 58s - loss: 0.2704 - iou_score: 0.7135 - f1-score: 0.8307For batch 162, tr_loss is    0.27.\n",
      "164/225 [====================>.........] - ETA: 57s - loss: 0.2704 - iou_score: 0.7136 - f1-score: 0.8307For batch 163, tr_loss is    0.27.\n",
      "165/225 [=====================>........] - ETA: 56s - loss: 0.2704 - iou_score: 0.7137 - f1-score: 0.8308For batch 164, tr_loss is    0.27.\n",
      "166/225 [=====================>........] - ETA: 55s - loss: 0.2710 - iou_score: 0.7131 - f1-score: 0.8304For batch 165, tr_loss is    0.27.\n",
      "167/225 [=====================>........] - ETA: 54s - loss: 0.2708 - iou_score: 0.7132 - f1-score: 0.8305For batch 166, tr_loss is    0.27.\n",
      "168/225 [=====================>........] - ETA: 53s - loss: 0.2704 - iou_score: 0.7138 - f1-score: 0.8309For batch 167, tr_loss is    0.27.\n",
      "169/225 [=====================>........] - ETA: 52s - loss: 0.2702 - iou_score: 0.7140 - f1-score: 0.8310For batch 168, tr_loss is    0.27.\n",
      "170/225 [=====================>........] - ETA: 51s - loss: 0.2706 - iou_score: 0.7138 - f1-score: 0.8308For batch 169, tr_loss is    0.27.\n",
      "171/225 [=====================>........] - ETA: 50s - loss: 0.2711 - iou_score: 0.7133 - f1-score: 0.8305For batch 170, tr_loss is    0.27.\n",
      "172/225 [=====================>........] - ETA: 49s - loss: 0.2712 - iou_score: 0.7129 - f1-score: 0.8302For batch 171, tr_loss is    0.27.\n",
      "173/225 [======================>.......] - ETA: 48s - loss: 0.2716 - iou_score: 0.7124 - f1-score: 0.8299For batch 172, tr_loss is    0.27.\n",
      "174/225 [======================>.......] - ETA: 47s - loss: 0.2716 - iou_score: 0.7125 - f1-score: 0.8299For batch 173, tr_loss is    0.27.\n",
      "175/225 [======================>.......] - ETA: 46s - loss: 0.2720 - iou_score: 0.7120 - f1-score: 0.8296For batch 174, tr_loss is    0.27.\n",
      "176/225 [======================>.......] - ETA: 45s - loss: 0.2721 - iou_score: 0.7119 - f1-score: 0.8295For batch 175, tr_loss is    0.27.\n",
      "177/225 [======================>.......] - ETA: 44s - loss: 0.2717 - iou_score: 0.7124 - f1-score: 0.8299For batch 176, tr_loss is    0.27.\n",
      "178/225 [======================>.......] - ETA: 43s - loss: 0.2716 - iou_score: 0.7125 - f1-score: 0.8299For batch 177, tr_loss is    0.27.\n",
      "179/225 [======================>.......] - ETA: 43s - loss: 0.2715 - iou_score: 0.7126 - f1-score: 0.8300For batch 178, tr_loss is    0.27.\n",
      "180/225 [=======================>......] - ETA: 42s - loss: 0.2717 - iou_score: 0.7123 - f1-score: 0.8298For batch 179, tr_loss is    0.27.\n",
      "181/225 [=======================>......] - ETA: 41s - loss: 0.2718 - iou_score: 0.7122 - f1-score: 0.8298For batch 180, tr_loss is    0.27.\n",
      "182/225 [=======================>......] - ETA: 40s - loss: 0.2718 - iou_score: 0.7123 - f1-score: 0.8298For batch 181, tr_loss is    0.27.\n",
      "183/225 [=======================>......] - ETA: 39s - loss: 0.2719 - iou_score: 0.7121 - f1-score: 0.8297For batch 182, tr_loss is    0.27.\n",
      "184/225 [=======================>......] - ETA: 38s - loss: 0.2717 - iou_score: 0.7122 - f1-score: 0.8298For batch 183, tr_loss is    0.27.\n",
      "185/225 [=======================>......] - ETA: 37s - loss: 0.2716 - iou_score: 0.7123 - f1-score: 0.8299For batch 184, tr_loss is    0.27.\n",
      "186/225 [=======================>......] - ETA: 36s - loss: 0.2715 - iou_score: 0.7125 - f1-score: 0.8300For batch 185, tr_loss is    0.27.\n",
      "187/225 [=======================>......] - ETA: 35s - loss: 0.2713 - iou_score: 0.7127 - f1-score: 0.8302For batch 186, tr_loss is    0.27.\n",
      "188/225 [========================>.....] - ETA: 34s - loss: 0.2710 - iou_score: 0.7131 - f1-score: 0.8304For batch 187, tr_loss is    0.27.\n",
      "189/225 [========================>.....] - ETA: 33s - loss: 0.2707 - iou_score: 0.7134 - f1-score: 0.8307For batch 188, tr_loss is    0.27.\n",
      "190/225 [========================>.....] - ETA: 32s - loss: 0.2706 - iou_score: 0.7135 - f1-score: 0.8307For batch 189, tr_loss is    0.27.\n",
      "191/225 [========================>.....] - ETA: 31s - loss: 0.2703 - iou_score: 0.7138 - f1-score: 0.8309For batch 190, tr_loss is    0.27.\n",
      "192/225 [========================>.....] - ETA: 30s - loss: 0.2700 - iou_score: 0.7140 - f1-score: 0.8311For batch 191, tr_loss is    0.27.\n",
      "193/225 [========================>.....] - ETA: 29s - loss: 0.2701 - iou_score: 0.7141 - f1-score: 0.8311For batch 192, tr_loss is    0.27.\n",
      "194/225 [========================>.....] - ETA: 28s - loss: 0.2702 - iou_score: 0.7140 - f1-score: 0.8311For batch 193, tr_loss is    0.27.\n",
      "195/225 [=========================>....] - ETA: 27s - loss: 0.2700 - iou_score: 0.7143 - f1-score: 0.8313For batch 194, tr_loss is    0.27.\n",
      "196/225 [=========================>....] - ETA: 27s - loss: 0.2699 - iou_score: 0.7144 - f1-score: 0.8313For batch 195, tr_loss is    0.27.\n",
      "197/225 [=========================>....] - ETA: 26s - loss: 0.2702 - iou_score: 0.7140 - f1-score: 0.8311For batch 196, tr_loss is    0.27.\n",
      "198/225 [=========================>....] - ETA: 25s - loss: 0.2699 - iou_score: 0.7144 - f1-score: 0.8313For batch 197, tr_loss is    0.27.\n",
      "199/225 [=========================>....] - ETA: 24s - loss: 0.2705 - iou_score: 0.7138 - f1-score: 0.8309For batch 198, tr_loss is    0.27.\n",
      "200/225 [=========================>....] - ETA: 23s - loss: 0.2703 - iou_score: 0.7141 - f1-score: 0.8311For batch 199, tr_loss is    0.27.\n",
      "201/225 [=========================>....] - ETA: 22s - loss: 0.2704 - iou_score: 0.7139 - f1-score: 0.8310For batch 200, tr_loss is    0.27.\n",
      "202/225 [=========================>....] - ETA: 21s - loss: 0.2702 - iou_score: 0.7142 - f1-score: 0.8312For batch 201, tr_loss is    0.27.\n",
      "203/225 [==========================>...] - ETA: 20s - loss: 0.2701 - iou_score: 0.7144 - f1-score: 0.8313For batch 202, tr_loss is    0.27.\n",
      "204/225 [==========================>...] - ETA: 19s - loss: 0.2698 - iou_score: 0.7148 - f1-score: 0.8316For batch 203, tr_loss is    0.27.\n",
      "205/225 [==========================>...] - ETA: 18s - loss: 0.2698 - iou_score: 0.7149 - f1-score: 0.8317For batch 204, tr_loss is    0.27.\n",
      "206/225 [==========================>...] - ETA: 17s - loss: 0.2698 - iou_score: 0.7149 - f1-score: 0.8317For batch 205, tr_loss is    0.27.\n",
      "207/225 [==========================>...] - ETA: 16s - loss: 0.2698 - iou_score: 0.7148 - f1-score: 0.8316For batch 206, tr_loss is    0.27.\n",
      "208/225 [==========================>...] - ETA: 15s - loss: 0.2700 - iou_score: 0.7146 - f1-score: 0.8315For batch 207, tr_loss is    0.27.\n",
      "209/225 [==========================>...] - ETA: 14s - loss: 0.2698 - iou_score: 0.7149 - f1-score: 0.8317For batch 208, tr_loss is    0.27.\n",
      "210/225 [===========================>..] - ETA: 13s - loss: 0.2701 - iou_score: 0.7147 - f1-score: 0.8315For batch 209, tr_loss is    0.27.\n",
      "211/225 [===========================>..] - ETA: 12s - loss: 0.2701 - iou_score: 0.7147 - f1-score: 0.8315For batch 210, tr_loss is    0.27.\n",
      "212/225 [===========================>..] - ETA: 12s - loss: 0.2702 - iou_score: 0.7145 - f1-score: 0.8314For batch 211, tr_loss is    0.27.\n",
      "213/225 [===========================>..] - ETA: 11s - loss: 0.2704 - iou_score: 0.7142 - f1-score: 0.8312For batch 212, tr_loss is    0.27.\n",
      "214/225 [===========================>..] - ETA: 10s - loss: 0.2706 - iou_score: 0.7143 - f1-score: 0.8313For batch 213, tr_loss is    0.27.\n",
      "215/225 [===========================>..] - ETA: 9s - loss: 0.2703 - iou_score: 0.7145 - f1-score: 0.8314 For batch 214, tr_loss is    0.27.\n",
      "216/225 [===========================>..] - ETA: 8s - loss: 0.2701 - iou_score: 0.7148 - f1-score: 0.8316For batch 215, tr_loss is    0.27.\n",
      "217/225 [===========================>..] - ETA: 7s - loss: 0.2699 - iou_score: 0.7151 - f1-score: 0.8319For batch 216, tr_loss is    0.27.\n",
      "218/225 [============================>.] - ETA: 6s - loss: 0.2697 - iou_score: 0.7155 - f1-score: 0.8321For batch 217, tr_loss is    0.27.\n",
      "219/225 [============================>.] - ETA: 5s - loss: 0.2696 - iou_score: 0.7155 - f1-score: 0.8321For batch 218, tr_loss is    0.27.\n",
      "220/225 [============================>.] - ETA: 4s - loss: 0.2695 - iou_score: 0.7156 - f1-score: 0.8322For batch 219, tr_loss is    0.27.\n",
      "221/225 [============================>.] - ETA: 3s - loss: 0.2696 - iou_score: 0.7155 - f1-score: 0.8321For batch 220, tr_loss is    0.27.\n",
      "222/225 [============================>.] - ETA: 2s - loss: 0.2696 - iou_score: 0.7154 - f1-score: 0.8320For batch 221, tr_loss is    0.27.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/225 [============================>.] - ETA: 1s - loss: 0.2698 - iou_score: 0.7152 - f1-score: 0.8319For batch 222, tr_loss is    0.27.\n",
      "224/225 [============================>.] - ETA: 0s - loss: 0.2700 - iou_score: 0.7150 - f1-score: 0.8318For batch 223, tr_loss is    0.27.\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.2698 - iou_score: 0.7153 - f1-score: 0.8320For batch 224, tr_loss is    0.27.\n",
      "For batch 0, vl_loss is    0.38.\n",
      "For batch 1, vl_loss is    0.37.\n",
      "For batch 2, vl_loss is    0.42.\n",
      "For batch 3, vl_loss is    0.41.\n",
      "For batch 4, vl_loss is    0.38.\n",
      "For batch 5, vl_loss is    0.39.\n",
      "For batch 6, vl_loss is    0.39.\n",
      "For batch 7, vl_loss is    0.39.\n",
      "For batch 8, vl_loss is    0.39.\n",
      "For batch 9, vl_loss is    0.39.\n",
      "For batch 10, vl_loss is    0.38.\n",
      "For batch 11, vl_loss is    0.38.\n",
      "For batch 12, vl_loss is    0.38.\n",
      "For batch 13, vl_loss is    0.37.\n",
      "For batch 14, vl_loss is    0.38.\n",
      "For batch 15, vl_loss is    0.39.\n",
      "For batch 16, vl_loss is    0.39.\n",
      "For batch 17, vl_loss is    0.39.\n",
      "For batch 18, vl_loss is    0.39.\n",
      "For batch 19, vl_loss is    0.39.\n",
      "For batch 20, vl_loss is    0.40.\n",
      "For batch 21, vl_loss is    0.40.\n",
      "For batch 22, vl_loss is    0.40.\n",
      "For batch 23, vl_loss is    0.40.\n",
      "For batch 24, vl_loss is    0.40.\n",
      "For batch 25, vl_loss is    0.40.\n",
      "For batch 26, vl_loss is    0.40.\n",
      "For batch 27, vl_loss is    0.40.\n",
      "For batch 28, vl_loss is    0.40.\n",
      "For batch 29, vl_loss is    0.40.\n",
      "For batch 30, vl_loss is    0.40.\n",
      "For batch 31, vl_loss is    0.40.\n",
      "For batch 32, vl_loss is    0.40.\n",
      "For batch 33, vl_loss is    0.40.\n",
      "For batch 34, vl_loss is    0.40.\n",
      "For batch 35, vl_loss is    0.40.\n",
      "For batch 36, vl_loss is    0.40.\n",
      "For batch 37, vl_loss is    0.40.\n",
      "For batch 38, vl_loss is    0.40.\n",
      "For batch 39, vl_loss is    0.40.\n",
      "For batch 40, vl_loss is    0.40.\n",
      "For batch 41, vl_loss is    0.40.\n",
      "For batch 42, vl_loss is    0.39.\n",
      "For batch 43, vl_loss is    0.40.\n",
      "For batch 44, vl_loss is    0.40.\n",
      "For batch 45, vl_loss is    0.39.\n",
      "For batch 46, vl_loss is    0.39.\n",
      "For batch 47, vl_loss is    0.39.\n",
      "For batch 48, vl_loss is    0.39.\n",
      "For batch 49, vl_loss is    0.39.\n",
      "For batch 50, vl_loss is    0.39.\n",
      "For batch 51, vl_loss is    0.39.\n",
      "For batch 52, vl_loss is    0.39.\n",
      "For batch 53, vl_loss is    0.39.\n",
      "For batch 54, vl_loss is    0.40.\n",
      "For batch 55, vl_loss is    0.39.\n",
      "For batch 56, vl_loss is    0.39.\n",
      "For batch 57, vl_loss is    0.40.\n",
      "For batch 58, vl_loss is    0.40.\n",
      "For batch 59, vl_loss is    0.39.\n",
      "For batch 60, vl_loss is    0.40.\n",
      "For batch 61, vl_loss is    0.40.\n",
      "For batch 62, vl_loss is    0.39.\n",
      "For batch 63, vl_loss is    0.39.\n",
      "For batch 64, vl_loss is    0.40.\n",
      "For batch 65, vl_loss is    0.39.\n",
      "For batch 66, vl_loss is    0.40.\n",
      "For batch 67, vl_loss is    0.40.\n",
      "For batch 68, vl_loss is    0.40.\n",
      "For batch 69, vl_loss is    0.40.\n",
      "For batch 70, vl_loss is    0.40.\n",
      "For batch 71, vl_loss is    0.40.\n",
      "For batch 72, vl_loss is    0.40.\n",
      "For batch 73, vl_loss is    0.40.\n",
      "For batch 74, vl_loss is    0.40.\n",
      "225/225 [==============================] - 211s 935ms/step - loss: 0.2698 - iou_score: 0.7153 - f1-score: 0.8320 - val_loss: 0.3956 - val_iou_score: 0.6454 - val_f1-score: 0.7822\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.37292\n",
      "The average loss for epoch 7 is    0.27 \n",
      "Epoch 9/200\n",
      "  1/225 [..............................] - ETA: 8:34 - loss: 0.3000 - iou_score: 0.6792 - f1-score: 0.8089For batch 0, tr_loss is    0.30.\n",
      "  2/225 [..............................] - ETA: 5:38 - loss: 0.2783 - iou_score: 0.6998 - f1-score: 0.8232For batch 1, tr_loss is    0.28.\n",
      "  3/225 [..............................] - ETA: 4:39 - loss: 0.2789 - iou_score: 0.6980 - f1-score: 0.8218For batch 2, tr_loss is    0.28.\n",
      "  4/225 [..............................] - ETA: 4:35 - loss: 0.2791 - iou_score: 0.7021 - f1-score: 0.8244For batch 3, tr_loss is    0.28.\n",
      "  5/225 [..............................] - ETA: 4:57 - loss: 0.2748 - iou_score: 0.7093 - f1-score: 0.8293For batch 4, tr_loss is    0.27.\n",
      "  6/225 [..............................] - ETA: 5:06 - loss: 0.2753 - iou_score: 0.7119 - f1-score: 0.8310For batch 5, tr_loss is    0.28.\n",
      "  7/225 [..............................] - ETA: 5:04 - loss: 0.2776 - iou_score: 0.7081 - f1-score: 0.8280For batch 6, tr_loss is    0.28.\n",
      "  8/225 [>.............................] - ETA: 4:59 - loss: 0.2787 - iou_score: 0.7027 - f1-score: 0.8243For batch 7, tr_loss is    0.28.\n",
      "  9/225 [>.............................] - ETA: 5:03 - loss: 0.2699 - iou_score: 0.7125 - f1-score: 0.8304For batch 8, tr_loss is    0.27.\n",
      " 10/225 [>.............................] - ETA: 4:54 - loss: 0.2714 - iou_score: 0.7091 - f1-score: 0.8282For batch 9, tr_loss is    0.27.\n",
      " 11/225 [>.............................] - ETA: 4:46 - loss: 0.2717 - iou_score: 0.7075 - f1-score: 0.8271For batch 10, tr_loss is    0.27.\n",
      " 12/225 [>.............................] - ETA: 4:32 - loss: 0.2800 - iou_score: 0.6984 - f1-score: 0.8204For batch 11, tr_loss is    0.28.\n",
      " 13/225 [>.............................] - ETA: 4:26 - loss: 0.2822 - iou_score: 0.6948 - f1-score: 0.8179For batch 12, tr_loss is    0.28.\n",
      " 14/225 [>.............................] - ETA: 4:19 - loss: 0.2811 - iou_score: 0.6960 - f1-score: 0.8188For batch 13, tr_loss is    0.28.\n",
      " 15/225 [=>............................] - ETA: 4:15 - loss: 0.2822 - iou_score: 0.6945 - f1-score: 0.8179For batch 14, tr_loss is    0.28.\n",
      " 16/225 [=>............................] - ETA: 4:10 - loss: 0.2828 - iou_score: 0.6938 - f1-score: 0.8173For batch 15, tr_loss is    0.28.\n",
      " 17/225 [=>............................] - ETA: 4:07 - loss: 0.2811 - iou_score: 0.6975 - f1-score: 0.8198For batch 16, tr_loss is    0.28.\n",
      " 18/225 [=>............................] - ETA: 4:02 - loss: 0.2816 - iou_score: 0.6963 - f1-score: 0.8190For batch 17, tr_loss is    0.28.\n",
      " 19/225 [=>............................] - ETA: 3:53 - loss: 0.2800 - iou_score: 0.6989 - f1-score: 0.8209For batch 18, tr_loss is    0.28.\n",
      " 20/225 [=>............................] - ETA: 3:47 - loss: 0.2776 - iou_score: 0.7011 - f1-score: 0.8223For batch 19, tr_loss is    0.28.\n",
      " 21/225 [=>............................] - ETA: 3:41 - loss: 0.2760 - iou_score: 0.7028 - f1-score: 0.8235For batch 20, tr_loss is    0.28.\n",
      " 22/225 [=>............................] - ETA: 3:40 - loss: 0.2737 - iou_score: 0.7052 - f1-score: 0.8252For batch 21, tr_loss is    0.27.\n",
      " 23/225 [==>...........................] - ETA: 3:36 - loss: 0.2823 - iou_score: 0.6979 - f1-score: 0.8197For batch 22, tr_loss is    0.28.\n",
      " 24/225 [==>...........................] - ETA: 3:34 - loss: 0.2820 - iou_score: 0.6970 - f1-score: 0.8192For batch 23, tr_loss is    0.28.\n",
      " 25/225 [==>...........................] - ETA: 3:33 - loss: 0.2832 - iou_score: 0.6953 - f1-score: 0.8180For batch 24, tr_loss is    0.28.\n",
      " 26/225 [==>...........................] - ETA: 3:32 - loss: 0.2801 - iou_score: 0.6994 - f1-score: 0.8207For batch 25, tr_loss is    0.28.\n",
      " 27/225 [==>...........................] - ETA: 3:30 - loss: 0.2805 - iou_score: 0.6984 - f1-score: 0.8202For batch 26, tr_loss is    0.28.\n",
      " 28/225 [==>...........................] - ETA: 3:29 - loss: 0.2788 - iou_score: 0.6994 - f1-score: 0.8209For batch 27, tr_loss is    0.28.\n",
      " 29/225 [==>...........................] - ETA: 3:27 - loss: 0.2786 - iou_score: 0.6998 - f1-score: 0.8211For batch 28, tr_loss is    0.28.\n",
      " 30/225 [===>..........................] - ETA: 3:26 - loss: 0.2778 - iou_score: 0.7007 - f1-score: 0.8219For batch 29, tr_loss is    0.28.\n",
      " 31/225 [===>..........................] - ETA: 3:25 - loss: 0.2770 - iou_score: 0.7021 - f1-score: 0.8228For batch 30, tr_loss is    0.28.\n",
      " 32/225 [===>..........................] - ETA: 3:22 - loss: 0.2769 - iou_score: 0.7019 - f1-score: 0.8228For batch 31, tr_loss is    0.28.\n",
      " 33/225 [===>..........................] - ETA: 3:18 - loss: 0.2750 - iou_score: 0.7045 - f1-score: 0.8245For batch 32, tr_loss is    0.27.\n",
      " 34/225 [===>..........................] - ETA: 3:18 - loss: 0.2763 - iou_score: 0.7040 - f1-score: 0.8241For batch 33, tr_loss is    0.28.\n",
      " 35/225 [===>..........................] - ETA: 3:15 - loss: 0.2768 - iou_score: 0.7031 - f1-score: 0.8235For batch 34, tr_loss is    0.28.\n",
      " 36/225 [===>..........................] - ETA: 3:14 - loss: 0.2756 - iou_score: 0.7045 - f1-score: 0.8245For batch 35, tr_loss is    0.28.\n",
      " 37/225 [===>..........................] - ETA: 3:09 - loss: 0.2745 - iou_score: 0.7055 - f1-score: 0.8253For batch 36, tr_loss is    0.27.\n",
      " 38/225 [====>.........................] - ETA: 3:07 - loss: 0.2720 - iou_score: 0.7076 - f1-score: 0.8267For batch 37, tr_loss is    0.27.\n",
      " 39/225 [====>.........................] - ETA: 3:07 - loss: 0.2726 - iou_score: 0.7066 - f1-score: 0.8261For batch 38, tr_loss is    0.27.\n",
      " 40/225 [====>.........................] - ETA: 3:06 - loss: 0.2703 - iou_score: 0.7094 - f1-score: 0.8279For batch 39, tr_loss is    0.27.\n",
      " 41/225 [====>.........................] - ETA: 3:04 - loss: 0.2694 - iou_score: 0.7098 - f1-score: 0.8282For batch 40, tr_loss is    0.27.\n",
      " 42/225 [====>.........................] - ETA: 3:00 - loss: 0.2691 - iou_score: 0.7096 - f1-score: 0.8281For batch 41, tr_loss is    0.27.\n",
      " 43/225 [====>.........................] - ETA: 3:00 - loss: 0.2675 - iou_score: 0.7111 - f1-score: 0.8292For batch 42, tr_loss is    0.27.\n",
      " 44/225 [====>.........................] - ETA: 2:59 - loss: 0.2672 - iou_score: 0.7116 - f1-score: 0.8295For batch 43, tr_loss is    0.27.\n",
      " 45/225 [=====>........................] - ETA: 2:58 - loss: 0.2669 - iou_score: 0.7116 - f1-score: 0.8296For batch 44, tr_loss is    0.27.\n",
      " 46/225 [=====>........................] - ETA: 2:57 - loss: 0.2672 - iou_score: 0.7112 - f1-score: 0.8293For batch 45, tr_loss is    0.27.\n",
      " 47/225 [=====>........................] - ETA: 2:56 - loss: 0.2657 - iou_score: 0.7126 - f1-score: 0.8303For batch 46, tr_loss is    0.27.\n",
      " 48/225 [=====>........................] - ETA: 2:53 - loss: 0.2656 - iou_score: 0.7134 - f1-score: 0.8308For batch 47, tr_loss is    0.27.\n",
      " 49/225 [=====>........................] - ETA: 2:52 - loss: 0.2673 - iou_score: 0.7116 - f1-score: 0.8296For batch 48, tr_loss is    0.27.\n",
      " 50/225 [=====>........................] - ETA: 2:52 - loss: 0.2691 - iou_score: 0.7096 - f1-score: 0.8282For batch 49, tr_loss is    0.27.\n",
      " 51/225 [=====>........................] - ETA: 2:51 - loss: 0.2691 - iou_score: 0.7093 - f1-score: 0.8280For batch 50, tr_loss is    0.27.\n",
      " 52/225 [=====>........................] - ETA: 2:50 - loss: 0.2687 - iou_score: 0.7097 - f1-score: 0.8283For batch 51, tr_loss is    0.27.\n",
      " 53/225 [======>.......................] - ETA: 2:47 - loss: 0.2696 - iou_score: 0.7091 - f1-score: 0.8278For batch 52, tr_loss is    0.27.\n",
      " 54/225 [======>.......................] - ETA: 2:47 - loss: 0.2691 - iou_score: 0.7092 - f1-score: 0.8279For batch 53, tr_loss is    0.27.\n",
      " 55/225 [======>.......................] - ETA: 2:44 - loss: 0.2684 - iou_score: 0.7101 - f1-score: 0.8285For batch 54, tr_loss is    0.27.\n",
      " 56/225 [======>.......................] - ETA: 2:43 - loss: 0.2683 - iou_score: 0.7099 - f1-score: 0.8284For batch 55, tr_loss is    0.27.\n",
      " 57/225 [======>.......................] - ETA: 2:43 - loss: 0.2690 - iou_score: 0.7091 - f1-score: 0.8279For batch 56, tr_loss is    0.27.\n",
      " 58/225 [======>.......................] - ETA: 2:42 - loss: 0.2686 - iou_score: 0.7092 - f1-score: 0.8280For batch 57, tr_loss is    0.27.\n",
      " 59/225 [======>.......................] - ETA: 2:39 - loss: 0.2682 - iou_score: 0.7101 - f1-score: 0.8286For batch 58, tr_loss is    0.27.\n",
      " 60/225 [=======>......................] - ETA: 2:39 - loss: 0.2680 - iou_score: 0.7103 - f1-score: 0.8287For batch 59, tr_loss is    0.27.\n",
      " 61/225 [=======>......................] - ETA: 2:37 - loss: 0.2677 - iou_score: 0.7105 - f1-score: 0.8289For batch 60, tr_loss is    0.27.\n",
      " 62/225 [=======>......................] - ETA: 2:36 - loss: 0.2674 - iou_score: 0.7113 - f1-score: 0.8294For batch 61, tr_loss is    0.27.\n",
      " 63/225 [=======>......................] - ETA: 2:34 - loss: 0.2677 - iou_score: 0.7108 - f1-score: 0.8291For batch 62, tr_loss is    0.27.\n",
      " 64/225 [=======>......................] - ETA: 2:32 - loss: 0.2685 - iou_score: 0.7100 - f1-score: 0.8285For batch 63, tr_loss is    0.27.\n",
      " 65/225 [=======>......................] - ETA: 2:32 - loss: 0.2676 - iou_score: 0.7112 - f1-score: 0.8293For batch 64, tr_loss is    0.27.\n",
      " 66/225 [=======>......................] - ETA: 2:31 - loss: 0.2678 - iou_score: 0.7113 - f1-score: 0.8294For batch 65, tr_loss is    0.27.\n",
      " 67/225 [=======>......................] - ETA: 2:30 - loss: 0.2684 - iou_score: 0.7109 - f1-score: 0.8290For batch 66, tr_loss is    0.27.\n",
      " 68/225 [========>.....................] - ETA: 2:28 - loss: 0.2682 - iou_score: 0.7111 - f1-score: 0.8292For batch 67, tr_loss is    0.27.\n",
      " 69/225 [========>.....................] - ETA: 2:28 - loss: 0.2684 - iou_score: 0.7107 - f1-score: 0.8290For batch 68, tr_loss is    0.27.\n",
      " 70/225 [========>.....................] - ETA: 2:27 - loss: 0.2692 - iou_score: 0.7099 - f1-score: 0.8284For batch 69, tr_loss is    0.27.\n",
      " 71/225 [========>.....................] - ETA: 2:25 - loss: 0.2687 - iou_score: 0.7103 - f1-score: 0.8287For batch 70, tr_loss is    0.27.\n",
      " 72/225 [========>.....................] - ETA: 2:25 - loss: 0.2689 - iou_score: 0.7096 - f1-score: 0.8282For batch 71, tr_loss is    0.27.\n",
      " 73/225 [========>.....................] - ETA: 2:24 - loss: 0.2690 - iou_score: 0.7096 - f1-score: 0.8282For batch 72, tr_loss is    0.27.\n",
      " 74/225 [========>.....................] - ETA: 2:22 - loss: 0.2699 - iou_score: 0.7088 - f1-score: 0.8276For batch 73, tr_loss is    0.27.\n",
      " 75/225 [=========>....................] - ETA: 2:21 - loss: 0.2710 - iou_score: 0.7080 - f1-score: 0.8270For batch 74, tr_loss is    0.27.\n",
      " 76/225 [=========>....................] - ETA: 2:20 - loss: 0.2715 - iou_score: 0.7079 - f1-score: 0.8270For batch 75, tr_loss is    0.27.\n",
      " 77/225 [=========>....................] - ETA: 2:19 - loss: 0.2714 - iou_score: 0.7080 - f1-score: 0.8271For batch 76, tr_loss is    0.27.\n",
      " 78/225 [=========>....................] - ETA: 2:18 - loss: 0.2725 - iou_score: 0.7065 - f1-score: 0.8259For batch 77, tr_loss is    0.27.\n",
      " 79/225 [=========>....................] - ETA: 2:17 - loss: 0.2722 - iou_score: 0.7070 - f1-score: 0.8262For batch 78, tr_loss is    0.27.\n",
      " 80/225 [=========>....................] - ETA: 2:17 - loss: 0.2717 - iou_score: 0.7077 - f1-score: 0.8267For batch 79, tr_loss is    0.27.\n",
      " 81/225 [=========>....................] - ETA: 2:16 - loss: 0.2710 - iou_score: 0.7087 - f1-score: 0.8274For batch 80, tr_loss is    0.27.\n",
      " 82/225 [=========>....................] - ETA: 2:15 - loss: 0.2704 - iou_score: 0.7095 - f1-score: 0.8280For batch 81, tr_loss is    0.27.\n",
      " 83/225 [==========>...................] - ETA: 2:14 - loss: 0.2708 - iou_score: 0.7090 - f1-score: 0.8276For batch 82, tr_loss is    0.27.\n",
      " 84/225 [==========>...................] - ETA: 2:13 - loss: 0.2704 - iou_score: 0.7097 - f1-score: 0.8281For batch 83, tr_loss is    0.27.\n",
      " 85/225 [==========>...................] - ETA: 2:12 - loss: 0.2702 - iou_score: 0.7098 - f1-score: 0.8282For batch 84, tr_loss is    0.27.\n",
      " 86/225 [==========>...................] - ETA: 2:12 - loss: 0.2703 - iou_score: 0.7100 - f1-score: 0.8283For batch 85, tr_loss is    0.27.\n",
      " 87/225 [==========>...................] - ETA: 2:10 - loss: 0.2700 - iou_score: 0.7104 - f1-score: 0.8286For batch 86, tr_loss is    0.27.\n",
      " 88/225 [==========>...................] - ETA: 2:09 - loss: 0.2697 - iou_score: 0.7107 - f1-score: 0.8288For batch 87, tr_loss is    0.27.\n",
      " 89/225 [==========>...................] - ETA: 2:07 - loss: 0.2699 - iou_score: 0.7107 - f1-score: 0.8288For batch 88, tr_loss is    0.27.\n",
      " 90/225 [===========>..................] - ETA: 2:06 - loss: 0.2694 - iou_score: 0.7115 - f1-score: 0.8293For batch 89, tr_loss is    0.27.\n",
      " 91/225 [===========>..................] - ETA: 2:05 - loss: 0.2698 - iou_score: 0.7110 - f1-score: 0.8290For batch 90, tr_loss is    0.27.\n",
      " 92/225 [===========>..................] - ETA: 2:04 - loss: 0.2697 - iou_score: 0.7111 - f1-score: 0.8291For batch 91, tr_loss is    0.27.\n",
      " 93/225 [===========>..................] - ETA: 2:03 - loss: 0.2685 - iou_score: 0.7126 - f1-score: 0.8300For batch 92, tr_loss is    0.27.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 94/225 [===========>..................] - ETA: 2:02 - loss: 0.2687 - iou_score: 0.7125 - f1-score: 0.8300For batch 93, tr_loss is    0.27.\n",
      " 95/225 [===========>..................] - ETA: 2:00 - loss: 0.2683 - iou_score: 0.7130 - f1-score: 0.8303For batch 94, tr_loss is    0.27.\n",
      " 96/225 [===========>..................] - ETA: 2:00 - loss: 0.2691 - iou_score: 0.7121 - f1-score: 0.8297For batch 95, tr_loss is    0.27.\n",
      " 97/225 [===========>..................] - ETA: 1:59 - loss: 0.2687 - iou_score: 0.7124 - f1-score: 0.8299For batch 96, tr_loss is    0.27.\n",
      " 98/225 [============>.................] - ETA: 1:58 - loss: 0.2689 - iou_score: 0.7117 - f1-score: 0.8294For batch 97, tr_loss is    0.27.\n",
      " 99/225 [============>.................] - ETA: 1:56 - loss: 0.2687 - iou_score: 0.7120 - f1-score: 0.8296For batch 98, tr_loss is    0.27.\n",
      "100/225 [============>.................] - ETA: 1:55 - loss: 0.2687 - iou_score: 0.7117 - f1-score: 0.8294For batch 99, tr_loss is    0.27.\n",
      "101/225 [============>.................] - ETA: 1:54 - loss: 0.2692 - iou_score: 0.7116 - f1-score: 0.8293For batch 100, tr_loss is    0.27.\n",
      "102/225 [============>.................] - ETA: 1:54 - loss: 0.2687 - iou_score: 0.7122 - f1-score: 0.8297For batch 101, tr_loss is    0.27.\n",
      "103/225 [============>.................] - ETA: 1:53 - loss: 0.2688 - iou_score: 0.7119 - f1-score: 0.8296For batch 102, tr_loss is    0.27.\n",
      "104/225 [============>.................] - ETA: 1:52 - loss: 0.2685 - iou_score: 0.7121 - f1-score: 0.8297For batch 103, tr_loss is    0.27.\n",
      "105/225 [=============>................] - ETA: 1:51 - loss: 0.2682 - iou_score: 0.7128 - f1-score: 0.8302For batch 104, tr_loss is    0.27.\n",
      "106/225 [=============>................] - ETA: 1:49 - loss: 0.2677 - iou_score: 0.7135 - f1-score: 0.8306For batch 105, tr_loss is    0.27.\n",
      "107/225 [=============>................] - ETA: 1:48 - loss: 0.2672 - iou_score: 0.7140 - f1-score: 0.8310For batch 106, tr_loss is    0.27.\n",
      "108/225 [=============>................] - ETA: 1:48 - loss: 0.2672 - iou_score: 0.7137 - f1-score: 0.8308For batch 107, tr_loss is    0.27.\n",
      "109/225 [=============>................] - ETA: 1:47 - loss: 0.2667 - iou_score: 0.7142 - f1-score: 0.8311For batch 108, tr_loss is    0.27.\n",
      "110/225 [=============>................] - ETA: 1:46 - loss: 0.2664 - iou_score: 0.7145 - f1-score: 0.8314For batch 109, tr_loss is    0.27.\n",
      "111/225 [=============>................] - ETA: 1:45 - loss: 0.2665 - iou_score: 0.7143 - f1-score: 0.8312For batch 110, tr_loss is    0.27.\n",
      "112/225 [=============>................] - ETA: 1:44 - loss: 0.2661 - iou_score: 0.7148 - f1-score: 0.8316"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=4,shuffle=True,random_state=311)\n",
    "TRAIN_VAL_SLIDES = TRAIN_SLIDE_PATHS + VALID_SLIDE_PATHS\n",
    "n_fold = 0\n",
    "for x in kfold.split(TRAIN_VAL_SLIDES):\n",
    "    train_idxs = x[0]; val_idxs = x[1]\n",
    "    train_slides = []; val_slides = []; TRAIN_ZIP = []; VALID_ZIP = []\n",
    "    \n",
    "    for i,j in enumerate(TRAIN_VAL_SLIDES):\n",
    "        if i in train_idxs:\n",
    "            train_slides.append(TRAIN_VAL_SLIDES[i])\n",
    "        else:\n",
    "            val_slides.append(TRAIN_VAL_SLIDES[i])\n",
    "    \n",
    "    for path in train_slides:\n",
    "        slide_name = path.split('/')[-1].replace('.tiff','').replace('svs','')\n",
    "        patient_path = '/'.join(path.split('/')[:-1]) + '/'\n",
    "        for lbl in TRUE_LABEL_LIST :\n",
    "            target_list = glob.glob(patient_path+f'{PATCH_NAME}/mask/{slide_name}*_p{lbl[\"label\"]}.png')\n",
    "            if lbl['restrict']==0:\n",
    "                TRAIN_ZIP.extend(target_list)\n",
    "            else:\n",
    "                TRAIN_ZIP.extend(shuffle(target_list,random_state = 311)[:lbl[\"restrict\"]])\n",
    "        for lbl in ZERO_LABEL_LIST :\n",
    "            target_list = glob.glob(patient_path+f'{PATCH_NAME}/mask/{slide_name}*_p{lbl[\"label\"]}.png')\n",
    "            TRAIN_ZIP.extend(shuffle(target_list,random_state = 311)[:lbl[\"restrict\"]])\n",
    "    TRAIN_ZIP = shuffle([('/'.join(x.split('/')[:-2])+'/image/'+re.sub('_p[0-9]','',x.split('/')[-1]),x) for x in TRAIN_ZIP],random_state=311)\n",
    "    \n",
    "    for path in val_slides:\n",
    "        slide_name = path.split('/')[-1].replace('.tiff','').replace('svs','')\n",
    "        patient_path = '/'.join(path.split('/')[:-1]) + '/'\n",
    "        for lbl in TRUE_LABEL_LIST :\n",
    "            target_list = glob.glob(patient_path+f'{PATCH_NAME}/mask/{slide_name}*_p{lbl[\"label\"]}.png')\n",
    "            if lbl['restrict']==0:\n",
    "                VALID_ZIP.extend(target_list) \n",
    "            else:\n",
    "                VALID_ZIP.extend(shuffle(target_list,random_state = 311)[:lbl[\"restrict\"]])\n",
    "        for lbl in ZERO_LABEL_LIST :\n",
    "            target_list = glob.glob(patient_path+f'{PATCH_NAME}/mask/{slide_name}*_p{lbl[\"label\"]}.png')\n",
    "            VALID_ZIP.extend(shuffle(target_list,random_state = 311)[:lbl[\"restrict\"]])\n",
    "    VALID_ZIP = shuffle([('/'.join(x.split('/')[:-2])+'/image/'+re.sub('_p[0-9]','',x.split('/')[-1]),x) for x in VALID_ZIP],random_state=311)\n",
    "\n",
    "    # Iterator로부터 create dataset\n",
    "    train_gen = generator(\n",
    "        TRAIN_ZIP,\n",
    "        BATCH_SIZE,\n",
    "        ZERO_LABELS,\n",
    "        is_train=True,\n",
    "        binary=binary\n",
    "    )\n",
    "    valid_gen = generator(\n",
    "        VALID_ZIP,\n",
    "        BATCH_SIZE,\n",
    "        ZERO_LABELS,\n",
    "        is_train=False,\n",
    "        binary=binary\n",
    "    )\n",
    "    # ---------------- \n",
    "    \n",
    "    # Train\n",
    "    # ----------------\n",
    "    MODEL = 'unet'\n",
    "    TODAY = datetime.datetime.now().strftime('%m%d')\n",
    "    BACKBONE = 'efficientnetb0'\n",
    "    WEIGHT = 'imagenet'\n",
    "    LOSS = 'focal_dice'\n",
    "    N_CLASSES = 1\n",
    "\n",
    "    MODEL_PATH = os.path.join('./model/',(CLASS_NAME+'_'+str(MAGNIFICATION)+'_'+MODEL+'_'+BACKBONE+'_'+WEIGHT+'_'+TODAY +str(n_fold) +'.hdf5'))\n",
    "    print(MODEL_PATH)\n",
    "    \n",
    "    # Loss, Optim, Metric\n",
    "    dice_loss = sm.losses.DiceLoss()\n",
    "    focal_loss = sm.losses.BinaryFocalLoss(alpha=0.25, gamma=6.0)\n",
    "    loss = dice_loss + focal_loss\n",
    "    optim = Adam(INITIAL_LEARNING_RATE)\n",
    "    metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n",
    "    \n",
    "    ## MULTIGPU\n",
    "    import tensorflow as tf\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "    with strategy.scope():\n",
    "        model = build_seg_model(model = MODEL,backbone=BACKBONE,weight = WEIGHT,input_shape=INPUT_SHAPE,n_classes=N_CLASSES)\n",
    "        #model = sm.Deeplabv3(weights = WEIGHT,input_shape=INPUT_SHAPE,classes = N_CLASSES,activation=ACTIVATION,backbone=BACKBONE)\n",
    "        #model = sm.Unet(BACKBONE, input_shape = INPUT_SHAPE,classes=N_CLASSES, activation=ACTIVATION,encoder_weights=WEIGHT,encoder_freeze=True)\n",
    "        model.compile(optim, loss, metrics)\n",
    "        \n",
    "    class LossAndErrorPrintingCallback(tf.keras.callbacks.Callback):\n",
    "        def on_train_batch_end(self, batch, logs=None):\n",
    "            print(\"For batch {}, tr_loss is {:7.2f}.\".format(batch, logs[\"loss\"]))\n",
    "\n",
    "        def on_test_batch_end(self, batch, logs=None):\n",
    "            print(\"For batch {}, vl_loss is {:7.2f}.\".format(batch, logs[\"loss\"]))\n",
    "\n",
    "        def on_epoch_end(self, epoch, logs=None):\n",
    "            print(\n",
    "                \"The average loss for epoch {} is {:7.2f} \"\n",
    "                .format(\n",
    "                    epoch, logs[\"loss\"]\n",
    "                )\n",
    "            )\n",
    "\n",
    "    #model.compile(optim, loss, metrics)\n",
    "    callback_list = build_callback(MODEL_PATH,PATIENCE)\n",
    "    callback_list.append(LossAndErrorPrintingCallback())\n",
    "    \n",
    "    # Train Model\n",
    "    try:\n",
    "        model.fit(train_set, \n",
    "                  epochs = EPOCHS,\n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  validation_data=valid_set,\n",
    "                  callbacks=callback_list,\n",
    "                  max_queue_size=36,\n",
    "                  workers=12,\n",
    "                  #use_multiprocessing=True,\n",
    "                  #verbose=1\n",
    "                 )    \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    model.evaluate(test_set)\n",
    "    n_fold+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = build_seg_model('deeplab')\n",
    "model1 = build_seg_model('deeplab')\n",
    "model2 = build_seg_model('deeplab')\n",
    "model3 = build_seg_model('deeplab')\n",
    "model4 = build_seg_model('deeplab')\n",
    "model0.load_weights('./model/tumor_50_deeplab_xception_pascal_voc_09280.hdf5')\n",
    "model1.load_weights('./model/tumor_50_deeplab_xception_pascal_voc_09281.hdf5')\n",
    "model2.load_weights('./model/tumor_50_deeplab_xception_pascal_voc_09282.hdf5')\n",
    "model3.load_weights('./model/tumor_50_deeplab_xception_pascal_voc_09283.hdf5')\n",
    "model4.load_weights('./model/tumor_50_deeplab_xception_pascal_voc_09284.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = build_seg_model('unet',backbone='efficientnetb0',weight = 'imagenet',n_classes = 1)\n",
    "model1 = build_seg_model('unet',backbone='efficientnetb0',weight = 'imagenet',n_classes = 1)\n",
    "model2 = build_seg_model('unet',backbone='efficientnetb0',weight = 'imagenet',n_classes = 1)\n",
    "model3 = build_seg_model('unet',backbone='efficientnetb0',weight = 'imagenet',n_classes = 1)\n",
    "model4 = build_seg_model('unet',backbone='efficientnetb0',weight = 'imagenet',n_classes = 1)\n",
    "model0.load_weights('./model/tumor_50_unet_efficientnetb0_imagenet_09290.hdf5')\n",
    "model1.load_weights('./model/tumor_50_unet_efficientnetb0_imagenet_09291.hdf5')\n",
    "model2.load_weights('./model/tumor_50_unet_efficientnetb0_imagenet_09292.hdf5')\n",
    "model3.load_weights('./model/tumor_50_unet_efficientnetb0_imagenet_09293.hdf5')\n",
    "model4.load_weights('./model/tumor_50_unet_efficientnetb0_imagenet_09294.hdf5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 10s 221ms/step - loss: 0.5226 - iou_score: 0.4706 - f1-score: 0.6388\n",
      "10/10 [==============================] - 5s 186ms/step - loss: 0.5487 - iou_score: 0.4494 - f1-score: 0.6185\n",
      "10/10 [==============================] - 5s 186ms/step - loss: 0.4755 - iou_score: 0.4803 - f1-score: 0.6473\n",
      "10/10 [==============================] - 5s 185ms/step - loss: 0.4622 - iou_score: 0.4917 - f1-score: 0.6575\n",
      "10/10 [==============================] - 5s 187ms/step - loss: 0.4946 - iou_score: 0.4755 - f1-score: 0.6431\n"
     ]
    }
   ],
   "source": [
    "model0.compile(optimizer=optim,loss=loss,metrics=metrics)\n",
    "eval_0 = model0.evaluate(test_set)\n",
    "model1.compile(optimizer=optim,loss=loss,metrics=metrics)\n",
    "eval_1 = model1.evaluate(test_set)\n",
    "model2.compile(optimizer=optim,loss=loss,metrics=metrics)\n",
    "eval_2 = model2.evaluate(test_set)\n",
    "model3.compile(optimizer=optim,loss=loss,metrics=metrics)\n",
    "eval_3 = model3.evaluate(test_set)\n",
    "model4.compile(optimizer=optim,loss=loss,metrics=metrics)\n",
    "eval_4 = model4.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5225640535354614, 0.4705980718135834, 0.6387785077095032]\n",
      "\n",
      "[0.5487152338027954, 0.4493583142757416, 0.6185491681098938]\n",
      "\n",
      "[0.4754830002784729, 0.4802636206150055, 0.6472601294517517]\n",
      "\n",
      "[0.46223515272140503, 0.4917338490486145, 0.657489538192749]\n",
      "\n",
      "[0.4946261942386627, 0.4754548668861389, 0.6431407332420349]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(eval_0)\n",
    "print('')\n",
    "print(eval_1)\n",
    "print('')\n",
    "print(eval_2)\n",
    "print('')\n",
    "print(eval_3)\n",
    "print('')\n",
    "print(eval_4)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f30f9b6fb00>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow((pred_prob0 + pred_prob1 + pred_prob2 + pred_prob3 + pred_prob4) /5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmwAAABkCAYAAAA7WWxhAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAACT1UlEQVR4nOz9eZilV3XeDf/2M5351Km5qruru6VWq1tCSAgJSUySGQwCDB4wXLb5MCaAXychcWKDJ+J8OOCP+E3exGAn+TzEBtuADTY42DHCDDYQM4hBEhpbavU81FxnHp5pv3+cXrt3HVVLdVpDt1Ct66qrq0+d8zx772efve99r3utpbTWbNmWbdmWbdmWbdmWbdnFa86FbsCWbdmWbdmWbdmWbdmWPbptAbYt27It27It27It27KL3LYA25Zt2ZZt2ZZt2ZZt2UVuW4Bty7Zsy7Zsy7Zsy7bsIrctwLZlW7ZlW7ZlW7ZlW3aR2xZg27It27It27It27Itu8jt+wKwKaXuVUr9wIVux9PRlFL/qJR6+4Vux4UypdQRpdTLL3Q7LpQ9k/u/1fetvj/d7enWl6dbe58sU0rtVkpppZQ3zOe+LwCb1vpZWut/vNDt2LKnvyml/q1Sal4pVVdK/ZFSKnOh2/RUmVLqKqXU55RSy0qpZ1SCRqXUW5RS3znz3E8opf7vYRfTp6sppX5CKXVAKVVTSi0qpT6ilCpf6HY91aaU+uL5bKJbtmVPlX1fALYt2zKAx7vQKqVeCfwK8DJgF3Ap8BtPQNOeEnsCNpoI+ATwtiegOU+pPQF9zwP/BpgAbqQ/B971OK/5lNgT0Pd/Al6otR6hP+c94P2Pu2FPgT1R4Eop9SbAfyKu9Tja8LQCik+39n4/2PcFYBOaVSn1XqXUJ5VSf6aUaiil7lZKXa6U+tUzJ8fjSqlXWJ+7RCn1lTPv/YJS6r8ppf7sQvZlGDvT73crpb6nlGoppf6nUmpaKfVZq0+jSqnsmTFZUUpVlVLfUkpNb3C92TPXeveF6M+57Ew/f1UpdZ9Sak0p9cdn+vQDZ9iQX1ZKzQN/rJRylFK/opR6+Ex/P6GUGrOu9Wal1NEzf3vPwK3eAvxPrfW9Wus14H3Azzx1Pd3Ynqr+a60PaK3/J3DvU93Hc9lT2Pf/obX+qtY61FqfBD4KvPAp7u46ewr7flxrvWy9lACXPUXd3NCewu88SqkR4P8L/NLTvS/nuP8NSqlvqz57vKCU+i9nXv8BpdSJDdo6f6a9S0qp8ExbGkqpQ2f+9lmlVALUlFKvvAja+/Izvw+1/z/K/f9RKfV+pdTXlFJNpdTfKKXGlVIfPdOmbymldlvv/+CZa9dVn6V/8WP1ZYN7vv5MX656tLZ9XwC2AXst8KfAKHAH8Dn6/dwO/Afg96z3fgy4HRgH3gu8+als6BNkrwd+ELicft8/C/waMEm/3/+aPhAZAebo9/XngI59EaXUJcCXgd/VWv+np6rxQ9ibgFcCe+j39d+deX0GGKPPiP0s8K+AHwFuAbYBa8B/A1BKXQn8D/rPeRv9sdhh3eNZwF3W/+8CppVS409Gh4a0p6L/F6tdiL7fzMUBXJ+SviulXqSUqgEN+mvKbz95Xdq0PVXP/f935j3zT1pPLuz394PAB7XW5TP3/8Qm2/unQAp0gQ8BDwHTQAEoA++mv4deDO0VG2b/fzT7iTPt3n6mDV8H/pj+s7qfPsAX+xbwnDN/+xjwSaVUdrN9UUq9Ffgt4OVa63setVVa66f9D3AEeDl90PV56/XXAk3APfP/EqCBCrATiIG89f4/A/7sQvdnyH6/yfr/XwH/w/r/vwL+GvhnwNeAqze4xj8C/+XMtX7yQvfpUfr5c9b/Xw08DPwAEAJZ62/3Ay+z/j9L39XnAf8e+HPrb4Uzn3/5mf8/DNxq/d0/M192PxP6b71+WX9peOY8+4F7/jPgBDDxDOz7dvrr6OXPhL4D1wN3nnnv7jPfd+/p2JdHuf9X6Es7JgZe/wHgxAZtnad/qH8v8Hmrvb96ZnzyZ94r++nrLnB75Vm+l03u/49x/38E3mP9//8BPjtw3Tsf5fNrwDWP0ReZa+8C7gN2bGYufT8ybAvW7x1gWWudWP8HKNJH/Kta67b1/uNPQfueaBvs7+D/i/RPHJ8D/lwpdUr1BdW2XuNNwEngL5/sxj4Os5/NUfrPD2BJa921/rYL+LTqu36r9BfAhP7JcJt9Ha11C1ixPtukf3IUk98bT0QHHqc9Ff2/WO0p67tS6keADwCv0uvdhBfKntLnrvvu4NuAP3+iOvA47Entu1LKAf478PNa6/jJ6sQZu5Df37fRZ/UeOOPO+6Eh2rtgtTcEEmvPlP30oxdBe8U2u/8Pe52N9lUAlFLvUkrdr/pBO1X63qyJM39+rL68G/hvWusTbMK+HwHbZu00MKaUyluvzV2oxjyZprWOtNa/obW+EngB8EPAT1tveS+wDHxMKeVegCZuxuxnsxM4deb3wWjG4/Q324r1kz2zEZ22r3Pm2dvuznuBa6z/XwMsaK0vBlDzVPT/YrWnpO9KqVuBPwBeq7W++4nuxHnahXjuHn33zYW2J7vvZfoM21+ovobsW2deP2HrkJ4mfTmnaa0f0lr/JDBF3/X2l0qpAtCiH2wj13PpS2kerb0b2ZsvgvZeEDszT34JeCMwqrWuADVAwaP2RewVwL9TSr1+M/d7xgI2rfVR4NvAe5VSgVLq+fSpzu87U0q9RCn17DMTvE6fsk6tt0TAG+hT1n9y5uR5sdm/VErtOCNofQ/wF+d43/8f+E2l1C4ApdSkUuqHz/ztL4EfOqPXCehrGuy+/gnwNqXUlUqpCn2dyYef+K6clz3p/Vd9ywLBmf9n1cWR1uSp6PtL6QcavF5rffuT1ZHzsKei729SSu088/su4DeBLz453RnKnuy+1+izQM858/PqM69fB3zzadaXc5pS6v+jlJrUWqdA9czLKfAgkFVKveaMx+XfAfJ9/5f0AW3wGO0F+OWLoL0Xykr0pVVLgKeU+vdYXppH6YvYvcCtwH9TSr3usW52MW7MT6W9CXg+fZr2/fQnZe+CtujJsRn6X546fcr6y/TdpMa01iHwY/Sp7D+6CEHbx4C/Bw7R11OcK+3AB4HPAH+vlGoA36CfpgGt9b30F6KP0T/9rdHXKnHm77cB/zfwD8Ax+q4AW1x6Ie1J7z99d0yHs2L7DnDgCe3F+dlT0fdfp+/K+DvVjwxrKqU++yT0ZVh7Kvp+JfA1pVSLfoqPA8A7nvCeDG9Pat913+blh/6mC31WPXw69eUx7FbgXqVU88z1f0Jr3dFa14B/AfwhfUlMy7rex+iL7n/kMdrLmX5d6PZeKPscfQnBg/T3iy7r3d8b9sW+gNb6Lvperz9QSr3q0W6mzgjgtgxQSv0F8IDW+mLZpLeMfug28Hat9RcudFsuhD2T+7/V962+X+i2PF57uvXl6dbeZ5JdbCzKU2pKqecppfaofu6bW4Efph9VuWVbtmVbtmVbtmVbdtHYkwLYlFK3qn6pk4NKqV95Mu7xBNkM/RDeJv08M/9ca33H473o06j/T7ht9X2r71t9f+bYM7nvcPH0X/WT2TY3+Pm1J/Ge5933C9HegftvdO+meuKDTZ5Qe8JdoqovbH+QfjLXE/Qjb35Sa33fE3qji9Seyf3f6vtW39nq+1bfnwF9h2d2/5/Jfb+Q9mQwbDcAB7XWh84IN/+cvqvxmWLP5P5v9X2r71t93+r7M8Weyf1/Jvf9gtmTAdi2sz5K4sSZ154p9kzu/1bfz9pW358ZttX3s/ZM6js8s/v/TO77BTPvQt1YKfWz9Gunkcvkrts1vQuNxnEd0jBBK3B0P/tc6kCaajzXJdUapTW4DjrVKH3mb56DBpQCrSFJNaQa11Wk6kwWO6Ug1SjPAa3RqQYNylEAaAVoSOIERyn0mftrB5TTx7ZpnOC6bv9SiUYpzjRSkwLbJ7bR7LRQSv2w1nrDpH523+nn/Pm+smH6rpSy/waA4zhnxlihlMJxHJIkIUkS8z55r1IKrTVpmqK1RilFEAQEQQBAHMdEUbTu88PIAORecm3nzDyQ16StQRAQx/Gj9n2j/j/WfR3Hwfd9HMcxv/u+TxAEZlyazSbdbpc4PpusXZ8tgUKapue6zRNqSqm3aa3Vo/z9UZ+9/Vyk73p9OZd1zx4e+SzlOoOvn+uZ29d6tL9v9Hl59mma4jjO29I03XTfH+ueG/XD7vujzeEnO/Lf/p6maYrrum9L03QZ+IVzvP8JWe8e7bk/FXauuTLsWr/RdeTZ2s9eXpfvvrwua5msSYOfkbVQ7FzfkSH7uK6d8t18Ju9z9KsoPKWJe58MwHaS9VmSd5x5bZ1prX8f+H2AfXP79J/+yh8SJxq35KMaMYnWeFpBNyaNE+LAIR/4REWPXjuiG8W4SR+clfI+US8lA2jXoUeCk/FwNdBLSIs+rVqHkckCYSciiTWu1mRGc+gwAVfRq/eIlMZLFa7nkDYi4oyD1ikqhbSX4OY8ur2YTDkgm/VRGY/aoSr58SxuR7O83OJ0epzf/9Tv862Hvn30XP23+66U+n7Mq7KpvjuOo2XxcF0X3/fJZDLk83k8z8NxHIrFIpVKBc/zWF1dpV6v43kemUyGYrGIUoowDFlZWaFWqzEyMsKuXbvYtm0bnuexsrJCHMc89NBDLCwsGNAmCx6s35QHf3dd1yyYjuMwOjpKJpMhDEMcx6FQKFAoFEjTlIMHD1KtVs/Z98H+Dz57WQwFrEr/p6en2bFjB/l8niAIGB0dZXZ2ltHRUZrNJgcOHODee+/l1Kl+MnLP82i326RpSrfbJQzDdf19vGYD2HOAi8fsu+d52vM82fDxPA+lFGmakiQJnucRBIEBm0mSCDAiCAIymQxJktDr9UjTlDRNHwHe4zjG8zy01kRRZNq8EfhTSuF5ngFgSZKY17TWhGG47v2+71MsFvF9n+XlZaIo2nTflVL6XO0YnJOD78tkMmQyGeI4JgzDdX2Xz8tm6rqu2eCtdgz1rDcyaYfnefR6PUZHR1lYWDg6TN/taw0+lw0+vw4oyKFJ5sTgOMkYyO9PVJ8Bc2gSO3MYHHq9G1xbpH+ZTIZsNksQBObZBUFALpcjl8uRpin1ep16vU673TZroev2C9T0ev00op1Oh16vt25s7fVtEIDZY2SPnf2dcF3XtC9NU9bW1uj1elv73FNoTwZg+xawVyl1Cf0H+BPATz1qI1yHdr1HF00x1Xiug4dDlMRoNGnGpVAK0N2U5skm+ZKP73n4gUOz0cPL+zhpDAp0khBkPZJujJvxaTd6+N2YVCe0FlrgK3Sc4uMQr/Xo6YTEUWQdRa6VEClN3E4h4xG1umTyGdy8B4FHdblBJhNAO6HRiHBzHrl8QNbzSfyI0d1lRqJ9nFo9CRCofnbnx+z/96EN3XfZJNM0pdPpGNASBAFRFFEqldizZw+rq6v0ej2iKGJiYoI0TWk0GtTrdbORtdttqtUq4+Pj5PN5ms0mmUwGpZTZvGxGzrZBNkcAgPze6XQYGRmhWCyazdJxHDKZDJ1O57z6vtFYSLviOCZJEorFIjt37jRA0XEcstksALlczoC5Xq9HGIaEYfgIduqJMntjlH+tMdt03wVQyEYs4MjehGUeZDKZdc9M2C0wmyZxHK/77EbAUjafwU19EPAAZpyFuVRKkc1mzX2VUuTzeRsMbrrvgwzIuQCLgEbplwBW3/dxXZcoigxoHbRBIPd4zWY84zg2oPnMtRXnMecH59KgDQILAQ1KKdrt9oZzfBDsPhFjYINq+c57nkcYhnCe3/nB527P/UwmQy6XM6Dc8zzy+bxZJ+UglqapmfcCrpIk2XBuP1o77H4O/k0OU/b1xKNwvn3fsvOzJxywaa1jpdQ76WcAdoE/0v2Mx+e0OElxFJSUSy7w6DVC4kgTBC4OilbWod6NyBUDvK7L8qkmI5MFVE6RqWRprnVJ2xGZ0SzZjEdUD2nVu/j5iGzWp+uAl0KvHZGZypFzHLxeSlwP8fIutCPS0YBsxiVq9kh9B7/ok/UdolaE47nojENxoggKlKtwqiHddkR2NE97qYWjQHUdvEjz7h//Bf7N7737cvpVBR6z/9+Htum+25uALES+75tTXLPZZGpqypxGS6WSAV0rKyt4nkc2mzUsVxiGVKtVRkdHSdOUYrGI4zhUKhXDhGzEONiburxuAwNhfDKZDIVCgUwmw9GjR4miiHq9ju/7TE5OcuLEifN+7vYpWECB1tqcakdGRgwABWg2m+tYvmw2S6fTodvtmj4K6HgygJu0b8A21XcbCMszkbEWV1uSJPi+v6G7R94v/RLgIsySgEEBW/bn5DnbbiXA/M0GR4Osndw3SRKiKCKOY/L5PPV6fdN938hswCX3zGQy6+QBAhSEzRPwOcjCPcqzedwm7YiiiEajgeM4LC0tATwLeN8wfd/IVScmgMP+mzyzXq9nnu8gc/RoLN3jsY1AVRzH+L5Pr9fb1Hd+8JAg888+fMRxbNYbWXN6vR5KKVqtlpnbAs7iOKbX65HJZNaxqvK9l0PlRuPwWK7RwYNOt9s1z95xHHK5HM1m85m8zz3l9qRo2LTWfwf83Wbf76DQEbiBQ9qM8HyX0ElJCn3w5UQaP9GEvRgv75GvZCDv4uU82u2IoJJBlQLSqM/G5UolkjAhdkBlHdwoxS9lCPIeTtYnifvsQ6o1Ba1IR7LE3Rgn8AhGsvTSlF4Yk80HkID2FEkvxtWKbpriNRI8X9FrRHSzIZmcS1qNyHoOvqu4ee46gHu01tc/GeP7NLBN910WBFlU7AVEXANC/UN/IZ+YmGBtbW0dizI5OcmOHTtYWFigXq8ThiFBEFAsFslms2it6fV6HDlyxJzMbXeSAAVZEIU1EVdtEARks1lyuRzdbpdWq2XYPK012WxWGK/H/dylX7JoS3sajQaFQoHp6WnCMKTb7RpwNjExQSaT4ciRIxw/ftywUr7v0263jYvkydazaa03VTRcxl9Al+hy0jQ1LicBW4N6xsFruK5LoVAgSRLDLArYEvbBBqyDG/xGrAKcBVE2syKblmyG4oI6A+Ied8F0m1W0XcW220vGSUDdyMgIKysrdLtd8zkBc5t93o+2eYsNXkuemed5xHF8j9b6N4fp5+D9bDZU3iNmg2d9xkVtz5/BZyXXs/99PLbRgUcAPkN85wdZNZsFHTysxHFMNpulVCqt0+HKQbRYLLK6ukqj0QAwrKvMH3nvRmvrIHO50Tyxv0NyLVuacGY+PpP3uafcLljQgW1KQTYf0I5jvKKPAgJ8eisdwl6CP57FzXnUV1tMVfI403nanYikFZF0YuJORC4fkAk8up2YUyfrlLIeOd8l7Ca4QGu5Q5Dz8LyUMErJVDJoIEohrPXIjOdIUw2xJpvz6cUp7UaXIHDRju7r2pa7FMZzdANNL00ZmShAkhLplMKlZegkdKs9nOj70V3/5JgsXrLQ2MySuIKq1apxlymlqFQqlEolo1FyXZexsTGCIKBSqdBqtchkMpTLZYrFIoDRuxUKBU6fPk29XjcARu4vwE7uDRh359jYGGmaGldAo9EwC2e32yWKosd0PWxmLGyTRTEMQxqNBqurq3iex6WXXroOzMVxTKVSIZPJMD4+juM4NJtN8vk8xWKRZrPJ8vIyy8vLdLvd82qXAAcBV08U8JN+2BvVoEvH1vlIAIbc33YFib5Hxk4+E0XRI9q7kUtyo36LC1LeF8excQfmcjk8z7P1a5s2AVYbAUmZe4ABbTIPRdsknymXy4yOjnLq1CmOHDlCt9s1hwx7g92o33ZbzmXn0oINstHD9n0j7dRGDPe5WDh5NoMA7Vxt2uhej9X2J9KdbF/T1uHZINSerzLPwjAkm83i+/46AJbL5QiCgEKhYLS5+XzePPdut2uuKRrWQRZ38Dtmv57JnK2pLm5X6INCae9TFcy0ZWftogBsKIVWmsBXRGtddKgpjubQRR83cPGLAannUM6V6NRDkmqI57p0dUq92WP7TIlOlNCptQhKGZJWjM54xK4i6cSo0SxRO8QNHdqLbfIzBVr1HtmJPF4rJokTwigmk/MJIpfWSpdEa/KlgEIpS3uhhRtp0mKAoxwKhQxxGBNXu5RyAUExIOlEtMOYwAM3e3EM69PB7I1ATphC89snz3a7TTabZWZmhlwuZ4BDGIaMjIwwNTUFQKlUotFoEAQB5XLZbPKZTIYdO3aQy+WYnJxkfn6eRqNBkiTmRBpFEVEU4XkeuVzOuL2mp6fZtm0bWmuazSYPP/wwURSZDVf68UQtYHbflFJUq1VGRkbMaVsAqZzCy+WyiR6dm5tjaWmJdrttxlOARRzHrKysbApw2YzW6OgoV111FYVCgeXlZe6//35zqh98hsOaDQaF1bSBi83AiYtItEPimhl0AwkAtzdHG+TZ7kN7Ux58XYI+isUiQRAQhiG1Wo1er2fGcJD1G6bfdntlI7aZRxsgy5wUtkXccQLUK5WK0TwJY2Jr9YQNGsZ16nmekRR0u106nc6GAEuuP0y/B9uyEfs5OEcF5Mq9BjWP5+rP+YBLWysn30WbDbP7slkbZLVssCagSOaEMPjlctkAcGmHBFyJ1EPeK5pWMXnm4la1o+xlLDaaw6VSicnJSRO8tLCwIBHw6z5/PvN+yx6fXRzIQkGMRkWaTODhFzyaYQJ5F5IUjabbCyHV+BmXKEpwewmZchbH6UDg4oYJrSglF7igNfl8AGGMqxw6UUJOubi+gzuVI6r1INH4nYRopYvrODiJIpMPoNXBi1MqhQyqo4l7XTzlUM+mBHmP+tE6jgadcZneVUYVPNrHangoPEfhdlO8iv/Yfd6yR2yWwv7Ioi2gSACXLBC2i9PzPMbHxykWi2YxzufzZlOQRUquY59M5SQqAECCHbrdrmFqXNdl586djI2NmfuWy2Xuu+8+FhYWAAy4EybmfG2Q9ZEFWhgce4MSlk/GUZiYfD7P7t27jRu03W4TxzHj4+M0Gg06nQ6dTseAo8HnYC/Kvu9TLpd5wQtewCtf+UrGxsZotVrcdtttfPGLXzQs40bt32x/xd1iM3fy7Gyx80ZaHNlEBPTYYzHIGNjMrZjcQ+49aBKBJ0Axm82ilDJaSBusDMuu2m5g+b/tJrMDG+Ta8j2Qvgt4lYOGzZSIK9gem8Hxs/82aEr1AyokYrtYLFKr1cwzl/babPT52CDzZQP2jcbUljEIMN0MIBvmUKGUIpfLGaDuOA69Xo/V1VUJMlgHVoc1O3hmEGzagNQOfrHf6/u+GXPP8yiXy+Z5y48c4ORQY4NDOxJa2mNfe3Z2ltnZWRPkUC6XOXToEK1Wa93cfDzPfcvOzy6aEU8aEZ7noPIuOkrQrsbtJGhHEYYxTthffDrtEB0maBRhkuCNZIjDpJ+zzVe4OZdYpaRJSpDziTSoMGFstkhruQPzXdwoIXAciLp9EFfwiTXUTjfxtCKTDejEKY7v4hcCoiTG64YEOZ9KIUMcpjTaIc2lNiWviBt40EnwPQcVAO7jc409U0w21420NrLACD1fKBQoFouUy2WzkInYPp/PG9ZtcGEWvYucXnO5nNEECcMmrtFMJkO9XqdarVKr1Uwk6tjYmBH1A2zfvt28x3VdRkZGDFg6cuTIUP2XNm5ksqjK4i4uY4kCDcPQuChk/HK5HNu2bTOLdKvVYmFhgWPHjq1jTORUfi6XlICckZERdu7cyfj4OLlcjmw2y80338zx48d54IEHjNBf2L5hzN5wN3p2g8BFNGODmiVhZQU82MELg7n35F42wzGo+TnXM5K5mM1mzeZ1PqzqIIO0EesFZw8Z8pPNZsnn84b59TxPRO/GjSyBMQCNRmOdhm/QHq3tg4BZ9KC9Xm+dW13m5bD2aABqI6BmA3T5/yDLaf8u35tB1tRm8s5lrutSKpXWgfVisUgcx1Sr1XVzdpjnP8iqDbbPdo3Ks5UDhbxHgnBsJlnSfYiEpNVqScS6cZEqdVbPKQcMGSf74JDL5SiXyybq3HVdduzYQb1eN4cCaYPv+9RqtU33f8sev10UgC1Fk53O43UTdApkHTKBS7fVI26EZDN5km4CcUzWUbiFgFY9JK52UQUX5Tm02z3cjEvUCJmaKuJ5Du04RuddtIKTp+oUsz65gk9QLNBrh3RaMWiN50HYTQiUg5f3qa62Ke8qk3YT1podXKfPzkVhQjCRpeC7NA+s0mlEEDfIFgKSDDRrPXI5n7gWXughfVqYUsqwVrbOSBY2e8MYGxtjenp6nZtTQFShUDCLCKwXL8t1ZUMXZi6KItbW1lhbW6NQKKC1Znl5mTAMWVxcpNPpmA262+2ae4gratu2bXS7XdbW1kjTlEqlMvRpW/pop6MY/Dtgggvk1K+UotlsmtOznRcqm82aa0oqkPHxcQNMc7mcWXw3SkQ8yLqIlkZAgbCI+/fvp9PpMD8/b5hJYSU323dhiwZdgrIZ2/2TDU3AtbRX5sjghm27SYFHbJBitt5LbJDtsjc5wOgYB/V2w/Rd2I/Bw4XcQ1jVfD5v3GLiCpPgAmGI5RlJuo98Pm/AfaPRMAeWYcxmP2WztxlNmyUa5to2q7kRkDwXU3muA53dXlu3KNG05wJog/c518HFdtcHQUA+nzfrx0bteqy+23PnXCBa5n2hUCCXy63rH2C+79JP+U7KgVKAm7RRnp0cqoQZk3VH1kj7OdusN8Do6Ci9Xo9ms2m0vMOyylv2+O3iAGyJhoJHN07xw5Skk+Ammqzj0nNdiPpVDjxfkbiKVjtEj3hUshmSJMXRgOOQy/usLDTZfskocSemttpBJZps1qfV7FIcydBOYtJI0dUpQd4liVN6YYKTcUijlMZykzjVdE61CDSESUQ2A8FIBu0pTj24zM4dlf7Cox3arZhOnDCxawTSfl+6yXCL4zPVlOoHAQwuYFI5QNiMqakppqenqVQqJuAAMDmxRGcki4+wUEopAzRarRatVsts+LVazei54jim2WxSr9dpNpu0220T/ZfNZllYWMB1XfL5PIA5dU9OTuL7PtVq1US0DmOu61KpVExU6+CmIYvxxMQEu3fvZnx83ESMSnSouHhlAe12u8aVIwu7uIJLpZIJUhBWyb4XrAc24mrrdDqEYWhyjklU5q5du1BKsbi4SC6XM6f6zT57AcCiybLddHbuM9vdtxErJ++1mQjZhAaBoJgAQdEG2XPQBmu2W15ArujJ7I1uWJO0NRsFLAhTmM/nqVQqJtLZZn2kfdLuTqdjopkFsEvUoIzJMC5rW6IgfRX3+kYAebMm7kYBkRtFdw6+f/DvNgiT+WDPj8dyf250L3t85DoSiOR5HvV6Ha21+Y7bLsVh+l4oFB7BztruVWHBS6WSWVMk0MZeH2XM5RAlhxR5PhvJB2xgbQM4uy0S+S6HOwFtnucxMjKCUv38dzLPtuyptYtjxFNN2olRGnynD8ocR6GTlBRFEiV4GYeeo1DNGMdVKBx0onE0uK7CUZAtZMhme6SxJuO5ZB2PxFcEOY+JiSJ+KaDV6JF2+8xaHHjkizlaYYSbcckGPlFYx+vG/ZJWCZTzGTqOJu4lZEfzZPMBa8sdPN8hyLiorqbXTmgvd/Adhe8qanq4L/Iz1WTxdhyHRqNBq9UylLswaLt37+ayyy4jl8utcwsJSBHWQdxAslkLEBAtV71eZ3l5mU6nY4BNvV5nbm6OSqViXEyyuMkmUK1WOXr0KPl8npGRESNEzufzJjpUa02pVDKAbrPmOA5TU1Nks1kajYY5uctGlM1mmZub45ZbbmHfvn2GNUjT1ICjcrlMNps17EKxWDS6JnnP6uqq+V1YGdkkZKzt0H3bVdftdllYWKDRaFCpVEzbBGjOzs4SRZG5zmbtXK4q22UpDKqkMLEB2qDGS9gL+V02KNlwNtrAZTMUcC7tkvvbG1qv11u3adoVFGwmeLMmgGAjdsr3fWZmZti3bx8jIyOEYUiv1yObzZrN005XIxu9tCsMQ7PpynwZBqyJyXwQ3dage1VAhu/7Q4F1+ezgQcH+22D6FvszNhM5OH9skH4u9/ZgEIp8Tv4u7G4mkzE5D3u93jrhvlWSbKh+C6sMrAP8Mn/lcFYqlUwfBCQKayrfd7mezG9Zj0SjKvpXO0o0l8uZJN+DScQBwjCkXq8zOjpqALtIE+z8mMI2btlTaxcFYHNchyAf0G42aRcDOtWIou/QixLyBZ+u1nTCmNZqF8dzGR3J9VPyuopuK8LLuSTdlPpKi0LQd4t6eZ9CLsDNu7gZB8ZzBJUsaaqJ0hQnTKEZ0W1FBFN5dM7l+PcWGb9ynOh0i1CnjOwcIan1yDnQWu2gqg5OxqHXTJjeVqIdxfTq3X47uhGZchatwQu3wp03Y0optm/fbqIe7c1BWJzJyUkmJiZMJKSwTiKylwhIifaUDUsAmeRJazQaRncm+rTR0VG2bdtGs9k0iXWF3RPgFIYhR48eNafe8fFxoy8RV5VEU7Xb7aH673keMzMzTE5O0ul0WFxcZHl52YCDUqnElVdeyfXXX0+hUDCshLipGo2GYStExyfsSqvVYnFxkWq1CpzdfGVB7/V6+L5vEhFLJK7NcgG0222OHz/O/Pw8o6OjuK5Lr9czrGYcxyZZ77B6LjuCU0CWbJrCaAqDaLOmAnYkKEPAm82kyUYlr8v9bEAmG72AL3vTB8x1BCQNsjCDrtRhn70dQGCDkmw2y/bt27nmmmvI5/MsLCywsrJiDiPyPgHw4q4TtrDdbpvggEG36zBmj6/oqQYTD5+P6F6elzyfjbRm9o8NLAZTUdjP02ZTz2WyfsictzWitju+2Wyue9ZyCJS5IGB7mLFVShmgHQQBzWbTaDIdxzHehLm5OROVLNHy4n6355zt+u/1ema9gz7AlLQg7Xbb6F3FoyFrnK1lA4xURNbbbDZrDkhSjg0wMokte2rt4gBsjqJ1ukmn1aOS8cjkPaJU9zVproNC4/ccsr5LF022kmHtdING0qWQDciM5eg1Y9I4JXEhcB1S38EbyZCQ4rma5nKHJE6hm5DqFCfVOBmHKEkpF3yOHFyj3YooL3UY3TVC82ST2vE6xXxfn6YyDq6GUiXHSthkYb6B0pp6r0fBD+iudCg4LokH5cnShR7Sp4XJYiELlWw0ot+QZLhjY2PrcgyJpkkWTuAR/4q7SLRea2trrKysUK1WTZ3Nqakpms3muiS71WrVAAJZ/FutlvlMq9UyAEJKYQVBwMLCgtmANmue51GpVEiSxCyEAtaKxSK7du1i3759RrcmC74d+ZUkCZlMZt3iK222NXK2i1VcZXZKCfu9NqBJkoRqtcri4iJ79uwx75dkxrKIr62tnVc+ssHkwPIMJSpTmCNb8yRsnjAI9qYnIMt2tw1uyGI22LKTlg5u3nZNUgENNqgdduOWe9ugTa4rDMrExAS5XA7XdSmXy6Ykm7C5AJVKxQTOlMtlRkZGaDab5jVbt3m+ZvdRdIfAOhZzGA2bzUpa5dzWjfmgi3CjFCq2615A/rn0arbZ88lmOe1xEgBkHwxgfXTn+aZysasYyPUk4KlSqTA5OWmeu8wxAcbCYEubZdw9zzMHJumL7S6XH2FoZa7J4dY+vAhT126317GzMl/lgNNqtYZ2CW/Z47eLArCliUZFKblsgK+h24opVHK0ehEpKd12vzzU5GyZaq1LFKdonZLL+8RRwuqhKtmMjxO4tBo93OCMOyeMUYEiH/j4OkS3Y3wUnusSxv0aokpBlGhUnJLJ9MtiFaaLdObbKCD2QLVicr6PTqDTjfAzHu1Oj0ApiqM5irkM3TTGz/uEzRCHLYZtsyZ0u2zEAlympqbYs2ePiU60s3jbv9tAzV6kZJEJw5Bms0mtVjPRU7KoVatVms2m2QCnpqZYWFggn8+bxVuutbS0xNLSErOzs48IvbfdcMOYnZBVkv7GcUy322Vubo4bb7zRnLbFHSNAxPd9RkdH15V1kgVXikVLQt1Go8Ha2tq6MRbxs2zE4p6WaFo7Oi2KIk6fPs3y8jLZbJZ6vc7i4qLRu4iWbhi3oGx6tgZJNjERztvpC2z2DTDsg7i+baZOxtT+d/B3mSu2m2wwytBOkSGgzdZJ2cB+GBPQMuhilYi/8fFxZmZmyGQytFotA1BFMiBgVu6byWSYmppi586dLC8vs7q6Sq1WO6creBizmR27ILkAZHnPMH2Hs8L5brf7iNQo8gwG07XIvQYjgDfS5z3aazYLJ4eUwc8kSWJS/tjAUb5/G6WJeSyz540AMKnQMTIywtzcnEkALvPPnot2sIdcT74j9iFK6ozaz0nYWZl3gAmokmvZ4Ey0vPK9FvBmu4SHXe+27PHbRQHYcBSp1ujAJYw13SQliSIKvku7HZHUe7QjjSolOAqSeoijFKkHjVpIZTRHpx3iFzzCXkxYDqifbpCgKZQCVpsxWkGhl6ID1U/Um6RklEsa+HS7EalOyWc8suNZ6gstmqsdVNZFtTXjkwWSM+lF4nZEvhhAJyZXyJAp+/RaEaN+DqUgyLq0wi2qeDOmlDLuOZs5EYZN2IfBhXLwBA5nN1WJqGy1Wgak1Wo1qtWqiaiTBatWq7G8vMz4+LjRMpVKJbrdLkEQGK2YLGZ2UtJer0ej0TB9kHQLw/bf8zwDPIIgYHZ2ljAM2bVrFzMzMwbASptlIR6M0hI3izAgsrkLeygLrizQcl8BALKBZjIZ8vm8SZliu6FqtZoBEaKLk2cj2rlhTDYIe8OEs+4u2RRsF5A8Zwm8kLkwyLY+VuStgCY7dYLNaEhgif1+e7O03a/nEyUqn7dZRdnEBThXq1W01hQKBQMcxO0tLnPJhC8stBxiBqN9z9dk3ttua2FzbIA1TN+l3+JSs5lhMRuMDaZnkec6yIaKbaR/k99tECtA5FzjJPcUoCqA5Xw1gfLcZQ6Ld0GeseSPlDlh98vukwA3YaJl/G2X8EYpPOTZFQqFdbnU7EOL7V4W3aS9rtqHqy176u2iGHVHgSr5pHFKWvYpuhBFKZ7vkgk0upwlWeuSkOCP5EgjTWW8TK/RI3JdHA2pq+gpTWmuBElKGqXMXDJKtxuBAgdo1br4uOhUkXEclAYvTOh0oDJVJEhBeQ5rh6v4BZ/SeJ6o1qPRDglbEdlKjmwxYGSmBBp8rXCjFFJNL4zxgv5iOVYpXughfVqY1prFxUUAxsfHzekyDENyuZxJSCtASRaZwQhA0e0IQLGjr8IwZHl5+RHsmiz21WqVRqPByMiIWczK5bIBKnIPx3GYnp42Gq5Op2NcpdlslkqlwsTEBP/n//yfTfc/SRJqtZpxD4lbq1arGW0a9N2kknfNznkli6u4LcfGxoz7VNi3MAypVqvmdC1AZ/AELlGekpx19+7dXH311czOzlKr1Wi32yb7OZx1A9qVIQYzrT+a2Zo1ebbiFhUgbgOBQReRAE3btSTXFRbW3txhvYbNvq5cA86CALm27VKyrydjLxU1Wq3WpvsuLjfpk+M45nAic0HcmrOzs+b55PN5RkdH14Hzer1Oo9HgxIkTBmCMj49z4sSJ8wYWgyYsrq0Tk3EulUrkcjlOnTq16evJ3LPZGrm2zGfbDSdz3gZtNoM6GD28EYgTGwTxNvCERybzFuBivybPXljHzUoBtO5LFQSYC1Mq+jJh7rvd7rp8a3J4sdspUeJwNpFuNps1ujgZX9vrIJpGYbHlwCLyjkKhsC7tiAQ0CFiTtVX0u7lcbqi8k1v2+O2iAGwaCJRDUvLpdSLcVNMNI8qFDGmUonsp+bEcsSzUBY80SvGUy8hkDpUqtKNoNrqkGQ/disnnfZJqD92NaYQhlckivUSTy7u0OzGu65AqKKSKXOChygGt4/V+0fg4JVPJQZzixJpMxqHejSnnXVQ7JVxo4bhn6jx2QrQDru8QKwh1TKH3+BfJi9mUUoyPj6O1ZmVl5byvI5owEUuXy2XDtAkwsDd2AQSDrsFut0uj0VjHvsmmJgtULpczyWJl85HcYUePHmV2dnZdVGGlUmFubg7AADSllOmvAJ9MJsPo6ChjY2Pr6u9txqRGqC02ljbIgi4uIDlJC3iUxVrYoeXl5XVC4UKhgOM4ZoMQ5lBSpchGaAMjW6+Uz+e54YYbmJiYMEDX930jxo7j2CRmVaofNfrtb3970323XVwCUmzXi2yWwgjKpiW6QZsdE0ArTJv0adDtKSYbrq31sRk0KaiutTYRd8I2yCYm7Z6dneXGG2/kM5/5zFDPXu4l0c7C4og8IIoilpeX0Vqzbds2oJ8La2RkhDRNTYoF0Wd2Oh2azSbbt29nenqafD5v9JjDgjYbPAgDNchue57H6OgoO3bsYGRkZCjAJn23AZhENsu1B3PcyX3hLMNkg7ZB9/RGfZb3ncvsQBIbpA9+Tg4U4rrfbP5BOVAKsyZJrG1AZh86JRrUTiUizP9gZHMQBJRKJRNkJJHftkzAZs7sMRQN3fbt242uTarI2GyzzIFSqcSOHTsYHR3ln/7pnzbV9y17YuziAGypxsn75D2HMNEs1zoEjiLsRXieooWmUM7i1Lp0lju443m0p1hebjI+kUelkIQJuAov6xG3YsYmC9Tmm7R7CRGaXj3E9x2SMKWU9VG+ItWKJOxXU+i2QsI4Jch6ZJQiTvvVElKdEmlF4iucQgBhQqsbojIeXRIKxYAg1sRnKiscP1zHnSxc6CF9wk0WlEwmwyte8Qo+8IEPkKYpt912G+9///tZXV0d+po2uzMyMkKlUqHdbhuXpLjs7B/5nDBOSvWz+cuiKcBJFlOJ7hTQIoydgD5J+SGbvERcTk5OMjk5aViQxcVFc+KXDbbdbhuwIozgMCabkyzKUmImjvt1ASWis1gsmihRqSUo7l3XdU0fxEUooEbK1sg4iiZHgjEEtImAX1yTvu9z+eWXm0TFEhgBmLqte/bsYW1tzdTWLJVKQ7lJRK8l/ZEUATZzlySJYQsEnMl4CXCVzcjOmQWsy90mANdmXuUzNjsjG9fU1BSXXnqpYVoPHTpEu93msssuY8+ePYRhyPHjx6nX6+zbt48bbriBL3zhC5vuu2zQNsMk7J9sks1mkziOTdqbqakp43aWTV/clfJ9kbktAvbV1VUDPjYD2kSKIKAvm83y0EMP0Wg02L59O/v37ydJEg4dOkStVmNqaoq9e/eya9cu/uEf/mFTfZc5bzOlcogSE+AlbBs8Un9oA1EBWQKs5HkO3ncQfA26UUdHR9m7d69xSR8+fJjV1VVGR0fZtWsXAMeOHWNtbc0wsMOyyjJ/5WAl/RGAZUfJA+vy6tnpVSSxt7jB5Zr5fN78TeaH7c61pRW2e3NmZoa9e/dSKpVQSnH8+HG63S6VSoXp6WmSJOHUqVMmvc/s7Cyjo6Ob7vvTwTzPo1AomIALyYUo37GLwS4KwIYG5SgSF3QKRd+l3YtRnksYJhSKGeJmiF8MSIBuvUuukiEKE+IwxXVAZxxGKgVcFFoputUenSRlrd6hMpIj7sQU8j5+0UclKb1ujJf3aJPgRw5pGIOG0mSBNErodmLcjEevE1PeXmL0qgkWH17Ddx38qTz1+SadtS41z2V0tkh1uQ2LKYV8Bvf7xL+fzWbJZrNceumlvO997zNpFq655hqz2MzMzPDf//t/Py/ABpiAAsfpFzLO5/OmRqa48MQ9ICdGcfVJBGiz2WRxcZF8Pm+S6QpTMjo6arRWwuLYi30URUYrFEUR5XKZ2dlZJiYmyOfzJtns6Oioub8wdHakViaTGRqwyWlVFgYp7F2r1YzLQ5gXOUXbgmXApPBoNpusrKywbds2M17iZpX8TLt372ZlZcUwmhJJKq7pOI4pFArceOON3HzzzcbFKpUg7LQizWbTsAQyvsNouZRShlEVxkHAliQSFkBpu37swABhCG39k+0yHtzYbS2PrUWT+ZLP57niiit46UtfylVXXWVKkknS5bGxMQMya7Uax48fR2ttDgTDmB3gIQyqbKziXpXNOAgCxsbGTHCMpKVZWlri5MmT1Ot10jRlZmaGNE0ZHx9n7969VKtVkiR5RNH2jczzPPbs2cNLX/pSbrzxRvbs2WNA3+rqKtPT0yYn3PHjx/mHf/gHut0u27ZtY2RkZKi+21UeNgJRtmtTnpt9WBt8TQ4ug3NjUBR/LrbR8zye/exn88Y3vpGbbrrJ6Gfr9TrHjx9namqKUqlEvV7nrrvu4o/+6I9YWFhYd9DYjCnVzy0o3818Pm/aJIDMTkgrBzkbZEluyXq9bvSOshaINEOSg9sgVgCyHUgTRRG5XI5nP/vZ3HrrrVx11VWMj4+bOV+r1SiXywRBQLfbZX5+nnvuuYdOp2M0rt8Ptn37dn7sx36M17zmNezZs4cjR47wwAMPcPnll7N7926OHDnC2972Nk6cOHGhm3pxADblQNwOoRgQZx269QSUhoyLSjSpk9JeaqNDl5zXB1G5Yoadu0fRUUKUpITtiDRKyfgu+YxP1Awp5jzqgBOlJDkXPAjDiE4rpFjM0otSHEfh9lKU5+KUFK5SeJ5LdjpL3IlpxQmdI2skhyGDw9JiC5KEMNX4vkuSpLSWOozPFFleaqICh9rJxlD9n52d5W1vext/+7d/y/e+972ho86eaJuenubHf/zH+cEf/EGuuuoqVldXed7znrfhe0dGRvjBH/xBDh48OPR9RANUqVQM7S/iW1mEbWGwLMJJktBoNKjVaqb2p7AAnU7HCHnFtSiuysEEoHYmeAFIc3NzJjpVkkNKGg9bMCwLrACO88n87fs+Y2NjjI6OmqhISQwsUVrj4+NGuyYbtgAnW8eitWZtbY1qtWo2eTvy0RY3r6yskMlkTHJOuU4cx1x55ZW87nWv45JLLmFkZIRcLmcWZmFwBKDZNTXPB6zu3r2bvXv3srKywvz8vNkc7LGVTVsYNjtDvrBw8iOpGGzXmc22bJT1XzY23/e54ooreOtb38qzn/1sA+KCIDDuUXEnCbgrFovm2QzjdlSqn3hZmFD5v+M45jQvoGNlZYWlpSVGR0dpt9sGzC8sLHDgwAGjT7STTedyOa666iqOHz9OtVpdx1RvZI7jcOWVV/ILv/ALXHfddQY8B0FgyprJ3Hddl5mZGXbu3GkqXAyTj0u0X3BWGydtgLNRqTaYs1N5yL82WzrIrAlos+8pnxvUqzmOw9VXX81v/MZvcP311xsdpVKKubk5nvWsZ5kAEDn0TE9Ps7KyYp7XZs1xHMrlMmNjY+ZAmclkcBzHyA5knIF16Wsk12G32zXBVNlslk6nY9KASO7CTCZjWDfb1WwnlpaDylVXXcU/+2f/jKuvvnpd7dTx8XHDyknqldHRUSqVimGinwh95IU0pRQ//uM/zm/91m+xe/duMzcuu+wyXv7yl5v37d27l1tvvZU//MM/vFBNNXZRALY01ShHUT/dxCv4ZEazVE81aCz2tWL5YgCBS6GQIatcijMBaZwQdkKiMMXzHDzXoV3rkp0pkqp+EIBbDiiN5yBW5EYyZH2fThhRLuVIHQ0KPMcl7CZ4gYcTK7oLbbyR/gmwtdQlboYkDpQqWQLfxXFhatcYq6f7NdUc1yWONW6mX01h7VgDlQw3kaenp/m1X/s1fv7nf553vetdfPzjHx86p9cTZb7v8x//43/kzW9+s9ng9uzZc873O45jIhnP515S3iifz9NqtYyIWRgrAWziFpOEuNVq1USYLi0tAX3QJcWpbdeR7V6wT/T2ZgD9tB7bt29nfHyc0dFRA1aE6RCmys4gLuJxG/xt1rLZLHv27KFYLBrNkUT8iVtX9Caio5IAC9t1Iq6jRqPB4uIiSZKYSLB6vW5O3I7jmEgvAUaSNR/6C/IrX/lKrrjiCpMPSoCSaIRsHYxkuBdgPAzLVCqVeMlLXsL09DRxHHPnnXea9CCAKYNks3qyYdnRobLJ2SJxAc/iLhZAYYMO+bwwpqOjo7z85S/nqquuMsW0RbtoA3YbENilu4bZvHzfZ/v27SanXq1WMyDJdhUCLC0t0Wq1WFhYMKDccRx6vR7Ly8tGWyhgbdu2babu7ejoqHHfS6WIjWxkZIQ3vOENvOAFLzDfEZlT0lfptwSY2FUihomOVkqZkkfSX5tJsxlV+5nK/8UGwZcN5mwAN+j+tK8hWtx3vOMdvPCFLySTyRiZhTwnee5RFFEsFimXy0xNTXHy5EnDym/Wstkse/fuNd4JYcmkgoq0CVgnY+h2u2aOCTMuc1m+H3JNW+8q6yWcBcR2IMPExASvec1ruOaaaxgZGTEHHJEeCPMnwE3chDbr93S2Zz3rWfzu7/4uU1NTj/o+pRT/1//1f/Hnf/7npvLFhbKLArAlcYoXeKR+SGetS24kQ2ksjxOl1GodssWASj5L2Iogp1BeP2AgCjX4DmnWxYs00zsrhI0eOqPwPIekHRP4Ps1Oj3i5gz/u4Gc92t0ID3CjFJXPMLajQHu5Tasd4eLQ68Y0612aaz0KI1ncKGFluUXO8/DcfmF6XIjCBJL+l2ibP0Z9oUW7HeKPDic+h/6kmJiY4Hd+53d42ctexr/9t//2cQn6AePCmZ+f3/SiOj09zSte8YqhwMdVV11l3BzDmEQjdrtds4lKJnA4W2TbFp+LUL/RaBitgQjBhaXodrsmSaSkyygUCiwuLj4i+lDYA9d1GR8fZ3x83Lj6JiYmTB44OJs9XNrS6XSo1Wpm0Xw0QfNGJhoz0Q7JBiiuaAFr4uK0Q+ulVI6czu2s5KIrszdEcWMKGBBxvwRmtNtt9u7dy+WXX27KXQmIsAX6cFaDJT922ajNWjabXZck9DnPeQ6nTp2i0+mYQIe1tTVzPykwb+eksoGEgCopISbPTJKAtlqtdRHEdh4trTXT09Ps27evH0hkJROV99iCeDs31urqKuVyeSjQksvluO666ygWizSbTRYWFsy8kijkKIrIZrPUajVOnTpldJbyfRDWpdfrUalUTLoVO5pT6u5KwMy5bNeuXbzoRS8ykbVidqS0rT2Tterb3/62+a5s1gSU2WJ6ed0Gw4PubHt+2WBMgMMg4wYY5nOQkZPrCbN4yy23mLx2AnTkX5ln9nfm2c9+Nvfee69Jpr1Z832fbdu2mbZLbV5hSG0tn0g94CyzbQdFCWsu89UOvJCI4mq1+ghgJeOstWbXrl1cffXVRicpINwGznLwkfV5YmKChYUFo+d9OtvrX//6xwRrYldffTXPe97zNq3VfLLsohhxz3NBa3KBS7ejScIU7UEQuFTGCoStEAeFclyyOZ840aATgqJPHMa4vT7go5uQDXySXoLK+7hKkY1SdEUxOlukUe0QN0MKmQAdJ+iMh9NNaC+0aLZDHAfwHIKMj+eFZIo+QSVD0kso9TwK5QzVhSZryx0UCpRD4DokqaZ+soHrK4oTOUqTw9VYs8FRqVTiTW96E1/60pf48Ic/fF7jmc1m+fVf/3Ve/epXMz09zUc/+lHe8573bIq1u+WWW5iZmRnqfs997nOHCm8XE5GsnNhlMRWQYFP69gYVxzH1ep1Op0OapuTzeSPKthN8yklUIjpFyC/Xi+N+eRVhswQoSrsEsMn1ZLOUBU9ciadPnzYRqMOYaFokSlJAr7gc7JQPdrCEHWUnueBEd2O7brvd7iNqIYo4XxirtbU1Mw42S2hvcIMibnk2srCLzmkYYa6tz5GIwzAMeeCBB0yUrlQsEObDTgMi/bf1bcVi0UT3zszMGIbt4Ycf5siRI8Z9aWvehOkZGRlZl0vPdnMO6qxE/yPXFqHyZi2Xy7F7924jEM9ms3S7XY4dO2Y2YwlCkRyCkuoFzjLJwrrY5aMkmESAfrFYfNSDn+u65ruzkT7Mdkva0clhGHLixAkjcN+s2cy2BFjIfWSeDc69QVbs0X4GAzrke7sRYHUchz179hiXt7BINiNrF1+X70culzM6smE8IcJm2wFcnU6H1dVV8z2XNVQYXJkP9poFZyUCIvmQ36V9dkF4AVZygJW2yIFexlXaZTNt8n+ZZ47jsLS0tM6d/XS1YfY5OVxfaLsoABsKmp0QP3Dxg5TKrjL15TbEkM/5JJ5i9WSdwHPptiPIufiOotuOyY9lyWRdwlCTaI1qxSRJSoxirdVjupxDxynN1Q69apdCJYOXpLR6MRnHp9OLiKOU/HiebrtHqDSB29ex6TikudohjhJ2XzlFfrZIY62D9hRkHPzIYbyUZbHeRjtQyAUEGZ80Gs4l+sM//MPrUkIMnj6HtRe/+MX863/9r83J9xWveAX//t//+0199nzobqHvz8ccxzGpCsSNaS+2ok1qNpumVp4sXM1m0wQESJJX+zqLi4tmc5PryCnVTqwqmjQbFNlF5QWwifbGdhG0220OHz5scr0Na6I5EYZkkPkRlksWcMDkDVtZWTEslLRLNhjP81hbWzMb+dLSEo1Gw7AozWaTpaUlE10rY2inTLHHxwaqwlh0Oh3m5+f51re+xbFjx4ZihGXDEqCqVD8IwfM8qtUq+Xye6elpk7JF6/XlggbTPbiuS6VS4corr2T79u0mJYLWmtXVVQ4dOmQ2K2m/AAdbHyfgR9ytMq9lE7Mji48fP86dd95p5uYwfS8Wi6aObjabZWFhwUQlCqgW3ZKACGFNbTexsM9BEJhM+c1mk9XVVRNUYkfIDpqkgxiMJJWxscGVXKvdbnPffffx4IMPUqvVhmKZ5KAjQEzWucFksRutJ4MuUPmxoyRlbASoDK5NNij1vH5pODFh9ur1utHNZrNZkw9SDkIrKyumNvEwrLrcs1QqGQ2bUsqUHRPXtr1eCbMrgEnS/MgakMlkTHBMtVpdl8rDZuXkkCHMsF0NRdZbeb4iP7HBmzy3U6dO8cADDxjQ9nS2w4cPb/q9p06d4jvf+c6T2JrN2UUB2JTqxxhU51s4qaaw1kOhUK4GNFqDVorCdIG40cNpxSjXJVf0cJTGy7nUVlskWhMEPrlMhna9Q9Z3CeOUKEpI2gnl6TzZVJE0Q9LkzKKgoVDJknUdKAQkul9ovlDKkvF96lFEs9pl6XCN/FqXOErBS/EiTepAJ03J5TzCdkTgKFLfAX/zgCcIAt7ylres++LX63W+973vnddYZrNZ3vnOd56XrkwpxdjY2FCfSZKEP/uzPzPC1GHMdgXatLu4/mSBaTabLC8vr9u8W62WWTAkD5eEpMsGYovE2+32ujqLNviQtggjISDHTiMhG5ftuhG3xcLCAsePHx96DASkCCgTMCXaMnHhCYtmi+Z7vZ4pQSQb1vj4uDmpi3vQ930ajQYnT55kcXHRLMSnT59mdXXV6N3GxsbYvXu3YVoGc1DZG50IkbvdLktLSxw7doyDBw8Orbu0Xa420yYbCWD0O/LMpC0yX4T5qVQqXHLJJezZs8dEn8rmeurUKeNKtt1k8kzL5TK7d+82m6WMnw1ibFdlo9GgXq9z4sQJVldXjat5s+b7Pjt37mRsbIzx8XEqlYrpk7iXJc/d2tqaua/cwwbT8pwLhYJJYZOmKUePHmV5eZmlpaVzauyk75dccsk6DdQgYLI1ZvL9FHBpHzI2awKM5HAlrLCw6XA2+EDuO9h++7nIv3Lolbljf88H+yIHRUnXYafsESAlBzgZD5n3R48eNUECw/RdKcXIyMi6fJISvCOJaR3HodlsmrQuwg5KEXdbLyo6Xwk0kYNtt9tldXXVAE84G3Ev86xcLrNjxw7jCrZdv3KgEUZVDnHtdpsTJ06YMn1PZ4YtCAJuvPHGTb//0KFDLCwsPIkt2pxdFIANIG3FjJayrNQ7LC+0mbp8lOaJOrGXohSMFALidoSbcdGJpqs02ZJPdiRDp9bDcRSBcvETjQIa9S5OqmgRUihnyLpQwCHqRPi5gPGiR6L6ZariVNNqReCkhGkKjkOn1SUzEhB1I0g1YSci7ER4jkOvGlLKeAS5DM0wwkFTKAZo3yXIuHhDkE2Tk5MmQatYs9nk0KFD5zWOL37xi9dFuAxjnufx2te+dqjPHDhwgD//8z8/L4ZNdCIibhf6v91uG0ZB3J+yyAvTIgtopVJhZGSEUqlkElEKEzY9PY3Wmvn5eebn580iaC/i4n7atm0b+/fvp1Qqkc/nDVAbFC+LyQm42+0+gunarDlOPzecHQwhdUzldC8AUTZtubcsmnEcGyawXC6boA2tNePj47Tbbe6//37uuOMOqtWqOcWL+7JcLrNr1y6uu+46A9jg7IYoY2WDBNm42u22qfhgs1Gb7buI+wWgyLOZnJxk+/btLCwsGLBhMz7yeZkTErl49dVXm9Qwruty9OhRbr/9dg4fPky73V63IQlDJxFxu3fvXpcCw3aBSt/tvHDCiEi/h2FaMpmMqWAgP5LYWPonLmsxOSAMugs9z2PHjh0mybFEHN95550cPHjQ6OM2siAI2L9/Py9+8YvXpRURk00bWFeqy5YmDKtdlO+bSBXEJS2HFHk2oucbBFywniWzvQEC3CUydpBZlOck47Z9+3auvPJKo0+zJRnCoAvAkQNTvV5neXl5HZjcrLmua3LpyT0FZMqhVYCV3U9hWG3mUFK9bNu2jVKpZJjqVqvF0aNHOX78uMkTKeBT+lYsFtmzZw9XXXXVI+rD2ho/+4Aj6WbkAPV0Z9dKpRLXXHPNpt9/xx13XBR9vigAWxynOIFHL0xwlMINFL1uTKgUI5UcawsNxicL6ETjlgNW5utkcQgqGRprXdJGiI5SOnFCXAzIZVwqpSztdkTYiujGMcUgIGxFeHkP7Tm0w5g00aSeIu0muFrhjmRwEk272qVdD0k0pJ0Ez1U4CiamSzSWO8QK6mFE2ukyPlsm7cREvZiRbSXWTtXJeZs/dU1PTw/1pT+XKaV4/vOfz3ve856hcgPZJuVJNmtpmvIHf/AHzM/Pn9f9RHhrp94QtsLzPHN6lwWzVqvRbDbJZDKsrq6uy+gvJ2PbdQP9nFUnTpwwYfmDp23P85ienmZubo5SqWQAjTBR8MiknXKSlXqd+Xyedrs9lI5J7m8zRXCWLbTZPGHZms0mSikajYZJaGqH1wvbIhtOu93mzjvv5Otf/zqnTp0ym5Lo/OSULbm0MpnMurQC8rtsfLLJClMpLjeJSB124xZGyR5XAZoTExNmfG22Rd4rJlqcZz3rWUxNTZmoO4CTJ09y+PBh6vW6cSXZUa8yZsJYrqyskMvl1umMpK3yPATUSZRyEAQ0Go2h3IK2y1OegwTMyMZtzz3RGNpuXAmymJyc5EUvehFXXHEFSZIwNTVl2GSJIj1XGwqFggF4NoM5eEAR9krYtXvuuYeFhYV1ya2H6XupVKLZbBpGWVgj+b/c3+6zjIXdNgFA8mxmZ2epVCrcf//9Rt+6EaAUNjdNU+POtgMd4Gz5O1mfAJaXl/n617/OyZMnTfLqYQ8poh+19WKAceHb88w+CNXrdbNeyvu3bdvG5OSkcbFL5PCxY8fMnJd7SJ9zuZw52Em0sR3cJWuOAGnAeDlOnDhBs9kkl8s96tx6Otjq6ip/93d/x7/6V//qMd974sSJ89aTP9F2UQA2ULTDGLQ+w27FjGY88qWAJEooZQO61ZBM4NI93aIyUSDtpehGvxB7Enj0ltrkJzOkvsPqqQa9MMZ3HbKFgMB38fIe3TBGdyMKI1kysSbxHBqNHn4lQ/dUk0LGIT9VoL7QQmVciDQqhZznUporUdk7RuOrJ3F9BxWlVHaMoAo+q4tNnIxH2gzJ5zzidLiNa9BGR0e57rrr+OxnP/uYn3cch507d/KWt7yFt7/97ezYseMR7/nKV77ymO6qIAi49dZbefazn73ptj/wwAP8xV/8xabfP2g2rS9gQUCVgDYBacJgiWZHIjorlQozMzNUKpV1JYmiKGJ1dZXDhw+zsLCw4elIFjPJBWezJxJZKODG1pFUq1VWVlZYXl5e195hs2Hbbk4ZC8/zTNSnuDNXVlZYWFgw4n4BhxKkMDo6yszMjEm8K+Dn4Ycf5stf/jInT55c139xfU9OTlIqlYx2TNwejuPQbrfN6Vui2GQTWVpa4qGHHqLVapmN73xPn5Jbz3aBCps1Pz9vKl/IGMn7hE2Zm5vjmmuu4VnPepYBFaLnOXr0qEkqa4+3AANhkDqdDg899JARYEuiYDtCFvob1/LyMvfee69x0Qs4HpZhFtAmLOrk5KQJMshmswagi7DdBmu5XI6JiQmuuOIKbrzxRm688UaTQLlYLLK2tsbp06cfdc6LK1IYaPn+2AcVARPiHm42m9x1111mPTkfna2AFjkIiC5PnpEcQDZKFyIi+kKhwI4dO5ibm2Nqaor777+fZrPJa17zGqIo4p577tmQ8RWwJyB4cXGRT3/607z5zW82Qn2pXiAARjS9q6ur3Hbbbdx2220mUKperw99SLEDe5RSBqhJehbJsVatVtfV/BWwJi7syy67jEsuucQwcmNjY5w4cYLDhw9Tq9XWjZ2wmnagQpIkHDlyxLBzAthtbah891dWVrjzzju56667DONoH+yejqa15oMf/CAvfOELufbaa89JmiwsLPDWt76VO++886lt4DnsogBsyunnYktTjZtoijmXbrtHcTJPe6mNXw5IWiFu1kFpRVQN+8L/XBankqF1sEriK5aP1ej1YqJOzPYdFUqTeY7et8hEMY+jIdGakW0ldJrSaMTkR3I0w5hxP4dX8Fhr9Sic1ASeQ3F7EU85hI0Q1YgJF7u0VI2i7+LrgMg/E+qecSlM5onjhF6aQpSSDR7fsOZyuUe4STey6elp/vk//+e85S1vMfnMNrJDhw49qt4gm83yx3/8x7zsZS8zyTxXVlaMLmYje7zsGpxdwGzdSBiGlMtlc8IW15+wQ2maGs2RjEGlUjFaDNnU1tbWOHXqFCsrKxtuXLL4Q5/Vq1arJtLVdrkmSWIADWCYmEOHDrG6usry8jIrKytGizKs2QuksFhSXkhA17333svp06fpdDomKk/6PTs7y65duwxDI3qvXq/H8ePHWVlZWbewuq7L9u3bueyyy8wYSISsaGdKpZL5jGzKtvD49OnTfPe73zWRcsvLy+eVN1DG2A4GEF1brVbj5MmTppi1gAzZdEqlErt27eLmm29mZmZmnVs5DENTBUACFaQPg2k5ZJ4dOHCAer3Ojh072L9/vwliEEAmou3Dhw+b+okCbIdh16QdtjtU2iW1SoXBaDQahimSZ1Eul5menuYHf/AHufHGG5mYmMD3fVZWVgz4PX78uEm9YJswePZYLi8v8+1vf5vTp08zMzPDlVdeaWrSyjORQ9JDDz3EJz7xCe6++26TJkX6M0zfpSKJbP7y3RLBvB14JJ+RMZqYmOBHf/RHef7zn0+hUKDRaFAsFpmfn+eSSy7hnnvu2ZD1k2vI9y2OY1ZXV/mbv/kbHnroIW6++WZe/epXs2/fPpMGSOZdkiTcf//9fPzjH+fYsWNkMhmazeY6gLPZvos7VNYpOTDK90sOZ8LaSgCAJK299tprufbaaw2LLBVm0jRlfn7+EcEASinjOZH+iwZYDh67du3iqquuYseOHaayi1wziiIOHTrEF77wBRYWFkziXvn+PJ3t4Ycf5rWvfS2/+Iu/yM/+7M9uuNd98IMf5Itf/OIFaN3GdlEANpTCUQrlgE5SeommXAzoLLapL7eJ44TRiTzdXoSTKuK8h0o0YTtm9USNXCGgvtYj7aWoWBMEHt1Wj2zJR2noOpDrJhR9n/aJBkHOI7e9xOKxGmk7IY00nufSWumQ+CljO0pksj5p4JDNuDTCBq7jsXy6ias0JCkRKeVKBj/rk+YDnIJPtNbBQ5HGjz8D9POf/3z+5//8n+cEWo7j8Au/8Au8+93vftQFM47jx9RX7du3j5e//OVMTEzQbDb51V/9VT796U9z2WWX8S//5b/kVa961SMm88LCAn/5l395Xto126SagAjNxf0iIlspai1lVOS9jUaDnTt3rhMqy0IYx7ERXG/kphSgIq7IKIo4fvy4KYeUy+XMZ6MoYtu2bcb1IklMDx8+zNGjRwnDkJWVFRM8MEzFh8GFW3Q8IpqvVqscOXKEe++91wBjSazr+z5TU1OmFJX0Rxg6Ox2ArfnZvn07z3nOc5iamjKaPhHbnzx5kjAMjbsuSRKKxeK6tCvNZpMjR44YEa7kS9tI5/doZgNUaXc2m2Xnzp0ALC4umvEX4CHsjCSJlU1fWDkBGY1GwyQ3FvZO5tVg6gJx8wkje/DgQY4fP85NN93E/v37GRsbM21NkoS1tbV1B4hOp2NA4PmYsH7ZbJaZmRmazeY6N6itPSqXy2zfvp2bbrqJZz/72abOoegIbZfiIPthR8MKWBOx+3e+8x2++tWvks/nefGLX8zNN9/M7Oys0ZbKM7j//vv52te+ZsTX4roXdnazNj09TbFYNGuTzFNppxw45AAmY+R5HpdffjnPe97zTImwNE255JJLTOksiXQeHGP512bZZH7cfvvtfPe73+Xzn/8873jHO7jlllsYHR01TFKr1eL222/nwIEDhoG2md5hzGa4oigiCAJGR0cNqyZJweU+kvg4k8mwc+dOdu7cabRu4koWF+pgkISANWHRbJdyo9EgiiKOHj3K9773PR566CFe/OIXs3fv3nWVZzqdDgcPHuSBBx5geXnZRNHKXJIygk9XO3XqFL/0S7/El7/8Zd773vdy9dVXrzvI/+///b8f9x73RNpFAdg8pchlPNq9iJ7W+IkmXOtR2VaittgiyAcEroOHIiQh7kRkMx69ZggJeGk/cCAhJVPwiboJa/UerV6MRpG2Y7ys1wdSjsIvZ6iudIiWu6TofuJepfAdB8eB1lKLtB3glAMCxyHwXXL5ADfrUFtuEbcjEjS6E9NY7ZA6Cnc5JvEVOuuQ7Tz+6JkXvvCFTE9Pc+rUqQ3/fuWVV/JTP/VTj7lJVqtVvvSlLz3qe7Zt22aiQz/3uc/xB3/wB2YD//rXv85P/uRP8q53vYurrrrKfEbEp4/XJAdZNps1i5ScbiWTvoARcV1KpJWc1G0RtFRCOHbsGEtLS49gGWTxt0/bjUbDMBPCKh45coT5+XlarRadTofZ2VkymQy1Wo3Tp09z+PBh1tbWjIYNGPqLbYMc2yUhrMbq6ir33XcfR48epdvtmgAN0dxNTEyQpqlheUTPJxvxoKsun8+zf/9+rr76aorFIseOHTOulxMnThiXmgAhcZVImhPoRzCfPn2aEydOsLy8bPI+SaLfYZ+9gCzRI42Pj1Ov13Fd11Q7kPfaVSeKxaLJZWbrfmSzbjabJpJPri/CbNEQCSgSQCbszoEDB1hdXWVpaYnnPve5TE5OrosclPlm588bduOy3WLior7hhhsYGRlhYWGBO++8cx2DNTIywg033MCznvUs9uzZY4C61nrd99COwLTN1onaOk8Be8KiffGLX+TUqVNcf/31XH755ezcudOAqMXFRZNvT76PMNy8z+VyBnBls1nuvfdeo0cVtlfc2AIwfN+nVCoxNjbG8573PLZv3w70vzNynTiOTV3ec7Frg78LwyvuvTvuuIP3vOc93HLLLbzqVa/iuuuuY3R01LBMkphYDlgy3ps1iUyVQ6akdJmYmDB6QDu/pGhSd+zYwfT0NLt372Z8fHxdZKr0R6quDEY2S+SwgExh8KXOrMzhVqvFysoKz33uc7nqqquYm5sz+eYWFhZYXFyk2Wya9WXYYJNcLscrX/lKXvayl/HFL36Rz372s0OvF0+WJUnCZz7zGb761a/yMz/zM7znPe9hfHycarV6UUSG2nZRALY01ag4xVEOaapxMi69akhrLEK5inzOI0WTJpBqhe8q/JEMyw+uUCxmqS42yWoIxvJEqSaNEpwY4iglW/IZmcoTLPeoRxGuUqQZl/rhFrVmh0RrJqkQJinaUxTLGbJZjzBK8LVCZV105OEVPDIrEaXJPMv1KuVCBjfSZH2XwHXpZTRryy0qxUzfXfs4TXQKGwG2/fv38+EPf3hDvdqg3X///Y/JsF1//fXmlPuHf/iH675IYRjykY98hAMHDnDbbbcZKv4LX/jCeUVG2mZT9MKQ2PoRYT7sUjiXXXaZ0ZrI6V/yZ8nPwsICy8vLG6YzsAGuLHSSU0wCGwQMiihcEu+KWFpYAdkAJVp0mFxctomex86Z1Ov1OHHiBMeOHTMsoed5XHHFFbz4xS82AEJKG7VaLePKkTZJQXfob9izs7NceumlppC9aLKk/91u1+ijJOXH5Zdfvk6zIkXmBVBLZGKn0xm6Moct/pbnkcvlTHZ/AUHCElx66aWUSiVWV1cpFouMjY0ZDZAwC6Lf+973vsfKyopJ1yAbu7xHGBabjZDNV2vN4uIi3/rWt/B9n2c/+9kUi0W63e46sbXMy2HF59J3+zMSsRnHMUePHjUuMRGU33rrrbzmNa8xrLDMURtASB6yu+++ex2zLGBVXI8y70V3KX8TBvnee+81KSGmpqYIgoB2u838/LxhhCV/oJ1odjOWz+dNChVh8L773e8yMzPD5OQkp06d4v7771/HrO3evZtrr72W/fv3m2chJiWj5Dv4jW98Y5173gZnNrsmDLT9k6b93IZ/93d/xz333MM73/lObrrpJqrVKgcOHDDzVFjKYU30h/KsRKsn6XgefvhharUagBmfq6++mquuuopsNmtq7doBPvLdrNfrPPjggwa823PErmAxuCbKgUsYdcktqZQyh6dTp04ZACmJvkXnu1m79NJL+au/+iscx+Htb387b3jDG/jbv/3bocfwybS1tTV++7d/m2q1ynvf+14++clPsry8fKGbtc4uCsCGgi6aKOkHGGTHc3SXO4Tt/gbmuArlKHpJSpDxUDmX2okmcSsiDnz8coac65DG4Gcd2qsd8uUsnU7IxNwInYU2ruvhZ32cwMHP+xRHc3TqPbyMi+u5OG7KxPYR8p5L0ovRqabb6OF0QtIopROntFs9WnGC40AUxSRao8OEOimho3F6kJRVv3TV4x0Spc6pY3vb297Gddddt+61wXQFcRyztLTEpz71qUc9/SuluPLKK+l0Ohw4cIDvfve7G76vVCqtWwiHTZh5rnvbIudcLmc2gEajYcCEJHkcHR01LrEgCNYl1e12u7RaLZPHSBLm2iauUBkjcYkM9kPaoJTi+PHjjIyMGDDZarVMpKq4bSRgYdh8VAIaALMByMZy/Phxvv71r7O6umrGYNu2bTz3uc9ldnaWRqPB0tISJ06coFarrUsXEIYh9913Hw8//LBxs46NjXHFFVeYguWNRsO4W4U5kPuMjY0xOztrWIuRkRHDXkq6AGEFZmdn2bFjB91ulwMHDgzV/8GUAuIarNVqPPDAA+vqtJbLZS699FJmZ2c5ePAg7Xab48ePG5YPWBcd+s1vftMUUc9ms4Z9kfEWV6ntLraTFssYLS0tGRfV8vIyp06dMi5W0dvZ0YWbNWHC5HellElge8cdd5jNUPSKz3nOcygUCkY/pLWmUqkYBmVsbIxut8vXv/51vvSlL5l+ShCG1OUVXZJs7CJIt11vwqYJqEnT1ETFyqYtJdxEx7jZGotSVULcqDt27CCKIvbs2UMcx3z9619fF7wTBAFXXHEFt9xyiwELS0tLhu0pl8tGU3bbbbfxT//0T+tcooN59+RvAtxlDGwQI7n2jh07xtzcHN/73vc4fvy4ea990BhmDZT1Tp5rPp83c3B+fp777rtv3eFsfHycffv2cckllxh5wOnTpw0zJvn3Wq0Wd911F3feeafJ2xYEgYn8ttlUyUMp64yALwm4yefz1Ot1s+4cP36c1dVV4wItl8sUCgWjZZNxeSyz191sNssv//Ivc9999xmd6cViWms+8pGP8JnPfMZE2l5MdlEANjdwUY7CcRSJA/Vqh8BR6E5EvhygFLjKQQUOYZxCOwWV4riKIOuRy/q017rgQJDLMHfFBCrw6LUi3FZCtxeTln06UUw5F/Dgt08xNVskM3KmSkInJOs6uK7C0ZrIUxSyPirpT+pukpIk4BcD4lqbsZkS2oWgkqE23ySONV7BZ6HRIT+Rozdk8fcNx8R1ecUrXsFHP/rRR/zNrh0HcPToUf7kT/6EKIr4qZ/6Ke68807+/u//nq985SuPmc1Za82v/Mqv8Ju/+Zt0Oh1TSN22SqXCr//6rzMxMQHAXXfdxUc+8pHH3UdbYyFlpSTTvejEBBxJJJQsUkopWq0Wy8vLht6XUkzz8/MbAkrZWO2ov42YETlptlotUwJoeXnZbOSy2crCLalBhj2N2W4FWxPT6/X45je/aTQzAiZGR0eZnJwkn8+TpimHDx82p3KllIl07PV6HDp0yLRHgNX4+LipwXrq1CnuvPPOdSwc9OedBB/Is2g0Gniex8LCAvfeey/dbpfdu3eTy+WYmppix44dppzXMM9edHECnAuFAmEY8uCDD3LixAkDmmWM8vk8u3btolgs8k//9E/ceeed64CuBMzMz8+zvLy8LpWB6LokAa0I0wUoyoYijIW0qVqtmrxe99xzD/Pz84ZtkDYVi0WOHj06VN/lmdo/rVaLr371qzz44IPrhOODpYcOHz7M/Pw8u3fvZmJiwqwHDz30EJ/97Gc5ffq0+ax8p6R/9hjI90MYZDkI5XI5k8xX8v8dP36cpaUlw2iOjIxQqVQMS7vZuS9uPmE+K5UK1113HYVCgS984QscPnx4Xd9FOzg+Pk4mk2FhYYG///u/5/Dhw2itmZycZHR0lMOHD3P//fevqzYyCMSAdYDt0doYBAFhGHLXXXfxxS9+0Rx6bQmDPLfNmn1AlXnn+z7VapW7776bhx56yAQVSRvsg+rBgwe59957zUFGNG6Li4s88MADVKtV0347t6WsjbVabR0bbMsIBOjZB+Zqtco999xjvA7C9pZKJcbHxymVStxzzz2b7r9tL3zhC/na177Gr/7qr/LHf/zH53WNJ8uEab0Y7aIAbKnWdOOUsB2Rz/m0Gj1CFJlRH7/Qn+C9SBP4Li4QJylBLkD7Ia3VDqQpcQpJFJN2HJyMS8F3CbyEbi3E9RzIeRQqATFQzvrQSxktBmSKPjrWpCicZkwX8AMH3UtwPYd2FJOWA3QvIe72GcDcSKaf9225g+e5uK6m2erhlwNay22i/ONn2NI0Paf//G/+5m/4hV/4BVMb87d+67f40z/9U9rtNr/7u7+7LoJrM/ZYm02tVuOnf/qneetb38r111/PL//yL5/3F9U20eZIgXXZVEVTJYXV5TS8uLjIvn37jGtLcrZJf8VdORjWbptsUo/lwpJ21Go1lpaWTGUFyYRv5x6T8jXbtm0bqv/2KR/OuslOnDjBvffea1gLYffGxsZMrjgZt2KxaMpOiW5NQKa4mUulEqOjoybv1MmTJ01S1cEIWmEhJFptYWGBnTt3kqYp9913H/fffz8A4+PjzM3NmdI+kgB4syablx2tG8cxhw4d4v777zeuIcm1l8lkDOMg82N+ft6U4xEQIi4drbVxndtMprxX3KG2a9IWbQtwPnr0KNVq1QSXNBoNI4CXqEYpYj+MCasmz1YpxaFDh/jHf/xHw7IIAyJ6UakCsbCwwMMPP8wdd9zB6uoqJ0+epNFomJQvNnMkhws70nUwZYbMQxk/EbWfOnWKu+++m3q9zte//nWOHj26TrMobrtyubzp9UBATr1eJ45jxsbGKBaLHD58mC9/+csm6ELaL8EglUplXc4xiR6/5557zLqx0QFsMHHuRma/LmC6Vqvx13/91yilWFlZWef+s0Hf+cx5MUlldODAAb797W+vyxdoHwol8GV1dRWlFIuLi9TrdZPIVlLfyLwVgC7jYb9no0OsfHc8zzMH3jAMqdVq5tAsgT5yACgUCo+rtqZSyhw2Hs2uv/56KpUKX/3qVy8qJu5C2UUB2FzXodsJ8VGMjxdQCSRovDOsl6sdlJOg0PhZD8eFXC7AcRWtxTau5+AHDm4mi+qlRPUIUkW92sVNNH4hoFXt4OU8ei74gYuKdT/QIIK04BM3I5TvoANF7ICbKrqdpM/qrXbI5DycvIuu9nBSTeJColO8kSxhJ0JXEyqFgF6qiWqPf2Ldcccd/Kf/9J/WvSYZ7V/96lebhcL3ff7zf/7P/PRP/zSf+tSn+OhHP/q4tWWDprXmyJEjvPe97zVi7SfKJOpT9DfLy8s8/PDD1Ot1IzKXXGGyuIt7tlKpMDU1hdaatbU14wJ7NDfFMFojSW8i7Bb0xeyS6FQWdxF024vxsCZgYWFhgS9/+cssLCyYhXHnzp1ce+213HDDDczMzBgmaf/+/RQKBR588EEOHDhgcjAJeyRamYmJCfL5vDk1nwusyfgIk3jixAm+9a1v0Wq1KJfLPPjggywsLJj8d6VSyaQyESZwGJNNRe5brVb55je/ycrKCqVSiZ07d3LNNdewe/duxsbGuPLKK5mZmSGOY378x3+ca665hqNHj3LXXXfx4IMPmlqzAjrsABNhEuTHFpxL6g555jaAlI1OXO9xHJvcXMK07dy5c10t4M2YMIPCgiwvL/OpT32KEydOGFCyd+9eLr/8cpNuY2RkhJGREV70ohdx5ZVXcvLkSf72b/+WWq3GysrKhkFAAsLkOzGYMsM2eU+v16PVahn39+HDhzl06BDtdttE2vZ6PcMuDjvvJfmyUsoknf7MZz7D0aNH0VpTKBS49NJL2b59O/l8nhe84AVs27bNBBxt27aNG2+8kb/6q7/iW9/6ltFfDZp4IYbVF0rSaQEIAuJlLg0ypMOYnaBXa83S0hJf/OIXmZ+fN3VdRb88OzvLc57zHOPZuO6665iZmeGhhx7iG9/4Bvfee685WMo17dQtAmIlSMZOQmyPi3znxZMQBAErKytUq1UWFxfxPI+pqSkzZ2193PlamqZ88pOf5DOf+cy613O5HJOTk/i+z5VXXsnv/M7vMD09zSc/+Ul+7/d+b51c4JloFwVgS+KUUjagVAxwMg46o5jeWSFuh+hQ02x2cLIufsGnudgGV7EWt4gbETnHZWWphe97RGFMUAoIFMRJ0gd1YYxb8ImVJo5TAteFjIeTguc5JEFfH6dGfLTn4nmKcKVLEEHGd4g6MQqFm0CmEJBUXNJOQqJT3JxPfa1NbixHbiaP004I2z3yI8Odtgft+PHjvPvd72ZpaYnZ2Vne+MY3Mjc3xw033MDu3bsZHR1dF52Uz+e56aabuOGGG3jta1/Lrbfe+qRMahHEP5FmF7JeXl7m4MGDhsWR8in79+83+aZEkC9JW6Ue3sjIiBH+P1GgUsS8SikTFSgASNwZomUSd9KwJptpp9Ph+PHjfO1rX+OOO+5Aa83evXt5+ctfzvOf/3wTtQV9ICEpSEqlkhmnb37zm9x9990cOXKEZrNpcolJNKlosjaTmT9JEuOqOXbsmDlN+77PFVdcwfbt2015KnGhDWsiFI/jmFqtxte+9jVuv/12isUiN998M295y1vYv3+/Kb4dhqEBT7t27WL79u2EYchNN93Ehz/8YRNZKcyXnSRXtIqyscvmJu8TsCnvkQ1MmDgBOnbWeDvx87AmbZTUFp/85Cf57Gc/i+u6PO95z+PNb34zt9xyixlX230ugSESLSratY2CH4RBEXApLjnbJTz4/k6nw/z8vNGSyTjYyWXlc77vD/XshQ1L09REM3/605/ma1/7Gkopnvvc5/KOd7yDl7zkJVQqFcMyCTgqFouMjo6yY8cOrrvuOj70oQ/xmc98ZsNEucNGMooJkJd5IGBtMG+erXvcrNngeXV1lc997nN87Wtfw3VdbrzxRt74xjdy0003MTExYcCd6C2z2SyVSoU9e/ZwxRVX8Bd/8RdGqxmGoWmXnfBaXPvAIw6zdkAGYFjkbrdrNMISfJDL5YxHQe5zvgfUbrfLH//xH/Nrv/ZrxtVcKBT4yZ/8Sd7+9rdz2WWXGY2e3OPNb34zb3jDG/je977Hz//8z/ONb3zjvO79dLeLArClUUqvE+Gm0Gz2GNtRJKmH4DukOUVrOaSxEjJeC6lMFXDzPosHVvv6s1STKkg1ZDI+XsYlDhOiboRyIJfx0FFC4Dt0SXGjFEcpyDp0WzFKO9CO8fM+XhgTd2MygUuU0fRUipvLoOMU13dJewntMKJQ7EcspqkmqzXdlS6Br/CUwgVy48MnUBWLoogPfvCDfOMb3+CVr3wl73//+7n22ms3tTA4jsMll1zC1NQUR44cOe82PFWmdb8ou+iqjh49yv3334/v+9xwww1cf/31ppi30PyiLZPixsLOSRkXSXZpnyCHPWXbp+goioyrQgqkT01Nmbxxtp5pWIbJBgVHjx7lS1/6Evfccw9JknDTTTfxQz/0Q+zfv9/cT+4RRdG6BJyu6zI9Pc3+/ftNZvzTp0+jlDLlayQKVE7jsvlsBNxkgxSgIlGhU1NT7Nu3jyuuuMLUPJWoyZGRkaHGWKKARdz/3e9+l69+9atceumlvOY1r+EHfuAH2LFjxyMCE2TM7c1TQKlsoMIEyKZq1ym181TZudhEu2YDOYlAttlKW0smQQziuh/muYtmaG1tjb/+67/mIx/5CPl8nje96U284Q1vYPfu3abmpgj/bZefMIU7duxg7969fPvb3143zwXgiDDeZoNl7th1UO3PKaVMNQ3ZnEdGRoyWSt4j+s1hmRbJvdhsNvnc5z7HZz/7WUZGRviZn/kZ3vrWt7Jv3z5c16XT6Zi8gHaiYXn+k5OTXH/99Xz+8583ZcyknzLHBt2dm5mjg0BPgjEEYNv3GSboQL5PaZqytrbGl7/8ZT7/+c9TKpV43etex4/8yI+wd+/edeUBBXBL2g6pOjIxMcHOnTu56667jGsV+hICKTVlM8r2GAz+LnNeooclP1w+n2dqasqktRHwKHPqfKqbhGHIr//6r/PBD37Q5DK89tpred/73scrX/nKR93nstksN9xwAy972cu2ANsFNa1JgU4vojydh05CqkAlsPTQGi6KQiZDppJh8vpp4lZM62SLjpuSyQW4HZeom9DrxqSNhEw5wEkg7SX0HEUm8EijlOqpBtsvGSPpxfTihNDrJ+htNbq4gaLbjSGFJNVopel0E9IowlOajlKUChkKYzmazR6qB41aj5HxPAk9Elw8R5HL+OftEl1bW+MP/uAP+PznP8+f/MmfcOutt56z0sC5bNu2bVx99dVPG8AmEV8ihC+VSuzdu9cwKHbeIVlwxY0qJzDXdVlaWlqX8kDcYPYiP1hLdNBk47YLMdvJXQuFAhMTEybqTkTxsrkPm9ZD637G8Xq9zr333stDDz1ENpvlZS97GbfccosJMBDGUDZb+awtjhcXRaVSYdu2bWaspL4iYKo5yDWFZbGZJ4kSlfJOjUbDjPkll1zCFVdcYaIx0zQ1ruBhKx3I5tXpdDh58iR33nknz3rWs3jjG9/I/v37KZVKhiWQjSKKonUuH9k0c7kcMzMzBqDZ7Ie8zxbay+fkbzbLZv/fFmPD2Zxbgyzcww8/PFRZMtvtfNddd/G//tf/YmxsjJ/7uZ/jJS95CeVyeZ27WNomrljAbOCScHiQORQmDDAbo32AkQOHrcMSQJck/TJUYRgaYJrP503ewzRNKZVKTExMGJ3fMCaM6Ze+9CVuu+02xsfHefe7382rX/1qxsbGzNxcW1uj3W6bhLgSpGI/eztfm/TxXMDM7v9GZl/Dvqadt3GjChCbNQniaLfb3H333XzjG99gcnKSN7zhDbzwhS9kYmJiXakqOShI0IlEdALm+y7P32Zf7WAeWJ8rzh4jmy22q7wIIC4UClQqFTKZjPm7HJylnvBmTTSwH/7wh/nQhz5k5uQb3/hGPvShDzE1NbXpa+3bt++8XN3fD3ZRADblKEancjiuA75DZqpIpxWyeqgGGtpRjBu7hLWQ09+Yp13tkqRQ2lZk7USDNNZ4WQfd0RQnCmQLAfW1LiXXIXUViaPI5AJmLxklSlPIe4TNHrmcT9gK8TMeaTfG7aXEOZdePSSJUjqtEM91iD3F5EiWtBWRpBoHhRM4eBr0WkjedXF8l9pSh1wmoNMe7uShtebYsWN84AMfYO/evfzv//2/2b59+9CMDZzNZv90MDsPmCRnFe3G3NwcIyMjZpOyF1vJySYLie/77N692+i3JNN9t9s1p9VqtWoWosFwfBlnSSIpuY7khC/AaJDpkE21Wq0acfIw1mw2uf3226lWq5w+fZrJyUlTH3JkZGQdUyBpF6QNdtJS21UrehdZYCcnJ03KByn2PTY2xtLSEr1ez7idJHVFoVDgkksuoVQqcfLkSaNjktQYwqzZGrHzKUsVRREPPfQQp0+fpt1u86xnPYsXv/jFJpO7zWTImA8GKnieRxiGjI6Ocu211/IP//APJlhBNjqZZ/J5Ya0G9UeD6R6EYbQBmwBGmSs2sBmGaUnT1NR9vP3229m7dy8/+qM/ynXXXWfYKmmvtENc7/YzF7AlbJwADIm8lvkpjInNzkrA0mAQjgAyyWko95Zn0m63KRaLJi+duM82a3Ecc9ddd/Hxj3+cO++8k/Hxcd75znfy0pe+lFwut6490n5x4ZdKJeBs0mHHcYw8ZBBknQuc2QycmLzXZpbthMtwNgWQuJTFBTmMSVLmgwcPcuzYMbZt28ZLX/pSrr/+ekZGRtallbG1boPRxFpryuUye/bsoVKpmETGWmsTlNRoNExAi+QmhLOpdOT7JXNBDl32e+XAYx9cZF20vxebsUOHDvH85z9/3aH25ptv5nd+53eYnJwcahx/4Ad+gF27dj0tSIkn2i4KwAaQdV1CnaJcxfyRNZJWTHkyT3etw6iTpRUnxLGmvtjGdxWJTjl9YAWlIef7OF3IFzL0ahG6FVOczBHVQrK+R7ebkDopcS9CBS5pO8IDeq0YN3Bwo5R2LyaKEorFPG7GI1v26PZidC8lnw1IgKTkE/US8iNZWvV+EEOiFa7vEEYJuUqA4zo0Tg7HsN111128//3v533vex/79+8/L6AmppTiVa96Fb/3e7/3uPOkPdkm+h3RWklB8pmZGZNDyM4qDmeTrcqGbW8mnU6H06dPc/DgQXMiVUqZBV9ST4geSoCPXdJHmB05OQtYaLVaNBoNarUalUrFsABSS1PuP4xVq1W++MUvmtqoz3nOc5ibm1vHeAizZGtGbHegiI7lRCwLtARFCBPo+z6Tk5MUCgUmJydNJm9xZZbLZarVqqn0YEdQ2qyCRCxq3Y/SXVpaMov/MPNtbW2Nj33sY1QqFW6++WYuu+wyo7WTKEa7QLkwAsA6oCXswOzsLNu3b+fQoUPm/bKxSCCBHZEq4yfjbP8uz90Wh9v/F/AuAM5mODbb9//6X/8rjuMY3emePXtM5KnN6ghLLM/AbqfMibm5OcbHx1laWjKgVsZNUkPk8/l17mU4qx8V95nt5hLAaLtgpW0SfCEbvlRJ2YzNz8/zvve9j8XFRcbHx3nd617Hc57zHCN1EFBkuyVt/SJgxsLzPLZt28b4+DiLi4vm/YMHMlujaLOncg95vvZztp+n/X+bZbXXpc1YtVrlYx/7GL7vs2/fPq6++mr2799vykbJ+A/235ZoQH/dzOVy7Nixg6mpKRYWFtaxzt1u13z3xdsg3ylb3yZjbSeMlnGz04HYxeEFyEtk/GZtUFNdqVT4wAc+MDRYA5ibm+Onf/qn+Q//4T8M/dmnu10UgM3xHIIEOlGKnyR4nRQ/cMkWPTqrcGqhzuhskbgd42hF6jh0uxHlbECqoddL0MQ4DsS9hMnZErqTkLiQosiMZAh7EZ4XQNbF6yYk3QQnTvESIOtSyfuoUJM4Dm0dky/4uDMlemjiZoh2FSmgwpSo3sNPFI0wxks05WyOFI2rAa3YvqMyVP8/8YlP8MIXvvBxgzWxJ+IaT4XJgjA2Nka5XGZ8fJypqSmTIsJ2WdmL1uDpWVySp0+fNiWqstkso6OjJm+aiNvL5bLRu9gnUugvhFLjUPRVdvWBpaUlxsfH1yWSPXHihKk7OmySxTTtl5Wam5szZYDsfg9uQNIeYQBtF5+9QcvpX+qbCrMkiS9brZbJhSWflxJPlUrFRJTKBiklo+BsZKeM6eLiogGudg6sx7JOp8Pi4iJzc3OGBZWNBs4yPQLa7PEY3GQFjMlYiaBfxsfOs2bPG2Hv5No2iLO1cvYmLkBG5plskMM8ewnmuO6664zLelBbNNhWm2W0x8AGdzI+dgCMuNNyudw6HWi73V7HjAo4l4AWm0ERsGaDINF1Sh6xzZqkHclms1x22WVceuml9Ho9k0vQfm69Xs8cNsIwNOyW3TbRbNmg3v7dfk3AtbDCtr5rEJiL2fnq7CAAed8woE3yXEqwyPT0tBH3299FGyzLc5fvt8x3ea7yfsAEBtjssbi+7bkuwM1moXu9nhkT+bzMcQlwCsOQtbU1kwfufKo9iO3bt4/nPve55/35YQ4J3092UQA2nWo6UUwYJvhKkTqabiemfaTKyESe7dM56CU0OzFJmuIph7lLR3FSxcpSCy9SjI3m0XHCitcjV/DpRAm5wMdxgZxLruSRNCPiVkQUppSmC/RWu6gEnFaKW3DwthVQjsLP+sRrXXqtEHc8i1PwSX0HvRZSygekvkM3jVErMaWpAkExoF1r4yXQivpgb9N915oHHniAL33pS0xOTvLa177WaIREUzCsjk1Yhovd5GQv7j7RhtkMymAUH7BuoxKBrSzmUkBcKWXylrVaLU6ePMna2hqZTIbV1VWj/xGw4vu+AW6S5VsWarl3r9djYWGBIAgoFoumELqdA2lYm5mZYW5ujmKxaO4nfZEfya1mbx6ygEv7ZCwdx2Fqasroj8bGxsjlchQKBbNJt9ttkxwXMBv59PQ0l156KY7jcPz4cRYWFkxFA8nKPj8/j+P0SxgdPnzYZEIfthC0bDyVSsWAX0nHIRusbCq2q8j+vJ17y65OYetz7I1PxlI2XFujBJiNzd4EB0GEzEV7gx3WJSrPqVAomJqlkv3f1msKiwZnAZU9J4VNk3GRyFWpsyplvmSDlQogAmjtfgnj4jhny3zZYwNnDw5SVUTeP4zZ47i0tMTRo0fZvXv3OsAobRgsGydMm9xTtHqiyZRxtZ+bgCphRQWM2FpQmUODuqjBg6+ASFs3NwxoEUZ/ZGRkXb5A2+1vt3kQPEp77TZK5KzW/XQoIyMjOI5jaunK7wLOZY6IVlfWT3nmsvZIJQeJNhdmdW1tzRwIHw8x0Gg0WFlZGTp3pdgzNbXHRQHYUP16ovmRDGGaUh7Nk+slZHM+Yb2H7zhEroNyXSZHM4xdPopbDqgeruHGmtDRzC83CByHTjekUQmJkwTwcJRHcrpJc61LpxmyY2aETqtLca5EdjKHG2p0tUc84lPYXSIOE5yci0bTdTTtdghRQjH2cHMe7TTB8xRJI2F6tkS3E9NYaZO6ECkIlENY27ymJ0kSvvnNb3Lq1Cm++93v8rznPY+Xv/zlACZb/ac+9amh6OeJiQmuu+46HnroIaPpuRhN8h2J5kbyi8mGarMrYoMiY9t1lM1mmZubY2VlxZRVklxuhUKB48eP0+l0jLBa3KuTk5NGxyHASzYHYRuE4VpYWDCuNjmVysY5bC4ux+knxZybmzsTdZyadCWyWAuIkDbJv4CJ6LKBnCS4FP2a5DQqFArGpStuTRm7OI6pVCrGLS1jNzc3Z3JcOY5Do9Gg0Whw/Phxk2BT0gAAQ0WN2QwZ9Nk1KYGTJAnlcpnZ2VmTymUwSnCQbSuXy+zfv58HH3zQzHmbLROm1C5HJs9NnoUdpCKbt2iZbN2PDQAlEnOYA5JsiOKuXl1dZWVlxeixpG6kzCdbzySuYhtc7Nixg+c///mG/SiXy1QqFaN5W1tbM3NKypAJ+yogRFhCcXMO3kvc/bK524Xph02hI4Ck2+3y1a9+lUqlwrXXXmvAmWjZJCBHnr8wy3B2rlUqFZ73vOdx9913myL28n2RWsO2jEJYNdH02dpFGWsbFJ3rdxn/YQ/GjuOYJOGrq6sUCgUzt7LZLMVi0bBug4mAB1m3crnMvn37WFxcpNVqUSgUTELvIAio1Wrr8grK2iYHVBknObzm83mznojLv1qtmsOUpNQZZKPPxx544AF+7Md+jI997GNceumlQ3/+pS99KeVy+bzrNz9d7eIAbKnGDRxSrclnAjKFgPykR9xNyLgOzaUWruOgFeSyPvVTTda+0yJVmuxIhnKYEHVTyCr8ok9joYWT99GpouB6eBkPP+dTmCoQOYpcMc/q8TqlUpaMq1BZh+JciTRMias9crMFmCnQuXsJtdzBHc8TNyNoJkS+xklcMoFL2kvpNHukrsLPevTCGNdzh/oSy6IEfddTuVxm+/bt3HfffXz5y1/mJS95ydBfjJ/6qZ/ida97Hd/5znd4+9vfzsGDB4f6/FNlkkdsenqaXbt2GfekffobjIqE9YulsANyer3ssssoFAqmQLss9HJS7HQ6Rt/mOI4pXi5FmWVzzGaz7Nixg4WFBZaWlkzlgEFXKZx1yQ5rpVKJm266yYiHxe0gQMDW4ckpHDCbpQA2WWRd1zXZwxuNhimt5bquYVok6e/Y2JjZeCUK7/777+eee+4xLupCocDi4qJJuyIZ0x3HoV6vmyg+O1XGZi0IAubm5ti+fTvbt283rirJ7Sa6MAGjtn7NBk+ACVi54YYbOHDgAPfcc49hL+Ask2unOhBgYjMsYrIZDboGBfDZLOf5WKFQ4Prrr+dFL3oRl1xyiWFAbZZl8KAibRe9JpwttVapVPiJn/gJGo0G3/72t0nT1LgYpQqIMEzSN2Gz5RpxHJv6nKVSyYA4AZcCaCXFhFxP2rFZE93Z85//fG644QaU6uf56vV6nD59mkwmY3L+CYsi302RUAiAlEPaq1/9ar7zne/wrW99a90Bx2ZgbUZRDgHCQtt9sA9Hg6zboBRj2L5ns1n27t3L1VdfzeWXX04ulzOgXNyOg4cE+d7bOlFxVfq+zwte8AKWlpZ44IEHzPukOob03w5WkYAR13Vpt9tmvGTvEWmDrVmTsZJ1xh6nYW337t383M/9HDt37mT//v3nHSB3/fXXc/PNN190BeSfbLs4AJtSJHmPIOOzOt8kXmnhBQ6VqQJBJUvZc1g6WiUKY06drOMHLmmSEvVi0DC7s4LnOxx9YJluGFPI9IMDKjvKqF5Kux1SHskSak3SiHBHAnQYEnUinHxAdjRD60id3nIXN3Dw8j54ChWmpAqO37fMtrkRspWAnIKwFdFVoLTGybq4SpGkGr+QIQ5jsqObZ1oKhQL/5b/8Fw4ePMjrX/96rr32WsO2/PzP/zzbtm0bmrmB/iJ34MAB5ufnh/7sU2WFQoHrrruOK664gqmpKZNF3XZrDW4Kg0Jh2YjhbNZ4OZ13u10mJiZot9tUq1UjbJZrl0olSqWS2TBlQ/J9n507dwIwNTXF/fffz8LCgimFNbjBS9uGZRqEHRAQZSeIlYVRmDa7rwIQbYbPbkO322Vtbc1UvJA8duJylNJaIyMjBrAmSb/g96lTp+h0OqawuLin7IjZjQT5wwK28fFxfuzHfozt27cbLY/0V/RKdiSs7foEHuGW2SioRDY/e1MVQG5f1zZbmP9o4nMBMnZE62ZtcnKSt7/97czMzBi9pjB1cRybSGW5p91umX92gIC4QUdHR03aiCiKWFhYMAEpwrAJwyNicxuMCBOby+XI5XJG6wlnKzPYqSWAR4zvY9nMzAy/+Iu/yJ49exgZGaHX61GtVg2wFM2V9FPWAzkwSVvl0JLJZEw1FBkv0RgKUBt0IQqYGdSg2VrGR5vPNpAb5rlPTEzwxje+kV27djE2NmaeibC+dhS4rVG0v9uyRsl3WSLbhf2SMRNQZwexSCUFYfhEIyhAzpaFSHUEGdNBG5ZVHh0d5dZbb+WXfumXeM5znrPpz53LbKnEM8kuCsAWRylpO6HX1sTdmJxyIdVkImjfv0YvSojilFw+oFXt0ktTAt9DK0XBcXDHMrSW2+RyAd1uTKsbMbN7BLeXkHRjgkiTNEN03kMnGsKUUjlHFCeEOiVablMoZwmjhNrpOpnZAjiQ9BKU61AeyeKWfLrtqJ/+Qzl0ehF+xiNxFS4Knab98lW+Qya7eQ2b53m84x3veMTrjtNPgns+lqYpf/RHf8S73vUuo1O6GC0IAq655hqmp6fXJcfciFHc6DRvRy3JCbBer5tCyLKZ5vN5A4KELRDdnBSxBoy+rdPpGEAjVRRWVlbMAnuuhWrYE6fv+2zfvt24QeSELTm27AVVFl8bHAiAtCO/1tbWeOCBB4yuLEkSU9YnSRLW1tYYGRkxANEGB5dddpnRuHW7XZPhPJfLmYoGNkC29TvDuoay2Sz79+83onEZPzuac5DdEMBos61wNhCiWq3y8MMPG/bFdl3K3JL72MzZ4JySDc7evG1NobTP1tsN+9zn5ubWufPt8ZRN2h4PAWvSVps5gr7b81vf+pZxB8tcl4jCQVG7fFY2aUk4LYBNALMAJ7sWq4ybvD6MB6BYLPK85z2PMAyp1+vrcv3Jj4ANGROZ45lMxgTRCCMVxzEHDhzgu9/9rgFx9vywQY+Ao430YfI+Gf/N2LCej0wmw5VXXrmuagCwLsLTPgxKP2xNmy0ZieOYxcVF7rrrLpNSaJBRkz7akfUCyqTEnxx+MpmMYWVlnbH1jLYcQXSIm7W5uTn+7M/+7LxYuY2s1WqxvLz8hFzr6WSbAmxKqSNAA0iAWGt9vVJqDPgLYDdwBHij1npN9WfxB4FXA23gZ7TW333060OvHVMqZ4gTjcoqXAWNWofAc+i0QpQD2y+p0FrrcuzhVSrlLOVdI6SNkMWH10jaMcVyhpLKEidnsnZ3+4DL9UAHLr32mUkYJZRmCqhuRHi6RamUJa6G6FTj+g7x0TqxqwiV5vW/8mPkM3kcx8V1HP77u36fpm7xG7/375hfPs3M2Ay/8bb3MTExSqxTPviJ/8o37/46wJVKqec+Vt+fDDty5Ajvf//7hxKBP8G2qb5LBnWJeNoIrA3qRoRdEiZJ6iiKPuvIkSOcOHFi3SIjm57v+0xPT+O6Lq1Wi23btpl8VLJQrq6uUqvVCIKAv/mbv1nnPhkdHaXVaq1jHqSNgJxIr1JKfY9NzHthRmQTst1+nucZrZwd0SbAVFhEO61JrVbj1KlTLC4umsCJXq9HNpsljmPDOsZxbOqByuKepqnRSa6urvKJT3yCYrFo3GUveclLaLVaHDp0yOR9Gh0dXccInHlGm+67AAPZvAZTSdggQzZbW4MEZ0XsvV6Pw4cPs7i4aBIky9jYkW/2hjjoahbdpOTVk/eJe1auawM6uxrCZvsu95U+D0Yi2szfYI4z2Shljkj7FxcXWV5eXpdvy3ar2oBP9EsCxldXV9G6H+TxwAMPmL9rrbniiitoNpucOnXK6KEkF5/tImOT33mZT+JmlwocImmQw4poskqlknHzCRixgU2n0+G73/0ua2trGwJnG2zb0ZY2iB9kb6WdtpZ0sA8DbtJN9V2iMm1m2nbF2s9oo6AQm4WN435OvIcffpiFhQUToS3tttpm5rXNrNrPIgxDbr/99nUM39zcHEnSz4EnrL6d11Dautm+y/r+RNlf//Vf881vfvMJu97TxYZh2F6itbYh7a8AX9Ra/0el1K+c+f8vA68C9p75uRH4H2f+fVTLj2aYfPYkne8k6HZClCR0VkO0o8gXfOJIEzuQ5j083yE3mQOtaesU11MQKKIkod0KGdtexk1TtKeIkpRM1kVnfYq9hCjnkWYcAt+hdbpHVjskYUo3TimM58jP5PC0olvvkfEcdAr/z8/+F3Zsm6bbi4kc+Nhn/oTr91/HT97yJj7+Dx/l41/8KP/6p/4137z7n5hfPMFffeAvufGf3XR0s31/ou2+++7jxIkTT/Vtbdt03wWk2T9iG2lIZPHqdDrUajVOnjxJvV43+qpqtUqSJAbMiKtTWCzXdVlZWTFAZXV11eSVkutKoIJSite//vX0ej0jtD9y5IhxWdfr9XWuwTOswD3AOzfTf9mY2+32uqSYIvCV4ADbFdJut80JuNVq4fs+5XIZ3/fpdrtmgRX9j7COshFqrU0EWTabNSze/Pw8R48e5fTp02bD/sVf/EVKpRK1Wo2HH36Yu+66i9nZWa666iruuOMOVlZWNtokf3YzfbdBj4yfvGbPAxtwCPuyEchZWVnh3nvvXRfFN6g5EjBkAxkJNJHPyGY3Ojq6jk1ot9smyajoGIWBsvqwqb6LyfXtOS8HDLuddsCEvaHb804SUNubtNbabLLSD3GhiV5wbW2N5eVloigyQQ8/9EM/RJIk1Ot12u02x44do1gssm3bNk6fPm1kBQOa0k1/5zudDqurq6bfto5MGF5J5yEufIkGhbMaToDl5WXuvPPOR7ir7cOfzZba80HGxTYBSsJIiSA/CIJ1Rdbls8P2XVirQVAFPGJeyzOzK5LI79CPtDx69KhxkcLZABs7uliAqgQYyGFXKswIULv55pvxfd+srcvLyybd0vz8vAk8ke/WGYZzU30flo0ctDiOOX78uCmT9eEPf3hoCcr3gz0eyPvDwEfO/P4R4Ees1/9E9+0bQEUpNftoF9JaE/ZiWisdXKVoRhGx76IyHpVylmI5i+8qFo5WcT2HwmiO+qkG3niGMIxQvZTKeJ4Eja8cdDcmqkdEcUo+H5B4Lmm9R3xmQyhPF+k6EKFRGYdumhA5Gs9TqHpI2owIUkg7McoB5TmErYgwSnADj3+68//wshteSaRTXv6cH+Qrd36FME352h1f5bXPfxUkKUBrM31/PNZut/nmN7/JAw88sG4sv/KVrzxZt9ysDdX3QaC2kckiIcJjqQ4gYeaASeJZqVQYHx9flzuoVquZEyqc1bJEUUSj0eDYsWOsrKzgOI7RdomboFAoMDs7y/T0NJ1Oh2uvvZZdu3aZDUSAgKW52tS8BwxD0+l0qNfrhnmwC50LQJB/m80mtVrNRHFJ5GupVDK1Q6Xqged5NJtN6vW6AX+tVoulpSWWl5dZXFzkwQcf5Dvf+Q6HDx8mTVOzcQvrIT+nTp3i+uuvZ9u2bezbt49ms/kIUDRM3+2NTwJNZKMVBmkw0a3oFOfn5zl+/Di1Wo16vU6tVjMiattlZLtEbd2ZABcp9yUuaQFJovmxowuz2ax5rwC1gajNofpu38vOEyf9lbERsC7zTOaE7SYXF6Zcx2YD5XMCOOUwUq1WOXbsmAnIkcCPXC5HsVg0iatrtRqzs7OUSiUmJydNGht59mfauunvvLA1oj+zc4plMhkTrSyRrOVymYmJCcrlsjmUyNyp1Wom7cfg+MrzlmvLmNpAXOaHvEdcr/JvmqZGrjFY7Ny65qb7PgjQ7dfhbA1Y+8Aiz7NarZpIYJEmyPMU9ixNUzM3BoGpAMJ6vc78/DyNRsOw/NK/bDZLJpMhl8vRbDaZm5tjYmKCqampdQykgNph+n6+1m63+e3f/m1uuOEGPvWpTz1CEvFMss0ybBr4e6WUBn5Pa/37wLTW+vSZv88D02d+3w4ctz574sxrpzmHaQ3teo+178xTKmRQGrJKge+SK/qMXlpBPVRlZbXF8QeWKAY+uaxH83STciHA76REcdpPyYGmU+tRrGTJF3x6cX9hyeT6gQSJp+g0u2SKGUqOCy4kYUwGh+58i+xUnkRB0o5w/ABQ/NLvvxu05nUv+mFe97IfZbW+SkGXSboJ0xNTrDXWoBuzsLLI1PNnCFxn030/X2s2m7zhDW/gvvvu4+Mf/7h5XSnFv/gX/4LTp0/zsY997EJO7E0897Oi8HO5M+THdgW0Wi3m5+dZWFig1+uZGodSAF0pZXJbyeZWrVbJZrNMTU2ZpLFyam80GuTzebPQCfsG8MlPfhKlFFdddRVXX301n//859m7dy+VSoV2u81DDz1kBP3Ccg3T/16vty4aVjYPARjChsiGKxFgdl0/2VxmZmZMrjRY7y4Ud6PneRQKBQPICoUCY2NjBEFgFn8pi/WhD30I13V50YtexP79+wnDkKuvvtqwdAIUYL2YfzN9FxOWyAYr8n+bbRPA0u12OXjwIA888ACzs7Pm9VarZeqJyudtt+Oglk2Akrj0ZAOUTU7chKLzk41W3NP23LQjNzfbdxs4CliwN2pb02RH6dmJoWWsAHbu3MnMzMwjktjKsxdgKmMgc0zc5TL/kiTh05/+NEopUx5O0rxIuwddeRYw2FTf7fJbWmuTGFf6JrnBBHzIXDt69Cjf+973uOyyy7jsssvM93pmZoaDBw8aQGG7HOX5WC4883c73YXruoapiqLI1OSU9tlgxQar1rq1qb7bhwZph7TVdpXLeicH1FOnTrGwsECxWDTPQEry3XfffWa85EcifqXeqMwnGVtxP1vAi3/8x3802unZ2VniOGZqaoo0TU1FFPv7OsxzP999aGVlhbe+9a3cdtttRFHEu971Lv72b/+Wu+6667yu93S3zQK2F2mtTyqlpoDPK6UesP+otdZnwNymTSn1s/TdJ0yOTKEdxchIhnzgEWRcer0YX9PXtKWaqBejUGRSRWkkSxjF5BIIXIe45BKFMRnXw886rNU7xCOapq9orHWoBD5dUvyZvvYiO5nDSSDO9Gg0Qzr1Ho1Ek8165EMNZR/lKKJmyH/7N/+NmdIk9bjOv/rgv2FuehdoTRKm5MdypI5CAdlCABrSOEVlHn1Y7b5LNOKwprXm4MGDXHrppVx//fXr/rZ7927e+c538r/+1/+6kDq2Dc3u+9TUlBGOSib2wdOnbLaS96zdbrO4uGiqC8h7RDxdLpfNIicnY9HJQD9Du6RREZAhInURtTcaDVzX5TWveY0BAX/6p3/Kjh07jCuo0WgYECSL4GY0Gnb/p6enzYYq+jHZ+JVSJk+WbBbCmsiJWJIqS745SUQrusByuYxSioMHD7K8vEy32zWRsaVSySTVdRyHyy+/nMOHDzM+Ps6OHTt497vfzY4dO2i1WnzgAx/gsssuw3EcZmdnjUsMhgs2sPs+MzOzTkxtuzdlHCXFhc2G1Go1br/9do4cOWIqMAigkUg3G5CJC0quLZuinT/NDqSI49jUdYzjmHq9vi6x7qDOadD9tpm+S7LQwb7+v+2dzWsdVRiHnzdiCUkKNzVdRLyIhVDSpTTSpatSdeHWlV35PxS6cWvdCS70D4hCFmIIpKCC2QSqEdSiEBsld1HEC9d8DVwTCcfFnBlP0nzcj7mZmTu/B4Y7OTncnOfOZHLyzrznDW/JHl//LYmwhlnOYdR5amqKer1Oo9FIo73JeZpMSPb399OoYnh7MSndFkURMzMzTE5OMjY2xurqKrOzs+kf6b29vXQiG/ofm7Ce6T49PZ0+dJ84JxHLkZGRNEkqiTwfHh7SbrdpNBosLCzQbDaJooharUa73WZzczPNKk6ii0lSSTjBCM+vMKoZZgmHj01sbW0dWbA8jIyFi/Qe+0fl3OMeLjsSPu4RJiGEGeIHBwdsb2+zsbHBzs4O9XqdWq2WntcTExNplDI593d3d4miKL2dDhxZyijMpk7uCszNzaUVN1ZWVtI7DKOjo+nyQMk4w8/vLI4f9yiKOl4EvtVq0W63mZ+fZ2lpKf1sWq0Wy8vLhU6mGyTWzQUXwMzeByLgPeB159yfPhz6rXPuupl94vc/8/3Xk35nvOcesN6jw0XyInHixVXi8f4LPA9cJ3526WXi5IwRYBz4G7kPgzt05g+Ac+5qBc97QO4VdW/4/WH6na/y9a7K7p0yBYw757ovhtoPYWj/pI34gFwO9leBO8CHwD3ffg944PffApYBA24B33XwM9bO65PH1of7mtzL696H/06Fz3u5y71q7kNxvauyex+fWS4+nQzsGvCT334B7vv2F4BvgCfA18AV327Ax8DvwGPgZlHlB+j+j9zL696Hf7PC573c5V4196G43lXZvY/PLBefrm+JDgIzW3PO3Ty/Zznoxkfu1XTvpX+RkbvcB9G/6Oh6J/eLJLuV7Prj07wHkDHd+Mh9eOjWZ5j85T64/kWmyu6g690g+paBXHwKEWETQgghhBCnU5QImxBCCCGEOIXcJ2xmdsfM1s1sw+ISV4XHzDbN7LGZ/Whma77tipl9ZWZP/Oukbzcz+8j7/WxmrwbvI3e5y70EZOFfZXf/vdL5y13u/bhnTs6ZFs8RZxhdAy4RZ6ncyDsDpINxbwJTx9oecDQF+gO//yZHlzl5JHe5y7087ln4V9m9zMde7nLv1X0QW94RtteADefcH865A+Bz4lqkZeRtuqutKne5y7287tCFP/AGFXUfwmMv9xi5/9/eVf30Xsl7wnZa3dGi44hrq/5gcfkN6L62qtyfbS86cq+mO/Tvf+OEtqq4l/nYy13uvbpnTqe1RMVRMq+tWiLkLvequUO1/eUud7kH5OWed4TtKVAPvn7JtxUa59xT/9oEviAO+/6VhEH9a9N3P81R7s+2Fxq5V9MdMvH/9YS2qriX9tjLXe707p45eU/YvgdmzOwVM7sEvAMs5jymMzGzcTO7nOwDt4kL4i4Cd323u8CXfn8ReNdnktwCdnxYVe5yl3vB3SEbf+AhFXUv67GXu9z7dM8eN6Bshk434gyL34gzSe7nPZ4OxptZbVW5y13u+ftdlH+V3cvoL3e59+ue9aZKB0IIIYQQBSfvW6JCCCGEEOIcNGETQgghhCg4mrAJIYQQQhQcTdiEEEIIIQqOJmxCCCGEEAVHEzYhhBBCiIKjCZsQQgghRMHRhE0IIYQQouD8B37/0J2BzofaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_set = test_set.take(1)\n",
    "for img_batch,msk_batch in batch_set:\n",
    "    for i in range(20):\n",
    "        img_input = np.expand_dims(img_batch[i],axis =0)\n",
    "        pred_prob0 = np.squeeze(model0.predict(img_input))\n",
    "        #pred_mask0 = np.logical_and(pred_prob>0.5,1)\n",
    "        \n",
    "        pred_prob1 = np.squeeze(model1.predict(img_input))\n",
    "        #pred_mask1 = np.logical_and(pred_prob>0.5,1)\n",
    "        \n",
    "        pred_prob2 = np.squeeze(model2.predict(img_input))\n",
    "        #pred_mask2 = np.logical_and(pred_prob>0.5,1)\n",
    "        \n",
    "        pred_prob3 = np.squeeze(model3.predict(img_input))\n",
    "        #pred_mask3 = np.logical_and(pred_prob>0.5,1)\n",
    "        \n",
    "        pred_prob4 = np.squeeze(model4.predict(img_input))\n",
    "        #pred_mask4 = np.logical_and(pred_prob>0.5,1)\n",
    "        \n",
    "        pred_prob_sum = (pred_prob0 + pred_prob1 + pred_prob2 + pred_prob3 + pred_prob4) /5\n",
    "        pred_prob_sum_mask = np.logical_and(pred_prob_sum>0.5,1)\n",
    "        plt.figure()\n",
    "        plt.subplot(1,9,1); plt.title('img') ; plt.imshow(img_batch[i])\n",
    "        plt.subplot(1,9,2); plt.title('msk') ; plt.imshow(msk_batch[i])\n",
    "        plt.subplot(1,9,3); plt.title('pred0') ; plt.imshow(pred_prob0)\n",
    "        plt.subplot(1,9,4); plt.title('pred1') ; plt.imshow(pred_prob1)\n",
    "        plt.subplot(1,9,5); plt.title('pred2') ; plt.imshow(pred_prob2)\n",
    "        plt.subplot(1,9,6); plt.title('pred3') ; plt.imshow(pred_prob3)\n",
    "        plt.subplot(1,9,7); plt.title('pred4') ; plt.imshow(pred_prob4)\n",
    "        plt.subplot(1,9,8); plt.title('pred_sum') ; plt.imshow(pred_prob_sum)\n",
    "        plt.subplot(1,9,9); plt.title('pred_sum_mask') ; plt.imshow(pred_prob_sum_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KERA_TUNER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from kerastuner import Hyperband, HyperParameter, HyperParameters, HyperModel\n",
    "\n",
    "def build_model(hp):\n",
    "    dice_loss = sm.losses.DiceLoss()\n",
    "    focal_loss = sm.losses.BinaryFocalLoss(alpha=0.25, gamma=6.0)\n",
    "    total_loss = dice_loss + focal_loss\n",
    "    metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n",
    "    \n",
    "    BACKBONE = hp.Choice('backbone',['inceptionresnetv2','inceptionv3'])\n",
    "    model = sm.Unet(BACKBONE,input_shape=(512,512,3),classes=1,activation='sigmoid',encoder_weights='imagenet')\n",
    "    '''\n",
    "    if hp.Choice('optimizer',['adam','sgd'])=='adam':\n",
    "        model.compile(Adam(lr=hp.Choice('learning_rate',[1e-3,1e-4,1e-5])),total_loss,metrics)\n",
    "    else:\n",
    "        model.compile(SGD(lr=hp.Choice('learning_rate',[1e-3,1e-4,1e-5])),total_loss,metrics)\n",
    "    '''\n",
    "    model.compile(optimizer = Adam(hp.Float('learning_rate',1e-4,1e-2,sampling='log')),loss=total_loss,metrics=metrics)\n",
    "    return model\n",
    "    \n",
    "## CALLBACK\n",
    "model_path='./data/model/seg_tumor_0718.hdf5'\n",
    "mc = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "es = EarlyStopping(monitor = 'val_loss',patience = 4)\n",
    "lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',  # 검증 손실을 기준으로 callback이 호출됩니다\n",
    "    factor=0.5,          # callback 호출시 학습률을 1/2로 줄입니다\n",
    "    patience=2,         # epoch 4 동안 개선되지 않으면 callback이 호출됩니다\n",
    ")\n",
    "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
    "    def on_train_end(*args, **kwargs):\n",
    "        IPython.display.clear_output(wait = True)\n",
    "callbacks_list = [mc,es,lr,ClearTrainingOutput()]\n",
    "\n",
    "tuner = Hyperband(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_loss\",\n",
    "    max_epochs=10,\n",
    "    factor=3,\n",
    "    hyperband_iterations=1,\n",
    "    distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "    directory='tumor_segmentation'\n",
    ")\n",
    "\n",
    "tuner.search(\n",
    "    train_gen, \n",
    "    validation_data=valid_gen, \n",
    "    epochs=10,\n",
    "    callbacks = callbacks_list\n",
    ")\n",
    "\n",
    "tuner.results_summary()\n",
    "\n",
    "best_hp = tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "best_hp.values\n",
    "\n",
    "best_model = tuner.hypermodel.build(best_hp)\n",
    "\n",
    "model_path = './data/model/seg_tumor_tuner_inceptionv3.hdf5'\n",
    "mc = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "es = EarlyStopping(monitor = 'val_loss',patience = 8)\n",
    "lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',  # 검증 손실을 기준으로 callback이 호출됩니다\n",
    "    factor=0.5,          # callback 호출시 학습률을 1/2로 줄입니다\n",
    "    patience=4,         # epoch 4 동안 개선되지 않으면 callback이 호출됩니다\n",
    ")\n",
    "callbacks_list = [mc,es,lr]\n",
    "\n",
    "history = best_model.fit(\n",
    "    train_gen,\n",
    "    validation_data = valid_gen,\n",
    "    callbacks = callbacks_list,\n",
    "    epochs=EPOCHS,\n",
    "    max_queue_size=15,\n",
    "    use_multiprocessing=True,\n",
    "    verbose=1\n",
    ")\n",
    "best_model.evaluate(test_gen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
