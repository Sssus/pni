{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cfg import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.datagen import generator, tumor_generator\n",
    "from util.model import build_seg_model\n",
    "\n",
    "import segmentation_models as sm\n",
    "sm.set_framework('tf.keras')\n",
    "import tensorflow.keras.backend as k\n",
    "import gc\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 2 Logical GPUs\n",
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Number of devices: 2\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import IPython\n",
    "from IPython.display import Image, display\n",
    "from tensorflow.keras.preprocessing.image import load_img, array_to_img\n",
    "import PIL\n",
    "from PIL import ImageOps\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.rcParams['figure.figsize'] = (10,8)\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = generator(BATCH_SIZE,INPUT_SIZE,TRAIN_ZIP, is_train=True, zero_labels = ZERO_LABELS)\n",
    "valid_gen = generator(BATCH_SIZE,INPUT_SIZE,VALID_ZIP, is_train=False, zero_labels = ZERO_LABELS)\n",
    "test_gen = generator(BATCH_SIZE,INPUT_SIZE,TEST_ZIP, is_train=False, zero_labels = ZERO_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_x,batch_y = train_gen.__getitem__(2)\n",
    "\n",
    "for idx in range(0,5):\n",
    "    plt.figure(figsize = (12,6));\n",
    "    d = np.unique(batch_x,return_counts=True)\n",
    "    plt.subplot(1,3,1);plt.imshow((batch_x[idx]))\n",
    "    plt.subplot(1,3,2);plt.imshow(np.squeeze(batch_y[idx],axis=-1),vmin=0,vmax=2)\n",
    "    #plt.subplot(1,3,3);plt.bar(d[0],d[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN BY KERAS-TUNER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from kerastuner import Hyperband, HyperParameter, HyperParameters, HyperModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def build_model(hp):\n",
    "    dice_loss = sm.losses.DiceLoss()\n",
    "    focal_loss = sm.losses.BinaryFocalLoss(alpha=0.25, gamma=6.0)\n",
    "    total_loss = dice_loss + focal_loss\n",
    "    metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n",
    "    \n",
    "    BACKBONE = hp.Choice('backbone',['inceptionresnetv2','inceptionv3'])\n",
    "    model = sm.Unet(BACKBONE,input_shape=(512,512,3),classes=1,activation='sigmoid',encoder_weights='imagenet')\n",
    "    '''\n",
    "    if hp.Choice('optimizer',['adam','sgd'])=='adam':\n",
    "        model.compile(Adam(lr=hp.Choice('learning_rate',[1e-3,1e-4,1e-5])),total_loss,metrics)\n",
    "    else:\n",
    "        model.compile(SGD(lr=hp.Choice('learning_rate',[1e-3,1e-4,1e-5])),total_loss,metrics)\n",
    "    '''\n",
    "    model.compile(optimizer = Adam(hp.Float('learning_rate',1e-4,1e-2,sampling='log')),loss=total_loss,metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CALLBACK\n",
    "model_path='./data/model/seg_tumor_0718.hdf5'\n",
    "mc = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "es = EarlyStopping(monitor = 'val_loss',patience = 4)\n",
    "lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',  # 검증 손실을 기준으로 callback이 호출됩니다\n",
    "    factor=0.5,          # callback 호출시 학습률을 1/2로 줄입니다\n",
    "    patience=2,         # epoch 4 동안 개선되지 않으면 callback이 호출됩니다\n",
    ")\n",
    "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
    "    def on_train_end(*args, **kwargs):\n",
    "        IPython.display.clear_output(wait = True)\n",
    "callbacks_list = [mc,es,lr,ClearTrainingOutput()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tuner = Hyperband(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"val_loss\",\n",
    "    max_epochs=10,\n",
    "    factor=3,\n",
    "    hyperband_iterations=1,\n",
    "    distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "    directory='tumor_segmentation'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "tuner.search(\n",
    "    train_gen, \n",
    "    validation_data=valid_gen, \n",
    "    epochs=10,\n",
    "    callbacks = callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best_hp = tuner.get_best_hyperparameters()[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best_hp.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best_model = tuner.hypermodel.build(best_hp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_path = './data/model/seg_tumor_tuner_inceptionv3.hdf5'\n",
    "mc = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "es = EarlyStopping(monitor = 'val_loss',patience = 8)\n",
    "lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',  # 검증 손실을 기준으로 callback이 호출됩니다\n",
    "    factor=0.5,          # callback 호출시 학습률을 1/2로 줄입니다\n",
    "    patience=4,         # epoch 4 동안 개선되지 않으면 callback이 호출됩니다\n",
    ")\n",
    "callbacks_list = [mc,es,lr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "history = best_model.fit(\n",
    "    train_gen,\n",
    "    validation_data = valid_gen,\n",
    "    callbacks = callbacks_list,\n",
    "    epochs=EPOCHS,\n",
    "    max_queue_size=15,\n",
    "    use_multiprocessing=True,\n",
    "    verbose=1\n",
    ")\n",
    "best_model.evaluate(test_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN BY FIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 3)\n",
      "200\n",
      "10\n",
      "./model/0824_deeplabv3.hdf5\n",
      "deeplab\n",
      "xception\n",
      "pascal_voc\n",
      "sigmoid\n",
      "0.005\n",
      "dice+focal\n",
      "adam\n",
      "['iou', 'f1-score']\n"
     ]
    }
   ],
   "source": [
    "print(INPUT_SHAPE)\n",
    "print(EPOCHS)\n",
    "print(PATIENCE)\n",
    "print(MODEL_PATH) \n",
    "print(MODEL)\n",
    "print(BACKBONE)\n",
    "print(WEIGHT)\n",
    "print(ACTIVATION)\n",
    "print(INITIAL_LEARNING_RATE)\n",
    "print(LOSS)\n",
    "print(OPTIMIZER)\n",
    "print(METRIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'deeplab'\n",
    "MODEL_PATH = './model/0825_deeplab_xception.hdf5'\n",
    "BACKBONE = 'xception'\n",
    "WEIGHT = 'pascal_voc'\n",
    "LOSS = 'focal_dice'\n",
    "N_CLASSES = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "#loss = build_binary_loss(LOSS)\n",
    "dice_loss = sm.losses.DiceLoss()\n",
    "\n",
    "# default focal_loss (alpha=0.25, gamma=2.0)\n",
    "focal_loss = sm.losses.BinaryFocalLoss(alpha=0.25, gamma=6.0)\n",
    "loss = dice_loss + focal_loss\n",
    "optim = Adam(INITIAL_LEARNING_RATE)\n",
    "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n",
    "#metrics = [my_metric]\n",
    "class ClearMemory(Callback):\n",
    "    def on_epoch_end(self,epoch,logs=None):\n",
    "        gc.collect()\n",
    "        k.clear_session()\n",
    "        \n",
    "mc = ModelCheckpoint(filepath=MODEL_PATH, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "es = EarlyStopping(monitor = 'val_loss',patience = 10)\n",
    "lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',  # 검증 손실을 기준으로 callback이 호출됩니다\n",
    "    factor=0.5,          # callback 호출시 학습률을 1/2로 줄입니다\n",
    "    patience=5,         # epoch 4 동안 개선되지 않으면 callback이 호출됩니다\n",
    ")\n",
    "callback_list = [mc,es,lr,ClearMemory()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Number of devices: 2\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "## MULTIGPU\n",
    "import tensorflow as tf\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "with strategy.scope():\n",
    "    model = build_seg_model(model = MODEL,backbone=BACKBONE,weight = WEIGHT,input_shape=INPUT_SHAPE,n_classes=N_CLASSES,loss=LOSS,init_lr=INITIAL_LEARNING_RATE,optimizer=OPTIMIZER,is_train=False)\n",
    "    #model = sm.Deeplabv3(weights = WEIGHT,input_shape=INPUT_SHAPE,classes = N_CLASSES,activation=ACTIVATION,backbone=BACKBONE)\n",
    "    #model = sm.Unet(BACKBONE, input_shape = INPUT_SHAPE,classes=N_CLASSES, activation=ACTIVATION,encoder_weights=WEIGHT)\n",
    "    model.compile(optim, loss, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_list = build_callback(MODEL_PATH,PATIENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "INFO:tensorflow:batch_all_reduce: 440 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 440 all-reduces with algorithm = nccl, num_packs = 1\n",
      "211/211 [==============================] - 889s 4s/step - loss: 0.6582 - iou_score: 0.3007 - f1-score: 0.4434 - val_loss: 1.2075 - val_iou_score: 0.0132 - val_f1-score: 0.0132\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.20746, saving model to ./model/0825_deeplab_xception.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      "INFO:tensorflow:batch_all_reduce: 440 all-reduces with algorithm = nccl, num_packs = 1\n",
      "211/211 [==============================] - 533s 2s/step - loss: 0.4134 - iou_score: 0.5190 - f1-score: 0.6733 - val_loss: 1.8136 - val_iou_score: 0.1290 - val_f1-score: 0.2244\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.20746\n",
      "Epoch 3/200\n",
      "211/211 [==============================] - 371s 2s/step - loss: 0.3663 - iou_score: 0.5659 - f1-score: 0.7142 - val_loss: 1.1632 - val_iou_score: 0.0997 - val_f1-score: 0.1786\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.20746 to 1.16322, saving model to ./model/0825_deeplab_xception.hdf5\n",
      "Epoch 4/200\n",
      "211/211 [==============================] - 355s 2s/step - loss: 0.3455 - iou_score: 0.5877 - f1-score: 0.7317 - val_loss: 1.1844 - val_iou_score: 0.1171 - val_f1-score: 0.2060\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.16322\n",
      "Epoch 5/200\n",
      "211/211 [==============================] - 365s 2s/step - loss: 0.3259 - iou_score: 0.6068 - f1-score: 0.7485 - val_loss: 1.6269 - val_iou_score: 0.1400 - val_f1-score: 0.2390\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.16322\n",
      "Epoch 6/200\n",
      "211/211 [==============================] - 390s 2s/step - loss: 0.3106 - iou_score: 0.6222 - f1-score: 0.7600 - val_loss: 0.5664 - val_iou_score: 0.3815 - val_f1-score: 0.5361\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.16322 to 0.56635, saving model to ./model/0825_deeplab_xception.hdf5\n",
      "Epoch 7/200\n",
      "211/211 [==============================] - 330s 2s/step - loss: 0.3064 - iou_score: 0.6254 - f1-score: 0.7623 - val_loss: 0.8043 - val_iou_score: 0.2696 - val_f1-score: 0.4138\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.56635\n",
      "Epoch 8/200\n",
      "211/211 [==============================] - 317s 1s/step - loss: 0.2934 - iou_score: 0.6413 - f1-score: 0.7745 - val_loss: 0.3008 - val_iou_score: 0.6075 - val_f1-score: 0.7461\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.56635 to 0.30084, saving model to ./model/0825_deeplab_xception.hdf5\n",
      "Epoch 9/200\n",
      "211/211 [==============================] - 318s 1s/step - loss: 0.2833 - iou_score: 0.6518 - f1-score: 0.7827 - val_loss: 0.3213 - val_iou_score: 0.6071 - val_f1-score: 0.7447\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.30084\n",
      "Epoch 10/200\n",
      "211/211 [==============================] - 341s 2s/step - loss: 0.2789 - iou_score: 0.6552 - f1-score: 0.7857 - val_loss: 0.2711 - val_iou_score: 0.6494 - val_f1-score: 0.7767\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.30084 to 0.27112, saving model to ./model/0825_deeplab_xception.hdf5\n",
      "Epoch 11/200\n",
      "211/211 [==============================] - 368s 2s/step - loss: 0.2762 - iou_score: 0.6579 - f1-score: 0.7874 - val_loss: 0.3496 - val_iou_score: 0.5561 - val_f1-score: 0.7032\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.27112\n",
      "Epoch 12/200\n",
      "211/211 [==============================] - 382s 2s/step - loss: 0.2723 - iou_score: 0.6613 - f1-score: 0.7899 - val_loss: 0.4582 - val_iou_score: 0.4638 - val_f1-score: 0.6185\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.27112\n",
      "Epoch 13/200\n",
      "211/211 [==============================] - 404s 2s/step - loss: 0.2696 - iou_score: 0.6645 - f1-score: 0.7923 - val_loss: 0.5649 - val_iou_score: 0.3518 - val_f1-score: 0.5001\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.27112\n",
      "Epoch 14/200\n",
      "211/211 [==============================] - 429s 2s/step - loss: 0.2801 - iou_score: 0.6532 - f1-score: 0.7830 - val_loss: 0.4423 - val_iou_score: 0.4693 - val_f1-score: 0.6196\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.27112\n",
      "Epoch 15/200\n",
      "211/211 [==============================] - 507s 2s/step - loss: 0.2701 - iou_score: 0.6648 - f1-score: 0.7927 - val_loss: 0.3034 - val_iou_score: 0.6024 - val_f1-score: 0.7422\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.27112\n",
      "Epoch 16/200\n",
      "211/211 [==============================] - 361s 2s/step - loss: 0.2409 - iou_score: 0.6961 - f1-score: 0.8156 - val_loss: 0.2453 - val_iou_score: 0.6770 - val_f1-score: 0.7985\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.27112 to 0.24526, saving model to ./model/0825_deeplab_xception.hdf5\n",
      "Epoch 17/200\n",
      "211/211 [==============================] - 350s 2s/step - loss: 0.2280 - iou_score: 0.7095 - f1-score: 0.8255 - val_loss: 0.3946 - val_iou_score: 0.5173 - val_f1-score: 0.6626\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.24526\n",
      "Epoch 18/200\n",
      "211/211 [==============================] - 363s 2s/step - loss: 0.2271 - iou_score: 0.7100 - f1-score: 0.8258 - val_loss: 0.2336 - val_iou_score: 0.6888 - val_f1-score: 0.8066\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.24526 to 0.23362, saving model to ./model/0825_deeplab_xception.hdf5\n",
      "Epoch 19/200\n",
      "211/211 [==============================] - 400s 2s/step - loss: 0.2253 - iou_score: 0.7134 - f1-score: 0.8281 - val_loss: 0.2589 - val_iou_score: 0.6663 - val_f1-score: 0.7930\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.23362\n",
      "Epoch 20/200\n",
      "211/211 [==============================] - 421s 2s/step - loss: 0.2156 - iou_score: 0.7233 - f1-score: 0.8353 - val_loss: 0.2773 - val_iou_score: 0.6413 - val_f1-score: 0.7695\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.23362\n",
      "Epoch 21/200\n",
      "211/211 [==============================] - 450s 2s/step - loss: 0.2229 - iou_score: 0.7149 - f1-score: 0.8290 - val_loss: 0.2184 - val_iou_score: 0.7052 - val_f1-score: 0.8179\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.23362 to 0.21840, saving model to ./model/0825_deeplab_xception.hdf5\n",
      "Epoch 22/200\n",
      "211/211 [==============================] - 538s 2s/step - loss: 0.2184 - iou_score: 0.7191 - f1-score: 0.8321 - val_loss: 0.2419 - val_iou_score: 0.6847 - val_f1-score: 0.8031\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.21840\n",
      "Epoch 23/200\n",
      "211/211 [==============================] - 586s 3s/step - loss: 0.2156 - iou_score: 0.7236 - f1-score: 0.8353 - val_loss: 0.2400 - val_iou_score: 0.6934 - val_f1-score: 0.8129\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.21840\n",
      "Epoch 24/200\n",
      "211/211 [==============================] - 611s 3s/step - loss: 0.2169 - iou_score: 0.7214 - f1-score: 0.8338 - val_loss: 0.2464 - val_iou_score: 0.6749 - val_f1-score: 0.7966\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.21840\n",
      "Epoch 25/200\n",
      "211/211 [==============================] - 444s 2s/step - loss: 0.2198 - iou_score: 0.7181 - f1-score: 0.8316 - val_loss: 0.2519 - val_iou_score: 0.6849 - val_f1-score: 0.8067\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.21840\n",
      "Epoch 26/200\n",
      "211/211 [==============================] - 472s 2s/step - loss: 0.2113 - iou_score: 0.7279 - f1-score: 0.8384 - val_loss: 0.3851 - val_iou_score: 0.5368 - val_f1-score: 0.6784\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.21840\n",
      "Epoch 27/200\n",
      "211/211 [==============================] - 566s 3s/step - loss: 0.2013 - iou_score: 0.7383 - f1-score: 0.8454 - val_loss: 0.2080 - val_iou_score: 0.7226 - val_f1-score: 0.8309\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.21840 to 0.20801, saving model to ./model/0825_deeplab_xception.hdf5\n",
      "Epoch 28/200\n",
      "211/211 [==============================] - 663s 3s/step - loss: 0.1926 - iou_score: 0.7466 - f1-score: 0.8513 - val_loss: 0.2502 - val_iou_score: 0.6906 - val_f1-score: 0.8058\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.20801\n",
      "Epoch 29/200\n",
      "211/211 [==============================] - 696s 3s/step - loss: 0.1946 - iou_score: 0.7456 - f1-score: 0.8506 - val_loss: 0.2088 - val_iou_score: 0.7162 - val_f1-score: 0.8261\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.20801\n",
      "Epoch 30/200\n",
      "211/211 [==============================] - 741s 3s/step - loss: 0.1910 - iou_score: 0.7485 - f1-score: 0.8528 - val_loss: 0.2065 - val_iou_score: 0.7208 - val_f1-score: 0.8295\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.20801 to 0.20648, saving model to ./model/0825_deeplab_xception.hdf5\n",
      "Epoch 31/200\n",
      "211/211 [==============================] - 764s 4s/step - loss: 0.1887 - iou_score: 0.7515 - f1-score: 0.8546 - val_loss: 0.2047 - val_iou_score: 0.7197 - val_f1-score: 0.8288\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.20648 to 0.20471, saving model to ./model/0825_deeplab_xception.hdf5\n",
      "Epoch 32/200\n",
      "211/211 [==============================] - 863s 4s/step - loss: 0.1851 - iou_score: 0.7546 - f1-score: 0.8570 - val_loss: 0.2217 - val_iou_score: 0.7052 - val_f1-score: 0.8187\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.20471\n",
      "Epoch 33/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192/211 [==========================>...] - ETA: 1:03 - loss: 0.1914 - iou_score: 0.7483 - f1-score: 0.8524"
     ]
    }
   ],
   "source": [
    "model.fit(train_gen, \n",
    "            epochs = EPOCHS,\n",
    "            validation_data=valid_gen,\n",
    "            callbacks=callback_list,\n",
    "            max_queue_size=20,\n",
    "            workers=10,\n",
    "            #use_multiprocessing=True,\n",
    "            #verbose=1\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "#loss = build_binary_loss(LOSS)\n",
    "dice_loss = sm.losses.DiceLoss()\n",
    "\n",
    "# default focal_loss (alpha=0.25, gamma=2.0)\n",
    "focal_loss = sm.losses.BinaryFocalLoss(alpha=0.25, gamma=6.0)\n",
    "loss = dice_loss + focal_loss\n",
    "optim = Adam(INITIAL_LEARNING_RATE)\n",
    "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n",
    "#metrics = [my_metric]\n",
    "class ClearMemory(Callback):\n",
    "    def on_epoch_end(self,epoch,logs=None):\n",
    "        gc.collect()\n",
    "        k.clear_session()\n",
    "        \n",
    "mc = ModelCheckpoint(filepath=MODEL_PATH, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "es = EarlyStopping(monitor = 'val_loss',patience = 10)\n",
    "lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',  # 검증 손실을 기준으로 callback이 호출됩니다\n",
    "    factor=0.5,          # callback 호출시 학습률을 1/2로 줄입니다\n",
    "    patience=5,         # epoch 4 동안 개선되지 않으면 callback이 호출됩니다\n",
    ")\n",
    "callbacks_list = [mc,es,lr,ClearMemory()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MULTIGPU\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "with strategy.scope():\n",
    "    #model = build_seg_model(model = MODEL)\n",
    "    #model = sm.Deeplabv3(weights = WEIGHT,input_shape=INPUT_SHAPE,classes = N_CLASSES,activation=ACTIVATION,backbone=BACKBONE)\n",
    "    model = sm.Unet(BACKBONE, input_shape = INPUT_SHAPE,classes=N_CLASSES, activation=ACTIVATION,encoder_weights=WEIGHT)\n",
    "    model.compile(optim, loss, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_gen, \n",
    "            epochs = EPOCHS,\n",
    "            validation_data=valid_gen,\n",
    "            callbacks=callbacks_list,\n",
    "            max_queue_size=20,\n",
    "            workers=10,\n",
    "            #use_multiprocessing=True,\n",
    "            #verbose=1\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (12,10))\n",
    "plt.plot(model.history.history['loss'])\n",
    "plt.plot(model.history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validate'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_val = model.evaluate(test_gen)\n",
    "print(f'IOU Score : {e_val[1]:.2f} F1-Score : {e_val[2]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model2 = build_seg_model(model='unet',backbone='inceptionv3',weight = WEIGHT,input_shape=INPUT_SHAPE,n_classes=N_CLASSES,loss=LOSS,init_lr=INITIAL_LEARNING_RATE,optimizer=OPTIMIZER,)\n",
    "model2 = sm.Unet('inceptionv3',input_shape = INPUT_SHAPE,)\n",
    "model2.load_weights('./model/0824_unet_inceptionv3.hdf5')\n",
    "model3 = sm.Unet('efficientnetb0',input_shape = INPUT_SHAPE)\n",
    "model3.load_weights('./model/0824_unet_eff0.hdf5')\n",
    "model4 = sm.Deeplabv3(backbone='xception',classes=N_CLASSES,activation=ACTIVATION)\n",
    "model4.load_weights('./model/0817_deeplabv3_xception_pascal_hsv.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "batch_x,batch_y=  test_gen.__getitem__(2)\n",
    "for i in range(10,20):\n",
    "\n",
    "    img,msk = batch_x[i],batch_y[i]\n",
    "    img = np.expand_dims(img,axis=0)\n",
    "    pr_msk = model.predict(img)\n",
    "    pr_msk = np.where(np.squeeze(pr_msk)>0.5,np.squeeze(pr_msk),0)\n",
    "    pr_msk_2 = model2.predict(img)\n",
    "    pr_msk_2 = np.where(np.squeeze(pr_msk_2)>0.5,np.squeeze(pr_msk_2),0)\n",
    "    pr_msk_3 = model3.predict(img)\n",
    "    pr_msk_3 = np.where(np.squeeze(pr_msk_3)>0.5,np.squeeze(pr_msk_3),0)\n",
    "    pr_msk_4 = model4.predict(img)\n",
    "    pr_msk_4 = np.where(np.squeeze(pr_msk_4)>0.5,np.squeeze(pr_msk_4),0)\n",
    "    plt.figure(figsize = (14,10))\n",
    "    plt.subplot(1,6,1); plt.title('new'); plt.imshow(pr_msk)\n",
    "    plt.subplot(1,6,2); plt.title('unet_inception'); plt.imshow(pr_msk_2)\n",
    "    plt.subplot(1,6,3); plt.title('unet_eff'); plt.imshow(pr_msk_3)\n",
    "    plt.subplot(1,6,4); plt.title('deeplab_x'); plt.imshow(pr_msk_4)\n",
    "    plt.subplot(1,6,5); plt.title('true_mask'); plt.imshow(np.squeeze(batch_y[i]))\n",
    "    plt.subplot(1,6,6); plt.title('true_img'); plt.imshow(np.squeeze((255*img).astype(np.uint8)))\n",
    "\n",
    "#pr_msk = np.expand_dims(pr_msk,axis=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SepConv_BN(x, filters, prefix, stride=1, kernel_size=3, rate=1, depth_activation=False, epsilon=1e-3):\n",
    "    \"\"\" SepConv with BN between depthwise & pointwise. Optionally add activation after BN\n",
    "        Implements right \"same\" padding for even kernel sizes\n",
    "        Args:\n",
    "            x: input tensor\n",
    "            filters: num of filters in pointwise convolution\n",
    "            prefix: prefix before name\n",
    "            stride: stride at depthwise conv\n",
    "            kernel_size: kernel size for depthwise convolution\n",
    "            rate: atrous rate for depthwise convolution\n",
    "            depth_activation: flag to use activation between depthwise & poinwise convs\n",
    "            epsilon: epsilon to use in BN layer\n",
    "    \"\"\"\n",
    "\n",
    "    if stride == 1:\n",
    "        depth_padding = 'same'\n",
    "    else:\n",
    "        kernel_size_effective = kernel_size + (kernel_size - 1) * (rate - 1)\n",
    "        pad_total = kernel_size_effective - 1\n",
    "        pad_beg = pad_total // 2\n",
    "        pad_end = pad_total - pad_beg\n",
    "        x = ZeroPadding2D((pad_beg, pad_end))(x)\n",
    "        depth_padding = 'valid'\n",
    "\n",
    "    if not depth_activation:\n",
    "        x = Activation(tf.nn.relu)(x)\n",
    "    x = DepthwiseConv2D((kernel_size, kernel_size), strides=(stride, stride), dilation_rate=(rate, rate),\n",
    "                        kernel_initializer = 'he_normal',\n",
    "                        padding=depth_padding, use_bias=False, name=prefix + '_depthwise')(x)\n",
    "    x = BatchNormalization(name=prefix + '_depthwise_BN', epsilon=epsilon)(x)\n",
    "    if depth_activation:\n",
    "        x = Activation(tf.nn.relu)(x)\n",
    "    x = Conv2D(filters, (1, 1), padding='same',kernel_initializer = 'he_normal',\n",
    "               use_bias=False, name=prefix + '_pointwise')(x)\n",
    "    x = BatchNormalization(name=prefix + '_pointwise_BN', epsilon=epsilon)(x)\n",
    "    if depth_activation:\n",
    "        x = Activation(tf.nn.relu)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def _conv2d_same(x, filters, prefix, stride=1, kernel_size=3, rate=1):\n",
    "    \"\"\"Implements right 'same' padding for even kernel sizes\n",
    "        Without this there is a 1 pixel drift when stride = 2\n",
    "        Args:\n",
    "            x: input tensor\n",
    "            filters: num of filters in pointwise convolution\n",
    "            prefix: prefix before name\n",
    "            stride: stride at depthwise conv\n",
    "            kernel_size: kernel size for depthwise convolution\n",
    "            rate: atrous rate for depthwise convolution\n",
    "    \"\"\"\n",
    "    if stride == 1:\n",
    "        return Conv2D(filters,\n",
    "                      (kernel_size, kernel_size),\n",
    "                      strides=(stride, stride),\n",
    "                      padding='same', use_bias=False,\n",
    "                      dilation_rate=(rate, rate),\n",
    "                      kernel_initializer = 'he_normal',\n",
    "                      name=prefix)(x)\n",
    "    else:\n",
    "        kernel_size_effective = kernel_size + (kernel_size - 1) * (rate - 1)\n",
    "        pad_total = kernel_size_effective - 1\n",
    "        pad_beg = pad_total // 2\n",
    "        pad_end = pad_total - pad_beg\n",
    "        x = ZeroPadding2D((pad_beg, pad_end))(x)\n",
    "        return Conv2D(filters,\n",
    "                      (kernel_size, kernel_size),\n",
    "                      strides=(stride, stride),\n",
    "                      kernel_initializer = 'he_normal',\n",
    "                      padding='valid', use_bias=False,\n",
    "                      dilation_rate=(rate, rate),\n",
    "                      name=prefix)(x)\n",
    "\n",
    "\n",
    "def _xception_block(inputs, depth_list, prefix, skip_connection_type, stride,\n",
    "                    rate=1, depth_activation=False, return_skip=False):\n",
    "    \"\"\" Basic building block of modified Xception network\n",
    "        Args:\n",
    "            inputs: input tensor\n",
    "            depth_list: number of filters in each SepConv layer. len(depth_list) == 3\n",
    "            prefix: prefix before name\n",
    "            skip_connection_type: one of {'conv','sum','none'}\n",
    "            stride: stride at last depthwise conv\n",
    "            rate: atrous rate for depthwise convolution\n",
    "            depth_activation: flag to use activation between depthwise & pointwise convs\n",
    "            return_skip: flag to return additional tensor after 2 SepConvs for decoder\n",
    "            \"\"\"\n",
    "    residual = inputs\n",
    "    for i in range(3):\n",
    "        residual = SepConv_BN(residual,\n",
    "                              depth_list[i],\n",
    "                              prefix + '_separable_conv{}'.format(i + 1),\n",
    "                              stride=stride if i == 2 else 1,\n",
    "                              rate=rate,\n",
    "                              depth_activation=depth_activation)\n",
    "        if i == 1:\n",
    "            skip = residual\n",
    "    if skip_connection_type == 'conv':\n",
    "        shortcut = _conv2d_same(inputs, depth_list[-1], prefix + '_shortcut',\n",
    "                                kernel_size=1,\n",
    "                                stride=stride)\n",
    "        shortcut = BatchNormalization(name=prefix + '_shortcut_BN')(shortcut)\n",
    "        outputs = Add()([residual, shortcut])\n",
    "    elif skip_connection_type == 'sum':\n",
    "        outputs = Add()([residual, inputs])\n",
    "    elif skip_connection_type == 'none':\n",
    "        outputs = residual\n",
    "    if return_skip:\n",
    "        return outputs, skip\n",
    "    else:\n",
    "        return outputs\n",
    "\n",
    "\n",
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "\n",
    "def _inverted_res_block(inputs, expansion, stride, alpha, filters, block_id, skip_connection, rate=1):\n",
    "    in_channels = inputs.shape[-1]  # inputs._keras_shape[-1]\n",
    "    pointwise_conv_filters = int(filters * alpha)\n",
    "    pointwise_filters = _make_divisible(pointwise_conv_filters, 8)\n",
    "    x = inputs\n",
    "    prefix = 'expanded_conv_{}_'.format(block_id)\n",
    "    if block_id:\n",
    "        # Expand\n",
    "\n",
    "        x = Conv2D(expansion * in_channels, kernel_size=1, padding='same',\n",
    "                   use_bias=False, activation=None,\n",
    "                   kernel_initializer = 'he_normal',\n",
    "                   name=prefix + 'expand')(x)\n",
    "        x = BatchNormalization(epsilon=1e-3, momentum=0.999,\n",
    "                               name=prefix + 'expand_BN')(x)\n",
    "        x = Activation(tf.nn.relu6, name=prefix + 'expand_relu')(x)\n",
    "    else:\n",
    "        prefix = 'expanded_conv_'\n",
    "    # Depthwise\n",
    "    x = DepthwiseConv2D(kernel_size=3, strides=stride, activation=None,kernel_initializer = 'he_normal',\n",
    "                        use_bias=False, padding='same', dilation_rate=(rate, rate),\n",
    "                        name=prefix + 'depthwise')(x)\n",
    "    x = BatchNormalization(epsilon=1e-3, momentum=0.999,\n",
    "                           name=prefix + 'depthwise_BN')(x)\n",
    "\n",
    "    x = Activation(tf.nn.relu6, name=prefix + 'depthwise_relu')(x)\n",
    "\n",
    "    # Project\n",
    "    x = Conv2D(pointwise_filters,kernel_initializer = 'he_normal',\n",
    "               kernel_size=1, padding='same', use_bias=False, activation=None,\n",
    "               name=prefix + 'project')(x)\n",
    "    x = BatchNormalization(epsilon=1e-3, momentum=0.999,\n",
    "                           name=prefix + 'project_BN')(x)\n",
    "\n",
    "    if skip_connection:\n",
    "        return Add(name=prefix + 'add')([inputs, x])\n",
    "\n",
    "    # if in_channels == pointwise_filters and stride == 1:\n",
    "    #    return Add(name='res_connect_' + str(block_id))([inputs, x])\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def Deeplabv3(weights='pascal_voc', input_tensor=None, input_shape=(512, 512, 3), classes=21, backbone='mobilenetv2',\n",
    "              OS=16, alpha=1., activation=None):\n",
    "    \"\"\" Instantiates the Deeplabv3+ architecture\n",
    "    Optionally loads weights pre-trained\n",
    "    on PASCAL VOC or Cityscapes. This model is available for TensorFlow only.\n",
    "    # Arguments\n",
    "        weights: one of 'pascal_voc' (pre-trained on pascal voc),\n",
    "            'cityscapes' (pre-trained on cityscape) or None (random initialization)\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: shape of input image. format HxWxC\n",
    "            PASCAL VOC model was trained on (512,512,3) images. None is allowed as shape/width\n",
    "        classes: number of desired classes. PASCAL VOC has 21 classes, Cityscapes has 19 classes.\n",
    "            If number of classes not aligned with the weights used, last layer is initialized randomly\n",
    "        backbone: backbone to use. one of {'xception','mobilenetv2'}\n",
    "        activation: optional activation to add to the top of the network.\n",
    "            One of 'softmax', 'sigmoid' or None\n",
    "        OS: determines input_shape/feature_extractor_output ratio. One of {8,16}.\n",
    "            Used only for xception backbone.\n",
    "        alpha: controls the width of the MobileNetV2 network. This is known as the\n",
    "            width multiplier in the MobileNetV2 paper.\n",
    "                - If `alpha` < 1.0, proportionally decreases the number\n",
    "                    of filters in each layer.\n",
    "                - If `alpha` > 1.0, proportionally increases the number\n",
    "                    of filters in each layer.\n",
    "                - If `alpha` = 1, default number of filters from the paper\n",
    "                    are used at each layer.\n",
    "            Used only for mobilenetv2 backbone. Pretrained is only available for alpha=1.\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    # Raises\n",
    "        RuntimeError: If attempting to run this model with a\n",
    "            backend that does not support separable convolutions.\n",
    "        ValueError: in case of invalid argument for `weights` or `backbone`\n",
    "    \"\"\"\n",
    "\n",
    "    if not (weights in {'pascal_voc', 'cityscapes', None}):\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization), `pascal_voc`, or `cityscapes` '\n",
    "                         '(pre-trained on PASCAL VOC)')\n",
    "\n",
    "    if not (backbone in {'xception', 'mobilenetv2'}):\n",
    "        raise ValueError('The `backbone` argument should be either '\n",
    "                         '`xception`  or `mobilenetv2` ')\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        img_input = input_tensor\n",
    "\n",
    "    if backbone == 'xception':\n",
    "        if OS == 8:\n",
    "            entry_block3_stride = 1\n",
    "            middle_block_rate = 2  # ! Not mentioned in paper, but required\n",
    "            exit_block_rates = (2, 4)\n",
    "            atrous_rates = (12, 24, 36)\n",
    "        else:\n",
    "            entry_block3_stride = 2\n",
    "            middle_block_rate = 1\n",
    "            exit_block_rates = (1, 2)\n",
    "            atrous_rates = (6, 12, 18)\n",
    "\n",
    "        x = Conv2D(32, (3, 3), strides=(2, 2),\n",
    "                   name='entry_flow_conv1_1', use_bias=False, padding='same')(img_input)\n",
    "        x = BatchNormalization(name='entry_flow_conv1_1_BN')(x)\n",
    "        x = Activation(tf.nn.relu)(x)\n",
    "\n",
    "        x = _conv2d_same(x, 64, 'entry_flow_conv1_2', kernel_size=3, stride=1)\n",
    "        x = BatchNormalization(name='entry_flow_conv1_2_BN')(x)\n",
    "        x = Activation(tf.nn.relu)(x)\n",
    "\n",
    "        x = _xception_block(x, [128, 128, 128], 'entry_flow_block1',\n",
    "                            skip_connection_type='conv', stride=2,\n",
    "                            depth_activation=False)\n",
    "        x, skip1 = _xception_block(x, [256, 256, 256], 'entry_flow_block2',\n",
    "                                   skip_connection_type='conv', stride=2,\n",
    "                                   depth_activation=False, return_skip=True)\n",
    "\n",
    "        x = _xception_block(x, [728, 728, 728], 'entry_flow_block3',\n",
    "                            skip_connection_type='conv', stride=entry_block3_stride,\n",
    "                            depth_activation=False)\n",
    "        for i in range(16):\n",
    "            x = _xception_block(x, [728, 728, 728], 'middle_flow_unit_{}'.format(i + 1),\n",
    "                                skip_connection_type='sum', stride=1, rate=middle_block_rate,\n",
    "                                depth_activation=False)\n",
    "\n",
    "        x = _xception_block(x, [728, 1024, 1024], 'exit_flow_block1',\n",
    "                            skip_connection_type='conv', stride=1, rate=exit_block_rates[0],\n",
    "                            depth_activation=False)\n",
    "        x = _xception_block(x, [1536, 1536, 2048], 'exit_flow_block2',\n",
    "                            skip_connection_type='none', stride=1, rate=exit_block_rates[1],\n",
    "                            depth_activation=True)\n",
    "\n",
    "    else:\n",
    "        OS = 8\n",
    "        first_block_filters = _make_divisible(32 * alpha, 8)\n",
    "        x = Conv2D(first_block_filters,\n",
    "                   kernel_size=3,\n",
    "                   strides=(2, 2), padding='same', use_bias=False,\n",
    "                   name='Conv' if input_shape[2] == 3 else 'Conv_')(img_input)\n",
    "        x = BatchNormalization(\n",
    "            epsilon=1e-3, momentum=0.999, name='Conv_BN')(x)\n",
    "        x = Activation(tf.nn.relu6, name='Conv_Relu6')(x)\n",
    "\n",
    "        x = _inverted_res_block(x, filters=16, alpha=alpha, stride=1,\n",
    "                                expansion=1, block_id=0, skip_connection=False)\n",
    "\n",
    "        x = _inverted_res_block(x, filters=24, alpha=alpha, stride=2,\n",
    "                                expansion=6, block_id=1, skip_connection=False)\n",
    "        x = _inverted_res_block(x, filters=24, alpha=alpha, stride=1,\n",
    "                                expansion=6, block_id=2, skip_connection=True)\n",
    "\n",
    "        x = _inverted_res_block(x, filters=32, alpha=alpha, stride=2,\n",
    "                                expansion=6, block_id=3, skip_connection=False)\n",
    "        x = _inverted_res_block(x, filters=32, alpha=alpha, stride=1,\n",
    "                                expansion=6, block_id=4, skip_connection=True)\n",
    "        x = _inverted_res_block(x, filters=32, alpha=alpha, stride=1,\n",
    "                                expansion=6, block_id=5, skip_connection=True)\n",
    "\n",
    "        # stride in block 6 changed from 2 -> 1, so we need to use rate = 2\n",
    "        x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1,  # 1!\n",
    "                                expansion=6, block_id=6, skip_connection=False)\n",
    "        x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1, rate=2,\n",
    "                                expansion=6, block_id=7, skip_connection=True)\n",
    "        x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1, rate=2,\n",
    "                                expansion=6, block_id=8, skip_connection=True)\n",
    "        x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1, rate=2,\n",
    "                                expansion=6, block_id=9, skip_connection=True)\n",
    "\n",
    "        x = _inverted_res_block(x, filters=96, alpha=alpha, stride=1, rate=2,\n",
    "                                expansion=6, block_id=10, skip_connection=False)\n",
    "        x = _inverted_res_block(x, filters=96, alpha=alpha, stride=1, rate=2,\n",
    "                                expansion=6, block_id=11, skip_connection=True)\n",
    "        x = _inverted_res_block(x, filters=96, alpha=alpha, stride=1, rate=2,\n",
    "                                expansion=6, block_id=12, skip_connection=True)\n",
    "\n",
    "        x = _inverted_res_block(x, filters=160, alpha=alpha, stride=1, rate=2,  # 1!\n",
    "                                expansion=6, block_id=13, skip_connection=False)\n",
    "        x = _inverted_res_block(x, filters=160, alpha=alpha, stride=1, rate=4,\n",
    "                                expansion=6, block_id=14, skip_connection=True)\n",
    "        x = _inverted_res_block(x, filters=160, alpha=alpha, stride=1, rate=4,\n",
    "                                expansion=6, block_id=15, skip_connection=True)\n",
    "\n",
    "        x = _inverted_res_block(x, filters=320, alpha=alpha, stride=1, rate=4,\n",
    "                                expansion=6, block_id=16, skip_connection=False)\n",
    "\n",
    "    # end of feature extractor\n",
    "\n",
    "    # branching for Atrous Spatial Pyramid Pooling\n",
    "\n",
    "    # Image Feature branch\n",
    "    shape_before = tf.shape(x)\n",
    "    b4 = GlobalAveragePooling2D()(x)\n",
    "    b4_shape = tf.keras.backend.int_shape(b4)\n",
    "    # from (b_size, channels)->(b_size, 1, 1, channels)\n",
    "    b4 = Reshape((1, 1, b4_shape[1]))(b4)\n",
    "    b4 = Conv2D(256, (1, 1), padding='same',\n",
    "                use_bias=False, name='image_pooling')(b4)\n",
    "    b4 = BatchNormalization(name='image_pooling_BN', epsilon=1e-5)(b4)\n",
    "    b4 = Activation(tf.nn.relu)(b4)\n",
    "    # upsample. have to use compat because of the option align_corners\n",
    "    size_before = tf.keras.backend.int_shape(x)\n",
    "    b4 = tf.keras.layers.experimental.preprocessing.Resizing(\n",
    "            *size_before[1:3], interpolation=\"bilinear\"\n",
    "        )(b4)\n",
    "    # simple 1x1\n",
    "    b0 = Conv2D(256, (1, 1), padding='same', use_bias=False, name='aspp0')(x)\n",
    "    b0 = BatchNormalization(name='aspp0_BN', epsilon=1e-5)(b0)\n",
    "    b0 = Activation(tf.nn.relu, name='aspp0_activation')(b0)\n",
    "\n",
    "    # there are only 2 branches in mobilenetV2. not sure why\n",
    "    if backbone == 'xception':\n",
    "        # rate = 6 (12)\n",
    "        b1 = SepConv_BN(x, 256, 'aspp1',\n",
    "                        rate=atrous_rates[0], depth_activation=True, epsilon=1e-5)\n",
    "        # rate = 12 (24)\n",
    "        b2 = SepConv_BN(x, 256, 'aspp2',\n",
    "                        rate=atrous_rates[1], depth_activation=True, epsilon=1e-5)\n",
    "        # rate = 18 (36)\n",
    "        b3 = SepConv_BN(x, 256, 'aspp3',\n",
    "                        rate=atrous_rates[2], depth_activation=True, epsilon=1e-5)\n",
    "\n",
    "        # concatenate ASPP branches & project\n",
    "        x = Concatenate()([b4, b0, b1, b2, b3])\n",
    "    else:\n",
    "        x = Concatenate()([b4, b0])\n",
    "\n",
    "    x = Conv2D(256, (1, 1), padding='same',\n",
    "               use_bias=False, name='concat_projection')(x)\n",
    "    x = BatchNormalization(name='concat_projection_BN', epsilon=1e-5)(x)\n",
    "    x = Activation(tf.nn.relu)(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    # DeepLab v.3+ decoder\n",
    "\n",
    "    if backbone == 'xception':\n",
    "        # Feature projection\n",
    "        # x4 (x2) block\n",
    "        skip_size = tf.keras.backend.int_shape(skip1)\n",
    "        x = tf.keras.layers.experimental.preprocessing.Resizing(\n",
    "                *skip_size[1:3], interpolation=\"bilinear\"\n",
    "            )(x)\n",
    "        dec_skip1 = Conv2D(48, (1, 1), padding='same',\n",
    "                           use_bias=False, name='feature_projection0')(skip1)\n",
    "        dec_skip1 = BatchNormalization(\n",
    "            name='feature_projection0_BN', epsilon=1e-5)(dec_skip1)\n",
    "        dec_skip1 = Activation(tf.nn.relu)(dec_skip1)\n",
    "        x = Concatenate()([x, dec_skip1])\n",
    "        x = SepConv_BN(x, 256, 'decoder_conv0',\n",
    "                       depth_activation=True, epsilon=1e-5)\n",
    "        x = SepConv_BN(x, 256, 'decoder_conv1',\n",
    "                       depth_activation=True, epsilon=1e-5)\n",
    "\n",
    "    # you can use it with arbitary number of classes\n",
    "    if (weights == 'pascal_voc' and classes == 21) or (weights == 'cityscapes' and classes == 19):\n",
    "        last_layer_name = 'logits_semantic'\n",
    "    else:\n",
    "        last_layer_name = 'custom_logits_semantic'\n",
    "\n",
    "    x = Conv2D(classes, (1, 1), padding='same', name=last_layer_name)(x)\n",
    "    size_before3 = tf.keras.backend.int_shape(img_input)\n",
    "    x = tf.keras.layers.experimental.preprocessing.Resizing(\n",
    "            *size_before3[1:3], interpolation=\"bilinear\"\n",
    "        )(x)\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "\n",
    "    if activation in {'softmax', 'sigmoid'}:\n",
    "        x = tf.keras.layers.Activation(activation)(x)\n",
    "\n",
    "    model = Model(inputs, x, name='deeplabv3plus')\n",
    "\n",
    "    # load weights\n",
    "\n",
    "    if weights == 'pascal_voc':\n",
    "        if backbone == 'xception':\n",
    "            weights_path = get_file('deeplabv3_xception_tf_dim_ordering_tf_kernels.h5',\n",
    "                                    WEIGHTS_PATH_X,\n",
    "                                    cache_subdir='models')\n",
    "        else:\n",
    "            weights_path = get_file('deeplabv3_mobilenetv2_tf_dim_ordering_tf_kernels.h5',\n",
    "                                    WEIGHTS_PATH_MOBILE,\n",
    "                                    cache_subdir='models')\n",
    "        model.load_weights(weights_path, by_name=True)\n",
    "    elif weights == 'cityscapes':\n",
    "        if backbone == 'xception':\n",
    "            weights_path = get_file('deeplabv3_xception_tf_dim_ordering_tf_kernels_cityscapes.h5',\n",
    "                                    WEIGHTS_PATH_X_CS,\n",
    "                                    cache_subdir='models')\n",
    "        else:\n",
    "            weights_path = get_file('deeplabv3_mobilenetv2_tf_dim_ordering_tf_kernels_cityscapes.h5',\n",
    "                                    WEIGHTS_PATH_MOBILE_CS,\n",
    "                                    cache_subdir='models')\n",
    "        model.load_weights(weights_path, by_name=True)\n",
    "    else:\n",
    "        pass\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS_PATH_X = \"https://github.com/bonlime/keras-deeplab-v3-plus/releases/download/1.1/deeplabv3_xception_tf_dim_ordering_tf_kernels.h5\"\n",
    "WEIGHTS_PATH_MOBILE = \"https://github.com/bonlime/keras-deeplab-v3-plus/releases/download/1.1/deeplabv3_mobilenetv2_tf_dim_ordering_tf_kernels.h5\"\n",
    "WEIGHTS_PATH_X_CS = \"https://github.com/bonlime/keras-deeplab-v3-plus/releases/download/1.2/deeplabv3_xception_tf_dim_ordering_tf_kernels_cityscapes.h5\"\n",
    "WEIGHTS_PATH_MOBILE_CS = \"https://github.com/bonlime/keras-deeplab-v3-plus/releases/download/1.2/deeplabv3_mobilenetv2_tf_dim_ordering_tf_kernels_cityscapes.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.python.keras.utils.data_utils import get_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (512,512,3)\n",
    "LR = 0.005\n",
    "EPOCHS = 200\n",
    "#MODEL_PATH='/data/0818_deeplabv3_xception_pascal_hsv_tumor.hdf5'\n",
    "MODEL_PATH = './model/0819_unet_inceptionv3_imagenet_hsv_tumor.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "# define optomizer\n",
    "optim = Adam(INITIAL_LEARNING_RATE)\n",
    "\n",
    "# Segmentation models losses can be combined together by '+' and scaled by integer or float factor\n",
    "dice_loss = sm.losses.DiceLoss()\n",
    "\n",
    "# default focal_loss (alpha=0.25, gamma=2.0)\n",
    "focal_loss = sm.losses.BinaryFocalLoss(alpha=0.25, gamma=6.0)\n",
    "total_loss = dice_loss + focal_loss\n",
    "\n",
    "# actulally total_loss can be imported directly from library, above example just show you how to manipulate with losses\n",
    "# total_loss = sm.losses.binary_focal_dice_loss # or sm.losses.categorical_focal_dice_loss \n",
    "\n",
    "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n",
    "#metrics = [my_metric]\n",
    "class ClearMemory(Callback):\n",
    "    def on_epoch_end(self,epoch,logs=None):\n",
    "        gc.collect()\n",
    "        k.clear_session()\n",
    "        \n",
    "mc = ModelCheckpoint(filepath=MODEL_PATH, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "es = EarlyStopping(monitor = 'val_loss',patience = 10)\n",
    "lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',  # 검증 손실을 기준으로 callback이 호출됩니다\n",
    "    factor=0.5,          # callback 호출시 학습률을 1/2로 줄입니다\n",
    "    patience=4,         # epoch 4 동안 개선되지 않으면 callback이 호출됩니다\n",
    ")\n",
    "callbacks_list = [mc,es,lr,ClearMemory()]\n",
    "#mc = ModelCheckpoint(history_files); lr = ReduceLROnPlateau()\n",
    "#callback_list = [mc,lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.utils.data_utils import get_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "with strategy.scope():\n",
    "    model = sm.Deeplabv3(weights = WEIGHT,input_shape = INPUT_SHAPE,classes=1,activation=ACTIVATION, backbone=BACKBONE,)\n",
    "    #model = sm.Unet(backbone_name = 'inceptionv3',input_shape = INPUT_SHAPE,encoder_freeze=True)\n",
    "    model.compile(optim, total_loss, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_gen, \n",
    "          epochs = EPOCHS,\n",
    "          validation_data=valid_gen,\n",
    "          callbacks=callbacks_list,\n",
    "          max_queue_size=20,\n",
    "          workers=10,\n",
    "          #use_multiprocessing=True,\n",
    "          verbose=1\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(model.history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.history.history['loss'])\n",
    "plt.plot(model.history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validate'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_val = model.evaluate(test_gen)\n",
    "print(f'IOU Score : {e_val[1]:.2f} F1-Score : {e_val[2]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_summray = MODEL_PATH.split('/')[-1][:-5]\n",
    "save_json = {'model':model_summray,'loss':e_val[0],'iou':e_val[1],'f1-score':e_val[2]}\n",
    "\n",
    "with open(f'./model/eval_{model_summray}.json','w') as json_file:\n",
    "    json.dump(save_json,json_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x,batch_y=  test_gen.__getitem__(5)\n",
    "for i in range(10,20):\n",
    "\n",
    "    img,msk = batch_x[i],batch_y[i]\n",
    "    img = np.expand_dims(img,axis=0)\n",
    "    pr_msk = model.predict(img)\n",
    "    pr_msk = np.squeeze(pr_msk)\n",
    "    pr_msk = np.where(pr_msk>0.5,pr_msk,0) # prob threhsold 0.5\n",
    "    plt.figure(figsize = (8,6))\n",
    "    plt.subplot(1,3,1); plt.title('predict'); plt.imshow(pr_msk)\n",
    "    plt.subplot(1,3,2); plt.title('true_mask'); plt.imshow(np.squeeze(batch_y[i]))\n",
    "    plt.subplot(1,3,3); plt.title('true_img'); plt.imshow(np.squeeze((255*img).astype(np.uint8)))\n",
    "\n",
    "#pr_msk = np.expand_dims(pr_msk,axis=-1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
